[{"id": "2003.00330", "submitter": "Luis Lamb", "authors": "Luis C. Lamb, Artur Garcez, Marco Gori, Marcelo Prates, Pedro Avelar,\n  Moshe Vardi", "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and\n  Perspective", "comments": "Updated version, draft of accepted IJCAI2020 Survey Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:55:13 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 20:00:26 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 12:14:42 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 20:33:01 GMT"}, {"version": "v5", "created": "Sat, 16 May 2020 20:44:26 GMT"}, {"version": "v6", "created": "Thu, 21 May 2020 17:11:36 GMT"}, {"version": "v7", "created": "Sat, 12 Jun 2021 23:05:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lamb", "Luis C.", ""], ["Garcez", "Artur", ""], ["Gori", "Marco", ""], ["Prates", "Marcelo", ""], ["Avelar", "Pedro", ""], ["Vardi", "Moshe", ""]]}, {"id": "2003.00409", "submitter": "Haokun Li", "authors": "Haokun Li and Bican Xia", "title": "Solving Satisfiability of Polynomial Formulas By Sample-Cell Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm for deciding the satisfiability of polynomial formulas over\nthe reals is proposed. The key point of the algorithm is a new projection\noperator, called sample-cell projection operator, custom-made for\nConflict-Driven Clause Learning (CDCL)-style search. Although the new operator\nis also a CAD (Cylindrical Algebraic Decomposition)-like projection operator\nwhich computes the cell (not necessarily cylindrical) containing a given sample\nsuch that each polynomial from the problem is sign-invariant on the cell, it is\nof singly exponential time complexity. The sample-cell projection operator can\nefficiently guide CDCL-style search away from conflicting states. Experiments\nshow the effectiveness of the new algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 05:36:09 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:01:35 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Li", "Haokun", ""], ["Xia", "Bican", ""]]}, {"id": "2003.00473", "submitter": "Kees Middelburg", "authors": "C. A. Middelburg", "title": "Process algebra, process scheduling, and mutual exclusion", "comments": "15 pages, there is noticeable text overlap with earlier papers\n  (arXiv:1912.10041, arXiv:1703.06822); 15 pages, Section 3.2 improved; 15\n  pages, minor improvements including replacement of reference at end Section\n  3.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the case of multi-threading as found in contemporary programming\nlanguages, parallel processes are interleaved according to what is known as a\nprocess-scheduling policy in the field of operating systems. In a previous\npaper, we extend ACP with this form of interleaving. In the current paper, we\ndo so with the variant of ACP known as ACP$_\\epsilon$. The choice of\nACP$_\\epsilon$ stems from the need to cover more process-scheduling policies.\nWe show that a process-scheduling policy supporting mutual exclusion of\ncritical subprocesses is now covered.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:13:24 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 12:41:33 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 12:48:13 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Middelburg", "C. A.", ""]]}, {"id": "2003.00509", "submitter": "Jorge Almeida", "authors": "J. Almeida and O. Kl\\'ima", "title": "Profinite congruences and unary algebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Profinite congruences on profinite algebras determining profinite quotients\nare difficult to describe. In particular, no constructive description is known\nof the least profinite congruence containing a given binary relation on the\nalgebra. On the other hand, closed congruences and fully invariant congruences\ncan be described constructively. In a previous paper, we conjectured that fully\ninvariant closed congruences on a relatively free profinite algebra are always\nprofinite. Here, we show that our conjecture fails for unary algebras and that\nclosed congruences on relatively free profinite semigroups are not necessarily\nprofinite. As part of our study of unary algebras, we establish an adjunction\nbetween profinite unary algebras and profinite monoids. We also show that the\nPolish representation of the free profinite unary algebra is faithful.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 15:57:06 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Almeida", "J.", ""], ["Kl\u00edma", "O.", ""]]}, {"id": "2003.00644", "submitter": "Jonni Virtema", "authors": "Miika Hannula, Juha Kontinen, Jan Van den Bussche and Jonni Virtema", "title": "Descriptive complexity of real computation and probabilistic\n  independence logic", "comments": null, "journal-ref": "Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in\n  Computer Science (LICS), 2020. Association for Computing Machinery, New York,\n  NY, USA, 550-563", "doi": "10.1145/3373718.3394773", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel variant of BSS machines called Separate Branching BSS\nmachines (S-BSS in short) and develop a Fagin-type logical characterisation for\nlanguages decidable in non-deterministic polynomial time by S-BSS machines. We\nshow that NP on S-BSS machines is strictly included in NP on BSS machines and\nthat every NP language on S-BSS machines is a countable union of closed sets in\nthe usual topology of R^n. Moreover, we establish that on Boolean inputs NP on\nS-BSS machines without real constants characterises a natural fragment of the\ncomplexity class existsR (a class of problems polynomial time reducible to the\ntrue existential theory of the reals) and hence lies between NP and PSPACE.\nFinally we apply our results to determine the data complexity of probabilistic\nindependence logic.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:56:38 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:56:36 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hannula", "Miika", ""], ["Kontinen", "Juha", ""], ["Bussche", "Jan Van den", ""], ["Virtema", "Jonni", ""]]}, {"id": "2003.00767", "submitter": "Ringo Baumann", "authors": "Ringo Baumann", "title": "On the Existence of Characterization Logics and Fundamental Properties\n  of Argumentation Semantics", "comments": "Treatise", "journal-ref": "https://nbn-resolving.org/urn:nbn:de:bsz:15-qucosa2-365957 2019", "doi": "10.13140/RG.2.2.21831.24483", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the large variety of existing logical formalisms it is of utmost\nimportance to select the most adequate one for a specific purpose, e.g. for\nrepresenting the knowledge relevant for a particular application or for using\nthe formalism as a modeling tool for problem solving. Awareness of the nature\nof a logical formalism, in other words, of its fundamental intrinsic\nproperties, is indispensable and provides the basis of an informed choice. In\nthis treatise we consider the existence characterization logics as well as\nproperties like existence and uniqueness, expressibility, replaceability and\nverifiability in the realm of abstract argumentation\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 11:18:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Baumann", "Ringo", ""]]}, {"id": "2003.00963", "submitter": "Caterina Viola", "authors": "Manuel Bodirsky and Marcello Mamino and Caterina Viola", "title": "Piecewise Linear Valued Constraint Satisfaction Problems with Fixed\n  Number of Variables", "comments": "10 pages. Accepted for presentation at CTW2020 and publication in\n  AIRO Springer Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many combinatorial optimisation problems can be modelled as valued constraint\nsatisfaction problems. In this paper, we present a polynomial-time algorithm\nsolving the valued constraint satisfaction problem for a fixed number of\nvariables and for piecewise linear cost functions. Our algorithm finds the\ninfimum of a piecewise linear function and decides whether it is a proper\nminimum.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:20:12 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""], ["Viola", "Caterina", ""]]}, {"id": "2003.01075", "submitter": "Christoph Berkholz", "authors": "Christoph Berkholz, Nicole Schweikardt", "title": "Constant delay enumeration with FPT-preprocessing for conjunctive\n  queries of bounded submodular width", "comments": "This is the full version of the conference contribution with the same\n  title that appeared at MFCS 2019", "journal-ref": "Proceedings of the 44th International Symposium on Mathematical\n  Foundations of Computer Science, pp. 58:1-58:15, 2019", "doi": "10.4230/LIPIcs.MFCS.2019.58", "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marx (STOC~2010, J.~ACM 2013) introduced the notion of submodular width of a\nconjunctive query (CQ) and showed that for any class $\\Phi$ of Boolean CQs of\nbounded submodular width, the model-checking problem for $\\Phi$ on the class of\nall finite structures is fixed-parameter tractable (FPT). Note that for\nnon-Boolean queries, the size of the query result may be far too large to be\ncomputed entirely within FPT time. We investigate the free-connex variant of\nsubmodular width and generalise Marx's result to non-Boolean queries as\nfollows: For every class $\\Phi$ of CQs of bounded free-connex submodular width,\nwithin FPT-preprocessing time we can build a data structure that allows to\nenumerate, without repetition and with constant delay, all tuples of the query\nresult. Our proof builds upon Marx's splitting routine to decompose the query\nresult into a union of results; but we have to tackle the additional technical\ndifficulty to ensure that these can be enumerated efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:09:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Berkholz", "Christoph", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "2003.01422", "submitter": "W{\\l}odzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "The Prolog Debugger and Declarative Programming. Examples", "comments": "11 pages, 8 figures (an example added to the previous version + a few\n  corrections)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contains examples for a companion paper \"The Prolog Debugger and\nDeclarative Programming\", which discusses (in)adequacy of the Prolog debugger\nfor declarative programming.\n  Logic programming is a declarative programming paradigm. Programming language\nProlog makes logic programming possible, at least to a substantial extent.\nHowever the Prolog debugger works solely in terms of the operational semantics.\nSo it is incompatible with declarative programming. The companion paper tries\nto find methods of using it from the declarative point of view. Here we provide\nexamples of applying them.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:16:52 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 21:01:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}, {"id": "2003.01491", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling, Carlo Angiuli, Daniel Gratzer", "title": "A Cubical Language for Bishop Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present XTT, a version of Cartesian cubical type theory specialized for\nBishop sets \\`a la Coquand, in which every type enjoys a definitional version\nof the uniqueness of identity proofs. Using cubical notions, XTT reconstructs\nmany of the ideas underlying Observational Type Theory, a version of\nintensional type theory that supports function extensionality. We prove the\ncanonicity property of XTT (that every closed boolean is definitionally equal\nto a constant) by Artin gluing.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 12:59:54 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 16:20:35 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sterling", "Jonathan", ""], ["Angiuli", "Carlo", ""], ["Gratzer", "Daniel", ""]]}, {"id": "2003.01501", "submitter": "Hiromi Tanaka", "authors": "Hiromi Tanaka", "title": "Decision Problems for Propositional Non-associative Linear Logic and\n  Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous work, we proposed the logic obtained from full\nnon-associative Lambek calculus by adding a sort of linear-logical modality. We\ncall this logic non-associative non-commutative intuitionistic linear logic\n($\\mathbf{NACILL}$, for short). In this paper, we establish the decidability\nand undecidability results for various extensions of $\\mathbf{NACILL}$.\nRegarding the decidability results, we show that the deducibility problems for\nseveral extensions of $\\mathbf{NACILL}$ with the rule of left-weakening are\ndecidable. Regarding the undecidability results, we show that the provability\nproblems for all the extensions of non-associative non-commutative classical\nlinear logic by the rules of contraction and exchange are undecidable.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 13:37:42 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Tanaka", "Hiromi", ""]]}, {"id": "2003.01696", "submitter": "Johannes Waldmann", "authors": "Alfons Geser and Dieter Hofbauer and Johannes Waldmann", "title": "Sparse Tiling through Overlap Closures for Termination of String\n  Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We over-approximate reachability sets in string rewriting by languages\ndefined by admissible factors, called tiles. A sparse set of tiles contains\nonly those that are reachable in derivations, and is constructed by completing\nan automaton. Using the partial algebra defined by a sparse tiling for semantic\nlabelling, we obtain a transformational method for proving local termination.\nWith a known result on forward closures, and a new characterisation of overlap\nclosures, we obtain methods for proving termination and relative termination,\nrespectively. We report on experiments showing the strength of these methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:36:52 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Geser", "Alfons", ""], ["Hofbauer", "Dieter", ""], ["Waldmann", "Johannes", ""]]}, {"id": "2003.02087", "submitter": "Nazanin Roshandel Tavana", "authors": "Nazanin Roshandel Tavana", "title": "An effective version of definability in metric model theory", "comments": "It was not accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a computably definable predicate is defined and characterized.\nThen, it is proved that every separable infinite-dimensional Hilbert structure\nin an effectively presented language is computable. Moreover, every definable\npredicate in these structures is computable.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 14:01:39 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 20:41:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Tavana", "Nazanin Roshandel", ""]]}, {"id": "2003.02521", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Michael Benedikt", "title": "Finite Open-World Query Answering with Number Restrictions", "comments": "70 pages. Extended journal version of arXiv:1505.04216. This article\n  is the same as what will be published in ToCL, except for publisher-induced\n  changes, minor changes, and reordering of the material (in the ToCL version\n  some detailed proofs are moved from the article body to an appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-world query answering is the problem of deciding, given a set of facts,\nconjunction of constraints, and query, whether the facts and constraints imply\nthe query. This amounts to reasoning over all instances that include the facts\nand satisfy the constraints. We study finite open-world query answering (FQA),\nwhich assumes that the underlying world is finite and thus only considers the\nfinite completions of the instance. The major known decidable cases of FQA\nderive from the following: the guarded fragment of first-order logic, which can\nexpress referential constraints (data in one place points to data in another)\nbut cannot express number restrictions such as functional dependencies; and the\nguarded fragment with number restrictions but on a signature of arity only two.\nIn this paper, we give the first decidability results for FQA that combine both\nreferential constraints and number restrictions for arbitrary signatures: we\nshow that, for unary inclusion dependencies and functional dependencies, the\nfiniteness assumption of FQA can be lifted up to taking the finite implication\nclosure of the dependencies. Our result relies on new techniques to construct\nfinite universal models of such constraints, for any bound on the maximal query\nsize.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 10:21:04 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Amarilli", "Antoine", ""], ["Benedikt", "Michael", ""]]}, {"id": "2003.02718", "submitter": "Emma Rollon", "authors": "Javier Larrosa and Emma Rollon", "title": "Towards a Better Understanding of (Partial Weighted) MaxSAT Proof\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MaxSAT, the optimization version of the well-known SAT problem, has attracted\na lot of research interest in the last decade. Motivated by the many important\napplications and inspired by the success of modern SAT solvers, researchers\nhave developed many MaxSAT solvers. Since most research is algorithmic, its\nsignificance is mostly evaluated empirically. In this paper we want to address\nMaxSAT from the more formal point of view of Proof Complexity. With that aim we\nstart providing basic definitions and proving some basic results. Then we\nanalyze the effect of adding split and virtual, two original inference rules,\nto MaxSAT resolution. We show that each addition makes the resulting proof\nsystem stronger, with the virtual rule capturing the recently proposed concept\nof circular proof.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 15:44:16 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 11:50:24 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 10:16:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Larrosa", "Javier", ""], ["Rollon", "Emma", ""]]}, {"id": "2003.02882", "submitter": "Joseph Poremba", "authors": "Joseph Poremba", "title": "Static Symmetry Breaking in Many-Sorted Finite Model Finding", "comments": "34 pages, 1 figure. Undergraduate thesis for the University of\n  Waterloo. Supervised by Prof. Nancy Day", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry in finite model finding problems of many-sorted first-order logic\n(MSFOL) can be exploited to reduce the number of interpretations considered\nduring search, thereby improving solver performance. In this thesis, we situate\nsymmetry of many-sorted finite model finding (MSFMF) problems in a general\nframework used for constraint satisfaction problems (CSP). We survey and\nclassify existing approaches to symmetry for MSFOL as used in tools such as\nParadox. We provide new insight into how sorts affect the existence of symmetry\nand how sort inference can be viewed as a symmetry detection mechanism.\nFinally, we present two new symmetry breaking schemes for MSFOL that are\nimplemented at the MSFOL level and discuss when schemes can be combined. We\nprove the correctness of our new methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:32:10 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Poremba", "Joseph", ""]]}, {"id": "2003.03332", "submitter": "Jori Bomanson", "authors": "Jori Bomanson (1) and Tomi Janhunen (1 and 2) ((1) Aalto University,\n  (2) Tampere University)", "title": "Boosting Answer Set Optimization with Weighted Comparator Networks", "comments": "36 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 512-551", "doi": "10.1017/S147106842000006X", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) is a paradigm for modeling knowledge intensive\ndomains and solving challenging reasoning problems. In ASP solving, a typical\nstrategy is to preprocess problem instances by rewriting complex rules into\nsimpler ones. Normalization is a rewriting process that removes extended rule\ntypes altogether in favor of normal rules. Recently, such techniques led to\noptimization rewriting in ASP, where the goal is to boost answer set\noptimization by refactoring the optimization criteria of interest. In this\npaper, we present a novel, general, and effective technique for optimization\nrewriting based on comparator networks, which are specific kinds of circuits\nfor reordering the elements of vectors. The idea is to connect an ASP encoding\nof a comparator network to the literals being optimized and to redistribute the\nweights of these literals over the structure of the network. The encoding\ncaptures information about the weight of an answer set in auxiliary atoms in a\nstructured way that is proven to yield exponential improvements during\nbranch-and-bound optimization on an infinite family of example programs. The\nused comparator network can be tuned freely, e.g., to find the best size for a\ngiven benchmark class. Experiments show accelerated optimization performance on\nseveral benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 17:59:34 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:03:42 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bomanson", "Jori", "", "1 and 2"], ["Janhunen", "Tomi", "", "1 and 2"]]}, {"id": "2003.03514", "submitter": "Qisheng Wang", "authors": "Qisheng Wang and Mingsheng Ying", "title": "Quantum Random Access Stored-Program Machines", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random access machines (RAMs) and random access stored-program machines\n(RASPs) are models of computing that are closer to the architecture of\nreal-world computers than Turing machines (TMs). They are also convenient in\ncomplexity analysis of algorithms. The relationships between RAMs, RASPs and\nTMs are well-studied. However, a clear relationships between their quantum\ncounterparts are still missing in the literature.\n  We fill in this gap by formally defining the models of quantum random access\nmachines (QRAMs) and quantum random access stored-program machines (QRASPs) and\nclarifying the relationships between QRAMs, QRASPs and quantum Turing machines\n(QTMs). In particular, we prove:\n  1. A $T(n)$-time QRAM (resp. QRASP) can be simulated by an $O(T(n))$-time\nQRASP (resp. QRAM).\n  2. A $T(n)$-time QRAM under the logarithmic (resp. constant) cost criterion\ncan be simulated by an $\\tilde O(T(n)^4)$-time (resp. $\\tilde O(T(n)^8)$-time)\nQTM.\n  3. A $T(n)$-time QTM can be simulated within error $\\varepsilon > 0$ by an\n$O(T(n)^2 \\operatorname{polylog}(T(n), 1/\\varepsilon))$-time QRAM (under both\nthe logarithmic and constant cost criterions).\n  As a corollary, we have: $\\textbf{P} \\subseteq \\textbf{EQRAMP} \\subseteq\n\\textbf{EQP} \\subseteq \\textbf{BQP} = \\textbf{BQRAMP}$, where $\\textbf{EQRAMP}$\nand $\\textbf{BQRAMP}$ stand for the sets of problems that can be solved by\npolynomial-time QRAMs with certainty and bounded-error, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 04:21:39 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wang", "Qisheng", ""], ["Ying", "Mingsheng", ""]]}, {"id": "2003.03729", "submitter": "Adnan Rashid", "authors": "Adnan Rashid, Umair Siddique and Sofiene Tahar", "title": "Formal Verification of Cyber-Physical Systems using Theorem Proving\n  (Invited Paper)", "comments": "15 Pages, Seventh International Workshop on Formal Techniques for\n  Safety-Critical Systems, Shenzhen, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to major breakthroughs in software and engineering technologies, embedded\nsystems are increasingly being utilized in areas ranging from aerospace and\nnext-generation transportation systems, to smart grid and smart cities, to\nhealth care systems, and broadly speaking to what is known as Cyber-Physical\nSystems (CPS). A CPS is primarily composed of several electronic, communication\nand controller modules and some actuators and sensors. The mix of heterogeneous\nunderlying smart technologies poses a number of technical challenges to the\ndesign and more severely to the verification of such complex infrastructure. In\nfact, a CPS shall adhere to strict safety, reliability, performance and\nsecurity requirements, where one needs to capture both physical and random\naspects of the various CPS modules and then analyze their interrelationship\nacross interlinked continuous and discrete dynamics. Often times however,\nsystem bugs remain uncaught during the analysis and in turn cause unwanted\nscenarios that may have serious consequences in safety-critical applications.\nIn this paper, we introduce some of the challenges surrounding the design and\nverification of contemporary CPS with the advent of smart technologies. In\nparticular, we survey recent developments in the use of theorem proving, a\nformal method, for the modeling, analysis and verification of CPS, and overview\nsome real world CPS case studies from the automotive, avionics and healthtech\ndomains from system level to physical components.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 06:11:57 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Rashid", "Adnan", ""], ["Siddique", "Umair", ""], ["Tahar", "Sofiene", ""]]}, {"id": "2003.03867", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Wojciech Penczek, and Teofil Sidoruk", "title": "Strategic Abilities of Asynchronous Agents: Semantic Side Effects and\n  How to Tame Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, we have proposed a framework for verification of agents' abilities\nin asynchronous multi-agent systems, together with an algorithm for automated\nreduction of models. The semantics was built on the modeling tradition of\ndistributed systems. As we show here, this can sometimes lead to\ncounterintuitive interpretation of formulas when reasoning about the outcome of\nstrategies. First, the semantics disregards finite paths, and thus yields\nunnatural evaluation of strategies with deadlocks. Secondly, the semantic\nrepresentations do not allow to capture the asymmetry between proactive agents\nand the recipients of their choices. We propose how to avoid the problems by a\nsuitable extension of the representations and change of the execution semantics\nfor asynchronous MAS. We also prove that the model reduction scheme still works\nin the modified framework.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 23:23:31 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 17:11:10 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 08:45:43 GMT"}, {"version": "v4", "created": "Fri, 16 Jul 2021 22:44:59 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Penczek", "Wojciech", ""], ["Sidoruk", "Teofil", ""]]}, {"id": "2003.04176", "submitter": "Philipp Wanko", "authors": "Pedro Cabalar and Jorge Fandinno and Torsten Schaub and Philipp Wanko", "title": "A Uniform Treatment of Aggregates and Constraints in Hybrid ASP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing hybrid ASP solving in a generic way is difficult since one\nneeds to abstract from specific theories. Inspired by lazy SMT solving, this is\nusually addressed by treating theory atoms as opaque. Unlike this, we propose a\nslightly more transparent approach that includes an abstract notion of a term.\nRather than imposing a syntax on terms, we keep them abstract by stipulating\nonly some basic properties. With this, we further develop a semantic framework\nfor hybrid ASP solving and provide aggregate functions for theory variables\nthat adhere to different semantic principles, show that they generalize\nexisting aggregate semantics in ASP and how we can rely on off-the-shelf hybrid\nsolvers for implementation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:36:11 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 12:42:54 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Schaub", "Torsten", ""], ["Wanko", "Philipp", ""]]}, {"id": "2003.04218", "submitter": "Christopher Hahn", "authors": "Christopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus N. Rabe,\n  Bernd Finkbeiner", "title": "Teaching Temporal Logics to Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two fundamental questions in neuro-symbolic computing: can deep\nlearning tackle challenging problems in logics end-to-end, and can neural\nnetworks learn the semantics of logics. In this work we focus on linear-time\ntemporal logic (LTL), as it is widely used in verification. We train a\nTransformer on the problem to directly predict a solution, i.e. a trace, to a\ngiven LTL formula. The training data is generated with classical solvers,\nwhich, however, only provide one of many possible solutions to each formula. We\ndemonstrate that it is sufficient to train on those particular solutions to\nformulas, and that Transformers can predict solutions even to formulas from\nbenchmarks from the literature on which the classical solver timed out.\nTransformers also generalize to the semantics of the logics: while they often\ndeviate from the solutions found by the classical solvers, they still predict\ncorrect solutions to most formulas.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:46:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:02:34 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 12:41:20 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hahn", "Christopher", ""], ["Schmitt", "Frederik", ""], ["Kreber", "Jens U.", ""], ["Rabe", "Markus N.", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2003.04225", "submitter": "Roberto Sebastiani", "authors": "Roberto Sebastiani", "title": "Are You Satisfied by This Partial Assignment?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many procedures for SAT and SAT-related problems -- in particular for those\nrequiring the complete enumeration of satisfying truth assignments -- rely\ntheir efficiency on the detection of partial assignments satisfying an input\nformula. In this paper we analyze the notion of partial-assignment\nsatisfiability -- in particular when dealing with non-CNF and\nexistentially-quantified formulas -- raising a flag about the ambiguities and\nsubtleties of this concept, and investigating their practical consequences.\nThis may drive the development of more effective assignment-enumeration\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:21:06 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Sebastiani", "Roberto", ""]]}, {"id": "2003.04245", "submitter": "Manlio Valenti", "authors": "Alberto Marcone and Manlio Valenti", "title": "The open and clopen Ramsey theorems in the Weihrauch lattice", "comments": "Improved the presentation of lemmas 4.3 and 4.13. To appear in The\n  Journal of Symbolic Logic", "journal-ref": null, "doi": "10.1017/jsl.2021.10", "report-no": null, "categories": "math.LO cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the uniform computational content of the open and clopen\nRamsey theorems in the Weihrauch lattice. While they are known to be equivalent\nto $\\mathrm{ATR_0}$ from the point of view of reverse mathematics, there is not\na canonical way to phrase them as multivalued functions. We identify 8\ndifferent multivalued functions (5 corresponding to the open Ramsey theorem and\n3 corresponding to the clopen Ramsey theorem) and study their degree from the\npoint of view of Weihrauch, strong Weihrauch and arithmetic Weihrauch\nreducibility. In particular one of our functions turns out to be strictly\nstronger than any previously studied multivalued functions arising from\nstatements around $\\mathrm{ATR}_0$.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:35:15 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 10:27:24 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 17:10:37 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Marcone", "Alberto", ""], ["Valenti", "Manlio", ""]]}, {"id": "2003.04604", "submitter": "Yannick Forster", "authors": "Dominique Larchey-Wendling and Yannick Forster", "title": "Hilbert's Tenth Problem in Coq (Extended Version)", "comments": "submitted to LMCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalise the undecidability of solvability of Diophantine equations, i.e.\npolynomial equations over natural numbers, in Coq's constructive type theory.\nTo do so, we give the first full mechanisation of the\nDavis-Putnam-Robinson-Matiyasevich theorem, stating that every recursively\nenumerable problem -- in our case by a Minsky machine -- is Diophantine. We\nobtain an elegant and comprehensible proof by using a synthetic approach to\ncomputability and by introducing Conway's FRACTRAN language as intermediate\nlayer. Additionally, we prove the reverse direction and show that every\nDiophantine relation is recognisable by $\\mu$-recursive functions and give a\ncertified compiler from $\\mu$-recursive functions to Minsky machines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 09:38:27 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 09:19:51 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Larchey-Wendling", "Dominique", ""], ["Forster", "Yannick", ""]]}, {"id": "2003.04627", "submitter": "Christoph Weidenbach", "authors": "Martin Bromberger and Alberto Fiori and Christoph Weidenbach", "title": "SCL with Theory Constraints", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We lift the SCL calculus for first-order logic without equality to the SCL(T)\ncalculus for first-order logic without equality modulo a background theory. In\na nutshell, the SCL(T) calculus describes a new way to guide hierarchic\nresolution inferences by a partial model assumption instead of an a priori\nfixed order as done for instance in hierarchic superposition. The model\nrepresentation consists of ground background theory literals and ground\nforeground first-order literals. One major advantage of the model guided\napproach is that clauses generated by SCL(T) enjoy a non-redundancy property\nthat makes expensive testing for tautologies and forward subsumption completely\nobsolete. SCL(T) is a semi-decision procedure for pure clause sets that are\nclause sets without first-order function symbols ranging into the background\ntheory sorts. Moreover, SCL(T) can be turned into a decision procedure if the\nconsidered combination of a first-order logic modulo a background theory enjoys\nan abstract finite model property.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 10:43:56 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:27:32 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 18:32:32 GMT"}, {"version": "v4", "created": "Fri, 9 Oct 2020 14:20:42 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 10:23:53 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Bromberger", "Martin", ""], ["Fiori", "Alberto", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "2003.04712", "submitter": "Apostolos Syropoulos", "authors": "Valeria de Paiva and Apostolos Syropoulos", "title": "Dialectica Fuzzy Petri Nets", "comments": "arXiv admin note: substantial text overlap with arXiv:1107.2513", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brown and Gurr have introduced a model of Petri Nets that is based on\nde~Paiva's Dialectica categories. This model was refined in an unpublished\ntechnical report, where Petri nets with multiplicities, instead of {\\em\nelementary} nets (i.e., nets with multiplicities zero and one only) were\nconsidered. In this note we expand this modelling to deal with {\\em fuzzy}\npetri nets. The basic idea is to use as the dualizing object in the Dialectica\ncategories construction, the unit interval that has all the properties of a\n{\\em lineale} structure.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 16:28:19 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["de Paiva", "Valeria", ""], ["Syropoulos", "Apostolos", ""]]}, {"id": "2003.04728", "submitter": "Adriano Peron", "authors": "Laura Bozzelli, Aniello Murano, Adriano Peron", "title": "Module checking of pushdown multi-agent systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.02107", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the module-checking problem of pushdown\nmulti-agent systems (PMS) against ATL and ATL* specifications. We establish\nthat for ATL, module checking of PMS is 2EXPTIME-complete, which is the same\ncomplexity as pushdown module-checking for CTL. On the other hand, we show that\nATL* module-checking of PMS turns out to be 4EXPTIME-complete, hence\nexponentially harder than both CTL* pushdown module-checking and ATL*\nmodel-checking of PMS. Our result for ATL* provides a rare example of a natural\ndecision problem that is elementary yet but with a complexity that is higher\nthan triply exponential-time.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 13:42:10 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Bozzelli", "Laura", ""], ["Murano", "Aniello", ""], ["Peron", "Adriano", ""]]}, {"id": "2003.04730", "submitter": "Bastien Maubert", "authors": "Rapha\\\"el Berthon, Bastien Maubert, Aniello Murano, Sasha Rubin, Moshe\n  Vardi", "title": "Strategy Logic with Imperfect Information", "comments": "arXiv admin note: text overlap with arXiv:1805.12592", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an extension of Strategy Logic for the imperfect-information\nsetting, called SLii, and study its model-checking problem. As this logic\nnaturally captures multi-player games with imperfect information, this problem\nis undecidable; but we introduce a syntactical class of \"hierarchical\ninstances\" for which, intuitively, as one goes down the syntactic tree of the\nformula, strategy quantifications are concerned with finer observations of the\nmodel, and we prove that model-checking SLii restricted to hierarchical\ninstances is decidable. To establish this result we go through QCTL, an\nintermediary, \"low-level\" logic much more adapted to automata techniques. QCTL\nis an extension of CTL with second-order quantification over atomic\npropositions. We extend it to the imperfect information setting by\nparameterising second-order quantifiers with observations. While the\nmodel-checking problem of QCTLii is, in general, undecidable, we identify a\nsyntactic fragment of hierarchical formulas and prove, using an\nautomata-theoretic approach, that it is decidable. We apply our result to solve\ncomplex strategic problems in the imperfect-information setting. We first show\nthat the existence of Nash equilibria for deterministic strategies is decidable\nin games with hierarchical information. We also introduce distributed rational\nsynthesis, a generalisation of rational synthesis to the imperfect-information\nsetting. Because it can easily be expressed in our logic, our main result\nprovides solution to this problem in the case of hierarchical information.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 13:23:01 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""], ["Vardi", "Moshe", ""]]}, {"id": "2003.04791", "submitter": "Toby Murray", "authors": "Toby Murray", "title": "An Under-Approximate Relational Logic: Heralding Logics of Insecurity,\n  Incorrect Implementation & More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, authors have proposed under-approximate logics for reasoning about\nprograms. So far, all such logics have been confined to reasoning about\nindividual program behaviours. Yet there exist many over-approximate relational\nlogics for reasoning about pairs of programs and relating their behaviours. We\npresent the first under-approximate relational logic, for the simple imperative\nlanguage IMP. We prove our logic is both sound and complete. Additionally, we\nshow how reasoning in this logic can be decomposed into non-relational\nreasoning in an under-approximate Hoare logic, mirroring Beringer's result for\nover-approximate relational logics. We illustrate the application of our logic\non some small examples in which we provably demonstrate the presence of\ninsecurity.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:05:54 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 02:12:34 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Murray", "Toby", ""]]}, {"id": "2003.04803", "submitter": "Micha{\\l} Przyby{\\l}ek", "authors": "Micha{\\l} R. Przyby{\\l}ek", "title": "Beyond sets with atoms: definability in first order logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sets with atoms serve as an alternative to ZFC foundations for mathematics,\nwhere some infinite, though highly symmetric sets, behave in a finitistic way.\nTherefore, one can try to carry over analysis of the classical algorithms from\nfinite structures to some infinite structures. Recent results show that this is\nindeed possible and leads to many practical applications. In this paper we\nshall take another route to finite analysis of infinite sets, which extends and\nsheds more light on sets with atoms. As an application of our theory we give a\ncharacterisation of languages recognized by automata definable in fragments of\nfirst-order logic.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:28:59 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 19:28:52 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 22:19:31 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 18:46:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Przyby\u0142ek", "Micha\u0142 R.", ""]]}, {"id": "2003.04952", "submitter": "Ionel Eduard Stan", "authors": "Andrea Brunello, Guido Sciavicco, and Ionel Eduard Stan", "title": "Interval Temporal Logic Decision Tree Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-19570-0_50", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are simple, yet powerful, classification models used to\nclassify categorical and numerical data, and, despite their simplicity, they\nare commonly used in operations research and management, as well as in\nknowledge mining. From a logical point of view, a decision tree can be seen as\na structured set of logical rules written in propositional logic. Since\nknowledge mining is rapidly evolving towards temporal knowledge mining, and\nsince in many cases temporal information is best described by interval temporal\nlogics, propositional logic decision trees may evolve towards interval temporal\nlogic decision trees. In this paper, we define the problem of interval temporal\nlogic decision tree learning, and propose a solution that generalizes classical\ndecision tree learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 20:05:01 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 07:15:14 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Brunello", "Andrea", ""], ["Sciavicco", "Guido", ""], ["Stan", "Ionel Eduard", ""]]}, {"id": "2003.05081", "submitter": "Pedro Miguel Lafor\\^et Barroso", "authors": "Pedro Barroso, M\\'ario Pereira and Ant\\'onio Ravara", "title": "Animated Logic: Correct Functional Conversion to Conjunctive Normal Form", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to obtain formally verified implementations of\nclassical Computational Logic algorithms. We choose the Why3 platform because\nit allows to implement functions in a style very close to the mathematical\ndefinitions, as well as it allows a high degree of automation in the\nverification process.\n  As proof of concept, we present a mathematical definition of the algorithm to\nconvert propositional formulae to conjunctive normal form, implementations in\nWhyML (the Why3 language, very similar to OCaml), and proofs of correctness of\nthe implementations. We apply our proposal on two variants of this algorithm:\none in direct-style and another with an explicit stack structure. Being both\nfirst-order versions, Why3 processes the proofs naturally.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 02:15:19 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Barroso", "Pedro", ""], ["Pereira", "M\u00e1rio", ""], ["Ravara", "Ant\u00f3nio", ""]]}, {"id": "2003.05119", "submitter": "Stella Biderman", "authors": "Stella Biderman", "title": "Magic: the Gathering is as Hard as Arithmetic", "comments": "pre-print, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magic: the Gathering is a popular and famously complicated card game about\nmagical combat. Recently, several authors including Chatterjee and Ibsen-Jensen\n(2016) and Churchill, Biderman, and Herrick (2019) have investigated the\ncomputational complexity of playing Magic optimally. In this paper we show that\nthe ``mate-in-$n$'' problem for Magic is $\\Delta^0_n$-hard and that optimal\nplay in two-player Magic is non-arithmetic in general. These results apply to\nhow real Magic is played, can be achieved using standard-size tournament legal\ndecks, and do not rely on stochasticity or hidden information. Our paper builds\nupon the construction that Churchill, Biderman, and Herrick (2019) used to show\nthat this problem was at least as hard as the halting problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 05:42:28 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Biderman", "Stella", ""]]}, {"id": "2003.05213", "submitter": "Noam Zeilberger", "authors": "Tarmo Uustalu, Niccol\\`o Veltri, and Noam Zeilberger", "title": "The Sequent Calculus of Skew Monoidal Categories", "comments": "This article is a revised and extended version of a paper presented\n  at MFPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Szlach\\'anyi's skew monoidal categories are a well-motivated variation of\nmonoidal categories in which the unitors and associator are not required to be\nnatural isomorphisms, but merely natural transformations in a particular\ndirection. We present a sequent calculus for skew monoidal categories, building\non the recent formulation by one of the authors of a sequent calculus for the\nTamari order (skew semigroup categories). In this calculus, antecedents consist\nof a stoup (an optional formula) followed by a context, and the connectives\nbehave like in the standard monoidal sequent calculus except that the left\nrules may only be applied in stoup position. We prove that this calculus is\nsound and complete with respect to existence of maps in the free skew monoidal\ncategory, and moreover that it captures equality of maps once a suitable\nequivalence relation is imposed on derivations. We then identify a subsystem of\nfocused derivations and establish that it contains exactly one canonical\nrepresentative from each equivalence class. This coherence theorem leads\ndirectly to simple procedures for deciding equality of maps in the free skew\nmonoidal category and for enumerating any homset without duplicates. Finally,\nand in the spirit of Lambek's work, we describe the close connection between\nthis proof-theoretic analysis and Bourke and Lack's recent characterization of\nskew monoidal categories as left representable skew multicategories. We have\nformalized this development in the dependently typed programming language Agda.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 11:00:42 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Uustalu", "Tarmo", ""], ["Veltri", "Niccol\u00f2", ""], ["Zeilberger", "Noam", ""]]}, {"id": "2003.05386", "submitter": "Sergey Goncharov", "authors": "Miriam Polzer and Sergey Goncharov", "title": "Local Local Reasoning: A BI-Hyperdoctrine for Full Ground Store", "comments": "version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling and reasoning about dynamic memory allocation is one of the\nwell-established strands of theoretical computer science, which is particularly\nwell-known as a source of notorious challenges in semantics, reasoning, and\nproof theory. We capitalize on recent progress on categorical semantics of full\nground store, in terms of a full ground store monad, to build a corresponding\nsemantics of a higher order logic over the corresponding programs. Our main\nresult is a construction of an (intuitionistic) BI-hyperdoctrine, which is\narguably the semantic core of higher order logic over local store. Although we\nhave made an extensive use of the existing generic tools, certain principled\nchanges had to be made to enable the desired construction: while the original\nmonad works over total heaps (to disable dangling pointers), our version\ninvolves partial heaps (heaplets) to enable compositional reasoning using\nseparating conjunction. Another remarkable feature of our construction is that,\nin contrast to the existing generic approaches, our BI-algebra does not\ndirectly stem from an internal categorical partial commutative monoid.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 16:14:32 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Polzer", "Miriam", ""], ["Goncharov", "Sergey", ""]]}, {"id": "2003.05633", "submitter": "Matthew England Dr", "authors": "Erika \\'Abrah\\'am, James H. Davenport, Matthew England, and Gereon\n  Kremer", "title": "Deciding the Consistency of Non-Linear Real Arithmetic Constraints with\n  a Conflict Driven Search Using Cylindrical Algebraic Coverings", "comments": null, "journal-ref": "Journal of Logical and Algebraic Methods in Programming, 119,\n  Article Number 100633, Elsvier, 2021", "doi": "10.1016/j.jlamp.2020.100633", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for determining the satisfiability of conjunctions\nof non-linear polynomial constraints over the reals, which can be used as a\ntheory solver for satisfiability modulo theory (SMT) solving for non-linear\nreal arithmetic. The algorithm is a variant of Cylindrical Algebraic\nDecomposition (CAD) adapted for satisfiability, where solution candidates\n(sample points) are constructed incrementally, either until a satisfying sample\nis found or sufficient samples have been sampled to conclude unsatisfiability.\nThe choice of samples is guided by the input constraints and previous\nconflicts.\n  The key idea behind our new approach is to start with a partial sample;\ndemonstrate that it cannot be extended to a full sample; and from the reasons\nfor that rule out a larger space around the partial sample, which build up\nincrementally into a cylindrical algebraic covering of the space. There are\nsimilarities with the incremental variant of CAD, the NLSAT method of Jovanovic\nand de Moura, and the NuCAD algorithm of Brown; but we present worked examples\nand experimental results on a preliminary implementation to demonstrate the\ndifferences to these, and the benefits of the new approach.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 06:02:48 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 11:06:24 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["\u00c1brah\u00e1m", "Erika", ""], ["Davenport", "James H.", ""], ["England", "Matthew", ""], ["Kremer", "Gereon", ""]]}, {"id": "2003.05746", "submitter": "Camille Bourgaux", "authors": "Meghyn Bienvenu and Camille Bourgaux", "title": "Querying and Repairing Inconsistent Prioritized Knowledge Bases:\n  Complexity Analysis and Links with Abstract Argumentation", "comments": "27 pages. To appear in the 17th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2020) without the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the issue of inconsistency handling over\nprioritized knowledge bases (KBs), which consist of an ontology, a set of\nfacts, and a priority relation between conflicting facts. In the database\nsetting, a closely related scenario has been studied and led to the definition\nof three different notions of optimal repairs (global, Pareto, and completion)\nof a prioritized inconsistent database. After transferring the notions of\nglobally-, Pareto- and completion-optimal repairs to our setting, we study the\ndata complexity of the core reasoning tasks: query entailment under\ninconsistency-tolerant semantics based upon optimal repairs, existence of a\nunique optimal repair, and enumeration of all optimal repairs. Our results\nprovide a nearly complete picture of the data complexity of these tasks for\nontologies formulated in common DL-Lite dialects. The second contribution of\nour work is to clarify the relationship between optimal repairs and different\nnotions of extensions for (set-based) argumentation frameworks. Among our\nresults, we show that Pareto-optimal repairs correspond precisely to stable\nextensions (and often also to preferred extensions), and we propose a novel\nsemantics for prioritized KBs which is inspired by grounded extensions and\nenjoys favourable computational properties. Our study also yields some results\nof independent interest concerning preference-based argumentation frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 12:38:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 16:15:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Bourgaux", "Camille", ""]]}, {"id": "2003.05898", "submitter": "Michael Benedikt", "authors": "Michael Benedikt, Stanislav Kikot, Piotr Ostropolski-Nalewaja, and\n  Miguel Romero", "title": "On monotonic determinacy and rewritability for recursive queries and\n  views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A query Q is monotonically determined over a set of views if Q can be\nexpressed as a monotonic function of the view image. In the case of relational\nalgebra views and queries, monotonic determinacy coincides with rewritability\nas a union of conjunctive queries, and it is decidable in important special\ncases, such as for CQ views and queries. We investigate the situation for views\nand queries in the recursive query language Datalog. We give both positive and\nnegative results about the ability to decide monotonic determinacy, and also\nabout the co-incidence of monotonic determinacy with Datalog rewritability.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:56:13 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Benedikt", "Michael", ""], ["Kikot", "Stanislav", ""], ["Ostropolski-Nalewaja", "Piotr", ""], ["Romero", "Miguel", ""]]}, {"id": "2003.06077", "submitter": "Yuxi Fu", "authors": "Yuxi Fu, Qizhe Yang", "title": "Reachability is Tower Complete", "comments": "We apply to with draw this paper because there is a fatal error. At\n  the moment we do not know how correct the mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complete characterization of the complexity of the reachability problem for\nvector addition system has been open for a long time. The problem is shown to\nbe Tower complete.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 01:11:33 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 07:01:08 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Fu", "Yuxi", ""], ["Yang", "Qizhe", ""]]}, {"id": "2003.06203", "submitter": "Baudouin Le Charlier", "authors": "Baudouin Le Charlier", "title": "Experimental Evaluation of a Method to Simplify Expressions", "comments": "Paper rejected at IJCAR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to simplify expressions in the context of an equational\ntheory. The basic ideas and concepts of the method have been presented\npreviously elsewhere but here we tackle the difficult task of making it\nefficient in practice, in spite of its great generality. We first recall the\nnotion of a collection of structures, which allows us to manipulate very large\n(possibly infinite) sets of terms as a whole, i.e., without enumerating their\nelements. Then we use this tool to construct algorithms to simplify\nexpressions. We give various reasons why it is difficult to make these\nalgorithms precise and efficient. We then propose a number of approches to\nsolve the raised issues. Finally, and importantly, we provide a detailed\nexperimental evaluation of the method and a comparison of several variants of\nit. Although the method is completely generic, we use (arbitrary, not only\ntwo-level) boolean expressions as the application field for these experiments\nbecause impressive simplifications can be obtained in spite of the hardness of\nthe problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:12:19 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Charlier", "Baudouin Le", ""]]}, {"id": "2003.06214", "submitter": "Mario Rom\\'an", "authors": "Mario Rom\\'an", "title": "Comb Diagrams for Discrete-Time Feedback", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data for many useful bidirectional constructions in applied category\ntheory (optics, learners, games, quantum combs) can be expressed in terms of\ndiagrams containing \"holes\" or \"incomplete parts\", sometimes known as comb\ndiagrams. We give a possible formalization of what these circuits with\nincomplete parts represent in terms of symmetric monoidal categories, using the\ndinaturality equivalence relations arising from a coend. Our main idea is to\nextend this formal description to allow for infinite circuits with holes\nindexed by the natural numbers. We show how infinite combs over an arbitrary\nsymmetric monoidal category form again a symmetric monoidal category where\nnotions of delay and feedback can be considered. The constructions presented\nhere are still preliminary work.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 12:03:04 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Rom\u00e1n", "Mario", ""]]}, {"id": "2003.06267", "submitter": "Marc de Visme", "authors": "Marc de Visme, Glynn Winskel", "title": "Causal Unfoldings and Disjunctive Causes", "comments": "30 pages, no figures, submitted for publication in the special issue\n  of the Journal Logical Methods in Computer Science devoted to the best\n  contributions of CALCO 2019. arXiv admin note: text overlap with\n  arXiv:1607.03747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the simplest form of event structure, a prime event structure, an event is\nassociated with a unique causal history, its prime cause. However, it is quite\ncommon for an event to have disjunctive causes in that it can be enabled by any\none of multiple sets of causes. Sometimes the sets of causes may be mutually\nexclusive, inconsistent one with another, and sometimes not, in which case they\ncoexist consistently and constitute parallel causes of the event. The\nestablished model of general event structures can model parallel causes. On\noccasion however such a model abstracts too far away from the precise causal\nhistories of events to be directly useful. For example, sometimes one needs to\nassociate probabilities with different, possibly coexisting, causal histories\nof a common event. Ideally, the causal histories of a general event structure\nwould correspond to the configurations of its causal unfolding to a prime event\nstructure; and the causal unfolding would arise as a right adjoint to the\nembedding of prime in general event structures. But there is no such\nadjunction. However, a slight extension of prime event structures remedies this\ndefect and provides a causal unfolding as a universal construction. Prime event\nstructures are extended with an equivalence relation in order to dissociate the\ntwo roles, that of an event and its enabling; in effect, prime causes are\nlabelled by a disjunctive event, an equivalence class of its prime causes. With\nthis enrichment a suitable causal unfolding appears as a pseudo right adjoint.\nThe adjunction relies critically on the central and subtle notion of extremal\ncausal realisation as an embodiment of causal history. Finally, we explore\nsubcategories which support parallel causes as well the key operations needed\nin developing probabilistic distributed strategies with parallel causes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 10:30:08 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["de Visme", "Marc", ""], ["Winskel", "Glynn", ""]]}, {"id": "2003.06458", "submitter": "Karl Palmskog", "authors": "Talia Ringer, Karl Palmskog, Ilya Sergey, Milos Gligoric, Zachary\n  Tatlock", "title": "QED at Large: A Survey of Engineering of Formally Verified Software", "comments": "183 pages, for errata see\n  https://proofengineering.org/qed_errata.html", "journal-ref": "Foundations and Trends in Programming Languages, Vol. 5, No. 2-3\n  (Sept. 2019), pp. 102-281", "doi": "10.1561/2500000045", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of formal proofs of correctness of programs can increase actual\nand perceived reliability and facilitate better understanding of program\nspecifications and their underlying assumptions. Tools supporting such\ndevelopment have been available for over 40 years, but have only recently seen\nwide practical use. Projects based on construction of machine-checked formal\nproofs are now reaching an unprecedented scale, comparable to large software\nprojects, which leads to new challenges in proof development and maintenance.\nDespite its increasing importance, the field of proof engineering is seldom\nconsidered in its own right; related theories, techniques, and tools span many\nfields and venues. This survey of the literature presents a holistic\nunderstanding of proof engineering for program correctness, covering impact in\npractice, foundations, proof automation, proof organization, and practical\nproof development.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 19:35:25 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ringer", "Talia", ""], ["Palmskog", "Karl", ""], ["Sergey", "Ilya", ""], ["Gligoric", "Milos", ""], ["Tatlock", "Zachary", ""]]}, {"id": "2003.06488", "submitter": "Roy Overbeek", "authors": "Roy Overbeek, J\\\"org Endrullis", "title": "Patch Graph Rewriting (Extended Version)", "comments": "Accepted to The International Conference on Graph Transformation 2020\n  (ICGT 2020). Here with an Appendix. 25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic principle of graph rewriting is the stepwise replacement of\nsubgraphs inside a host graph. A challenge in such replacement steps is the\ntreatment of the patch graph, consisting of those edges of the host graph that\ntouch the subgraph, but are not part of it.\n  We introduce the patch graph rewriting framework, a visual graph rewriting\nlanguage with precise formal semantics. The language has rich expressive power\nin two ways. Firstly, rules can flexibly constrain the permitted shapes of\npatches touching matching subgraphs. Secondly, rules can freely transform\npatches. While the framework is designed to be easy to understand, it subsumes\nmany approaches to graph rewriting.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 21:15:49 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:52:52 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 13:57:49 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Overbeek", "Roy", ""], ["Endrullis", "J\u00f6rg", ""]]}, {"id": "2003.06492", "submitter": "Renyan Feng", "authors": "Renyan Feng, Erman Acar, Stefan Schlobach, Yisong Wang, Wanwei Liu", "title": "On Sufficient and Necessary Conditions in Bounded CTL: A Forgetting\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation Tree Logic (CTL) is one of the central formalisms in formal\nverification. As a specification language, it is used to express a property\nthat the system at hand is expected to satisfy. From both the verification and\nthe system design points of view, some information content of such property\nmight become irrelevant for the system due to various reasons, e.g., it might\nbecome obsolete by time, or perhaps infeasible due to practical difficulties.\nThen, the problem arises on how to subtract such piece of information without\naltering the relevant system behaviour or violating the existing specifications\nover a given signature. Moreover, in such a scenario, two crucial notions are\ninformative: the strongest necessary condition (SNC) and the weakest sufficient\ncondition (WSC) of a given property. To address such a scenario in a principled\nway, we introduce a forgetting-based approach in CTL and show that it can be\nused to compute SNC and WSC of a property under a given model and over a given\nsignature. We study its theoretical properties and also show that our notion of\nforgetting satisfies existing essential postulates of knowledge forgetting.\nFurthermore, we analyse the computational complexity of some basic reasoning\ntasks for the fragment CTL_AF in particular.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 21:51:59 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 08:26:45 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:44:36 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Feng", "Renyan", ""], ["Acar", "Erman", ""], ["Schlobach", "Stefan", ""], ["Wang", "Yisong", ""], ["Liu", "Wanwei", ""]]}, {"id": "2003.07291", "submitter": "Julio Cesar Carrasquel", "authors": "Khalil Mecheraoui, Julio C. Carrasquel, Irina A. Lomazova", "title": "Compositional Conformance Checking of Nested Petri Nets and Event Logs\n  of Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a compositional conformance checking approach between\nnested Petri nets and event logs of multi-agent systems. By projecting an event\nlog onto model components, one can perform conformance checking between each\nprojected log and the corresponding component. We formally demonstrate the\nvalidity of our approach proving that, to check fitness of a nested Petri net\nis equivalent to check fitness of each of its components. Leveraging the\nmulti-agent system structure of nested Petri nets, this approach may provide\nspecific conformance diagnostics for each system component as well as to avoid\nto compute artificial boundaries when decomposing a model for conformance\nchecking.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:52:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mecheraoui", "Khalil", ""], ["Carrasquel", "Julio C.", ""], ["Lomazova", "Irina A.", ""]]}, {"id": "2003.07520", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Daniel M. Gruen, Oshani Seneviratne, Deborah L.\n  McGuinness", "title": "Foundations of Explainable Knowledge-Enabled Systems", "comments": "S. Chari, D. Gruen, O. Seneviratne, D. L. McGuinness, \"Foundations of\n  Explainable Knowledge-Enabled Systems\". In: Ilaria Tiddi, Freddy Lecue,\n  Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations,\n  Applications and Challenges. Studies on the Semantic Web, IOS Press,\n  Amsterdam, 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainability has been an important goal since the early days of Artificial\nIntelligence. Several approaches for producing explanations have been\ndeveloped. However, many of these approaches were tightly coupled with the\ncapabilities of the artificial intelligence systems at the time. With the\nproliferation of AI-enabled systems in sometimes critical settings, there is a\nneed for them to be explainable to end-users and decision-makers. We present a\nhistorical overview of explainable artificial intelligence systems, with a\nfocus on knowledge-enabled systems, spanning the expert systems, cognitive\nassistants, semantic applications, and machine learning domains. Additionally,\nborrowing from the strengths of past approaches and identifying gaps needed to\nmake explanations user- and context-focused, we propose new definitions for\nexplanations and explainable knowledge-enabled systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:18:48 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Chari", "Shruthi", ""], ["Gruen", "Daniel M.", ""], ["Seneviratne", "Oshani", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2003.07523", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Daniel M. Gruen, Oshani Seneviratne, Deborah L.\n  McGuinness", "title": "Directions for Explainable Knowledge-Enabled Systems", "comments": "S. Chari, D. M. Gruen, O. Seneviratne, D. L. McGuinness, \"Directions\n  for Explainable Knowledge-Enabled Systems\". In: Ilaria Tiddi, Freddy Lecue,\n  Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations,\n  Applications and Challenges. Studies on the Semantic Web, IOS Press,\n  Amsterdam, 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interest in the field of Explainable Artificial Intelligence has been growing\nfor decades and has accelerated recently. As Artificial Intelligence models\nhave become more complex, and often more opaque, with the incorporation of\ncomplex machine learning techniques, explainability has become more critical.\nRecently, researchers have been investigating and tackling explainability with\na user-centric focus, looking for explanations to consider trustworthiness,\ncomprehensibility, explicit provenance, and context-awareness. In this chapter,\nwe leverage our survey of explanation literature in Artificial Intelligence and\nclosely related fields and use these past efforts to generate a set of\nexplanation types that we feel reflect the expanded needs of explanation for\ntoday's artificial intelligence applications. We define each type and provide\nan example question that would motivate the need for this style of explanation.\nWe believe this set of explanation types will help future system designers in\ntheir generation and prioritization of requirements and further help generate\nexplanations that are better aligned to users' and situational needs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:34:29 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chari", "Shruthi", ""], ["Gruen", "Daniel M.", ""], ["Seneviratne", "Oshani", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2003.07596", "submitter": "Tomas Teijeiro", "authors": "Tomas Teijeiro and Paulo Felix", "title": "Construe: a software solution for the explanation-based interpretation\n  of time series", "comments": "Original Software Publication. 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a software implementation of a general framework for time\nseries interpretation based on abductive reasoning. The software provides a\ndata model and a set of algorithms to make inference to the best explanation of\na time series, resulting in a description in multiple abstraction levels of the\nprocesses underlying the time series. As a proof of concept, a comprehensive\nknowledge base for the electrocardiogram (ECG) domain is provided, so it can be\nused directly as a tool for ECG analysis. This tool has been successfully\nvalidated in several noteworthy problems, such as heartbeat classification or\natrial fibrillation detection.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 09:26:55 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Teijeiro", "Tomas", ""], ["Felix", "Paulo", ""]]}, {"id": "2003.07739", "submitter": "Daniel Fremont", "authors": "Daniel J. Fremont, Edward Kim, Yash Vardhan Pant, Sanjit A. Seshia,\n  Atul Acharya, Xantha Bruso, Paul Wells, Steve Lemke, Qiang Lu, Shalin Mehta", "title": "Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to\n  the Real World", "comments": "9 pages, 6 figures. Full version of an ITSC 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.LO cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to automated scenario-based testing of the safety\nof autonomous vehicles, especially those using advanced artificial\nintelligence-based components, spanning both simulation-based evaluation as\nwell as testing in the real world. Our approach is based on formal methods,\ncombining formal specification of scenarios and safety properties, algorithmic\ntest case generation using formal simulation, test case selection for track\ntesting, executing test cases on the track, and analyzing the resulting data.\nExperiments with a real autonomous vehicle at an industrial testing facility\nsupport our hypotheses that (i) formal simulation can be effective at\nidentifying test cases to run on the track, and (ii) the gap between simulated\nand real worlds can be systematically evaluated and bridged.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 14:17:52 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 15:00:40 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Fremont", "Daniel J.", ""], ["Kim", "Edward", ""], ["Pant", "Yash Vardhan", ""], ["Seshia", "Sanjit A.", ""], ["Acharya", "Atul", ""], ["Bruso", "Xantha", ""], ["Wells", "Paul", ""], ["Lemke", "Steve", ""], ["Lu", "Qiang", ""], ["Mehta", "Shalin", ""]]}, {"id": "2003.08070", "submitter": "Zhiguang Zhao", "authors": "Zhiguang Zhao", "title": "Sahlqvist Correspondence Theory for Sabotage Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sabotage modal logic (SML) is a kind of dynamic logics. It extends static\nmodal logic with a dynamic modality which is interpreted as \"after deleting an\narrow in the frame, the formula is true\". In the present paper, we are aiming\nat solving an open problem, namely giving a Sahlqvist-type correspondence\ntheorem for sabotage modal logic. In this paper, we define sabotage Sahlqvist\nformulas and give an algorithm to compute the first-order correspondents of\nsabotage Sahlqvist formulas. We give some remarks and future directions at the\nend of the paper.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 07:11:02 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 01:23:24 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 12:54:04 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zhao", "Zhiguang", ""]]}, {"id": "2003.08164", "submitter": "Martin Grohe", "authors": "Martin Grohe", "title": "Counting Bounded Tree Depth Homomorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that graphs G, G' satisfy the same sentences of first-order logic\nwith counting of quantifier rank at most k if and only if they are\nhomomorphism-indistinguishable over the class of all graphs of tree depth at\nmost k. Here G, G' are homomorphism-indistinguishable over a class C of graphs\nif for each graph F in C, the number of homomorphisms from F to G equals the\nnumber of homomorphisms from F to G'.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:40:16 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Grohe", "Martin", ""]]}, {"id": "2003.08298", "submitter": "Rafael Pe\\~naloza", "authors": "Rafael Pe\\~naloza", "title": "Axiom Pinpointing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axiom pinpointing refers to the task of finding the specific axioms in an\nontology which are responsible for a consequence to follow. This task has been\nstudied, under different names, in many research areas, leading to a\nreformulation and reinvention of techniques. In this work, we present a general\noverview to axiom pinpointing, providing the basic notions, different\napproaches for solving it, and some variations and applications which have been\nconsidered in the literature. This should serve as a starting point for\nresearchers interested in related problems, with an ample bibliography for\ndelving deeper into the details.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:55:54 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "2003.08627", "submitter": "Marcin Jurdzi\\'nski", "authors": "Laure Daviaud and Marcin Jurdzi\\'nski and K. S. Thejaswini", "title": "The Strahler number of a parity game", "comments": "To appear in ICALP 2020", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2020.123", "report-no": null, "categories": "cs.DS cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Strahler number of a rooted tree is the largest height of a perfect\nbinary tree that is its minor. The Strahler number of a parity game is proposed\nto be defined as the smallest Strahler number of the tree of any of its\nattractor decompositions. It is proved that parity games can be solved in\nquasi-linear space and in time that is polynomial in the number of vertices~$n$\nand linear in $({d}/{2k})^k$, where $d$ is the number of priorities and $k$ is\nthe Strahler number. This complexity is quasi-polynomial because the Strahler\nnumber is at most logarithmic in the number of vertices. The proof is based on\na new construction of small Strahler-universal trees.\n  It is shown that the Strahler number of a parity game is a robust parameter:\nit coincides with its alternative version based on trees of progress measures\nand with the register number defined by Lehtinen~(2018). It follows that parity\ngames can be solved in quasi-linear space and in time that is polynomial in the\nnumber of vertices and linear in $({d}/{2k})^k$, where $k$ is the register\nnumber. This significantly improves the running times and space achieved for\nparity games of bounded register number by Lehtinen (2018) and by Parys (2020).\n  The running time of the algorithm based on small Strahler-universal trees\nyields a novel trade-off $k \\cdot \\lg(d/k) = O(\\log n)$ between the two natural\nparameters that measure the structural complexity of a parity game, which\nallows solving parity games in polynomial time. This includes as special cases\nthe asymptotic settings of those parameters covered by the results of Calude,\nJain Khoussainov, Li, and Stephan (2017), of Jurdzi\\'nski and Lazi\\'c (2017),\nand of Lehtinen (2018), and it significantly extends the range of such\nsettings, for example to $d = 2^{O\\left(\\sqrt{\\lg n}\\right)}$ and $k =\nO\\!\\left(\\sqrt{\\lg n}\\right)$.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 08:36:48 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 12:36:53 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Daviaud", "Laure", ""], ["Jurdzi\u0144ski", "Marcin", ""], ["Thejaswini", "K. S.", ""]]}, {"id": "2003.08877", "submitter": "Barbara K\\\"onig", "authors": "Paolo Baldan and Barbara K\\\"onig and Tommaso Padoan", "title": "Abstraction, Up-to Techniques and Games for Systems of Fixpoint\n  Equations", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2020.25", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems of fixpoint equations over complete lattices, consisting of (mixed)\nleast and greatest fixpoint equations, allow one to express a number of\nverification tasks such as model-checking of various kinds of specification\nlogics or the check of coinductive behavioural equivalences.\n  In this paper we develop a theory of approximation for systems of fixpoint\nequations in the style of abstract interpretation: a system over some concrete\ndomain is abstracted to a system in a suitable abstract domain, with conditions\nensuring that the abstract solution represents a sound/complete\noverapproximation of the concrete solution.\n  Interestingly, up-to techniques, a classical approach used in coinductive\nsettings to obtain easier or feasible proofs, can be interpreted as\nabstractions in a way that they naturally fit in our framework and extend to\nsystems of equations.\n  Additionally, relying on the approximation theory, we can provide a\ncharacterisation of the solution of systems of fixpoint equations over complete\nlattices in terms of a suitable parity game, generalising some recent work that\nwas restricted to continuous lattices.\n  The game view opens the way to the development of on-the-fly algorithms for\ncharacterising the solution of such equation systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 15:56:03 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 09:20:49 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Baldan", "Paolo", ""], ["K\u00f6nig", "Barbara", ""], ["Padoan", "Tommaso", ""]]}, {"id": "2003.08910", "submitter": "Mirco Giacobbe", "authors": "Alessandro Abate, Daniele Ahmed, Mirco Giacobbe, and Andrea Peruffo", "title": "Formal Synthesis of Lyapunov Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2020.3005328", "report-no": null, "categories": "eess.SY cs.LG cs.LO cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an automatic and formally sound method for synthesising Lyapunov\nfunctions for the asymptotic stability of autonomous non-linear systems.\nTraditional methods are either analytical and require manual effort or are\nnumerical but lack of formal soundness. Symbolic computational methods for\nLyapunov functions, which are in between, give formal guarantees but are\ntypically semi-automatic because they rely on the user to provide appropriate\nfunction templates. We propose a method that finds Lyapunov functions fully\nautomatically$-$using machine learning$-$while also providing formal\nguarantees$-$using satisfiability modulo theories (SMT). We employ a\ncounterexample-guided approach where a numerical learner and a symbolic\nverifier interact to construct provably correct Lyapunov neural networks\n(LNNs). The learner trains a neural network that satisfies the Lyapunov\ncriteria for asymptotic stability over a samples set; the verifier proves via\nSMT solving that the criteria are satisfied over the whole domain or augments\nthe samples set with counterexamples. Our method supports neural networks with\npolynomial activation functions and multiple depth and width, which display\nwide learning capabilities. We demonstrate our method over several non-trivial\nbenchmarks and compare it favourably against a numerical optimisation-based\napproach, a symbolic template-based approach, and a cognate LNN-based approach.\nOur method synthesises Lyapunov functions faster and over wider spatial domains\nthan the alternatives, yet providing stronger or equal guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:21:02 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 16:33:17 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Abate", "Alessandro", ""], ["Ahmed", "Daniele", ""], ["Giacobbe", "Mirco", ""], ["Peruffo", "Andrea", ""]]}, {"id": "2003.09134", "submitter": "Silvano Dal Zilio", "authors": "Silvano Dal Zilio (LAAS-VERTICS)", "title": "MCC: a Tool for Unfolding Colored Petri Nets in PNML Format", "comments": null, "journal-ref": "41st International Conference on Application and Theory of Petri\n  Nets and Concurrency, Jun 2020, Paris, France", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MCC is a tool designed for a very specific task: to transform the models of\nHigh-Level Petri nets, given in the PNML syntax, into equivalent\nPlace/Transition nets. The name of the tool derives from the annual\nModel-Checking Contest, a competition of model-checking tools that provides a\nlarge and diverse collection of PNML models. This choice in naming serves to\nunderline the main focus of the tool, which is to provide an open and efficient\nsolution that lowers the access cost for developers wanting to engage in this\ncompetition. We describe the architecture and functionalities of our tool and\nshow how it compares with other existing solutions. Despite the fact that the\nproblem we target is abundantly covered in the literature, we show that it is\nstill possible to innovate. To substantiate this assertion, we put a particular\nemphasis on two distinctive features of MCC that have proved useful when\ndealing with some of the most challenging colored models in the contest, namely\nthe use of a restricted notion of higher-order invariant, and the support of a\nPetri net scripting language.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 07:59:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zilio", "Silvano Dal", "", "LAAS-VERTICS"]]}, {"id": "2003.09140", "submitter": "Lasse Blaauwbroek", "authors": "Lasse Blaauwbroek, Josef Urban, and Herman Geuvers", "title": "Tactic Learning and Proving for the Coq Proof Assistant", "comments": "12 pages, 2 figures, 1 table. For the associated artefacts, see\n  https://doi.org/10.5281/zenodo.3693760", "journal-ref": "In LPAR, volume 73 of EPiC Series in Computing, pages 138-150.\n  Easychair, 2020", "doi": "10.29007/wg1q", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that utilizes machine learning for tactic proof search in\nthe Coq Proof Assistant. In a similar vein as the TacticToe project for HOL4,\nour system predicts appropriate tactics and finds proofs in the form of tactic\nscripts. To do this, it learns from previous tactic scripts and how they are\napplied to proof states. The performance of the system is evaluated on the Coq\nStandard Library. Currently, our predictor can identify the correct tactic to\nbe applied to a proof state 23.4% of the time. Our proof searcher can fully\nautomatically prove 39.3% of the lemmas. When combined with the CoqHammer\nsystem, the two systems together prove 56.7% of the library's lemmas.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 08:22:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Blaauwbroek", "Lasse", ""], ["Urban", "Josef", ""], ["Geuvers", "Herman", ""]]}, {"id": "2003.09340", "submitter": "Khalil Ghorbal", "authors": "Joan Thibault and Khalil Ghorbal", "title": "Ordered Functional Decision Diagrams: A Functional Semantics For Binary\n  Decision Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework, termed $\\lambda$DD, that revisits Binary\nDecision Diagrams from a purely functional point of view. The framework allows\nto classify the already existing variants, including the most recent ones like\nChain-DD and ESRBDD, as implementations of a special class of ordered models.\nWe enumerate, in a principled way, all the models of this class and isolate its\nmost expressive model. This new model, termed $\\lambda$DD-O-NUCX, is suitable\nfor both dense and sparse Boolean functions, and is moreover invariant by\nnegation. The canonicity of $\\lambda$DD-O-NUCX is formally verified using the\nCoq proof assistant. We furthermore give bounds on the size of the different\ndiagrams: the potential gain achieved by more expressive models can be at most\nlinear in the number of variables n.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 15:46:48 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 12:29:45 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 21:54:58 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 22:09:07 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Thibault", "Joan", ""], ["Ghorbal", "Khalil", ""]]}, {"id": "2003.09395", "submitter": "Nicolas Behr", "authors": "Nicolas Behr and Jean Krivine", "title": "Rewriting Theory for the Life Sciences: A Unifying Theory of CTMC\n  Semantics", "comments": "18+6 pages, LNCS style; ICGT 2020 conference paper extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kappa biochemistry and the M{\\O}D organo-chemistry frameworks are amongst\nthe most intensely developed applications of rewriting theoretical methods in\nthe life sciences to date. A typical feature of these types of rewriting\ntheories is the necessity to implement certain structural constraints on the\nobjects to be rewritten (a protein is empirically found to have a certain\nsignature of sites, a carbon atom can form at most four bonds, ...). In this\npaper, we contribute to the theoretical foundations of these types of rewriting\ntheory a number of conceptual and technical developments that permit to\nimplement a universal theory of continuous-time Markov chains (CTMCs) for\nstochastic rewriting systems. Our core mathematical concepts are a novel rule\nalgebra construction for the relevant setting of rewriting rules with\nconditions, both in Double- and in Sesqui-Pushout semantics, augmented by a\nsuitable stochastic mechanics formalism extension that permits to derive\ndynamical evolution equations for pattern-counting statistics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 17:13:07 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 22:30:16 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Behr", "Nicolas", ""], ["Krivine", "Jean", ""]]}, {"id": "2003.09453", "submitter": "Jens Seeber", "authors": "Filippo Bonchi, Jens Seeber, Pawel Sobocinski", "title": "Cartesian bicategories with choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational structures are emerging as ubiquitous mathematical machinery in\nthe semantics of open systems of various kinds. Cartesian bicategories are a\nwell-known categorical algebra of relations that has proved especially useful\nin recent applications. The passage between a category and its bicategory of\nrelations is an important question that has been widely studied for decades. We\nstudy an alternative construction that yields a cartesian bicategory of\nrelations. Its behaviour is closely related to the axiom of choice, which\nitself can be expressed in the language of cartesian bicategories.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:37:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bonchi", "Filippo", ""], ["Seeber", "Jens", ""], ["Sobocinski", "Pawel", ""]]}, {"id": "2003.09508", "submitter": "Veronika Thost", "authors": "Stefan Borgwardt, Veronika Thost", "title": "Temporal Conjunctive Query Answering in the Extended DL-Lite Family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based query answering (OBQA) augments classical query answering in\ndatabases by domain knowledge encoded in an ontology. Systems for OBQA use the\nontological knowledge to infer new information that is not explicitly given in\nthe data. Moreover, they usually employ the open-world assumption, which means\nthat knowledge that is not stated explicitly in the data and that is not\ninferred is not assumed to be true or false. Classical OBQA however considers\nonly a snapshot of the data, which means that information about the temporal\nevolution of the data is not used for reasoning and hence lost. We investigate\ntemporal conjunctive queries (TCQs) that allow to access temporal data through\nclassical ontologies. In particular, we study combined and data complexity of\nTCQ entailment for ontologies written in description logics from the extended\nDL-Lite family. Many of these logics allow for efficient reasoning in the\natemporal setting and are successfully applied in practice. We show\ncomprehensive complexity results for temporal reasoning with these logics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:44:34 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Borgwardt", "Stefan", ""], ["Thost", "Veronika", ""]]}, {"id": "2003.09667", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Partial Quantifier Elimination By Certificate Clauses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study partial quantifier elimination (PQE) for propositional CNF formulas.\nIn contrast to full quantifier elimination, in PQE, one can limit the set of\nclauses taken out of the scope of quantifiers to a small subset of target\nclauses. The appeal of PQE is twofold. First, PQE can be dramatically simpler\nthan full quantifier elimination. Second, it provides a language for performing\nincremental computations. Many verification problems (e.g. equivalence checking\nand model checking) are inherently incremental and so can be solved in terms of\nPQE. Our approach is based on deriving clauses depending only on unquantified\nvariables that make the target clauses $\\mathit{redundant}$. Proving redundancy\nof a target clause is done by construction of a ``certificate'' clause implying\nthe former. We describe a PQE algorithm called $\\mathit{START}$ that employs\nthe approach above. We apply $\\mathit{START}$ to generating properties of a\ndesign implementation that are not implied by specification. The existence of\nan $\\mathit{unwanted}$ property means that this implementation is buggy. Our\nexperiments with HWMCC-13 benchmarks suggest that $\\mathit{START}$ can be used\nfor generating properties of real-life designs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 14:07:56 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 01:01:07 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 13:09:43 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 19:56:02 GMT"}, {"version": "v5", "created": "Mon, 12 Oct 2020 10:40:08 GMT"}, {"version": "v6", "created": "Wed, 31 Mar 2021 17:54:38 GMT"}, {"version": "v7", "created": "Sat, 5 Jun 2021 23:35:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "2003.09918", "submitter": "Irmak Sa\\u{g}lam", "authors": "Irmak Saglam, Ebru Aydin Gol", "title": "Kontrol Edilebilir ptSTL Formulu Sentezi -- Synthesis of Controllable\n  ptSTL Formulas", "comments": "in Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop an approach to anomaly detection and prevention\nproblem using Signal Temporal Logic (STL). This approach consists of two steps:\ndetection of the causes of the anomalities as STL formulas and prevention of\nthe satisfaction of the formula via controller synthesis. This work focuses on\nthe first step and proposes a formula template such that any controllable cause\ncan be represented in this template. An efficient algorithm to synthesize\nformulas in this template is presented. Finally, the results are shown on an\nexample.\n  -----\n  Bu bildiride anomali tespiti ve onlenmesi problemine, Sinyal Zamansal Mantigi\n(Signal Temporal Logic) tabanli iki asamali bir cozum sunulmaktadir. Ilk asama\nnedenlerin tespiti, ikinci asama ise bir kontrol stratejisi ile nedenlerin\nsistem uzerinde engellenmesidir. Iki asama birbirine bagimlidir. Bu bildiride,\nilk asama olan istenmeyen olaylarin nedenlerinin tespitinde kullanilan neden\nformulu sablonu gelistirilmektedir. Bildiride kullanilan sablon ile butun\nkontrol edilebilir formuller tanimlanabilmektedir. Bu sablon icin verimli bir\nformul sentezleme algoritmasi sunulmus, ve sonuclar ornek bir sistem uzerinde\ngosterilmistir.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 15:09:22 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Saglam", "Irmak", ""], ["Gol", "Ebru Aydin", ""]]}, {"id": "2003.09993", "submitter": "Reynald Affeldt", "authors": "Reynald Affeldt, Jacques Garrigue, David Nowak, Takafumi Saikawa", "title": "A Trustful Monad for Axiomatic Reasoning with Probability and\n  Nondeterminism", "comments": "28 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algebraic properties of the combination of probabilistic choice and\nnondeterministic choice have long been a research topic in program semantics.\nThis paper explains a formalization in the Coq proof assistant of a monad\nequipped with both choices: the geometrically convex monad. This formalization\nhas an immediate application: it provides a model for a monad that implements a\nnon-trivial interface which allows for proofs by equational reasoning using\nprobabilistic and nondeterministic effects. We explain the technical choices we\nmade to go from the literature to a complete Coq formalization, from which we\nidentify reusable theories about mathematical structures such as convex spaces\nand concrete categories, and that we integrate in a framework for monadic\nequational reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 21:14:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 14:57:11 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 01:16:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Affeldt", "Reynald", ""], ["Garrigue", "Jacques", ""], ["Nowak", "David", ""], ["Saikawa", "Takafumi", ""]]}, {"id": "2003.10209", "submitter": "Marco Peressotti", "authors": "Alessio Chiapperini and Marino Miculan and Marco Peressotti", "title": "A CSP implementation of the directed bigraph embedding problem", "comments": "arXiv admin note: substantial text overlap with arXiv:1412.1042", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed bigraphs are a meta-model which generalises Milner's bigraphs by\ntaking into account the request flow between controls and names. A key problem\nabout these bigraphs is that of bigraph embedding, i.e., finding the embeddings\nof a bigraph inside a larger one.We present an algorithm for computing\nembeddings of directed bigraphs, via a reduction to a constraint satisfaction\nproblem. We prove soundness and completeness of this algorithm, and provide an\nimplementation in jLibBig, a general Java library for manipulating bigraphical\nreactive systems, together with some experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:24:28 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chiapperini", "Alessio", ""], ["Miculan", "Marino", ""], ["Peressotti", "Marco", ""]]}, {"id": "2003.10245", "submitter": "Bas Westerbaan", "authors": "Kenta Cho, Bas Westerbaan and John van de Wetering", "title": "Dichotomy between deterministic and probabilistic models in countably\n  additive effectus theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectus theory is a relatively new approach to categorical logic that can be\nseen as an abstract form of generalized probabilistic theories (GPTs). While\nthe scalars of a GPT are always the real unit interval $[0,1]$, in an effectus\nthey can form any effect monoid. Hence, there are quite exotic effectuses\nresulting from more pathological effect monoids.\n  In this paper we introduce $\\sigma$-effectuses, where certain countable sums\nof morphisms are defined. We study in particular $\\sigma$-effectuses where\nunnormalized states can be normalized. We show that a non-trivial\n$\\sigma$-effectus with normalization has as scalars either the two-element\neffect monoid $\\{0,1\\}$ or the real unit interval $[0,1]$.\n  When states and/or predicates separate the morphisms we find that in the\n$\\{0,1\\}$ case the category must embed into the category of sets and partial\nfunctions (and hence the category of Boolean algebras), showing that it\nimplements a deterministic model, while in the $[0,1]$ case we find it embeds\ninto the category of Banach order-unit spaces and of Banach pre-base-norm\nspaces (satisfying additional properties), recovering the structure present in\nGPTs.\n  Hence, from abstract categorical and operational considerations we find a\ndichotomy between deterministic and convex probabilistic models of physical\ntheories.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:53:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Cho", "Kenta", ""], ["Westerbaan", "Bas", ""], ["van de Wetering", "John", ""]]}, {"id": "2003.10480", "submitter": "Andrea Loreggia", "authors": "Roberta Calegari, Andrea Loreggia, Emiliano Lorini, Francesca Rossi,\n  Giovanni Sartor", "title": "Modeling Contrary-to-Duty with CP-nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a ceteris-paribus semantics for deontic logic, a state of affairs where a\nlarger set of prescriptions is respected is preferable to a state of affairs\nwhere some of them are violated. Conditional preference nets (CP-nets) are a\ncompact formalism to express and analyse ceteris paribus preferences, which\nnice computational properties. This paper shows how deontic concepts can be\ncaptured through conditional preference models. A restricted deontic logic will\nbe defined, and mapped into conditional preference nets. We shall also show how\nto model contrary to duties obligations in CP-nets and how to capture in this\nformalism the distinction between strong and weak permission.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:23:18 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Calegari", "Roberta", ""], ["Loreggia", "Andrea", ""], ["Lorini", "Emiliano", ""], ["Rossi", "Francesca", ""], ["Sartor", "Giovanni", ""]]}, {"id": "2003.10623", "submitter": "Daisuke Ishii", "authors": "Daisuke Ishii, Tomohito Yabu", "title": "Computer-Assisted Verification of Four Interval Arithmetic Operators", "comments": "15 pages, 5 figures, 2 tables", "journal-ref": "Journal of Computational and Applied Mathematics 377, 112893\n  (2020)", "doi": "10.1016/j.cam.2020.112893", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interval arithmetic libraries provide the four elementary arithmetic\noperators for operand intervals bounded by floating-point numbers. Actual\nimplementations need to make a large case analysis that considers, e.g.,\nmagnitude relations between all pairs of argument bounds, positional relations\nbetween the arguments and zero, and handling of the special values, infinities\nand NaN. Their correctness is not obvious as they are implemented by human\nhands, which comes to be critical for the reliability. This work provides a\nmechanically-verified interval arithmetic library. For this purpose, we utilize\nthe Why3 platform equipped with a specification language for annotated programs\nand back-end theorem provers. We conduct several proof tasks for each of three\nproperties of the target code: validity, soundness, and tightness; zero\ndivision exception handling is also verified for the division code. To\naccomplish the proof, we propose several techniques for\nspecification/verification. First, we specify additional lemmas that support\ndeductions made by back-end SMT solvers, which enable to discharge proof\nobligations in floating-point arithmetic containing nonlinear terms. Second, we\nexamine the annotation of tightness, which requires to assume that a\ncomputation may result in NaN; we propose specific extremum operators for this\npurpose. In the experiments, applying the techniques in conjunction with the\nAlt-Ergo SMT solver and the Coq proof assistant proved the entire code.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 02:31:57 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:50:46 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ishii", "Daisuke", ""], ["Yabu", "Tomohito", ""]]}, {"id": "2003.10935", "submitter": "Martin Grohe", "authors": "Martin Grohe and Pascal Schweitzer and Daniel Wiebking", "title": "Deep Weisfeiler Leman", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the framework of Deep Weisfeiler Leman algorithms (DeepWL),\nwhich allows the design of purely combinatorial graph isomorphism tests that\nare more powerful than the well-known Weisfeiler-Leman algorithm.\n  We prove that, as an abstract computational model, polynomial time\nDeepWL-algorithms have exactly the same expressiveness as the logic Choiceless\nPolynomial Time (with counting) introduced by Blass, Gurevich, and Shelah (Ann.\nPure Appl. Logic., 1999)\n  It is a well-known open question whether the existence of a polynomial time\ngraph isomorphism test implies the existence of a polynomial time canonisation\nalgorithm. Our main technical result states that for each class of graphs\n(satisfying some mild closure condition), if there is a polynomial time DeepWL\nisomorphism test then there is a polynomial canonisation algorithm for this\nclass. This implies that there is also a logic capturing polynomial time on\nthis class.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:53:17 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Grohe", "Martin", ""], ["Schweitzer", "Pascal", ""], ["Wiebking", "Daniel", ""]]}, {"id": "2003.11010", "submitter": "EPTCS", "authors": "Nicolas Behr (Universit\\'e de Paris, France), Reiko Heckel (University\n  of Leicester, UK), Maryam Ghaffari Saadat (University of Leicester, UK)", "title": "Efficient Computation of Graph Overlaps for Rule Composition: Theory and\n  Z3 Prototyping", "comments": "In Proceedings GCM 2020, arXiv:2012.01181", "journal-ref": "EPTCS 330, 2020, pp. 126-144", "doi": "10.4204/EPTCS.330.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph transformation theory relies upon the composition of rules to express\nthe effects of sequences of rules. In practice, graphs are often subject to\nconstraints, ruling out many candidates for composed rules. Focusing on the\ncase of sesqui-pushout (SqPO) semantics, we develop a number of alternative\nstrategies for computing compositions, each theoretically and with an\nimplementation via the Python API of the Z3 theorem prover. The strategies\ncomprise a straightforward generate-and-test strategy based on forbidden graph\npatterns, a variant with a more implicit logical encoding of the negative\nconstraints, and a modular strategy, where the patterns are decomposed as\nforbidden relation patterns. For a toy model of polymer formation in organic\nchemistry, we compare the performance of the three strategies in terms of\nexecution times and memory consumption.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:54:00 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 02:29:12 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Behr", "Nicolas", "", "Universit\u00e9 de Paris, France"], ["Heckel", "Reiko", "", "University\n  of Leicester, UK"], ["Saadat", "Maryam Ghaffari", "", "University of Leicester, UK"]]}, {"id": "2003.11331", "submitter": "Wilmer Ricciotti", "authors": "Wilmer Ricciotti and James Cheney", "title": "A Formalization of SQL with Nulls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SQL is the world's most popular declarative language, forming the basis of\nthe multi-billion-dollar database industry. Although SQL has been standardized,\nthe full standard is based on ambiguous natural language rather than formal\nspecification. Commercial SQL implementations interpret the standard in\ndifferent ways, so that, given the same input data, the same query can yield\ndifferent results depending on the SQL system it is run on. Even for a\nparticular system, mechanically checked formalization of all widely-used\nfeatures of SQL remains an open problem. The lack of a well-understood formal\nsemantics makes it very difficult to validate the soundness of database\nimplementations.\n  Although formal semantics for fragments of SQL were designed in the past,\nthey usually did not support set and bag operations, nested subqueries, and,\ncrucially, null values. Null values complicate SQL's semantics in profound ways\nanalogous to null pointers or side-effects in other programming languages.\nSince certain SQL queries are equivalent in the absence of null values, but\nproduce different results when applied to tables containing incomplete data,\nsemantics which ignore null values are able to prove query equivalences that\nare unsound in realistic databases.\n  A formal semantics of SQL supporting all the aforementioned features was only\nproposed recently. In this paper, we report about our mechanization of SQL\nsemantics covering set/bag operations, nested subqueries, and nulls, written\nthe Coq proof assistant, and describe the validation of key metatheoretic\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:23:25 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ricciotti", "Wilmer", ""], ["Cheney", "James", ""]]}, {"id": "2003.11351", "submitter": "Jakub Opr\\v{s}al", "authors": "Andrei Krokhin, Jakub Opr\\v{s}al, Marcin Wrochna, Stanislav\n  \\v{Z}ivn\\'y", "title": "Topology and adjunction in promise constraint satisfaction", "comments": "This merges and subsumes arXiv:1904.03214 and arXiv:1907.00872.\n  Corrected a mistakes in the proof of Theorem 1.9 and reformulated Lemma 3.26", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate graph colouring problem concerns colouring a $k$-colourable\ngraph with $c$ colours, where $c\\geq k$. This problem naturally generalises to\npromise graph homomorphism and further to promise constraint satisfaction\nproblems. Complexity analysis of all these problems is notoriously difficult.\nIn this paper, we introduce two new techniques to analyse the complexity of\npromise CSPs: one is based on topology and the other on adjunction. We apply\nthese techniques, together with the previously introduced algebraic approach,\nto obtain new NP-hardness results for a significant class of approximate graph\ncolouring and promise graph homomorphism problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 12:06:58 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 12:23:12 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Krokhin", "Andrei", ""], ["Opr\u0161al", "Jakub", ""], ["Wrochna", "Marcin", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "2003.11519", "submitter": "Eduardo Mizraji", "authors": "Eduardo Mizraji", "title": "Vector logic allows counterfactual virtualization by The Square Root of\n  NOT", "comments": "This is a 12 pages preprint", "journal-ref": "Logic Journal of IGPL-Published online on July 2020", "doi": "10.1093/jigpal/jzaa026", "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate the representation of counterfactual conditionals\nusing the vector logic, a matrix-vectors formalism for logical functions and\ntruth values. Inside this formalism, the counterfactuals can be transformed in\ncomplex matrices preprocessing an implication matrix with one of the square\nroots of NOT, a complex matrix. This mathematical approach puts in evidence the\nvirtual character of the counterfactuals. This happens because this\nrepresentation produces a valuation of a counterfactual that is the\nsuperposition of the two opposite truth values weighted, respectively, by two\ncomplex conjugated coefficients. This result shows that this procedure gives an\nuncertain evaluation projected on the complex domain. After this basic\nrepresentation, the judgment of the plausibility of a given counterfactual\nallows us to shift the decision towards an acceptance or a refusal. This shift\nis the result of applying for a second time one of the two square roots of NOT.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:56:36 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 01:23:39 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 21:59:24 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mizraji", "Eduardo", ""]]}, {"id": "2003.11631", "submitter": "Jasper De Bock", "authors": "Jasper De Bock", "title": "Choice functions based on sets of strict partial orders: an axiomatic\n  characterisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for choosing from a set of options are often based on a strict\npartial order on these options, or on a set of such partial orders. I here\nprovide a very general axiomatic characterisation for choice functions of this\nform. It includes as special cases axiomatic characterisations for choice\nfunctions based on (sets of) total orders, (sets of) weak orders, (sets of)\ncoherent lower previsions and (sets of) probability measures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 21:00:57 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 15:36:07 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["De Bock", "Jasper", ""]]}, {"id": "2003.11689", "submitter": "Philipp Berger", "authors": "Lukas Westhofen, Philipp Berger, Joost-Pieter Katoen", "title": "Benchmarking Software Model Checkers on Automotive Code", "comments": "This is the preprint of an NFM2020 conference paper, including the\n  full appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on our experiences with verifying automotive C code by\nstate-of-the-art open source software model checkers. The embedded C code is\nautomatically generated from Simulink open-loop controller models. Its diverse\nfeatures (decision logic, floating-point and pointer arithmetic, rate limiters\nand state-flow systems) and the extensive use of floating-point variables make\nverifying the code highly challenging. Our study reveals large discrepancies in\ncoverage - which is at most only 20% of all requirements --- and tool strength\ncompared to results from the main annual software verification competition. A\nhand-crafted, simple extension of the verifier CBMC with $k$-induction delivers\nresults on 63% of the requirements while the proprietary BTC EmbeddedValidator\ncovers 80% and obtains bounded verification results for most of the remaining\nrequirements.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 00:54:36 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Westhofen", "Lukas", ""], ["Berger", "Philipp", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2003.11692", "submitter": "Sebastian Siebertz", "authors": "Yiting Jiang, Jaroslav Nesetril, Patrice Ossona de Mendez, and\n  Sebastian Siebertz", "title": "Regular partitions of gentle graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Szemeredi's Regularity Lemma is a very useful tool of extremal combinatorics.\nRecently, several refinements of this seminal result were obtained for special,\nmore structured classes of graphs. We survey these results in their rich\ncombinatorial context. In particular, we stress the link to the theory of\n(structural) sparsity, which leads to alternative proofs, refinements and\nsolutions of open problems. It is interesting to note that many of these\nclasses present challenging problems. Nevertheless, from the point of view of\nregularity lemma type statements, they appear as \"gentle\" classes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 01:01:19 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 17:52:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jiang", "Yiting", ""], ["Nesetril", "Jaroslav", ""], ["de Mendez", "Patrice Ossona", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "2003.11764", "submitter": "Dmitriy Zhuk", "authors": "Dmitriy Zhuk", "title": "No-Rainbow Problem and the Surjective Constraint Satisfaction Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Surjective Constraint Satisfaction Problem (SCSP) is the problem of\ndeciding whether there exists a surjective assignment to a set of variables\nsubject to some specified constraints, where a surjective assignment is an\nassignment containing all elements of the domain. In this paper we show that\nthe most famous SCSP, called No-Rainbow Problem, is NP-Hard. Additionally, we\ndisprove the conjecture saying that the SCSP over a constraint language\n$\\Gamma$ and the CSP over the same language with constants have the same\ncomputational complexity up to poly-time reductions. Our counter-example also\nshows that the complexity of the SCSP cannot be described in terms of\npolymorphisms of the constraint language.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 06:55:46 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 19:39:35 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 10:19:32 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2021 16:04:02 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhuk", "Dmitriy", ""]]}, {"id": "2003.11838", "submitter": "Florian Kamm\\\"uller", "authors": "Florian Kamm\\\"uller and Manfred Kerber", "title": "Applying the Isabelle Insider Framework to Airplane Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avionics is one of the fields in which verification methods have been\npioneered and brought a new level of reliability to systems used in safety\ncritical environments. Tragedies, like the 2015 insider attack on a German\nairplane, in which all 150 people on board died, show that safety and security\ncrucially depend not only on the well functioning of systems but also on the\nway how humans interact with the systems. Policies are a way to describe how\nhumans should behave in their interactions with technical systems, formal\nreasoning about such policies requires integrating the human factor into the\nverification process. In this paper, we report on our work on using logical\nmodelling and analysis of infrastructure models and policies with actors to\nscrutinize security policies in the presence of insiders. We model insider\nattacks on airplanes in the Isabelle Insider framework. This application\nmotivates the use of an extension of the framework with Kripke structures and\nthe temporal logic CTL to enable reasoning on dynamic system states.\nFurthermore, we illustrate that Isabelle modelling and invariant reasoning\nreveal subtle security assumptions. We summarize by providing a methodology for\nthe development of policies that satisfy stated properties.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 11:15:07 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Kamm\u00fcller", "Florian", ""], ["Kerber", "Manfred", ""]]}, {"id": "2003.12531", "submitter": "Maaike Zwart", "authors": "Maaike Zwart and Dan Marsden", "title": "No-Go Theorems for Distributive Laws", "comments": "arXiv admin note: text overlap with arXiv:1811.06460", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monads are commonplace in computer science, and can be composed using Beck's\ndistributive laws. Unfortunately, finding distributive laws can be extremely\ndifficult and error-prone. The literature contains some general principles for\nconstructing distributive laws. However, until now there have been no such\ntechniques for establishing when no distributive law exists.\n  We present three families of theorems for showing when there can be no\ndistributive law between two monads. The first widely generalizes a\ncounterexample attributed to Plotkin. It covers all the previous known no-go\nresults for specific pairs of monads, and includes many new results. The second\nand third families are entirely novel, encompassing various new practical\nsituations. For example, they negatively resolve the open question of whether\nthe list monad distributes over itself, reveal a previously unobserved error in\nthe literature, and confirm a conjecture made by Beck himself in his first\npaper on distributive laws. In addition, we establish conditions under which\nthere can be at most one possible distributive law between two monads, proving\nvarious known distributive laws to be unique.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:48:07 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 11:05:23 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 11:29:10 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zwart", "Maaike", ""], ["Marsden", "Dan", ""]]}, {"id": "2003.12906", "submitter": "Sabine Frittella", "authors": "Marta B\\'ilkov\\'a, Sabine Frittella, Ondrej Majer, Sajad Nazari", "title": "How to reason with inconsistent probabilistic information?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of research has developed around logics of belief based on\nevidence. The approach of B\\'ilkov\\'a et al understands belief as based on\ninformation confirmed by a reliable source. We propose a finer analysis of how\nbelief can be based on information, where the confirmation comes from multiple\npossibly conflicting sources and is of a probabilistic nature. We use\nBelnap-Dunn logic and its probabilistic extensions to account for potentially\ncontradictory information on which belief is grounded. We combine it with an\nextension of Lukasiewicz logic, or a bilattice logic, within a two-layer modal\nlogical framework to account for belief.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 22:53:49 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 08:36:36 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["B\u00edlkov\u00e1", "Marta", ""], ["Frittella", "Sabine", ""], ["Majer", "Ondrej", ""], ["Nazari", "Sajad", ""]]}, {"id": "2003.13108", "submitter": "Micha{\\l} Przyby{\\l}ek", "authors": "Micha{\\l} R. Przyby{\\l}ek", "title": "On amenability of constraint satisfaction problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results show that a constraint satisfaction problem (CSP) defined over\nrational numbers with their natural ordering has a solution if and only if it\nhas a definable solution. The proof uses advanced results from topology and\nmodern model theory. The aim of this paper is threefold. (1) We give a simple\npurely-logical proof of the claim and show that the advanced results from\ntopology and model theory are not needed; (2) we introduce an intrinsic\ncharacterisation of the statement \"definable CSP has a solution iff it has a\ndefinable solution\" and investigate it in general intuitionistic set theories\n(3) we show that the results from modern model theory are indeed needed, but\nfor the implication reversed: we prove that \"definable CSP has a solution iff\nit has a definable solution\" holds over a countable structure if and only if\nthe automorphism group of the structure is extremely amenable.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 18:50:01 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Przyby\u0142ek", "Micha\u0142 R.", ""]]}, {"id": "2003.13542", "submitter": "Edmund Robinson", "authors": "Claudio Hermida and Uday Reddy and Edmund Robinson and Alessio\n  Santamaria", "title": "Bisimulation as a Logical Relation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate how various forms of bisimulation can be characterised using\nthe technology of logical relations. The approach taken is that each form of\nbisimulation corresponds to an algebraic structure derived from a transition\nsystem, and the general result is that a relation $R$ between two transition\nsystems on state spaces $S$ and $T$ is a bisimulation if and only if the\nderived algebraic structures are in the logical relation automatically\ngenerated from $R$. We show that this approach works for the original\nPark-Milner bisimulation and that it extends to weak bisimulation, and\nbranching and semi-branching bisimulation. The paper concludes with a\ndiscussion of probabilistic bisimulation, where the situation is slightly more\ncomplex, partly owing to the need to encompass bisimulations that are not just\nrelations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:12:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hermida", "Claudio", ""], ["Reddy", "Uday", ""], ["Robinson", "Edmund", ""], ["Santamaria", "Alessio", ""]]}, {"id": "2003.13745", "submitter": "Pascal Schweitzer", "authors": "Jendrik Brachter and Pascal Schweitzer", "title": "On the Weisfeiler-Leman Dimension of Finite Groups", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparison to graphs, combinatorial methods for the isomorphism problem of\nfinite groups are less developed than algebraic ones. To be able to investigate\nthe descriptive complexity of finite groups and the group isomorphism problem,\nwe define the Weisfeiler-Leman algorithm for groups. In fact we define three\nversions of the algorithm. In contrast to graphs, where the three analogous\nversions readily agree, for groups the situation is more intricate. For groups,\nwe show that their expressive power is linearly related. We also give\ndescriptions in terms of counting logics and bijective pebble games for each of\nthe versions.\n  In order to construct examples of groups, we devise an isomorphism and\nnon-isomorphism preserving transformation from graphs to groups. Using graphs\nof high Weisfeiler-Leman dimension, we construct highly similar but\nnon-isomorphic groups with equal~$\\Theta(\\log n)$-subgroup-profiles, which\nnevertheless have Weisfeiler-Leman dimension 3. These groups are nilpotent\ngroups of class 2 and exponent~$p$, they agree in many combinatorial properties\nsuch as the combinatorics of their conjugacy classes and have highly similar\ncommuting graphs.\n  The results indicate that the Weisfeiler-Leman algorithm can be more\neffective in distinguishing groups than in distinguishing graphs based on\nsimilar combinatorial constructions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:51:55 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Brachter", "Jendrik", ""], ["Schweitzer", "Pascal", ""]]}, {"id": "2003.14177", "submitter": "Micha{\\l} Pilipczuk", "authors": "Adam Paszke and Micha{\\l} Pilipczuk", "title": "VC density of set systems defnable in tree-like graphs", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study set systems definable in graphs using variants of logic with\ndifferent expressive power. Our focus is on the notion of Vapnik-Chervonenkis\ndensity: the smallest possible degree of a polynomial bounding the\ncardinalities of restrictions of such set systems. On one hand, we prove that\nif $\\varphi(\\bar x,\\bar y)$ is a fixed CMSO$_1$ formula and $\\cal C$ is a class\nof graphs with uniformly bounded cliquewidth, then the set systems defined by\n$\\varphi$ in graphs from $\\cal C$ have VC density at most $|\\bar y|$, which is\nthe smallest bound that one could expect. We also show an analogous statement\nfor the case when $\\varphi(\\bar x,\\bar y)$ is a CMSO$_2$ formula and $\\cal C$\nis a class of graphs with uniformly bounded treewidth. We complement these\nresults by showing that if $\\cal C$ has unbounded cliquewidth (respectively,\ntreewidth), then, under some mild technical assumptions on $\\cal C$, the set\nsystems definable by CMSO$_1$ (respectively, CMSO$_2$) formulas in graphs from\n$\\cal C$ may have unbounded VC dimension, hence also unbounded VC density.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 13:21:59 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Paszke", "Adam", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "2003.14187", "submitter": "Zhiguang Zhao", "authors": "Zhiguang Zhao", "title": "Sahlqvist Correspondence Theory for Instantial Neighbourhood Logic", "comments": "arXiv admin note: text overlap with arXiv:2003.08070", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we investigate the Sahlqvist-type correspondence theory\nfor instantial neighbourhood logic (INL), which can talk about existential\ninformation about the neighbourhoods of a given world and is a mixture between\nrelational semantics and neighbourhood semantics. We have two proofs of the\ncorrespondence results, the first proof is obtained by using standard\ntranslation and minimal valuation techniques directly, the second proof follows\n[4] and [6], where we use bimodal translation method to reduce the\ncorrespondence problem in instantial neighbourhood logic to normal bimodal\nlogics in classical Kripke semantics. We give some remarks and future\ndirections at the end of the paper.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 06:07:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhao", "Zhiguang", ""]]}, {"id": "2003.14204", "submitter": "Chao Gu", "authors": "Chao Gu, Ziyue Ma, Zhiwu Li, Alessandro Giua", "title": "Verification of Nonblockingness in Bounded Petri Nets With Minimax Basis\n  Reachability Graphs", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a semi-structural approach to verify the nonblockingness\nof a Petri net. We construct a structure, called minimax basis reachability\ngraph (minimax-BRG): it provides an abstract description of the reachability\nset of a net while preserving all information needed to test if the net is\nblocking. We prove that a bounded deadlock-free Petri net is nonblocking if and\nonly if its minimax-BRG is unobstructed, which can be verified by solving a set\nof integer constraints and then examining the minimax-BRG. For Petri nets that\nare not deadlock-free, one needs to determine the set of deadlock markings.\nThis can be done with an approach based on the computation of maximal implicit\nfiring sequences enabled by the markings in the minimax-BRG. The approach we\ndeveloped does not require the construction of the reachability graph and has\nwide applicability.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 13:44:58 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 04:04:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Gu", "Chao", ""], ["Ma", "Ziyue", ""], ["Li", "Zhiwu", ""], ["Giua", "Alessandro", ""]]}, {"id": "2003.14271", "submitter": "Murdoch Gabbay", "authors": "Lars Brunjes and Murdoch J. Gabbay", "title": "UTxO- vs account-based smart contract blockchain programming paradigms", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61467-6_6", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement two versions of a simple but illustrative smart contract: one in\nSolidity on the Ethereum blockchain platform, and one in Plutus on the Cardano\nplatform, with annotated code excerpts and with source code attached. We get a\nclearer view of the Cardano programming model in particular by introducing a\nnovel mathematical abstraction which we call Idealised EUTxO. For each version\nof the contract, we trace how the architectures of the underlying platforms and\ntheir mathematics affects the natural programming styles and natural classes of\nerrors. We prove some simple but novel results about alpha-conversion and\nobservational equivalence for Cardano, and explain why Ethereum does not have\nthem. We conclude with a wide-ranging and detailed discussion in the light of\nthe examples, mathematical model, and mathematical results so far.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:53:56 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 06:40:15 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 10:38:49 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 08:29:50 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Brunjes", "Lars", ""], ["Gabbay", "Murdoch J.", ""]]}, {"id": "2003.14342", "submitter": "Gabriel Nivasch", "authors": "Jeff Erickson, Gabriel Nivasch, Junyan Xu", "title": "Fusible numbers and Peano Arithmetic", "comments": "Minor improvements. 26 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a mathematical riddle involving fuses, we define the \"fusible\nnumbers\" as follows: $0$ is fusible, and whenever $x,y$ are fusible with\n$|y-x|<1$, the number $(x+y+1)/2$ is also fusible. We prove that the set of\nfusible numbers, ordered by the usual order on $\\mathbb R$, is well-ordered,\nwith order type $\\varepsilon_0$. Furthermore, we prove that the density of the\nfusible numbers along the real line grows at an incredibly fast rate: Letting\n$g(n)$ be the largest gap between consecutive fusible numbers in the interval\n$[n,\\infty)$, we have $g(n)^{-1} \\ge F_{\\varepsilon_0}(n-c)$ for some constant\n$c$, where $F_\\alpha$ denotes the fast-growing hierarchy. Finally, we derive\nsome true statements that can be formulated but not proven in Peano Arithmetic,\nof a different flavor than previously known such statements: PA cannot prove\nthe true statement \"For every natural number $n$ there exists a smallest\nfusible number larger than $n$.\" Also, consider the algorithm \"$M(x)$: if $x<0$\nreturn $-x$, else return $M(x-M(x-1))/2$.\" Then $M$ terminates on real inputs,\nalthough PA cannot prove the statement \"$M$ terminates on all natural inputs.\"\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:25:09 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 17:41:44 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 07:46:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Erickson", "Jeff", ""], ["Nivasch", "Gabriel", ""], ["Xu", "Junyan", ""]]}]