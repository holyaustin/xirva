[{"id": "1506.00398", "submitter": "Giulio Chiribella", "authors": "Giulio Chiribella, Giacomo Mauro D'Ariano, and Paolo Perinotti", "title": "Quantum from principles", "comments": "50 pages, no figures, published version. Summarizes the framework and\n  the results of arXiv:0908.1583 and arXiv:1011.6451", "journal-ref": "book chapter in\"Quantum Theory: Informational Foundations and\n  Foils\", G. Chiribella and R. Spekkens eds., Springer (2016)", "doi": "10.1007/978-94-017-7303-4", "report-no": null, "categories": "quant-ph cs.IT cs.LO math-ph math.CT math.IT math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum theory was discovered in an adventurous way, under the urge to solve\npuzzles-like the spectrum of the blackbody radiation-that haunted the physics\ncommunity at the beginning of the 20th century. It soon became clear, though,\nthat quantum theory was not just a theory of specific physical systems, but\nrather a new language of universal applicability. Can this language be\nreconstructed from first principles? Can we arrive at it from logical\nreasoning, instead of ad hoc guesswork? A positive answer was provided in Refs.\n[1, 2], where we put forward six principles that identify quantum theory\nuniquely in a broad class of theories. We first defined a class of \"theories of\ninformation\", constructed as extensions of probability theory in which events\ncan be connected into networks. In this framework, we formulated the six\nprinciples as rules governing the control and the accessibility of information.\nDirectly from these rules, we reconstructed a number of quantum information\nfeatures, and eventually, the whole Hilbert space framework. In short, our\nprinciples characterize quantum theory as the theory of information that allows\nfor maximal control of randomness.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 09:10:27 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2015 03:28:20 GMT"}, {"version": "v3", "created": "Sun, 13 Mar 2016 10:38:43 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Chiribella", "Giulio", ""], ["D'Ariano", "Giacomo Mauro", ""], ["Perinotti", "Paolo", ""]]}, {"id": "1506.00482", "submitter": "Oded Maler", "authors": "Irini-Eleftheria Mens (CNRS-VERIMAG), Oded Maler (CNRS-VERIMAG)", "title": "Learning Regular Languages over Large Ordered Alphabets", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  17, 2015) lmcs:1589", "doi": "10.2168/LMCS-11(3:13)2015", "report-no": null, "categories": "cs.LO cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with regular languages defined over large alphabets,\neither infinite or just too large to be expressed enumeratively. We define a\ngeneric model where transitions are labeled by elements of a finite partition\nof the alphabet. We then extend Angluin's L* algorithm for learning regular\nlanguages from examples for such automata. We have implemented this algorithm\nand we demonstrate its behavior where the alphabet is a subset of the natural\nor real numbers. We sketch the extension of the algorithm to a class of\nlanguages over partially ordered alphabets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 13:12:54 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 19:04:30 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Mens", "Irini-Eleftheria", "", "CNRS-VERIMAG"], ["Maler", "Oded", "", "CNRS-VERIMAG"]]}, {"id": "1506.01001", "submitter": "Lucius Meredith", "authors": "Lucius Gregory Meredith", "title": "Linear Types Can Change the Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We give an interpretation of full classical linear logic, and linear proofs\nin terms of operations on the blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 19:35:08 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Meredith", "Lucius Gregory", ""]]}, {"id": "1506.01296", "submitter": "Vladimir Podolskii", "authors": "Vladimir V. Podolskii", "title": "Circuit Complexity Meets Ontology-Based Data Access", "comments": "To appear in proceedings of CSR 2015, LNCS 9139, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based data access is an approach to organizing access to a database\naugmented with a logical theory. In this approach query answering proceeds\nthrough a reformulation of a given query into a new one which can be answered\nwithout any use of theory. Thus the problem reduces to the standard database\nsetting.\n  However, the size of the query may increase substantially during the\nreformulation. In this survey we review a recently developed framework on\nproving lower and upper bounds on the size of this reformulation by employing\nmethods and results from Boolean circuit complexity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 16:02:07 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Podolskii", "Vladimir V.", ""]]}, {"id": "1506.01315", "submitter": "Mario Szegedy", "authors": "Mario Szegedy and Yixin Xu", "title": "Impossibility Theorems and the Universal Algebraic Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elucidate a close connection between the Theory of Judgment Aggregation\n(more generally, Evaluation Aggregation), and a relatively young but rapidly\ngrowing field of universal algebra, that was primarily developed to investigate\nconstraint satisfaction problems. Our connection yields a full classification\nof non-binary evaluations into possibility and impossibility domains both under\nthe idempotent and the supportive conditions. Prior to the current result E.\nDokow and R. Holzman nearly classified non-binary evaluations in the supportive\ncase, by combinatorial means. The algebraic approach gives us new insights to\nthe easier binary case as well, which had been fully classified by the above\nauthors. Our algebraic view lets us put forth a suggestion about a\nstrengthening of the Non-dictatorship criterion, that helps us avoid \"outliers\"\nlike the affine subspace. Finally, we give upper bounds on the complexity of\ncomputing if a domain is impossible or not (to our best knowledge no finite\ntime bounds were given earlier).\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 04:42:36 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Szegedy", "Mario", ""], ["Xu", "Yixin", ""]]}, {"id": "1506.01476", "submitter": "Marianna Nicolosi Asmundo", "authors": "Domenico Cantone, Marianna Nicolosi-Asmundo", "title": "The decision problem for a three-sorted fragment of set theory with\n  restricted quantification and finite enumerations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve the satisfiability problem for a three-sorted fragment of set theory\n(denoted $3LQST_0^R$), which admits a restricted form of quantification over\nindividual and set variables and the finite enumeration operator $\\{\\text{-},\n\\text{-}, \\ldots, \\text{-}\\}$ over individual variables, by showing that it\nenjoys a small model property, i.e., any satisfiable formula $\\psi$ of\n$3LQST_0^R$ has a finite model whose size depends solely on the length of\n$\\psi$ itself. Several set-theoretic constructs are expressible by\n$3LQST_0^R$-formulae, such as some variants of the power set operator and the\nunordered Cartesian product. In particular, concerning the unordered Cartesian\nproduct, we show that when finite enumerations are used to represent the\nconstruct, the resulting formula is exponentially shorter than the one that can\nbe constructed without resorting to such terms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 06:54:54 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Cantone", "Domenico", ""], ["Nicolosi-Asmundo", "Marianna", ""]]}, {"id": "1506.01602", "submitter": "Liana Hadarean", "authors": "Liana Hadarean, Alex Horn, Tim King", "title": "A Concurrency Problem with Exponential DPLL(T) Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many satisfiability modulo theories solvers implement a variant of the DPLL(T\n) framework which separates theory-specific reasoning from reasoning on the\npropositional abstraction of the formula. Such solvers conclude that a formula\nis unsatisfiable once they have learned enough theory conflicts to derive a\npropositional contradiction. However some problems, such as the diamonds\nproblem, require learning exponentially many conflicts. We give a general\ncriterion for establishing lower bounds on the number of theory conflicts in\nany DPLL(T ) proof for a given problem. We apply our criterion to two different\nstate-of-the-art symbolic partial-order encodings of a simple, yet\nrepresentative concurrency problem. Even though one of the encodings is\nasymptotically smaller than the other, we establish the same exponential lower\nbound proof complexity for both. Our experiments confirm this theoretical lower\nbound across multiple solvers and theory combinations.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 14:18:54 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Hadarean", "Liana", ""], ["Horn", "Alex", ""], ["King", "Tim", ""]]}, {"id": "1506.01603", "submitter": "Sebastien Tixeuil", "authors": "Pierre Courtieu (CEDRIC), Lionel Rieg, S\\'ebastien Tixeuil (NPA,\n  LINCS, IUF, LIP6), Xavier Urbain (ENSIIE, LRI, CEDRIC)", "title": "A Certified Universal Gathering Algorithm for Oblivious Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.DS cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the problem of universal gathering mobile\noblivious robots (that is, starting from any initial configuration that is not\nbivalent, using any number of robots, the robots reach in a finite number of\nsteps the same position, not known beforehand) without relying on a common\nchirality. We give very strong guaranties on the correctness of our algorithm\nby proving formally that it is correct, using the COQ proof assistant. To our\nknowledge, this is the first certified positive (and constructive) result in\nthe context of oblivious mobile robots. It demonstrates both the effectiveness\nof the approach to obtain new algorithms that are truly generic, and its\nmanagability since the amount of developped code remains human readable.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 14:23:19 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Courtieu", "Pierre", "", "CEDRIC"], ["Rieg", "Lionel", "", "NPA,\n  LINCS, IUF, LIP6"], ["Tixeuil", "S\u00e9bastien", "", "NPA,\n  LINCS, IUF, LIP6"], ["Urbain", "Xavier", "", "ENSIIE, LRI, CEDRIC"]]}, {"id": "1506.01762", "submitter": "Daisuke Ishii", "authors": "Daisuke Ishii, Naoki Yonezaki, Alexandre Goldsztejn", "title": "Monitoring Bounded LTL Properties Using Interval Analysis", "comments": "Appeared in NSV'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of temporal logic properties plays a crucial role in proving the\ndesired behaviors of hybrid systems. In this paper, we propose an interval\nmethod for verifying the properties described by a bounded linear temporal\nlogic. We relax the problem to allow outputting an inconclusive result when\nverification process cannot succeed with a prescribed precision, and present an\nefficient and rigorous monitoring algorithm that demonstrates that the problem\nis decidable. This algorithm performs a forward simulation of a hybrid\nautomaton, detects a set of time intervals in which the atomic propositions\nhold, and validates the property by propagating the time intervals. A\ncontinuous state at a certain time computed in each step is enclosed by an\ninterval vector that is proven to contain a unique solution. In the\nexperiments, we show that the proposed method provides a useful tool for formal\nanalysis of nonlinear and complex hybrid systems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 01:19:18 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 14:38:49 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Ishii", "Daisuke", ""], ["Yonezaki", "Naoki", ""], ["Goldsztejn", "Alexandre", ""]]}, {"id": "1506.01872", "submitter": "Jie Fan", "authors": "Jie Fan", "title": "Logics of Essence and Accident", "comments": "under submission. arXiv admin note: substantial text overlap with\n  arXiv:1505.03950", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature, essence is formalized in two different ways, either de\ndicto, or de re. Following \\cite{Marcos:2005}, we adopt its de dicto\nformalization: a formula is essential, if once it is true, it is necessarily\ntrue; otherwise, it is accidental. In this article, we study the model theory\nand axiomatization of the logic of essence and accident, i.e. the logic with\nessence operator (or accident operator) as the only primitive modality. We show\nthat the logic of essence and accident is less expressive than modal logic on\nnon-reflexive models, but the two logics are equally expressive on reflexive\nmodels. We prove that some frame properties are undefinable in the logic of\nessence and accident, while some are. We propose the suitable bisimulation for\nthis logic, based on which we characterize the expressive power of this logic\nwithin modal logic and within first-order logic. We axiomatize this logic over\nvarious frame classes, among which the symmetric case is missing, and our\nmethod is more suitable than those in the literature. We also find a method to\ncompute certain axioms used to axiomatize this logic over special frames in the\nliterature. As a side effect, we answer some open questions raised in\n\\cite{Marcos:2005}.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 11:33:42 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Fan", "Jie", ""]]}, {"id": "1506.01930", "submitter": "Benjamin Lucien Kaminski", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen", "title": "On the Hardness of Almost-Sure Termination", "comments": "MFCS 2015. arXiv admin note: text overlap with arXiv:1410.7225", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the computational hardness of computing expected\noutcomes and deciding (universal) (positive) almost-sure termination of\nprobabilistic programs. It is shown that computing lower and upper bounds of\nexpected outcomes is $\\Sigma_1^0$- and $\\Sigma_2^0$-complete, respectively.\nDeciding (universal) almost-sure termination as well as deciding whether the\nexpected outcome of a program equals a given rational value is shown to be\n$\\Pi^0_2$-complete. Finally, it is shown that deciding (universal) positive\nalmost-sure termination is $\\Sigma_2^0$-complete ($\\Pi_3^0$-complete).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 14:52:51 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1506.02367", "submitter": "Pierre Lescanne", "authors": "Maciej Bendkowski (TCS), Katarzyna Grygiel (TCS), Pierre Lescanne\n  (TCS, LIP), Marek Zaionc (TCS)", "title": "A natural counting of lambda terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.PL math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sequences of numbers corresponding to lambda terms of given\nsizes, where the size is this of lambda terms with de Bruijn indices in a very\nnatural model where all the operators have size 1. For plain lambda terms, the\nsequence corresponds to two families of binary trees for which we exhibit\nbijections. We study also the distribution of normal forms, head normal forms\nand strongly normalizing terms. In particular we show that strongly normalizing\nterms are of density 0 among plain terms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 06:57:41 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 08:19:29 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 08:30:30 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Bendkowski", "Maciej", "", "TCS"], ["Grygiel", "Katarzyna", "", "TCS"], ["Lescanne", "Pierre", "", "TCS, LIP"], ["Zaionc", "Marek", "", "TCS"]]}, {"id": "1506.02369", "submitter": "Anca Muscholl", "authors": "Anca Muscholl (LaBRI)", "title": "Automated Synthesis of Distributed Controllers", "comments": "ICALP 2015, Jul 2015, Kyoto, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesis is a particularly challenging problem for concurrent programs. At\nthe same time it is a very promising approach, since concurrent programs are\ndifficult to get right, or to analyze with traditional verification techniques.\nThis paper gives an introduction to distributed synthesis in the setting of\nMazurkiewicz traces, and its applications to decentralized runtime monitoring.\n1 Context Modern computing systems are increasingly distributed and\nheterogeneous. Software needs to be able to exploit these advances, providing\nmeans for applications to be more performant. Traditional concurrent\nprogramming paradigms, as in Java, are based on threads, shared-memory, and\nlocking mechanisms that guard access to common data. More recent paradigms like\nthe reactive programming model of Erlang [4] and Scala [35,36] replace shared\nmemory by asynchronous message passing, where sending a message is\nnon-blocking. In all these concurrent frameworks, writing reliable software is\na serious challenge. Programmers tend to think about code mostly in a\nsequential way, and it is hard to grasp all possible schedulings of events in a\nconcurrent execution. For similar reasons, verification and analysis of\nconcurrent programs is a difficult task. Testing, which is still the main\nmethod for error detection in software, has low coverage for concurrent\nprograms. The reason is that bugs in such programs are difficult to reproduce:\nthey may happen under very specific thread schedules and the likelihood of\ntaking such corner-case schedules is very low. Automated verification, such as\nmodel-checking and other traditional exploration techniques, can handle very\nlimited instances of concurrent programs, mostly because of the very large\nnumber of possible states and of possible interleavings of executions. Formal\nanalysis of programs requires as a prerequisite a clean mathematical model for\nprograms. Verification of sequential programs starts usually with an\nabstraction step -- reducing the value domains of variables to finite domains,\nviewing conditional branching as non-determinism, etc. Another major\nsimplification consists in disallowing recursion. This leads to a very robust\ncomputational model, namely finite-state automata and regular languages.\nRegular languages of words (and trees) are particularly well understood\nnotions. The deep connections between logic and automata revealed by the\nfoundational work of B\\\"uchi, Rabin, and others, are the main ingredients in\nautomata-based verification .\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 07:09:08 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Muscholl", "Anca", "", "LaBRI"]]}, {"id": "1506.02434", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Kristoffer Arnsfelt Hansen and Rasmus\n  Ibsen-Jensen", "title": "Strategy Complexity of Concurrent Stochastic Games with Safety and\n  Reachability Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider finite-state concurrent stochastic games, played by k>=2 players\nfor an infinite number of rounds, where in every round, each player\nsimultaneously and independently of the other players chooses an action,\nwhereafter the successor state is determined by a probability distribution\ngiven by the current state and the chosen actions. We consider reachability\nobjectives that given a target set of states require that some state in the\ntarget is visited, and the dual safety objectives that given a target set\nrequire that only states in the target set are visited. We are interested in\nthe complexity of stationary strategies measured by their patience, which is\ndefined as the inverse of the smallest nonzero probability employed. Our main\nresults are as follows: We show that in two-player zero-sum concurrent\nstochastic games (with reachability objective for one player and the\ncomplementary safety objective for the other player): (i) the optimal bound on\nthe patience of optimal and epsilon-optimal strategies, for both players is\ndoubly exponential; and (ii) even in games with a single nonabsorbing state\nexponential (in the number of actions) patience is necessary. In general we\nstudy the class of non-zero-sum games admitting stationary epsilon-Nash\nequilibria. We show that if there is at least one player with reachability\nobjective, then doubly-exponential patience may be needed for epsilon-Nash\nequilibrium strategies, whereas in contrast if all players have safety\nobjectives, the optimal bound on patience for epsilon-Nash equilibrium\nstrategies is only exponential.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 10:52:00 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Hansen", "Kristoffer Arnsfelt", ""], ["Ibsen-Jensen", "Rasmus", ""]]}, {"id": "1506.02483", "submitter": "Souymodip Chakraborty", "authors": "Souymodip Chakraborty and Joost-Pieter Katoen", "title": "On the Hardness of PCTL Satisfiability", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  Theorem 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that the satisfiability problem for probabilistic CTL (PCTL,\nfor short) is undecidable. By a reduction from $1\\frac{1}{2}$-player games with\nPCTL winning objectives, we establish that the PCTL satisfiability problem is\n${\\Sigma}_1^1$-hard. We present an exponential-time algorithm for the\nsatisfiability of a bounded, negation-closed fragment of PCTL, and show that\nthe satisfiability problem for this fragment is EXPTIME-hard.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 13:30:33 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 12:24:34 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2015 11:34:02 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Chakraborty", "Souymodip", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1506.02721", "submitter": "Arthur Ramos BSCS", "authors": "Arthur F. Ramos, Ruy J. G. B. de Queiroz, and Anjolina G. de Oliveira", "title": "On the Groupoid Model of Computational Paths", "comments": "12 pages + 2 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this work is to study mathematical properties of\ncomputational paths. Originally proposed by de Queiroz \\& Gabbay (1994) as\n`sequences or rewrites', computational paths are taken to be terms of the\nidentity type of Martin L\\\"of's Intensional Type Theory, since these paths can\nbe seen as the grounds on which the propositional equality between two\ncomputational objects stand. From this perspective, this work aims to show that\none of the properties of the identity type is present on computational paths.\nWe are referring to the fact that that the identity type induces a groupoid\nstructure, as proposed by Hofmann \\& Streicher (1994). Using categorical\nsemantics, we show that computational paths induce a groupoid structure. We\nalso show that computational paths are capable of inducing higher categorical\nstructures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 23:11:51 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 18:24:15 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Ramos", "Arthur F.", ""], ["de Queiroz", "Ruy J. G. B.", ""], ["de Oliveira", "Anjolina G.", ""]]}, {"id": "1506.02790", "submitter": "Saeed Salehi", "authors": "Saeed Salehi, Payam Seraji", "title": "Godel-Rosser's Incompleteness Theorems for Non-Recursively Enumerable\n  Theories", "comments": "Journal of Logic and Computation (2016) \"G\\\"odel-Rosser's\n  Incompleteness Theorem, generalized and optimized for definable theories\"", "journal-ref": "Journal of Logic and Computation 27:5 (2017) 1391--1397", "doi": "10.1093/logcom/exw025", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Godel's First Incompleteness Theorem is generalized to definable theories,\nwhich are not necessarily recursively enumerable, by using a couple of\nsyntactic-semantic notions, one is the consistency of a theory with the set of\nall true $\\Pi_n$-sentences or equivalently the $\\Sigma_n$-soundness of the\ntheory, and the other is $n$-consistency the restriction of\n$\\omega$-consistency to the $\\Sigma_n$-formulas. It is also shown that Rosser's\nIncompleteness Theorem does not generally hold for definable non-recursively\nenumerable theories, whence Godel-Rosser's Incompleteness Theorem is optimal in\na sense. Though the proof of the incompleteness theorem using the\n$\\Sigma_n$-soundness assumption is constructive, it is shown that there is no\nconstructive proof for the incompleteness theorem using the $n$-consistency\nassumption, for $n\\!>\\!2$.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 06:16:25 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2016 15:15:33 GMT"}, {"version": "v3", "created": "Sat, 10 Dec 2016 07:19:42 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Salehi", "Saeed", ""], ["Seraji", "Payam", ""]]}, {"id": "1506.02812", "submitter": "Xuechong Guan", "authors": "Xuechong Guan", "title": "A study on central soft sets: Definitions and basic operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new kind of soft sets related with some common decision\nmaking problems in real life called central soft sets is introduced. Properties\nof some basic operations on central soft sets are shown. It is investigated\nthat some classic operations between soft sets can be obtained by central soft\nsets with selecting different central sets. We initiate the concepts of an\nevaluation system for a parameters set and its optional solutions. An algorithm\nis presented to solve such decision making problems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 07:54:03 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Guan", "Xuechong", ""]]}, {"id": "1506.02931", "submitter": "EPTCS", "authors": "Oscar Cunningham (University of Oxford), Chris Heunen (University of\n  Oxford)", "title": "Axiomatizing complete positivity", "comments": "In Proceedings QPL 2015, arXiv:1511.01181", "journal-ref": "EPTCS 195, 2015, pp. 148-157", "doi": "10.4204/EPTCS.195.11", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two ways to turn a categorical model for pure quantum theory into\none for mixed quantum theory, both resulting in a category of completely\npositive maps. One has quantum systems as objects, whereas the other also\nallows classical systems on an equal footing. The former has been axiomatized\nusing environment structures. We extend this axiomatization to the latter by\nintroducing decoherence structures.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 14:29:24 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 01:42:50 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Cunningham", "Oscar", "", "University of Oxford"], ["Heunen", "Chris", "", "University of\n  Oxford"]]}, {"id": "1506.03266", "submitter": "Michael Gabbay", "authors": "Dov Gabbay, Michael Gabbay", "title": "The Attack as Strong Negation, Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We add strong negation $N$ to classical logic and interpret the attack\nrelation of \"$x$ attacks $y$\" in argumentation as $(x\\to Ny)$. We write a\ncorresponding object level (using $N$ only) classical theory for each\nargumentation network and show that the classical models of this theory\ncorrespond exactly to the complete extensions of the argumentation network. We\nshow by example how this approach simplifies the study of abstract\nargumentation networks. We compare with other translations of abstract\nargumentation networks into logic, such as classical predicate logic or modal\nlogics, or logic programming, and we also compare with Abstract Dialectical\nFrameworks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 11:44:53 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Gabbay", "Dov", ""], ["Gabbay", "Michael", ""]]}, {"id": "1506.03553", "submitter": "EPTCS", "authors": "Johan Arcile (Laboratoire IBISC, Universit\\'e d'Evry-Val d'Essonne),\n  Jean-Yves Didier (Laboratoire IBISC, Universit\\'e d'Evry-Val d'Essonne),\n  Hanna Klaudel (Laboratoire IBISC, Universit\\'e d'Evry-Val d'Essonne), Raymond\n  Devillers (D\\'epartement d'Informatique, Universit\\'e Libre de Bruxelles),\n  Artur Rataj (Institute of Theoretical and Applied Computer Science)", "title": "Indefinite waitings in MIRELA systems", "comments": "In Proceedings ESSS 2015, arXiv:1506.03250", "journal-ref": "EPTCS 184, 2015, pp. 5-18", "doi": "10.4204/EPTCS.184.1", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MIRELA is a high-level language and a rapid prototyping framework dedicated\nto systems where virtual and digital objects coexist in the same environment\nand interact in real time. Its semantics is given in the form of networks of\ntimed automata, which can be checked using symbolic methods. This paper shows\nhow to detect various kinds of indefinite waitings in the components of such\nsystems. The method is experimented using the PRISM model checker.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 06:10:32 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Arcile", "Johan", "", "Laboratoire IBISC, Universit\u00e9 d'Evry-Val d'Essonne"], ["Didier", "Jean-Yves", "", "Laboratoire IBISC, Universit\u00e9 d'Evry-Val d'Essonne"], ["Klaudel", "Hanna", "", "Laboratoire IBISC, Universit\u00e9 d'Evry-Val d'Essonne"], ["Devillers", "Raymond", "", "D\u00e9partement d'Informatique, Universit\u00e9 Libre de Bruxelles"], ["Rataj", "Artur", "", "Institute of Theoretical and Applied Computer Science"]]}, {"id": "1506.03554", "submitter": "EPTCS", "authors": "Simon Busard (Universit\\'e catholique de Louvain), Quentin Cappart\n  (Universit\\'e catholique de Louvain), Christophe Limbr\\'ee (Universit\\'e\n  catholique de Louvain), Charles Pecheur (Universit\\'e catholique de Louvain),\n  Pierre Schaus (Universit\\'e catholique de Louvain)", "title": "Verification of railway interlocking systems", "comments": "In Proceedings ESSS 2015, arXiv:1506.03250", "journal-ref": "EPTCS 184, 2015, pp. 19-31", "doi": "10.4204/EPTCS.184.2", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the railway domain, an interlocking is a computerised system that controls\nthe railway signalling objects in order to allow a safe operation of the train\ntraffic. Each interlocking makes use of particular data, called application\ndata, that reflects the track layout of the station under control. The\nverification and validation of the application data are performed manually and\nis thus error-prone and costly. In this paper, we explain how we built an\nexecutable model in NuSMV of a railway interlocking based on the application\ndata. We also detail the tool that we have developed in order to translate the\napplication data into our model automatically. Finally we show how we could\nverify a realistic set of safety properties on a real-size station model by\ncustomizing the existing model-checking algorithm with PyNuSMV a Python library\nbased on NuSMV.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 06:10:41 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Busard", "Simon", "", "Universit\u00e9 catholique de Louvain"], ["Cappart", "Quentin", "", "Universit\u00e9 catholique de Louvain"], ["Limbr\u00e9e", "Christophe", "", "Universit\u00e9\n  catholique de Louvain"], ["Pecheur", "Charles", "", "Universit\u00e9 catholique de Louvain"], ["Schaus", "Pierre", "", "Universit\u00e9 catholique de Louvain"]]}, {"id": "1506.03555", "submitter": "EPTCS", "authors": "Sentot Kromodimoeljo (University of Queensland), Peter A. Lindsay\n  (University of Queensland)", "title": "Automatic Generation of Minimal Cut Sets", "comments": "In Proceedings ESSS 2015, arXiv:1506.03250", "journal-ref": "EPTCS 184, 2015, pp. 33-47", "doi": "10.4204/EPTCS.184.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cut set is a collection of component failure modes that could lead to a\nsystem failure. Cut Set Analysis (CSA) is applied to critical systems to\nidentify and rank system vulnerabilities at design time. Model checking tools\nhave been used to automate the generation of minimal cut sets but are generally\nbased on checking reachability of system failure states. This paper describes a\nnew approach to CSA using a Linear Temporal Logic (LTL) model checker called BT\nAnalyser that supports the generation of multiple counterexamples. The approach\nenables a broader class of system failures to be analysed, by generalising from\nfailure state formulae to failure behaviours expressed in LTL. The traditional\napproach to CSA using model checking requires the model or system failure to be\nmodified, usually by hand, to eliminate already-discovered cut sets, and the\nmodel checker to be rerun, at each step. By contrast, the new approach works\nincrementally and fully automatically, thereby removing the tedious and\nerror-prone manual process and resulting in significantly reduced computation\ntime. This in turn enables larger models to be checked. Two different\nstrategies for using BT Analyser for CSA are presented. There is generally no\nsingle best strategy for model checking: their relative efficiency depends on\nthe model and property being analysed. Comparative results are given for the\nA320 hydraulics case study in the Behavior Tree modelling language.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 06:10:51 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Kromodimoeljo", "Sentot", "", "University of Queensland"], ["Lindsay", "Peter A.", "", "University of Queensland"]]}, {"id": "1506.03556", "submitter": "EPTCS", "authors": "Eike M\\\"ohlmann (Carl von Ossietzky University of Oldenburg), Oliver\n  Theel (Carl von Ossietzky University of Oldenburg)", "title": "Breaking Dense Structures: Proving Stability of Densely Structured\n  Hybrid Systems", "comments": "In Proceedings ESSS 2015, arXiv:1506.03250", "journal-ref": "EPTCS 184, 2015, pp. 49-63", "doi": "10.4204/EPTCS.184.4", "report-no": null, "categories": "cs.SE cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction and refinement is widely used in software development. Such\ntechniques are valuable since they allow to handle even more complex systems.\nOne key point is the ability to decompose a large system into subsystems,\nanalyze those subsystems and deduce properties of the larger system. As\ncyber-physical systems tend to become more and more complex, such techniques\nbecome more appealing.\n  In 2009, Oehlerking and Theel presented a (de-)composition technique for\nhybrid systems. This technique is graph-based and constructs a Lyapunov\nfunction for hybrid systems having a complex discrete state space. The\ntechnique consists of (1) decomposing the underlying graph of the hybrid system\ninto subgraphs, (2) computing multiple local Lyapunov functions for the\nsubgraphs, and finally (3) composing the local Lyapunov functions into a\npiecewise Lyapunov function. A Lyapunov function can serve multiple purposes,\ne.g., it certifies stability or termination of a system or allows to construct\ninvariant sets, which in turn may be used to certify safety and security.\n  In this paper, we propose an improvement to the decomposing technique, which\nrelaxes the graph structure before applying the decomposition technique. Our\nrelaxation significantly reduces the connectivity of the graph by exploiting\nsuper-dense switching. The relaxation makes the decomposition technique more\nefficient on one hand and on the other allows to decompose a wider range of\ngraph structures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 06:11:10 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["M\u00f6hlmann", "Eike", "", "Carl von Ossietzky University of Oldenburg"], ["Theel", "Oliver", "", "Carl von Ossietzky University of Oldenburg"]]}, {"id": "1506.03557", "submitter": "EPTCS", "authors": "Linna Pang (McMaster University), Chen-Wei Wang (McMaster University),\n  Mark Lawford (McMaster University), Alan Wassyng (McMaster University), Josh\n  Newell (Systemware Innovation Corporation), Vera Chow (Systemware Innovation\n  Corporation), David Tremaine (Systemware Innovation Corporation)", "title": "Formal Verification of Real-Time Function Blocks Using PVS", "comments": "In Proceedings ESSS 2015, arXiv:1506.03250", "journal-ref": "EPTCS 184, 2015, pp. 65-79", "doi": "10.4204/EPTCS.184.5", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical step towards certifying safety-critical systems is to check their\nconformance to hard real-time requirements. A promising way to achieve this is\nby building the systems from pre-verified components and verifying their\ncorrectness in a compositional manner. We previously reported a formal approach\nto verifying function blocks (FBs) using tabular expressions and the PVS proof\nassistant. By applying our approach to the IEC 61131-3 standard of Programmable\nLogic Controllers (PLCs), we constructed a repository of precise specification\nand reusable (proven) theorems of feasibility and correctness for FBs. However,\nwe previously did not apply our approach to verify FBs against timing\nrequirements, since IEC 61131-3 does not define composite FBs built from\ntimers. In this paper, based on our experience in the nuclear domain, we\nconduct two realistic case studies, consisting of the software requirements and\nthe proposed FB implementations for two subsystems of an industrial control\nsystem. The implementations are built from IEC 61131-3 FBs, including the\non-delay timer. We find issues during the verification process and suggest\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 06:11:18 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Pang", "Linna", "", "McMaster University"], ["Wang", "Chen-Wei", "", "McMaster University"], ["Lawford", "Mark", "", "McMaster University"], ["Wassyng", "Alan", "", "McMaster University"], ["Newell", "Josh", "", "Systemware Innovation Corporation"], ["Chow", "Vera", "", "Systemware Innovation\n  Corporation"], ["Tremaine", "David", "", "Systemware Innovation Corporation"]]}, {"id": "1506.03558", "submitter": "EPTCS", "authors": "Chen-Wei Wang (York University), Jonathan S. Ostroff (York\n  University), Simon Hudon (York University)", "title": "Using Indexed and Synchronous Events to Model and Validate\n  Cyber-Physical Systems", "comments": "In Proceedings ESSS 2015, arXiv:1506.03250", "journal-ref": "EPTCS 184, 2015, pp. 81-95", "doi": "10.4204/EPTCS.184.6", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timed Transition Models (TTMs) are event-based descriptions for modelling,\nspecifying, and verifying discrete real-time systems. An event can be\nspontaneous, fair, or timed with specified bounds. TTMs have a textual syntax,\nan operational semantics, and an automated tool supporting linear-time temporal\nlogic. We extend TTMs and its tool with two novel modelling features for\nwriting high-level specifications: indexed events and synchronous events.\nIndexed events allow for concise description of behaviour common to a set of\nactors. The indexing construct allows us to select a specific actor and to\nspecify a temporal property for that actor. We use indexed events to validate\nthe requirements of a train control system. Synchronous events allow developers\nto decompose simultaneous state updates into actions of separate events. To\nspecify the intended data flow among synchronized actions, we use primed\nvariables to reference the post-state (i.e., one resulted from taking the\nsynchronized actions). The TTM tool automatically infers the data flow from\nsynchronous events, and reports errors on inconsistencies due to circular data\nflow. We use synchronous events to validate part of the requirements of a\nnuclear shutdown system. In both case studies, we show how the new notation\nfacilitates the formal validation of system requirements, and use the TTM tool\nto verify safety, liveness, and real-time properties.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 06:16:40 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Wang", "Chen-Wei", "", "York University"], ["Ostroff", "Jonathan S.", "", "York\n  University"], ["Hudon", "Simon", "", "York University"]]}, {"id": "1506.03710", "submitter": "Ugo Dal Lago", "authors": "Alberto Cappai, Ugo Dal Lago", "title": "On Equivalences, Metrics, and Polynomial Time (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive behaviors are ubiquitous in modern cryptography, but are also\npresent in $\\lambda$-calculi, in the form of higher-order constructions.\nTraditionally, however, typed $\\lambda$-calculi simply do not fit well into\ncryptography, being both deterministic and too powerful as for the complexity\nof functions they can express. We study interaction in a $\\lambda$-calculus for\nprobabilistic polynomial time computable functions. In particular, we show how\nnotions of context equivalence and context metric can both be characterized by\nway of traces when defined on linear contexts. We then give evidence on how\nthis can be turned into a proof methodology for computational\nindistinguishability, a key notion in modern cryptography. We also hint at what\nhappens if a more general notion of a context is used.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 15:32:04 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Cappai", "Alberto", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "1506.03930", "submitter": "Michal Krupka", "authors": "Jan Konecny and Michal Krupka", "title": "Complete relations on fuzzy complete lattices", "comments": "Preprint submitted to Fuzzy Sets and Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the notion of complete binary relation on complete lattice to\nresiduated lattice valued ordered sets and show its properties. Then we focus\non complete fuzzy tolerances on fuzzy complete lattices and prove they are in\none-to-one correspondence with extensive isotone Galois connections. Finally,\nwe prove that fuzzy complete lattice, factorized by a complete fuzzy tolerance,\nis again a fuzzy complete lattice.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 08:21:33 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Konecny", "Jan", ""], ["Krupka", "Michal", ""]]}, {"id": "1506.03943", "submitter": "Fr", "authors": "Fr\\'ed\\'eric Blanqui (INRIA), Jean-Pierre Jouannaud (Ecole\n  Polytechnique, Universit\\'e Paris-Sud, Tsinghua University), Albert Rubio\n  (Technical University of Catalonia)", "title": "The computability path ordering", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (October\n  26, 2015) lmcs:1604", "doi": "10.2168/LMCS-11(4:3)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at carrying out termination proofs for simply typed\nhigher-order calculi automatically by using ordering comparisons. To this end,\nwe introduce the computability path ordering (CPO), a recursive relation on\nterms obtained by lifting a precedence on function symbols. A first version,\ncore CPO, is essentially obtained from the higher-order recursive path ordering\n(HORPO) by eliminating type checks from some recursive calls and by\nincorporating the treatment of bound variables as in the com-putability\nclosure. The well-foundedness proof shows that core CPO captures the essence of\ncomputability arguments \\'a la Tait and Girard, therefore explaining its name.\nWe further show that no further type check can be eliminated from its recursive\ncalls without loosing well-foundedness, but for one for which we found no\ncounterexample yet. Two extensions of core CPO are then introduced which allow\none to consider: the first, higher-order inductive types; the second, a\nprecedence in which some function symbols are smaller than application and\nabstraction.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 09:04:56 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2015 00:14:23 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "INRIA"], ["Jouannaud", "Jean-Pierre", "", "Ecole\n  Polytechnique, Universit\u00e9 Paris-Sud, Tsinghua University"], ["Rubio", "Albert", "", "Technical University of Catalonia"]]}, {"id": "1506.04161", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG), Francesco Alberti", "title": "A simple abstraction of arrays and maps by program translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for the static analysis of programs handling arrays,\nwith a Galois connection between the semantics of the array program and\nsemantics of purely scalar operations. The simplest way to implement it is by\nautomatic, syntactic transformation of the array program into a scalar program\nfollowed analysis of the scalar program with any static analysis technique\n(abstract interpretation, acceleration, predicate abstraction,.. .). The\nscalars invariants thus obtained are translated back onto the original program\nas universally quantified array invariants. We illustrate our approach on a\nvariety of examples, leading to the \" Dutch flag \" algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 20:12:57 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"], ["Alberti", "Francesco", ""]]}, {"id": "1506.04349", "submitter": "Santiago Hern\\'andez Orozco", "authors": "Santiago Hern\\'andez-Orozco, Francisco Hern\\'andez-Quiroz, Hector\n  Zenil and Wilfried Sieg", "title": "Rare Speed-up in Automatic Theorem Proving Reveals Tradeoff Between\n  Computational Time and Information Value", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that strategies implemented in automatic theorem proving involve an\ninteresting tradeoff between execution speed, proving speedup/computational\ntime and usefulness of information. We advance formal definitions for these\nconcepts by way of a notion of normality related to an expected (optimal)\ntheoretical speedup when adding useful information (other theorems as axioms),\nas compared with actual strategies that can be effectively and efficiently\nimplemented. We propose the existence of an ineluctable tradeoff between this\nnormality and computational time complexity. The argument quantifies the\nusefulness of information in terms of (positive) speed-up. The results disclose\na kind of no-free-lunch scenario and a tradeoff of a fundamental nature. The\nmain theorem in this paper together with the numerical experiment---undertaken\nusing two different automatic theorem provers AProS and Prover9 on random\ntheorems of propositional logic---provide strong theoretical and empirical\narguments for the fact that finding new useful information for solving a\nspecific problem (theorem) is, in general, as hard as the problem (theorem)\nitself.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 04:17:45 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Hern\u00e1ndez-Orozco", "Santiago", ""], ["Hern\u00e1ndez-Quiroz", "Francisco", ""], ["Zenil", "Hector", ""], ["Sieg", "Wilfried", ""]]}, {"id": "1506.04863", "submitter": "Grant Passmore", "authors": "Grant Olney Passmore", "title": "Decidability of Univariate Real Algebra with Predicates for Rational and\n  Integer Powers", "comments": "To appear in CADE-25: 25th International Conference on Automated\n  Deduction, 2015. Proceedings to be published by Springer-Verlag", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove decidability of univariate real algebra extended with predicates for\nrational and integer powers, i.e., $(x^n \\in \\mathbb{Q})$ and $(x^n \\in\n\\mathbb{Z})$. Our decision procedure combines computation over real algebraic\ncells with the rational root theorem and witness construction via algebraic\nnumber density arguments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 07:31:24 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Passmore", "Grant Olney", ""]]}, {"id": "1506.04871", "submitter": "Marco Gario", "authors": "Marco Bozzano (Fondazione Bruno Kessler), Alessandro Cimatti\n  (Fondazione Bruno Kessler), Marco Gario (Fondazione Bruno Kessler), Stefano\n  Tonetta (Fondazione Bruno Kessler)", "title": "Formal Design of Asynchronous Fault Detection and Identification\n  Components using Temporal Epistemic Logic", "comments": "33 pages, 20 figures", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (November\n  4, 2015) lmcs:1605", "doi": "10.2168/LMCS-11(4:4)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous critical systems, such as satellites and space rovers, must be\nable to detect the occurrence of faults in order to ensure correct operation.\nThis task is carried out by Fault Detection and Identification (FDI)\ncomponents, that are embedded in those systems and are in charge of detecting\nfaults in an automated and timely manner by reading data from sensors and\ntriggering predefined alarms. The design of effective FDI components is an\nextremely hard problem, also due to the lack of a complete theoretical\nfoundation, and of precise specification and validation techniques. In this\npaper, we present the first formal approach to the design of FDI components for\ndiscrete event systems, both in a synchronous and asynchronous setting. We\npropose a logical language for the specification of FDI requirements that\naccounts for a wide class of practical cases, and includes novel aspects such\nas maximality and trace-diagnosability. The language is equipped with a clear\nsemantics based on temporal epistemic logic, and is proved to enjoy suitable\nproperties. We discuss how to validate the requirements and how to verify that\na given FDI component satisfies them. We propose an algorithm for the synthesis\nof correct-by-construction FDI components, and report on the applicability of\nthe design approach on an industrial case-study coming from aerospace.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 08:26:01 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 08:51:13 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2016 13:32:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bozzano", "Marco", "", "Fondazione Bruno Kessler"], ["Cimatti", "Alessandro", "", "Fondazione Bruno Kessler"], ["Gario", "Marco", "", "Fondazione Bruno Kessler"], ["Tonetta", "Stefano", "", "Fondazione Bruno Kessler"]]}, {"id": "1506.04879", "submitter": "Lacramioara Astefanoaei", "authors": "Lacramioara Astefanoaei (UJF, Verimag), Souha Ben Rayana (UJF,\n  Verimag), Saddek Bensalem (UJF, Verimag), Marius Bozga (CNRS, Verimag),\n  Jacques Combaz (CNRS, Verimag)", "title": "Compositional Verification for Timed Systems Based on Automatic\n  Invariant Generation", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  17, 2015) lmcs:1591", "doi": "10.2168/LMCS-11(3:15)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for compositional verification to address the state space\nexplosion problem inherent to model-checking timed systems with a large number\nof components. The main challenge is to obtain pertinent global timing\nconstraints from the timings in the components alone. To this end, we make use\nof auxiliary clocks to automatically generate new invariants which capture the\nconstraints induced by the synchronisations between components. The method has\nbeen implemented in the RTD-Finder tool and successfully experimented on\nseveral benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 08:48:25 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 19:59:26 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Astefanoaei", "Lacramioara", "", "UJF, Verimag"], ["Rayana", "Souha Ben", "", "UJF,\n  Verimag"], ["Bensalem", "Saddek", "", "UJF, Verimag"], ["Bozga", "Marius", "", "CNRS, Verimag"], ["Combaz", "Jacques", "", "CNRS, Verimag"]]}, {"id": "1506.04929", "submitter": "Mehul Bhatt", "authors": "Przemys{\\l}aw Andrzej Wa{\\l}\\k{e}ga and Mehul Bhatt and Carl Schultz", "title": "ASPMT(QS): Non-Monotonic Spatial Reasoning with Answer Set Programming\n  Modulo Theories", "comments": "pages 13. accepted for publication at: LPNMR 2015 - Logic Programming\n  and Nonmonotonic Reasoning, 13th International Conference, LPNMR 2015, LNAI\n  Vol. 9345., Lexington, September 27-30, 2015. Proceedings., (editors:\n  Francesco Calimeri, Giovambattista Ianni, Miroslaw Truszczynski)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The systematic modelling of \\emph{dynamic spatial systems} [9] is a key\nrequirement in a wide range of application areas such as comonsense cognitive\nrobotics, computer-aided architecture design, dynamic geographic information\nsystems. We present ASPMT(QS), a novel approach and fully-implemented prototype\nfor non-monotonic spatial reasoning ---a crucial requirement within dynamic\nspatial systems-- based on Answer Set Programming Modulo Theories (ASPMT).\nASPMT(QS) consists of a (qualitative) spatial representation module (QS) and a\nmethod for turning tight ASPMT instances into Sat Modulo Theories (SMT)\ninstances in order to compute stable models by means of SMT solvers. We\nformalise and implement concepts of default spatial reasoning and spatial frame\naxioms using choice formulas. Spatial reasoning is performed by encoding\nspatial relations as systems of polynomial constraints, and solving via SMT\nwith the theory of real nonlinear arithmetic. We empirically evaluate ASPMT(QS)\nin comparison with other prominent contemporary spatial reasoning systems. Our\nresults show that ASPMT(QS) is the only existing system that is capable of\nreasoning about indirect spatial effects (i.e. addressing the ramification\nproblem), and integrating geometric and qualitative spatial information within\na non-monotonic spatial reasoning context.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 11:52:50 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Wa\u0142\u0119ga", "Przemys\u0142aw Andrzej", ""], ["Bhatt", "Mehul", ""], ["Schultz", "Carl", ""]]}, {"id": "1506.04945", "submitter": "Mehul Bhatt", "authors": "Carl Schultz and Mehul Bhatt", "title": "Spatial Symmetry Driven Pruning Strategies for Efficient Declarative\n  Spatial Reasoning", "comments": "22 pages. Accepted for publication at: COSIT 2015 - Conference on\n  Spatial Information Theory XII (COSIT), Santa Fe, New Mexico, USA ,October\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Declarative spatial reasoning denotes the ability to (declaratively) specify\nand solve real-world problems related to geometric and qualitative spatial\nrepresentation and reasoning within standard knowledge representation and\nreasoning (KR) based methods (e.g., logic programming and derivatives). One\napproach for encoding the semantics of spatial relations within a declarative\nprogramming framework is by systems of polynomial constraints. However, solving\nsuch constraints is computationally intractable in general (i.e. the theory of\nreal-closed fields).\n  We present a new algorithm, implemented within the declarative spatial\nreasoning system CLP(QS), that drastically improves the performance of deciding\nthe consistency of spatial constraint graphs over conventional polynomial\nencodings. We develop pruning strategies founded on spatial symmetries that\nform equivalence classes (based on affine transformations) at the qualitative\nspatial level. Moreover, pruning strategies are themselves formalised as\nknowledge about the properties of space and spatial symmetries. We evaluate our\nalgorithm using a range of benchmarks in the class of contact problems, and\nproofs in mereology and geometry. The empirical results show that CLP(QS) with\nknowledge-based spatial pruning outperforms conventional polynomial encodings\nby orders of magnitude, and can thus be applied to problems that are otherwise\nunsolvable in practice.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 12:40:30 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Schultz", "Carl", ""], ["Bhatt", "Mehul", ""]]}, {"id": "1506.04998", "submitter": "Fedor Part", "authors": "Fedor Part, Zhaohui Luo", "title": "Semi-simplicial Types in Logic-enriched Homotopy Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of defining Semi-Simplicial Types (SSTs) in Homotopy Type Theory\n(HoTT) has been recognized as important during the Year of Univalent\nFoundations at the Institute of Advanced Study. According to the interpretation\nof HoTT in Quillen model categories, SSTs are type-theoretic versions of Reedy\nfibrant semi-simplicial objects in a model category and simplicial and\nsemi-simplicial objects play a crucial role in many constructions in homotopy\ntheory and higher category theory. Attempts to define SSTs in HoTT lead to some\ndifficulties such as the need of infinitary assumptions which are beyond HoTT\nwith only non-strict equality types.\n  Voevodsky proposed a definition of SSTs in Homotopy Type System (HTS), an\nextension of HoTT with non-fibrant types, including an extensional strict\nequality type. However, HTS does not have the desirable computational\nproperties such as decidability of type checking and strong normalization. In\nthis paper, we study a logic-enriched homotopy type theory, an alternative\nextension of HoTT with equational logic based on the idea of logic-enriched\ntype theories. In contrast to Voevodskys HTS, all types in our system are\nfibrant and it can be implemented in existing proof assistants. We show how\nSSTs can be defined in our system and outline an implementation in the proof\nassistant Plastic.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 15:13:09 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Part", "Fedor", ""], ["Luo", "Zhaohui", ""]]}, {"id": "1506.05025", "submitter": "EPTCS", "authors": "Stefano Gogioso (Quantum Group, University of Oxford)", "title": "A Bestiary of Sets and Relations", "comments": "In Proceedings QPL 2015, arXiv:1511.01181", "journal-ref": "EPTCS 195, 2015, pp. 208-227", "doi": "10.4204/EPTCS.195.16", "report-no": null, "categories": "quant-ph cs.LO math.CT math.QA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on established literature and recent developments in the\ngraph-theoretic characterisation of its CPM category, we provide a treatment of\npure state and mixed state quantum mechanics in the category fRel of finite\nsets and relations. On the way, we highlight the wealth of exotic beasts that\nhide amongst the extensive operational and structural similarities that the\ntheory shares with more traditional arenas of categorical quantum mechanics,\nsuch as the category fdHilb. We conclude our journey by proving that fRel is\nlocal, but not without some unexpected twists.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 16:24:31 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 01:43:41 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Gogioso", "Stefano", "", "Quantum Group, University of Oxford"]]}, {"id": "1506.05028", "submitter": "EPTCS", "authors": "Chris Heunen (University of Oxford), Sean Tull (University of Oxford)", "title": "Categories of relations as models of quantum theory", "comments": "In Proceedings QPL 2015, arXiv:1511.01181", "journal-ref": "EPTCS 195, 2015, pp. 247-261", "doi": "10.4204/EPTCS.195.18", "report-no": null, "categories": "math.CT cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categories of relations over a regular category form a family of models of\nquantum theory. Using regular logic, many properties of relations over sets\nlift to these models, including the correspondence between Frobenius structures\nand internal groupoids. Over compact Hausdorff spaces, this lifting gives\ncontinuous symmetric encryption. Over a regular Mal'cev category, this\ncorrespondence gives a characterization of categories of completely positive\nmaps, enabling the formulation of quantum features. These models are closer to\nHilbert spaces than relations over sets in several respects: Heisenberg\nuncertainty, impossibility of broadcasting, and behavedness of rank one\nmorphisms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 16:40:01 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 01:44:06 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Heunen", "Chris", "", "University of Oxford"], ["Tull", "Sean", "", "University of Oxford"]]}, {"id": "1506.05043", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Ugo Dal Lago and Georg Moser", "title": "Analysing the Complexity of Functional Programs: Higher-Order Meets\n  First-Order (Long Version)", "comments": "Long version of paper presented at ICFP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We show how the complexity of higher-order functional programs can be\nanalysed automatically by applying program transformations to a\ndefunctionalized versions of them, and feeding the result to existing tools for\nthe complexity analysis of first-order term rewrite systems. This is done while\ncarefully analysing complexity preservation and reflection of the employed\ntransformations such that the complexity of the obtained term rewrite system\nreflects on the complexity of the initial program. Further, we describe\nsuitable strategies for the application of the studied transformations and\nprovide ample experimental data for assessing the viability of our method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 17:37:31 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Avanzini", "Martin", ""], ["Lago", "Ugo Dal", ""], ["Moser", "Georg", ""]]}, {"id": "1506.05127", "submitter": "Eike Neumann", "authors": "Eike Neumann (Technische Universit\\\"at Darmstadt)", "title": "Computational Problems in Metric Fixed Point Theory and their Weihrauch\n  Degrees", "comments": "44 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  29, 2015) lmcs:1621", "doi": "10.2168/LMCS-11(4:20)2015", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational difficulty of the problem of finding fixed points\nof nonexpansive mappings in uniformly convex Banach spaces. We show that the\nfixed point sets of computable nonexpansive self-maps of a nonempty, computably\nweakly closed, convex and bounded subset of a computable real Hilbert space are\nprecisely the nonempty, co-r.e. weakly closed, convex subsets of the domain. A\nuniform version of this result allows us to determine the Weihrauch degree of\nthe Browder-Goehde-Kirk theorem in computable real Hilbert space: it is\nequivalent to a closed choice principle, which receives as input a closed,\nconvex and bounded set via negative information in the weak topology and\noutputs a point in the set, represented in the strong topology. While in finite\ndimensional uniformly convex Banach spaces, computable nonexpansive mappings\nalways have computable fixed points, on the unit ball in infinite-dimensional\nseparable Hilbert space the Browder-Goehde-Kirk theorem becomes\nWeihrauch-equivalent to the limit operator, and on the Hilbert cube it is\nequivalent to Weak Koenig's Lemma. In particular, computable nonexpansive\nmappings may not have any computable fixed points in infinite dimension. We\nalso study the computational difficulty of the problem of finding rates of\nconvergence for a large class of fixed point iterations, which generalise both\nHalpern- and Mann-iterations, and prove that the problem of finding rates of\nconvergence already on the unit interval is equivalent to the limit operator.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 20:05:00 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2015 04:28:44 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Neumann", "Eike", "", "Technische Universit\u00e4t Darmstadt"]]}, {"id": "1506.05282", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern", "title": "Why Bother With Syntax?", "comments": "To appear in \"Rohit Parikh on Logic, Language and Society\" (C.\n  Baskent, L. Moss, and R. Ramanjum, editors)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note discusses the role of syntax vs. semantics and the interplay\nbetween logic, philosophy, and language in computer science and game theory.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 11:27:12 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Halpern", "Joseph Y.", ""]]}, {"id": "1506.05312", "submitter": "Jaros{\\l}aw Waliszko", "authors": "Jaros{\\l}aw Waliszko", "title": "Knowledge representation and processing methods in Semantic Web", "comments": "Master's thesis at AGH UST, Krakow 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal is to take a closer look at progress of knowledge engineering in the\nfield of Semantic Web. Along with theory of Knowledge Representation (KR) and\nknowledge processing methods such as Description Logic (DL), reasoning\nmechanisms and ontology modelling languages (OWL, RDF, RDFS), the thesis shows\nthe practical usage of the mentioned approaches in building systems driven by\nontologies. A working prototype of ontology-driven application, written in\nJava, has been developed within the scope of this thesis. The system main\nassumption is an attempt to integrate database and ontology approach, for\nstoring and inferring desired information about domain of traffic dangers. For\nthe needs of the system, domain model of traffic danger concept has been also\ndesigned.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 13:06:25 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Waliszko", "Jaros\u0142aw", ""]]}, {"id": "1506.05561", "submitter": "Richard Moot", "authors": "Richard Moot (LaBRI)", "title": "Comparing and evaluating extended Lambek calculi", "comments": "Empirical advances in categorial grammars, Aug 2015, Barcelona,\n  Spain. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lambeks Syntactic Calculus, commonly referred to as the Lambek calculus, was\ninnovative in many ways, notably as a precursor of linear logic. But it also\nshowed that we could treat our grammatical framework as a logic (as opposed to\na logical theory). However, though it was successful in giving at least a basic\ntreatment of many linguistic phenomena, it was also clear that a slightly more\nexpressive logical calculus was needed for many other cases. Therefore, many\nextensions and variants of the Lambek calculus have been proposed, since the\neighties and up until the present day. As a result, there is now a large class\nof calculi, each with its own empirical successes and theoretical results, but\nalso each with its own logical primitives. This raises the question: how do we\ncompare and evaluate these different logical formalisms? To answer this\nquestion, I present two unifying frameworks for these extended Lambek calculi.\nBoth are proof net calculi with graph contraction criteria. The first calculus\nis a very general system: you specify the structure of your sequents and it\ngives you the connectives and contractions which correspond to it. The calculus\ncan be extended with structural rules, which translate directly into graph\nrewrite rules. The second calculus is first-order (multiplicative\nintuitionistic) linear logic, which turns out to have several other,\nindependently proposed extensions of the Lambek calculus as fragments. I will\nillustrate the use of each calculus in building bridges between analyses\nproposed in different frameworks, in highlighting differences and in helping to\nidentify problems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 07:10:26 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Moot", "Richard", "", "LaBRI"]]}, {"id": "1506.05605", "submitter": "Enrico Tassi", "authors": "Bruno Barras, Carst Tankink (SPECFUN), Enrico Tassi (MARELLE)", "title": "Asynchronous processing of Coq documents: from the kernel up to the user\n  interface", "comments": "in Proceedings of ITP, Aug 2015, Nanjing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work described in this paper improves the reactivity of the Coq system by\ncompletely redesigning the way it processes a formal document. By subdividing\nsuch work into independent tasks the system can give precedence to the ones of\nimmediate interest for the user and postpones the others. On the user side, a\nmodern interface based on the PIDE middleware aggregates and present in a\nconsistent way the output of the prover. Finally postponed tasks are processed\nexploiting modern, parallel, hardware to offer better scalability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 09:47:41 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Barras", "Bruno", "", "SPECFUN"], ["Tankink", "Carst", "", "SPECFUN"], ["Tassi", "Enrico", "", "MARELLE"]]}, {"id": "1506.05671", "submitter": "Peter Schrammel", "authors": "Martin Brain, Saurabh Joshi, Daniel Kroening, Peter Schrammel", "title": "Safety Verification and Refutation by k-invariants and k-induction\n  (extended version)", "comments": "extended version of paper published at SAS'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most software verification tools can be classified into one of a number of\nestablished families, each of which has their own focus and strengths. For\nexample, concrete counterexample generation in model checking, invariant\ninference in abstract interpretation and completeness via annotation for\ndeductive verification. This creates a significant and fundamental usability\nproblem as users may have to learn and use one technique to find potential\nproblems but then need an entirely different one to show that they have been\nfixed. This paper presents a single, unified algorithm kIkI, which strictly\ngeneralises abstract interpretation, bounded model checking and k-induction.\nThis not only combines the strengths of these techniques but allows them to\ninteract and reinforce each other, giving a `single-tool' approach to\nverification.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 13:30:45 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 13:32:17 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Brain", "Martin", ""], ["Joshi", "Saurabh", ""], ["Kroening", "Daniel", ""], ["Schrammel", "Peter", ""]]}, {"id": "1506.05728", "submitter": "Maximilien Colange", "authors": "Maximilien Colange and Dimitri Racordon and Didier Buchs", "title": "A CEGAR-like Approach for Cost LTL Bounds", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative formal verification, that seeks boolean answers about the\nbehavior of a system, is often insufficient for practical purposes. Observing\nquantitative information is of interest, e.g. for the proper calibration of a\nbattery or a real-time scheduler. Historically, the focus has been on\nquantities in a continuous domain, but recent years showed a renewed interest\nfor discrete quantitative domains.\n  Cost Linear Temporal Logic (CLTL) is a quantitative extension of classical\nLTL. It integrates into a nice theory developed in the past few years that\nextends the qualitative setting, with counterparts in terms of logics, automata\nand algebraic structure. We propose a practical usage of this logics for\nmodel-checking purposes. A CLTL formula defines a function from infinite words\nto integers. Finding the bounds of such a function over a given set of words\ncan be seen as an extension of LTL universal and existential model-checking. We\npropose a CEGAR-like algorithm to find these bounds by relying on classical LTL\nmodel-checking, and use B\\\"{u}chi automata with counters to implement it. This\nmethod constitutes a first step towards the practical use of such a discrete\nquantitative logic.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 15:52:06 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Colange", "Maximilien", ""], ["Racordon", "Dimitri", ""], ["Buchs", "Didier", ""]]}, {"id": "1506.05887", "submitter": "Jean-Paul Comet", "authors": "Gilles Bernot and Jean-Paul Comet and Zohra Khalis and Adrien Richard\n  and Olivier Roux", "title": "A Genetically Modified Hoare Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem when modeling gene networks lies in the identification\nof parameters, even if we consider a purely discrete framework as the one of\nRen\\'e Thomas. Here we are interested in the exhaustive search of all parameter\nvalues that are consistent with observed behaviors of the gene network. We\npresent in this article a new approach based on Hoare Logic and on a weakest\nprecondition calculus to generate constraints on possible parameter values.\nObserved behaviors play the role of \"programs\" for the classical Hoare logic,\nand computed weakest preconditions represent the sets of all compatible\nparameterizations expressed as constraints on parameters. Finally we give a\nproof of correctness of our Hoare logic for gene networks as well as a proof of\ncompleteness based on the computation of the weakest precondition.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 06:37:46 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Bernot", "Gilles", ""], ["Comet", "Jean-Paul", ""], ["Khalis", "Zohra", ""], ["Richard", "Adrien", ""], ["Roux", "Olivier", ""]]}, {"id": "1506.06024", "submitter": "Vitaly Perevoshchikov", "authors": "Manfred Droste and Vitaly Perevoshchikov", "title": "Multi-weighted Automata and MSO Logic", "comments": "The final version appeared in the Proceedings of the 8th\n  International Computer Science Symposium in Russia (CSR 2013)", "journal-ref": null, "doi": "10.1007/978-3-642-38536-0_36", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted automata are non-deterministic automata where the transitions are\nequipped with weights. They can model quantitative aspects of systems like\ncosts or energy consumption. The value of a run can be computed, for example,\nas the maximum, limit average, or discounted sum of transition weights. In\nmulti-weighted automata, transitions carry several weights and can model, for\nexample, the ratio between rewards and costs, or the efficiency of use of a\nprimary resource under some upper bound constraint on a secondary resource.\nHere, we introduce a general model for multi-weighted automata as well as a\nmultiweighted MSO logic. In our main results, we show that this multi-weighted\nMSO logic and multi-weighted automata are expressively equivalent both for\nfinite and infinite words. The translation process is effective, leading to\ndecidability results for our multi-weighted MSO logic.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 14:39:15 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Droste", "Manfred", ""], ["Perevoshchikov", "Vitaly", ""]]}, {"id": "1506.06057", "submitter": "Plotkin Boris", "authors": "Elena Aladova, Aleko Gvaramia, Boris Plotkin, Tatjana Plotkin", "title": "Multi-sorted logic, models and logical geometry", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Theta$ be a variety of algebras, $(H, \\Psi, f)$ be a model, where $H$\nis an algebra from $\\Theta$, $\\Psi$ is a set of relation symbols $\\varphi$, $f$\nis an interpretation of all $\\varphi$ in $H$. Let $X^0$ be an infinite set of\nvariables, $\\Gamma$ be a collection of all finite subsets in $X^0$ (collection\nof sorts), $\\widetilde\\Phi$ be the multi-sorted algebra of formulas. These data\ndefine a knowledge base $KB(H,\\Psi, f)$. In the paper the notion of isomorphism\nof knowledge bases is considered. We give sufficient conditions which provide\nisomorphism of knowledge bases. We also study the problem of necessary and\nsufficient conditions for isomorphism of two knowledge bases.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 19:47:45 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Aladova", "Elena", ""], ["Gvaramia", "Aleko", ""], ["Plotkin", "Boris", ""], ["Plotkin", "Tatjana", ""]]}, {"id": "1506.06165", "submitter": "Panagiotis Katsaros", "authors": "George Chatzieleftheriou (Aristotle University of Thessaloniki,\n  Greece), Borzoo Bonakdarpour (University of Waterloo, Canada), Panagiotis\n  Katsaros (Aristotle University of Thessaloniki, Greece), Scott A. Smolka\n  (Stony Brook University, NY, USA)", "title": "Abstract Model Repair", "comments": "43 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  17, 2015) lmcs:1587", "doi": "10.2168/LMCS-11(3:11)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Kripke structure M and CTL formula $\\varphi$, where M does not\nsatisfy $\\varphi$, the problem of Model Repair is to obtain a new model M' such\nthat M' satisfies $\\varphi$. Moreover, the changes made to M to derive M'\nshould be minimum with respect to all such M'. As in model checking, state\nexplosion can make it virtually impossible to carry out model repair on models\nwith infinite or even large state spaces. In this paper, we present a framework\nfor model repair that uses abstraction refinement to tackle state explosion.\nOur framework aims to repair Kripke Structure models based on a Kripke Modal\nTransition System abstraction and a 3-valued semantics for CTL. We introduce an\nabstract-model-repair algorithm for which we prove soundness and\nsemi-completeness, and we study its complexity class. Moreover, a prototype\nimplementation is presented to illustrate the practical utility of\nabstract-model-repair on an Automatic Door Opener system model and a model of\nthe Andrew File System 1 protocol.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 21:44:05 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 17:10:49 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Chatzieleftheriou", "George", "", "Aristotle University of Thessaloniki,\n  Greece"], ["Bonakdarpour", "Borzoo", "", "University of Waterloo, Canada"], ["Katsaros", "Panagiotis", "", "Aristotle University of Thessaloniki, Greece"], ["Smolka", "Scott A.", "", "Stony Brook University, NY, USA"]]}, {"id": "1506.06166", "submitter": "Ekaterina Komendantskaya Dr", "authors": "Peng Fu, Ekaterina Komendantskaya", "title": "A Type-Theoretic Approach to Structural Resolution", "comments": "LOPSTR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural resolution (or S-resolution) is a newly proposed alternative to\nSLD-resolution that allows a systematic separation of derivations into\nterm-matching and unification steps. Productive logic programs are those for\nwhich term-matching reduction on any query must terminate. For productive\nprograms with coinductive meaning, finite term-rewriting reductions can be seen\nas measures of observation in an infinite derivation. Ability of handling\ncorecursion in a productive way is an attractive computational feature of\nS-resolution.\n  In this paper, we make first steps towards a better conceptual understanding\nof operational properties of S-resolution as compared to SLD-resolution. To\nthis aim, we propose a type system for the analysis of both SLD-resolution and\nS-resolution.\n  We formulate S-resolution and SLD-resolution as reduction systems, and show\ntheir soundness relative to the type system. One of the central methods of this\npaper is realizability transformation, which makes logic programs productive\nand non-overlapping. We show that S-resolution and SLD-resolution are only\nequivalent for programs with these two properties.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 21:52:13 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Fu", "Peng", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1506.06299", "submitter": "Alexander Andreychenko", "authors": "Alexander Andreychenko and Morgan Magnin and Katsumi Inoue", "title": "Modeling of Resilience Properties in Oscillatory Biological Systems\n  using Parametric Time Petri Nets, Supplementary Information", "comments": "8 pages, 2 figures, supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated verification of living organism models allows us to gain previously\nunknown knowledge about underlying biological processes. In this paper, we show\nthe benefits to use parametric time Petri nets in order to analyze precisely\nthe dynamic behavior of biological oscillatory systems. In particular, we focus\non the resilience properties of such systems. This notion is crucial to\nunderstand the behavior of biological systems (e.g. the mammalian circadian\nrhythm) that are reactive and adaptive enough to endorse major changes in their\nenvironment (e.g. jet-lags, day-night alternating work-time). We formalize\nthese properties through parametric TCTL and demonstrate how changes of the\nenvironmental conditions can be tackled to guarantee the resilience of living\norganisms. In particular, we are able to discuss the influence of various\nperturbations, e.g. artificial jet-lag or components knock-out, with regard to\nquantitative delays. This analysis is crucial when it comes to model\nelicitation for dynamic biological systems. We demonstrate the applicability of\nthis technique using a simplified model of circadian clock.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 21:59:09 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Andreychenko", "Alexander", ""], ["Magnin", "Morgan", ""], ["Inoue", "Katsumi", ""]]}, {"id": "1506.06394", "submitter": "J\\\"urgen Koslowski", "authors": "Elie M. Adam, Munther A. Dahleh and Asuman Ozdaglar", "title": "Towards an Algebra for Cascade Effects", "comments": "31 pages", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (July 6,\n  2017) lmcs:3770", "doi": "10.23638/LMCS-13(3:1)2017", "report-no": null, "categories": "cs.DM cs.LO cs.SI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of (dynamical) systems that inherently capture\ncascading effects (viewed as consequential effects) and are naturally amenable\nto combinations. We develop an axiomatic general theory around those systems,\nand guide the endeavor towards an understanding of cascading failure. The\ntheory evolves as an interplay of lattices and fixed points, and its results\nmay be instantiated to commonly studied models of cascade effects.\n  We characterize the systems through their fixed points, and equip them with\ntwo operators. We uncover properties of the operators, and express global\nsystems through combinations of local systems. We enhance the theory with a\nnotion of failure, and understand the class of shocks inducing a system to\nfailure. We develop a notion of mu-rank to capture the energy of a system, and\nunderstand the minimal amount of effort required to fail a system, termed\nresilience. We deduce a dual notion of fragility and show that the combination\nof systems sets a limit on the amount of fragility inherited.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 17:36:15 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 16:48:34 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 17:23:02 GMT"}, {"version": "v4", "created": "Wed, 5 Jul 2017 09:31:26 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Adam", "Elie M.", ""], ["Dahleh", "Munther A.", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "1506.06419", "submitter": "David Parker", "authors": "Gethin Norman, David Parker and Xueyi Zou", "title": "Verification and Control of Partially Observable Probabilistic Real-Time\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose automated techniques for the verification and control of\nprobabilistic real-time systems that are only partially observable. To formally\nmodel such systems, we define an extension of probabilistic timed automata in\nwhich local states are partially visible to an observer or controller. We give\na probabilistic temporal logic that can express a range of quantitative\nproperties of these models, relating to the probability of an event's\noccurrence or the expected value of a reward measure. We then propose\ntechniques to either verify that such a property holds or to synthesise a\ncontroller for the model which makes it true. Our approach is based on an\ninteger discretisation of the model's dense-time behaviour and a grid-based\nabstraction of the uncountable belief space induced by partial observability.\nThe latter is necessarily approximate since the underlying problem is\nundecidable, however we show how both lower and upper bounds on numerical\nresults can be generated. We illustrate the effectiveness of the approach by\nimplementing it in the PRISM model checker and applying it to several case\nstudies, from the domains of computer security and task scheduling.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 22:24:58 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 00:46:15 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Norman", "Gethin", ""], ["Parker", "David", ""], ["Zou", "Xueyi", ""]]}, {"id": "1506.06534", "submitter": "Esma Balkir", "authors": "Esma Balkir, Mehrnoosh Sadrzadeh and Bob Coecke", "title": "Distributional Sentence Entailment Using Density Matrices", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IT cs.LO math.CT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical compositional distributional model of Coecke et al. (2010)\nsuggests a way to combine grammatical composition of the formal, type logical\nmodels with the corpus based, empirical word representations of distributional\nsemantics. This paper contributes to the project by expanding the model to also\ncapture entailment relations. This is achieved by extending the representations\nof words from points in meaning space to density operators, which are\nprobability distributions on the subspaces of the space. A symmetric measure of\nsimilarity and an asymmetric measure of entailment is defined, where lexical\nentailment is measured using von Neumann entropy, the quantum variant of\nKullback-Leibler divergence. Lexical entailment, combined with the composition\nmap on word representations, provides a method to obtain entailment relations\non the level of sentences. Truth theoretic and corpus-based examples are\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 10:14:47 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 14:08:28 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Balkir", "Esma", ""], ["Sadrzadeh", "Mehrnoosh", ""], ["Coecke", "Bob", ""]]}, {"id": "1506.06537", "submitter": "Samy Abbes", "authors": "Samy Abbes", "title": "Synchronization of Bernoulli sequences on shared letters", "comments": "36 pages, 23 references, 8 figures", "journal-ref": null, "doi": "10.1016/j.ic.2017.04.002", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of this paper is the distributed and incremental generation of long\nexecutions of concurrent systems, uniformly or more generally with weights\nassociated to elementary actions. Synchronizing sequences of letters on\nalphabets sharing letters are known to produce a trace in the concurrency\ntheoretic sense, i.e., a labeled partially ordered set. We study the\nprobabilistic aspects by considering the synchronization of Bernoulli sequences\nof letters, under the light of Bernoulli and uniform measures recently\nintroduced for trace monoids. We introduce two algorithms that produce random\ntraces, using only local random primitives. We thoroughly study some specific\nexamples, the path model and the ring model, both of arbitrary size. For these\nmodels, we show how to generate any Bernoulli distributed random traces, which\nincludes the case of uniform generation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 10:21:45 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 09:15:19 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Abbes", "Samy", ""]]}, {"id": "1506.06661", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago and Alessandro Rioli", "title": "Applicative Bisimulation and Quantum $\\lambda$-Calculi (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applicative bisimulation is a coinductive technique to check program\nequivalence in higher-order functional languages. It is known to be sound, and\nsometimes complete, with respect to context equivalence. In this paper we show\nthat applicative bisimulation also works when the underlying language of\nprograms takes the form of a linear $\\lambda$-calculus extended with features\nsuch as probabilistic binary choice, but also quantum data, the latter being a\nsetting in which linearity plays a role. The main results are proofs of\nsoundness for the obtained notions of bisimilarity.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 15:57:43 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Rioli", "Alessandro", ""]]}, {"id": "1506.06869", "submitter": "Frank Stephan", "authors": "C.T. Chong (National University of Singapore), Gordon Hoi (National\n  University of Singapore), Frank Stephan (National University of Singapore),\n  Daniel Turetsky (Kurt Goedel Research Center)", "title": "Partial functions and domination", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  21, 2015) lmcs:1592", "doi": "10.2168/LMCS-11(3:16)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current work introduces the notion of pdominant sets and studies their\nrecursion-theoretic properties. Here a set A is called pdominant iff there is a\npartial A-recursive function {\\psi} such that for every partial recursive\nfunction {\\phi} and almost every x in the domain of {\\phi} there is a y in the\ndomain of {\\psi} with y<= x and {\\psi}(y) > {\\phi}(x). While there is a full\n{\\pi}01-class of nonrecursive sets where no set is pdominant, there is no\n{\\pi}01-class containing only pdominant sets. No weakly 2-generic set is\npdominant while there are pdominant 1-generic sets below K. The halves of\nChaitin's {\\Omega} are pdominant. No set which is low for Martin-L\\\"of random\nis pdominant. There is a low r.e. set which is pdominant and a high r.e. set\nwhich is not pdominant.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 05:41:51 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 13:10:35 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2016 12:35:39 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Chong", "C. T.", "", "National University of Singapore"], ["Hoi", "Gordon", "", "National\n  University of Singapore"], ["Stephan", "Frank", "", "National University of Singapore"], ["Turetsky", "Daniel", "", "Kurt Goedel Research Center"]]}, {"id": "1506.06933", "submitter": "Thomas Studer", "authors": "Thomas Studer", "title": "Justification logic enjoys the strong finite model property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that justification logic enjoys a form the strong finite model\nproperty (sometimes also called small model property). Thus we obtain\ndecidability proofs for justification logic that do not rely on Post's theorem.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 10:21:19 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Studer", "Thomas", ""]]}, {"id": "1506.07000", "submitter": "Frederic Herbreteau", "authors": "Fr\\'ed\\'eric Herbreteau (LaBRI), Thanh-Tung Tran (LaBRI)", "title": "Improving search order for reachability testing in timed automata", "comments": null, "journal-ref": "International Conference on Formal Modeling and Analysis of Timed\n  Systems (FORMATS), Sep 2015, Madrid, Spain", "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard algorithms for reachability analysis of timed automata are sensitive\nto the order in which the transitions of the automata are taken. To tackle this\nproblem, we propose a ranking system and a waiting strategy. This paper\ndiscusses the reason why the search order matters and shows how a ranking\nsystem and a waiting strategy can be integrated into the standard reachability\nalgorithm to alleviate and prevent the problem respectively. Experiments show\nthat the combination of the two approaches gives optimal search order on\nstandard benchmarks except for one example. This suggests that it should be\nused instead of the standard BFS algorithm for reachability analysis of timed\nautomata.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 13:51:20 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Herbreteau", "Fr\u00e9d\u00e9ric", "", "LaBRI"], ["Tran", "Thanh-Tung", "", "LaBRI"]]}, {"id": "1506.07031", "submitter": "Stefan D\\\"uck", "authors": "Manfred Droste and Stefan D\\\"uck", "title": "Weighted Automata and Logics for Infinite Nested Words", "comments": "LATA 2014, 12 pages", "journal-ref": "Proc. of Language and Automata Theory and Applications (LATA\n  2014), LNCS 8370, pp. 323-334. Springer (2014)", "doi": "10.1007/978-3-319-04921-2_26", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested words introduced by Alur and Madhusudan are used to capture structures\nwith both linear and hierarchical order, e.g. XML documents, without losing\nvaluable closure properties. Furthermore, Alur and Madhusudan introduced\nautomata and equivalent logics for both finite and infinite nested words, thus\nextending B\\\"uchi's theorem to nested words. Recently, average and discounted\ncomputations of weights in quantitative systems found much interest. Here, we\nwill introduce and investigate weighted automata models and weighted MSO logics\nfor infinite nested words. As weight structures we consider valuation monoids\nwhich incorporate average and discounted computations of weights as well as the\nclassical semirings. We show that under suitable assumptions, two resp. three\nfragments of our weighted logics can be transformed into each other. Moreover,\nwe show that the logic fragments have the same expressive power as weighted\nnested word automata.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 14:39:21 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Droste", "Manfred", ""], ["D\u00fcck", "Stefan", ""]]}, {"id": "1506.07290", "submitter": "Baltasar Tranc\\'on y Widemann", "authors": "Baltasar Tranc\\'on y Widemann, Michael Hauhs", "title": "Scientific Modelling with Coalgebra-Algebra Homomorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Many recursive functions can be defined elegantly as the unique\nhomomorphisms, between two algebras, two coalgebras, or one each, that are\ninduced by some universal property of a distinguished structure. Besides the\nwell-known applications in recursive functional programming, several basic\nmodes of reasoning about scientific models have been demonstrated to admit such\nan exact meta-theory. Here we explore the potential of coalgebra--algebra\nhomomorphism that are not a priori unique, for capturing more loosely\nspecifying patterns of scientific modelling. We investigate a pair of dual\ntechniques that leverage (co)monadic structure to obtain reasonable genericity\neven when no universal properties are given. We show the general applicability\nof the approach by discussing a surprisingly broad collection of instances from\nreal-world modelling practice.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 08:56:44 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Widemann", "Baltasar Tranc\u00f3n y", ""], ["Hauhs", "Michael", ""]]}, {"id": "1506.07774", "submitter": "Christoph Haase", "authors": "Christoph Haase, Piotr Hofman", "title": "Tightening the Complexity of Equivalence Problems for Commutative\n  Grammars", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the language equivalence problem for regular and context-free\ncommutative grammars is coNEXP-complete. In addition, our lower bound\nimmediately yields further coNEXP-completeness results for equivalence problems\nfor communication-free Petri nets and reversal-bounded counter automata.\nMoreover, we improve both lower and upper bounds for language equivalence for\nexponent-sensitive commutative grammars.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 14:46:41 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Haase", "Christoph", ""], ["Hofman", "Piotr", ""]]}, {"id": "1506.07861", "submitter": "Luca Laurenti", "authors": "Luca Laurenti, Luca Cardelli and Marta Kwiatkowska", "title": "Stochastic Analysis of Chemical Reaction Networks Using Linear Noise\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic evolution of Chemical Reactions Networks (CRNs) over time is\nusually analysed through solving the Chemical Master Equation (CME) or\nperforming extensive simulations. Analysing stochasticity is often needed,\nparticularly when some molecules occur in low numbers. Unfortunately, both\napproaches become infeasible if the system is complex and/or it cannot be\nensured that initial populations are small. We develop a probabilistic logic\nfor CRNs that enables stochastic analysis of the evolution of populations of\nmolecular species. We present an approximate model checking algorithm based on\nthe Linear Noise Approximation (LNA) of the CME, whose computational complexity\nis independent of the population size of each species and polynomial in the\nnumber of different species. The algorithm requires the solution of first order\npolynomial differential equations. We prove that our approach is valid for any\nCRN close enough to the thermodynamical limit. However, we show on four case\nstudies that it can still provide good approximation even for low molecule\ncounts. Our approach enables rigorous analysis of CRNs that are not analyzable\nby solving the CME, but are far from the deterministic limit. Moreover, it can\nbe used for a fast approximate stochastic characterization of a CRN.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 10:44:38 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 19:31:26 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Laurenti", "Luca", ""], ["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1506.07990", "submitter": "Thomas Bolander", "authors": "Mikkel Birkegaard Andersen, Thomas Bolander, Hans van Ditmarsch,\n  Martin Holm Jensen", "title": "Bisimulation and expressivity for conditional belief, degrees of belief,\n  and safe belief", "comments": null, "journal-ref": "Synthese 194(7): 2447-2487 (2017)", "doi": "10.1007/s11229-016-1060-x", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plausibility models are Kripke models that agents use to reason about\nknowledge and belief, both of themselves and of each other. Such models are\nused to interpret the notions of conditional belief, degrees of belief, and\nsafe belief. The logic of conditional belief contains that modality and also\nthe knowledge modality, and similarly for the logic of degrees of belief and\nthe logic of safe belief. With respect to these logics, plausibility models may\ncontain too much information. A proper notion of bisimulation is required that\ncharacterises them. We define that notion of bisimulation and prove the\nrequired characterisations: on the class of image-finite and preimage-finite\nmodels (with respect to the plausibility relation), two pointed Kripke models\nare modally equivalent in either of the three logics, if and only if they are\nbisimilar. As a result, the information content of such a model can be\nsimilarly expressed in the logic of conditional belief, or the logic of degrees\nof belief, or that of safe belief. This, we found a surprising result. Still,\nthat does not mean that the logics are equally expressive: the logics of\nconditional and degrees of belief are incomparable, the logics of degrees of\nbelief and safe belief are incomparable, while the logic of safe belief is more\nexpressive than the logic of conditional belief. In view of the result on\nbisimulation characterisation, this is an equally surprising result. We hope\nour insights may contribute to the growing community of formal epistemology and\non the relation between qualitative and quantitative modelling.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 08:17:32 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 21:43:40 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Andersen", "Mikkel Birkegaard", ""], ["Bolander", "Thomas", ""], ["van Ditmarsch", "Hans", ""], ["Jensen", "Martin Holm", ""]]}, {"id": "1506.08030", "submitter": "Ismail Ilkan Ceylan", "authors": "\\.Ismail \\.Ilkan Ceylan and Rafael Pe\\~naloza", "title": "Dynamic Bayesian Ontology Languages", "comments": "Fifth International Workshop on Statistical Relational AI\n  (StarAI'2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many formalisms combining ontology languages with uncertainty, usually in the\nform of probabilities, have been studied over the years. Most of these\nformalisms, however, assume that the probabilistic structure of the knowledge\nremains static over time. We present a general approach for extending ontology\nlanguages to handle time-evolving uncertainty represented by a dynamic Bayesian\nnetwork. We show how reasoning in the original language and dynamic Bayesian\ninferences can be exploited for effective reasoning in our framework.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 11:32:46 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Ceylan", "\u0130smail \u0130lkan", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1506.08238", "submitter": "Wenda Li", "authors": "Wenda Li, Grant Olney Passmore and Lawrence C. Paulson", "title": "Deciding Univariate Polynomial Problems Using Untrusted Certificates in\n  Isabelle/HOL", "comments": "24 pages", "journal-ref": "Journal of Automated Reasoning, 2017", "doi": "10.1007/s10817-017-9424-6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a proof procedure for univariate real polynomial problems in\nIsabelle/HOL. The core mathematics of our procedure is based on univariate\ncylindrical algebraic decomposition. We follow the approach of untrusted\ncertificates, separating solving from verifying: efficient external tools\nperform expensive real algebraic computations, producing evidence that is\nformally checked within Isabelle's logic. This allows us to exploit\nhighly-tuned computer algebra systems like Mathematica to guide our procedure\nwithout impacting the correctness of its results. We present experiments\ndemonstrating the efficacy of this approach, in many cases yielding orders of\nmagnitude improvements over previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 23:57:46 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 22:19:07 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Li", "Wenda", ""], ["Passmore", "Grant Olney", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "1506.08563", "submitter": "Florian Lonsing", "authors": "Uwe Egly, Florian Lonsing, and Johannes Oetsch", "title": "Automated Benchmarking of Incremental SAT and QBF Solvers", "comments": "camera-ready version (8 pages + 2 pages appendix), to appear in the\n  proceedings of the 20th International Conference on Logic for Programming,\n  Artificial Intelligence and Reasoning (LPAR), LNCS, Springer, 2015", "journal-ref": null, "doi": "10.1007/978-3-662-48899-7_13", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental SAT and QBF solving potentially yields improvements when\nsequences of related formulas are solved. An incremental application is usually\ntailored towards some specific solver and decomposes a problem into incremental\nsolver calls. This hinders the independent comparison of different solvers,\nparticularly when the application program is not available. As a remedy, we\npresent an approach to automated benchmarking of incremental SAT and QBF\nsolvers. Given a collection of formulas in (Q)DIMACS format generated\nincrementally by an application program, our approach automatically translates\nthe formulas into instructions to import and solve a formula by an incremental\nSAT/QBF solver. The result of the translation is a program which replays the\nincremental solver calls and thus allows to evaluate incremental solvers\nindependently from the application program. We illustrate our approach by\ndifferent hardware verification problems for SAT and QBF solvers.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 09:52:15 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 09:26:37 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Egly", "Uwe", ""], ["Lonsing", "Florian", ""], ["Oetsch", "Johannes", ""]]}, {"id": "1506.08726", "submitter": "Swen Jacobs", "authors": "Swen Jacobs, Roderick Bloem, Romain Brenguier, R\\\"udiger Ehlers,\n  Timotheus Hell, Robert K\\\"onighofer, Guillermo A. P\\'erez, Jean-Fran\\c{c}ois\n  Raskin, Leonid Ryzhyk, Ocan Sankur, Martina Seidl, Leander Tentrup, Adam\n  Walker", "title": "The First Reactive Synthesis Competition (SYNTCOMP 2014)", "comments": "24 pages, published in STTT", "journal-ref": "International Journal on Software Tools for Technology Transfer,\n  Online First, 2016, pp 1-24", "doi": "10.1007/s10009-016-0416-3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the reactive synthesis competition (SYNTCOMP), a long-term\neffort intended to stimulate and guide advances in the design and application\nof synthesis procedures for reactive systems. The first iteration of SYNTCOMP\nis based on the controller synthesis problem for finite-state systems and\nsafety specifications. We provide an overview of this problem and existing\napproaches to solve it, and report on the design and results of the first\nSYNTCOMP. This includes the definition of the benchmark format, the collection\nof benchmarks, the rules of the competition, and the five synthesis tools that\nparticipated. We present and analyze the results of the competition and draw\nconclusions on the state of the art. Finally, we give an outlook on future\ndirections of SYNTCOMP.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 16:45:03 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 13:55:42 GMT"}, {"version": "v3", "created": "Wed, 13 Apr 2016 07:34:07 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Jacobs", "Swen", ""], ["Bloem", "Roderick", ""], ["Brenguier", "Romain", ""], ["Ehlers", "R\u00fcdiger", ""], ["Hell", "Timotheus", ""], ["K\u00f6nighofer", "Robert", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Ryzhyk", "Leonid", ""], ["Sankur", "Ocan", ""], ["Seidl", "Martina", ""], ["Tentrup", "Leander", ""], ["Walker", "Adam", ""]]}, {"id": "1506.08905", "submitter": "Jia Liang Mr", "authors": "Jia Hui Liang, Vijay Ganesh, Ed Zulkoski, Atulan Zaman, Krzysztof\n  Czarnecki", "title": "Understanding VSIDS Branching Heuristics in Conflict-Driven\n  Clause-Learning SAT Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conflict-Driven Clause-Learning SAT solvers crucially depend on the Variable\nState Independent Decaying Sum (VSIDS) branching heuristic for their\nperformance. Although VSIDS was proposed nearly fifteen years ago, and many\nother branching heuristics for SAT solving have since been proposed, VSIDS\nremains one of the most effective branching heuristics.\n  In this paper, we advance our understanding of VSIDS by answering the\nfollowing key questions. The first question we pose is \"what is special about\nthe class of variables that VSIDS chooses to additively bump?\" In answering\nthis question we showed that VSIDS overwhelmingly picks, bumps, and learns\nbridge variables, defined as the variables that connect distinct communities in\nthe community structure of SAT instances. This is surprising since VSIDS was\ninvented more than a decade before the link between community structure and SAT\nsolver performance was discovered. Additionally, we show that VSIDS viewed as a\nranking function correlates strongly with temporal graph centrality measures.\nPutting these two findings together, we conclude that VSIDS picks\nhigh-centrality bridge variables. The second question we pose is \"what role\ndoes multiplicative decay play in making VSIDS so effective?\" We show that the\nmultiplicative decay behaves like an exponential moving average (EMA) that\nfavors variables that persistently occur in conflicts (the signal) over\nvariables that occur intermittently (the noise). The third question we pose is\n\"whether VSIDS is temporally and spatially focused.\" We show that VSIDS\ndisproportionately picks variables from a few communities unlike, say, the\nrandom branching heuristic. We put these findings together to invent a new\nadaptive VSIDS branching heuristic that solves more instances than one of the\nbest-known VSIDS variants over the SAT Competition 2013 benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 00:16:47 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 02:53:37 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2015 23:46:28 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Liang", "Jia Hui", ""], ["Ganesh", "Vijay", ""], ["Zulkoski", "Ed", ""], ["Zaman", "Atulan", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1506.08982", "submitter": "Lvzhou Li", "authors": "Lvzhou Li, Yuan Feng", "title": "Quantum Markov chains: description of hybrid systems, decidability of\n  equivalence, and model checking linear-time properties", "comments": "This paper has been accepted for publication in Information and\n  Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a model of quantum Markov chains that is a quantum\nanalogue of Markov chains and is obtained by replacing probabilities in\ntransition matrices with quantum operations. We show that this model is very\nsuited to describe hybrid systems that consist of a quantum component and a\nclassical one, although it has the same expressive power as another quantum\nMarkov model proposed in the literature.\n  Indeed, hybrid systems are often encountered in quantum information\nprocessing; for example, both quantum programs and quantum protocols can be\nregarded as hybrid systems. Thus, we further propose a model called hybrid\nquantum automata (HQA) that can be used to describe these hybrid systems that\nreceive inputs (actions) from the outer world. We show the language equivalence\nproblem of HQA is decidable in polynomial time. Furthermore, we apply this\nresult to the trace equivalence problem of quantum Markov chains, and thus it\nis also decidable in polynomial time. Finally, we discuss model checking\nlinear-time properties of quantum Markov chains, and show the quantitative\nanalysis of regular safety properties can be addressed successfully.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 08:08:55 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Li", "Lvzhou", ""], ["Feng", "Yuan", ""]]}]