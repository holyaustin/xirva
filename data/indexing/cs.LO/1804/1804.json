[{"id": "1804.00037", "submitter": "Alireza Partovi", "authors": "Alireza Partovi and Hai Lin", "title": "Reactive Supervisory Control of Open Discrete-event Systems", "comments": "IEEE CDC technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.FL cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The conventional Wonham-Ramadge supervisory control framework of discrete\nevent systems enforces a closed discrete event system to generate correct\nbehaviors under certain environments, which can be captured by an appropriate\nplant model. Nevertheless, such control methods cannot be directly applied for\nmany practical engineering systems nowadays since they are open systems and\ntheir operation heavily depends on nontrivial interactions between the systems\nand the external environments. These open systems should be controlled in such\na way that accomplishment of the control objective can be guaranteed for any\npossible environment, which may be dynamic, uncertain and sometimes\nunpredictable. In this paper, we aim at extending the conventional supervisory\ncontrol theory to open discrete event systems in a reactive manner. Starting\nfrom a novel input-output automaton model of an open system, we consider\ncontrol objectives that characterize the desired input-output behaviors of the\nsystem, based on which a game-theoretic approach is carried out to compute a\nreactive supervisor that steers the system to fulfill the specifications\nregardless of the environment behaviors. We present a necessary and sufficient\nconditions for the existence of such a reactive supervisor. Furthermore,\nillustrative examples are given throughout this paper to demonstrate the key\ndefinitions and the effectiveness of the proposed reactive supervisor synthesis\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 19:19:33 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 19:41:31 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 17:51:39 GMT"}, {"version": "v4", "created": "Wed, 18 Sep 2019 00:57:42 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Partovi", "Alireza", ""], ["Lin", "Hai", ""]]}, {"id": "1804.00073", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Generation of complete test sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use testing to check if a combinational circuit N always evaluates to 0.\nThe usual point of view is that to prove that N always evaluates to 0 one has\nto check the value of N for all 2^|X| input assignments where X is the set of\ninput variables of N. We use the notion of a Stable Set of Assignments (SSA) to\nshow that one can build a complete test set (i.e. a test set proving that N\nalways evaluates to 0) that consists of less than 2^|X| tests. Given an\nunsatisfiable CNF formula H(W), an SSA of H is a set of assignments to W\nproving unsatisfiability of H. A trivial SSA is the set of all 2^|W|\nassignments to W. Importantly, real-life formulas can have SSAs that are much\nsmaller than 2^|W|. Generating a complete test set for N using only the\nmachinery of SSAs is inefficient. We describe a much faster algorithm that\ncombines computation of SSAs with resolution derivation and produces a complete\ntest set for a \"projection\" of N on a subset of variables of N. We give\nexperimental results and describe potential applications of this algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 22:33:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "1804.00415", "submitter": "Mahsa Ghasemi", "authors": "Rayna Dimitrova, Mahsa Ghasemi, Ufuk Topcu", "title": "Maximum Realizability for Linear Temporal Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic synthesis from linear temporal logic (LTL) specifications is widely\nused in robotic motion planning, control of autonomous systems, and load\ndistribution in power networks. A common specification pattern in such\napplications consists of an LTL formula describing the requirements on the\nbehaviour of the system, together with a set of additional desirable\nproperties. We study the synthesis problem in settings where the overall\nspecification is unrealizable, more precisely, when some of the desirable\nproperties have to be (temporarily) violated in order to satisfy the system's\nobjective. We provide a quantitative semantics of sets of safety\nspecifications, and use it to formalize the \"best-effort\" satisfaction of such\nsoft specifications while satisfying the hard LTL specification. We propose an\nalgorithm for synthesizing implementations that are optimal with respect to\nthis quantitative semantics. Our method builds upon the idea of the bounded\nsynthesis approach, and we develop a MaxSAT encoding which allows for\nmaximizing the quantitative satisfaction of the safety specifications. We\nevaluate our algorithm on scenarios from robotics and power distribution\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 06:59:39 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Dimitrova", "Rayna", ""], ["Ghasemi", "Mahsa", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1804.00427", "submitter": "Thorsten Wissmann", "authors": "Andrej Bauer, Andrew Swan", "title": "Every metric space is separable in function realizability", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 23,\n  2019) lmcs:5501", "doi": "10.23638/LMCS-15(2:14)2019", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We first show that in the function realizability topos every metric space is\nseparable, and every object with decidable equality is countable. More\ngenerally, working with synthetic topology, every $T_0$-space is separable and\nevery discrete space is countable. It follows that intuitionistic logic does\nnot show the existence of a non-separable metric space, or an uncountable set\nwith decidable equality, even if we assume principles that are validated by\nfunction realizability, such as Dependent and Function choice, Markov's\nprinciple, and Brouwer's continuity and fan principles.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 08:06:33 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 06:42:19 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 13:44:06 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2019 19:13:45 GMT"}, {"version": "v5", "created": "Fri, 3 May 2019 16:15:43 GMT"}, {"version": "v6", "created": "Wed, 22 May 2019 05:52:44 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bauer", "Andrej", ""], ["Swan", "Andrew", ""]]}, {"id": "1804.00568", "submitter": "K. V. Krishna", "authors": "Gayatri Panicker, K. V. Krishna, Purandar Bhaduri", "title": "On the structure of C-algebras through atomicity and if-then-else", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the notions of atoms and atomicity in $C$-algebras and\nobtains a characterisation of atoms in the $C$-algebra of transformations.\nFurther, this work presents some necessary conditions and sufficient conditions\nfor the atomicity of $C$-algebras and shows that the class of finite atomic\n$C$-algebras is precisely that of finite adas. This paper also uses the\nif-then-else action to study the structure of $C$-algebras and classify the\nelements of the $C$-algebra of transformations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 14:44:55 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Panicker", "Gayatri", ""], ["Krishna", "K. V.", ""], ["Bhaduri", "Purandar", ""]]}, {"id": "1804.00596", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier, Cezary Kaliszyk, Josef Urban, Ramana Kumar, Michael\n  Norrish", "title": "Learning to Prove with Tactics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a automated tactical prover TacticToe on top of the HOL4\ninteractive theorem prover. TacticToe learns from human proofs which\nmathematical technique is suitable in each proof situation. This knowledge is\nthen used in a Monte Carlo tree search algorithm to explore promising\ntactic-level proof paths. On a single CPU, with a time limit of 60 seconds,\nTacticToe proves 66.4 percent of the 7164 theorems in HOL4's standard library,\nwhereas E prover with auto-schedule solves 34.5 percent. The success rate rises\nto 69.0 percent by combining the results of TacticToe and E prover.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 15:43:17 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Gauthier", "Thibault", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Kumar", "Ramana", ""], ["Norrish", "Michael", ""]]}, {"id": "1804.00617", "submitter": "Ario Santoso", "authors": "Ario Santoso", "title": "Specification-Driven Multi-Perspective Predictive Business Process\n  Monitoring (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive analysis in business process monitoring aims at forecasting the\nfuture information of a running business process. The prediction is typically\nmade based on the model extracted from historical process execution logs (event\nlogs). In practice, different business domains might require different kinds of\npredictions. Hence, it is important to have a means for properly specifying the\ndesired prediction tasks, and a mechanism to deal with these various prediction\ntasks. Although there have been many studies in this area, they mostly focus on\na specific prediction task. This work introduces a language for specifying the\ndesired prediction tasks, and this language allows us to express various kinds\nof prediction tasks. This work also presents a mechanism for automatically\ncreating the corresponding prediction model based on the given specification.\nThus, different from previous studies, our approach enables us to deal with\nvarious kinds of prediction tasks based on the given specification. A prototype\nimplementing our approach has been developed and experiments using a real-life\nevent log have been conducted.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 16:26:35 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 17:37:58 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Santoso", "Ario", ""]]}, {"id": "1804.00731", "submitter": "Valentin Blot", "authors": "Valentin Blot", "title": "An interpretation of system F through bar recursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two possible computational interpretations of second-order\narithmetic: Girard's system F or Spector's bar recursion and its variants.\nWhile the logic is the same, the programs obtained from these two\ninterpretations have a fundamentally different computational behavior and their\nrelationship is not well understood. We make a step towards a comparison by\ndefining the first translation of system F into a simply-typed total language\nwith a variant of bar recursion. This translation relies on a realizability\ninterpretation of second-order arithmetic. Due to G\\\"odel's incompleteness\ntheorem there is no proof of termination of system F within second-order\narithmetic. However, for each individual term of system F there is a proof in\nsecond-order arithmetic that it terminates, with its realizability\ninterpretation providing a bound on the number of reduction steps to reach a\nnormal form. Using this bound, we compute the normal form through primitive\nrecursion. Moreover, since the normalization proof of system F proceeds by\ninduction on typing derivations, the translation is compositional. The\nflexibility of our method opens the possibility of getting a more direct\ntranslation that will provide an alternative approach to the study of\npolymorphism, namely through bar recursion.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 21:07:42 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Blot", "Valentin", ""]]}, {"id": "1804.00952", "submitter": "Beno\\^it Valiron", "authors": "Amr Sabry and Beno\\^it Valiron and Juliana Kaizer Vizzotto", "title": "From Symmetric Pattern-Matching to Quantum Control (Extended Version)", "comments": "22 pages. Extended version of a paper accepted at FoSSaCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One perspective on quantum algorithms is that they are classical algorithms\nhaving access to a special kind of memory with exotic properties. This\nperspective suggests that, even in the case of quantum algorithms, the control\nflow notions of sequencing, conditionals, loops, and recursion are entirely\nclassical. There is however, another notion of control flow, that is itself\nquantum. The notion of quantum conditional expression is reasonably\nwell-understood: the execution of the two expressions becomes itself a\nsuperposition of executions. The quantum counterpart of loops and recursion is\nhowever not believed to be meaningful in its most general form.\n  In this paper, we argue that, under the right circumstances, a reasonable\nnotion of quantum loops and recursion is possible. To this aim, we first\npropose a classical, typed, reversible language with lists and fixpoints. We\nthen extend this language to the closed quantum domain (without measurements)\nby allowing linear combinations of terms and restricting fixpoints to\nstructurally recursive fixpoints whose termination proofs match the proofs of\nconvergence of sequences in infinite-dimensional Hilbert spaces. We\nadditionally give an operational semantics for the quantum language in the\nspirit of algebraic lambda-calculi and illustrate its expressiveness by\nmodeling several common unitary operations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 13:19:42 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Sabry", "Amr", ""], ["Valiron", "Beno\u00eet", ""], ["Vizzotto", "Juliana Kaizer", ""]]}, {"id": "1804.01023", "submitter": "Tom van Dijk", "authors": "Tom van Dijk", "title": "Attracting Tangles to Solve Parity Games", "comments": "Accepted for publication at CAV 2018", "journal-ref": null, "doi": "10.1007/978-3-319-96142-2_14", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parity games have important practical applications in formal verification and\nsynthesis, especially to solve the model-checking problem of the modal\nmu-calculus. They are also interesting from the theory perspective, because\nthey are widely believed to admit a polynomial solution, but so far no such\nalgorithm is known.\n  We propose a new algorithm to solve parity games based on learning tangles,\nwhich are strongly connected subgraphs for which one player has a strategy to\nwin all cycles in the subgraph. We argue that tangles play a fundamental role\nin the prominent parity game solving algorithms. We show that tangle learning\nis competitive in practice and the fastest solver for large random games.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 15:07:22 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 12:30:43 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["van Dijk", "Tom", ""]]}, {"id": "1804.01106", "submitter": "EPTCS", "authors": "Nuriya Nurgalieva, L\\'idia del Rio", "title": "Inadequacy of Modal Logic in Quantum Settings", "comments": "In Proceedings QPL 2018, arXiv:1901.09476", "journal-ref": "EPTCS 287, 2019, pp. 267-297", "doi": "10.4204/EPTCS.287.16", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We test the principles of classical modal logic in fully quantum settings.\nModal logic models our reasoning in multi-agent problems, and allows us to\nsolve puzzles like the muddy children paradox. The Frauchiger-Renner thought\nexperiment highlighted fundamental problems in applying classical reasoning\nwhen quantum agents are involved; we take it as a guiding example to test the\naxioms of classical modal logic. In doing so, we find a problem in the original\nformulation of the Frauchiger-Renner theorem: a missing assumption about\nunitarity of evolution is necessary to derive a contradiction and prove the\ntheorem. Adding this assumption clarifies how different interpretations of\nquantum theory fit in, i.e., which properties they violate. Finally, we show\nhow most of the axioms of classical modal logic break down in quantum settings,\nand attempt to generalize them. Namely, we introduce constructions of trust and\ncontext, which highlight the importance of an exact structure of trust\nrelations between agents. We propose a challenge to the community: to find\nconditions for the validity of trust relations, strong enough to exorcise the\nparadox and weak enough to still recover classical logic.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:00:21 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 05:39:40 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Nurgalieva", "Nuriya", ""], ["del Rio", "L\u00eddia", ""]]}, {"id": "1804.01172", "submitter": "Curtis Bright", "authors": "Curtis Bright, Ilias Kotsireas, Vijay Ganesh", "title": "Applying Computer Algebra Systems with SAT Solvers to the Williamson\n  Conjecture", "comments": "To appear in the Journal of Symbolic Computation", "journal-ref": null, "doi": "10.1016/j.jsc.2019.07.024", "report-no": null, "categories": "cs.LO cs.SC math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We employ tools from the fields of symbolic computation and satisfiability\nchecking---namely, computer algebra systems and SAT solvers---to study the\nWilliamson conjecture from combinatorial design theory and increase the bounds\nto which Williamson matrices have been enumerated. In particular, we completely\nenumerate all Williamson matrices of even order up to and including 70 which\ngives us deeper insight into the behaviour and distribution of Williamson\nmatrices. We find that, in contrast to the case when the order is odd,\nWilliamson matrices of even order are quite plentiful and exist in every even\norder up to and including 70. As a consequence of this and a new construction\nfor 8-Williamson matrices we construct 8-Williamson matrices in all odd orders\nup to and including 35. We additionally enumerate all Williamson matrices whose\norders are divisible by 3 and less than 70, finding one previously unknown set\nof Williamson matrices of order 63.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 21:12:29 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 03:51:28 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bright", "Curtis", ""], ["Kotsireas", "Ilias", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1804.01413", "submitter": "Tiago Veras Sr.", "authors": "Tiago Mendon\\c{c}a Lucena de Veras, Arthur F. Ramos, Ruy J. G. B. de\n  Queiroz, Anjolina G. de Oliveira", "title": "On the Calculation of Fundamental Groups in Homotopy Type Theory by\n  Means of Computational Paths", "comments": "30 pages, 9 figures, 2 appendix. arXiv admin note: substantial text\n  overlap with arXiv:1803.01709, arXiv:1609.05079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most interesting entities of homotopy type theory is the identity\ntype. It gives rise to an interesting interpretation of the equality, since one\ncan semantically interpret the equality between two terms of the same type as a\ncollection of homotopical paths between points of the same space. Since this is\nonly a semantical interpretation, the addition of paths to the syntax of\nhomotopy type theory has been recently proposed by De Queiroz, Ramos and De\nOliveira . In these works, the authors propose an entity known as\n`computational path', proposed by De Queiroz and Gabbay in 1994, and show that\nit can be used to formalize the identity type. We have found that it is\npossible to use these computational paths as a tool to achieve one central\nresult of algebraic topology and homotopy type theory: the calculation of\nfundamental groups of surfaces. We review the concept of computational paths\nand the $LND_{EQ}-TRS$, which is a term rewriting system proposed by De\nOliveira in 1994 to map redundancies between computational paths. We then\nproceed to calculate the fundamental group of the circle, cylinder, M{\\\"o}bius\nband, torus and the real projective plane. Moreover, we show that the use of\ncomputational paths make these calculations simple and straightforward, whereas\nthe same result is much harder to obtain using the traditional\ncode-encode-decode approach of homotopy type theory.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 17:38:07 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 16:55:59 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["de Veras", "Tiago Mendon\u00e7a Lucena", ""], ["Ramos", "Arthur F.", ""], ["de Queiroz", "Ruy J. G. B.", ""], ["de Oliveira", "Anjolina G.", ""]]}, {"id": "1804.01437", "submitter": "Manuel Kauers", "authors": "Manuel Kauers and Martina Seidl", "title": "Short Proofs for Some Symmetric Quantified Boolean Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit symmetries to give short proofs for two prominent formula families\nof QBF proof complexity. On the one hand, we employ symmetry breakers. On the\nother hand, we enrich the (relatively weak) QBF resolution calculus Q-Res with\nthe symmetry rule and obtain separations to powerful QBF calculi.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 14:35:55 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Kauers", "Manuel", ""], ["Seidl", "Martina", ""]]}, {"id": "1804.01514", "submitter": "EPTCS", "authors": "Martti Karvonen (University of Edinburgh)", "title": "Categories of Empirical Models", "comments": "In Proceedings QPL 2018, arXiv:1901.09476", "journal-ref": "EPTCS 287, 2019, pp. 239-252", "doi": "10.4204/EPTCS.287.14", "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notion of morphism that is suitable for the sheaf-theoretic approach to\ncontextuality is developed, resulting in a resource theory for contextuality.\nThe key features involve using an underlying relation rather than a function\nbetween measurement scenarios, and allowing for stochastic mappings of outcomes\nto outcomes. This formalizes an intuitive idea of using one empirical model to\nsimulate another one with the help of pre-shared classical randomness. This\nallows one to reinterpret concepts and earlier results in terms of morphisms.\nMost notably: non-contextual models are precisely those allowing a morphism\nfrom the terminal object; contextual fraction is functorial; Graham-reductions\ninduce morphisms, reinterpreting Vorob'evs theorem; contextual models cannot be\ncloned.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 17:27:56 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 15:23:39 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 09:11:23 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Karvonen", "Martti", "", "University of Edinburgh"]]}, {"id": "1804.01637", "submitter": "Fadoua Ghourabi", "authors": "Fadoua Ghourabi and Kazuko Takahashi", "title": "A Proof of the Compositions of Time Interval Relations", "comments": "Proofs available for checking:\n  https://www.isa-afp.org/entries/Allen_Calculus.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We prove the 169 compositions of time interval relations. The proof is\nfirst-order and inferred from an axiomatic system on time intervals. We show a\ngeneral proof template that can alleviate the manual proof with Isar.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 00:55:27 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Ghourabi", "Fadoua", ""], ["Takahashi", "Kazuko", ""]]}, {"id": "1804.01682", "submitter": "Radu Mardare", "authors": "Radu Mardare and Prakash Panangaden and Gordon Plotkin", "title": "On the Axiomatizability of Quantitative Algebras", "comments": "34 pages, this is an extended version of the paper with the same\n  title presented at LICS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative algebras (QAs) are algebras over metric spaces defined by\nquantitative equational theories as introduced by the same authors in a related\npaper presented at LICS 2016. These algebras provide the mathematical\nfoundation for metric semantics of probabilistic, stochastic and other\nquantitative systems. This paper considers the issue of axiomatizability of\nQAs. We investigate the entire spectrum of types of quantitative equations that\ncan be used to axiomatize theories: (i) simple quantitative equations; (ii)\nHorn clauses with no more than $c$ equations between variables as hypotheses,\nwhere $c$ is a cardinal and (iii) the most general case of Horn clauses. In\neach case we characterize the class of QAs and prove variety/quasivariety\ntheorems that extend and generalize classical results from model theory for\nalgebras and first-order structures.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:39:33 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Mardare", "Radu", ""], ["Panangaden", "Prakash", ""], ["Plotkin", "Gordon", ""]]}, {"id": "1804.01710", "submitter": "Caterina Viola", "authors": "Manuel Bodirsky, Marcello Mamino, Caterina Viola", "title": "Submodular Functions and Valued Constraint Satisfaction Problems over\n  Infinite Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valued constraint satisfaction problems (VCSPs) are a large class of\ncombinatorial optimisation problems. It is desirable to classify the\ncomputational complexity of VCSPs depending on a fixed set of allowed cost\nfunctions in the input. Recently, the computational complexity of all VCSPs for\nfinite sets of cost functions over finite domains has been classified in this\nsense. Many natural optimisation problems, however, cannot be formulated as\nVCSPs over a finite domain. We initiate the systematic investigation of\ninfinite-domain VCSPs by studying the complexity of VCSPs for piecewise linear\nhomogeneous cost functions. We show that such VCSPs can be solved in polynomial\ntime when the cost functions are additionally submodular, and that this is\nindeed a maximally tractable class: adding any cost function that is not\nsubmodular leads to an NP-hard VCSP.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:49:13 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""], ["Viola", "Caterina", ""]]}, {"id": "1804.01853", "submitter": "Borzoo Bonakdarpour", "authors": "Erika Abraham and Borzoo Bonakdarpour", "title": "HyperPCTL: A Temporal Logic for Probabilistic Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new logic for expressing and reasoning about\nprobabilistic hyperproperties. Hyperproperties characterize the relation\nbetween different independent executions of a system. Probabilistic\nhyperproperties express quantitative dependencies between such executions. The\nstandard temporal logics for probabilistic systems, i.e., PCTL and PCTL* can\nrefer only to a single path at a time and, hence, cannot express many\nprobabilistic hyperproperties of interest. The logic proposed in this paper,\n\\HyperPCTL, adds explicit and simultaneous quantification over multiple traces\nto PCTL. Such quantification allows expressing probabilistic hyperproperties. A\nmodel checking algorithm for the proposed logic is also given for discrete-time\nMarkov chains.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 13:54:49 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Abraham", "Erika", ""], ["Bonakdarpour", "Borzoo", ""]]}, {"id": "1804.01872", "submitter": "Paul Gainer", "authors": "Paul Gainer, Ernst Moritz Hahn, Sven Schewe", "title": "Incremental Verification of Parametric and Reconfigurable Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of parametrised systems is a growing field in verification, but\nthe analysis of parametrised probabilistic systems is still in its infancy.\nThis is partly because it is much harder: while there are beautiful cut-off\nresults for non-stochastic systems that allow to focus only on small instances,\nthere is little hope that such approaches extend to the quantitative analysis\nof probabilistic systems, as the probabilities depend on the size of a system.\nThe unicorn would be an automatic transformation of a parametrised system into\na formula, which allows to plot, say, the likelihood to reach a goal or the\nexpected costs to do so, against the parameters of a system. While such\nanalysis exists for narrow classes of systems, such as waiting queues, we aim\nboth lower---stepwise exploring the parameter space---and higher---considering\ngeneral systems.\n  The novelty is to heavily exploit the similarity between instances of\nparametrised systems. When the parameter grows, the system for the smaller\nparameter is, broadly speaking, present in the larger system. We use this\nobservation to guide the elegant state-elimination method for parametric Markov\nchains in such a way, that the model transformations will start with those\nparts of the system that are stable under increasing the parameter. We argue\nthat this can lead to a very cheap iterative way to analyse parametric systems,\nshow how this approach extends to reconfigurable systems, and demonstrate on\ntwo benchmarks that this approach scales.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 14:22:43 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Gainer", "Paul", ""], ["Hahn", "Ernst Moritz", ""], ["Schewe", "Sven", ""]]}, {"id": "1804.01943", "submitter": "Giulio Chiribella", "authors": "Giulio Chiribella", "title": "Agents, subsystems, and the conservation of information", "comments": "31+26 pages, updated version with new results, contribution to\n  Special Issue on Quantum Information and Foundations, Entropy, GM D'Ariano\n  and P Perinotti, eds", "journal-ref": "Entropy 20(5), 358 (2018)", "doi": "10.3390/e20050358", "report-no": null, "categories": "quant-ph cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dividing the world into subsystems is an important component of the\nscientific method. The choice of subsystems, however, is not defined a priori.\nTypically, it is dictated by experimental capabilities, which may be different\nfor different agents. Here we propose a way to define subsystems in general\nphysical theories, including theories beyond quantum and classical mechanics.\nOur construction associates every agent A with a subsystem SA, equipped with\nits set of states and its set of transformations. In quantum theory, this\nconstruction accommodates the notion of subsystems as factors of a tensor\nproduct Hilbert space, as well as the notion of subsystems associated to a\nsubalgebra of operators. Classical systems can be interpreted as subsystems of\nquantum systems in different ways, by applying our construction to agents who\nhave access to different sets of operations, including multiphase covariant\nchannels and certain sets of free operations arising in the resource theory of\nquantum coherence. After illustrating the basic definitions, we restrict our\nattention to closed systems, that is, systems where all physical\ntransformations act invertibly and where all states can be generated from a\nfixed initial state. For closed systems, we propose a dynamical definition of\npure states, and show that all the states of all subsystems admit a canonical\npurification. This result extends the purification principle to a broader\nsetting, in which coherent superpositions can be interpreted as purifications\nof incoherent mixtures.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 16:35:12 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 14:29:08 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Chiribella", "Giulio", ""]]}, {"id": "1804.02203", "submitter": "Abraham Westerbaan", "authors": "Abraham A. Westerbaan", "title": "The Category of Von Neumann Algebras", "comments": "Ph.D. thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OA cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this dissertation we study the category of completely positive normal\ncontractive maps between von Neumann algebras. It includes an extensive\nintroduction to the basic theory of $C^*$-algebras and von Neumann algebras.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 11:03:16 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 15:03:23 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Westerbaan", "Abraham A.", ""]]}, {"id": "1804.02265", "submitter": "Thorsten Wissmann", "authors": "Sean Tull", "title": "A Categorical Reconstruction of Quantum Theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (January\n  17, 2020) lmcs:6035", "doi": "10.23638/LMCS-16(1:4)2020", "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We reconstruct finite-dimensional quantum theory from categorical principles.\nThat is, we provide properties ensuring that a given physical theory described\nby a dagger compact category in which one may `discard' objects is equivalent\nto a generalised finite-dimensional quantum theory over a suitable ring $S$.\nThe principles used resemble those due to Chiribella, D'Ariano and Perinotti.\nUnlike previous reconstructions, our axioms and proof are fully categorical in\nnature, in particular not requiring tomography assumptions. Specialising the\nresult to probabilistic theories we obtain either traditional quantum theory\nwith $S$ being the complex numbers, or that over real Hilbert spaces with $S$\nbeing the reals.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:45:01 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 14:08:41 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 16:44:30 GMT"}, {"version": "v4", "created": "Thu, 16 Jan 2020 14:50:18 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Tull", "Sean", ""]]}, {"id": "1804.02316", "submitter": "Massimiliano De Leoni", "authors": "Massimiliano de Leoni, Paolo Felli, and Marco Montali", "title": "A Holistic Approach for Soundness Verification of Decision-Aware Process\n  Models (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed an increasing transformation in the design,\nengineering, and mining of processes, moving from a pure control-flow\nperspective to more integrated models where also data and decisions are\nexplicitly considered. This calls for methods and techniques able to ascertain\nthe correctness of such integrated models. Differently from previous\napproaches, which mainly focused on the local interplay between decisions and\ntheir corresponding outgoing branches, we introduce a holistic approach to\nverify the end-to-end soundness of a Petri net-based process model, enriched\nwith case data and decisions. In particular, we present an effective,\nimplemented technique that verifies soundness by translating the input net into\na colored Petri net with bounded color domains, which can then be analyzed\nusing conventional tools. We prove correctness and termination of this\ntechnique. In addition, we relate our contribution to recent results on\ndecision-aware soundness, showing that our approach can be readily applied\nthere.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 15:09:32 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["de Leoni", "Massimiliano", ""], ["Felli", "Paolo", ""], ["Montali", "Marco", ""]]}, {"id": "1804.02322", "submitter": "A Mani", "authors": "A Mani", "title": "Comparing Dependencies in Probability Theory and General Rough Sets:\n  Part-A", "comments": "69 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.IT cs.LO math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of comparing concepts of dependence in general rough sets with\nthose in probability theory had been initiated by the present author in some of\nher recent papers. This problem relates to the identification of the\nlimitations of translating between the methodologies and possibilities in the\nidentification of concepts. Comparison of ideas of dependence in the approaches\nhad been attempted from a set-valuation based minimalist perspective by the\npresent author. The deviant probability framework has been the result of such\nan approach. Other Bayesian reasoning perspectives (involving numeric\nvaluations) and frequentist approaches are also known. In this research,\nduality results are adapted to demonstrate the possibility of improved\ncomparisons across implications between ontologically distinct concepts in a\ncommon logic-based framework by the present author. Both positive and negative\nresults are proved that delimit possible comparisons in a clearer way by her.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 15:26:36 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Mani", "A", ""]]}, {"id": "1804.02546", "submitter": "Meven Bertrand", "authors": "Meven Bertrand, Jurriaan Rot", "title": "Coalgebraic Determinization of Alternating Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coalgebra is a currently quite active field, which aims to look at generic\nstate-based systems (most prominently automata) from a very abstract point of\nview, mainly using tools from category theory. One of its achievements is to\ngive a completely generic approach of determinization, unifying in an elegant\nmanner non-deterministic automata, probabilistic automata or non-deterministic\npushdown automata in one and the same model. However, the case of alternating\nautomata fails to easily fit in this model. The aim of this internship was\ntherefore to tackle this problem: can alternating automata also be determinized\nin the coalgebraic way? Does this give semantics that coincides with the\nconcretely defined one? In this report, we give a positive answer to both\nquestions. The main element of our construction is a distributive law, the\ndefinition of which has been for some time an open question.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 11:30:00 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Bertrand", "Meven", ""], ["Rot", "Jurriaan", ""]]}, {"id": "1804.02809", "submitter": "Yuichi Nishiwaki", "authors": "Yuichi Nishiwaki, Yoshihiko Kakutani, Yuito Murase", "title": "Modality via Iterated Enrichment", "comments": "MFPS34 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates modal type theories by using a new categorical\nsemantics called change-of-base semantics. Change-of-base semantics is novel in\nthat it is based on (possibly infinitely) iterated enrichment and\ninterpretation of modality as hom objects. In our semantics, the relationship\nbetween meta and object levels in multi-staged computation exactly corresponds\nto the relationship between enriching and enriched categories. As a result, we\nobtain a categorical explanation of situations where meta and object logics may\nbe completely different. Our categorical models include conventional models of\nmodal type theory (e.g., cartesian closed categories with a monoidal\nendofunctor) as special cases and hence can be seen as a natural refinement of\nformer results.\n  On the type theoretical side, it is shown that Fitch-style modal type theory\ncan be directly interpreted in iterated enrichment of categories.\nInterestingly, this interpretation suggests the fact that Fitch-style modal\ntype theory is the right adjoint of dual-context calculus. In addition, we\npresent how linear temporal, S4, and linear exponential modalities are\ndescribed in terms of change-of-base semantics. Finally, we show that the\nchange-of-base semantics can be naturally extended to multi-staged effectful\ncomputation and generalized contextual modality a la Nanevski et al. We\nemphasize that this paper answers the question raised in the survey paper by de\nPaiva and Ritter in 2011, what a categorical model for Fitch-style type theory\nis like.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:14:38 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 10:24:52 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Nishiwaki", "Yuichi", ""], ["Kakutani", "Yoshihiko", ""], ["Murase", "Yuito", ""]]}, {"id": "1804.02840", "submitter": "Juerg Kohlas", "authors": "Juerg Kohlas", "title": "Information and Set Algebras: Interpretation and Uniqueness of\n  Conditional Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new seemingly weak axiomatic formulation of information algebras is given.\nIt is shown how such information algebras can be embedded into set\n(information) algebras. In set algebras there is a natural relation of\nconditional independence between partitions. Via the embedding of information\nalgebras this relation carries over to information algebras. The new axiomatic\nformulation is thereby shown to be equivalent to the one given in\narXiv:1701.02658. In this way the abstract concept of conditional independence\nin information algebras gets a concrete interpretation in terms of set\ntheoretical relations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 06:43:12 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Kohlas", "Juerg", ""]]}, {"id": "1804.02908", "submitter": "Florian Lonsing", "authors": "Florian Lonsing and Uwe Egly", "title": "QRAT+: Generalizing QRAT by a More Powerful QBF Redundancy Property", "comments": "preprint of a paper to be published at IJCAR 2018, LNCS, Springer,\n  including appendix", "journal-ref": null, "doi": "10.1007/978-3-319-94205-6_12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The QRAT (quantified resolution asymmetric tautology) proof system simulates\nvirtually all inference rules applied in state of the art quantified Boolean\nformula (QBF) reasoning tools. It consists of rules to rewrite a QBF by adding\nand deleting clauses and universal literals that have a certain redundancy\nproperty. To check for this redundancy property in QRAT, propositional unit\npropagation (UP) is applied to the quantifier free, i.e., propositional part of\nthe QBF. We generalize the redundancy property in the QRAT system by QBF\nspecific UP (QUP). QUP extends UP by the universal reduction operation to\neliminate universal literals from clauses. We apply QUP to an abstraction of\nthe QBF where certain universal quantifiers are converted into existential\nones. This way, we obtain a generalization of QRAT we call QRAT+. The\nredundancy property in QRAT+ based on QUP is more powerful than the one in QRAT\nbased on UP. We report on proof theoretical improvements and experimental\nresults to illustrate the benefits of QRAT+ for QBF preprocessing.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 10:51:09 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 10:34:25 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Lonsing", "Florian", ""], ["Egly", "Uwe", ""]]}, {"id": "1804.02929", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and Xavier Parent", "title": "First Experiments with a Flexible Infrastructure for Normative Reasoning", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flexible infrastructure for normative reasoning is outlined. A small-scale\ndemonstrator version of the envisioned system has been implemented in the proof\nassistant Isabelle/HOL by utilising the first authors universal logical\nreasoning approach based on shallow semantical embeddings in meta-logic HOL.\nThe need for such a flexible reasoning infrastructure is motivated and\nillustrated with a contrary-to-duty example scenario selected from the General\nData Protection Regulation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 11:55:22 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Parent", "Xavier", ""]]}, {"id": "1804.02939", "submitter": "Gregory Wilsenach", "authors": "Anuj Dawar and Gregory Wilsenach", "title": "Symmetric Circuits for Rank Logic", "comments": "40 Pages. A conference version of this paper appeared in Computer\n  Science Logic (CSL) 2018. A journal submission is in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-point logic with rank (FPR) is an extension of fixed-point logic with\ncounting (FPC) with operators for computing the rank of a matrix over a finite\nfield. The expressive power of FPR properly extends that of FPC and is\ncontained in PTime, but not known to be properly contained. We give a circuit\ncharacterization for FPR in terms of families of symmetric circuits with rank\ngates, along the lines of that for FPC given by [Anderson and Dawar 2017]. This\nrequires the development of a broad framework of circuits in which the\nindividual gates compute functions that are not symmetric (i.e., invariant\nunder all permutations of their inputs). In the case of FPC, the proof of\nequivalence of circuits and logic rests heavily on the assumption that\nindividual gates compute such symmetric functions and so novel techniques are\nrequired to make this work for FPR.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 12:29:35 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 04:10:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Dawar", "Anuj", ""], ["Wilsenach", "Gregory", ""]]}, {"id": "1804.03011", "submitter": "Christoph Rauch", "authors": "Ji\\v{r}\\'i Adamek and Stefan Milius and Henning Urbat", "title": "A Categorical Approach to Syntactic Monoids", "comments": "arXiv admin note: substantial text overlap with arXiv:1504.02694", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (May 15,\n  2018) lmcs:4505", "doi": "10.23638/LMCS-14(2:9)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The syntactic monoid of a language is generalized to the level of a symmetric\nmonoidal closed category $\\mathcal D$. This allows for a uniform treatment of\nseveral notions of syntactic algebras known in the literature, including the\nsyntactic monoids of Rabin and Scott ($\\mathcal D=$ sets), the syntactic\nordered monoids of Pin ($\\mathcal D =$ posets), the syntactic semirings of\nPol\\'ak ($\\mathcal D=$ semilattices), and the syntactic associative algebras of\nReutenauer ($\\mathcal D$ = vector spaces). Assuming that $\\mathcal D$ is a\ncommutative variety of algebras or ordered algebras, we prove that the\nsyntactic $\\mathcal D$-monoid of a language $L$ can be constructed as a\nquotient of a free $\\mathcal D$-monoid modulo the syntactic congruence of $L$,\nand that it is isomorphic to the transition $\\mathcal D$-monoid of the minimal\nautomaton for $L$ in $\\mathcal D$. Furthermore, in the case where the variety\n$\\mathcal D$ is locally finite, we characterize the regular languages as\nprecisely the languages with finite syntactic $\\mathcal D$-monoids.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 11:55:29 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 11:38:18 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Adamek", "Ji\u0159\u00ed", ""], ["Milius", "Stefan", ""], ["Urbat", "Henning", ""]]}, {"id": "1804.03084", "submitter": "EPTCS", "authors": "Renaud Vilmart (Universit\\'e de Lorraine, CNRS, Inria, LORIA, F 54000\n  Nancy, France)", "title": "A ZX-Calculus with Triangles for Toffoli-Hadamard, Clifford+T, and\n  Beyond", "comments": "In Proceedings QPL 2018, arXiv:1901.09476. Contains Appendix", "journal-ref": "EPTCS 287, 2019, pp. 313-344", "doi": "10.4204/EPTCS.287.18", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a ZX-calculus augmented with triangle nodes which is well-suited\nto reason on the so-called Toffoli-Hadamard fragment of quantum mechanics. We\nprecisely show the form of the matrices it represents, and we provide an\naxiomatisation which makes the language complete for the Toffoli-Hadamard\nquantum mechanics. We extend the language with arbitrary angles and show that\nany true equation involving linear diagrams which constant angles are multiple\nof Pi are derivable. We show that a single axiom is then necessary and\nsufficient to make the language equivalent to the ZX-calculus which is known to\nbe complete for Clifford+T quantum mechanics. As a by-product, it leads to a\nnew and simple complete axiomatisation for Clifford+T quantum mechanics.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 16:21:18 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 13:52:10 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 05:40:28 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Vilmart", "Renaud", "", "Universit\u00e9 de Lorraine, CNRS, Inria, LORIA, F 54000\n  Nancy, France"]]}, {"id": "1804.03121", "submitter": "Mariia Vasileva Mrs", "authors": "Mariia Vasileva and Paolo Zuliani", "title": "Full version: An evaluation of estimation techniques for probabilistic\n  reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate numerically-precise Monte Carlo (MC), Quasi-Monte Carlo (QMC) and\nRandomised Quasi-Monte Carlo (RQMC) methods for computing probabilistic\nreachability in hybrid systems with random parameters. Computing reachability\nprobability amounts to computing (multidimensional) integrals. In particular,\nwe pay attention to QMC methods due to their theoretical benefits in\nconvergence speed with respect to the MC method. The Koksma-Hlawka inequality\nis a standard result that bounds the approximation of an integral by QMC\ntechniques. However, it is not useful in practice because it depends on the\nvariation of the integrand function, which is in general difficult to compute.\nThe question arises whether it is possible to apply statistical or empirical\nmethods for estimating the approximation error. In this paper we compare a\nnumber of interval estimation techniques based on the Central Limit Theorem\n(CLT), and we also introduce a new approach based on the CLT for computing\nconfidence intervals for probability near the borders of the [0,1] interval.\nBased on our analysis, we provide justification for the use of the developed\napproach and suggest usage guidelines for probability estimation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:40:09 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 16:46:43 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Vasileva", "Mariia", ""], ["Zuliani", "Paolo", ""]]}, {"id": "1804.03237", "submitter": "Ezio Bartocci", "authors": "Ezio Bartocci, Roderick Bloem, Dejan Nickovic and Franz Roeck", "title": "A Counting Semantics for Monitoring LTL Specifications over Finite\n  Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of monitoring a Linear Time Logic (LTL) specification\nthat is defined on infinite paths, over finite traces. For example, we may need\nto draw a verdict on whether the system satisfies or violates the property \"p\nholds infinitely often.\" The problem is that there is always a continuation of\na finite trace that satisfies the property and a different continuation that\nviolates it.\n  We propose a two-step approach to address this problem. First, we introduce a\ncounting semantics that computes the number of steps to witness the\nsatisfaction or violation of a formula for each position in the trace. Second,\nwe use this information to make a prediction on inconclusive suffixes. In\nparticular, we consider a good suffix to be one that is shorter than the\nlongest witness for a satisfaction, and a bad suffix to be shorter than or\nequal to the longest witness for a violation. Based on this assumption, we\nprovide a verdict assessing whether a continuation of the execution on the same\nsystem will presumably satisfy or violate the property.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 20:57:35 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Bartocci", "Ezio", ""], ["Bloem", "Roderick", ""], ["Nickovic", "Dejan", ""], ["Roeck", "Franz", ""]]}, {"id": "1804.03453", "submitter": "Nir Piterman", "authors": "Krishnendu Chatterjee and Nir Piterman", "title": "Combinations of Qualitative Winning for Stochastic Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Markov decision processes and turn-based stochastic games with\nparity conditions. There are three qualitative winning criteria, namely, sure\nwinning, which requires all paths must satisfy the condition, almost-sure\nwinning, which requires the condition is satisfied with probability~1, and\nlimit-sure winning, which requires the condition is satisfied with probability\narbitrarily close to~1. We study the combination of these criteria for parity\nconditions, e.g., there are two parity conditions one of which must be won\nsurely, and the other almost-surely. The problem has been studied recently by\nBerthon et.~al for MDPs with combination of sure and almost-sure winning, under\ninfinite-memory strategies, and the problem has been established to be in NP\n$\\cap$ coNP. Even in MDPs there is a difference between finite-memory and\ninfinite-memory strategies. Our main results for combination of sure and\nalmost-sure winning are as follows: (a)~we show that for MDPs with\nfinite-memory strategies the problem lie in NP $\\cap$ coNP; (b)~we show that\nfor turn-based stochastic games the problem is coNP-complete, both for\nfinite-memory and infinite-memory strategies; and (c)~we present algorithmic\nresults for the finite-memory case, both for MDPs and turn-based stochastic\ngames, by reduction to non-stochastic parity games. In addition we show that\nall the above results also carry over to combination of sure and limit-sure\nwinning, and results for all other combinations can be derived from existing\nresults in the literature. Thus we present a complete picture for the study of\ncombinations of qualitative winning criteria for parity conditions in MDPs and\nturn-based stochastic games.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 11:12:42 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Piterman", "Nir", ""]]}, {"id": "1804.03454", "submitter": "Nir Piterman", "authors": "Krishnendu Chatterjee and Nir Piterman", "title": "Coverability: Realizability Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of temporal coverability for realizability and\nsynthesis. Namely, given a language of words that must be covered by a produced\nsystem, how to automatically produce such a system. We consider the case of\ncoverability with no further specifications, where we have to show that the\nnondeterminism of the produced system is sufficient to produce all the words\nrequired in the output language. We show a counting argument on a deterministic\nautomaton representing the language to be covered that allows to produce such a\nsystem. We then turn to the case of coverability with additional specification\nand give a precondition for the existence of a system that produces all\nrequired words and at the same time produces only computations satisfying the\nadditional correctness criterion. We combine our counting argument on the\ndeterministic automaton for the language to be covered with a ranking on the\ndeterministic B\\\"uchi automaton for the correctness criterion.\n  One of the major issues with practical realizability is the interaction\nbetween environment assumptions and system guarantees. In many cases, synthesis\nproduces systems that are vacuous and concentrate on forcing the environment to\nfalsify its assumptions instead of fulfilling their guarantees. Coverability\noffers an alternative approach to tackle this problem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 11:12:49 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Piterman", "Nir", ""]]}, {"id": "1804.03527", "submitter": "Paolo Perrone", "authors": "Tobias Fritz and Paolo Perrone", "title": "Bimonoidal Structure of Probability Monads", "comments": "39 pages, 58 figures, MFPS 2018 conference paper. Fixed minor issue\n  in published version, see footnote 2", "journal-ref": "Electron. Notes Theor. Comput. Sci. 341, 121-149 (2018)", "doi": "10.1016/j.entcs.2018.11.007", "report-no": null, "categories": "math.PR cs.LO math.CT math.QA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a conceptual treatment of the notion of joints, marginals, and\nindependence in the setting of categorical probability. This is achieved by\nendowing the usual probability monads (like the Giry monad) with a monoidal and\nan opmonoidal structure, mutually compatible (i.e. a bimonoidal structure). If\nthe underlying monoidal category is cartesian monoidal, a bimonoidal structure\nis given uniquely by a commutative strength. However, if the underlying\nmonoidal category is not cartesian monoidal, a strength is not enough to\nguarantee all the desired properties of joints and marginals. A bimonoidal\nstructure is then the correct requirement for the more general case.\n  We explain the theory and the operational interpretation, with the help of\nthe graphical calculus for monoidal categories. We give a definition of\nstochastic independence based on the bimonoidal structure, compatible with the\nintuition and with other approaches in the literature for cartesian monoidal\ncategories. We then show as an example that the Kantorovich monad on the\ncategory of complete metric spaces is a bimonoidal monad for a non-cartesian\nmonoidal structure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 13:43:01 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 17:42:30 GMT"}, {"version": "v3", "created": "Wed, 22 Aug 2018 16:12:10 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 16:01:40 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Fritz", "Tobias", ""], ["Perrone", "Paolo", ""]]}, {"id": "1804.03556", "submitter": "Radu Iosif", "authors": "Mnacho Echenim and Radu Iosif and Nicolas Peltier", "title": "The Complexity of Prenex Separation Logic with One Selector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first show that infinite satisfiability can be reduced to finite\nsatisfiability for all prenex formulas of Separation Logic with $k\\geq1$\nselector fields ($\\seplogk{k}$). Second, we show that this entails the\ndecidability of the finite and infinite satisfiability problem for the class of\nprenex formulas of $\\seplogk{1}$, by reduction to the first-order theory of one\nunary function symbol and unary predicate symbols. We also prove that the\ncomplexity is not elementary, by reduction from the first-order theory of one\nunary function symbol. Finally, we prove that the Bernays-Sch\\\"onfinkel-Ramsey\nfragment of prenex $\\seplogk{1}$ formulae with quantifier prefix in the\nlanguage $\\exists^*\\forall^*$ is \\pspace-complete. The definition of a complete\n(hierarchical) classification of the complexity of prenex $\\seplogk{1}$,\naccording to the quantifier alternation depth is left as an open problem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 14:22:25 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 11:41:41 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Echenim", "Mnacho", ""], ["Iosif", "Radu", ""], ["Peltier", "Nicolas", ""]]}, {"id": "1804.03579", "submitter": "Thomas Zeume", "authors": "Gaetano Geck, Artur Ljulin, Sebastian Peter, Jonas Schmidt, Fabian\n  Vehlken, Thomas Zeume", "title": "Introduction to Iltis: An Interactive, Web-Based System for Teaching\n  Logic", "comments": null, "journal-ref": null, "doi": "10.1145/3197091.3197095", "report-no": null, "categories": "cs.CY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic is a foundation for many modern areas of computer science. In\nartificial intelligence, as a basis of database query languages, as well as in\nformal software and hardware verification --- modelling scenarios using logical\nformalisms and inferring new knowledge are important skills for going-to-be\ncomputer scientists. The Iltis project aims at providing a web-based,\ninteractive system that supports teaching logical methods. In particular the\nsystem shall (a) support to learn to model knowledge and to infer new knowledge\nusing propositional logic, modal logic and first-order logic, and (b) provide\nimmediate feedback and support to students. This article presents a\nprototypical system that currently supports the above tasks for propositional\nlogic. First impressions on its use in a second year logic course for computer\nscience students are reported.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 12:44:14 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Geck", "Gaetano", ""], ["Ljulin", "Artur", ""], ["Peter", "Sebastian", ""], ["Schmidt", "Jonas", ""], ["Vehlken", "Fabian", ""], ["Zeume", "Thomas", ""]]}, {"id": "1804.03862", "submitter": "Maciej Bendkowski", "authors": "Maciej Bendkowski and Pierre Lescanne", "title": "Combinatorics of explicit substitutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\lambda\\upsilon$ is an extension of the $\\lambda$-calculus which\ninternalises the calculus of substitutions. In the current paper, we\ninvestigate the combinatorial properties of $\\lambda\\upsilon$ focusing on the\nquantitative aspects of substitution resolution. We exhibit an unexpected\ncorrespondence between the counting sequence for $\\lambda\\upsilon$-terms and\nfamous Catalan numbers. As a by-product, we establish effective sampling\nschemes for random $\\lambda\\upsilon$-terms. We show that typical\n$\\lambda\\upsilon$-terms represent, in a strong sense, non-strict computations\nin the classic $\\lambda$-calculus. Moreover, typically almost all substitutions\nare in fact suspended, i.e. unevaluated, under closures. Consequently, we argue\nthat $\\lambda\\upsilon$ is an intrinsically non-strict calculus of explicit\nsubstitutions. Finally, we investigate the distribution of various redexes\ngoverning the substitution resolution in $\\lambda\\upsilon$ and investigate the\nquantitative contribution of various substitution primitives.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 08:13:14 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Bendkowski", "Maciej", ""], ["Lescanne", "Pierre", ""]]}, {"id": "1804.03922", "submitter": "Wenda Li", "authors": "Wenda Li and Lawrence C. Paulson", "title": "Evaluating Winding Numbers and Counting Complex Roots through Cauchy\n  Indices in Isabelle/HOL", "comments": "32 pages", "journal-ref": "Journal of Automated Reasoning (2019)", "doi": "10.1007/s10817-019-09521-3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex analysis, the winding number measures the number of times a path\n(counter-clockwise) winds around a point, while the Cauchy index can\napproximate how the path winds. We formalise this approximation in the Isabelle\ntheorem prover, and provide a tactic to evaluate winding numbers through Cauchy\nindices. By further combining this approximation with the argument principle,\nwe are able to make use of remainder sequences to effectively count the number\nof complex roots of a polynomial within some domains, such as a rectangular box\nand a half-plane.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 10:57:56 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 12:15:51 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 14:12:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Li", "Wenda", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "1804.03938", "submitter": "Makoto Tatsuta", "authors": "Makoto Tatsuta, Koji Nakazawa, and Daisuke Kimura", "title": "Completeness of Cyclic Proofs for Symbolic Heaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation logic is successful for software verification in both theory and\npractice. Decision procedure for symbolic heaps is one of the key issues. This\npaper proposes a cyclic proof system for symbolic heaps with general form of\ninductive definitions, and shows its soundness and completeness. The decision\nprocedure for entailments of symbolic heaps with inductive definitions is also\ngiven. Decidability for entailments of symbolic heaps with inductive\ndefinitions is an important question. Completeness of cyclic proof systems is\nalso an important question. The results of this paper answer both questions.\nThe decision procedure is feasible since it is nondeterministic\ndouble-exponential time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 11:34:30 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 11:48:20 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tatsuta", "Makoto", ""], ["Nakazawa", "Koji", ""], ["Kimura", "Daisuke", ""]]}, {"id": "1804.04145", "submitter": "Fredrik Dahlqvist", "authors": "Fredrik Dahlqvist and Renato Neves", "title": "Compositional semantics for new paradigms: probabilistic, hybrid and\n  beyond", "comments": "17 pages, proofs in the Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging computational paradigms, such as probabilistic and hybrid\nprogramming, introduce new primitive operations that often need to be combined\nwith classic programming constructs. However, it still remains a challenge to\nprovide a semantics to these features and their combination in a systematic\nmanner. For this reason, we introduce a generic, monadic framework that allows\nus to investigate not only which programming features a given paradigm\nsupports, but also on how it can be extended with new constructs. By applying\nour method to the probabilistic and hybrid case, we list for example all binary\nprogram operations they possess, and show precisely when and if important\naxioms such as commutativity and idempotency hold. Using this framework, we\nalso study the possibility of incorporating notions of failure and\nnon-determinism, and obtain new results on this topic for hybrid and\nprobabilistic programming.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 18:00:34 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Neves", "Renato", ""]]}, {"id": "1804.04346", "submitter": "EPTCS", "authors": "Maike Schwammberger (University of Oldenburg)", "title": "Introducing Liveness into Multi-lane Spatial Logic lane change\n  controllers using UPPAAL", "comments": "In Proceedings SCAV 2018, arXiv:1804.03406", "journal-ref": "EPTCS 269, 2018, pp. 17-31", "doi": "10.4204/EPTCS.269.3", "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With Multi-lane Spatial Logic (MLSL) a powerful approach to formally reason\nabout and prove safety of autonomous traffic manoeuvres was introduced.\nExtended timed automata controllers using MLSL were constructed to commit safe\nlane change manoeuvres on highways. However, the approach has only few\nimplementation and verification results. We thus strenghen the MLSL approach by\nimplementing their lane change controller in UPPAAL and confirming the safety\nof the lane change protocol. We also detect the unlive behaviour of the\noriginal controller and thus extend it to finally verify liveness of the new\nlane change controller.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 06:52:46 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Schwammberger", "Maike", "", "University of Oldenburg"]]}, {"id": "1804.04372", "submitter": "Guy Avni", "authors": "Guy Avni and Thomas A. Henzinger and Rasmus Ibsen-Jensen", "title": "Infinite-Duration Poorman-Bidding Games", "comments": "The full version of a WINE 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two-player games on graphs, the players move a token through a graph to\nproduce an infinite path, which determines the winner or payoff of the game.\nSuch games are central in formal verification since they model the interaction\nbetween a non-terminating system and its environment. We study {\\em bidding\ngames} in which the players bid for the right to move the token. Two bidding\nrules have been defined. In {\\em Richman} bidding, in each round, the players\nsimultaneously submit bids, and the higher bidder moves the token and pays the\nother player. {\\em Poorman} bidding is similar except that the winner of the\nbidding pays the \"bank\" rather than the other player. While poorman\nreachability games have been studied before, we present, for the first time,\nresults on {\\em infinite-duration} poorman games. A central quantity in these\ngames is the {\\em ratio} between the two players' initial budgets. The\nquestions we study concern a necessary and sufficient ratio with which a player\ncan achieve a goal. For reachability objectives, such {\\em threshold ratios}\nare known to exist for both bidding rules. We show that the properties of\npoorman reachability games extend to complex qualitative objectives such as\nparity, similarly to the Richman case. Our most interesting results concern\nquantitative poorman games, namely poorman mean-payoff games, where we\nconstruct optimal strategies depending on the initial ratio, by showing a\nconnection with {\\em random-turn based games}. The connection in itself is\ninteresting, because it does not hold for reachability poorman games. We also\nsolve the complexity problems that arise in poorman bidding games.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 08:28:11 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 11:41:01 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 12:52:06 GMT"}, {"version": "v4", "created": "Mon, 27 Jan 2020 14:44:36 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Avni", "Guy", ""], ["Henzinger", "Thomas A.", ""], ["Ibsen-Jensen", "Rasmus", ""]]}, {"id": "1804.04402", "submitter": "Alexander Weigl", "authors": "Bernhard Beckert and Sarah Grebing and and Alexander Weigl", "title": "Debugging Program Verification Proof Scripts (Tool Paper)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive program verification is characterized by iterations of unfinished\nproof attempts. To support the process of constructing a complete proof, many\ninteractive program verification systems offer a proof scripting language as a\ntext-based way to describe the non-automatic steps in a proof. Such scripting\nlanguages are beneficial, but users spent a lot of effort on inspecting proof\nscripts and the proofs they construct to detect the cause when a proof attempt\nis unsuccessful and leads to unintended proof states. We present an offline and\nreplay debugger to support the user in analyzing proof attempts performed with\nproof scripts. This debugger adapts successful concepts from software debugging\nto the area of proof script debugging. The tool is built on top of KeY, a\nsystem for deductive verification of Java programs. The debugger and its\ngraphical user interface are designed to support program verification in\nparticular, the underlying concepts and the implementation, however, are\nadaptable to other provers and proof tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 09:53:02 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Beckert", "Bernhard", ""], ["Grebing", "Sarah", ""], ["Weigl", "and Alexander", ""]]}, {"id": "1804.04487", "submitter": "Bernd Finkbeiner", "authors": "Florian-Michael Adolf, Peter Faymonville, Bernd Finkbeiner, Sebastian\n  Schirmer, Christoph Torens", "title": "Stream Runtime Monitoring on UAS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aircraft Systems (UAS) with autonomous decision-making capabilities\nare of increasing interest for a wide area of applications such as logistics\nand disaster recovery. In order to ensure the correct behavior of the system\nand to recognize hazardous situations or system faults, we applied stream\nruntime monitoring techniques within the DLR ARTIS (Autonomous Research Testbed\nfor Intelligent System) family of unmanned aircraft. We present our experience\nfrom specification elicitation, instrumentation, offline log-file analysis, and\nonline monitoring on the flight computer on a test rig. The debugging and\nhealth management support through stream runtime monitoring techniques have\nproven highly beneficial for system design and development. At the same time,\nthe project has identified usability improvements to the specification\nlanguage, and has influenced the design of the language.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:55:28 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Adolf", "Florian-Michael", ""], ["Faymonville", "Peter", ""], ["Finkbeiner", "Bernd", ""], ["Schirmer", "Sebastian", ""], ["Torens", "Christoph", ""]]}, {"id": "1804.04607", "submitter": "Anna Philippou", "authors": "Anna Philippou and Kyriaki Psara", "title": "Reversible Computation in Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible computation is an unconventional form of computing where any\nexecuted sequence of operations can be executed in reverse at any point during\ncomputation. It has recently been attracting increasing attention in various\nresearch communities as on the one hand it promises low-power computation and\non the other hand it is inherent or of interest in a variety of applications.\nIn this paper, we propose a reversible approach to Petri nets by introducing\nmachinery and associated operational semantics to tackle the challenges of the\nthree main forms of reversibility, namely, backtracking, causal reversing and\nout-of-causal-order reversing. Our proposal concerns a variation of Petri nets\nwhere tokens are persistent and are distinguished from each other by an\nidentity which allows for transitions to be reversed spontaneously in or out of\ncausal order. Our design decisions are influenced by applications in\nbiochemistry but the methodology can be applied to a wide range of problems\nthat feature reversibility. In particular, to demonstrate the applicability of\nour approach we use an example of a biochemical system and an example of a\ntransaction-processing system both of which naturally embed reversible\nbehaviour.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 11:11:00 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Philippou", "Anna", ""], ["Psara", "Kyriaki", ""]]}, {"id": "1804.04901", "submitter": "Maximilian Weininger", "authors": "Edon Kelmendi, Julia Kr\\\"amer, Jan Kretinsky, Maximilian Weininger", "title": "Value Iteration for Simple Stochastic Games: Stopping Criterion and\n  Learning Algorithm", "comments": "CAV2018", "journal-ref": null, "doi": "10.1007/978-3-319-96145-3_36", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simple stochastic games can be solved by value iteration (VI), which yields a\nsequence of under-approximations of the value of the game. This sequence is\nguaranteed to converge to the value only in the limit. Since no stopping\ncriterion is known, this technique does not provide any guarantees on its\nresults. We provide the first stopping criterion for VI on simple stochastic\ngames. It is achieved by additionally computing a convergent sequence of\nover-approximations of the value, relying on an analysis of the game graph.\nConsequently, VI becomes an anytime algorithm returning the approximation of\nthe value and the current error bound. As another consequence, we can provide a\nsimulation-based asynchronous VI algorithm, which yields the same guarantees,\nbut without necessarily exploring the whole game graph.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 11:56:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kelmendi", "Edon", ""], ["Kr\u00e4mer", "Julia", ""], ["Kretinsky", "Jan", ""], ["Weininger", "Maximilian", ""]]}, {"id": "1804.04967", "submitter": "Moritz Lichter", "authors": "Moritz Lichter and Gert Smolka", "title": "Constructive Analysis of S1S and B\\\"uchi Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study S1S and B\\\"uchi automata in the constructive type theory of the Coq\nproof assistant. For UP semantics (ultimately periodic sequences), we verify\nB\\\"uchi's translation of formulas to automata and thereby establish\ndecidability of S1S constructively. For AS semantics (all sequences), we verify\nB\\\"uchi's translation assuming that sequences over finite semigroups have\nRamseyan factorisations (RF). Assuming RF, UP semantics and AS semantics agree.\nRF is a consequence of Ramsey's theorem and implies the infinite pigeonhole\nprinciple, which is known to be unprovable constructively. We show that each of\nthe following properties holds for UP semantics but is equivalent to RF for AS\nsemantics: excluded middle of formula satisfaction, excluded middle of\nautomaton acceptance, and existence of complement automata.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 14:36:35 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Lichter", "Moritz", ""], ["Smolka", "Gert", ""]]}, {"id": "1804.04968", "submitter": "Martin L\\\"uck", "authors": "Martin L\\\"uck", "title": "On the Complexity of Team Logic and its Two-Variable Fragment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the logic FO(~), the extension of first-order logic with team\nsemantics by unrestricted Boolean negation. It was recently shown\naxiomatizable, but otherwise has not yet received much attention in questions\nof computational complexity.\n  In this paper, we consider its two-variable fragment FO2(~) and prove that\nits satisfiability problem is decidable, and in fact complete for the recently\nintroduced non-elementary class TOWER(poly). Moreover, we classify the\ncomplexity of model checking of FO(~) with respect to the number of variables\nand the quantifier rank, and prove a dichotomy between PSPACE- and\nATIME-ALT(exp, poly)-completeness.\n  To achieve the lower bounds, we propose a translation from modal team logic\nMTL to FO2(~) that extends the well-known standard translation from modal logic\nML to FO2. For the upper bounds, we translate to a fragment of second-order\nlogic.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 14:36:47 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["L\u00fcck", "Martin", ""]]}, {"id": "1804.05001", "submitter": "Tim Quatmann", "authors": "Tim Quatmann and Joost-Pieter Katoen", "title": "Sound Value Iteration", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing reachability probabilities is at the heart of probabilistic model\nchecking. All model checkers compute these probabilities in an iterative\nfashion using value iteration. This technique approximates a fixed point from\nbelow by determining reachability probabilities for an increasing number of\nsteps. To avoid results that are significantly off, variants have recently been\nproposed that converge from both below and above. These procedures require\nstarting values for both sides. We present an alternative that does not require\nthe a priori computation of starting vectors and that converges faster on many\nbenchmarks. The crux of our technique is to give tight and safe bounds - whose\ncomputation is cheap - on the reachability probabilities. Lifting this\ntechnique to expected rewards is trivial for both Markov chains and MDPs.\nExperimental results on a large set of benchmarks show its scalability and\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 15:45:56 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Quatmann", "Tim", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1804.05025", "submitter": "Andrew Reynolds", "authors": "Aina Niemetz, Mathias Preiner, Andrew Reynolds, Clark Barrett, Cesare\n  Tinelli", "title": "On Solving Quantified Bit-Vectors using Invertibility Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for solving quantified bit-vector formulas in\nSatisfiability Modulo Theories (SMT) based on computing symbolic inverses of\nbit-vector operators. We derive conditions that precisely characterize when\nbit-vector constraints are invertible for a representative set of bit-vector\noperators commonly supported by SMT solvers. We utilize syntax-guided synthesis\ntechniques to aid in establishing these conditions and verify them\nindependently by using several SMT solvers. We show that invertibility\nconditions can be embedded into quantifier instantiations using Hilbert choice\nexpressions, and give experimental evidence that a counterexample-guided\napproach for quantifier instantiation utilizing these techniques leads to\nperformance improvements with respect to state-of-the-art solvers for\nquantified bit-vector constraints.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:53:51 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 23:30:29 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Niemetz", "Aina", ""], ["Preiner", "Mathias", ""], ["Reynolds", "Andrew", ""], ["Barrett", "Clark", ""], ["Tinelli", "Cesare", ""]]}, {"id": "1804.05037", "submitter": "Daniel Fremont", "authors": "Daniel J. Fremont and Sanjit A. Seshia", "title": "Reactive Control Improvisation", "comments": "25 pages. Full version of a CAV 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive synthesis is a paradigm for automatically building\ncorrect-by-construction systems that interact with an unknown or adversarial\nenvironment. We study how to do reactive synthesis when part of the\nspecification of the system is that its behavior should be random. Randomness\ncan be useful, for example, in a network protocol fuzz tester whose output\nshould be varied, or a planner for a surveillance robot whose route should be\nunpredictable. However, existing reactive synthesis techniques do not provide a\nway to ensure random behavior while maintaining functional correctness. Towards\nthis end, we generalize the recently-proposed framework of control\nimprovisation (CI) to add reactivity. The resulting framework of reactive\ncontrol improvisation provides a natural way to integrate a randomness\nrequirement with the usual functional specifications of reactive synthesis over\na finite window. We theoretically characterize when such problems are\nrealizable, and give a general method for solving them. For specifications\ngiven by reachability or safety games or by deterministic finite automata, our\nmethod yields a polynomial-time synthesis algorithm. For various other types of\nspecifications including temporal logic formulas, we obtain a polynomial-space\nalgorithm and prove matching PSPACE-hardness results. We show that all of these\nrandomized variants of reactive synthesis are no harder in a\ncomplexity-theoretic sense than their non-randomized counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 17:10:05 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 18:18:07 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Fremont", "Daniel J.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1804.05045", "submitter": "Valery Isaev", "authors": "Valery Isaev", "title": "Morita equivalences between algebraic dependent type theories", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a notion of equivalence between algebraic dependent type theories\nwhich we call Morita equivalence. This notion has a simple syntactic\ndescription and an equivalent description in terms of models of the theories.\nThe category of models of a type theory often carries a natural structure of a\nmodel category. If this holds for the categories of models of two theories,\nthen a map between them is a Morita equivalence if and only if the adjunction\ngenerated by it is a Quillen equivalence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 17:22:19 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 13:59:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Isaev", "Valery", ""]]}, {"id": "1804.05196", "submitter": "Suha Orhun Mutluergil", "authors": "Ahmed Bouajjani, Constantin Enea, Suha Orhun Mutluergil, Serdar\n  Tasiran", "title": "Reasoning About TSO Programs Using Reduction and Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for proving that a program running under the Total Store\nOrdering (TSO) memory model is robust, i.e., all its TSO computations are\nequivalent to computations under the Sequential Consistency (SC) semantics.\nThis method is inspired by Lipton's reduction theory for proving atomicity of\nconcurrent programs. For programs which are not robust, we introduce an\nabstraction mechanism that allows to construct robust programs\nover-approximating their TSO semantics. This enables the use of proof methods\ndesigned for the SC semantics in proving invariants that hold on the TSO\nsemantics of a non-robust program. These techniques have been evaluated on a\nlarge set of benchmarks using the infrastructure provided by CIVL, a generic\ntool for reasoning about concurrent programs under the SC semantics.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 09:37:49 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bouajjani", "Ahmed", ""], ["Enea", "Constantin", ""], ["Mutluergil", "Suha Orhun", ""], ["Tasiran", "Serdar", ""]]}, {"id": "1804.05236", "submitter": "Bas Spitters", "authors": "Lars Birkedal, Ranald Clouston, Bassel Mannaa, Rasmus Ejlers\n  M{\\o}gelberg, Andrew M. Pitts, Bas Spitters", "title": "Modal Dependent Type Theory and Dependent Right Adjoints", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 30 (2020) 118-138", "doi": "10.1017/S0960129519000197", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years we have seen several new models of dependent type theory\nextended with some form of modal necessity operator, including nominal type\ntheory, guarded and clocked type theory, and spatial and cohesive type theory.\nIn this paper we study modal dependent type theory: dependent type theory with\nan operator satisfying (a dependent version of) the K-axiom of modal logic. We\ninvestigate both semantics and syntax. For the semantics, we introduce\ncategories with families with a dependent right adjoint (CwDRA) and show that\nthe examples above can be presented as such. Indeed, we show that any finite\nlimit category with an adjunction of endofunctors gives rise to a CwDRA via the\nlocal universe construction. For the syntax, we introduce a dependently typed\nextension of Fitch-style modal lambda-calculus, show that it can be interpreted\nin any CwDRA, and build a term model. We extend the syntax and semantics with\nuniverses.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 15:13:53 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 10:17:57 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 12:11:43 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Birkedal", "Lars", ""], ["Clouston", "Ranald", ""], ["Mannaa", "Bassel", ""], ["M\u00f8gelberg", "Rasmus Ejlers", ""], ["Pitts", "Andrew M.", ""], ["Spitters", "Bas", ""]]}, {"id": "1804.05507", "submitter": "S. Akshay", "authors": "S. Akshay, Supratik Chakraborty, Shubham Goel, Sumith Kulal, and\n  Shetal Shah", "title": "What's hard about Boolean Functional Synthesis", "comments": "Full version of a conference paper to appear in CAV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a relational specification between Boolean inputs and outputs, the goal\nof Boolean functional synthesis is to synthesize each output as a function of\nthe inputs such that the specification is met. In this paper, we first show\nthat unless some hard conjectures in complexity theory are falsified, Boolean\nfunctional synthesis must necessarily generate exponential-sized Skolem\nfunctions, thereby requiring exponential time, in the worst-case. Given this\ninherent hardness, what does one do to solve the problem? We present a\ntwo-phase algorithm for Boolean functional synthesis, where the first phase is\nefficient both in terms of time and sizes of synthesized functions, and solves\nan overwhelming majority of benchmarks. To explain this surprisingly good\nperformance, we provide a sufficient condition under which the first phase must\nproduce exact correct answers. When this condition fails, the second phase\nbuilds upon the result of the first phase, possibly requiring exponential time\nand generating exponential-sized functions in the worst-case. Detailed\nexperimental evaluation shows our algorithm to perform better than\nstate-of-the-art techniques for a majority of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 05:29:21 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 11:10:50 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Akshay", "S.", ""], ["Chakraborty", "Supratik", ""], ["Goel", "Shubham", ""], ["Kulal", "Sumith", ""], ["Shah", "Shetal", ""]]}, {"id": "1804.05539", "submitter": "Edwin James Beggs", "authors": "E.J. Beggs and J.V. Tucker", "title": "Analogue-digital systems and the modular decomposition of physical\n  behaviour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a fresh look at analogue-digital systems focussing on their physical\nbehaviour. We model a general analogue-digital system as a physical process\ncontrolled by an algorithm by viewing the physical process as physical oracle\nto the algorithm, generalising the notion of Turing. We develop a theoretical\nframework for the specification and analysis of such systems that combines five\nsemantical notions: actual physical behaviour, measured behaviour, predicted\nbehaviour, computed behaviour and exceptional behaviour. Next, we consider the\nmore general and applicable situation of complex processes that exhibit several\ndistinct modes of physical behaviour. Thus, for their design, a set of\nmathematical models may be needed, each model having its own domain of\napplication and representing a particular mode of behaviour or operation of\nphysical reality with its own physical oracle. The models may be of disparate\nkinds and, furthermore, not all physical modes may even have a reliable model.\nWe address the questions: How do we specify algorithms and software that\nmonitor or govern a complex physical situation with many physical modes? How do\nwe specify a portfolio of modes, and the computational problem of transitioning\nfrom using one mode to another mode as physical behaviour changes? We propose a\ngeneral definition of an analogue-digital system with modes, and show how any\ndiverse set of modes, with or without models, can be bound together, and how\nthe transitions between modes can be determined, by constructing a data type\nand mode selection functions. We illustrate the ideas of physical modes and our\ntheory by reflecting on simple examples, including driverless racing cars.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 08:10:46 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Beggs", "E. J.", ""], ["Tucker", "J. V.", ""]]}, {"id": "1804.05578", "submitter": "Claudia Faggian", "authors": "Claudia Faggian", "title": "Probabilistic Rewriting and Asymptotic Behaviour: on Termination and\n  Unique Normal Forms", "comments": "Extended version of the conference paper FSCD 2019, International\n  Conference on Formal Structures for Computation and Deduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a mature body of work supports the study of rewriting systems, abstract\ntools for Probabilistic Rewriting are still limited. In this paper we study the\nquestion of \\emph{uniqueness of the result} (unique limit distribution), and\ndevelop a set of proof techniques to analyze and compare \\emph{reduction\nstrategies}. The goal is to have tools to support the \\emph{operational}\nanalysis of \\emph{probabilistic} calculi (such as probabilistic lambda-calculi)\nwhose evaluation is also non-deterministic, in the sense that different\nreductions are possible.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 09:52:06 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 19:23:08 GMT"}, {"version": "v3", "created": "Fri, 4 May 2018 21:38:05 GMT"}, {"version": "v4", "created": "Sat, 17 Nov 2018 14:47:41 GMT"}, {"version": "v5", "created": "Tue, 26 Mar 2019 22:23:22 GMT"}, {"version": "v6", "created": "Fri, 10 May 2019 11:22:49 GMT"}, {"version": "v7", "created": "Mon, 2 Mar 2020 22:48:40 GMT"}, {"version": "v8", "created": "Fri, 19 Feb 2021 22:38:32 GMT"}, {"version": "v9", "created": "Mon, 7 Jun 2021 12:43:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Faggian", "Claudia", ""]]}, {"id": "1804.05797", "submitter": "Christoph Rauch", "authors": "Davide Sangiorgi, Xian Xu", "title": "Trees from Functions as Processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (August\n  27, 2018) lmcs:4785", "doi": "10.23638/LMCS-14(3:11)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Levy-Longo Trees and Bohm Trees are the best known tree structures on the\n{\\lambda}-calculus. We give general conditions under which an encoding of the\n{\\lambda}-calculus into the {\\pi}-calculus is sound and complete with respect\nto such trees. We apply these conditions to various encodings of the\ncall-by-name {\\lambda}-calculus, showing how the two kinds of tree can be\nobtained by varying the behavioural equivalence adopted in the {\\pi}-calculus\nand/or the encoding.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:13:54 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 11:01:17 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Sangiorgi", "Davide", ""], ["Xu", "Xian", ""]]}, {"id": "1804.05880", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer", "title": "Uniform Substitution for Differential Game Logic", "comments": null, "journal-ref": "Automated Reasoning, 9th International Joint Conference, IJCAR\n  2018", "doi": "10.1007/978-3-319-94205-6_15", "report-no": null, "categories": "cs.LO cs.GT cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a uniform substitution calculus for differential game\nlogic (dGL). Church's uniform substitutions substitute a term or formula for a\nfunction or predicate symbol everywhere. After generalizing them to\ndifferential game logic and allowing for the substitution of hybrid games for\ngame symbols, uniform substitutions make it possible to only use axioms instead\nof axiom schemata, thereby substantially simplifying implementations. Instead\nof subtle schema variables and soundness-critical side conditions on the\noccurrence patterns of logical variables to restrict infinitely many axiom\nschema instances to sound ones, the resulting axiomatization adopts only a\nfinite number of ordinary dGL formulas as axioms, which uniform substitutions\ninstantiate soundly. This paper proves soundness and completeness of uniform\nsubstitutions for the monotone modal logic dGL. The resulting axiomatization\nadmits a straightforward modular implementation of dGL in theorem provers.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 18:22:55 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Platzer", "Andr\u00e9", ""]]}, {"id": "1804.05926", "submitter": "Jonni Virtema", "authors": "Flavio Ferrarotti, Jan Van den Bussche, and Jonni Virtema", "title": "Expressivity within second-order transitive-closure logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order transitive-closure logic, SO(TC), is an expressive declarative\nlanguage that captures the complexity class PSPACE. Already its monadic\nfragment, MSO(TC), allows the expression of various NP-hard and even\nPSPACE-hard problems in a natural and elegant manner. As SO(TC) offers an\nattractive framework for expressing properties in terms of declaratively\nspecified computations, it is interesting to understand the expressivity of\ndifferent features of the language. This paper focuses on the fragment MSO(TC),\nas well on the purely existential fragment SO(2TC)(E); in 2TC, the TC operator\nbinds only tuples of relation variables. We establish that, with respect to\nexpressive power, SO(2TC)(E) collapses to existential first-order logic. In\naddition we study the relationship of MSO(TC) to an extension of MSO(TC) with\ncounting features (CMSO(TC)) as well as to order-invariant MSO. We show that\nthe expressive powers of CMSO(TC) and MSO(TC) coincide. Moreover we establish\nthat, over unary vocabularies, MSO(TC) strictly subsumes order-invariant MSO.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:35:26 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Ferrarotti", "Flavio", ""], ["Bussche", "Jan Van den", ""], ["Virtema", "Jonni", ""]]}, {"id": "1804.05989", "submitter": "Bishoksan Kafle", "authors": "Bishoksan Kafle, John P. Gallagher, Graeme Gange, Peter Schachte,\n  Harald Sondergaard, Peter J. Stuckey", "title": "An iterative approach to precondition inference using constrained Horn\n  clauses", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for automatic inference of conditions on the initial\nstates of a program that guarantee that the safety assertions in the program\nare not violated. Constrained Horn clauses (CHCs) are used to model the program\nand assertions in a uniform way, and we use standard abstract interpretations\nto derive an over-approximation of the set of unsafe initial states. The\nprecondition then is the constraint corresponding to the complement of that\nset, under-approximating the set of safe initial states. This idea of\ncomplementation is not new, but previous attempts to exploit it have suffered\nfrom the loss of precision. Here we develop an iterative specialisation\nalgorithm to give more precise, and in some cases optimal safety conditions.\nThe algorithm combines existing transformations, namely constraint\nspecialisation, partial evaluation and a trace elimination transformation. The\nlast two of these transformations perform polyvariant specialisation, leading\nto disjunctive constraints which improve precision. The algorithm is\nimplemented and tested on a benchmark suite of programs from the literature in\nprecondition inference and software verification competitions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 00:13:24 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kafle", "Bishoksan", ""], ["Gallagher", "John P.", ""], ["Gange", "Graeme", ""], ["Schachte", "Peter", ""], ["Sondergaard", "Harald", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "1804.06130", "submitter": "Luigi Santocanale", "authors": "Luigi Santocanale (LIS), Silvio Ghilardi", "title": "Ruitenburg's Theorem via Duality and Bounded Bisimulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given intuitionistic propositional formula A and a propositional\nvariable x occurring in it, define the infinite sequence of formulae { A \\_i |\ni$\\ge$1} by letting A\\_1 be A and A\\_{i+1} be A(A\\_i/x). Ruitenburg's Theorem\n[8] says that the sequence { A \\_i } (modulo logical equivalence) is ultimately\nperiodic with period 2, i.e. there is N $\\ge$ 0 such that A N+2\n$\\leftrightarrow$ A N is provable in intuitionistic propositional calculus. We\ngive a semantic proof of this theorem, using duality techniques and bounded\nbisimulations ranks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 09:38:43 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Santocanale", "Luigi", "", "LIS"], ["Ghilardi", "Silvio", ""]]}, {"id": "1804.06168", "submitter": "Martin Zimmermann", "authors": "Sven Schewe, Alexander Weinert, Martin Zimmermann", "title": "Parity Games with Weights", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August\n  23, 2019) lmcs:5705", "doi": "10.23638/LMCS-15(3:20)2019", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantitative extensions of parity games have recently attracted significant\ninterest. These extensions include parity games with energy and payoff\nconditions as well as finitary parity games and their generalization to parity\ngames with costs. Finitary parity games enjoy a special status among these\nextensions, as they offer a native combination of the qualitative and\nquantitative aspects in infinite games: The quantitative aspect of finitary\nparity games is a quality measure for the qualitative aspect, as it measures\nthe limit superior of the time it takes to answer an odd color by a larger even\none. Finitary parity games have been extended to parity games with costs, where\neach transition is labeled with a nonnegative weight that reflects the costs\nincurred by taking it. We lift this restriction and consider parity games with\ncosts with arbitrary integer weights.\n  We show that solving such games is in NP $\\cap$ coNP, the signature\ncomplexity for games of this type. We also show that the protagonist has\nfinite-state winning strategies, and provide tight pseudo-polynomial bounds for\nthe memory he needs to win the game. Naturally, the antagonist may need\ninfinite memory to win. Moreover, we present tight bounds on the quality of\nwinning strategies for the protagonist.\n  Furthermore, we investigate the problem of determining, for a given threshold\n$b$, whether the protagonist has a strategy of quality at most $b$ and show\nthis problem to be EXPTIME-complete. The protagonist inherits the necessity of\nexponential memory for implementing such strategies from the special case of\nfinitary parity games.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 11:24:16 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 17:14:32 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 10:58:04 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2019 09:33:28 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Schewe", "Sven", ""], ["Weinert", "Alexander", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1804.06170", "submitter": "Stefan Kiefer", "authors": "Stefan Kiefer", "title": "On Computing the Total Variation Distance of Hidden Markov Models", "comments": "Technical report for an ICALP'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove results on the decidability and complexity of computing the total\nvariation distance (equivalently, the $L_1$-distance) of hidden Markov models\n(equivalently, labelled Markov chains). This distance measures the difference\nbetween the distributions on words that two hidden Markov models induce. The\nmain results are: (1) it is undecidable whether the distance is greater than a\ngiven threshold; (2) approximation is #P-hard and in PSPACE.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 11:28:52 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kiefer", "Stefan", ""]]}, {"id": "1804.06531", "submitter": "Jan Gorzny", "authors": "Jan Gorzny, Ezequiel Postan, Bruno Woltzenlogel Paleo", "title": "Partial Regularization of First-Order Resolution Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolution and superposition are common techniques which have seen widespread\nuse with propositional and first-order logic in modern theorem provers. In\nthese cases, resolution proof production is a key feature of such tools;\nhowever, the proofs that they produce are not necessarily as concise as\npossible. For propositional resolution proofs, there are a wide variety of\nproof compression techniques. There are fewer techniques for compressing\nfirst-order resolution proofs generated by automated theorem provers. This\npaper describes an approach to compressing first-order logic proofs based on\nlifting proof compression ideas used in propositional logic to first-order\nlogic. One method for propositional proof compression is partial\nregularization, which removes an inference $\\eta$ when it is redundant in the\nsense that its pivot literal already occurs as the pivot of another inference\nin every path from $\\eta$ to the root of the proof. This paper describes the\ngeneralization of the partial-regularization algorithm\nRecyclePivotsWithIntersection [10] from propositional logic to first-order\nlogic. The generalized algorithm performs partial regularization of resolution\nproofs containing resolution and factoring inferences with unification. An\nempirical evaluation of the generalized algorithm and its combinations with the\npreviously lifted GreedyLinearFirstOrderLowerUnits algorithm [12] is also\npresented\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 02:29:10 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Gorzny", "Jan", ""], ["Postan", "Ezequiel", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1804.06612", "submitter": "Constantin Enea", "authors": "Ahmed Bouajjani, Constantin Enea, Kailiang Ji, Shaz Qadeer", "title": "On the Completeness of Verifying Message Passing Programs under Bounded\n  Asynchrony", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of verifying message passing programs, defined as a\nset of parallel processes communicating through unbounded FIFO buffers. We\nintroduce a bounded analysis that explores a special type of computations,\ncalled k-synchronous. These computations can be viewed as (unbounded) sequences\nof interaction phases, each phase allowing at most k send actions (by different\nprocesses), followed by a sequence of receives corresponding to sends in the\nsame phase. We give a procedure for deciding k-synchronizability of a program,\ni.e., whether every computation is equivalent (has the same happens-before\nrelation) to one of its k-synchronous computations. We also show that\nreachability over k-synchronous computations and checking k-synchronizability\nare both PSPACE-complete. Furthermore, we introduce a class of programs called\n{\\em flow-bounded} for which the problem of deciding whether there exists a k>0\nfor which the program is k-synchronizable, is decidable.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 09:11:10 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bouajjani", "Ahmed", ""], ["Enea", "Constantin", ""], ["Ji", "Kailiang", ""], ["Qadeer", "Shaz", ""]]}, {"id": "1804.06687", "submitter": "Bassel Mannaa", "authors": "Bassel Mannaa, Rasmus Ejlers M{\\o}gelberg", "title": "The clocks they are adjunctions:Denotational semantics for Clocked Type\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clocked Type Theory (CloTT) is a type theory for guarded recursion useful for\nprogramming with coinductive types, allowing productivity to be encoded in\ntypes, and for reasoning about advanced programming language features using an\nabstract form of step-indexing. CloTT has previously been shown to enjoy a\nnumber of syntactic properties including strong normalisation, canonicity and\ndecidability of type checking. In this paper we present a denotational\nsemantics for CloTT useful, e.g., for studying future extensions of CloTT with\nconstructions such as path types.\n  The main challenge for constructing this model is to model the notion of\nticks used in CloTT for coinductive reasoning about coinductive types. We build\non a category previously used to model guarded recursion, but in this category\nthere is no object of ticks, so tick-assumptions in a context can not be\nmodelled using standard tools. Instead we show how ticks can be modelled using\nadjoint functors, and how to model the tick constant using a semantic\nsubstitution.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:36:50 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Mannaa", "Bassel", ""], ["M\u00f8gelberg", "Rasmus Ejlers", ""]]}, {"id": "1804.06689", "submitter": "Mauro Ferrari", "authors": "Camillo Fiorentini and Mauro Ferrari", "title": "Duality between unprovability and provability in forward proof-search\n  for Intuitionistic Propositional Logic", "comments": null, "journal-ref": null, "doi": "10.1145/3372299", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse method is a saturation based theorem proving technique; it relies\non a forward proof-search strategy and can be applied to cut-free calculi\nenjoying the subformula property. Here we apply this method to derive the\nunprovability of a goal formula G in Intuitionistic Propositional Logic. To\nthis aim we design a forward calculus FRJ(G) for Intuitionistic unprovability\nwhich is prone to constructively ascertain the unprovability of a formula G by\nproviding a concise countermodel for it; in particular we prove that the\ngenerated countermodels have minimal height. Moreover, we clarify the role of\nthe saturated database obtained as result of a failed proof-search in FRJ(G) by\nshowing how to extract from such a database a derivation witnessing the\nIntuitionistic validity of the goal.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:39:08 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fiorentini", "Camillo", ""], ["Ferrari", "Mauro", ""]]}, {"id": "1804.06894", "submitter": "Carsten Lutz", "authors": "Andre Hernich, Carsten Lutz, Fabio Papacchini, Frank Wolter", "title": "Dichotomies in Ontology-Mediated Querying with the Guarded Fragment", "comments": null, "journal-ref": null, "doi": "10.1145/3034786.3056108", "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of ontology-mediated querying when ontologies are\nformulated in the guarded fragment of first-order logic (GF). Our general aim\nis to classify the data complexity on the level of ontologies where query\nevaluation w.r.t. an ontology O is considered to be in PTime if all (unions of\nconjunctive) queries can be evaluated in PTime w.r.t. O and coNP-hard if at\nleast one query is coNP-hard w.r.t. O. We identify several large and relevant\nfragments of GF that enjoy a dichotomy between PTime and coNP, some of them\nadditionally admitting a form of counting. In fact, almost all ontologies in\nthe BioPortal repository fall into these fragments or can easily be rewritten\nto do so. We then establish a variation of Ladner's Theorem on the existence of\nNP-intermediate problems and use this result to show that for other fragments,\nthere is provably no such dichotomy. Again for other fragments (such as full\nGF), establishing a dichotomy implies the Feder-Vardi conjecture on the\ncomplexity of constraint satisfaction problems. We also link these results to\nDatalog-rewritability and study the decidability of whether a given ontology\nenjoys PTime query evaluation, presenting both positive and negative results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 19:49:15 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hernich", "Andre", ""], ["Lutz", "Carsten", ""], ["Papacchini", "Fabio", ""], ["Wolter", "Frank", ""]]}, {"id": "1804.07074", "submitter": "EPTCS", "authors": "Jules Hedges (University of Oxford)", "title": "Backward Induction for Repeated Games", "comments": "In Proceedings MSFP 2018, arXiv:1807.03732", "journal-ref": "EPTCS 275, 2018, pp. 35-52", "doi": "10.4204/EPTCS.275.5", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method of backward induction for computing approximate subgame\nperfect Nash equilibria of infinitely repeated games with discounted payoffs.\nThis uses the selection monad transformer, combined with the searchable set\nmonad viewed as a notion of 'topologically compact' nondeterminism, and a\nsimple model of computable real numbers. This is the first application of\nEscard\\'o and Oliva's theory of higher-order sequential games to games of\nimperfect information, in which (as well as its mathematical elegance) lazy\nevaluation does nontrivial work for us compared with a traditional\ngame-theoretic analysis. Since a full theoretical understanding of this method\nis lacking (and appears to be very hard), we consider this an 'experimental'\npaper heavily inspired by theoretical ideas. We use the famous Iterated\nPrisoner's Dilemma as a worked example.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 10:42:16 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 12:14:09 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Hedges", "Jules", "", "University of Oxford"]]}, {"id": "1804.07099", "submitter": "Vernon Asuncion Va", "authors": "Vernon Asuncion, Yan Zhang, Heng Zhang, Yun Bai and Weisheng Si", "title": "Loop Restricted Existential Rules and First-order Rewritability for\n  Query Answering", "comments": "Full paper version of extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ontology-based data access (OBDA), the classical database is enhanced with\nan ontology in the form of logical assertions generating new intensional\nknowledge. A powerful form of such logical assertions is the tuple-generating\ndependencies (TGDs), also called existential rules, where Horn rules are\nextended by allowing existential quantifiers to appear in the rule heads. In\nthis paper we introduce a new language called loop restricted (LR) TGDs\n(existential rules), which are TGDs with certain restrictions on the loops\nembedded in the underlying rule set. We study the complexity of this new\nlanguage. We show that the conjunctive query answering (CQA) under the LR TGDs\nis decid- able. In particular, we prove that this language satisfies the\nso-called bounded derivation-depth prop- erty (BDDP), which implies that the\nCQA is first-order rewritable, and its data complexity is in AC0 . We also\nprove that the combined complexity of the CQA is EXPTIME complete, while the\nlanguage membership is PSPACE complete. Then we extend the LR TGDs language to\nthe generalised loop restricted (GLR) TGDs language, and prove that this class\nof TGDs still remains to be first-order rewritable and properly contains most\nof other first-order rewritable TGDs classes discovered in the literature so\nfar.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:45:14 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 01:48:26 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Asuncion", "Vernon", ""], ["Zhang", "Yan", ""], ["Zhang", "Heng", ""], ["Bai", "Yun", ""], ["Si", "Weisheng", ""]]}, {"id": "1804.07173", "submitter": "Jochen Hoenicke", "authors": "Jochen Hoenicke and Tanja Schindler", "title": "Efficient Interpolation for the Theory of Arrays", "comments": "long version of the paper at IJCAR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques for Craig interpolation for the quantifier-free fragment\nof the theory of arrays are inefficient for computing sequence and tree\ninterpolants: the solver needs to run for every partitioning $(A, B)$ of the\ninterpolation problem to avoid creating $AB$-mixed terms. We present a new\napproach using Proof Tree Preserving Interpolation and an array solver based on\nWeak Equivalence on Arrays. We give an interpolation algorithm for the lemmas\nproduced by the array solver. The computed interpolants have worst-case\nexponential size for extensionality lemmas and worst-case quadratic size\notherwise. We show that these bounds are strict in the sense that there are\nlemmas with no smaller interpolants. We implemented the algorithm and show that\nthe produced interpolants are useful to prove memory safety for C programs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:53:37 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 13:22:09 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Hoenicke", "Jochen", ""], ["Schindler", "Tanja", ""]]}, {"id": "1804.07274", "submitter": "Cristina Feier", "authors": "David Carral, Cristina Feier, Pascal Hitzler", "title": "A Practical Acyclicity Notion for Query Answering over Horn-SRIQ\n  Ontologies", "comments": null, "journal-ref": "The Semantic Web - ISWC 2016 - 15th International Semantic Web\n  Conference, Kobe, Japan. Proceedings, Part I, volume 9981 of LNCS, 70-85,\n  October 2016. Springer", "doi": "10.1007/978-3-319-46523-4_5", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjunctive query answering over expressive Horn Description Logic ontologies\nis a relevant and challenging problem which, in some cases, can be addressed by\napplication of the chase algorithm. In this paper, we define a novel acyclicity\nnotion which provides a sufficient condition for termination of the restricted\nchase over Horn-SRIQ TBoxes. We show that this notion generalizes most of the\nexisting acyclicity conditions (both theoretically and empirically).\nFurthermore, this new acyclicity notion gives rise to a very efficient\nreasoning procedure. We provide evidence for this by providing a\nmaterialization based reasoner for acyclic ontologies which outperforms other\nstate-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:57:25 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Carral", "David", ""], ["Feier", "Cristina", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1804.07277", "submitter": "John Longley", "authors": "John Longley", "title": "Bar recursion is not computable via iteration", "comments": "43 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the bar recursion operators of Spector and Kohlenbach,\nconsidered as third-order functionals acting on total arguments, are not\ncomputable in Goedel's System T plus minimization, which we show to be\nequivalent to a programming language with a higher-order iteration construct.\nThe main result is formulated so as to imply the non-definability of bar\nrecursion in T + min within a variety of partial and total models, for instance\nthe Kleene-Kreisel continuous functionals. The paper thus supplies proofs of\nsome results stated in the book by Longley and Normann.\n  The proof of the main theorem makes serious use of the theory of nested\nsequential procedures (also known as PCF Boehm trees), and proceeds by showing\nthat bar recursion cannot be represented by any sequential procedure within\nwhich the tree of nested function applications is well-founded.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 17:15:07 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Longley", "John", ""]]}, {"id": "1804.07602", "submitter": "Li Zhang", "authors": "Li Zhang", "title": "Choice Revision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choice revision is a sort of non-prioritized multiple revision, in which the\nagent partially accepts the new information represented by a set of sentences.\nWe investigate the construction of choice revision based on a new approach to\nbelief change called descriptor revision. We prove that each of two variants of\nchoice revision based on such construction is axiomatically characterized with\na set of plausible postulates, assuming that the object language is finite.\nFurthermore, we introduce an alternative modelling for choice revision, which\nis based on a type of relation on sets of sentences, named multiple\nbelievability relation. We show without assuming a finite language that choice\nrevision constructed from such relations is axiomatically characterized with\nthe same sets of postulates proposed for the choice revision based on\ndescriptor revision, whenever the relations satisfy certain rationality\nconditions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 13:28:20 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 18:59:15 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Zhang", "Li", ""]]}, {"id": "1804.07603", "submitter": "Thomas Wright", "authors": "Thomas Wright, Ian Stark", "title": "The Bond-Calculus: A Process Algebra for Complex Biological Interaction\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the bond-calculus, a process algebra for modelling biological and\nchemical systems featuring nonlinear dynamics, multiway interactions, and\ndynamic bonding of agents. Mathematical models based on differential equations\nhave been instrumental in modelling and understanding the dynamics of\nbiological systems. Quantitative process algebras aim to build higher level\ndescriptions of biological systems, capturing the agents and interactions\nunderlying their behaviour, and can be compiled down to a range of lower level\nmathematical models. The bond-calculus builds upon the work of Kwiatkowski,\nBanks, and Stark's continuous pi-calculus by adding a flexible multiway\ncommunication operation based on affinity patterns and general kinetic laws. We\ndevelop a compositional semantics based on vector fields and linear operators,\nwhich we use to define the time evolution of this system. This enables\nsimulation and analysis via differential equation generation or stochastic\nsimulation. Finally, we apply our framework to an existing biological model:\nKuznetsov's classic model of tumour immune interactions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 00:28:05 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 13:24:58 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Wright", "Thomas", ""], ["Stark", "Ian", ""]]}, {"id": "1804.07626", "submitter": "Jens Seeber", "authors": "Filippo Bonchi, Jens Seeber, Pawel Sobocinski", "title": "Graphical Conjunctive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Calculus of Conjunctive Queries (CCQ) has foundational status in database\ntheory. A celebrated theorem of Chandra and Merlin states that CCQ query\ninclusion is decidable. Its proof transforms logical formulas to graphs: each\nquery has a natural model - a kind of graph - and query inclusion reduces to\nthe existence of a graph homomorphism between natural models.\n  We introduce the diagrammatic language Graphical Conjunctive Queries (GCQ)\nand show that it has the same expressivity as CCQ. GCQ terms are string\ndiagrams, and their algebraic structure allows us to derive a sound and\ncomplete axiomatisation of query inclusion, which turns out to be exactly\nCarboni and Walters' notion of cartesian bicategory of relations. Our\ncompleteness proof exploits the combinatorial nature of string diagrams as\n(certain cospans of) hypergraphs: Chandra and Merlin's insights inspire a\ntheorem that relates such cospans with spans. Completeness and decidability of\nthe (in)equational theory of GCQ follow as a corollary. Categorically speaking,\nour contribution is a model-theoretic completeness theorem of free cartesian\nbicategories (on a relational signature) for the category of sets and\nrelations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 14:05:10 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Bonchi", "Filippo", ""], ["Seeber", "Jens", ""], ["Sobocinski", "Pawel", ""]]}, {"id": "1804.07703", "submitter": "Martin Bromberger", "authors": "Martin Bromberger", "title": "A Reduction from Unbounded Linear Mixed Arithmetic Problems into Bounded\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a combination of the Mixed-Echelon-Hermite transformation and the\nDouble-Bounded Reduction for systems of linear mixed arithmetic that preserve\nsatisfiability and can be computed in polynomial time. Together, the two\ntransformations turn any system of linear mixed constraints into a bounded\nsystem, i.e., a system for which termination can be achieved easily. Existing\napproaches for linear mixed arithmetic, e.g., branch-and-bound and cuts from\nproofs, only explore a finite search space after application of our two\ntransformations. Instead of generating a priori bounds for the variables, e.g.,\nas suggested by Papadimitriou, unbounded variables are eliminated through the\ntwo transformations. The transformations orient themselves on the structure of\nan input system instead of computing a priori (over-)approximations out of the\navailable constants. Experiments provide further evidence to the efficiency of\nthe transformations in practice. We also present a polynomial method for\nconverting certificates of (un)satisfiability from the transformed to the\noriginal system.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 16:13:24 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Bromberger", "Martin", ""]]}, {"id": "1804.07799", "submitter": "Arne Meier", "authors": "Arne Meier", "title": "Enumeration in Incremental FPT-Time", "comments": "improved proof of Thm. 24", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the relationship of parametrised enumeration\ncomplexity classes defined by Creignou et al. (MFCS 2013). Specifically, we\nintroduce two hierarchies (IncFPTa and CapIncFPTa) of enumeration complexity\nclasses for incremental fpt-time in terms of exponent slices and show how they\ninterleave. Furthermore, we define several parametrised function classes and,\nin particular, introduce the parametrised counterpart of the class of\nnondeterministic multivalued functions with values that are polynomially\nverifiable and guaranteed to exist, TFNP, known from Megiddo and Papadimitriou\n(TCS 1991). We show that TF(para-NP) collapsing to F(FPT) is equivalent to\nOutputFPT coinciding with IncFPT. This result is in turn connected to a\ncollapse in the classical function setting and eventually to the collapse of\nIncP and OutputP which proves the first direct connection of classical to\nparametrised enumeration.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 19:01:36 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 19:28:55 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 09:13:13 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Meier", "Arne", ""]]}, {"id": "1804.07815", "submitter": "Lorenzo Clemente", "authors": "Lorenzo Clemente", "title": "Decidability of Timed Communicating Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the reachability problem for networks of timed communicating\nprocesses. Each process is a timed automaton communicating with other processes\nby exchanging messages over unbounded FIFO channels. Messages carry clocks\nwhich are checked at the time of transmission and reception with suitable\ntiming constraints. Each automaton can only access its set of local clocks and\nmessage clocks of sent/received messages. Time is dense and all clocks evolve\nat the same rate. Our main contribution is a complete characterisation of\ndecidable and undecidable communication topologies generalising and unifying\nprevious work. From a technical point of view, we use quantifier elimination\nand a reduction to counter automata with registers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 20:23:05 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Clemente", "Lorenzo", ""]]}, {"id": "1804.07832", "submitter": "Antonin Delpeuch", "authors": "Antonin Delpeuch and Jamie Vicary", "title": "Normalization for planar string diagrams and a quadratic equivalence\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the graphical calculus of planar string diagrams, equality is generated by\nexchange moves, which swap the heights of adjacent vertices. We show that left-\nand right-handed exchanges each give strongly normalizing rewrite strategies\nfor connected string diagrams. We use this result to give a linear-time\nsolution to the equivalence problem in the connected case, and a quadratic\nsolution in the general case. We also give a stronger proof of the Joyal-Street\ncoherence theorem, settling Selinger's conjecture on recumbent isotopy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:34:21 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 16:40:49 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 14:14:21 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Delpeuch", "Antonin", ""], ["Vicary", "Jamie", ""]]}, {"id": "1804.07860", "submitter": "Lawrence Paulson", "authors": "Lawrence C. Paulson", "title": "Formalising Mathematics In Simple Type Theory", "comments": "Submitted to a volume on the Foundations of Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the considerable interest in new dependent type theories, simple type\ntheory (which dates from 1940) is sufficient to formalise serious topics in\nmathematics. This point is seen by examining formal proofs of a theorem about\nstereographic projections. A formalisation using the HOL Light proof assistant\nis contrasted with one using Isabelle/HOL. Harrison's technique for formalising\nEuclidean spaces is contrasted with an approach using Isabelle/HOL's axiomatic\ntype classes. However, every formal system can be outgrown, and mathematics\nshould be formalised with a view that it will eventually migrate to a new\nformalism.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 23:26:01 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Paulson", "Lawrence C.", ""]]}, {"id": "1804.07951", "submitter": "Adnan Rashid", "authors": "Adnan Rashid, Umair Siddique and Osman Hasan", "title": "Formal Verification of Platoon Control Strategies", "comments": "15 pages, Software Engineering and Formal Methods (SEFM-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in autonomous driving, vehicle-to-vehicle communication\nand smart traffic controllers have provided a hope to realize platoon formation\nof vehicles. The main benefits of vehicle platooning include improved safety,\nenhanced highway utility, efficient fuel consumption and reduced highway\naccidents. One of the central components of reliable and efficient platoon\nformation is the underlying control strategies, e.g., constant spacing,\nvariable spacing and dynamic headway. In this paper, we provide a generic\nformalization of platoon control strategies in higher-order logic. In\nparticular, we formally verify the stability constraints of various strategies\nusing the libraries of multivariate calculus and Laplace transform within the\nsound core of HOL Light proof assistant. We also illustrate the use of verified\nstability theorems to develop runtime monitors for each controller, which can\nbe used to automatically detect the violation of stability constraints in a\nruntime execution or a logged trace of the platoon controller. Our proposed\nformalization has two main advantages: 1) it provides a framework to combine\nboth static (theorem proving) and dynamic (runtime) verification approaches for\nplatoon controllers, and 2) it is inline with the industrial standards, which\nexplicitly recommend the use of formal methods for functional safety, e.g.,\nautomotive ISO 26262.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 11:56:40 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Rashid", "Adnan", ""], ["Siddique", "Umair", ""], ["Hasan", "Osman", ""]]}, {"id": "1804.08105", "submitter": "Luca Roversi", "authors": "Luca Roversi", "title": "Subatomic systems need not be subatomic", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subatomic systems were recently introduced to identify the structural\nprinciples underpinning the normalization of proofs. \"Subatomic\" means that we\ncan reformulate logical systems in accordance with two principles. Their atomic\nformulas become instances of sub-atoms, non-commutative self-dual relations\namong logical constants, and their rules are derivable by means of a unique\ndeductive scheme, the medial shape. One of the results is that the\ncut-elimination of subatomic systems implies the cut-elimination of every\nstandard system we can represent sub-atomically.\n  We here introduce Subatomic systems-1.1. They relax and widen the properties\nthat the sub-atoms of Subatomic systems can satisfy while maintaining the use\nof the medial shape as their only inference principle. Since sub-atoms can\noperate directly on variables we introduce P. The cut-elimination of P is a\ncorollary of the cut-elimination that we prove for Subatomic systems-1.1.\nMoreover, P is sound and complete with respect to the clone at the top of\nPost's Lattice. I.e. P proves all and only the tautologies that contain\nconjunctions, disjunctions and projections. So, P extends Propositional logic\nwithout any encoding of its atoms as sub-atoms of P.\n  This shows that the logical principles underpinning Subatomic systems also\napply outside the sub-atomic level which they are conceived to work at. We\nreinforce this point of view by introducing the set R of medial shapes. The\nformulas that the rules in R deal with belong to the union of two disjoint\nclones of Post's Lattice. The SAT-problem of the first clone is in P-Time. The\nSAT-problem of the other is NP-Time complete. So, R and the proof technology of\nSubatomic systems could help to identify proof-theoretical properties that\nhighlight the phase transition from P-Time to NP-Time complete satisfiability.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 12:32:41 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Roversi", "Luca", ""]]}, {"id": "1804.08308", "submitter": "Stefan Ciobaca", "authors": "\\c{S}tefan Ciob\\^ac\\u{a} and Dorel Lucanu", "title": "A Coinductive Approach to Proving Reachability Properties in Logically\n  Constrained Term Rewriting Systems", "comments": "Extended version of IJCAR 2018 article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a sound and complete coinductive proof system for reachability\nproperties in transition systems generated by logically constrained term\nrewriting rules over an order-sorted signature modulo builtins. A key feature\nof the calculus is a circularity proof rule, which allows to obtain finite\nrepresentations of the infinite coinductive proofs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 09:43:47 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Ciob\u00e2c\u0103", "\u015etefan", ""], ["Lucanu", "Dorel", ""]]}, {"id": "1804.08373", "submitter": "Sergue\\\"i Lenglet", "authors": "Dariusz Biernacki, Sergue\\\"i Lenglet, Piotr Polesiuk", "title": "Bisimulations for Delimited-Control Operators", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 24,\n  2019) lmcs:5508", "doi": "10.23638/LMCS-15(2:18)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a comprehensive study of the behavioral theory of an untyped\n$\\lambda$-calculus extended with the delimited-control operators shift and\nreset. To that end, we define a contextual equivalence for this calculus, that\nwe then aim to characterize with coinductively defined relations, called\nbisimilarities. We consider different styles of bisimilarities (namely\napplicative, normal-form, and environmental) within a unifying framework, and\nwe give several examples to illustrate their respective strengths and\nweaknesses. We also discuss how to extend this work to other delimited-control\noperators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:41:54 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 15:31:35 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 08:20:52 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 08:42:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Biernacki", "Dariusz", ""], ["Lenglet", "Sergue\u00ef", ""], ["Polesiuk", "Piotr", ""]]}, {"id": "1804.08443", "submitter": "David Warren", "authors": "David S. Warren", "title": "Top-down and Bottom-up Evaluation Procedurally Integrated", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018, 16 pages,\n  LaTeX, 1 PDF figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how XSB combines top-down and bottom-up computation\nthrough the mechanisms of variant tabling and subsumptive tabling with\nabstraction, respectively.\n  It is well known that top-down evaluation of logical rules in Prolog has a\nprocedural interpretation as recursive procedure invocation (Kowalski 1986).\nTabling adds the intuition of short-circuiting redundant computations (Warren\n1992) .This paper shows how to introduce into tabled logic program evaluation a\nbottom-up component, whose procedural intuition is the initialization of a data\nstructure, in which a relation is initially computed and filled, on first\ndemand, and then used throughout the remainder of a larger computation for\nefficient lookup. This allows many Prolog programs to be expressed fully\ndeclaratively, programs which formerly required procedural features, such as\nassert, to be made efficient.\n  This paper is under consideration for acceptance in \"Theory and Practice of\nLogic Programming (TPLP)\".\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:00:41 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Warren", "David S.", ""]]}, {"id": "1804.08480", "submitter": "Carmine Dodaro", "authors": "Mario Alviano, Carmine Dodaro, Matti J\\\"arvisalo, Marco Maratea,\n  Alessandro Previti", "title": "Cautious reasoning in ASP via minimal models and unsatisfiable cores", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018. 18 pages,\n  LaTeX, 4 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a logic-based knowledge representation\nframework, supporting---among other reasoning modes---the central task of query\nanswering. In the propositional case, query answering amounts to computing\ncautious consequences of the input program among the atoms in a given set of\ncandidates, where a cautious consequence is an atom belonging to all stable\nmodels. Currently, the most efficient algorithms either iteratively verify the\nexistence of a stable model of the input program extended with the complement\nof one candidate, where the candidate is heuristically selected, or introduce a\nclause enforcing the falsity of at least one candidate, so that the solver is\nfree to choose which candidate to falsify at any time during the computation of\na stable model. This paper introduces new algorithms for the computation of\ncautious consequences, with the aim of driving the solver to search for stable\nmodels discarding more candidates. Specifically, one of such algorithms\nenforces minimality on the set of true candidates, where different notions of\nminimality can be used, and another takes advantage of unsatisfiable cores\ncomputation. The algorithms are implemented in WASP, and experiments on\nbenchmarks from the latest ASP competitions show that the new algorithms\nperform better than the state of the art. (Under consideration for acceptance\nin TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:47:21 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Alviano", "Mario", ""], ["Dodaro", "Carmine", ""], ["J\u00e4rvisalo", "Matti", ""], ["Maratea", "Marco", ""], ["Previti", "Alessandro", ""]]}, {"id": "1804.08488", "submitter": "Carmine Dodaro", "authors": "Mario Alviano, Carmine Dodaro, Marco Maratea", "title": "Shared aggregate sets in answer set programming", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 19 pages,\n  LaTeX, 2 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregates are among the most frequently used linguistic extensions of answer\nset programming. The result of an aggregation may introduce new constants\nduring the instantiation of the input program, a feature known as value\ninvention. When the aggregation involves literals whose truth value is\nundefined at instantiation time, modern grounders introduce several instances\nof the aggregate, one for each possible interpretation of the undefined\nliterals. This paper introduces new data structures and techniques to handle\nsuch cases, and more in general aggregations on the same aggregate set\nidentified in the ground program in input. The proposed solution reduces the\nmemory footprint of the solver without sacrificing efficiency. On the contrary,\nthe performance of the solver may improve thanks to the addition of some simple\nentailed clauses which are not easily discovered otherwise, and since redundant\ncomputation is avoided during propagation. Empirical evidence of the potential\nimpact of the proposed solution is given. (Under consideration for acceptance\nin TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 15:06:58 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Alviano", "Mario", ""], ["Dodaro", "Carmine", ""], ["Maratea", "Marco", ""]]}, {"id": "1804.08555", "submitter": "Nils Vortmeier", "authors": "Samir Datta, Anish Mukherjee, Nils Vortmeier, Thomas Zeume", "title": "Reachability and Distances under Multiple Changes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it was shown that the transitive closure of a directed graph can be\nupdated using first-order formulas after insertions and deletions of single\nedges in the dynamic descriptive complexity framework by Dong, Su, and Topor,\nand Patnaik and Immerman. In other words, Reachability is in DynFO.\n  In this article we extend the framework to changes of multiple edges at a\ntime, and study the Reachability and Distance queries under these changes. We\nshow that the former problem can be maintained in DynFO$(+, \\times)$ under\nchanges affecting O($\\frac{\\log n}{\\log \\log n}$) nodes, for graphs with $n$\nnodes. If the update formulas may use a majority quantifier then both\nReachability and Distance can be maintained under changes that affect O($\\log^c\nn$) nodes, for fixed $c \\in \\mathbb{N}$. Some preliminary results towards\nshowing that distances are in DynFO are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 16:44:12 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Datta", "Samir", ""], ["Mukherjee", "Anish", ""], ["Vortmeier", "Nils", ""], ["Zeume", "Thomas", ""]]}, {"id": "1804.08674", "submitter": "AnneMarie Borg", "authors": "AnneMarie Borg", "title": "Equipping sequent-based argumentation with defeasible assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many expert and everyday reasoning contexts it is very useful to reason on\nthe basis of defeasible assumptions. For instance, if the information at hand\nis incomplete we often use plausible assumptions, or if the information is\nconflicting we interpret it as consistent as possible. In this paper\nsequent-based argumentation, a form of logical argumentation in which arguments\nare represented by a sequent, is extended to incorporate assumptions. The\nresulting assumptive framework is general, in that some other approaches to\nreasoning with assumptions can adequately be represented in it. To exemplify\nthis, we show that assumption-based argumentation can be expressed in\nassumptive sequent-based argumentation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:10:51 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Borg", "AnneMarie", ""]]}, {"id": "1804.08744", "submitter": "Luca Laurenti", "authors": "Luca Bortolussi, Luca Cardelli, Marta Kwiatkowska, and Luca Laurenti", "title": "Central Limit Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider probabilistic model checking for continuous-time Markov chains\n(CTMCs) induced from Stochastic Reaction Networks (SRNs) against a fragment of\nContinuous Stochastic Logic (CSL) extended with reward operators. Classical\nnumerical algorithms for CSL model checking based on uniformisation are limited\nto finite CTMCs and suffer from the state sapce explosion problem. On the other\nhand, approximate techniques such as mean-field approximations and simulations\ncombined with statistical inference are more scalable, but can be time\nconsuming and do not support the full expressiveness of CSL. In this paper we\nemploy a continuous-space approximation of the CTMC in terms of a Gaussian\nprocess based on the Central Limit Approximation (CLA), also known as the\nLinear Noise Approximation (LNA), whose solution requires solving a number of\ndifferential equations that is quadratic in the number of species and\nindependent of the population size. We then develop efficient and scalable\napproximate model checking algorithms on the resulting Gaussian process, where\nwe restrict the target regions for probabilistic reachability to convex\npolytopes. This allows us to derive an abstraction in terms of a\ntime-inhomogeneous discrete-time Markov chain (DTMC), whose dimension is\nindependent of the number of species, on which model checking is performed.\nUsing results from probability theory, we prove the convergence in distribution\nof our algorithms to the corresponding measures on the original CTMC. We\nimplement the techniques and, on a set of examples, demonstrate that they allow\nus to overcome the state space explosion problem, while still correctly\ncharacterizing the stochastic behaviour of the system. Our methods can be used\nfor formal analysis of a wide range of distributed stochastic systems,\nincluding biochemical systems, sensor networks and population protocols.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:27:07 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bortolussi", "Luca", ""], ["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""], ["Laurenti", "Luca", ""]]}, {"id": "1804.08834", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Measuring and Computing Database Inconsistency via Repairs", "comments": "Submission as short paper; to appear in Proc. Scalable Uncertainty\n  Management, SUM 2018. Abstract and keywords added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic numerical measure of inconsistency of a database with\nrespect to a set of integrity constraints. It is based on an abstract repair\nsemantics. A particular inconsistency measure associated to cardinality-repairs\nis investigated; and we show that it can be computed via answer-set programs.\n  Keywords: Integrity constraints in databases, inconsistent databases,\ndatabase repairs, inconsistency measure.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 04:04:27 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 01:50:28 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2018 20:42:04 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "1804.08855", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (PROTHEO)", "title": "Higher-order dependency pairs", "comments": null, "journal-ref": "Eighth International Workshop on Termination - WST 2006, Aug 2006,\n  Seattle, United States. 2006", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arts and Giesl proved that the termination of a first-order rewrite system\ncan be reduced to the study of its \"dependency pairs\". We extend these results\nto rewrite systems on simply typed lambda-terms by using Tait's computability\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 06:25:39 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "PROTHEO"]]}, {"id": "1804.08883", "submitter": "Thorsten Wissmann", "authors": "Thomas Place, Varun Ramanathan, Pascal Weil", "title": "Covering and separation for logical fragments with modular predicates", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 8,\n  2019) lmcs:5441", "doi": "10.23638/LMCS-15(2:11)2019", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For every class $\\mathscr{C}$ of word languages, one may associate a decision\nproblem called $\\mathscr{C}$-separation. Given two regular languages, it asks\nwhether there exists a third language in $\\mathscr{C}$ containing the first\nlanguage, while being disjoint from the second one. Usually, finding an\nalgorithm deciding $\\mathscr{C}$-separation yields a deep insight on\n$\\mathscr{C}$.\n  We consider classes defined by fragments of first-order logic. Given such a\nfragment, one may often build a larger class by adding more predicates to its\nsignature. In the paper, we investigate the operation of enriching signatures\nwith modular predicates. Our main theorem is a generic transfer result for this\nconstruction. Informally, we show that when a logical fragment is equipped with\na signature containing the successor predicate, separation for the stronger\nlogic enriched with modular predicates reduces to separation for the original\nlogic. This result actually applies to a more general decision problem, called\nthe covering problem.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 08:03:58 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 17:11:53 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 08:12:33 GMT"}, {"version": "v4", "created": "Fri, 3 May 2019 08:09:26 GMT"}, {"version": "v5", "created": "Tue, 7 May 2019 11:16:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Place", "Thomas", ""], ["Ramanathan", "Varun", ""], ["Weil", "Pascal", ""]]}, {"id": "1804.08917", "submitter": "Ian Cassar", "authors": "Ian Cassar, Adrian Francalanza, Luca Aceto and Anna Ingolfsdottir", "title": "Developing Theoretical Foundations for Runtime Enforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous reliance on software systems increases the need for ensuring\nthat systems behave correctly and are well protected against security risks.\nRuntime enforcement is a dynamic analysis technique that utilizes software\nmonitors to check the runtime behaviour of a software system with respect to a\ncorrectness specification. Whenever the runtime behaviour of the monitored\nsystem is about to deviate from the specification (either due to a programming\nbug or a security hijack attack), the monitors apply enforcement techniques to\nprevent this deviation.\n  Current Runtime Enforcement techniques require that the correctness\nspecification defines the behaviour of the enforcement monitor itself. This\nburdens the specifier with not only having to define property that needs to be\nenforced, but also with having to specify how this should be enforced at\nruntime; we thus relieve the specifier from this burden by resorting to a\nhighly expressive logic. Using a logic we allow the specifier to define the\ncorrectness specification as a logic formula from which we can automatically\nsynthesise the appropriate enforcement monitor.\n  Highly expressive logics can, however, permit for defining a wide variety of\nformulae, some of which cannot actually be enforced correctly at runtime. We\nthus study the enforceability of Hennessy Milner Logic with Recursion for which\nwe identify a subset that allows for defining enforceable formulae. This allows\nus to define a synthesis function that translates enforceable formulae into\nenforcement monitors. As our monitors are meant to ensure the correct behaviour\nof the monitored system, it is imperative that they work correctly themselves.\nWe thus study formal definitions that allow us to ensure that our enforcement\nmonitors behave correctly.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 09:19:35 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 17:00:21 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Cassar", "Ian", ""], ["Francalanza", "Adrian", ""], ["Aceto", "Luca", ""], ["Ingolfsdottir", "Anna", ""]]}, {"id": "1804.08924", "submitter": "Guillermo P\\'erez", "authors": "Jan K\\v{r}et\\'insk\\'y, Guillermo A. P\\'erez, Jean-Fran\\c{c}ois Raskin", "title": "Learning-Based Mean-Payoff Optimization in an Unknown MDP under\n  Omega-Regular Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the problem of maximizing the mean-payoff value with high\nprobability while satisfying a parity objective in a Markov decision process\n(MDP) with unknown probabilistic transition function and unknown reward\nfunction. Assuming the support of the unknown transition function and a lower\nbound on the minimal transition probability are known in advance, we show that\nin MDPs consisting of a single end component, two combinations of guarantees on\nthe parity and mean-payoff objectives can be achieved depending on how much\nmemory one is willing to use. (i) For all $\\epsilon$ and $\\gamma$ we can\nconstruct an online-learning finite-memory strategy that almost-surely\nsatisfies the parity objective and which achieves an $\\epsilon$-optimal mean\npayoff with probability at least $1 - \\gamma$. (ii) Alternatively, for all\n$\\epsilon$ and $\\gamma$ there exists an online-learning infinite-memory\nstrategy that satisfies the parity objective surely and which achieves an\n$\\epsilon$-optimal mean payoff with probability at least $1 - \\gamma$. We\nextend the above results to MDPs consisting of more than one end component in a\nnatural way. Finally, we show that the aforementioned guarantees are tight,\ni.e. there are MDPs for which stronger combinations of the guarantees cannot be\nensured.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 09:35:27 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 12:04:19 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 07:54:50 GMT"}, {"version": "v4", "created": "Thu, 23 Aug 2018 15:24:36 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1804.08982", "submitter": "Qisheng Wang", "authors": "Qisheng Wang and Mingsheng Ying", "title": "Quantum B\\\"uchi Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a notion of quantum B\\\"uchi automaton (QBA for short) with\ntwo different acceptance conditions for {\\omega}-words: non-disturbing and\ndisturbing. Several pumping lemmas are established for QBAs. The relationship\nbetween the {\\omega}-languages accepted by QBAs and those accepted by classical\nB\\\"uchi automata are clarified with the help of the pumping lemmas. The closure\nproperties of the languages accepted by QBAs are studied in the probable,\nalmost sure and threshold semantics. The decidability of the emptiness problem\nfor the languages accepted by QBAs is proved using the Tarski-Seidenberg\nelimination.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 12:23:49 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Wang", "Qisheng", ""], ["Ying", "Mingsheng", ""]]}, {"id": "1804.09007", "submitter": "Emanuele De Angelis", "authors": "Emanuele De Angelis (1), Fabio Fioravanti (1), Alberto Pettorossi (2),\n  Maurizio Proietti (3) ((1) DEC, University G. D'Annunzio of Chieti-Pescara,\n  Pescara, Italy, (2) DICII, University of Rome Tor Vergata, Roma, Italy, (3)\n  CNR-IASI, Roma, Italy)", "title": "Solving Horn Clauses on Inductive Data Types Without Induction", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018. 22 pages,\n  LaTeX", "journal-ref": "Theory and Practice of Logic Programming, 18(3-4), 2018, 452-469", "doi": "10.1017/S1471068418000157", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of verifying the satisfiability of Constrained Horn\nClauses (CHCs) based on theories of inductively defined data structures, such\nas lists and trees. We propose a transformation technique whose objective is\nthe removal of these data structures from CHCs, hence reducing their\nsatisfiability to a satisfiability problem for CHCs on integers and booleans.\nWe propose a transformation algorithm and identify a class of clauses where it\nalways succeeds. We also consider an extension of that algorithm, which\ncombines clause transformation with reasoning on integer constraints. Via an\nexperimental evaluation we show that our technique greatly improves the\neffectiveness of applying the Z3 solver to CHCs. We also show that our\nverification technique based on CHC transformation followed by CHC solving, is\ncompetitive with respect to CHC solvers extended with induction. This paper is\nunder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:20:25 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["De Angelis", "Emanuele", ""], ["Fioravanti", "Fabio", ""], ["Pettorossi", "Alberto", ""], ["Proietti", "Maurizio", ""]]}, {"id": "1804.09098", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling and Robert Harper", "title": "Guarded Computational Type Theory", "comments": "To appear in LICS 2018", "journal-ref": null, "doi": "10.1145/3209108.3209153", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nakano's later modality can be used to specify and define recursive functions\nwhich are causal or synchronous; in concert with a notion of clock variable, it\nis possible to also capture the broader class of productive (co)programs. Until\nnow, it has been difficult to combine these constructs with dependent types in\na way that preserves the operational meaning of type theory and admits a\nhierarchy of universes. We present an operational account of guarded dependent\ntype theory with clocks called Guarded Computational Type Theory, featuring a\nnovel clock intersection connective that enjoys the clock irrelevance\nprinciple, as well as a predicative hierarchy of universes which does not\nrequire any indexing in clock contexts. Guarded Computational Type Theory is\nsimultaneously a programming language with a rich specification logic, as well\nas a computational metalanguage that can be used to develop semantics of other\nlanguages and logics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:29:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sterling", "Jonathan", ""], ["Harper", "Robert", ""]]}, {"id": "1804.09341", "submitter": "S. Akshay", "authors": "S. Akshay, Blaise Genest and Nikhil Vyas", "title": "Distribution-based objectives for Markov Decision Processes", "comments": "An extended abstract of this paper has been accepted in the\n  conference LICS'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distribution-based objectives for Markov Decision Processes\n(MDP). This class of objectives gives rise to an interesting trade-off between\nfull and partial information. As in full observation, the strategy in the MDP\ncan depend on the state of the system, but similar to partial information, the\nstrategy needs to account for all the states at the same time. In this paper,\nwe focus on two safety problems that arise naturally in this context, namely,\nexistential and universal safety. Given an MDP A and a closed and convex\npolytope H of probability distributions over the states of A, the existential\nsafety problem asks whether there exists some distribution d in H and a\nstrategy of A, such that starting from d and repeatedly applying this strategy\nkeeps the distribution forever in H. The universal safety problem asks whether\nfor all distributions in H, there exists such a strategy of A which keeps the\ndistribution forever in H. We prove that both problems are decidable, with\ntight complexity bounds: we show that existential safety is PTIME-complete,\nwhile universal safety is co-NP-complete. Further, we compare these results\nwith existential and universal safety problems for Rabin's probabilistic\nfinite-state automata (PFA), the subclass of Partially Observable MDPs which\nhave zero observation. Compared to MDPs, strategies of PFAs are not\nstate-dependent. In sharp contrast to the PTIME result, we show that\nexistential safety for PFAs is undecidable, with H having closed and open\nboundaries. On the other hand, it turns out that the universal safety for PFAs\nis decidable in EXPTIME, with a co-NP lower bound. Finally, we show that an\nalternate representation of the input polytope allows us to improve the\ncomplexity of universal safety for MDPs and PFAs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 04:37:56 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Akshay", "S.", ""], ["Genest", "Blaise", ""], ["Vyas", "Nikhil", ""]]}, {"id": "1804.09408", "submitter": "Miko{\\l}aj Boja\\'nczyk", "authors": "Mikolaj Bojanczyk", "title": "Two monads for graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An introduction to algebras for graphs, based on Courcelle's algebras of\nhyperedge replacement and vertex replacement. The paper uses monad notation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:52:32 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Bojanczyk", "Mikolaj", ""]]}, {"id": "1804.09447", "submitter": "Lidia Tendera", "authors": "Wies{\\l}aw Szwast, Lidia Tendera", "title": "On the satisfiability problem for fragments of the two-variable logic\n  with one transitive relation", "comments": "arXiv admin note: text overlap with arXiv:1707.05558 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the satisfiability problem for the two-variable first-order logic\nover structures with one transitive relation. % We show that the problem is\ndecidable in 2-NExpTime for the fragment consisting of formulas where\nexistential quantifiers are guarded by transitive atoms. As this fragment\nenjoys neither the finite model nor the tree model property, to show\ndecidability we introduce novel model construction technique based on the\ninfinite Ramsey theorem.\n  We also point out why the technique is not sufficient to obtain decidability\nfor the full two-variable logic with one transitive relation, hence contrary to\nour previous claim, [FO$^2$ with one transitive relation is decidable, STACS\n2013: 317-328], the status of the latter problem remains open.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 09:28:59 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 11:13:04 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 09:48:40 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Szwast", "Wies\u0142aw", ""], ["Tendera", "Lidia", ""]]}, {"id": "1804.09473", "submitter": "Mark Kaminski", "authors": "Mark Kaminski, Bernardo Cuenca Grau, Egor V. Kostylev, Boris Motik,\n  Ian Horrocks", "title": "Stratified Negation in Limit Datalog Programs", "comments": "14 pages; full version of a paper accepted at IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been an increasing interest in declarative data analysis,\nwhere analytic tasks are specified using a logical language, and their\nimplementation and optimisation are delegated to a general-purpose query\nengine. Existing declarative languages for data analysis can be formalised as\nvariants of logic programming equipped with arithmetic function symbols and/or\naggregation, and are typically undecidable. In prior work, the language of\n$\\mathit{limit\\ programs}$ was proposed, which is sufficiently powerful to\ncapture many analysis tasks and has decidable entailment problem. Rules in this\nlanguage, however, do not allow for negation. In this paper, we study an\nextension of limit programs with stratified negation-as-failure. We show that\nthe additional expressive power makes reasoning computationally more demanding,\nand provide tight data complexity bounds. We also identify a fragment with\ntractable data complexity and sufficient expressivity to capture many relevant\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 10:40:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kaminski", "Mark", ""], ["Grau", "Bernardo Cuenca", ""], ["Kostylev", "Egor V.", ""], ["Motik", "Boris", ""], ["Horrocks", "Ian", ""]]}, {"id": "1804.09705", "submitter": "Thomas Sturm", "authors": "Hoon Hong, Thomas Sturm", "title": "Positive Solutions of Systems of Signed Parametric Polynomial\n  Inequalities", "comments": null, "journal-ref": "Proc. CASC 2018, LNCS 11077, pp.238-253, Springer 2018", "doi": "10.1007/978-3-319-99639-4_17", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider systems of strict multivariate polynomial inequalities over the\nreals. All polynomial coefficients are parameters ranging over the reals, where\nfor each coefficient we prescribe its sign. We are interested in the existence\nof positive real solutions of our system for all choices of coefficients\nsubject to our sign conditions. We give a decision procedure for the existence\nof such solutions. In the positive case our procedure yields a parametric\npositive solution as a rational function in the coefficients. Our framework\nallows to reformulate heuristic subtropical approaches for non-parametric\nsystems of polynomial inequalities that have been recently used in qualitative\nbiological network analysis and, independently, in satisfiability modulo theory\nsolving. We apply our results to characterize the incompleteness of those\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 17:53:25 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Hong", "Hoon", ""], ["Sturm", "Thomas", ""]]}, {"id": "1804.09746", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Sabrina Ouazzani", "title": "Cheap Non-standard Analysis and Computability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non standard analysis is an area of Mathematics dealing with notions of\ninfinitesimal and infinitely large numbers, in which many statements from\nclassical analysis can be expressed very naturally. Cheap non-standard analysis\nintroduced by Terence Tao in 2012 is based on the idea that considering that a\nproperty holds eventually is sufficient to give the essence of many of its\nstatements. This provides constructivity but at some (acceptable) price. We\nconsider computability in cheap non-standard analysis. We prove that many\nconcepts from computable analysis as well as several concepts from\ncomputability can be very elegantly and alternatively presented in this\nframework. It provides a dual view and dual proofs to several statements\nalready known in these fields.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 18:36:17 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 22:07:06 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Bournez", "Olivier", ""], ["Ouazzani", "Sabrina", ""]]}, {"id": "1804.09822", "submitter": "Vladimir Zamdzhiev", "authors": "Bert Lindenhovius, Michael Mislove, Vladimir Zamdzhiev", "title": "Enriching a Linear/Non-linear Lambda Calculus: A Programming Language\n  for String Diagrams", "comments": "To appear in LICS 2018", "journal-ref": null, "doi": "10.1145/3209108.3209196", "report-no": null, "categories": "cs.LO cs.PL math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear/non-linear (LNL) models, as described by Benton, soundly model a LNL\nterm calculus and LNL logic closely related to intuitionistic linear logic.\nEvery such model induces a canonical enrichment that we show soundly models a\nLNL lambda calculus for string diagrams, introduced by Rios and Selinger (with\nprimary application in quantum computing). Our abstract treatment of this\nlanguage leads to simpler concrete models compared to those presented so far.\nWe also extend the language with general recursion and prove soundness.\nFinally, we present an adequacy result for the diagram-free fragment of the\nlanguage which corresponds to a modified version of Benton and Wadler's adjoint\ncalculus with recursion.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:34:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Lindenhovius", "Bert", ""], ["Mislove", "Michael", ""], ["Zamdzhiev", "Vladimir", ""]]}, {"id": "1804.09970", "submitter": "Erisa Karafili", "authors": "Erisa Karafili, Matteo Cristani, and Luca Vigan\\`o", "title": "A Formal Approach to Analyzing Cyber-Forensics Evidence", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-99073-6_14", "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The frequency and harmfulness of cyber-attacks are increasing every day, and\nwith them also the amount of data that the cyber-forensics analysts need to\ncollect and analyze. In this paper, we propose a formal analysis process that\nallows an analyst to filter the enormous amount of evidence collected and\neither identify crucial information about the attack (e.g., when it occurred,\nits culprit, its target) or, at the very least, perform a pre-analysis to\nreduce the complexity of the problem in order to then draw conclusions more\nswiftly and efficiently. We introduce the Evidence Logic EL for representing\nsimple and derived pieces of evidence from different sources. We propose a\nprocedure, based on monotonic reasoning, that rewrites the pieces of evidence\nwith the use of tableau rules, based on relations of trust between sources and\nthe reasoning behind the derived evidence, and yields a consistent set of\npieces of evidence. As proof of concept, we apply our analysis process to a\nconcrete cyber-forensics case study.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 10:10:46 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 15:15:51 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 10:27:34 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Karafili", "Erisa", ""], ["Cristani", "Matteo", ""], ["Vigan\u00f2", "Luca", ""]]}, {"id": "1804.10004", "submitter": "Aleksy Schubert", "authors": "Aleksy Schubert and Pawe{\\l} Urzyczyn", "title": "First-order answer set programming as constructive proof search", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages, LaTeX\n  (arXiv:1804.10004)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an interpretation of the first-order answer set programming\n(FOASP) in terms of intuitionistic proof theory. It is obtained by two\npolynomial translations between FOASP and the bounded-arity fragment of the\nSigma_1 level of the Mints hierarchy in first-order intuitionistic logic. It\nfollows that Sigma_1 formulas using predicates of fixed arity (in particular\nunary) is of the same strength as FOASP. Our construction reveals a close\nsimilarity between constructive provability and stable entailment, or\nequivalently, between the construction of an answer set and an intuitionistic\nrefutation. This paper is under consideration for publication in Theory and\nPractice of Logic Programming\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 11:49:01 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 11:38:23 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Schubert", "Aleksy", ""], ["Urzyczyn", "Pawe\u0142", ""]]}, {"id": "1804.10076", "submitter": "Benedikt Bollig", "authors": "Benedikt Bollig, Marie Fortin, Paul Gastin", "title": "It Is Easy to Be Wise After the Event: Communicating Finite-State\n  Machines Capture First-Order Logic with \"Happened Before\"", "comments": "Full version of CONCUR'18 paper:\n  http://dx.doi.org/10.4230/LIPIcs.CONCUR.2018.7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message sequence charts (MSCs) naturally arise as executions of communicating\nfinite-state machines (CFMs), in which finite-state processes exchange messages\nthrough unbounded FIFO channels. We study the first-order logic of MSCs,\nfeaturing Lamport's happened-before relation. We introduce a star-free version\nof propositional dynamic logic (PDL) with loop and converse. Our main results\nstate that (i) every first-order sentence can be transformed into an equivalent\nstar-free PDL sentence (and conversely), and (ii) every star-free PDL sentence\ncan be translated into an equivalent CFM. This answers an open question and\nsettles the exact relation between CFMs and fragments of monadic second-order\nlogic. As a byproduct, we show that first-order logic over MSCs has the\nthree-variable property.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 14:16:57 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 07:28:03 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Bollig", "Benedikt", ""], ["Fortin", "Marie", ""], ["Gastin", "Paul", ""]]}, {"id": "1804.10185", "submitter": "Antti Kuusisto", "authors": "Antti Kuusisto and Carsten Lutz", "title": "Weighted model counting beyond two-variable logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was recently shown by van den Broeck at al. that the symmetric weighted\nfirst-order model counting problem (WFOMC) for sentences of two-variable logic\nFO2 is in polynomial time, while it is Sharp-P_1 complete for some\nFO3-sentences. We extend the result for FO2 in two independent directions: to\nsentences of the form \"phi and \\forall\\exists^=1 psi\" with phi and psi in FO2,\nand to sentences formulated in the uniform one-dimensional fragment of FO, a\nrecently introduced extension of two-variable logic with the capacity to deal\nwith relation symbols of all arities. Note that the former generalizes the\nextension of FO2 with a functional relation symbol. We also identify a complete\nclassification of first-order prefix classes according to whether WFOMC is in\npolynomial time or Sharp-P_1 complete.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:36:18 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Kuusisto", "Antti", ""], ["Lutz", "Carsten", ""]]}, {"id": "1804.10237", "submitter": "Arun Nampally", "authors": "Arun Nampally, Timothy Zhang, C. R. Ramakrishnan", "title": "Constraint-Based Inference in Probabilistic Logic Programs", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 5 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Logic Programs (PLPs) generalize traditional logic programs and\nallow the encoding of models combining logical structure and uncertainty. In\nPLP, inference is performed by summarizing the possible worlds which entail the\nquery in a suitable data structure, and using it to compute the answer\nprobability. Systems such as ProbLog, PITA, etc., use propositional data\nstructures like explanation graphs, BDDs, SDDs, etc., to represent the possible\nworlds. While this approach saves inference time due to substructure sharing,\nthere are a number of problems where a more compact data structure is possible.\nWe propose a data structure called Ordered Symbolic Derivation Diagram (OSDD)\nwhich captures the possible worlds by means of constraint formulas. We describe\na program transformation technique to construct OSDDs via query evaluation, and\ngive procedures to perform exact and approximate inference over OSDDs. Our\napproach has two key properties. Firstly, the exact inference procedure is a\ngeneralization of traditional inference, and results in speedup over the latter\nin certain settings. Secondly, the approximate technique is a generalization of\nlikelihood weighting in Bayesian Networks, and allows us to perform\nsampling-based inference with lower rejection rate and variance. We evaluate\nthe effectiveness of the proposed techniques through experiments on several\nproblems. This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 18:34:24 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Nampally", "Arun", ""], ["Zhang", "Timothy", ""], ["Ramakrishnan", "C. R.", ""]]}, {"id": "1804.10355", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert, Ioana Cristescu (TAMIS)", "title": "History-Preserving Bisimulations on Reversible Calculus of Communicating\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  History-and hereditary history-preserving bisimulation (HPB and HHPB) are\nequivalences relations for denotational models of concurrency. Finding their\ncounterpart in process algebras is an open problem, with some partial\nsuccesses: there exists in calculus of communicating systems (CCS) an\nequivalence based on causal trees that corresponds to HPB. In Reversible CSS\n(RCCS), there is a bisimulation that corresponds to HHPB, but it considers only\nprocesses without auto-concurrency. We propose equivalences on CCS with\nauto-concurrency that correspond to HPB and HHPB, and their so-called \"weak\"\nvariants. The equivalences exploit not only reversibility but also the memory\nmechanism of RCCS.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 06:22:56 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "TAMIS"], ["Cristescu", "Ioana", "", "TAMIS"]]}, {"id": "1804.10360", "submitter": "Cole Comfort", "authors": "J.R.B. Cockett, Cole Comfort", "title": "The Category TOF", "comments": "In Proceedings QPL 2018, arXiv:1901.09476", "journal-ref": "EPTCS 287, 2019, pp. 67-84", "doi": "10.4204/EPTCS.287.4", "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a complete set of identities for the symmetric monoidal category,\nTOF, generated by the Toffoli gate and computational ancillary bits. We do so\nby demonstrating that the functor which evaluates circuits on total points, is\nan equivalence into the full subcategory of sets and partial isomorphisms with\nobjects finite powers of the two element set. The structure of the proof builds\n-- and follows the proof of Cockett et al.-- which provided a full set of\nidentities for the cnot gate with computational ancillary bits. Thus, first it\nis shown that TOF is a discrete inverse category in which all of the identities\nfor the cnot gate hold; and then a normal form for the restriction idempotents\nis constructed which corresponds precisely to subobjects of the total points of\nTOF. This is then used to show that TOF is equivalent to FPinj2, the full\nsubcategory of sets and partial isomorphisms in which objects have cardinality\na power of 2.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 06:52:42 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 03:00:53 GMT"}, {"version": "v3", "created": "Sat, 19 Jan 2019 00:15:50 GMT"}, {"version": "v4", "created": "Tue, 29 Jan 2019 06:59:28 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Cockett", "J. R. B.", ""], ["Comfort", "Cole", ""]]}, {"id": "1804.10486", "submitter": "Simone Vuotto", "authors": "Simone Vuotto", "title": "Consistency Checking of Functional Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requirements are informal and semi-formal descriptions of the expected\nbehavior of a system. They are usually expressed in the form of natural\nlanguage sentences and checked for errors manually, e.g., by peer reviews.\nManual checks are error-prone, time-consuming and not scalable. With the\nincreasing complexity of cyber-physical systems and the need of operating in\nsafety- and security-critical environments, it became essential to automatize\nthe consistency check of requirements and build artifacts to help system\nengineers in the design process.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:17:57 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Vuotto", "Simone", ""]]}, {"id": "1804.10507", "submitter": "Pierre Ganty", "authors": "Filippo Bonchi, Pierre Ganty, Roberto Giacobazzi, Dusko Pavlovic", "title": "Sound up-to techniques and Complete abstract domains", "comments": "12 pages, accepted to 33rd Annual ACM/IEEE Symposium on Logic in\n  Computer Science (LICS'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract interpretation is a method to automatically find invariants of\nprograms or pieces of code whose semantics is given via least fixed-points.\nUp-to techniques have been introduced as enhancements of coinduction, an\nabstract principle to prove properties expressed via greatest fixed-points.\n  While abstract interpretation is always sound by definition, the soundness of\nup-to techniques needs some ingenuity to be proven. For completeness, the\nsetting is switched: up-to techniques are always complete, while abstract\ndomains are not.\n  In this work we show that, under reasonable assumptions, there is an evident\nconnection between sound up-to techniques and complete abstract domains.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:53:26 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 09:57:00 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Bonchi", "Filippo", ""], ["Ganty", "Pierre", ""], ["Giacobazzi", "Roberto", ""], ["Pavlovic", "Dusko", ""]]}, {"id": "1804.10540", "submitter": "Noam Zeilberger", "authors": "Noam Zeilberger", "title": "A theory of linear typings as flows on 3-valent graphs", "comments": "To appear in LICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on recently established enumerative connections between lambda\ncalculus and the theory of embedded graphs (or \"maps\"), this paper develops an\nanalogy between typing (of lambda terms) and coloring (of maps). Our starting\npoint is the classical notion of an abelian group-valued \"flow\" on an abstract\ngraph (Tutte, 1954). Typing a linear lambda term may be naturally seen as\nconstructing a flow (on an embedded 3-valent graph with boundary) valued in a\nmore general algebraic structure consisting of a preordered set equipped with\nan \"implication\" operation and unit satisfying composition, identity, and unit\nlaws. Interesting questions and results from the theory of flows (such as the\nexistence of nowhere-zero flows) may then be re-examined from the standpoint of\nlambda calculus and logic. For example, we give a characterization of when the\nlocal flow relations (across vertices) may be categorically lifted to a global\nflow relation (across the boundary), proving that this holds just in case the\nunderlying map has the orientation of a lambda term. We also develop a basic\ntheory of rewriting of flows that suggests topological meanings for classical\ncompleteness results in combinatory logic, and introduce a polarized notion of\nflow, which draws connections to the theory of proof-nets in linear logic and\nto bidirectional typing.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 14:52:35 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Zeilberger", "Noam", ""]]}, {"id": "1804.10565", "submitter": "Stefania Dumbrava", "authors": "Angela Bonifati, Stefania Dumbrava, and Emilio Jesus Gallego Arias", "title": "Certified Graph View Maintenance with Regular Datalog", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018. 18 pages,\n  LaTeX, (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ the Coq proof assistant to develop a mechanically-certified\nframework for evaluating graph queries and incrementally maintaining\nmaterialized graph instances, also called views. The language we use for\ndefining queries and views is Regular Datalog (RD) -- a notable fragment of\nnon-recursive Datalog that can express complex navigational queries, with\ntransitive closure as native operator. We first design and encode the theory of\nRD and then mechanize a RD-specific evaluation algorithm capable of\nfine-grained, incremental graph view computation, which we prove sound with\nrespect to the declarative RD semantics. By using the Coq extraction mechanism,\nwe test an Ocaml version of the verified engine on a set of preliminary\nbenchmarks. Our development is particularly focused on leveraging existing\nverification and notational techniques to: a) define mechanized properties that\ncan be easily understood by logicians and database researchers and b) attain\nformal verification with limited effort. Our work is the first step towards a\nunified, machine-verified, formal framework for dynamic graph query languages\nand their evaluation engines. This paper is under consideration for acceptance\nin TPLP.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:42:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Bonifati", "Angela", ""], ["Dumbrava", "Stefania", ""], ["Arias", "Emilio Jesus Gallego", ""]]}, {"id": "1804.10772", "submitter": "Lorenzo Clemente", "authors": "Lorenzo Clemente and S{\\l}awomir Lasota", "title": "Binary reachability of timed pushdown automata via quantifier\n  elimination and cyclic order atoms", "comments": "Technical report of an ICALP'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study an expressive model of timed pushdown automata extended with modular\nand fractional clock constraints. We show that the binary reachability relation\nis effectively expressible in hybrid linear arithmetic with a rational and an\ninteger sort. This subsumes analogous expressibility results previously known\nfor finite and pushdown timed automata with untimed stack. As key technical\ntools, we use quantifier elimination for a fragment of hybrid linear arithmetic\nand for cyclic order atoms, and a reduction to register pushdown automata over\ncyclic order atoms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 09:37:39 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Clemente", "Lorenzo", ""], ["Lasota", "S\u0142awomir", ""]]}, {"id": "1804.10829", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana", "title": "Formal Security Analysis of Neural Networks using Symbolic Intervals", "comments": "Accepted to USENIX Security 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing deployment of Deep Neural Networks (DNNs) in real-world\nsecurity-critical domains including autonomous vehicles and collision avoidance\nsystems, formally checking security properties of DNNs, especially under\ndifferent attacker capabilities, is becoming crucial. Most existing security\ntesting techniques for DNNs try to find adversarial examples without providing\nany formal security guarantees about the non-existence of such adversarial\nexamples. Recently, several projects have used different types of\nSatisfiability Modulo Theory (SMT) solvers to formally check security\nproperties of DNNs. However, all of these approaches are limited by the high\noverhead caused by the solver.\n  In this paper, we present a new direction for formally checking security\nproperties of DNNs without using SMT solvers. Instead, we leverage interval\narithmetic to compute rigorous bounds on the DNN outputs. Our approach, unlike\nexisting solver-based approaches, is easily parallelizable. We further present\nsymbolic interval analysis along with several other optimizations to minimize\noverestimations of output bounds.\n  We design, implement, and evaluate our approach as part of ReluVal, a system\nfor formally checking security properties of Relu-based DNNs. Our extensive\nempirical results show that ReluVal outperforms Reluplex, a state-of-the-art\nsolver-based system, by 200 times on average. On a single 8-core machine\nwithout GPUs, within 4 hours, ReluVal is able to verify a security property\nthat Reluplex deemed inconclusive due to timeout after running for more than 5\ndays. Our experiments demonstrate that symbolic interval analysis is a\npromising new direction towards rigorously analyzing different security\nproperties of DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 16:37:01 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 04:57:23 GMT"}, {"version": "v3", "created": "Sun, 1 Jul 2018 17:33:53 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "Shiqi", ""], ["Pei", "Kexin", ""], ["Whitehouse", "Justin", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""]]}, {"id": "1804.10886", "submitter": "J\\'er\\'emy Dubut", "authors": "J\\'er\\'emy Dubut", "title": "Bisimilarity of diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate diagrams, namely functors from any small\ncategory to a fixed category, and more particularly, their bisimilarity.\nInitially defined using the theory of open maps of Joyal et al., we prove\nseveral equivalent characterizations: it is equivalent to the existence of a\nrelation, similar to history-preserving bisimulations for event structures and\nit has a logical characterization similar to the Hennessy-Milner theorem. We\nthen prove that we capture many different known bismilarities, by considering\nthe category of executions and extensions of executions, and by forming the\nfunctor that maps every execution to the information of interest for the\nproblem at hand. We then look at the particular case of finitary diagrams with\nvalues in real or rational vector spaces. We prove that checking bisimilarity\nand satisfiability of a positive formula by a diagram are both decidable by\nreducing to a problem of existence of invertible matrices with linear\nconditions, which in turn reduces to the existential theory of the reals.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 07:48:31 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 03:53:29 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dubut", "J\u00e9r\u00e9my", ""]]}, {"id": "1804.10894", "submitter": "J\\'er\\'emy Dubut", "authors": "J\\'er\\'emy Dubut", "title": "Trees in Partial Higher Dimensional Automata", "comments": "Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a new definition of partial Higher Dimension Automata\nusing lax functors. This definition is simpler and more natural from a\ncategorical point of view, but also matches more clearly the intuition that\npHDA are Higher Dimensional Automata with some missing faces. We then focus on\ntrees. Originally, for example in transition systems, trees are defined as\nthose systems that have a unique path property. To understand what kind of\nunique property is needed in pHDA, we start by looking at trees as colimits of\npaths. This definition tells us that trees are exactly the pHDA with the unique\npath property modulo a notion of homotopy, and without any shortcuts. This\nproperty allows us to prove two interesting characterisations of trees: trees\nare exactly those pHDA that are an unfolding of another pHDA; and trees are\nexactly the cofibrant objects, much as in the language of Quillen's model\nstructure. In particular, this last characterisation gives the premisses of a\nnew understanding of concurrency theory using homotopy theory.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 09:21:28 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 03:17:07 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Dubut", "J\u00e9r\u00e9my", ""]]}, {"id": "1804.10896", "submitter": "St\\'ephane Le Roux", "authors": "Stephane Le Roux", "title": "Concurrent games and semi-random determinacy", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider concurrent, infinite duration, two-player win/lose games played on\ngraphs. If the winning condition satisfies some simple requirement, the\nexistence of Player 1 winning (finite-memory) strategies is equivalent to the\nexistence of winning (finite-memory) strategies in finitely many derived\none-player games. Several classical winning conditions satisfy this simple\nrequirement.\n  Under an additional requirement on the winning condition, the non-existence\nof Player 1 winning strategies from all vertices is equivalent to the existence\nof Player 2 stochastic strategies winning almost surely from all vertices. Only\nfew classical winning conditions satisfy this additional requirement, but a\nfairness variant of o\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 09:31:28 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Roux", "Stephane Le", ""]]}, {"id": "1804.10985", "submitter": "Anton\\'in Ku\\v{c}era", "authors": "Tom\\'a\\v{s} Br\\'azdil, Krishnendu Chatterjee, Anton\\'in Ku\\v{c}era,\n  Petr Novotn\\'y, Dominik Velan, Florian Zuleger", "title": "Efficient Algorithms for Asymptotic Bounds on Termination Time in VASS", "comments": "arXiv admin note: text overlap with arXiv:1708.09253", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vector Addition Systems with States (VASS) provide a well-known and\nfundamental model for the analysis of concurrent processes, parameterized\nsystems, and are also used as abstract models of programs in resource bound\nanalysis. In this paper we study the problem of obtaining asymptotic bounds on\nthe termination time of a given VASS. In particular, we focus on the\npractically important case of obtaining polynomial bounds on termination time.\nOur main contributions are as follows: First, we present a polynomial-time\nalgorithm for deciding whether a given VASS has a linear asymptotic complexity.\nWe also show that if the complexity of a VASS is not linear, it is at least\nquadratic. Second, we classify VASS according to quantitative properties of\ntheir cycles. We show that certain singularities in these properties are the\nkey reason for non-polynomial asymptotic complexity of VASS. In absence of\nsingularities, we show that the asymptotic complexity is always polynomial and\nof the form $\\Theta(n^k)$, for some integer $k\\leq d$, where $d$ is the\ndimension of the VASS. We present a polynomial-time algorithm computing the\noptimal $k$. For general VASS, the same algorithm, which is based on a complete\ntechnique for the construction of ranking functions in VASS, produces a valid\nlower bound, i.e., a $k$ such that the termination complexity is $\\Omega(n^k)$.\nOur results are based on new insights into the geometry of VASS dynamics, which\nhold the potential for further applicability to VASS analysis.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 20:01:00 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chatterjee", "Krishnendu", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["Novotn\u00fd", "Petr", ""], ["Velan", "Dominik", ""], ["Zuleger", "Florian", ""]]}, {"id": "1804.10998", "submitter": "Marc Dahlem", "authors": "Marc Dahlem, Anoop Bhagyanath, and Klaus Schneider", "title": "Optimal Scheduling for Exposed Datapath Architectures with Buffered\n  Processing Units by ASP", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 3 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional processor architectures are restricted in exploiting instruction\nlevel parallelism (ILP) due to the relatively low number of programmer-visible\nregisters. Therefore, more recent processor architectures expose their\ndatapaths so that the compiler (1) can schedule parallel instructions to\ndifferent processing units and (2) can make effective use of local storage of\nthe processing units. Among these architectures, the Synchronous Control\nAsynchronous Dataflow (SCAD) architecture is a new exposed datapath\narchitecture whose processing units are equipped with first-in first-out (FIFO)\nbuffers at their input and output ports.\n  In contrast to register-based machines, the optimal code generation for SCAD\nis still a matter of research. In particular, SAT and SMT solvers were used to\ngenerate optimal resource constrained and optimal time constrained schedules\nfor SCAD, respectively. As Answer Set Programming (ASP) offers better\nflexibility in handling such scheduling problems, we focus in this paper on\nusing an answer set solver for both resource and time constrained optimal SCAD\ncode generation. As a major benefit of using ASP, we are able to generate\n\\emph{all} optimal schedules for a given program which allows one to study\ntheir properties. Furthermore, the experimental results of this paper\ndemonstrate that the answer set solver can compete with SAT solvers and\noutperforms SMT solvers. \\emph{This paper is under consideration for acceptance\nin TPLP.}\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 22:28:31 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dahlem", "Marc", ""], ["Bhagyanath", "Anoop", ""], ["Schneider", "Klaus", ""]]}, {"id": "1804.11066", "submitter": "Kazushige Terui", "authors": "Kazushige Terui", "title": "MacNeille completion and Buchholz' Omega rule for parameter-free second\n  order logics", "comments": "Submitted to the special issue of LMCS for CSL'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buchholz' Omega-rule is a way to give a syntactic, possibly ordinal-free\nproof of cut elimination for various subsystems of second order arithmetic. Our\ngoal is to understand it from an algebraic point of view. Among many proofs of\ncut elimination for higher order logics, Maehara and Okada's algebraic proofs\nare of particular interest, since the essence of their arguments can be\nalgebraically described as the (Dedekind-)MacNeille completion together with\nGirard's reducibility candidates. Interestingly, it turns out that the\n$\\Omega$-rule, formulated as a rule of logical inference, finds its algebraic\nfoundation in the MacNeille completion.\n  In this paper, we consider the parameter-free fragments LIP0, LIP1, LIP2, ...\nof the second order intuitionistic logic, that correspond to the arithmetical\ntheories ID0, ID1, ID2, ... of iterated inductive definitions up to omega. In\nthis setting, we observe a formal connection between the Omega-rule and the\nMacNeille completion, that leads to a way of interpreting second order\nquantifiers in a first order way in Heyting-valued semantics, called the\nOmega-interpretation. Based on this, we give an algebraic proof of cut\nelimination for LIPn for every n<omega that can be locally formalized in IDn.\nAs a consequence, we obtain an equivalence between the cut elimination for LIPn\nand the 1-consistency of IDn that holds in a weak theory of arithmetic.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 07:54:23 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 15:27:22 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Terui", "Kazushige", ""]]}, {"id": "1804.11116", "submitter": "Thorsten Wissmann", "authors": "Jean-Simon Pacaud Lemay", "title": "Lifting Coalgebra Modalities and $\\mathsf{MELL}$ Model Structure to\n  Eilenberg-Moore Categories", "comments": "An extend abstract version of this paper appears in the conference\n  proceedings of the 3rd International Conference on Formal Structures for\n  Computation and Deduction (FSCD 2018), under the title \"Lifting Coalgebra\n  Modalities and $\\mathsf{MELL}$ Model Structure to Eilenberg-Moore Categories\"", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 4 (November\n  7, 2019) lmcs:5895", "doi": "10.23638/LMCS-15(4:8)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A categorical model of the multiplicative and exponential fragments of\nintuitionistic linear logic ($\\mathsf{MELL}$), known as a \\emph{linear\ncategory}, is a symmetric monoidal closed category with a monoidal coalgebra\nmodality (also known as a linear exponential comonad). Inspired by Blute and\nScott's work on categories of modules of Hopf algebras as models of linear\nlogic, we study categories of algebras of monads (also known as Eilenberg-Moore\ncategories) as models of $\\mathsf{MELL}$. We define a $\\mathsf{MELL}$ lifting\nmonad on a linear category as a Hopf monad -- in the Brugui{\\`e}res, Lack, and\nVirelizier sense -- with a special kind of mixed distributive law over the\nmonoidal coalgebra modality. As our main result, we show that the linear\ncategory structure lifts to the category of algebras of $\\mathsf{MELL}$ lifting\nmonads. We explain how groups in the category of coalgebras of the monoidal\ncoalgebra modality induce $\\mathsf{MELL}$ lifting monads and provide a source\nfor such groups from enrichment over abelian groups. Along the way we also\ndefine mixed distributive laws of symmetric comonoidal monads over symmetric\nmonoidal comonads and lifting differential category structure.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 10:53:59 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 11:06:01 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 15:03:46 GMT"}, {"version": "v4", "created": "Mon, 5 Aug 2019 18:15:16 GMT"}, {"version": "v5", "created": "Thu, 3 Oct 2019 09:48:23 GMT"}, {"version": "v6", "created": "Wed, 6 Nov 2019 14:47:32 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lemay", "Jean-Simon Pacaud", ""]]}, {"id": "1804.11162", "submitter": "Joaqu\\'in Arias M.Sc.", "authors": "Joaqu\\'in Arias, Manuel Carro, Elmer Salazar, Kyle Marple and Gopal\n  Gupta", "title": "Constraint Answer Set Programming without Grounding", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending ASP with constraints (CASP) enhances its expressiveness and\nperformance. This extension is not straightforward as the grounding phase,\npresent in most ASP systems, removes variables and the links among them, and\nalso causes a combinatorial explosion in the size of the program. Several\nmethods to overcome this issue have been devised: restricting the constraint\ndomains (e.g., discrete instead of dense), or the type (or number) of models\nthat can be returned. In this paper we propose to incorporate constraints into\ns(ASP), a goal-directed, top-down execution model which implements ASP while\nretaining logical variables both during execution and in the answer sets. The\nresulting model, s(CASP), can constrain variables that, as in CLP, are kept\nduring the execution and in the answer sets. s(CASP) inherits and generalizes\nthe execution model of s(ASP) and is parametric w.r.t. the constraint solver.\nWe describe this novel execution model and show through several examples the\nenhanced expressiveness of s(CASP) w.r.t. ASP, CLP, and other CASP systems. We\nalso report improved performance w.r.t. other very mature, highly optimized ASP\nsystems in some benchmarks. This paper is under consideration for publication\nin Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 12:50:28 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 15:33:53 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Arias", "Joaqu\u00edn", ""], ["Carro", "Manuel", ""], ["Salazar", "Elmer", ""], ["Marple", "Kyle", ""], ["Gupta", "Gopal", ""]]}, {"id": "1804.11222", "submitter": "Daniele Francesco Santamaria", "authors": "Domenico Cantone and Marianna Nicolosi-Asmundo and Daniele Francesco\n  Santamaria", "title": "An optimized KE-tableau-based system for reasoning in the description\n  logic $\\shdlssx$ (Extended Version)", "comments": "arXiv admin note: text overlap with arXiv:1702.03096,\n  arXiv:1805.08606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a \\ke-based procedure for the main TBox and ABox reasoning tasks\nfor the description logic $\\dlssx$, in short $\\shdlssx$. The logic $\\shdlssx$,\nrepresentable in the decidable multi-sorted quantified set-theoretic fragment\n$\\flqsr$, combines the high scalability and efficiency of rule languages such\nas the Semantic Web Rule Language (SWRL) with the expressivity of description\nlogics. %In fact it supports, among other features, Boolean operations on\nconcepts and roles, role constructs such as the product of concepts and role\nchains on the left hand side of inclusion axioms, and role properties such as\ntransitivity, symmetry, reflexivity, and irreflexivity.\n  Our algorithm is based on a variant of the \\ke\\space system for sets of\nuniversally quantified clauses, where the KE-elimination rule is generalized in\nsuch a way as to incorporate the $\\gamma$-rule. The novel system, called \\keg,\nturns out to be an improvement of the system introduced in \\cite{RR2017} and of\nstandard first-order \\ke x \\cite{dagostino94}. Suitable benchmark test sets\nexecuted on C++ implementations of the three mentioned systems show that the\nperformances of the \\keg-based reasoner are often up to about 400\\% better than\nthe ones of the other two systems. This a first step towards the construction\nof efficient reasoners for expressive OWL ontologies based on fragments of\ncomputable set-theory.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 17:45:34 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 12:19:37 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 16:14:07 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Cantone", "Domenico", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""]]}, {"id": "1804.11250", "submitter": "Frantisek Farka", "authors": "Franti\\v{s}ek Farka, Ekaterina Komendantskya and Kevin Hammond", "title": "Proof-relevant Horn Clauses for Dependent Type Inference and Term\n  Synthesis", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 0 PDF figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order resolution has been used for type inference for many years,\nincluding in Hindley- Milner type inference, type-classes, and constrained data\ntypes. Dependent types are a new trend in functional languages. In this paper,\nwe show that proof-relevant first-order resolution can play an important role\nin automating type inference and term synthesis for dependently typed\nlanguages. We propose a calculus that translates type inference and term\nsynthesis problems in a dependently typed language to a logic program and a\ngoal in the proof-relevant first-order Horn clause logic. The computed answer\nsubstitution and proof term then provide a solution to the given type inference\nand term synthesis problem. We prove the decidability and soundness of our\nmethod. The paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 14:56:45 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Farka", "Franti\u0161ek", ""], ["Komendantskya", "Ekaterina", ""], ["Hammond", "Kevin", ""]]}, {"id": "1804.11301", "submitter": "Clemens Dubslaff", "authors": "Christel Baier, Nathalie Bertrand, Clemens Dubslaff, Daniel Gburek,\n  Ocan Sankur", "title": "Stochastic Shortest Paths and Weight-Bounded Properties in Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with finite-state Markov decision processes (MDPs) with\ninteger weights assigned to each state-action pair. New algorithms are\npresented to classify end components according to their limiting behavior with\nrespect to the accumulated weights. These algorithms are used to provide\nsolutions for two types of fundamental problems for integer-weighted MDPs.\nFirst, a polynomial-time algorithm for the classical stochastic shortest path\nproblem is presented, generalizing known results for special classes of\nweighted MDPs. Second, qualitative probability constraints for weight-bounded\n(repeated) reachability conditions are addressed. Among others, it is shown\nthat the problem to decide whether a disjunction of weight-bounded reachability\nconditions holds almost surely under some scheduler belongs to $\\textrm{NP}\\cap\n\\textrm{coNP}$, is solvable in pseudo-polynomial time and is at least as hard\nas solving two-player mean-payoff games, while the corresponding problem for\nuniversal quantification over schedulers is solvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 16:26:49 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Baier", "Christel", ""], ["Bertrand", "Nathalie", ""], ["Dubslaff", "Clemens", ""], ["Gburek", "Daniel", ""], ["Sankur", "Ocan", ""]]}]