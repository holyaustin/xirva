[{"id": "1806.00028", "submitter": "Bastien Maubert", "authors": "Bastien Maubert and Aniello Murano", "title": "Reasoning about Knowledge and Strategies under Hierarchical Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two distinct semantics have been considered for knowledge in the context of\nstrategic reasoning, depending on whether players know each other's strategy or\nnot. The problem of distributed synthesis for epistemic temporal specifications\nis known to be undecidable for the latter semantics, already on systems with\nhierarchical information. However, for the other, uninformed semantics, the\nproblem is decidable on such systems. In this work we generalise this result by\nintroducing an epistemic extension of Strategy Logic with imperfect\ninformation. The semantics of knowledge operators is uninformed, and captures\nagents that can change observation power when they change strategies. We solve\nthe model-checking problem on a class of \"hierarchical instances\", which\nprovides a solution to a vast class of strategic problems with epistemic\ntemporal specifications on hierarchical systems, such as distributed synthesis\nor rational synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 18:04:50 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 15:52:32 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Maubert", "Bastien", ""], ["Murano", "Aniello", ""]]}, {"id": "1806.00238", "submitter": "Simone Silvetti", "authors": "Simone Silvetti, Laura Nenzi, Ezio Bartocci, Luca Bortolussi", "title": "Signal Convolution Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new logic called Signal Convolution Logic (SCL) that combines\ntemporal logic with convolutional filters from digital signal processing. SCL\nenables to reason about the percentage of time a formula is satisfied in a\nbounded interval. We demonstrate that this new logic is a suitable formalism to\neffectively express non-functional requirements in Cyber-Physical Systems\ndisplaying noisy and irregular behaviours. We define both a qualitative and\nquantitative semantics for it, providing an efficient monitoring procedure.\nFinally, we prove SCL at work to monitor the artificial pancreas controllers\nthat are employed to automate the delivery of insulin for patients with type-1\ndiabetes.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 08:41:53 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 13:02:11 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Silvetti", "Simone", ""], ["Nenzi", "Laura", ""], ["Bartocci", "Ezio", ""], ["Bortolussi", "Luca", ""]]}, {"id": "1806.00256", "submitter": "Thorsten Wissmann", "authors": "Moses Ganardi, Stefan G\\\"oller, Markus Lohrey", "title": "The Complexity of Bisimulation and Simulation on Finite Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (October\n  26, 2018) lmcs:4922", "doi": "10.23638/LMCS-14(4:5)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper the computational complexity of the (bi)simulation problem over\nrestricted graph classes is studied. For trees given as pointer structures or\nterms the (bi)simulation problem is complete for logarithmic space or NC$^1$,\nrespectively. This solves an open problem from Balc\\'azar, Gabarr\\'o, and\nS\\'antha. Furthermore, if only one of the input graphs is required to be a\ntree, the bisimulation (simulation) problem is contained in AC$^1$ (LogCFL). In\ncontrast, it is also shown that the simulation problem is P-complete already\nfor graphs of bounded path-width.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 09:39:46 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 12:16:53 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Ganardi", "Moses", ""], ["G\u00f6ller", "Stefan", ""], ["Lohrey", "Markus", ""]]}, {"id": "1806.00344", "submitter": "John Longley", "authors": "John Longley", "title": "The encodability hierarchy for PCF types", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working with the simple types over a base type of natural numbers (including\nproduct types), we consider the question of when a type $\\sigma$ is encodable\nas a definable retract of $\\tau$: that is, when there are $\\lambda$-terms\n$e:\\sigma\\rightarrow\\tau$ and $d:\\tau\\rightarrow\\sigma$ with $d \\circ e = id$.\nIn general, the answer to this question may vary according to both the choice\nof $\\lambda$-calculus and the notion of equality considered; however, we shall\nshow that the encodability relation $\\preceq$ between types actually remains\nstable across a large class of languages and equality relations, ranging from a\nvery basic language with infinitely many distinguishable constants $0,1,\\ldots$\n(but no arithmetic) considered modulo computational equality, up to the whole\nof Plotkin's PCF considered modulo observational equivalence. We show that\n$\\sigma \\preceq \\tau \\preceq \\sigma$ iff $\\sigma \\cong \\tau$ via trivial\nisomorphisms, and that for any $\\sigma,\\tau$ we have either $\\sigma \\preceq\n\\tau$ or $\\tau \\preceq \\sigma$. Furthermore, we show that the induced linear\norder on isomorphism classes of types is actually a well-ordering of type\n$\\epsilon_0$, and indeed that there is a close syntactic correspondence between\nsimple types and Cantor normal forms for ordinals below $\\epsilon_0$. This\nmeans that the relation $\\preceq$ is readily decidable, and that terms\nwitnessing a retraction $\\sigma \\lhd \\tau$ are readily constructible when\n$\\sigma \\preceq \\tau$ holds.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 13:49:12 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Longley", "John", ""]]}, {"id": "1806.00608", "submitter": "Daniel Huang", "authors": "Daniel Huang, Prafulla Dhariwal, Dawn Song, Ilya Sutskever", "title": "GamePad: A Learning Environment for Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a system called GamePad that can be used to\nexplore the application of machine learning methods to theorem proving in the\nCoq proof assistant. Interactive theorem provers such as Coq enable users to\nconstruct machine-checkable proofs in a step-by-step manner. Hence, they\nprovide an opportunity to explore theorem proving with human supervision. We\nuse GamePad to synthesize proofs for a simple algebraic rewrite problem and\ntrain baseline models for a formalization of the Feit-Thompson theorem. We\naddress position evaluation (i.e., predict the number of proof steps left) and\ntactic prediction (i.e., predict the next proof step) tasks, which arise\nnaturally in tactic-based theorem proving.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 09:19:08 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 18:37:30 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Huang", "Daniel", ""], ["Dhariwal", "Prafulla", ""], ["Song", "Dawn", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1806.00810", "submitter": "William Farmer", "authors": "William M. Farmer", "title": "A New Style of Proof for Mathematics Organized as a Network of Axiomatic\n  Theories", "comments": "14 pages. This is a longer, revised version with a modified title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theory graph is a network of axiomatic theories connected with\nmeaning-preserving mappings called theory morphisms. Theory graphs are well\nsuited for organizing large bodies of mathematical knowledge. Traditional and\nformal proofs do not adequately fulfill all the purposes that mathematical\nproofs have, and they do not exploit the structure inherent in a theory graph.\nWe propose a new style of proof that fulfills the principal purposes of a\nmathematical proof as well as capitalizes on the connections provided by the\ntheory morphisms in a theory graph. This new style of proof combines the\nstrengths of traditional proofs with the strengths of formal proofs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 15:18:01 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 12:25:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Farmer", "William M.", ""]]}, {"id": "1806.01672", "submitter": "Antonio Farias", "authors": "Antonio Diego S. Farias and Regivan H. N. Santiago and Benjam\\'in\n  Bedregal", "title": "Dynamic Ordered Weighted Averaging Functions for Complete Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a class of operators on complete lattices called\nDynamic Ordered Weighted Averaging (DYOWA) functions. These functions provide a\ngeneralized form of an important class of aggregation functions: The Ordered\nWeighted Averaging (OWA) functions, whose applications can be found in several\nareas like: Image Processing and Decision Making. The wide range of\napplications of OWAs motivated many researchers to study their variations. One\nof them was proposed by Lizassoaim and Moreno in 2013, which extends those\nfunctions to complete lattices. Here, we propose a new generalization of OWAs\nthat also generalizes the operators proposed by Lizassoaim and Moreno.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 13:08:09 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Farias", "Antonio Diego S.", ""], ["Santiago", "Regivan H. N.", ""], ["Bedregal", "Benjam\u00edn", ""]]}, {"id": "1806.02101", "submitter": "Simon Foster", "authors": "Simon Foster, Kangfeng Ye, Ana Cavalcanti, Jim Woodcock", "title": "Calculational Verification of Reactive Programs with Reactive Relations\n  and Kleene Algebra", "comments": "18 pages, accepted for RAMICS 2018", "journal-ref": "RAMICS 2018, Oct 2018, Groningen, Netherlands", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive programs are ubiquitous in modern applications, and so verification\nis highly desirable. We present a verification strategy for reactive programs\nwith a large or infinite state space utilising algebraic laws for reactive\nrelations. We define novel operators to characterise interactions and state\nupdates, and an associated equational theory. With this we can calculate a\nreactive program's denotational semantics, and thereby facilitate automated\nproof. Of note is our reasoning support for iterative programs with reactive\ninvariants, which is supported by Kleene algebra. We illustrate our strategy by\nverifying a reactive buffer. Our laws and strategy are mechanised in\nIsabelle/UTP, which provides soundness guarantees, and practical verification\nsupport.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 10:29:38 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 09:56:00 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Foster", "Simon", ""], ["Ye", "Kangfeng", ""], ["Cavalcanti", "Ana", ""], ["Woodcock", "Jim", ""]]}, {"id": "1806.02239", "submitter": "Kuldeep S. Meel", "authors": "Kuldeep S. Meel", "title": "Constrained Counting and Sampling: Bridging the Gap between Theory and\n  Practice", "comments": null, "journal-ref": "PhD Thesis, Rice University, 2018", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained counting and sampling are two fundamental problems in Computer\nScience with numerous applications, including network reliability, privacy,\nprobabilistic reasoning, and constrained-random verification. In constrained\ncounting, the task is to compute the total weight, subject to a given weighting\nfunction, of the set of solutions of the given constraints. In constrained\nsampling, the task is to sample randomly, subject to a given weighting\nfunction, from the set of solutions to a set of given constraints.\nConsequently, constrained counting and sampling have been subject to intense\ntheoretical and empirical investigations over the years. Prior work, however,\noffered either heuristic techniques with poor guarantees of accuracy or\napproaches with proven guarantees but poor performance in practice.\n  In this thesis, we introduce a novel hashing-based algorithmic framework for\nconstrained sampling and counting that combines the classical algorithmic\ntechnique of universal hashing with the dramatic progress made in combinatorial\nreasoning tools, in particular, SAT and SMT, over the past two decades. The\nresulting frameworks for counting (ApproxMC2) and sampling (UniGen) can handle\nformulas with up to million variables representing a significant boost up from\nthe prior state of the art tools' capability to handle few hundreds of\nvariables. If the initial set of constraints is expressed as Disjunctive Normal\nForm (DNF), ApproxMC is the only known Fully Polynomial Randomized\nApproximation Scheme (FPRAS) that does not involve Monte Carlo steps. By\nexploiting the connection between definability of formulas and variance of the\ndistribution of solutions in a cell defined by 3-universal hash functions, we\nintroduced an algorithmic technique, MIS, that reduced the size of XOR\nconstraints employed in the underlying universal hash functions by as much as\ntwo orders of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 15:16:32 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Meel", "Kuldeep S.", ""]]}, {"id": "1806.02621", "submitter": "Joshua Heneage Dawes", "authors": "Joshua Heneage Dawes (University of Manchester and CERN), Giles Reger\n  (University of Manchester)", "title": "Specification of State and Time Constraints for Runtime Verification of\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for runtime verification often utilise specification languages\nthat are (i) reasonably expressive, and (ii) relatively abstract (i.e. they\noperate on a level of abstraction that separates them from the system being\nmonitored). Inspired by the problem of monitoring systems involved in\nprocessing data generated by the high energy physics experiments at CERN, this\nreport proposes a specification language, Control Flow Temporal Logic (CFTL),\nwhose distinguishing characteristic is its tight coupling with the control flow\nof the programs for which it is used to write specifications. This coupling\nleads to a departure from the typically high level of abstraction used by most\ntemporal logics. The remaining contributions are a static-analysis based\ninstrumentation process, which is specific to CFTL and its formulas' structure,\nand a monitoring algorithm. The report concludes with analyses of CFTL and its\nmonitoring algorithm when applied to a number of example programs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 11:29:26 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 06:46:37 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Dawes", "Joshua Heneage", "", "University of Manchester and CERN"], ["Reger", "Giles", "", "University of Manchester"]]}, {"id": "1806.02930", "submitter": "Mohamed El Halaby", "authors": "Mohamed El Halaby and Areeg Abdalla", "title": "Maximizing the Number of Satisfied L-clauses", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-SAT problem for \\L{}-clausal forms has been found to be NP-complete\nif $k\\geq 3$. Similar to Boolean CNF formulas, \\L{}-clausal forms are important\nfrom a theoretical and practical points of view for their expressive power,\neasy-hard-easy pattern as well as having a phase transition phenomena. In this\npaper, we investigate further \\L{}-clausal forms in terms of instance\ngeneration and maximizing the number of satisfied \\L{}-clauses. Firstly, we\nprove that minimizing the cost of \\L{}-clausal forms is NP-complete and present\nan algorithm for the problem. Secondly, we devise an instance generation model\nto produce \\L{}-clausal forms with different values of $k$ and degree of\nabsence of negated terms $\\neg(l_1 \\oplus \\dots \\oplus l_m)$ (we call $p$) in\neach clause. Finally, we conduct empirical investigation to identify the\nrelationship between the cost and other parameters of the instance generator.\nOne of our findings shows that the cost decreases exponentially as $p$\nincreases, for any clauses to variables ratio. This enables us to generate\nsatisfiable and unsatisfiable instances with the same clauses to variables\nratio.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 00:48:10 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Halaby", "Mohamed El", ""], ["Abdalla", "Areeg", ""]]}, {"id": "1806.03049", "submitter": "Adnan Rashid", "authors": "Adnan Rashid and Osman Hasan", "title": "Formalization of Lerch's Theorem using HOL Light", "comments": "Journal of Applied Logics, 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Laplace transform is an algebraic method that is widely used for\nanalyzing physical systems by either solving the differential equations\nmodeling their dynamics or by evaluating their transfer function. The dynamics\nof the given system are firstly modeled using differential equations and then\nLaplace transform is applied to convert these differential equations to their\nequivalent algebraic equations. These equations can further be simplified to\neither obtain the transfer function of the system or to find out the solution\nof the differential equations in frequency domain. Next, the uniqueness of the\nLaplace transform provides the solution of these differential equations in the\ntime domain. The traditional Laplace transform based analysis techniques, i.e.,\npaper-and-pencil proofs and computer simulation methods are error-prone due to\ntheir inherent limitations and thus are not suitable for the analysis of the\nsystems. Higher-order-logic theorem proving can overcome these limitations of\nthese techniques and can ascertain accurate analysis of the systems. In this\npaper, we extend our higher-order logic formalization of the Laplace transform,\nwhich includes the formal definition of the Laplace transform and verification\nof its various classical properties. One of the main contributions of the paper\nis the formalization of Lerch's theorem, which describes the uniqueness of the\nLaplace transform and thus plays a vital role in solving linear differential\nequations in the frequency domain. For illustration, we present the formal\nanalysis of a $4$-$\\pi$ soft error crosstalk model, which is widely used in\nnanometer technologies, such as, Integrated Circuits (ICs).\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 09:43:53 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Rashid", "Adnan", ""], ["Hasan", "Osman", ""]]}, {"id": "1806.03205", "submitter": "Fabian Kunze", "authors": "Fabian Kunze, Gert Smolka, Yannick Forster", "title": "Formal Small-step Verification of a Call-by-value Lambda Calculus\n  Machine", "comments": null, "journal-ref": "APLAS 2018, LNCS 11275, pp. 264-283", "doi": "10.1007/978-3-030-02768-1_15", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally verify an abstract machine for a call-by-value lambda-calculus\nwith de Bruijn terms, simple substitution, and small-step semantics. We follow\na stepwise refinement approach starting with a naive stack machine with\nsubstitution. We then refine to a machine with closures, and finally to a\nmachine with a heap providing structure sharing for closures. We prove the\ncorrectness of the three refinement steps with compositional small-step\nbottom-up simulations. There is an accompanying Coq development verifying all\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 14:59:07 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 13:33:29 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 15:04:41 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Kunze", "Fabian", ""], ["Smolka", "Gert", ""], ["Forster", "Yannick", ""]]}, {"id": "1806.03953", "submitter": "Ivan Gavran", "authors": "Daniel Neider, Ivan Gavran", "title": "Learning Linear Temporal Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel algorithms for learning formulas in Linear Temporal\nLogic (LTL) from examples. The first learning algorithm reduces the learning\ntask to a series of satisfiability problems in propositional Boolean logic and\nproduces a smallest LTL formula (in terms of the number of subformulas) that is\nconsistent with the given data. Our second learning algorithm, on the other\nhand, combines the SAT-based learning algorithm with classical algorithms for\nlearning decision trees. The result is a learning algorithm that scales to\nreal-world scenarios with hundreds of examples, but can no longer guarantee to\nproduce minimal consistent LTL formulas. We compare both learning algorithms\nand demonstrate their performance on a wide range of synthetic benchmarks.\nAdditionally, we illustrate their usefulness on the task of understanding\nexecutions of a leader election protocol.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 13:13:54 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 07:23:34 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 07:13:02 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Neider", "Daniel", ""], ["Gavran", "Ivan", ""]]}, {"id": "1806.04254", "submitter": "Roman Nesterov", "authors": "Luca Bernardinello, Irina Lomazova, Roman Nesterov, Lucia Pomello", "title": "Compositional Discovery of Workflow Nets from Event Logs Using Morphisms", "comments": "The extended version of the paper accepted for ATAED'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a modular approach to discover process models for\nmulti-agent systems from event logs. System event logs are filtered according\nto individual agent behavior. We discover workflow nets for each agent using\nexisting process discovery algorithms. We consider asynchronous interactions\namong agents. Given a specification of an interaction protocol, we propose a\ngeneral scheme of workflow net composition. By using morphisms, we prove that\nthis composition preserves soundness of components. A quality evaluation shows\nthe increase in the precision of models discovered by the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 21:55:45 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Bernardinello", "Luca", ""], ["Lomazova", "Irina", ""], ["Nesterov", "Roman", ""], ["Pomello", "Lucia", ""]]}, {"id": "1806.04774", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima, Julian Parsert", "title": "Goal-Oriented Conjecturing for Isabelle/HOL", "comments": "This paper has been accepted at 11th Conference on Intelligent\n  Computer Mathematics. An error in Abstract has been fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PGT, a Proof Goal Transformer for Isabelle/HOL. Given a proof goal\nand its background context, PGT attempts to generate conjectures from the\noriginal goal by transforming the original proof goal. These conjectures should\nbe weak enough to be provable by automation but sufficiently strong to prove\nthe original goal. By incorporating PGT into the pre-existing PSL framework, we\nexploit Isabelle's strong automation to identify and prove such conjectures.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 21:38:26 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 13:12:37 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Nagashima", "Yutaka", ""], ["Parsert", "Julian", ""]]}, {"id": "1806.04831", "submitter": "Thorsten Wissmann", "authors": "Benjamin Rossman", "title": "Subspace-Invariant AC$^0$ Formulas", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (July 24,\n  2019) lmcs:5641", "doi": "10.23638/LMCS-15(3:3)2019", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the action of a linear subspace $U$ of $\\{0,1\\}^n$ on the set of\nAC$^0$ formulas with inputs labeled by literals in the set $\\{X_1,\\overline\nX_1,\\dots,X_n,\\overline X_n\\}$, where an element $u \\in U$ acts on formulas by\ntransposing the $i$th pair of literals for all $i \\in [n]$ such that $u_i=1$. A\nformula is {\\em $U$-invariant} if it is fixed by this action. For example,\nthere is a well-known recursive construction of depth $d+1$ formulas of size\n$O(n{\\cdot}2^{dn^{1/d}})$ computing the $n$-variable PARITY function; these\nformulas are easily seen to be $P$-invariant where $P$ is the subspace of\neven-weight elements of $\\{0,1\\}^n$. In this paper we establish a nearly\nmatching $2^{d(n^{1/d}-1)}$ lower bound on the $P$-invariant depth $d+1$\nformula size of PARITY. Quantitatively this improves the best known\n$\\Omega(2^{\\frac{1}{84}d(n^{1/d}-1)})$ lower bound for {\\em unrestricted} depth\n$d+1$ formulas, while avoiding the use of the switching lemma. More generally,\nfor any linear subspaces $U \\subset V$, we show that if a Boolean function is\n$U$-invariant and non-constant over $V$, then its $U$-invariant depth $d+1$\nformula size is at least $2^{d(m^{1/d}-1)}$ where $m$ is the minimum Hamming\nweight of a vector in $U^\\bot \\setminus V^\\bot$.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 02:56:33 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 19:33:20 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 13:31:54 GMT"}, {"version": "v4", "created": "Tue, 23 Jul 2019 11:57:29 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Rossman", "Benjamin", ""]]}, {"id": "1806.05040", "submitter": "Christian Sternagel", "authors": "Jonas Sch\\\"opf and Christian Sternagel", "title": "TTT2 with Termination Templates for Teaching", "comments": "Accepted at the International Workshop on Termination 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the one hand, checking specific termination proofs by hand, say using a\nparticular collection of matrix interpretations, can be an arduous and\nerror-prone task. On the other hand, automation of such checks would save time\nand help to establish correctness of exam solutions, examples in lecture notes\netc. To this end, we introduce a template mechanism for the termination tool\nTTT2 that allows us to restrict parameters of certain termination methods. In\nthe extreme, when all parameters are fixed, such restrictions result in checks\nfor specific proofs.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 13:52:34 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Sch\u00f6pf", "Jonas", ""], ["Sternagel", "Christian", ""]]}, {"id": "1806.05126", "submitter": "Sebastian Arming", "authors": "Sebastian Arming, Ezio Bartocci, Krishnendu Chatterjee, Joost-Pieter\n  Katoen, Ana Sokolova", "title": "Parameter-Independent Strategies for pMDPs via POMDPs", "comments": "Extended version of a QEST 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Decision Processes (MDPs) are a popular class of models suitable for\nsolving control decision problems in probabilistic reactive systems. We\nconsider parametric MDPs (pMDPs) that include parameters in some of the\ntransition probabilities to account for stochastic uncertainties of the\nenvironment such as noise or input disturbances.\n  We study pMDPs with reachability objectives where the parameter values are\nunknown and impossible to measure directly during execution, but there is a\nprobability distribution known over the parameter values. We study for the\nfirst time computing parameter-independent strategies that are expectation\noptimal, i.e., optimize the expected reachability probability under the\nprobability distribution over the parameters. We present an encoding of our\nproblem to partially observable MDPs (POMDPs), i.e., a reduction of our problem\nto computing optimal strategies in POMDPs.\n  We evaluate our method experimentally on several benchmarks: a motivating\n(repeated) learner model; a series of benchmarks of varying configurations of a\nrobot moving on a grid; and a consensus protocol.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 16:01:51 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Arming", "Sebastian", ""], ["Bartocci", "Ezio", ""], ["Chatterjee", "Krishnendu", ""], ["Katoen", "Joost-Pieter", ""], ["Sokolova", "Ana", ""]]}, {"id": "1806.05230", "submitter": "Peng Fu", "authors": "Peng Fu, Peter Selinger", "title": "Dependently Typed Folds for Nested Data Types", "comments": "source code for each section is at:\n  https://github.com/Fermat/dependent-fold", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to develop folds for nested data types using dependent\ntypes. We call such folds $\\textit{dependently typed folds}$, they have the\nfollowing properties. (1) Dependently typed folds are defined by well-founded\nrecursion and they can be defined in a total dependently typed language. (2)\nDependently typed folds do not depend on maps, map functions and many\nterminating functions can be defined using dependently typed folds. (3) The\ninduction principles for nested data types follow from the definitions of\ndependently typed folds and the programs defined by dependently typed folds can\nbe formally verified. (4) Dependently typed folds exist for any nested data\ntypes and they can be specialized to the traditional $\\textit{higher-order\nfolds}$. Using various of examples, we show how to program and reason about\ndependently typed folds. We also show how to obtain dependently typed folds in\ngeneral and how to specialize them to the corresponding higher-order folds.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 19:12:56 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Fu", "Peng", ""], ["Selinger", "Peter", ""]]}, {"id": "1806.05654", "submitter": "Christoph Rauch", "authors": "Thorsten Wi{\\ss}mann, Ulrich Dorsch, Stefan Milius, Lutz Schr\\\"oder", "title": "Efficient and Modular Coalgebraic Partition Refinement", "comments": "Extended journal version of the conference paper arXiv:1705.08362.\n  Beside reorganization of the material, the introductory section 3 is entirely\n  new and the other new section 7 contains new mathematical results", "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (January\n  31, 2020) lmcs:6064", "doi": "10.23638/LMCS-16(1:8)2020", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a generic partition refinement algorithm that quotients\ncoalgebraic systems by behavioural equivalence, an important task in system\nanalysis and verification. Coalgebraic generality allows us to cover not only\nclassical relational systems but also, e.g. various forms of weighted systems\nand furthermore to flexibly combine existing system types. Under assumptions on\nthe type functor that allow representing its finite coalgebras in terms of\nnodes and edges, our algorithm runs in time $\\mathcal{O}(m\\cdot \\log n)$ where\n$n$ and $m$ are the numbers of nodes and edges, respectively. The generic\ncomplexity result and the possibility of combining system types yields a\ntoolbox for efficient partition refinement algorithms. Instances of our generic\nalgorithm match the run-time of the best known algorithms for unlabelled\ntransition systems, Markov chains, deterministic automata (with fixed\nalphabets), Segala systems, and for color refinement.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 17:22:10 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 17:55:31 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 18:00:12 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 08:22:43 GMT"}, {"version": "v5", "created": "Thu, 30 Jan 2020 13:27:49 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wi\u00dfmann", "Thorsten", ""], ["Dorsch", "Ulrich", ""], ["Milius", "Stefan", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "1806.05956", "submitter": "Gal Vardi", "authors": "Orna Kupferman, Gal Vardi", "title": "Flow Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 4 (November\n  14, 2019) lmcs:5910", "doi": "10.23638/LMCS-15(4:9)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flow networks have attracted a lot of research in computer science. Indeed,\nmany questions in numerous application areas can be reduced to questions about\nflow networks. Many of these applications would benefit from a framework in\nwhich one can formally reason about properties of flow networks that go beyond\ntheir maximal flow. We introduce Flow Logics: modal logics that treat flow\nfunctions as explicit first-order objects and enable the specification of rich\nproperties of flow networks. The syntax of our logic BFL* (Branching Flow\nLogic) is similar to the syntax of the temporal logic CTL*, except that atomic\nassertions may be flow propositions, like $> \\gamma$ or $\\geq \\gamma$, for\n$\\gamma \\in \\mathbb{N}$, which refer to the value of the flow in a vertex, and\nthat first-order quantification can be applied both to paths and to flow\nfunctions. We present an exhaustive study of the theoretical and practical\naspects of BFL*, as well as extensions and fragments of it. Our extensions\ninclude flow quantifications that range over non-integral flow functions or\nover maximal flow functions, path quantification that ranges over paths along\nwhich non-zero flow travels, past operators, and first-order quantification of\nflow values. We focus on the model-checking problem and show that it is\nPSPACE-complete, as it is for CTL*. Handling of flow quantifiers, however,\nincreases the complexity in terms of the network to ${\\rm P}^{\\rm NP}$, even\nfor the LFL and BFL fragments, which are the flow-counterparts of LTL and CTL.\nWe are still able to point to a useful fragment of BFL* for which the\nmodel-checking problem can be solved in polynomial time. Finally, we introduce\nand study the query-checking problem for BFL*, where under-specified BFL*\nformulas are used for network exploration.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 13:40:51 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 21:13:36 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 08:59:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kupferman", "Orna", ""], ["Vardi", "Gal", ""]]}, {"id": "1806.06114", "submitter": "Mark Bickford", "authors": "Mark Bickford", "title": "Formalizing Category Theory and Presheaf Models of Type Theory in Nuprl", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is the first in a series of articles that explain the\nformalization of a constructive model of cubical type theory in Nuprl. In this\ndocument we discuss only the parts of the formalization that do not depend on\nthe choice of base category. So, it spells out how we make the first steps of\nour formalization of cubical type theory.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 20:16:46 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Bickford", "Mark", ""]]}, {"id": "1806.06143", "submitter": "Radu Grigore", "authors": "Radu Grigore and Stefan Kiefer", "title": "Selective Monitoring", "comments": "CONCUR 2018", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2018.20", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study selective monitors for labelled Markov chains. Monitors observe the\noutputs that are generated by a Markov chain during its run, with the goal of\nidentifying runs as correct or faulty. A monitor is selective if it skips\nobservations in order to reduce monitoring overhead. We are interested in\nmonitors that minimize the expected number of observations. We establish an\nundecidability result for selectively monitoring general Markov chains. On the\nother hand, we show for non-hidden Markov chains (where any output identifies\nthe state the Markov chain is in) that simple optimal monitors exist and can be\ncomputed efficiently, based on DFA language equivalence. These monitors do not\ndepend on the precise transition probabilities in the Markov chain. We report\non experiments where we compute these monitors for several open-source Java\nprojects.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 22:08:38 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 10:48:57 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Grigore", "Radu", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1806.06537", "submitter": "Antonio Bucciarelli", "authors": "Antonio Bucciarelli, Antonio Ledda, Francesco Paoli, Antonino Salibra", "title": "Boolean-like algebras of finite dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Boolean-like algebras of dimension n (nBA) having n constants\ne1,...,en, and an (n+1)-ary operation q (a \"generalised if-then-else\") that\ninduces a decomposition of the algebra into n factors through the so-called\nn-central elements. Varieties of nBAs share many remarkable properties with the\nvariety of Boolean algebras and with primal varieties. Exploiting the concept\nof central element, we extend the notion of Boolean power to that of semiring\npower and we prove two representation theorems: (i) Any pure nBA is isomorphic\nto the algebra of n-central elements of a Boolean vector space; (ii) Any member\nof a variety of nBAs with one generator is isomorphic to a Boolean power of\nthis generator. This gives a new proof of Foster's theorem on primal varieties.\nThe nBAs provide the algebraic framework for generalising the classical\npropositional calculus to the case of n - perfectly symmetric - truth-values.\nEvery finite-valued tabular logic can be embedded into such an n-valued\npropositional logic, nCL, and this embedding preserves validity. We define a\nconfluent and terminating first-order rewriting system for deciding validity in\nnCL, and, via the embeddings, in all the finite tabular logics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 07:54:39 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Bucciarelli", "Antonio", ""], ["Ledda", "Antonio", ""], ["Paoli", "Francesco", ""], ["Salibra", "Antonino", ""]]}, {"id": "1806.06683", "submitter": "Mingzhang Huang", "authors": "Mingzhang Huang, Hongfei Fu and Krishnendu Chatterjee", "title": "New Approaches for Almost-Sure Termination of Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the almost-sure termination problem for probabilistic programs.\nFirst, we show that supermartingales with lower bounds on conditional absolute\ndifference provide a sound approach for the almost-sure termination problem.\nMoreover, using this approach we can obtain explicit optimal bounds on tail\nprobabilities of non-termination within a given number of steps. Second, we\npresent a new approach based on Central Limit Theorem for the almost-sure\ntermination problem, and show that this approach can establish almost-sure\ntermination of programs which none of the existing approaches can handle.\nFinally, we discuss algorithmic approaches for the two above methods that lead\nto automated analysis techniques for almost-sure termination of probabilistic\nprograms.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 05:42:18 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 06:21:12 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Huang", "Mingzhang", ""], ["Fu", "Hongfei", ""], ["Chatterjee", "Krishnendu", ""]]}, {"id": "1806.06759", "submitter": "Ivan Scagnetto", "authors": "Alberto Ciaffaglione, Furio Honsell, Marina Lenisa, Ivan Scagnetto", "title": "Lambda-calculus and Reversible Automatic Combinators", "comments": "43 pages (22+21 of Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2005, Abramsky introduced various linear/affine combinatory algebras of\npartial involutions over a suitable formal language, to discuss reversible\ncomputation in a game-theoretic setting. These algebras arise as instances of\nthe general paradigm explored by Haghverdi (Abramsky's Programme), which\namounts to defining a lambda-algebra starting from a GoI Situation in a traced\nsymmetric monoidal category. We investigate this construction from the point of\nview of the model theory of lambda-calculus. We focus on the strictly linear\nand affine parts of Abramsky's Affine Combinatory Algebras, sketching how to\nencompass the full algebra. The gist of our approach is that the GoI\ninterpretation of a term based on involutions is dual to the principal type of\nthe term, w.r.t. the type discipline for a linear/affine lambda-calculus. In\nthe general case the type discipline and the calculus need to be extended,\nresp., with intersection, !-types, and !-abstractions. Our analysis unveils\nthree conceptually independent, but ultimately equivalent, accounts of\napplication in the lambda-calculus: beta-reduction, the GoI application of\ninvolutions based on symmetric feedback (Girard's Execution Formula), and\nunification of principal types. Thus we provide an answer, in the strictly\naffine case, to the question raised in [1] of characterising the partial\ninvolutions arising from bi-orthogonal pattern matching automata, which are\ndenotations of affine combinators, and we point to the answer to the full\nquestion. Furthermore, we prove that the strictly linear combinatory algebra of\npartial involutions is a strictly linear lambda-algebra, albeit not a\ncombinatory model, while both the strictly affine combinatory algebra and the\nfull affine combinatory algebra are not. To check all the equations involved in\nthe definition of affine lambda-algebra, we implement in Erlang application of\ninvolutions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:14:03 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 13:33:06 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Ciaffaglione", "Alberto", ""], ["Honsell", "Furio", ""], ["Lenisa", "Marina", ""], ["Scagnetto", "Ivan", ""]]}, {"id": "1806.07041", "submitter": "Taro Sekiyama", "authors": "Taro Sekiyama, Atsushi Igarashi", "title": "Reasoning about Polymorphic Manifest Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifest contract calculi, which integrate cast-based dynamic contract\nchecking and refinement type systems, have been studied as foundations for\nhybrid contract checking. In this article, we study techniques to reasoning\nabout a polymorphic manifest contract calculus, including a few program\ntransformations related to static contract verification. We first define a\npolymorphic manifest contract calculus $\\mathrm{F}_{H}$, which is much simpler\nthan a previously studied one with delayed substitution, and a logical relation\nfor it and prove that the logical relation is sound with respect to contextual\nequivalence. Next, we show that the upcast elimination property, which has been\nstudied as correctness of subtyping-based static cast verification, holds for\n$\\mathrm{F}_{H}$. More specifically, we give a subtyping relation (which is not\npart of the calculus) for $\\mathrm{F}_{H}$ types and prove that a term obtained\nby eliminating upcasts---casts from one type to a supertype of it---is\nlogically related and so contextually equivalent to the original one. We also\njustify two other program transformations for casts: selfification and static\ncast decomposition, which help upcast elimination. A challenge is that, due to\nthe subsumption-free approach to manifest contracts, these program\ntransformations do not always preserve well-typedness of terms. To address it,\nthe logical relation and contextual equivalence in this work are defined as\nsemityped relations: only one side of the relations is required to be well\ntyped and the other side may be ill typed.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 05:08:27 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Sekiyama", "Taro", ""], ["Igarashi", "Atsushi", ""]]}, {"id": "1806.07100", "submitter": "Germ\\'an Vidal", "authors": "Ivan Lanese, Naoki Nishida, Adri\\'an Palacios, and Germ\\'an Vidal", "title": "A Theory of Reversibility for Erlang", "comments": "To appear in the Journal of Logical and Algebraic Methods in\n  Programming (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a reversible language, any forward computation can be undone by a finite\nsequence of backward steps. Reversible computing has been studied in the\ncontext of different programming languages and formalisms, where it has been\nused for testing and verification, among others. In this paper, we consider a\nsubset of Erlang, a functional and concurrent programming language based on the\nactor model. We present a formal semantics for reversible computation in this\nlanguage and prove its main properties, including its causal consistency. We\nalso build on top of it a rollback operator that can be used to undo the\nactions of a process up to a given checkpoint.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 08:35:51 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Lanese", "Ivan", ""], ["Nishida", "Naoki", ""], ["Palacios", "Adri\u00e1n", ""], ["Vidal", "Germ\u00e1n", ""]]}, {"id": "1806.07127", "submitter": "Flavio Ferrarotti", "authors": "Flavio Ferrarotti, Sen\\'en Gonz\\'alez, Klaus-Dieter Schewe, Jos\\'e\n  Mar\\'ia Turull-Torres", "title": "The Polylog-Time Hierarchy Captured by Restricted Second-Order Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathrm{SO}^{\\mathit{plog}}$ denote the restriction of second-order\nlogic, where second-order quantification ranges over relations of size at most\npoly-logarithmic in the size of the structure. In this article we investigate\nthe problem, which Turing machine complexity class is captured by Boolean\nqueries over ordered relational structures that can be expressed in this logic.\nFor this we define a hierarchy of fragments $\\Sigma^{\\mathit{plog}}_m$ (and\n$\\Pi^{\\mathit{plog}}_m$) defined by formulae with alternating blocks of\nexistential and universal second-order quantifiers in quantifier-prenex normal\nform. We first show that the existential fragment $\\Sigma^{\\mathit{plog}}_1$\ncaptures NPolyLogTime, i.e. the class of Boolean queries that can be accepted\nby a non-deterministic Turing machine with random access to the input in time\n$O((\\log n)^k)$ for some $k \\ge 0$. Using alternating Turing machines with\nrandom access input allows us to characterise also the fragments\n$\\Sigma^{\\mathit{plog}}_m$ (and $\\Pi^{\\mathit{plog}}_m$) as those Boolean\nqueries with at most $m$ alternating blocks of second-order quantifiers that\nare accepted by an alternating Turing machine. Consequently,\n$\\mathrm{SO}^{\\mathit{plog}}$ captures the whole poly-logarithmic time\nhierarchy. We demonstrate the relevance of this logic and complexity class by\nseveral problems in database theory.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 09:41:57 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Ferrarotti", "Flavio", ""], ["Gonz\u00e1lez", "Sen\u00e9n", ""], ["Schewe", "Klaus-Dieter", ""], ["Turull-Torres", "Jos\u00e9 Mar\u00eda", ""]]}, {"id": "1806.07164", "submitter": "Saurabh Joshi", "authors": "Saurabh Joshi, Prateek Kumar, Ruben Martins and Sukrut Rao", "title": "Approximation Strategies for Incomplete MaxSAT", "comments": "10 pages, 3 algorithms, 1 figure, International Conference on\n  Principles and Practice of Constraint Programming (CP) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incomplete MaxSAT solving aims to quickly find a solution that attempts to\nminimize the sum of the weights of the unsatisfied soft clauses without\nproviding any optimality guarantees.\n  In this paper, we propose two approximation strategies for improving\nincomplete MaxSAT solving. In one of the strategies, we cluster the weights and\napproximate them with a representative weight. In another strategy, we break up\nthe problem of minimizing the sum of weights of unsatisfiable clauses into\nmultiple minimization subproblems. Experimental results show that approximation\nstrategies can be used to find better solutions than the best incomplete\nsolvers in the MaxSAT Evaluation 2017.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 11:37:50 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Joshi", "Saurabh", ""], ["Kumar", "Prateek", ""], ["Martins", "Ruben", ""], ["Rao", "Sukrut", ""]]}, {"id": "1806.07187", "submitter": "Jie Fan", "authors": "Jie Fan", "title": "A road to ultrafilter extensions", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a uniform method of constructing ultrafilter extensions from\ncanonical models, which is based on the similarity between ultrafilters and\nmaximal consistent sets. This method can help us understand why the known\nultrafilter extensions of models for normal modal logics and for classical\nmodal logics are so defined. We then apply this method to obtain ultrafilter\nextensions of models for Kripke contingency logics and for neighborhood\ncontingency logics.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 12:39:28 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Fan", "Jie", ""]]}, {"id": "1806.07197", "submitter": "Bas Spitters", "authors": "Helene Haagh, Aleksandr Karbyshev, Sabine Oechsner, Bas Spitters,\n  Pierre-Yves Strub", "title": "Computer-aided proofs for multiparty computation with active security", "comments": null, "journal-ref": "Computer Security Foundations (CSF) 2018", "doi": "10.1109/CSF.2018.00016", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure multi-party computation (MPC) is a general cryptographic technique\nthat allows distrusting parties to compute a function of their individual\ninputs, while only revealing the output of the function. It has found\napplications in areas such as auctioning, email filtering, and secure\nteleconference. Given its importance, it is crucial that the protocols are\nspecified and implemented correctly. In the programming language community it\nhas become good practice to use computer proof assistants to verify correctness\nproofs. In the field of cryptography, EasyCrypt is the state of the art proof\nassistant. It provides an embedded language for probabilistic programming,\ntogether with a specialized logic, embedded into an ambient general purpose\nhigher-order logic. It allows us to conveniently express cryptographic\nproperties. EasyCrypt has been used successfully on many applications,\nincluding public-key encryption, signatures, garbled circuits and differential\nprivacy. Here we show for the first time that it can also be used to prove\nsecurity of MPC against a malicious adversary. We formalize additive and\nreplicated secret sharing schemes and apply them to Maurer's MPC protocol for\nsecure addition and multiplication. Our method extends to general polynomial\nfunctions. We follow the insights from EasyCrypt that security proofs can be\noften be reduced to proofs about program equivalence, a topic that is well\nunderstood in the verification of programming languages. In particular, we show\nthat in the passive case the non-interference-based definition is equivalent to\na standard game-based security definition. For the active case we provide a new\nNI definition, which we call input independence.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 12:55:38 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Haagh", "Helene", ""], ["Karbyshev", "Aleksandr", ""], ["Oechsner", "Sabine", ""], ["Spitters", "Bas", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1806.07239", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima, Yilun He", "title": "PaMpeR: Proof Method Recommendation System for Isabelle/HOL", "comments": "An anonymized version of this paper has been submitted to a Computer\n  Science conference in April 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding which sub-tool to use for a given proof state requires expertise\nspecific to each ITP. To mitigate this problem, we present PaMpeR, a Proof\nMethod Recommendation system for Isabelle/HOL. Given a proof state, PaMpeR\nrecommends proof methods to discharge the proof goal and provides qualitative\nexplanations as to why it suggests these methods. PaMpeR generates these\nrecommendations based on existing hand-written proof corpora, thus transferring\nexperienced users' expertise to new users. Our evaluation shows that PaMpeR\ncorrectly predicts experienced users' proof methods invocation especially when\nit comes to special purpose proof methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 13:58:14 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Nagashima", "Yutaka", ""], ["He", "Yilun", ""]]}, {"id": "1806.07275", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "Upward confluence in the interaction calculus", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lambda calculus is not upward confluent, one of counterexamples known\nthanks to Plotkin. This paper investigates upward confluence in the interaction\ncalculus. Can an interaction system have this property? We positively answer\nthis question and also provide a necessary and sufficient condition for\nstronger one-step upward confluence which happens to be very restrictive.\nHowever, the provided condition is not necessary for upward confluence as we\nprove that the interaction system of the linear lambda calculus is upward\nconfluent.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 14:23:14 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 20:08:26 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 10:15:14 GMT"}, {"version": "v4", "created": "Sun, 14 Oct 2018 14:44:38 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1806.07376", "submitter": "Mehul Bhatt", "authors": "Jakob Suchan, Mehul Bhatt, Srikrishna Vardarajan, Seyed Ali Amirshahi,\n  Stella Yu", "title": "Semantic Analysis of (Reflectional) Visual Symmetry: A Human-Centred\n  Computational Model for Declarative Explainability", "comments": "Preprint of accepted article / Journal: Advances in Cognitive\n  Systems. ( http://www.cogsys.org/journal )", "journal-ref": "Advances in Cognitive Systems. (http://www.cogsys.org/journal),\n  2018", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational model for the semantic interpretation of symmetry\nin naturalistic scenes. Key features include a human-centred representation,\nand a declarative, explainable interpretation model supporting deep semantic\nquestion-answering founded on an integration of methods in knowledge\nrepresentation and deep learning based computer vision. In the backdrop of the\nvisual arts, we showcase the framework's capability to generate human-centred,\nqueryable, relational structures, also evaluating the framework with an\nempirical study on the human perception of visual symmetry. Our framework\nrepresents and is driven by the application of foundational, integrated Vision\nand Knowledge Representation and Reasoning methods for applications in the\narts, and the psychological and social sciences.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 11:47:46 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 17:59:34 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Suchan", "Jakob", ""], ["Bhatt", "Mehul", ""], ["Vardarajan", "Srikrishna", ""], ["Amirshahi", "Seyed Ali", ""], ["Yu", "Stella", ""]]}, {"id": "1806.07523", "submitter": "Yuting Wang", "authors": "Gopalan Nadathur, Yuting Wang", "title": "Schematic Polymorphism in the Abella Proof Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Abella interactive theorem prover has proven to be an effective vehicle\nfor reasoning about relational specifications. However, the system has a\nlimitation that arises from the fact that it is based on a simply typed logic:\nformalizations that are identical except in the respect that they apply to\ndifferent types have to be repeated at each type. We develop an approach that\novercomes this limitation while preserving the logical underpinnings of the\nsystem. In this approach object constructors, formulas and other relevant\nlogical notions are allowed to be parameterized by types, with the\ninterpretation that they stand for the (infinite) collection of corresponding\nconstructs that are obtained by instantiating the type parameters. The proof\nstructures that we consider for formulas that are schematized in this fashion\nare limited to ones whose type instances are valid proofs in the simply typed\nlogic. We develop schematic proof rules that ensure this property, a task that\nis complicated by the fact that type information influences the notion of\nunification that plays a key role in the logic. Our ideas, which have been\nimplemented in an updated version of the system, accommodate schematic\npolymorphism both in the core logic of Abella and in the executable\nspecification logic that it embeds.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 02:04:41 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Nadathur", "Gopalan", ""], ["Wang", "Yuting", ""]]}, {"id": "1806.08038", "submitter": "Valery Isaev", "authors": "Valery Isaev", "title": "Indexed type theories", "comments": "53 pages", "journal-ref": null, "doi": "10.1017/S0960129520000092", "report-no": null, "categories": "math.CT cs.LO math.AT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define indexed type theories which are related to indexed\n($\\infty$-)categories in the same way as (homotopy) type theories are related\nto ($\\infty$-)categories. We define several standard constructions for such\ntheories including finite (co)limits, arbitrary (co)products, exponents, object\nclassifiers, and orthogonal factorization systems. We also prove that these\nconstructions are equivalent to their type theoretic counterparts such as\n$\\Sigma$-types, unit types, identity types, finite higher inductive types,\n$\\Pi$-types, univalent universes, and higher modalities.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 01:31:30 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Isaev", "Valery", ""]]}, {"id": "1806.08170", "submitter": "Patrick Totzke", "authors": "Parosh Aziz Abdulla, Mohamed Faouzi Atig, Radu Ciobanu, Richard Mayr,\n  Patrick Totzke", "title": "Universal Safety for Timed Petri Nets is PSPACE-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A timed network consists of an arbitrary number of initially identical\n1-clock timed automata, interacting via hand-shake communication. In this\nsetting there is no unique central controller, since all automata are initially\nidentical. We consider the universal safety problem for such controller-less\ntimed networks, i.e., verifying that a bad event (enabling some given\ntransition) is impossible regardless of the size of the network.\n  This universal safety problem is dual to the existential coverability problem\nfor timed-arc Petri nets, i.e., does there exist a number $m$ of tokens, such\nthat starting with $m$ tokens in a given place, and none in the other places,\nsome given transition is eventually enabled.\n  We show that these problems are PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 11:12:10 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Ciobanu", "Radu", ""], ["Mayr", "Richard", ""], ["Totzke", "Patrick", ""]]}, {"id": "1806.08206", "submitter": "Tangliu Wen", "authors": "Tangliu Wen", "title": "Proving Linearizability Using Reduction", "comments": "the co-authors of the paper require me to withdraw it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipton's reduction theory provides an intuitive and simple way for deducing\nthe non-interference properties of concurrent programs, but it is difficult to\ndirectly apply the technique to verify linearizability of sophisticated\nfine-grained concurrent data structures. In this paper, we propose three\nreduction-based proof methods that can handle such data structures. The key\nidea behind our reduction methods is that an irreducible operation can be\nviewed as an atomic operation at a higher level of abstraction. This allows us\nto focus on the reduction properties of an operation related to its abstract\nsemantics. We have successfully applied the methods to verify 11 concurrent\ndata structures including the most challenging ones: the Herlihy and Wing\nqueue, the HSY elimination-based stack, and the time-stamped queue, and the\nlazy list. Our methods inherit intuition and simplicity of Lipton's reduction,\nand concurrent data structures designers can easily and quickly learn to use\nthe methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 12:43:22 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 08:59:18 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 01:02:50 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Wen", "Tangliu", ""]]}, {"id": "1806.08298", "submitter": "Alessandro Antonucci", "authors": "Alessandro Antonucci and Alessandro Facchini", "title": "A Credal Extension of Independent Choice Logic", "comments": "SUM 2018 (12th International Conference on Scalable Uncertainty\n  Management)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of Poole's independent choice logic based on a\nrelaxation of the underlying independence assumptions. A credal semantics\ninvolving multiple joint probability mass functions over the possible worlds is\nadopted. This represents a conservative approach to probabilistic logic\nprogramming achieved by considering all the mass functions consistent with the\nprobabilistic facts. This allows to model tasks for which independence among\nsome probabilistic choices cannot be assumed, and a specific dependence model\ncannot be assessed. Preliminary tests on an object ranking application show\nthat, despite the loose underlying assumptions, informative inferences can be\nextracted.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 15:46:33 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Antonucci", "Alessandro", ""], ["Facchini", "Alessandro", ""]]}, {"id": "1806.08304", "submitter": "Brendan Fong", "authors": "Brendan Fong and David I Spivak", "title": "Hypergraph Categories", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph categories have been rediscovered at least five times, under\nvarious names, including well-supported compact closed categories, dgs-monoidal\ncategories, and dungeon categories. Perhaps the reason they keep being\nreinvented is two-fold: there are many applications---including to automata,\ndatabases, circuits, linear relations, graph rewriting, and belief\npropagation---and yet the standard definition is so involved and ornate as to\nbe difficult to find in the literature. Indeed, a hypergraph category is,\nroughly speaking, a \"symmetric monoidal category in which each object is\nequipped with the structure of a special commutative Frobenius monoid,\nsatisfying certain coherence conditions\".\n  Fortunately, this description can be simplified a great deal: a hypergraph\ncategory is simply a \"cospan-algebra\". The goal of this paper is to remove the\nscare-quotes and make the previous statement precise. We prove two main\ntheorems. First is a coherence theorem for hypergraph categories, which says\nthat every hypergraph category is equivalent to an objectwise-free hypergraph\ncategory. Second, we prove that the category of objectwise-free hypergraph\ncategories is equivalent to the category of cospan-algebras.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 16:03:04 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 19:39:12 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 23:06:25 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Fong", "Brendan", ""], ["Spivak", "David I", ""]]}, {"id": "1806.08490", "submitter": "Bruno Bentzen", "authors": "Bruno Bentzen", "title": "Cubical informal type theory: the higher groupoid structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a project of developing conventions and notations for informal type\ntheory carried out in the homotopy type theory book for a framework built out\nof an augmentation of constructive type theory with axioms governing\nhigher-dimensional constructions via Voevodsky's univalance axiom and\nhigher-inductive types, this paper proposes a way of doing informal type theory\nwith a cubical type theory as the underlying foundation instead. To that end,\nwe adopt a cubical type theory recently proposed by Angiuli, Hou (Favonia) and\nHarper, a framework with a cumulative hierarchy of univalent Kan universes,\nfull univalence and instances of higher-inductive types. In the present paper\nwe confine ourselves to some elementary theorems concerning the higher groupoid\nstructure of types.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 04:33:46 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Bentzen", "Bruno", ""]]}, {"id": "1806.08536", "submitter": "Claire Medrala", "authors": "Olivier Hermant (CRI)", "title": "Polarized Rewriting and Tableaux in B Set Theory", "comments": null, "journal-ref": "3RD INTERNATIONAL WORKSHOP ABOUT SETS AND TOOLS (SETS 2018), Jun\n  2018, Southampton, United Kingdom", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and extension of the tableau-based first-order automated theorem\nprover Zenon Modulo to polarized rewriting. We introduce the framework and\nexplain the potential benefits. The first target is an industrial benchmark\ncomposed of B Set Theory problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 07:56:56 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Hermant", "Olivier", "", "CRI"]]}, {"id": "1806.08653", "submitter": "Einar Broch Johnsen", "authors": "Einar Broch Johnsen, Martin Steffen, Johanna Beate Stumpf", "title": "Assumption-Commitment Types for Resource Management in Virtually Timed\n  Ambients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a type system for resource management in the context of\nnested virtualization. With nested virtualization, virtual machines compete\nwith other processes for the resources of their host environment in order to\nprovision their own processes, which could again be virtual machines. The\ncalculus of virtually timed ambients formalizes such resource provisioning,\nextending the capabilities of mobile ambients to model the dynamic creation,\nmigration, and destruction of virtual machines. The proposed type system uses\nassumptions about the outside of a virtually timed ambient to guarantee\nresource provisioning on the inside. We prove subject reduction and progress\nfor well-typed virtually timed ambients, expressing that upper bounds on\nresource needs are preserved by reduction and that processes do not run out of\nresources.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 13:26:44 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 09:14:35 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Johnsen", "Einar Broch", ""], ["Steffen", "Martin", ""], ["Stumpf", "Johanna Beate", ""]]}, {"id": "1806.08684", "submitter": "Claudio Menghi", "authors": "Claudio Menghi, Marcello Bersani, Matteo Rossi and Pierluigi San\n  Pietro", "title": "Verifying MITL formulae on Timed Automata considering a Continuous Time\n  Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timed Automata (TA) is de facto a standard modelling formalism to represent\nsystems when the interest is the analysis of their behaviour as time\nprogresses. This modelling formalism is mostly used for checking whether the\nbehaviours of a system satisfy a set of properties of interest. Even if\nefficient model-checkers for Timed Automata exist, these tools are not easily\nconfigurable. First, they are not designed to easily allow adding new Timed\nAutomata constructs, such as new synchronization mechanisms or communication\nprocedures, but they assume a fixed set of Timed Automata constructs. Second,\nthey usually do not support the full Metric Interval Temporal Logic (MITL) and\nrely on a precise semantics for the logic in which the property of interest is\nspecified which cannot be easily modified and customized. Finally, they do not\neasily allow using different solvers that may speed up verification in\ndifferent contexts. This paper presents a novel technique to perform model\nchecking of full Metric Interval Temporal Logic (MITL) properties on TA. The\ntechnique relies on the translation of both the TA and the MITL formula into an\nintermediate Constraint LTL over clocks (CLTLoc) formula which is verified\nthrough an available decision procedure. The technique is flexible since the\nintermediate logic allows the encoding of new semantics as well as new TA\nconstructs, by just adding new CLTLoc formulae. Furthermore, our technique is\nnot bound to a specific solver as the intermediate CLTLoc formula can be\nverified using different procedures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 14:14:09 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:23:24 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Menghi", "Claudio", ""], ["Bersani", "Marcello", ""], ["Rossi", "Matteo", ""], ["Pietro", "Pierluigi San", ""]]}, {"id": "1806.08771", "submitter": "David Feller", "authors": "David Feller, Joe B. Wells, Fairouz Kamareddine (ULTRA), Sebastien\n  Carlier", "title": "What Does This Notation Mean Anyway?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the introduction of BNF notation by Backus for the Algol 60 report\nand subsequent notational variants, a metalanguage involving formal \"grammars\"\nhas developed for discussing structured objects in Computer Science and\nMathematical Logic. We refer to this offspring of BNF as Math-BNF or MBNF, to\nthe original BNF and its notational variants just as BNF, and to aspects common\nto both as BNF-style. What all BNF-style notations share is the use of\nproduction rules roughly of this form: $$\\bullet \\mathrel{::=} \\circ_1 \\mid\n\\cdots \\mid \\circ_n $$ Normally, such a rule says \"every instance of $\\circ_i$\nfor $i \\in \\{1, \\ldots, n\\}$ is also an in stance of $\\bullet$\". MBNF is\ndistinct from BNF in the entities and operations it allows. Instead of strings,\nMBNF builds arrangements of symbols that we call math-text. Sometimes \"syntax\"\nis defined by interleaving MBNF production rules and other mathematical\ndefinitions that can contain chunks of math-text. There is no clear definition\nof MBNF. Readers do not have a document which tells them how MBNF is to be read\nand must learn MBNF through a process of cultural initiation. To the extent\nthat MBNF is defined, it is largely through examples scattered throughout the\nliterature and which require readers to guess the mathematical structures\nunderpinning them. This paper gives MBNF examples illustrating some of the\ndifferences between MBNF and BNF. We propose a definition of syntactic math\ntext (SMT) which handles many (but far from all) uses of math-text and MBNF in\nthe wild. We aim to balance the goal of being accessible and not requiring too\nmuch prerequisite knowledge with the conflicting goal of providing a rich\nmathematical structure that already supports many uses and has possibilities to\nbe extended to support more challenging cases.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 13:07:15 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Feller", "David", "", "ULTRA"], ["Wells", "Joe B.", "", "ULTRA"], ["Kamareddine", "Fairouz", "", "ULTRA"], ["Carlier", "Sebastien", ""]]}, {"id": "1806.08775", "submitter": "Aina Niemetz", "authors": "Clark Barrett, Haniel Barbosa, Martin Brain, Duligur Ibeling, Tim\n  King, Paul Meng, Aina Niemetz, Andres N\\\"otzli, Mathias Preiner, Andrew\n  Reynolds, Cesare Tinelli", "title": "CVC4 at the SMT Competition 2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a description of the CVC4 SMT solver as entered into the 2018\nSMT Competition. We only list important differences from the 2017 SMT\nCompetition version of CVC4. For further and more detailed information about\nCVC4, please refer to the original paper, the CVC4 website, or the source code\non GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 01:38:24 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Barrett", "Clark", ""], ["Barbosa", "Haniel", ""], ["Brain", "Martin", ""], ["Ibeling", "Duligur", ""], ["King", "Tim", ""], ["Meng", "Paul", ""], ["Niemetz", "Aina", ""], ["N\u00f6tzli", "Andres", ""], ["Preiner", "Mathias", ""], ["Reynolds", "Andrew", ""], ["Tinelli", "Cesare", ""]]}, {"id": "1806.08810", "submitter": "Nima Roohi", "authors": "Nima Roohi, Ramneet Kaur, James Weimer, Oleg Sokolsky, Insup Lee", "title": "Self-Driving Vehicle Verification Towards a Benchmark", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial cyber-physical systems are hybrid systems with strict safety\nrequirements. Despite not having a formal semantics, most of these systems are\nmodeled using Stateflow/Simulink for mainly two reasons: (1) it is easier to\nmodel, test, and simulate using these tools, and (2) dynamics of these systems\nare not supported by most other tools. Furthermore, with the ever growing\ncomplexity of cyber-physical systems, grows the gap between what can be modeled\nusing an automatic formal verification tool and models of industrial\ncyber-physical systems. In this paper, we present a simple formal model for\nself-deriving cars. While after some simplification, safety of this system has\nalready been proven manually, to the best of our knowledge, no automatic formal\nverification tool supports its dynamics. We hope this serves as a challenge\nproblem for formal verification tools targeting industrial applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 12:23:35 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Roohi", "Nima", ""], ["Kaur", "Ramneet", ""], ["Weimer", "James", ""], ["Sokolsky", "Oleg", ""], ["Lee", "Insup", ""]]}, {"id": "1806.08920", "submitter": "Janardan Misra", "authors": "Janardan Misra", "title": "A Note on Digitization of Real-Time Models and Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digitization provides a sound and complete method to reduce the problem of\nverifying whether a real-time system satisfies a property under dense-time\nsemantics to whether the same real-time system satisfies the property over\ndiscrete-time. This is a brief overview of digitization of real-time models and\nlogics covering known results, value, limitations, and alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 07:19:59 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Misra", "Janardan", ""]]}, {"id": "1806.09031", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Nihil Shah", "title": "Relating Structure and Power: Comonadic Semantics for Computational\n  Resources", "comments": "To appear in Proceedings of Computer Science Logic 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial games are widely used in finite model theory, constraint\nsatisfaction, modal logic and concurrency theory to characterize logical\nequivalences between structures. In particular, Ehrenfeucht-Fraisse games,\npebble games, and bisimulation games play a central role. We show how each of\nthese types of games can be described in terms of an indexed family of comonads\non the category of relational structures and homomorphisms. The index k is a\nresource parameter which bounds the degree of access to the underlying\nstructure. The coKleisli categories for these comonads can be used to give\nsyntax-free characterizations of a wide range of important logical\nequivalences. Moreover, the coalgebras for these indexed comonads can be used\nto characterize key combinatorial parameters: tree-depth for the\nEhrenfeucht-Fraisse comonad, tree-width for the pebbling comonad, and\nsynchronization-tree depth for the modal unfolding comonad. These results pave\nthe way for systematic connections between two major branches of the field of\nlogic in computer science which hitherto have been almost disjoint: categorical\nsemantics, and finite and algorithmic model theory.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 20:09:13 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 19:02:19 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Abramsky", "Samson", ""], ["Shah", "Nihil", ""]]}, {"id": "1806.09236", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro and Octavio Malherbe", "title": "A concrete model for a typed linear algebraic lambda calculus", "comments": "Extended revisited version of ENTCS 344:83-100, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an adequate, concrete, categorical-based model for Lambda-S, which is\na typed version of a linear-algebraic lambda calculus, extended with\nmeasurements. Lambda-S is an extension to first-order lambda calculus unifying\ntwo approaches of non-cloning in quantum lambda-calculi: to forbid duplication\nof variables, and to consider all lambda-terms as algebraic linear functions.\nThe type system of Lambda-S have a superposition constructor S such that a type\nA is considered as the base of a vector space while SA is its span. Our model\nconsiders S as the composition of two functors in an adjunction relation\nbetween the category of sets and the category of vector spaces over C. The\nright adjoint is a forgetful functor U, which is hidden in the language, and\nplays a central role in the computational reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 23:36:13 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:10:02 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 15:00:47 GMT"}, {"version": "v4", "created": "Fri, 11 Jan 2019 14:08:32 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 14:33:07 GMT"}, {"version": "v6", "created": "Mon, 5 Oct 2020 23:12:37 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Malherbe", "Octavio", ""]]}, {"id": "1806.09329", "submitter": "Domenico Cantone", "authors": "Domenico Cantone and Alberto Policriti", "title": "Encoding Sets as Real Numbers (Extended version)", "comments": "This is the extended version of a paper which will appear in the\n  proceedings of SETS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the Ackermann encoding $\\mathbb{N}(x) := \\sum_{y\\in\nx}2^{\\mathbb{N}(y)}$ of the hereditarily finite sets by the natural numbers,\napplicable to the larger collection $\\mathsf{HF}^{1/2}$ of the hereditarily\nfinite hypersets. The proposed variation is obtained by simply placing a\n`minus' sign before each exponent in the definition of $\\mathbb{N}$, resulting\nin the expression $\\mathbb{R}(x) := \\sum_{y\\in x}2^{-\\mathbb{R}(y)}$. By a\ncareful analysis, we prove that the encoding $\\mathbb{R}_{A}$ is well-defined\nover the whole collection $\\mathsf{HF}^{1/2}$, as it allows one to univocally\nassign a real-valued code to each hereditarily finite hyperset. We also address\nsome preliminary cases of the injectivity problem for $\\mathbb{R}_{A}$.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 08:53:33 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Cantone", "Domenico", ""], ["Policriti", "Alberto", ""]]}, {"id": "1806.09383", "submitter": "Iddo Tzameret", "authors": "Fedor Part, Iddo Tzameret", "title": "Resolution with Counting: Dag-Like Lower Bounds and Different Moduli", "comments": "40 pages. To appear in ITCS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolution over linear equations is a natural extension of the popular\nresolution refutation system, augmented with the ability to carry out basic\ncounting. Denoted Res(lin_R), this refutation system operates with disjunctions\nof linear equations with boolean variables over a ring R, to refute\nunsatisfiable sets of such disjunctions. Beginning in the work of [RT08],\nthrough the work of [IS14] which focused on tree-like lower bounds, this\nrefutation system was shown to be fairly strong. Subsequent work (cf.[Kra17,\nIS14, KO18, GK18]) made it evident that establishing lower bounds against\ngeneral Res(lin_R) refutations is a challenging and interesting task since the\nsystem captures a 'minimal' extension of resolution with counting gates for\nwhich no super-polynomial lower bounds are known to date.\n  We provide the first super-polynomial size lower bounds on general (dag-like)\nresolution over linear equations refutations in the large characteristic\nregime. In particular we prove that the subset-sum principle 1+x1+...+2^n xn=0\nrequires refutations of exponential size over Q. Our proof technique is\nnontrivial and novel: roughly speaking, we show that under certain conditions\nevery refutation of a subset-sum instance f=0 must pass through a fat clause\ncontaining an equation f=alpha for each alpha in the image of f under boolean\nassignments. We develop a somewhat different approach to prove exponential\nlower bounds against tree-like refutations of any subset-sum instance that\ndepends on n variables, hence also separating tree-like from dag-like\nrefutations over the rationals. (Abstract continued in the full paper.)\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 11:09:39 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:42:15 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Part", "Fedor", ""], ["Tzameret", "Iddo", ""]]}, {"id": "1806.09392", "submitter": "Sebastiaan Joosten", "authors": "Sebastiaan J. C. Joosten", "title": "Finding models through graph saturation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a procedure that can be used to automatically satisfy invariants of a\ncertain shape. These invariants may be written with the operations\nintersection, composition and converse over binary relations, and equality over\nthese operations. We call these invariants \\tr{}s that we interpret over\ngraphs. For questions stated through sets of these sentences, this paper gives\na semi-decision procedure we call graph saturation. It decides entailment over\nthese \\tr{}s, inspired on graph rewriting. We prove correctness of the\nprocedure. Moreover, we show the corresponding decision problem to be\nundecidable. This confirms a conjecture previously stated by the author.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 11:34:38 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Joosten", "Sebastiaan J. C.", ""]]}, {"id": "1806.09443", "submitter": "Tomasz Witczak", "authors": "Tomasz Witczak", "title": "Simple example of weak modal logic based on intuitionistic core", "comments": "One of the first attempt to create non-normal (and, in general, very\n  weak) intuitionistic modal logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present simple example of propositional logic which has one\nmodal operator and is based on intuitionistic core. This system is very weak in\nmodal sense - e.g. rules of regularity or monotonicity do not hold. It has\ncomplete semantics composed of possible worlds equipped with neighborhoods and\npre-order relation. We discuss certain restrictions imposed on those\nstructures. Also, we present characterization of axiom 4 known from logic S4.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 13:19:41 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Witczak", "Tomasz", ""]]}, {"id": "1806.09686", "submitter": "Alessandro Gianola", "authors": "Diego Calvanese, Silvio Ghilardi, Alessandro Gianola, Marco Montali\n  and Andrey Rivkin", "title": "Quantifier Elimination for Database Driven Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running verification tasks in database driven systems requires solving\nquantifier elimination problems of a new kind. These quantifier elimination\nproblems are related to the notion of a cover introduced in ESOP 2008 by\nGulwani and Musuvathi. In this paper, we show how covers are strictly related\nto model completions, a well-known topic in model theory. We also investigate\nthe computation of covers within the Superposition Calculus, by adopting a\nconstrained version of the calculus, equipped with appropriate settings and\nreduction strategies. In addition, we show that cover computations are\ncomputationally tractable for the fragment of the language used in applications\nto database driven verification. This observation is confirmed by analyzing the\npreliminary results obtained using the MCMT tool on the verification of\ndata-aware process benchmarks. These benchmarks can be found in the last\nversion of the tool distribution.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 19:57:31 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 14:54:03 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Calvanese", "Diego", ""], ["Ghilardi", "Silvio", ""], ["Gianola", "Alessandro", ""], ["Montali", "Marco", ""], ["Rivkin", "Andrey", ""]]}, {"id": "1806.09760", "submitter": "Brett McLean", "authors": "Robin Hirsch, Brett McLean", "title": "The temporal logic of two-dimensional Minkowski spacetime with\n  slower-than-light accessibility is decidable", "comments": "20 pages", "journal-ref": "Advances in Modal Logic, Volume 12 (2018) 347-366", "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We work primarily with the Kripke frame consisting of two-dimensional\nMinkowski spacetime with the irreflexive accessibility relation 'can reach with\na slower-than-light signal'. We show that in the basic temporal language, the\nset of validities over this frame is decidable. We then refine this to\nPSPACE-complete. In both cases the same result for the corresponding reflexive\nframe follows immediately. With a little more work we obtain\nPSPACE-completeness for the validities of the Halpern-Shoham logic of intervals\non the real line with two different combinations of modalities.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 02:18:39 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Hirsch", "Robin", ""], ["McLean", "Brett", ""]]}, {"id": "1806.09818", "submitter": "Sabine Bauer", "authors": "Sabine Bauer, Martin Hofmann", "title": "Linear Tree Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear tree constraints were introduced by Hofmann and Rodriguez in the\ncontext of amortized resource analysis for object oriented programs. More\nprecisely, they gave a reduction from inference of resource types to constraint\nsolving. Thus, once we have found an algorithm to solve the constraints\ngenerated from a program, we can read off the resource consumption from their\nsolutions.\n  These constraints have the form of pointwise linear inequalities between\ninfinite trees labeled with nonnegative rational numbers. We are interested in\nthe question if a system of such constraints is simultaneously satisfiable.\nBauer and Hofmann have recently identified a fragment of the tree constraint\nproblem (UTC) that is still sufficient for program analysis and they proved\nthat the list case of UTC is decidable, whereas the case with trees of degree\nat least two remained open. In this paper, we solve this problem. We give a\ndecision procedure that covers the entire range of constraints needed for\nresource analysis.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 07:16:06 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Bauer", "Sabine", ""], ["Hofmann", "Martin", ""]]}, {"id": "1806.09848", "submitter": "EPTCS", "authors": "Antonios Gouglidis (School of Computing and Communications, Lancaster\n  University, Lancaster, UK), Christos Grompanopoulos (Department of Mechanical\n  Engineering, University of Western Macedonia, Kozani, Greece), Anastasia\n  Mavridou (Institute for Software Integrated Systems, Vanderbilt University,\n  Nashville, TN, USA)", "title": "Formal Verification of Usage Control Models: A Case Study of UseCON\n  Using TLA+", "comments": "In Proceedings MeTRiD 2018, arXiv:1806.09330", "journal-ref": "EPTCS 272, 2018, pp. 52-64", "doi": "10.4204/EPTCS.272.5", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage control models provide an integration of access control, digital\nrights, and trust management. To achieve this integration, usage control models\nsupport additional concepts such as attribute mutability and continuity of\ndecision. However, these concepts may introduce an additional level of\ncomplexity to the underlying model, rendering its definition a cumbersome and\nprone to errors process. Applying a formal verification technique allows for a\nrigorous analysis of the interactions amongst the components, and thus for\nformal guarantees in respect of the correctness of a model. In this paper, we\nelaborate on a case study, where we express the high-level functional model of\nthe UseCON usage control model in the TLA+ formal specification language, and\nverify its correctness for <=12 uses in both of its supporting authorisation\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 08:53:20 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Gouglidis", "Antonios", "", "School of Computing and Communications, Lancaster\n  University, Lancaster, UK"], ["Grompanopoulos", "Christos", "", "Department of Mechanical\n  Engineering, University of Western Macedonia, Kozani, Greece"], ["Mavridou", "Anastasia", "", "Institute for Software Integrated Systems, Vanderbilt University,\n  Nashville, TN, USA"]]}, {"id": "1806.10025", "submitter": "Youssouf Oualhadj", "authors": "Youssouf Oualhadj, L\\'eo Tible and Daniele Varacca", "title": "Banach-Mazur Parity Games and Almost-sure Winning Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player stochastic games are games with two 2 players and a randomised\nentity called \"nature\". A natural question to ask in this framework is the\nexistence of strategies that ensure that an event happens with probability 1\n(almost-sure strategies). In the case of Markov decision processes, when the\nevent 2 of interest is given as a parity condition, we can replace the \"nature\"\nby two more players that play according to the rules of what is known as\nBanach-Mazur game [1]. In this paper we continue this research program by\nextending the above result to two-player stochastic parity games. As in the\npaper [1], the basic idea is that, under the correct hypothesis, we can replace\nthe randomised player with two players playing a Banach-Mazur game. This\nrequires a few technical observations, and a non trivial proof, that this paper\nsets out to do.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 14:39:48 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Oualhadj", "Youssouf", ""], ["Tible", "L\u00e9o", ""], ["Varacca", "Daniele", ""]]}, {"id": "1806.10199", "submitter": "Mary Southern", "authors": "Mary Southern and Gopalan Nadathur", "title": "Towards a Logic for Reasoning About LF Specifications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the development of a logic for reasoning about specifications in\nthe Edinburgh Logical Framework (LF). In this logic, typing judgments in LF\nserve as atomic formulas, and quantification is permitted over contexts and\nterms that might appear in them. Further, contexts, which constitute type\nassignments to uniquely named variables that are modeled using the technical\ndevice of nominal constants, can be characterized via an inductive description\nof their structure. We present a semantics for such formulas and then consider\nthe task of proving them. Towards this end, we restrict the collection of\nformulas we consider so as to ensure that they have normal forms upon which\nproof rules may be based. We then specifically discuss a proof rule that\nprovides the basis for case analysis over LF typing judgments; this rule is the\nmost complex and innovative one in the collection. We illustrate the proof\nsystem through an example. Finally, we discuss ongoing work and we relate our\nproject to existing systems that have a similar goal.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 20:16:22 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Southern", "Mary", ""], ["Nadathur", "Gopalan", ""]]}, {"id": "1806.10261", "submitter": "Kensuke Kojima", "authors": "Kensuke Kojima", "title": "BDDs Naturally Represent Boolean Functions, and ZDDs Naturally Represent\n  Sets of Sets", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a difference between Binary Decision Diagrams (BDDs) and\nZero-suppressed BDDs (ZDDs) from a conceptual point of view. It is commonly\nunderstood that a BDD is a representation of a Boolean function, whereas a ZDD\nis a representation of a set of sets. However, there is a one-to-one\ncorrespondence between Boolean functions and sets of sets, and therefore we\ncould also regard a BDD as a representation of a set of sets, and similarly for\na ZDD and a Boolean function. The aim of this paper is to give an explanation\nwhy the distinction between BDDs and ZDDs mentioned above is made despite the\nexistence of the one-to-one correspondence. To achieve this, we first observe\nthat Boolean functions and sets of sets are equipped with non-isomorphic\nfunctor structures, and show that these functor structures are reflected in the\ndefinitions of BDDs and ZDDs. This result can be stated formally as naturality\nof certain maps. To the author's knowledge, this is the first formally stated\ntheorem that justifies the commonly accepted distinction between BDDs and ZDDs.\nIn addition, we show that this result extends to sentential decision diagrams\nand their zero-suppressed variant.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 00:58:24 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Kojima", "Kensuke", ""]]}, {"id": "1806.10435", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "A Game-Semantic Model of Computation, Revisited: an Automata-Theoretic\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the previous work, we have given a novel, game-semantic model of\ncomputation in an intrinsic, non-inductive and non-axiomatic manner, which is\nsimilar to Turing machines but beyond computation on natural numbers, e.g.,\nhigher-order computation. As the main theorem of the work, it has been shown\nthat the game-semantic model may execute all the computation of the programming\nlanguage PCF. The present paper revisits this result from an automata-theoretic\nperspective: It shows that deterministic non-erasing pushdown automata whose\ninput tape is equipped with simple directed edges between cells can implement\nall the game-semantic PCF-computation, where the edges rather restrict the\ncells of the tape which the automata may read off. This is a mathematically\nhighly-surprising phenomenon because it is well-known that the more powerful\nnon-deterministic erasing pushdown automata are strictly weaker than Turing\nmachines (in the Chomsky hierarchy), let alone than PCF.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 12:23:15 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 06:12:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1806.10463", "submitter": "Ruggero Lanotte Dr", "authors": "Ruggero Lanotte and Massimo Merro and Simone Tini", "title": "Towards a formal notion of impact metric for cyber-physical attacks\n  (full version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial facilities and critical infrastructures are transforming into\n\"smart\" environments that dynamically adapt to external events. The result is\nan ecosystem of heterogeneous physical and cyber components integrated in\ncyber-physical systems which are more and more exposed to cyber-physical\nattacks, i.e., security breaches in cyberspace that adversely affect the\nphysical processes at the core of the systems.\n  We provide a formal compositional metric to estimate the impact of\ncyber-physical attacks targeting sensor devices of IoT systems formalised in a\nsimple extension of Hennessy and Regan's Timed Process Language. Our impact\nmetric relies on a discrete-time generalisation of Desharnais et al.'s weak\nbisimulation metric for concurrent systems. We show the adequacy of our\ndefinition on two different attacks on a simple surveillance system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 13:20:19 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Lanotte", "Ruggero", ""], ["Merro", "Massimo", ""], ["Tini", "Simone", ""]]}, {"id": "1806.11007", "submitter": "B Srivathsan", "authors": "Paul Gastin, Sayan Mukherjee, B Srivathsan", "title": "Reachability in timed automata with diagonal constraints", "comments": "Shorter version of this article appears in CONCUR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the reachability problem for timed automata having diagonal\nconstraints (like x - y < 5) as guards in transitions. The best algorithms for\ntimed automata proceed by enumerating reachable sets of its configurations,\nstored in the form of a data structure called \"zones\". Simulation relations\nbetween zones are essential to ensure termination and efficiency. The algorithm\nemploys a simulation test \"is-Z-simulated-by-Z' ?\" which ascertains that zone Z\ndoes not reach more states than zone Z', and hence further enumeration from Z\nis not necessary. No effective simulations are known for timed automata\ncontaining diagonal constraints as guards. In this paper, we propose a\nsimulation relation LU-d for timed automata with diagonal constraints. On the\nnegative side, we show that deciding Z-is-not-LU-d-simulated-by-Z' is\nNP-complete. On the positive side, we identify a witness for non-simulation and\npropose an algorithm to decide the existence of such a witness using an SMT\nsolver. The shape of the witness reveals that the simulation test is likely to\nbe efficient in practice.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 14:32:30 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Gastin", "Paul", ""], ["Mukherjee", "Sayan", ""], ["Srivathsan", "B", ""]]}, {"id": "1806.11064", "submitter": "Daniela Petri\\c{s}an", "authors": "Filippo Bonchi, Barbara K\\\"onig, Daniela Petrisan", "title": "Up-To Techniques for Behavioural Metrics via Fibrations", "comments": "long version of our CONCUR 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Up-to techniques are a well-known method for enhancing coinductive proofs of\nbehavioural equivalences. We introduce up-to techniques for behavioural metrics\nbetween systems modelled as coalgebras and we provide abstract results to prove\ntheir oundness in a compositional way.\n  In order to obtain a general framework, we need a systematic way to lift\nfunctors: we show that the Wasserstein lifting of a functor, introduced in a\nprevious work, corresponds to a change of base in a fibrational sense. This\nobservation enables us to reuse existing results about soundness of up-to\ntechniques in a fibrational setting.\n  We focus on the fibrations of predicates and relations valued in a quantale,\nfor which pseudo-metric spaces are an example. To illustrate our approach we\nprovide an example on distances between regular languages.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 16:26:03 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Bonchi", "Filippo", ""], ["K\u00f6nig", "Barbara", ""], ["Petrisan", "Daniela", ""]]}, {"id": "1806.11204", "submitter": "Brendan Juba", "authors": "Brendan Juba", "title": "Polynomial-time probabilistic reasoning with partial observations via\n  implicit learning in probability logics", "comments": "Presented in Eighth International Workshop on Statistical Relational\n  AI (STARAI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard approaches to probabilistic reasoning require that one possesses an\nexplicit model of the distribution in question. But, the empirical learning of\nmodels of probability distributions from partial observations is a problem for\nwhich efficient algorithms are generally not known. In this work we consider\nthe use of bounded-degree fragments of the \"sum-of-squares\" logic as a\nprobability logic. Prior work has shown that we can decide refutability for\nsuch fragments in polynomial-time. We propose to use such fragments to answer\nqueries about whether a given probability distribution satisfies a given system\nof constraints and bounds on expected values. We show that in answering such\nqueries, such constraints and bounds can be implicitly learned from partial\nobservations in polynomial-time as well. It is known that this logic is capable\nof deriving many bounds that are useful in probabilistic analysis. We show here\nthat it furthermore captures useful polynomial-time fragments of resolution.\nThus, these fragments are also quite expressive.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 21:33:34 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Juba", "Brendan", ""]]}, {"id": "1806.11307", "submitter": "Anuj Dawar", "authors": "Albert Atserias and Anuj Dawar", "title": "Definable Inapproximability: New Challenges for Duplicator", "comments": "29 pages. Long version of paper accepted for CSL 2018. To appear in\n  Journal of Logic and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the hardness of approximation of optimization problems from the\npoint of view of definability. For many NP-hard optimization problems it is\nknown that, unless P = NP, no polynomial-time algorithm can give an approximate\nsolution guaranteed to be within a fixed constant factor of the optimum. We\nshow, in several such instances and without any complexity theoretic\nassumption, that no algorithm that is expressible in fixed-point logic with\ncounting (FPC) can compute an approximate solution. Since important algorithmic\ntechniques for approximation algorithms (such as linear or semidefinite\nprogramming) are expressible in FPC, this yields lower bounds on what can be\nachieved by such methods. The results are established by showing lower bounds\non the number of variables required in first-order logic with counting to\nseparate instances with a high optimum from those with a low optimum for\nfixed-size instances.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 09:01:23 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 08:09:53 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 11:21:37 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Atserias", "Albert", ""], ["Dawar", "Anuj", ""]]}, {"id": "1806.11354", "submitter": "Thorsten Wissmann", "authors": "Adrien Durier, Daniel Hirschkoff, Davide Sangiorgi", "title": "Divergence and unique solution of equations", "comments": "This is an extended version of the paper with the same title\n  published in the proceedings of CONCUR'17", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August 7,\n  2019) lmcs:5672", "doi": "10.23638/LMCS-15(3:12)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study proof techniques for bisimilarity based on unique solution of\nequations. We draw inspiration from a result by Roscoe in the denotational\nsetting of CSP and for failure semantics, essentially stating that an equation\n(or a system of equations) whose infinite unfolding never produces a divergence\nhas the unique-solution property. We transport this result onto the operational\nsetting of CCS and for bisimilarity. We then exploit the operational approach\nto: refine the theorem, distinguishing between different forms of divergence;\nderive an abstract formulation of the theorems, on generic LTSs; adapt the\ntheorems to other equivalences such as trace equivalence, and to preorders such\nas trace inclusion. We compare the resulting techniques to enhancements of the\nbisimulation proof method (the `up-to techniques'). Finally, we study the\ntheorems in name-passing calculi such as the asynchronous $\\pi$-calculus, and\nuse them to revisit the completeness part of the proof of full abstraction of\nMilner's encoding of the $\\lambda$-calculus into the $\\pi$-calculus for\nL\\'evy-Longo Trees.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 11:07:43 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 13:05:33 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 13:03:05 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Durier", "Adrien", ""], ["Hirschkoff", "Daniel", ""], ["Sangiorgi", "Davide", ""]]}, {"id": "1806.11418", "submitter": "Jan K\\v{r}et\\'insk\\'y", "authors": "Jan K\\v{r}et\\'insk\\'y and Alexej Rotar", "title": "The Satisfiability Problem for Unbounded Fragments of Probabilistic CTL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the satisfiability and finite satisfiability problem for\nprobabilistic computation-tree logic (PCTL) where operators are not restricted\nby any step bounds. We establish decidability for several fragments containing\nquantitative operators and pinpoint the difficulties arising in more complex\nfragments where the decidability remains open.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 14:00:58 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Rotar", "Alexej", ""]]}, {"id": "1806.11459", "submitter": "Alessandro Gianola", "authors": "Diego Calvanese, Silvio Ghilardi, Alessandro Gianola, Marco Montali\n  and Andrey Rivkin", "title": "Verification of Data-Aware Processes via Array-Based Systems (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study verification over a general model of artifact-centric systems, to\nassess (parameterized) safety properties irrespectively of the initial database\ninstance. We view such artifact systems as array-based systems, which allows us\nto check safety by adapting backward reachability, establishing for the first\ntime a correspondence with model checking based on\nSatisfiability-Modulo-Theories (SMT). To do so, we make use of the\nmodel-theoretic machinery of model completion, which surprisingly turns out to\nbe an effective tool for verification of relational systems, and represents the\nmain original contribution of this paper. In this way, we pursue a twofold\npurpose. On the one hand, we reconstruct (restricted to safety) the essence of\nsome important decidability results obtained in the literature for\nartifact-centric systems, and we devise a genuinely novel class of decidable\ncases. On the other, we are able to exploit SMT technology in implementations,\nbuilding on the well-known MCMT model checker for array-based systems, and\nextending it to make all our foundational results fully operational.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 15:00:59 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:10:10 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Calvanese", "Diego", ""], ["Ghilardi", "Silvio", ""], ["Gianola", "Alessandro", ""], ["Montali", "Marco", ""], ["Rivkin", "Andrey", ""]]}, {"id": "1806.11559", "submitter": "Brian Logan", "authors": "Natasha Alechina, Brian Logan", "title": "Resource Logics with a Diminishing Resource", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-checking resource logics with production and consumption of resources\nis a computationally hard and often undecidable problem. We introduce a simple\nand realistic assumption that there is at least one diminishing resource, that\nis, a resource that cannot be produced and every action has a non-zero cost on\nthis resource. An example of such resource is time. We show that, with this\nassumption, problems that are undecidable even for the underlying Alternating\nTime Temporal Logic, such as model-checking under imperfect information and\nperfect recall, become decidable for resource logics with a diminishing\nresource.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 10:50:26 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Alechina", "Natasha", ""], ["Logan", "Brian", ""]]}]