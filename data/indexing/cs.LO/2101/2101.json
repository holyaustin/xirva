[{"id": "2101.00003", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "Yet another argument in favour of NP=CoNP", "comments": "This article puts together the results shown in arXiv:2009.09802v1\n  and in arXiv:2012.07833v1 to show a proof of NP=CoNP. It is need to read\n  these article to get the details on the proof presented here", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article shows yet another proof of NP=CoNP$. In a previous article, we\nproved that NP=PSPACE and from it we can conclude that NP=CoNP immediately. The\nformer proof shows how to obtain polynomial and, polynomial in time checkable\nDag-like proofs for all purely implicational Minimal logic tautologies. From\nthe fact that Minimal implicational logic is PSPACE-complete we get the proof\nthat NP=PSPACE.\n  This first proof of NP=CoNP uses Hudelmaier linear upper-bound on the height\nof Sequent Calculus minimal implicational logic proofs. In an addendum to the\nproof of NP=PSPACE, we observe that we do not need to use Hudelmaier\nupper-bound since any proof of non-hamiltonicity for any graph is linear\nupper-bounded. By the CoNP-completeness of non-hamiltonicity, we obtain NP=CoNP\nas a corollary of the first proof. In this article we show the third proof of\nCoNP=NP, also providing polynomial size and polynomial verifiable certificates\nthat are Dags. They are generated from normal Natural Deduction proofs, linear\nheight upper-bounded too, by removing redundancy, i.e., repeated parts. The\nexistence of repeated parts is a consequence of the redundancy theorem for a\nfamily of super-polynomial proofs in the purely implicational Minimal logic. It\nis mandatory to read at least two previous articles to get the details of the\nproof presented here. The article that proves the redundancy theorem and the\narticle that shows how to remove the repeated parts of a normal Natural\nDeduction proof to have a polynomial Dag certificate for minimal implicational\nlogic tautologies.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 22:08:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "2101.00102", "submitter": "Nikolaos Kekatos", "authors": "Nikolaos Kekatos", "title": "Verifying a Cruise Control System using Simulink and SpaceEx", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article aims to provide a simple step-by-step guide highlighting the\nsteps needed to verify a control system with formal verification tools.\nStarting from a description of the physical system and a control objective in\nnatural language, we design the plant and the controller, we use Simulink for\nsimulation and we employ a reachability analysis tool, SpaceEx, for formal\nverification.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 22:46:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kekatos", "Nikolaos", ""]]}, {"id": "2101.00127", "submitter": "Kyle Miller", "authors": "Alena Gusakov, Bhavik Mehta, Kyle A. Miller", "title": "Formalizing Hall's Marriage Theorem in Lean", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize Hall's Marriage Theorem in the Lean theorem prover for inclusion\nin mathlib, which is a community-driven effort to build a unified mathematics\nlibrary for Lean. One goal of the mathlib project is to contain all of the\ntopics of a complete undergraduate mathematics education.\n  We provide three presentations of the main theorem statement: in terms of\nindexed families of finite sets, of relations on types, and of matchings in\nbipartite graphs. We also formalize a version of K\\H{o}nig's lemma (in terms of\ninverse limits) to boost the theorem to the case of countably infinite index\nsets. We give a description of the design of the recent mathlib library for\nsimple graphs, and we also give a necessary and sufficient condition for a\nsimple graph to carry a function.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 01:10:31 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Gusakov", "Alena", ""], ["Mehta", "Bhavik", ""], ["Miller", "Kyle A.", ""]]}, {"id": "2101.00485", "submitter": "Pavel Naumov", "authors": "Sanaz Azimipour and Pavel Naumov", "title": "If You're Happy, Then You Know It: The Logic of Happiness... and Sadness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article proposes a formal semantics of happiness and sadness modalities\nin imperfect information setting. It shows that these modalities are not\ndefinable through each other and gives a sound and complete axiomatization of\ntheir properties.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 17:42:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Azimipour", "Sanaz", ""], ["Naumov", "Pavel", ""]]}, {"id": "2101.00589", "submitter": "Matthias Nickles", "authors": "Matthias Nickles", "title": "diff-SAT -- A Software for Sampling and Probabilistic Reasoning for SAT\n  and Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes diff-SAT, an Answer Set and SAT solver which combines\nregular solving with the capability to use probabilistic clauses, facts and\nrules, and to sample an optimal world-view (multiset of satisfying Boolean\nvariable assignments or answer sets) subject to user-provided probabilistic\nconstraints. The sampling process minimizes a user-defined differentiable\nobjective function using a gradient descent based optimization method called\nDifferentiable Satisfiability Solving ($\\partial\\mathrm{SAT}$) respectively\nDifferentiable Answer Set Programming ($\\partial\\mathrm{ASP}$). Use cases are\ni.a. probabilistic logic programming (in form of Probabilistic Answer Set\nProgramming), Probabilistic Boolean Satisfiability solving (PSAT), and\ndistribution-aware sampling of model multisets (answer sets or Boolean\ninterpretations).\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 09:04:31 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Nickles", "Matthias", ""]]}, {"id": "2101.00718", "submitter": "Simone Faro", "authors": "Domenico Cantone, Simone Faro and Arianna Pavone", "title": "Text Searching Allowing for Non-Overlapping Adjacent Unbalanced\n  Translocations", "comments": "arXiv admin note: substantial text overlap with arXiv:1812.00421", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the \\emph{approximate string matching problem}\nwhen the allowed edit operations are \\emph{non-overlapping unbalanced\ntranslocations of adjacent factors}. Such kind of edit operations take place\nwhen two adjacent sub-strings of the text swap, resulting in a modified string.\nThe two involved substrings are allowed to be of different lengths.\n  Such large-scale modifications on strings have various applications. They are\namong the most frequent chromosomal alterations, accounted for 30\\% of all\nlosses of heterozygosity, a major genetic event causing inactivation of cancer\nsuppressor genes. In addition, among other applications, they are frequent\nmodifications accounted in musical or in natural language information\nretrieval. However, despite of their central role in so many fields of text\nprocessing, little attention has been devoted to the problem of matching\nstrings allowing for this kind of edit operation.\n  In this paper we present three algorithms for solving the problem, all of\nthem with a $\\bigO(nm^3)$ worst-case and a $\\bigO(m^2)$-space complexity, where\n$m$ and $n$ are the length of the pattern and of the text, respectively. % In\nparticular, our first algorithm is based on the dynamic-programming approach.\nOur second solution improves the previous one by making use of the Directed\nAcyclic Word Graph of the pattern. Finally our third algorithm is based on an\nalignment procedure. We also show that under the assumptions of equiprobability\nand independence of characters, our second algorithm has a\n$\\bigO(n\\log^2_{\\sigma} m)$ average time complexity, for an alphabet of size\n$\\sigma \\geq 4$.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 22:21:51 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Cantone", "Domenico", ""], ["Faro", "Simone", ""], ["Pavone", "Arianna", ""]]}, {"id": "2101.00834", "submitter": "Anne-Kathrin Schmuck", "authors": "Rupak Majumdar, Kaushik Mallik, Anne-Kathrin Schmuck, Sadegh Soudjani", "title": "Symbolic Control for Stochastic Systems via Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the maximal probability of satisfying an\n$\\omega$-regular specification for stochastic, continuous-state, nonlinear\nsystems evolving in discrete time. The problem reduces, after\nautomata-theoretic constructions, to finding the maximal probability of\nsatisfying a parity condition on a (possibly hybrid) state space. While\ncharacterizing the exact satisfaction probability is open, we show that a lower\nbound on this probability can be obtained by (I) computing an\nunder-approximation of the qualitative winning region, i.e., states from which\nthe parity condition can be enforced almost surely, and (II) computing the\nmaximal probability of reaching this qualitative winning region. The heart of\nour approach is a technique to symbolically compute the under-approximation of\nthe qualitative winning region in step (I) via a finite-state abstraction of\nthe original system as a $2\\frac{1}{2}$-player parity game. Our abstraction\nprocedure uses only the support of the probabilistic evolution; it does not use\nprecise numerical transition probabilities. We prove that the winning set in\nthe abstract $2\\frac{1}{2}$-player game induces an under-approximation of the\nqualitative winning region in the original synthesis problem, along with a\npolicy to solve it. By combining these contributions with (a) existing symbolic\nfixpoint algorithms to solve $2\\frac{1}{2}$-player games and (b) existing\ntechniques for reachability policy synthesis in stochastic nonlinear systems,\nwe get an abstraction-based symbolic algorithm for finding a lower bound on the\nmaximal satisfaction probability. We have implemented our approach and\nevaluated it on the nonlinear model of the perturbed Dubins vehicle.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 08:50:42 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Majumdar", "Rupak", ""], ["Mallik", "Kaushik", ""], ["Schmuck", "Anne-Kathrin", ""], ["Soudjani", "Sadegh", ""]]}, {"id": "2101.00930", "submitter": "Heiko Becker", "authors": "Heiko Becker, Nathaniel Bos, Ivan Gavran, Eva Darulova, Rupak Majumdar", "title": "Lassie: HOL4 Tactics by Example", "comments": null, "journal-ref": null, "doi": "10.1145/3437992.3439925", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Proof engineering efforts using interactive theorem proving have yielded\nseveral impressive projects in software systems and mathematics. A key obstacle\nto such efforts is the requirement that the domain expert is also an expert in\nthe low-level details in constructing the proof in a theorem prover. In\nparticular, the user needs to select a sequence of tactics that lead to a\nsuccessful proof, a task that in general requires knowledge of the exact names\nand use of a large set of tactics.\n  We present Lassie, a tactic framework for the HOL4 theorem prover that allows\nindividual users to define their own tactic language by example and give\nfrequently used tactics or tactic combinations easier-to-remember names. The\ncore of Lassie is an extensible semantic parser, which allows the user to\ninteractively extend the tactic language through a process of definitional\ngeneralization. Defining tactics in Lassie thus does not require any knowledge\nin implementing custom tactics, while proofs written in Lassie retain the\ncorrectness guarantees provided by the HOL4 system. We show through case\nstudies how Lassie can be used in small and larger proofs by novice and more\nexperienced interactive theorem prover users, and how we envision it to ease\nthe learning curve in a HOL4 tutorial.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 12:50:36 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Becker", "Heiko", ""], ["Bos", "Nathaniel", ""], ["Gavran", "Ivan", ""], ["Darulova", "Eva", ""], ["Majumdar", "Rupak", ""]]}, {"id": "2101.00956", "submitter": "Pieter Collins", "authors": "Pieter Collins", "title": "Computable Random Variables and Conditioning", "comments": "arXiv admin note: text overlap with arXiv:1409.4667", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The aim of this paper is to present an elementary computable theory of random\nvariables, based on the approach to probability via valuations. The theory is\nbased on a type of lower-measurable sets, which are controlled limits of open\nsets, and extends existing work in this area by providing a computable theory\nof conditional random variables. The theory is based within the framework of\ntype-two effectivity, so has an explicit direct link with Turing computation,\nand is expressed in a system of computable types and operations, so has a clean\nmathematical description.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 21:17:34 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Collins", "Pieter", ""]]}, {"id": "2101.00958", "submitter": "Daniel Schuster", "authors": "Daniel Schuster, Gero J. Kolhof", "title": "Scalable Online Conformance Checking Using Incremental Prefix-Alignment\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformance checking techniques aim to collate observed process behavior with\nnormative/modeled process models. The majority of existing approaches focuses\non completed process executions, i.e., offline conformance checking. Recently,\nnovel approaches have been designed to monitor ongoing processes, i.e., online\nconformance checking. Such techniques detect deviations of an ongoing process\nexecution from a normative process model at the moment they occur. Thereby,\ncountermeasures can be taken immediately to prevent a process deviation from\ncausing further, undesired consequences. Most online approaches only allow to\ndetect approximations of deviations. This causes the problem of falsely\ndetected deviations, i.e., detected deviations that are actually no deviations.\nWe have, therefore, recently introduced a novel approach to compute exact\nconformance checking results in an online environment. In this paper, we focus\non the practical application and present a scalable, distributed implementation\nof the proposed online conformance checking approach. Moreover, we present two\nextensions to said approach to reduce its computational effort and its\npractical applicability. We evaluate our implementation using data sets\ncapturing the execution of real processes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 09:45:40 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Schuster", "Daniel", ""], ["Kolhof", "Gero J.", ""]]}, {"id": "2101.00992", "submitter": "Paul Riggins", "authors": "Paul Riggins, David McPherson", "title": "Formal Game Grammar and Equivalence", "comments": "8 pages, 7 figures. Presented at the 2020 IEEE Conference on Games\n  (Full Paper. August 24-27, 2020). arXiv admin note: text overlap with\n  arXiv:1912.03295", "journal-ref": "2020 IEEE Conference on Games (CoG), Osaka, Japan, 2020, pp.\n  206-213", "doi": "10.1109/CoG47356.2020.9231594", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop methods to formally describe and compare games, in order to probe\nquestions of game structure and design, and as a stepping stone to predicting\nplayer behavior from design patterns. We define a grammar-like formalism to\ndescribe finite discrete games without hidden information, allowing for\nrandomness, and mixed sequential and simultaneous play. We make minimal\nassumptions about the form or content of game rules or user interface. The\nassociated game trees resemble hybrid extensive- and strategic-form games, in\nthe game theory sense. By transforming and comparing game trees, we develop\nequivalence relations on the space of game systems, which equate games that\ngive players the same meaningful agency. We bring these together to suggest a\nmethod to measure distance between games, insensitive to cosmetic variations in\nthe game logic descriptions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:22:56 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Riggins", "Paul", ""], ["McPherson", "David", ""]]}, {"id": "2101.01255", "submitter": "Nikolaos Kekatos", "authors": "Antonio Anastasio Bruto da Costa, Pallab Dasgupta, Nikolaos Kekatos", "title": "Quantitative Corner Case Feature Analysis of Hybrid Automata with\n  ForFET$^{SMT}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The analysis and verification of hybrid automata (HA) models against rich\nformal properties can be a challenging task. Existing methods and tools can\nmainly reason whether a given property is satisfied or violated. However, such\nqualitative answers might not provide sufficient information about the model\nbehaviors. This paper presents the ForFET$^{SMT}$ tool which can be used to\nreason quantitatively about such properties. It employs feature automata and\ncan evaluate quantitative property corners of HA. ForFET$^{SMT}$ uses two\nthird-party formal verification tools as its backbone: the SpaceEx reachability\ntool and the SMT solver dReach/dReal. Herein, we describe the design and\nimplementation of ForFET$^{SMT}$ and present its functionalities and modules.\nTo improve the usability of the tool for non-expert users, we also provide a\nlist of quantitative property templates.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 22:06:11 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["da Costa", "Antonio Anastasio Bruto", ""], ["Dasgupta", "Pallab", ""], ["Kekatos", "Nikolaos", ""]]}, {"id": "2101.01676", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira, Renata Vieira", "title": "Dynamic Preference Logic meets Iterated Belief Change: Representation\n  Results and Postulates Characterization", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2020.12.042", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AGM's belief revision is one of the main paradigms in the study of belief\nchange operations. Recently, several logics for belief and information change\nhave been proposed in the literature and used to encode belief change\noperations in rich and expressive semantic frameworks. While the connections of\nAGM-like operations and their encoding in dynamic doxastic logics have been\nstudied before by the work of Segerberg, most works on the area of Dynamic\nEpistemic Logics (DEL) have not, to our knowledge, attempted to use those\nlogics as tools to investigate mathematical properties of belief change\noperators. This work investigates how Dynamic Preference Logic, a logic in the\nDEL family, can be used to study properties of dynamic belief change operators,\nfocusing on well-known postulates of iterated belief change.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 17:47:18 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""], ["Vieira", "Renata", ""]]}, {"id": "2101.01842", "submitter": "Graham Campbell", "authors": "Graham Campbell and Detlef Plump", "title": "Confluence up to Garbage in Graph Transformation", "comments": "33 pages, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The transformation of graphs and graph-like structures is ubiquitous in\ncomputer science. When a system is described by graph-transformation rules, it\nis often desirable that the rules are both terminating and confluent so that\nrule applications in an arbitrary order produce unique resulting graphs.\nHowever, there are application scenarios where the rules are not globally\nconfluent but confluent on a subclass of graphs that are of interest. In other\nwords, non-resolvable conflicts can only occur on graphs that are considered as\n\"garbage\". In this paper, we introduce the notion of confluence up to garbage\nand generalise Plump's critical pair lemma for double-pushout graph\ntransformation, providing a sufficient condition for confluence up to garbage\nby non-garbage critical pair analysis. We apply our results in two case studies\nabout efficient language recognition: we present backtracking-free graph\nreduction systems which recognise a class of flow diagrams and a class of\nlabelled series-parallel graphs, respectively. Both systems are non-confluent\nbut confluent up to garbage. We also give a critical pair condition for\nsubcommutativity up to garbage which, together with closedness, implies\nconfluence up to garbage even in non-terminating systems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 01:26:49 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Campbell", "Graham", ""], ["Plump", "Detlef", ""]]}, {"id": "2101.01944", "submitter": "Uwe Egbert Wolter", "authors": "Uwe Wolter", "title": "Logics of First-Order Constraints -- A Category Independent Approach", "comments": "23 pages, presented at the 8th Conference on Algebra and Coalgebra in\n  Computer Science (CALCO 2019), London, UK, June 3-6, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reflecting our experiences in areas, like Algebraic Specifications, Abstract\nModel Theory, Graph Transformations, and Model Driven Software Engineering\n(MDSE), we present a general, category independent approach to Logics of\nFirst-Order Constraints (LFOC). Traditional First-Order Logic, Description\nLogic and the sketch framework are discussed as examples. We use the concept of\ninstitution [Diaconescu08,GoguenBurstall92] as a guideline to describe LFOC's.\nThe main result states that any choice of the six parameters, we are going to\ndescribe, gives us a corresponding \"institution of constraints\" at hand. The\n\"presentations\" for an institution of constraints can be characterized as\n\"first-order sketches\". As a corresponding variant of the \"sketch-entailments\"\nin [Makkai97], we finally introduce \"sketch rules\" to equip LFOC's with the\nnecessary expressive power.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 09:55:43 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wolter", "Uwe", ""]]}, {"id": "2101.01968", "submitter": "Denis Kuperberg", "authors": "Denis Kuperberg", "title": "Positive first-order logic on words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study FO+, a fragment of first-order logic on finite words, where monadic\npredicates can only appear positively. We show that there is a FO-definable\nlanguage that is monotone in monadic predicates but not definable in FO+. This\nprovides a simple proof that Lyndon's preservation theorem fails on finite\nstructures. We additionally show that given a regular language, it is\nundecidable whether it is definable in FO+.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 11:08:06 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 16:49:29 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 14:14:57 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 15:44:33 GMT"}, {"version": "v5", "created": "Thu, 29 Apr 2021 10:27:55 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kuperberg", "Denis", ""]]}, {"id": "2101.02310", "submitter": "Graham Campbell", "authors": "Graham Campbell", "title": "Parallel Hyperedge Replacement Grammars", "comments": "40 pages, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In 2018, it was shown that all finitely generated virtually Abelian groups\nhave multiple context-free word problems, and it is still an open problem as to\nwhere to precisely place the word problems of hyperbolic groups in the formal\nlanguage hierarchy. Motivated by this, we introduce a new language class, the\nparallel hyperedge replacement string languages, containing all multiple\ncontext-free and ET0L languages. We show that parallel hyperedge replacement\ngrammars can be \"synchronised\", which allows us to establish many useful formal\nlanguage closure results relating to both the hypergraph and string languages\ngenerated by various families of parallel hyperedge replacement grammars,\nlaying the foundations for future work in this area.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 00:24:35 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Campbell", "Graham", ""]]}, {"id": "2101.02466", "submitter": "Miika Hannula", "authors": "Miika Hannula, Juha Kontinen, Sebastian Link", "title": "On the Interaction of Functional and Inclusion Dependencies with\n  Independence Atoms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infamously, the finite and unrestricted implication problems for the classes\nof i) functional and inclusion dependencies together, and ii) embedded\nmultivalued dependencies alone are each undecidable. Famously, the restriction\nof i) to functional and unary inclusion dependencies in combination with the\nrestriction of ii) to multivalued dependencies yield implication problems that\nare still different in the finite and unrestricted case, but each are finitely\naxiomatizable and decidable in low-degree polynomial time. An important\nembedded tractable fragment of embedded multivalued dependencies are\nindependence atoms that stipulate independence between two attribute sets. We\nestablish a series of results for implication problems over subclasses of the\ncombined class of functional and inclusion dependencies as well as independence\natoms. One of our main results is that both finite and unrestricted implication\nproblems for the combined class of independence atoms, unary functional and\nunary inclusion dependencies are axiomatizable and decidable in low-degree\npolynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 10:13:02 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hannula", "Miika", ""], ["Kontinen", "Juha", ""], ["Link", "Sebastian", ""]]}, {"id": "2101.02516", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Merging with unknown reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Merging beliefs depends on the relative reliability of their sources. When\nunknown, assuming equal reliability is unwarranted. The solution proposed in\nthis article is that every reliability profile is possible, and only what holds\naccording to all is accepted. Alternatively, one source is completely reliable,\nbut which one is unknown. These two cases motivate two existing forms of\nmerging: maxcons-based merging and arbitration.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 12:32:26 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2101.02547", "submitter": "Ole-Christoffer Granmo", "authors": "Lei Jiao, Xuan Zhang, Ole-Christoffer Granmo, K. Darshana Abeyrathna", "title": "On the Convergence of Tsetlin Machines for the XOR Operator", "comments": "31 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is a novel machine learning algorithm with several\ndistinct properties, including transparent inference and learning using\nhardware-near building blocks. Although numerous papers explore the TM\nempirically, many of its properties have not yet been analyzed mathematically.\nIn this article, we analyze the convergence of the TM when input is\nnon-linearly related to output by the XOR-operator. Our analysis reveals that\nthe TM, with just two conjunctive clauses, can converge almost surely to\nreproducing XOR, learning from training data over an infinite time horizon.\nFurthermore, the analysis shows how the hyper-parameter T guides clause\nconstruction so that the clauses capture the distinct sub-patterns in the data.\nOur analysis of convergence for XOR thus lays the foundation for analyzing\nother more complex logical expressions. These analyses altogether, from a\nmathematical perspective, provide new insights on why TMs have obtained\nstate-of-the-art performance on several pattern recognition problems\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 14:13:41 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Jiao", "Lei", ""], ["Zhang", "Xuan", ""], ["Granmo", "Ole-Christoffer", ""], ["Abeyrathna", "K. Darshana", ""]]}, {"id": "2101.02690", "submitter": "Narciso Mart\\'i-Oliet", "authors": "Joseph A. Goguen", "title": "Theorem Proving and Algebra", "comments": "427+ xviii pages, 38 figures, Unfinished book by Joseph A. Goguen,\n  Edited by Kokichi Futatsugi, Narciso Mart\\'i-Oliet and Jos\\'e Meseguer;\n  revised version corrects some strange characters in page xv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book can be seen either as a text on theorem proving that uses\ntechniques from general algebra, or else as a text on general algebra\nillustrated and made concrete by practical exercises in theorem proving. The\nbook considers several different logical systems, including first-order logic,\nHorn clause logic, equational logic, and first-order logic with equality.\nSimilarly, several different proof paradigms are considered. However, we do\nemphasize equational logic, and for simplicity we use only the OBJ3 software\nsystem, though it is used in a rather flexible manner. We do not pursue the\nlofty goal of mechanizing proofs like those of which mathematicians are justly\nso proud; instead, we seek to take steps towards providing mechanical\nassistance for proofs that are useful for computer scientists in developing\nsoftware and hardware. This more modest goal has the advantage of both being\nachievable and having practical benefits.\n  The following topics are covered: many-sorted signature, algebra and\nhomomorphism; term algebra and substitution; equation and satisfaction;\nconditional equations; equational deduction and its completeness; deduction for\nconditional equations; the theorem of constants; interpretation and equivalence\nof theories; term rewriting, termination, confluence and normal form; abstract\nrewrite systems; standard models, abstract data types, initiality, and\ninduction; rewriting and deduction modulo equations; first-order logic, models,\nand proof planning; second-order algebra; order-sorted algebra and rewriting;\nmodules; unification and completion; and hidden algebra. In parallel with these\nare a gradual introduction to OBJ3, applications to group theory, various\nabstract data types (such as number systems, lists, and stacks), propositional\ncalculus, hardware verification, the {\\lambda}-calculus, correctness of\nfunctional programs, and other topics.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 18:52:08 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 22:29:37 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Goguen", "Joseph A.", ""]]}, {"id": "2101.02835", "submitter": "EPTCS", "authors": "Claudio Sacerdoti Coen (University of Bologna), Alwen Tiu (The\n  Australian National University)", "title": "Proceedings Fifteenth Workshop on Logical Frameworks and Meta-Languages:\n  Theory and Practice", "comments": null, "journal-ref": "EPTCS 332, 2021", "doi": "10.4204/EPTCS.332", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of papers presented at LFMTP 2020, the 15th\nInternational Workshop on Logical Frameworks and Meta-Languages: Theory and\nPractice (LFMTP), held the 29-30th of June, 2019, using the Zoom video\nconferencing tool due to COVID restrictions. Officially the workshop was held\nin Paris, France, and it was affiliated with IJCAR 2020, FSCD 2020 and many\nother satellite events.\n  Logical frameworks and meta-languages form a common substrate for\nrepresenting, implementing and reasoning about a wide variety of deductive\nsystems of interest in logic and computer science. Their design, implementation\nand their use in reasoning tasks, ranging from the correctness of software to\nthe properties of formal systems, have been the focus of considerable research\nover the last two decades. This workshop will bring together designers,\nimplementors and practitioners to discuss various aspects impinging on the\nstructure and utility of logical frameworks, including the treatment of\nvariable binding, inductive and co-inductive reasoning techniques and the\nexpressiveness and lucidity of the reasoning process.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 03:37:59 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Coen", "Claudio Sacerdoti", "", "University of Bologna"], ["Tiu", "Alwen", "", "The\n  Australian National University"]]}, {"id": "2101.02994", "submitter": "S. C. Steenkamp", "authors": "Marcelo P. Fiore and Andrew M. Pitts and S. C. Steenkamp", "title": "Quotients, inductive types, and quotient inductive types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an expressive class of indexed quotient-inductive\ntypes, called QWI types, within the framework of constructive type theory. They\nare initial algebras for indexed families of equational theories with possibly\ninfinitary operators and equations. We prove that QWI types can be derived from\nquotient types and inductive types in the type theory of toposes with natural\nnumber object and universes, provided those universes satisfy the Weakly\nInitial Set of Covers (WISC) axiom. We do so by constructing QWI types as\ncolimits of a family of approximations to them defined by well-founded\nrecursion over a suitable notion of size, whose definition involves the WISC\naxiom. We developed the proof and checked it using the Agda theorem prover.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 13:00:52 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Fiore", "Marcelo P.", ""], ["Pitts", "Andrew M.", ""], ["Steenkamp", "S. C.", ""]]}, {"id": "2101.03113", "submitter": "Camilo Rocha", "authors": "Carlos Olarte, Elaine Pimentel, Camilo Rocha", "title": "A Rewriting Logic Approach to Specification, Proof-search, and\n  Meta-proofs in Sequent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper develops an algorithmic-based approach for proving inductive\nproperties of propositional sequent systems such as admissibility,\ninvertibility, cut-elimination, and identity expansion. Although undecidable in\ngeneral, these structural properties are crucial in proof theory because they\ncan reduce the proof-search effort and further be used as scaffolding for\nobtaining other meta-results such as consistency. The algorithms -- which take\nadvantage of the rewriting logic meta-logical framework, and use rewrite- and\nnarrowing-based reasoning -- are explained in detail and illustrated with\nexamples throughout the paper. They have been fully mechanized in the\nL-Framework, thus offering both a formal specification language and\noff-the-shelf mechanization of the proof-search algorithms coming together with\nsemi-decision procedures for proving theorems and meta-theorems of the object\nsystem. As illustrated with case studies in the paper, the L-Framework,\nachieves a great degree of automation when used on several propositional\nsequent systems, including single conclusion and multi-conclusion\nintuitionistic logic, classical logic, classical linear logic and its dyadic\nsystem, intuitionistic linear logic, and normal modal logics.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 17:11:47 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Olarte", "Carlos", ""], ["Pimentel", "Elaine", ""], ["Rocha", "Camilo", ""]]}, {"id": "2101.03215", "submitter": "Cristian F. Sottile", "authors": "Cristian F. Sottile, Alejandro D\\'iaz-Caro, and Pablo E. Mart\\'inez\n  L\\'opez", "title": "Polymorphic System I", "comments": "20 pages plus appendix", "journal-ref": "In IFL 2020: Proceedings of the 32nd Symposium on Implementation\n  and Application of Functional Languages (IFL 2020). Association for Computing\n  Machinery, New York, NY, USA, 127-137", "doi": "10.1145/3462172.3462198", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System I is a simply-typed lambda calculus with pairs, extended with an\nequational theory obtained from considering the type isomorphisms as\nequalities. In this work we propose an extension of System I to polymorphic\ntypes, adding the corresponding isomorphisms. We provide non-standard proofs of\nsubject reduction and strong normalisation, extending those of System I.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:42:21 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 22:21:40 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sottile", "Cristian F.", ""], ["D\u00edaz-Caro", "Alejandro", ""], ["L\u00f3pez", "Pablo E. Mart\u00ednez", ""]]}, {"id": "2101.03591", "submitter": "Samuel Mimram", "authors": "Simon Henry, Samuel Mimram", "title": "Tietze Equivalences as Weak Equivalences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.AT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A given monoid usually admits many presentations by generators and relations\nand the notion of Tietze equivalence characterizes when two presentations\ndescribe the same monoid: it is the case when one can transform one\npresentation into the other using the two families of so-called Tietze\ntransformations. The goal of this article is to provide an abstract and\ngeometrical understanding of this well-known fact, by constructing a model\nstructuree on the category of presentations, in which two presentations are\nweakly equivalent when they present the same monoid. We show that Tietze\ntransformations form a pseudo-generating family of trivial cofibrations and\ngive a proof of the completeness of these transformations by an abstract\nargument in this setting.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 18:18:56 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Henry", "Simon", ""], ["Mimram", "Samuel", ""]]}, {"id": "2101.03807", "submitter": "EPTCS", "authors": "Arve Gengelbach, Johannes {\\AA}man Pohjola, Tjark Weber", "title": "Mechanisation of Model-theoretic Conservative Extension for HOL with\n  Ad-hoc Overloading", "comments": "In Proceedings LFMTP 2020, arXiv:2101.02835", "journal-ref": "EPTCS 332, 2021, pp. 1-17", "doi": "10.4204/EPTCS.332.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Definitions of new symbols merely abbreviate expressions in logical\nframeworks, and no new facts (regarding previously defined symbols) should hold\nbecause of a new definition. In Isabelle/HOL, definable symbols are types and\nconstants. The latter may be ad-hoc overloaded, i.e. have different definitions\nfor non-overlapping types. We prove that symbols that are independent of a new\ndefinition may keep their interpretation in a model extension. This work\nrevises our earlier notion of model-theoretic conservative extension and\ngeneralises an earlier model construction. We obtain consistency of theories of\ndefinitions in higher-order logic (HOL) with ad-hoc overloading as a corollary.\nOur results are mechanised in the HOL4 theorem prover.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 10:51:17 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gengelbach", "Arve", ""], ["Pohjola", "Johannes \u00c5man", ""], ["Weber", "Tjark", ""]]}, {"id": "2101.03808", "submitter": "EPTCS", "authors": "Petros Papapanagiotou (University of Edinburgh), Jacques Fleuriot\n  (University of Edinburgh)", "title": "Object-Level Reasoning with Logics Encoded in HOL Light", "comments": "In Proceedings LFMTP 2020, arXiv:2101.02835", "journal-ref": "EPTCS 332, 2021, pp. 18-34", "doi": "10.4204/EPTCS.332.2", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic framework that facilitates object level reasoning with\nlogics that are encoded within the Higher Order Logic theorem proving\nenvironment of HOL Light. This involves proving statements in any logic using\nintuitive forward and backward chaining in a sequent calculus style. It is made\npossible by automated machinery that take care of the necessary structural\nreasoning and term matching automatically. Our framework can also handle type\ntheoretic correspondences of proofs, effectively allowing the type checking and\nconstruction of computational processes via proof. We demonstrate our\nimplementation using a simple propositional logic and its Curry-Howard\ncorrespondence to the lambda-calculus, and argue its use with linear logic and\nits various correspondences to session types.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 10:51:36 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Papapanagiotou", "Petros", "", "University of Edinburgh"], ["Fleuriot", "Jacques", "", "University of Edinburgh"]]}, {"id": "2101.03809", "submitter": "EPTCS", "authors": "Tarmo Uustalu, Niccol\\`o Veltri, Noam Zeilberger", "title": "Deductive Systems and Coherence for Skew Prounital Closed Categories", "comments": "In Proceedings LFMTP 2020, arXiv:2101.02835", "journal-ref": "EPTCS 332, 2021, pp. 35-53", "doi": "10.4204/EPTCS.332.3", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop the proof theory of skew prounital closed\ncategories. These are variants of the skew closed categories of Street where\nthe unit is not represented. Skew closed categories in turn are a weakening of\nthe closed categories of Eilenberg and Kelly where no structural law is\nrequired to be invertible. The presence of a monoidal structure in these\ncategories is not required. We construct several equivalent presentations of\nthe free skew prounital closed category on a given set of generating objects: a\ncategorical calculus (Hilbert-style system), a cut-free sequent calculus and a\nnatural deduction system corresponding to a variant of planar (=\nnon-commutative linear) typed lambda-calculus. We solve the coherence problem\nfor skew prounital closed categories by showing that the sequent calculus\nadmits focusing and presenting two reduction-free normalization procedures for\nthe natural deduction calculus: normalization by evaluation and hereditary\nsubstitutions. Normal natural deduction derivations (beta-eta-long forms) are\nin one-to-one correspondence with derivations in the focused sequent calculus.\nUnexpectedly, the free skew prounital closed category on a set satisfies a\nleft-normality condition which makes it lose its skew aspect. This pitfall can\nbe avoided by considering the free skew prounital closed category on a skew\nmulticategory instead. The latter has a presentation as a cut-free sequent\ncalculus for which it is easy to see that the left-normality condition\ngenerally fails.\n  The whole development has been fully formalized in the dependently typed\nprogramming language Agda.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 10:51:49 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Uustalu", "Tarmo", ""], ["Veltri", "Niccol\u00f2", ""], ["Zeilberger", "Noam", ""]]}, {"id": "2101.03810", "submitter": "EPTCS", "authors": "Bruno Barras (Inria, Universit\\'e Paris-Saclay, ENS Paris-Saclay,\n  CNRS, LSV, Gif-sur-Yvette, France), Valentin Maestracci (Universit\\'e\n  Paris-Saclay, ENS Paris-Saclay, CNRS, LSV, Gif-sur-Yvette, France)", "title": "Implementation of Two Layers Type Theory in Dedukti and Application to\n  Cubical Type Theory", "comments": "In Proceedings LFMTP 2020, arXiv:2101.02835", "journal-ref": "EPTCS 332, 2021, pp. 54-67", "doi": "10.4204/EPTCS.332.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we make a substantial step towards an encoding of Cubical Type\nTheory (CTT) in the Dedukti logical framework. Type-checking CTT expressions\nfeatures a decision procedure in a de Morgan algebra that so far could not be\nexpressed by the rewrite rules of Dedukti. As an alternative, 2 Layer Type\nTheories are variants of Martin-L\\\"of Type Theory where all or part of the\ndefinitional equality can be represented in terms of a so-called external\nequality. We propose to split the encoding by giving an encoding of 2 Layer\nType Theories (2LTT) in Dedukti, and a partial encoding of CTT in 2LTT.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 10:52:03 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Barras", "Bruno", "", "Inria, Universit\u00e9 Paris-Saclay, ENS Paris-Saclay,\n  CNRS, LSV, Gif-sur-Yvette, France"], ["Maestracci", "Valentin", "", "Universit\u00e9\n  Paris-Saclay, ENS Paris-Saclay, CNRS, LSV, Gif-sur-Yvette, France"]]}, {"id": "2101.03866", "submitter": "Thomas Zeume", "authors": "Szymon Toru\\'nczyk, Thomas Zeume", "title": "Register Automata with Extrema Constraints, and an Application to\n  Two-Variable Logic", "comments": "The short version of this article appeared in the conference\n  proceedings of LICS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a model of register automata over infinite trees with extrema\nconstraints. Such an automaton can store elements of a linearly ordered domain\nin its registers, and can compare those values to the suprema and infima of\nregister values in subtrees. We show that the emptiness problem for these\nautomata is decidable.\n  As an application, we prove decidability of the countable satisfiability\nproblem for two-variable logic in the presence of a tree order, a linear order,\nand arbitrary atoms that are MSO definable from the tree order. As a\nconsequence, the satisfiability problem for two-variable logic with arbitrary\npredicates, two of them interpreted by linear orders, is decidable.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 13:26:48 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Toru\u0144czyk", "Szymon", ""], ["Zeume", "Thomas", ""]]}, {"id": "2101.04819", "submitter": "Patricia Johann", "authors": "Patricia Johann and Enrico Ghiorzi", "title": "Parametricity for Nested Types and GADTs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers parametricity and its consequent free theorems for\nnested data types. Rather than representing nested types via their Church\nencodings in a higher-kinded or dependently typed extension of System F, we\nadopt a functional programming perspective and design a Hindley-Milner-style\ncalculus with primitives for constructing nested types directly as fixpoints.\nOur calculus can express all nested types appearing in the literature,\nincluding truly nested types. At the level of terms, it supports primitive\npattern matching, map functions, and fold combinators for nested types. Our\nmain contribution is the construction of a parametric model for our calculus.\nThis is both delicate and challenging. In particular, to ensure the existence\nof semantic fixpoints interpreting nested types, and thus to establish a\nsuitable Identity Extension Lemma for our calculus, our type system must\nexplicitly track functoriality of types, and cocontinuity conditions on the\nfunctors interpreting them must be appropriately threaded throughout the model\nconstruction. We also prove that our model satisfies an appropriate Abstraction\nTheorem, as well as that it verifies all standard consequences of parametricity\nin the presence of primitive nested types. We give several concrete examples\nillustrating how our model can be used to derive useful free theorems,\nincluding a short cut fusion transformation, for programs over nested types.\nFinally, we consider generalizing our results to GADTs, and argue that no\nextension of our parametric model for nested types can give a functorial\ninterpretation of GADTs in terms of left Kan extensions and still be\nparametric.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 00:43:58 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 14:55:40 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Johann", "Patricia", ""], ["Ghiorzi", "Enrico", ""]]}, {"id": "2101.04971", "submitter": "Jianling Fu", "authors": "Ming Xu (1), Jianling Fu (1), Jingyi Mei (1), Yuxin Deng (1) ((1)\n  Shanghai Key Lab of Trustworthy Computing, East China Normal University,\n  Shanghai, China)", "title": "An Algebraic Method to Fidelity-based Model Checking over Quantum Markov\n  Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fidelity is one of the most widely used quantities in quantum information\nthat measure the distance of quantum states through a noisy channel. In this\npaper, we introduce a quantum analogy of computation tree logic (CTL) called\nQCTL, which concerns fidelity instead of probability in probabilistic CTL, over\nquantum Markov chains (QMCs). Noisy channels are modelled by super-operators,\nwhich are specified by QCTL formulas; the initial quantum states are modelled\nby density operators, which are left parametric in the given QMC. The problem\nis to compute the minimumfidelity over all initial states for conservation. We\nachieve it by a reduction to quantifier elimination in the existential theory\nof the reals. The method is absolutely exact, so that QCTL formulas are proven\nto be decidable in exponential time. Finally, we implement the proposed method\nand demonstrate its effectiveness via a quantum IPv4 protocol.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 10:05:54 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Xu", "Ming", ""], ["Fu", "Jianling", ""], ["Mei", "Jingyi", ""], ["Deng", "Yuxin", ""]]}, {"id": "2101.05024", "submitter": "HAL CCSD", "authors": "Hubert Garavel (CONVECS)", "title": "Proposal for Adding Useful Features to Petri-Net Model Checkers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solutions proposed for the longstanding problem of automatic decomposition of\nPetri nets into concurrent processes, as well as methods developed in Grenoble\nfor the automatic conversion of safe Petri nets to NUPNs (Nested-Unit Petri\nNets), require certain properties to be computed on Petri nets. We notice that,\nalthough these properties are theoretically interesting and practically useful,\nthey are not currently implemented in mainstream Petri net tools. Taking into\naccount such properties would open fruitful research directions for tool\ndevelopers, and new perspectives for the Model Checking Contest as well.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 12:00:40 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 13:10:28 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Garavel", "Hubert", "", "CONVECS"]]}, {"id": "2101.05140", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Secure Process Algebra", "comments": "172 pages, 36 figures, 28 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on our previous work on truly concurrent process algebras APTC, we use\nit to verify the security protocols. This work (called Secure APTC, abbreviated\nSAPTC) have the following advantages in verifying security protocols: (1) It\nhas a firmly theoretic foundations, including equational logics, structured\noperational semantics, and axiomatizations between them; (2) It has rich\nexpressive powers to describe security protocols. Cryptographic operations are\nmodeled as atomic actions and can be extended, explicit parallelism and\ncommunication mechanism to modeling communication operations and principals,\nrich computational properties to describing computational logics in the\nsecurity protocols, including conditional guards, alternative composition,\nsequential composition, parallelism and communication, encapsulation and\ndeadlock, recursion, abstraction. (3) Especially by abstraction, it is\nconvenient and obvious to observe the relations between the inputs and outputs\nof a security protocols, including the relations without any attack, the\nrelations under each known attack, and the relations under unknown attacks if\nthe unknown attacks can be described.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:35:38 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 03:47:56 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 16:08:41 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 04:18:38 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "2101.05256", "submitter": "EPTCS", "authors": "Thao Dang (Verimag/CNRS, France), Stefan Ratschan (Institute of\n  Computer Science, Czech Academy of Sciences)", "title": "Proceedings 6th International Workshop on Symbolic-Numeric methods for\n  Reasoning about CPS and IoT", "comments": null, "journal-ref": "EPTCS 331, 2021", "doi": "10.4204/EPTCS.331", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proceedings of the 6th International Workshop on Symbolic-Numeric Methods\nfor Reasoning about CPS and IoT (SNR 2020) contains papers underlying talks\npresented at the workshop. SNR focuses on the combination of symbolic and\nnumeric methods for reasoning about Cyber-Physical Systems and the Internet of\nThings to facilitate model identification, specification, verification, and\ncontrol synthesis for these systems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 06:32:01 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Dang", "Thao", "", "Verimag/CNRS, France"], ["Ratschan", "Stefan", "", "Institute of\n  Computer Science, Czech Academy of Sciences"]]}, {"id": "2101.05257", "submitter": "Lawrence Paulson", "authors": "Angeliki Koutsoukou-Argyraki, Wenda Li, Lawrence C. Paulson", "title": "Irrationality and Transcendence Criteria for Infinite Series in\n  Isabelle/HOL", "comments": "23 pages. Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give an overview of our formalizations in the proof assistant Isabelle/HOL\nof certain irrationality and transcendence criteria for infinite series from\nthree different research papers: by Erd\\H{o}s and Straus (1974), Han\\v{c}l\n(2002), and Han\\v{c}l and Rucki (2005). Our formalizations in Isabelle/HOL can\nbe found on the Archive of Formal Proofs. Here we describe selected aspects of\nthe formalization and discuss what this reveals about the use and potential of\nIsabelle/HOL in formalizing modern mathematical research, particularly in these\nparts of number theory and analysis.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 14:20:03 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 15:35:50 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Koutsoukou-Argyraki", "Angeliki", ""], ["Li", "Wenda", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "2101.05415", "submitter": "EPTCS", "authors": "Tommaso Dreossi (Amazon Search), Giorgio Ballardin (Amazon Search),\n  Parth Gupta (Amazon Search), Jan Bakus (Amazon Search), Yu-Hsiang Lin (Amazon\n  Search), Vamsi Salaka (Amazon Search)", "title": "Analysis of E-commerce Ranking Signals via Signal Temporal Logic", "comments": "In Proceedings SNR 2020, arXiv:2101.05256", "journal-ref": "EPTCS 331, 2021, pp. 33-42", "doi": "10.4204/EPTCS.331.3", "report-no": null, "categories": "cs.LO cs.FL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The timed position of documents retrieved by learning to rank models can be\nseen as signals. Signals carry useful information such as drop or rise of\ndocuments over time or user behaviors. In this work, we propose to use the\nlogic formalism called Signal Temporal Logic (STL) to characterize document\nbehaviors in ranking accordingly to the specified formulas. Our analysis shows\nthat interesting document behaviors can be easily formalized and detected\nthanks to STL formulas. We validate our idea on a dataset of 100K product\nsignals. Through the presented framework, we uncover interesting patterns, such\nas cold start, warm start, spikes, and inspect how they affect our learning to\nranks models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 01:54:31 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Dreossi", "Tommaso", "", "Amazon Search"], ["Ballardin", "Giorgio", "", "Amazon Search"], ["Gupta", "Parth", "", "Amazon Search"], ["Bakus", "Jan", "", "Amazon Search"], ["Lin", "Yu-Hsiang", "", "Amazon\n  Search"], ["Salaka", "Vamsi", "", "Amazon Search"]]}, {"id": "2101.05418", "submitter": "EPTCS", "authors": "Luc Jaulin (Robex, Lab-STICC), Beno\\^it Desrochers (DGA-TN)", "title": "Enclosing the Sliding Surfaces of a Controlled Swing", "comments": "In Proceedings SNR 2020, arXiv:2101.05256", "journal-ref": "EPTCS 331, 2021, pp. 43-55", "doi": "10.4204/EPTCS.331.4", "report-no": null, "categories": "cs.RO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When implementing a non-continuous controller for a cyber-physical system, it\nmay happen that the evolution of the closed-loop system is not anymore\npiecewise differentiable along the trajectory, mainly due to conditional\nstatements inside the controller. This may lead to some unwanted chattering\neffects than may damage the system. This behavior is difficult to observe even\nin simulation. In this paper, we propose an interval approach to characterize\nthe sliding surface which corresponds to the set of all states such that the\nstate trajectory may jump indefinitely between two distinct behaviors. We show\nthat the recent notion of thick sets will allows us to compute efficiently an\nouter approximation of the sliding surface of a given class of hybrid system\ntaking into account all set-membership uncertainties. An application to the\nverification of the controller of a child swing is considered to illustrate the\nprinciple of the approach.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 01:58:15 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Jaulin", "Luc", "", "Robex, Lab-STICC"], ["Desrochers", "Beno\u00eet", "", "DGA-TN"]]}, {"id": "2101.05678", "submitter": "Francois Clement", "authors": "Fran\\c{c}ois Cl\\'ement (SERENA, CERMICS), Vincent Martin (LMAC)", "title": "Lebesgue integration. Detailed proofs to be formalized in Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CA math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To obtain the highest confidence on the correction of numerical simulation\nprograms implementing the finite element method, one has to formalize the\nmathematical notions and results that allow to establish the soundness of the\nmethod. Sobolev spaces are the mathematical framework in which most weak\nformulations of partial derivative equations are stated, and where solutions\nare sought. These functional spaces are built on integration and measure\ntheory. Hence, this chapter in functional analysis is a mandatory theoretical\ncornerstone for the definition of the finite element method. The purpose of\nthis document is to provide the formal proof community with very detailed\npen-and-paper proofs of the main results from integration and measure theory.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 15:53:18 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 07:32:24 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Cl\u00e9ment", "Fran\u00e7ois", "", "SERENA, CERMICS"], ["Martin", "Vincent", "", "LMAC"]]}, {"id": "2101.05754", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Eduardo Bonelli, Delia Kesner and Andr\\'es Viso", "title": "A Strong Bisimulation for Control Operators by Means of Multiplicative\n  and Exponential Reduction", "comments": "arXiv admin note: text overlap with arXiv:1906.09370", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this paper is to identify programs with control operators\nwhose reduction semantics are in exact correspondence. This is achieved by\nintroducing a relation $\\simeq$, defined over a revised presentation of\nParigot's $\\lambda\\mu$-calculus we dub $\\Lambda M$.\n  Our result builds on three main ingredients which guide our semantical\ndevelopment: (1) factorization of Parigot's $\\lambda\\mu$-reduction into\nmultiplicative and exponential steps by means of explicit operators, (2)\nadaptation of Laurent's original $\\simeq_\\sigma$-equivalence to $\\Lambda M$,\nand (3) interpretation of $\\Lambda M$ into Laurent's polarized proof-nets\n(PPN). More precisely, we first give a translation of $\\Lambda M$-terms into\nPPN which simulates the reduction relation of our calculus via cut elimination\nof PPN. Second, we establish a precise correspondence between our relation\n$\\simeq$ and Laurent's $\\simeq_\\sigma$-equivalence for $\\lambda\\mu$-terms.\nMoreover, $\\simeq$-equivalent terms translate to structurally equivalent PPN.\nMost notably, $\\simeq$ is shown to be a strong bisimulation with respect to\nreduction in $\\Lambda M$, i.e. two $\\simeq$-equivalent terms have the exact\nsame reduction semantics, a result which fails for Regnier's\n$\\simeq_\\sigma$-equivalence in $\\lambda$-calculus as well as for Laurent's\n$\\simeq_\\sigma$-equivalence in $\\lambda\\mu$.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 17:54:22 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bonelli", "Eduardo", ""], ["Kesner", "Delia", ""], ["Viso", "Andr\u00e9s", ""]]}, {"id": "2101.06015", "submitter": "Jeroen Keiren", "authors": "Anna Stramaglia, Jeroen J.A. Keiren and Hans Zantema", "title": "Deadlock in packet switching networks", "comments": "This is a version with full proofs of the preprint that was submitted\n  to FSEN 2021, and accepted for publication in that conference (to appear in\n  Springer LNCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deadlock in a packet switching network is a state in which one or more\nmessages have not yet reached their target, yet cannot progress any further. We\nformalize three different notions of deadlock in the context of packet\nswitching networks, to which we refer as global, local and weak deadlock. We\nestablish the precise relations between these notions, and prove they\ncharacterize different sets of deadlocks. Moreover, we implement checking of\ndeadlock freedom of packet switching networks using the symbolic model checker\nnuXmv. We show experimentally that the implementation is effective at finding\nsubtle deadlock situations in packet switching networks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 08:42:35 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Stramaglia", "Anna", ""], ["Keiren", "Jeroen J. A.", ""], ["Zantema", "Hans", ""]]}, {"id": "2101.06087", "submitter": "Christian Lidstr\\\"om", "authors": "Christian Lidstr\\\"om and Dilian Gurov (KTH Royal Institute of\n  Technology, Stockholm, Sweden)", "title": "An Abstract Contract Theory for Programs with Procedures", "comments": "24 pages. This is the full version of the paper An Abstract Contract\n  Theory for Programs with Procedures, published in Proceedings of the 24th\n  International Conference on Fundamental Approaches to Software Engineering\n  (FASE 2021), which includes the proofs of all theorems and additional\n  examples. The conference version should always be cited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When developing complex software and systems, contracts provide a means for\ncontrolling the complexity by dividing the responsibilities among the\ncomponents of the system in a hierarchical fashion. In specific application\nareas, dedicated contract theories formalise the notion of contract and the\noperations on contracts in a manner that supports best the development of\nsystems in that area. At the other end, contract meta-theories attempt to\nprovide a systematic view on the various contract theories by axiomatising\ntheir desired properties. However, there exists a noticeable gap between the\nmost well-known contract meta-theory of Benveniste et al., which focuses on the\ndesign of embedded and cyber-physical systems, and the established way of using\ncontracts when developing general software, following Meyer's\ndesign-by-contract methodology. At the core of this gap appears to be the\nnotion of procedure: while it is a central unit of composition in software\ndevelopment, the meta-theory does not suggest an obvious way of treating\nprocedures as components.\n  In this paper, we provide a first step towards a contract theory that takes\nprocedures as the basic building block, and is at the same time an\ninstantiation of the meta-theory. To this end, we propose an abstract contract\ntheory for sequential programming languages with procedures, based on\ndenotational semantics. We show that, on the one hand, the specification of\ncontracts of procedures in Hoare logic, and their procedure-modular\nverification, can be cast naturally in the framework of our abstract contract\ntheory. On the other hand, we also show our contract theory to fulfil the\naxioms of the meta-theory. In this way, we give further evidence for the\nutility of the meta-theory, and prepare the ground for combining our\ninstantiation with other, already existing instantiations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 13:02:57 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 08:16:29 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lidstr\u00f6m", "Christian", "", "KTH Royal Institute of\n  Technology, Stockholm, Sweden"], ["Gurov", "Dilian", "", "KTH Royal Institute of\n  Technology, Stockholm, Sweden"]]}, {"id": "2101.06195", "submitter": "Yong Kiam Tan", "authors": "Yong Kiam Tan, Andr\\'e Platzer", "title": "Switched Systems as Hybrid Programs", "comments": "Long version of paper at ADHS 2021 (7th IFAC Conference on Analysis\n  and Design of Hybrid Systems, July 7-9, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world systems of interest often feature interactions between discrete\nand continuous dynamics. Various hybrid system formalisms have been used to\nmodel and analyze this combination of dynamics, ranging from mathematical\ndescriptions, e.g., using impulsive differential equations and switching, to\nautomata-theoretic and language-based approaches. This paper bridges two such\nformalisms by showing how various classes of switched systems can be modeled\nusing the language of hybrid programs from differential dynamic logic (dL). The\nresulting models enable the formal specification and verification of switched\nsystems using dL and its existing deductive verification tools such as KeYmaera\nX. Switched systems also provide a natural avenue for the generalization of\ndL's deductive proof theory for differential equations. The completeness\nresults for switched system invariants proved in this paper enable effective\nsafety verification of those systems in dL.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 16:19:07 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 06:19:17 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Tan", "Yong Kiam", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2101.06223", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Markus Rabe, Wenda Li, Jimmy Ba, Roger Grosse, Christian\n  Szegedy", "title": "LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While designing inductive bias in neural architectures has been widely\nstudied, we hypothesize that transformer networks are flexible enough to learn\ninductive bias from suitable generic tasks. Here, we replace architecture\nengineering by encoding inductive bias in the form of datasets. Inspired by\nPeirce's view that deduction, induction, and abduction form an irreducible set\nof reasoning primitives, we design three synthetic tasks that are intended to\nrequire the model to have these three abilities. We specifically design these\nsynthetic tasks in a way that they are devoid of mathematical knowledge to\nensure that only the fundamental reasoning biases can be learned from these\ntasks. This defines a new pre-training methodology called \"LIME\" (Learning\nInductive bias for Mathematical rEasoning). Models trained with LIME\nsignificantly outperform vanilla transformers on three very different large\nmathematical reasoning benchmarks. Unlike dominating the computation cost as\ntraditional pre-training approaches, LIME requires only a small fraction of the\ncomputation cost of the typical downstream task.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 17:15:24 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wu", "Yuhuai", ""], ["Rabe", "Markus", ""], ["Li", "Wenda", ""], ["Ba", "Jimmy", ""], ["Grosse", "Roger", ""], ["Szegedy", "Christian", ""]]}, {"id": "2101.06240", "submitter": "Polly Fahey", "authors": "Isolde Adler and Polly Fahey", "title": "Towards Approximate Query Enumeration with Sublinear Preprocessing Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at providing extremely efficient algorithms for approximate\nquery enumeration on sparse databases, that come with performance and accuracy\nguarantees. We introduce a new model for approximate query enumeration on\nclasses of relational databases of bounded degree. We first prove that on\ndatabases of bounded degree any local first-order definable query can be\nenumerated approximately with constant delay after a constant time\npreprocessing phase. We extend this, showing that on databases of bounded\ntree-width and bounded degree, every query that is expressible in first-order\nlogic can be enumerated approximately with constant delay after a sublinear\n(more precisely, polylogarithmic) time preprocessing phase.\n  Durand and Grandjean (ACM Transactions on Computational Logic 2007) proved\nthat exact enumeration of first-order queries on databases of bounded degree\ncan be done with constant delay after a linear time preprocessing phase. Hence\nwe achieve a significant speed-up in the preprocessing phase. Since sublinear\nrunning time does not allow reading the whole input database even once,\nsacrificing some accuracy is inevitable for our speed-up. Nevertheless, our\nenumeration algorithms come with guarantees: With high probability, (1) only\ntuples are enumerated that are answers to the query or `close' to being answers\nto the query, and (2) if the proportion of tuples that are answers to the query\nis sufficiently large, then all answers will be enumerated. Here the notion of\n`closeness' is a tuple edit distance in the input database. For local\nfirst-order queries, only actual answers are enumerated, strengthening (1).\nMoreover, both the `closeness' and the proportion required in (2) are\ncontrollable.\n  We combine methods from property testing of bounded degree graphs with logic\nand query enumeration, which we believe can inspire further research.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 17:55:22 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Adler", "Isolde", ""], ["Fahey", "Polly", ""]]}, {"id": "2101.06644", "submitter": "Theophile Sautory", "authors": "Theophile Sautory, Nuri Cingillioglu, Alessandra Russo", "title": "HySTER: A Hybrid Spatio-Temporal Event Reasoner", "comments": "Preprint accepted by the 35th AAAI Conference on Artificial\n  Intelligence (AAAI-21) Workshop on Hybrid Artificial Intelligence (HAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Video Question Answering (VideoQA) consists in answering natural\nlanguage questions about a video and serves as a proxy to evaluate the\nperformance of a model in scene sequence understanding. Most methods designed\nfor VideoQA up-to-date are end-to-end deep learning architectures which\nstruggle at complex temporal and causal reasoning and provide limited\ntransparency in reasoning steps. We present the HySTER: a Hybrid\nSpatio-Temporal Event Reasoner to reason over physical events in videos. Our\nmodel leverages the strength of deep learning methods to extract information\nfrom video frames with the reasoning capabilities and explainability of\nsymbolic artificial intelligence in an answer set programming framework. We\ndefine a method based on general temporal, causal and physics rules which can\nbe transferred across tasks. We apply our model to the CLEVRER dataset and\ndemonstrate state-of-the-art results in question answering accuracy. This work\nsets the foundations for the incorporation of inductive logic programming in\nthe field of VideoQA.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 11:07:17 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sautory", "Theophile", ""], ["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "2101.06757", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Mathieu Huot, Sam Staton, Matthijs V\\'ak\\'ar", "title": "Higher Order Automatic Differentiation of Higher Order Functions", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.02209", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present semantic correctness proofs of automatic differentiation (AD). We\nconsider a forward-mode AD method on a higher order language with algebraic\ndata types, and we characterise it as the unique structure preserving macro\ngiven a choice of derivatives for basic operations. We describe a rich\nsemantics for differentiable programming, based on diffeological spaces. We\nshow that it interprets our language, and we phrase what it means for the AD\nmethod to be correct with respect to this semantics. We show that our\ncharacterisation of AD gives rise to an elegant semantic proof of its\ncorrectness based on a gluing construction on diffeological spaces. We explain\nhow this is, in essence, a logical relations argument. Throughout, we show how\nthe analysis extends to AD methods for computing higher order derivatives using\na Taylor approximation.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 19:24:46 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Huot", "Mathieu", ""], ["Staton", "Sam", ""], ["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "2101.06825", "submitter": "Makai Mann", "authors": "Makai Mann, Ahmed Irfan, Alberto Griggio, Oded Padon, Clark Barrett", "title": "Counterexample-Guided Prophecy for Model Checking Modulo the Theory of\n  Arrays", "comments": "23 pages, 1 figure, 1 table, extended version of paper that appeared\n  in International Conference on Tools and Algorithms for the Construction and\n  Analysis of Systems 2021, Version Updates: formatting and updated extended\n  proofs", "journal-ref": null, "doi": "10.1007/978-3-030-72016-2_7", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We develop a framework for model checking infinite-state systems by\nautomatically augmenting them with auxiliary variables, enabling\nquantifier-free induction proofs for systems that would otherwise require\nquantified invariants. We combine this mechanism with a counterexample-guided\nabstraction refinement scheme for the theory of arrays. Our framework can thus,\nin many cases, reduce inductive reasoning with quantifiers and arrays to\nquantifier-free and array-free reasoning. We evaluate the approach on a wide\nset of benchmarks from the literature. The results show that our implementation\noften outperforms state-of-the-art tools, demonstrating its practical\npotential.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 01:23:00 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 14:55:21 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Mann", "Makai", ""], ["Irfan", "Ahmed", ""], ["Griggio", "Alberto", ""], ["Padon", "Oded", ""], ["Barrett", "Clark", ""]]}, {"id": "2101.06989", "submitter": "Patrick Totzke", "authors": "Richard Mayr, Sven Schewe, Patrick Totzke, Dominik Wojtczak", "title": "Simple Stochastic Games with Almost-Sure Energy-Parity Objectives are in\n  NP and coNP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic games with energy-parity objectives, which combine\nquantitative rewards with a qualitative $\\omega$-regular condition: The\nmaximizer aims to avoid running out of energy while simultaneously satisfying a\nparity condition. We show that the corresponding almost-sure problem, i.e.,\nchecking whether there exists a maximizer strategy that achieves the\nenergy-parity objective with probability $1$ when starting at a given energy\nlevel $k$, is decidable and in $NP \\cap coNP$. The same holds for checking if\nsuch a $k$ exists and if a given $k$ is minimal.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 10:50:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Mayr", "Richard", ""], ["Schewe", "Sven", ""], ["Totzke", "Patrick", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "2101.07038", "submitter": "L\\'eo Exibard", "authors": "L\\'eo Exibard, Emmanuel Filiot, Nathan Lhote and Pierre-Alain Reynier", "title": "Computability of Data-Word Transductions over Different Data Domains", "comments": "Extended version of arxiv:2002.08203", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the problem of synthesizing computable\nfunctions of infinite words over an infinite alphabet (data $\\omega$-words).\nThe notion of computability is defined through Turing machines with infinite\ninputs which can produce the corresponding infinite outputs in the limit. We\nuse non-deterministic transducers equipped with registers, an extension of\nregister automata with outputs, to describe specifications. Being\nnon-deterministic, such transducers may not define functions but more generally\nrelations of data $\\omega$-words. In order to increase the expressive power of\nthese machines, we even allow guessing of arbitrary data values when updating\ntheir registers.\n  For functions over data $\\omega$-words, we identify a sufficient condition\n(the possibility of determining the next letter to be outputted, which we call\nnext letter problem) under which computability (resp. uniform computability)\nand continuity (resp. uniform continuity) coincide.\n  We focus on two kinds of data domains: first, the general setting of\noligomorphic data, which encompasses any data domain with equality, as well as\nthe setting of rational numbers with linear order; and second, the set of\nnatural numbers equipped with linear order. For both settings, we prove that\nfunctionality, i.e. determining whether the relation recognized by the\ntransducer is actually a function, is decidable. We also show that the\nso-called next letter problem is decidable, yielding equivalence between\n(uniform) continuity and (uniform) computability. Last, we provide\ncharacterizations of (uniform) continuity, which allow us to prove that these\nnotions, and thus also (uniform) computability, are decidable. We even show\nthat all these decision problems are PSpace-complete for (N,<) and for a large\nclass of oligomorphic data domains, including for instance (Q,<).\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 12:23:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Exibard", "L\u00e9o", ""], ["Filiot", "Emmanuel", ""], ["Lhote", "Nathan", ""], ["Reynier", "Pierre-Alain", ""]]}, {"id": "2101.07066", "submitter": "Kyriaki Psara", "authors": "Kyriaki Psara", "title": "Reversible Computation in Petri Nets", "comments": "PhD dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible computation is an unconventional form of computing that extends\nthe standard forward-only mode of computation with the ability to execute a\nsequence of operations in reverse at any point during computation. As such, in\nthis thesis we propose a reversible approach to Petri nets by introducing\nmachinery and associated operational semantics to tackle the challenges of the\nmain forms of reversibility. Our proposal concerns a variation of cyclic Petri\nnets, called Reversing Petri Nets (RPNs) where tokens are persistent and\ndistinguished from each other by an identity. An immediate extension of the\noriginal model includes allowing multiple tokens of the same base/type to occur\nin a model. Specifically, we explore the individual token interpretation where\none distinguishes different tokens residing in the same place by keeping track\nof where they come from. We also propose the collective token interpretation,\nas the opposite approach to token ambiguity, which considers all tokens of a\ncertain type to be identical, disregarding their history during execution. Both\nof the proposed models of RPNs (with single or multi tokens) implement the\nnotion of uncontrolled reversibility, meaning that it specifies how to reverse\nan execution and allows to do so freely, yet it places no restrictions as to\nwhen and whether to prefer backward execution over forward execution or vice\nversa. In this respect, a further aim is to control reversibility by extending\nour formal semantics where transitions are associated with conditions whose\nsatisfaction allows the execution of transitions in the forward/reversed\ndirection.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 16:21:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Psara", "Kyriaki", ""]]}, {"id": "2101.07109", "submitter": "Christopher Hahn", "authors": "Bernd Finkbeiner, Christopher Hahn, Marvin Stenger, Leander Tentrup", "title": "Efficient Monitoring of Hyperproperties using Prefix Trees", "comments": "arXiv admin note: text overlap with arXiv:1807.00758,\n  arXiv:1906.00798", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties, such as non-interference and observational determinism,\nrelate multiple computation traces with each other and are thus not monitorable\nby tools that consider computations in isolation. We present the monitoring\napproach implemented in the latest version of RVHyper, a runtime verification\ntool for hyperproperties. The input to the tool are specifications given in the\ntemporal logic HyperLTL, which extends linear-time temporal logic (LTL) with\ntrace quantifiers and trace variables. RVHyper processes execution traces\nsequentially until a violation of the specification is detected. In this case,\na counter example, in the form of a set of traces, is returned. RVHyper employs\na range of optimizations: a preprocessing analysis of the specification and a\nprocedure that minimizes the traces that need to be stored during the\nmonitoring process. In this article, we introduce a novel trace storage\ntechnique that arranges the traces in a tree-like structure to exploit\npartially equal traces. We evaluate RVhyper on existing benchmarks on secure\ninformation-flow control, error correcting codes and symmetry in hardware\ndesigns. As an example application outside of security, we show how RVHyper can\nbe used to detect spurious dependencies in hardware designs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 15:10:56 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Hahn", "Christopher", ""], ["Stenger", "Marvin", ""], ["Tentrup", "Leander", ""]]}, {"id": "2101.07161", "submitter": "Jana Hofmann", "authors": "Bernd Finkbeiner, Christopher Hahn, Jana Hofmann, Leander Tentrup", "title": "Realizing Omega-regular Hyperproperties", "comments": "International Conference on Computer Aided Verification (CAV 2020)", "journal-ref": "=In: Lahiri S., Wang C. (eds) Computer Aided Verification. CAV\n  2020. Lecture Notes in Computer Science, vol 12225", "doi": "10.1007/978-3-030-53291-8_4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied the hyperlogic HyperQPTL, which combines the concepts of trace\nrelations and $\\omega$-regularity. We showed that HyperQPTL is very expressive,\nit can express properties like promptness, bounded waiting for a grant,\nepistemic properties, and, in particular, any $\\omega$-regular property. Those\nproperties are not expressible in previously studied hyperlogics like HyperLTL.\nAt the same time, we argued that the expressiveness of HyperQPTL is optimal in\na sense that a more expressive logic for $\\omega$-regular hyperproperties would\nhave an undecidable model checking problem. We furthermore studied the\nrealizability problem of HyperQPTL. We showed that realizability is decidable\nfor HyperQPTL fragments that contain properties like promptness. But still, in\ncontrast to the satisfiability problem, propositional quantification does make\nthe realizability problem of hyperlogics harder. More specifically, the\nHyperQPTL fragment of formulas with a universal-existential propositional\nquantifier alternation followed by a single trace quantifier is undecidable in\ngeneral, even though the projection of the fragment to HyperLTL has a decidable\nrealizability problem. Lastly, we implemented the bounded synthesis problem for\nHyperQPTL in the prototype tool BoSy. Using BoSy with HyperQPTL specifications,\nwe have been able to synthesize several resource arbiters. The synthesis\nproblem of non-linear-time hyperlogics is still open. For example, it is not\nyet known how to synthesize systems from specifications given in branching-time\nhyperlogics like HyperCTL$^*$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 16:54:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Hahn", "Christopher", ""], ["Hofmann", "Jana", ""], ["Tentrup", "Leander", ""]]}, {"id": "2101.07202", "submitter": "Christoph Weinhuber", "authors": "Pranav Ashok, Mathias Jackermeier, Jan K\\v{r}et\\'insk\\'y, Christoph\n  Weinhuber, Maximilian Weininger, Mayank Yadav", "title": "dtControl 2.0: Explainable Strategy Representation via Decision Tree\n  Learning Steered by Experts", "comments": null, "journal-ref": "TACAS (2) (pp. 326-345). Springer. 2021", "doi": "10.1007/978-3-030-72013-1_17", "report-no": null, "categories": "cs.AI cs.FL cs.LG cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances have shown how decision trees are apt data structures for\nconcisely representing strategies (or controllers) satisfying various\nobjectives. Moreover, they also make the strategy more explainable. The recent\ntool dtControl had provided pipelines with tools supporting strategy synthesis\nfor hybrid systems, such as SCOTS and Uppaal Stratego. We present dtControl\n2.0, a new version with several fundamentally novel features. Most importantly,\nthe user can now provide domain knowledge to be exploited in the decision tree\nlearning process and can also interactively steer the process based on the\ndynamically provided information. To this end, we also provide a graphical user\ninterface. It allows for inspection and re-computation of parts of the result,\nsuggesting as well as receiving advice on predicates, and visual simulation of\nthe decision-making process. Besides, we interface model checkers of\nprobabilistic systems, namely Storm and PRISM and provide dedicated support for\ncategorical enumeration-type state variables. Consequently, the controllers are\nmore explainable and smaller.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 11:22:49 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:10:43 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ashok", "Pranav", ""], ["Jackermeier", "Mathias", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weinhuber", "Christoph", ""], ["Weininger", "Maximilian", ""], ["Yadav", "Mayank", ""]]}, {"id": "2101.07232", "submitter": "Felix Klein", "authors": "Gideon Geier, Philippe Heim, Felix Klein, Bernd Finkbeiner", "title": "Syntroids: Synthesizing a Game for FPGAs using Temporal Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Syntroids, a case study for the automatic synthesis of hardware\nfrom a temporal logic specification. Syntroids is a space shooter arcade game\nrealized on an FPGA, where the control flow architecture has been completely\nspecified in Temporal Stream Logic (TSL) and implemented using reactive\nsynthesis. TSL is a recently introduced temporal logic that separates control\nand data. This leads to scalable synthesis, because the cost of the synthesis\nprocess is independent of the complexity of the handled data.\n  In this case study, we report on our experience with the TSL-based\ndevelopment of the Syntroids game and on the implementation quality obtained\nwith synthesis in comparison to manual programming. We also discuss solved and\nopen challenges with respect to currently available synthesis tools.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 18:35:25 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Geier", "Gideon", ""], ["Heim", "Philippe", ""], ["Klein", "Felix", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2101.07491", "submitter": "Abolfazl Lavaei", "authors": "Abolfazl Lavaei, Sadegh Soudjani, Alessandro Abate, Majid Zamani", "title": "Automated Verification and Synthesis of Stochastic Hybrid Systems: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic hybrid systems have received significant attentions as a relevant\nmodelling framework describing many systems, from engineering to the life\nsciences: they enable the study of numerous applications, including\ntransportation networks, biological systems and chemical reaction networks,\nsmart energy and power grids, and beyond. Automated verification and policy\nsynthesis for stochastic hybrid systems can be inherently challenging: this is\ndue to the heterogeneity of their dynamics (presence of continuous and discrete\ncomponents), the presence of uncertainty, and in some applications the large\ndimension of state and input sets. Over the past few years, a few hundred\narticles have investigated these models, and developed diverse and powerful\napproaches to mitigate difficulties encountered in the analysis and synthesis\nof such complex stochastic systems. In this survey, we overview the most recent\nresults in the literature and discuss different approaches, including\n(in)finite abstractions, verification and synthesis for temporal logic\nspecifications, stochastic similarity relations, (control) barrier\ncertificates, compositional techniques, and a selection of results on\ncontinuous-time stochastic systems; we finally survey recently developed\nsoftware tools that implement the discussed approaches. Throughout the\nmanuscript we discuss a few open topics to be considered as potential future\nresearch directions: we hope that this survey will guide younger researchers\nthrough a comprehensive understanding of the various challenges, tools, and\nsolutions in this enticing and rich scientific area.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:24:47 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lavaei", "Abolfazl", ""], ["Soudjani", "Sadegh", ""], ["Abate", "Alessandro", ""], ["Zamani", "Majid", ""]]}, {"id": "2101.07495", "submitter": "Nathan Grosshans", "authors": "Nathan Grosshans, Pierre Mckenzie (DIRO), Luc Segoufin (VALDA, DI-ENS)", "title": "Tameness and the power of programs over monoids in DA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The program-over-monoid model of computation originates with Barrington's\nproof that it captures the complexity class NC$^1$. Here we make progress in\nunderstanding the subtleties of the model. First, we identify a new tameness\ncondition on a class of monoids that entails a natural characterization of the\nregular languages recognizable by programs over monoids from the class. Second,\nwe prove that the class known as DA satisfies tameness and hence that the\nregular languages recognized by programs over monoids in DA are precisely those\nrecognizable in the classical sense by morphisms from QDA. Third, we show by\ncontrast that the well studied class of monoids called J is not tame. Finally,\nwe exhibit a program-length-based hierarchy within the class of languages\nrecognized by programs over monoids from DA.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:41:31 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Grosshans", "Nathan", "", "DIRO"], ["Mckenzie", "Pierre", "", "DIRO"], ["Segoufin", "Luc", "", "VALDA, DI-ENS"]]}, {"id": "2101.07700", "submitter": "Maximiliano Cristia", "authors": "Maximiliano Cristi\\'a and Ricardo D. Katz and Gianfranco Rossi", "title": "Proof Automation in the Theory of Finite Sets and Finite Set Relation\n  Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  {log} ('setlog') is a satisfiability solver for formulas of the theory of\nfinite sets and finite set relation algebra (FSTRA). As such, it can be used as\nan automated theorem prover (ATP) for this theory. {log} is able to\nautomatically prove a number of FSTRA theorems, but not all of them.\nNevertheless, we have observed that many theorems that {log} cannot\nautomatically prove can be divided into a few subgoals automatically\ndischargeable by {log}. The purpose of this work is to present a prototype\ninteractive theorem prover (ITP), called {log}-ITP, providing evidence that a\nproper integration of {log} into world-class ITP's can deliver a great deal of\nproof automation concerning FSTRA. An empirical evaluation based on 210\ntheorems from the TPTP and Coq's SSReflect libraries shows a noticeable\nreduction in the size and complexity of the proofs with respect to Coq.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 16:05:40 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Cristi\u00e1", "Maximiliano", ""], ["Katz", "Ricardo D.", ""], ["Rossi", "Gianfranco", ""]]}, {"id": "2101.07701", "submitter": "Daniel Gra\\c{c}a", "authors": "Daniel S. Gra\\c{c}a and Ning Zhong", "title": "Computing the exact number of periodic orbits for planar flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we consider the problem of determining the \\emph{exact} number\nof periodic orbits for polynomial planar flows. This problem is a variant of\nHilbert's 16th problem. Using a natural definition of computability, we show\nthat the problem is noncomputable on the one hand and, on the other hand,\ncomputable uniformly on the set of all structurally stable systems defined on\nthe unit disk. We also prove that there is a family of polynomial planar\nsystems which does not have a computable sharp upper bound on the number of its\nperiodic orbits.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 16:06:46 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Gra\u00e7a", "Daniel S.", ""], ["Zhong", "Ning", ""]]}, {"id": "2101.07711", "submitter": "Irina Lomazova", "authors": "Irina Lomazova (HSE University, Moscow, Russia) and Vladimir Bashkin\n  (Yaroslavl State University, Yaroslavl, Russia)", "title": "On the Decidability of Behavioral Equivalences for (P,P)-PRS", "comments": "Submitted to LICS'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study resource similarity and resource bisimilarity -- congruent\nrestrictions of the bisimulation equivalence for the (P,P)-class of Process\nRewrite Systems (PRS). Both these equivalences coincide with the bisimulation\nequivalence for (1,P)-subclass of (P,P)-PRS, which is known to be decidable.\nWhile it has been shown in the literature that resource similarity is\nundecidable for (P,P)-PRS, decidability of resource bisimilarity for (P,P)-PRS\nremained an open question.\n  In this paper, we present an algorithm for checking resource bisimilarity for\n(P,P)-PRS. We show that although both resource similarity and resource\nbisimilarity are congruences and have a finite semi-linear basis, only the\nlatter is decidable.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 16:27:40 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lomazova", "Irina", "", "HSE University, Moscow, Russia"], ["Bashkin", "Vladimir", "", "Yaroslavl State University, Yaroslavl, Russia"]]}, {"id": "2101.07758", "submitter": "Robert Y. Lewis", "authors": "Robert Y. Lewis and Minchao Wu", "title": "A bi-directional extensible interface between Lean and Mathematica", "comments": "arXiv admin note: substantial text overlap with arXiv:1712.09288", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a user-extensible ad hoc connection between the Lean proof\nassistant and the computer algebra system Mathematica. By reflecting the syntax\nof each system in the other and providing a flexible interface for extending\ntranslation, our connection allows for the exchange of arbitrary information\nbetween the two systems.\n  We show how to make use of the Lean metaprogramming framework to verify\ncertain Mathematica computations, so that the rigor of the proof assistant is\nnot compromised. We also use Mathematica as an untrusted oracle to guide proof\nsearch in the proof assistant and interact with a Mathematica notebook from\nwithin a Lean session. In the other direction, we import and process Lean\ndeclarations from within Mathematica. The proof assistant library serves as a\ndatabase of mathematical knowledge that the CAS can display and explore.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 11:33:25 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lewis", "Robert Y.", ""], ["Wu", "Minchao", ""]]}, {"id": "2101.07761", "submitter": "Mario Frank", "authors": "Mario Frank", "title": "The Coq Proof Script Visualiser (coq-psv)", "comments": "This contribution was presented during a talk at the Coq Workshop\n  2020, affiliated with the IJCAR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we present a visualisation tool that is able to process Coq\nproof scripts and generate a table representation of the contained proofs as\n$\\LaTeX$ or PDF files. This tool has the aim to support both education and\nreview processes as all proof steps can be visualised. Thus, there is no need\nto use Coq in order to review proofs or use them as examples in teaching. In\ncontrast to the usual approach of visualising proofs as hypertext or markdown\ndocuments, the generated files can be easily printed.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 08:52:31 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Frank", "Mario", ""]]}, {"id": "2101.07847", "submitter": "Bernd Finkbeiner", "authors": "Borzoo Bonakdarpour and Bernd Finkbeiner", "title": "The Complexity of Monitoring Hyperproperties", "comments": null, "journal-ref": null, "doi": "10.1109/CSF.2018.00019", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the runtime verification of hyperproperties, expressed in the\ntemporal logic HyperLTL, as a means to inspect a system with respect to\nsecurity polices. Runtime monitors for hyperproperties analyze trace logs that\nare organized by common prefixes in the form of a tree-shaped Kripke structure,\nor are organized both by common prefixes and by common suffixes in the form of\nan acyclic Kripke structure. Unlike runtime verification techniques for trace\nproperties, where the monitor tracks the state of the specification but usually\ndoes not need to store traces, a monitor for hyperproperties repeatedly model\nchecks the growing Kripke structure. This calls for a rigorous complexity\nanalysis of the model checking problem over tree-shaped and acyclic Kripke\nstructures. We show that for trees, the complexity in the size of the Kripke\nstructure is L-complete independently of the number of quantifier alternations\nin the HyperLTL formula. For acyclic Kripke structures, the complexity is\nPSPACE-complete (in the level of the polynomial hierarchy that corresponds to\nthe number of quantifier alternations). The combined complexity in the size of\nthe Kripke structure and the length of the HyperLTL formula is PSPACE-complete\nfor both trees and acyclic Kripke structures, and is as low as NC for the\nrelevant case of trees and alternation-free HyperLTL formulas. Thus, the size\nand shape of both the Kripke structure and the formula have significant impact\non the complexity of the model checking problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 20:14:00 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Bonakdarpour", "Borzoo", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2101.08011", "submitter": "Anca Muscholl", "authors": "Sougata Bose, S.N. Krishna, Anca Muscholl, Gabriele Puppis", "title": "One-way resynchronizability of word transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The origin semantics for transducers was proposed in 2014, and led to various\ncharacterizations and decidability results that are in contrast with the\nclassical semantics. In this paper we add a further decidability result for\ncharacterizing transducers that are close to one-way transducers in the origin\nsemantics. We show that it is decidable whether a non-deterministic two-way\nword transducer can be resynchronized by a bounded, regular resynchronizer into\nan origin-equivalent one-way transducer. The result is in contrast with the\nusual semantics, where it is undecidable to know if a non-deterministic two-way\ntransducer is equivalent to some one-way transducer.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 07:59:46 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Bose", "Sougata", ""], ["Krishna", "S. N.", ""], ["Muscholl", "Anca", ""], ["Puppis", "Gabriele", ""]]}, {"id": "2101.08181", "submitter": "Julien Lange", "authors": "Mario Bravetti, Julien Lange, Gianluigi Zavattaro", "title": "Fair Refinement for Asynchronous Session Types (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Session types are widely used as abstractions of asynchronous message passing\nsystems. Refinement for such abstractions is crucial as it allows improvements\nof a given component without compromising its compatibility with the rest of\nthe system. In the context of session types, the most general notion of\nrefinement is the asynchronous session subtyping, which allows to anticipate\nmessage emissions but only under certain conditions. In particular,\nasynchronous session subtyping rules out candidates subtypes that occur\nnaturally in communication protocols where, e.g., two parties simultaneously\nsend each other a finite but unspecified amount of messages before removing\nthem from their respective buffers. To address this shortcoming, we study fair\ncompliance over asynchronous session types and fair refinement as the relation\nthat preserves it. This allows us to propose a novel variant of session\nsubtyping that leverages the notion of controllability from service contract\ntheory and that is a sound characterisation of fair refinement. In addition, we\nshow that both fair refinement and our novel subtyping are undecidable. We also\npresent a sound algorithm, and its implementation, which deals with examples\nthat feature potentially unbounded buffering.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 15:29:27 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Bravetti", "Mario", ""], ["Lange", "Julien", ""], ["Zavattaro", "Gianluigi", ""]]}, {"id": "2101.08184", "submitter": "Richard Eggert", "authors": "Paolo Baldan, Richard Eggert, Barbara K\\\"onig, Tommaso Padoan", "title": "Fixpoint Theory -- Upside Down", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knaster-Tarski's theorem, characterising the greatest fixpoint of a monotone\nfunction over a complete lattice as the largest post-fixpoint, naturally leads\nto the so-called coinduction proof principle for showing that some element is\nbelow the greatest fixpoint (e.g., for providing bisimilarity witnesses). The\ndual principle, used for showing that an element is above the least fixpoint,\nis related to inductive invariants. In this paper we provide proof rules which\nare similar in spirit but for showing that an element is above the greatest\nfixpoint or, dually, below the least fixpoint. The theory is developed for\nnon-expansive monotone functions on suitable lattices of the form\n$\\mathbb{M}^Y$, where $Y$ is a finite set and $\\mathbb{M}$ an MV-algebra, and\nit is based on the construction of (finitary) approximations of the original\nfunctions. We show that our theory applies to a wide range of examples,\nincluding termination probabilities, behavioural distances for probabilistic\nautomata and bisimilarity. Moreover, quite interestingly, it allows us to\ndetermine original algorithms for solving simple stochastic games.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 15:31:01 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 11:09:43 GMT"}], "update_date": "2021-04-10", "authors_parsed": [["Baldan", "Paolo", ""], ["Eggert", "Richard", ""], ["K\u00f6nig", "Barbara", ""], ["Padoan", "Tommaso", ""]]}, {"id": "2101.08257", "submitter": "Bernd Finkbeiner", "authors": "Borzoo Bonakdarpour and Bernd Finkbeiner", "title": "Program Repair for Hyperproperties", "comments": "arXiv admin note: text overlap with arXiv:2101.07847", "journal-ref": null, "doi": "10.1007/978-3-030-31784-3_25", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the repair problem for hyperproperties specified in the temporal\nlogic HyperLTL. Hyperproperties are system properties that relate multiple\ncomputation traces. This class of properties includes information flow policies\nlike noninterference and observational determinism. The repair problem is to\nfind, for a given Kripke structure, a substructure that satisfies a given\nspecification. We show that the repair problem is decidable for HyperLTL\nspecifications and finite-state Kripke structures. We provide a detailed\ncomplexity analysis for different fragments of HyperLTL and different system\ntypes: tree-shaped, acyclic, and general Kripke structures.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 20:21:36 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Bonakdarpour", "Borzoo", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2101.08364", "submitter": "Giulio Guerrieri", "authors": "Claudia Faggian, Giulio Guerrieri", "title": "Factorization in Call-by-Name and Call-by-Value Calculi via Linear Logic\n  (long version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In each variant of the lambda-calculus, factorization and normalization are\ntwo key-properties that show how results are computed. Instead of proving\nfactorization/normalization for the call-by-name (CbN) and call-by-value (CbV)\nvariants separately, we prove them only once, for the bang calculus (an\nextension of the lambda-calculus inspired by linear logic and subsuming CbN and\nCbV), and then we transfer the result via translations, obtaining\nfactorization/normalization for CbN and CbV. The approach is robust: it still\nholds when extending the calculi with operators and extra rules to model some\nadditional computational features.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 23:40:00 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Faggian", "Claudia", ""], ["Guerrieri", "Giulio", ""]]}, {"id": "2101.08377", "submitter": "Sebastian Rudolph", "authors": "Emanuel Kiero\\'nski and Sebastian Rudolph", "title": "Finite Model Theory of the Triguarded Fragment and Related Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Triguarded Fragment (TGF) is among the most expressive decidable\nfragments of first-order logic, subsuming both its two-variable and guarded\nfragments without equality. We show that the TGF has the finite model property\n(providing a tight doubly exponential bound on the model size) and hence finite\nsatisfiability coincides with satisfiability known to be N2ExpTime-complete.\nUsing similar constructions, we also establish 2ExpTime-completeness for finite\nsatisfiability of the constant-free (tri)guarded fragment with transitive\nguards.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 00:47:50 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 08:56:14 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kiero\u0144ski", "Emanuel", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2101.08491", "submitter": "Guilhem Jaber", "authors": "Guilhem Jaber (GALLINETTE, LS2N), Andrzej S. Murawski", "title": "Complete trace models of state and control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a hierarchy of four typed call-by-value languages with either\nhigher-order or ground-type references and with either callcc or no control\noperator.Our first result is a fully abstract trace model for the most\nexpressive setting, featuring both higher-order references and callcc,\nconstructed in the spirit of operational game semantics. Next we examine the\nimpact of suppressing higher-order references and callcc in contexts and\nprovide an operational explanation for the game-semantic conditions known as\nvisibility and bracketing respectively.This allows us to refine the original\nmodel to provide fully abstract trace models of interaction with contexts that\nneed not use higher-order references or callcc. Along the way, we discuss the\nrelationship between error- and termination-based contextual testing in each\ncase, and relate the two to trace and complete trace equivalence\nrespectively.Overall, the paper provides a systematic development of\noperational game semantics for all four cases, which represent the state-based\nface of the so-called semantic cube.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 08:11:08 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Jaber", "Guilhem", "", "GALLINETTE, LS2N"], ["Murawski", "Andrzej S.", ""]]}, {"id": "2101.08735", "submitter": "Jonas Schmidt", "authors": "Jonas Schmidt, Thomas Schwentick, Till Tantau, Nils Vortmeier, Thomas\n  Zeume", "title": "Work-sensitive Dynamic Complexity of Formal Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Which amount of parallel resources is needed for updating a query result\nafter changing an input? In this work we study the amount of work required for\ndynamically answering membership and range queries for formal languages in\nparallel constant time with polynomially many processors. As a prerequisite, we\npropose a framework for specifying dynamic, parallel, constant-time programs\nthat require small amounts of work. This framework is based on the dynamic\ndescriptive complexity framework by Patnaik and Immerman.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 17:25:47 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Schmidt", "Jonas", ""], ["Schwentick", "Thomas", ""], ["Tantau", "Till", ""], ["Vortmeier", "Nils", ""], ["Zeume", "Thomas", ""]]}, {"id": "2101.08767", "submitter": "Amanda Vidal", "authors": "Amanda Vidal", "title": "Non axiomatizability of Modal Lukasiewicz Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we study the decidability of the global modal logic arising from\nKripke frames evaluated on certain residuated lattices (including all BL\nalgebras), known in the literature as crisp modal many-valued logics. We\nexhibit a large family of these modal logics that are undecidable, in\nopposition to classical modal logic and to the propositional logics defined\nover the same classes of algebras. These include the global modal logics\narising from the standard Lukasiewicz and Product algebras. Furthermore, it is\nshown that global modal Lukasiewicz and Product logics are not recursively\naxiomatizable. We conclude the paper by solving negatively the open question of\nwhether a global modal logic coincides with the local modal logic closed under\nthe unrestricted necessitation rule.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 18:44:57 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Vidal", "Amanda", ""]]}, {"id": "2101.08880", "submitter": "Bernd Finkbeiner", "authors": "Borzoo Bonakdarpour and Bernd Finkbeiner", "title": "Controller Synthesis for Hyperproperties", "comments": "arXiv admin note: text overlap with arXiv:2101.08257", "journal-ref": null, "doi": "10.1109/CSF49147.2020.00033", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of controller synthesis for hyperproperties\nspecified in the temporal logic HyperLTL. Hyperproperties are system properties\nthat relate multiple execution traces. Hyperproperties can elegantly express\ninformation-flow policies like noninterference and observational determinism.\nThe controller synthesis problem is to automatically design a controller for a\nplant that ensures satisfaction of a given specification in the presence of the\nenvironment or adversarial actions. We show that the controller synthesis\nproblem is decidable for HyperLTL specifications and finite-state plants. We\nprovide a rigorous complexity analysis for different fragments of HyperLTL and\ndifferent system types: tree-shaped, acyclic, and general graphs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 20:29:07 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Bonakdarpour", "Borzoo", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2101.08939", "submitter": "Kartik Singhal", "authors": "Robert Rand, Aarthi Sundaram, Kartik Singhal, Brad Lackey", "title": "Static Analysis of Quantum Programs via Gottesman Types", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Heisenberg representation of quantum operators provides a powerful\ntechnique for reasoning about quantum circuits, albeit those restricted to the\ncommon (non-universal) Clifford set $H$, $S$ and $CNOT$. The Gottesman-Knill\ntheorem showed that we can use this representation to efficiently simulate\nClifford circuits. We show that Gottesman's semantics for quantum programs can\nbe treated as a type system, allowing us to efficiently characterize a common\nsubset of quantum programs. We apply this primarily towards tracking\nentanglement in programs, showing how superdense coding and GHZ circuits\nentangle and disentangle qubits and how to safely dispose of ancillae. We\ndemonstrate the efficiency of our typechecking algorithm both for simple\ndeductions and those involving entanglement and measurement.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 04:07:12 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Rand", "Robert", ""], ["Sundaram", "Aarthi", ""], ["Singhal", "Kartik", ""], ["Lackey", "Brad", ""]]}, {"id": "2101.09032", "submitter": "Sidi Mohamed Beillahi", "authors": "Sidi Mohamed Beillahi, Ahmed Bouajjani, and Constantin Enea", "title": "Checking Robustness Between Weak Transactional Consistency Models", "comments": "38 pages, 7 figures, 2 tables, extended version of ESOP 2021\n  conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concurrent accesses to databases are typically encapsulated in transactions\nin order to enable isolation from other concurrent computations and resilience\nto failures. Modern databases provide transactions with various semantics\ncorresponding to different trade-offs between consistency and availability.\nSince a weaker consistency model provides better performance, an important\nissue is investigating the weakest level of consistency needed by a given\nprogram (to satisfy its specification). As a way of dealing with this issue, we\ninvestigate the problem of checking whether a given program has the same set of\nbehaviors when replacing a consistency model with a weaker one. This property\nknown as robustness generally implies that any specification of the program is\npreserved when weakening the consistency. We focus on the robustness problem\nfor consistency models which are weaker than standard serializability, namely,\ncausal consistency, prefix consistency, and snapshot isolation. We show that\nchecking robustness between these models is polynomial time reducible to a\nstate reachability problem under serializability. We use this reduction to also\nderive a pragmatic proof technique based on Lipton's reduction theory that\nallows to prove programs robust. We have applied our techniques to several\nchallenging applications drawn from the literature of distributed systems and\ndatabases.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 10:17:42 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Beillahi", "Sidi Mohamed", ""], ["Bouajjani", "Ahmed", ""], ["Enea", "Constantin", ""]]}, {"id": "2101.09038", "submitter": "Bas van den Heuvel", "authors": "Bas van den Heuvel and Jorge A. P\\'erez", "title": "A Decentralized Analysis of Multiparty Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Protocols provide the unifying glue in concurrent and distributed software\ntoday; verifying that message-passing programs conform to such governing\nprotocols is important but difficult. Static approaches based on multiparty\nsession types (MPST) use protocols as types to avoid protocol violations and\ndeadlocks in programs. An elusive problem for MPST is to ensure both protocol\nconformance and deadlock freedom for implementations with interleaved and\ndelegated protocols.\n  We propose a decentralized analysis of multiparty protocols, specified as\nglobal types and implemented as interacting processes in an asynchronous\n$\\pi$-calculus. Our solution rests upon two novel notions: router processes and\nrelative types. While router processes use the global type to enable the\ncomposition of participant implementations in arbitrary process networks,\nrelative types extract from the global type the intended interactions and\ndependencies between pairs of participants. In our analysis, processes are\ntyped using APCP, a type system that ensures protocol conformance and deadlock\nfreedom with respect to binary protocols, developed in prior work. Our\ndecentralized, router-based analysis enables the sound and complete\ntransference of protocol conformance and deadlock freedom from APCP to\nmultiparty protocols.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 10:24:11 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 13:58:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Heuvel", "Bas van den", ""], ["P\u00e9rez", "Jorge A.", ""]]}, {"id": "2101.09042", "submitter": "Marie-Christine Jakobs", "authors": "Marie-Christine Jakobs", "title": "PEQcheck: Localized and Context-aware Checking of Functional Equivalence\n  (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refactorings must not alter the program's functionality. However, not all\nrefactorings fulfill this requirement. Hence, one must explicitly check that a\nrefactoring does not alter the functionality. Since one rarely has a formal\nspecification of the program's behavior, we utilize the original program as\nfunctional specification. Then, we check whether the original and refactored\nprogram are functionally equivalent. To this end, we apply a common idea and\nreduce equivalence checking to program verification. To increase efficiency,\nour equivalence checker PEQcheck constructs one verification task per\nrefactored code segment instead of one per function as typically done by prior\nwork. In addition, PEQcheck considers the context of the code segments. For\ninstance, only variables that are modified and live are required to be\nequivalent and read-only variables may be shared between original and\nrefactored code segments. We show that PEQcheck is sound.Moreover, our\nevaluation testifies that the localized and context-aware checking performed by\n\\peqcheck can indeed be beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 10:29:41 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 21:22:55 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Jakobs", "Marie-Christine", ""]]}, {"id": "2101.09100", "submitter": "Fosco Loregian G.", "authors": "Fabrizio Genovese, Fosco Loregian, Daniele Palombi", "title": "A Categorical Semantics for Bounded Petri Nets", "comments": "15 pages, gluten free. arXiv admin note: text overlap with\n  arXiv:2101.06234", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a categorical semantics for bounded Petri nets, both in the\ncollective- and individual-token philosophy. In both cases, we describe the\nprocess of bounding a net internally, by just constructing new categories of\nexecutions of a net using comonads, and externally, using lax-monoidal-lax\nfunctors. Our external semantics is non-local, meaning that tokens are endowed\nwith properties that say something about the global state of the net. We then\nprove, in both cases, that the internal and external constructions are\nequivalent, by using machinery built on top of the Grothendieck construction.\nThe individual-token case is harder, as it requires a more explicit reliance on\nabstract methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 13:35:05 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 10:30:55 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Genovese", "Fabrizio", ""], ["Loregian", "Fosco", ""], ["Palombi", "Daniele", ""]]}, {"id": "2101.09655", "submitter": "Aaron Stump", "authors": "Aaron Stump, Benjamin Delaware, Christopher Jenkins", "title": "Relational Type Theory (All Proofs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces Relational Type Theory (RelTT), a new approach to type\ntheory with extensionality principles, based on a relational semantics for\ntypes. The type constructs of the theory are those of System F plus relational\ncomposition, converse, and promotion of application of a term to a relation. A\nconcise realizability semantics is presented for these types. The paper shows\nhow a number of constructions of traditional interest in type theory are\npossible in RelTT, including eta-laws for basic types, inductive types with\ntheir induction principles, and positive-recursive types. A crucial role is\nplayed by a lemma called Identity Inclusion, which refines the Identity\nExtension property familiar from the semantics of parametric polymorphism. The\npaper concludes with a type system for RelTT, paving the way for\nimplementation.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 06:25:01 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Stump", "Aaron", ""], ["Delaware", "Benjamin", ""], ["Jenkins", "Christopher", ""]]}, {"id": "2101.10166", "submitter": "William DeMeo", "authors": "William DeMeo", "title": "The Agda Universal Algebra Library and Birkhoff's Theorem in Dependent\n  Type Theory", "comments": "111 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Agda Universal Algebra Library (UALib) is a library of types and programs\n(theorems and proofs) we developed to formalize the foundations of universal\nalgebra in dependent type theory using the Agda programming language and proof\nassistant. This paper describes the UALib and demonstrates that Agda is\naccessible to working mathematicians (such as ourselves) as a tool for formally\nverifying nontrivial results in general algebra and related fields. The library\nincludes a substantial collection of definitions, theorems, and proofs from\nuniversal algebra and equational logic and as such provides many examples that\nexhibit the power of inductive and dependent types for representing and\nreasoning about general algebraic and relational structures.\n  The first major milestone of the UALib project is a complete proof of\nBirkhoff's HSP theorem. To the best of our knowledge, this is the first time\nBirkhoff's theorem has been formulated and proved in dependent type theory and\nverified with a proof assistant.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 15:26:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 23:02:10 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["DeMeo", "William", ""]]}, {"id": "2101.10479", "submitter": "EPTCS", "authors": "Swaraj Dash (University of Oxford), Sam Staton (University of Oxford)", "title": "A Monad for Probabilistic Point Processes", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 19-32", "doi": "10.4204/EPTCS.333.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A point process on a space is a random bag of elements of that space. In this\npaper we explore programming with point processes in a monadic style. To this\nend we identify point processes on a space X with probability measures of bags\nof elements in X. We describe this view of point processes using the\ncomposition of the Giry and bag monads on the category of measurable spaces and\nfunctions and prove that this composition also forms a monad using a\ndistributive law for monads. Finally, we define a morphism from a point process\nto its intensity measure, and show that this is a monad morphism. A special\ncase of this monad morphism gives us Wald's Lemma, an identity used to\ncalculate the expected value of the sum of a random number of random variables.\nUsing our monad we define a range of point processes and point process\noperations and compositionally compute their corresponding intensity measures\nusing the monad morphism.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:01:21 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Dash", "Swaraj", "", "University of Oxford"], ["Staton", "Sam", "", "University of Oxford"]]}, {"id": "2101.10486", "submitter": "EPTCS", "authors": "Lachlan McPheat (University College London), Mehrnoosh Sadrzadeh\n  (University College London), Hadi Wazni (Queen Mary University London), Gijs\n  Wijnholds (Utrecht University)", "title": "Categorical Vector Space Semantics for Lambek Calculus with a Relevant\n  Modality (Extended Abstract)", "comments": "In Proceedings ACT 2020, arXiv:2101.07888. arXiv admin note:\n  substantial text overlap with arXiv:2005.03074", "journal-ref": "EPTCS 333, 2021, pp. 168-182", "doi": "10.4204/EPTCS.333.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a categorical compositional distributional semantics for Lambek\nCalculus with a Relevant Modality, which has a limited version of the\ncontraction and permutation rules. The categorical part of the semantics is a\nmonoidal biclosed category with a coalgebra modality as defined on Differential\nCategories. We instantiate this category to finite dimensional vector spaces\nand linear maps via quantisation functors and work with three concrete\ninterpretations of the coalgebra modality. We apply the model to construct\ncategorical and concrete semantic interpretations for the motivating example of\nthis extended calculus: the derivation of a phrase with a parasitic gap. The\neffectiveness of the concrete interpretations are evaluated via a\ndisambiguation task, on an extension of a sentence disambiguation dataset to\nparasitic gap phrases, using BERT, Word2Vec, and FastText vectors and\nRelational tensors\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:05:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["McPheat", "Lachlan", "", "University College London"], ["Sadrzadeh", "Mehrnoosh", "", "University College London"], ["Wazni", "Hadi", "", "Queen Mary University London"], ["Wijnholds", "Gijs", "", "Utrecht University"]]}, {"id": "2101.10487", "submitter": "EPTCS", "authors": "Tarmo Uustalu, Niccol\\`o Veltri, Noam Zeilberger", "title": "Proof Theory of Partially Normal Skew Monoidal Categories", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 230-246", "doi": "10.4204/EPTCS.333.16", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The skew monoidal categories of Szlach\\'anyi are a weakening of monoidal\ncategories where the three structural laws of left and right unitality and\nassociativity are not required to be isomorphisms but merely transformations in\na particular direction. In previous work, we showed that the free skew monoidal\ncategory on a set of generating objects can be concretely presented as a\nsequent calculus. This calculus enjoys cut elimination and admits focusing,\ni.e. a subsystem of canonical derivations, which solves the coherence problem\nfor skew monoidal categories.\n  In this paper, we develop sequent calculi for partially normal skew monoidal\ncategories, which are skew monoidal categories with one or more structural laws\ninvertible. Each normality condition leads to additional inference rules and\nequations on them. We prove cut elimination and we show that the calculi admit\nfocusing. The result is a family of sequent calculi between those of skew\nmonoidal categories and (fully normal) monoidal categories. On the level of\nderivability, these define 8 weakenings of the (unit,tensor) fragment of\nintuitionistic non-commutative linear logic.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:07:00 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Uustalu", "Tarmo", ""], ["Veltri", "Niccol\u00f2", ""], ["Zeilberger", "Noam", ""]]}, {"id": "2101.10488", "submitter": "EPTCS", "authors": "Paul Wilson (University of Southampton), Fabio Zanasi (University\n  College London)", "title": "Reverse Derivative Ascent: A Categorical Approach to Learning Boolean\n  Circuits", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 247-260", "doi": "10.4204/EPTCS.333.17", "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Reverse Derivative Ascent: a categorical analogue of gradient\nbased methods for machine learning. Our algorithm is defined at the level of\nso-called reverse differential categories. It can be used to learn the\nparameters of models which are expressed as morphisms of such categories. Our\nmotivating example is boolean circuits: we show how our algorithm can be\napplied to such circuits by using the theory of reverse differential\ncategories. Note our methodology allows us to learn the parameters of boolean\ncircuits directly, in contrast to existing binarised neural network approaches.\nMoreover, we demonstrate its empirical value by giving experimental results on\nbenchmark machine learning datasets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:07:20 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wilson", "Paul", "", "University of Southampton"], ["Zanasi", "Fabio", "", "University\n  College London"]]}, {"id": "2101.10490", "submitter": "EPTCS", "authors": "Brendan Fong (MIT), David Jaz Myers (Johns Hopkins), David I. Spivak\n  (MIT)", "title": "Behavioral Mereology: A Modal Logic for Passing Constraints", "comments": "In Proceedings ACT 2020, arXiv:2101.07888. arXiv admin note:\n  substantial text overlap with arXiv:1811.00420", "journal-ref": "EPTCS 333, 2021, pp. 276-288", "doi": "10.4204/EPTCS.333.19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mereology is the study of parts and the relationships that hold between them.\nWe introduce a behavioral approach to mereology, in which systems and their\nparts are known only by the types of behavior they can exhibit. Our discussion\nis formally topos-theoretic, and agnostic to the topos, providing maximal\ngenerality; however, by using only its internal logic we can hide the details\nand readers may assume a completely elementary set-theoretic discussion. We\nconsider the relationship between various parts of a whole in terms of how\nbehavioral constraints are passed between them, and give an inter-modal logic\nthat generalizes the usual alethic modalities in the setting of symmetric\naccessibility.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:08:26 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Fong", "Brendan", "", "MIT"], ["Myers", "David Jaz", "", "Johns Hopkins"], ["Spivak", "David I.", "", "MIT"]]}, {"id": "2101.10493", "submitter": "EPTCS", "authors": "Luigi Santocanale", "title": "Dualizing sup-preserving endomaps of a complete lattice", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 335-346", "doi": "10.4204/EPTCS.333.23", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is argued in (Eklund et al., 2018) that the quantale [L,L] of\nsup-preserving endomaps of a complete lattice L is a Girard quantale exactly\nwhen L is completely distributive. We have argued in (Santocanale, 2020) that\nthis Girard quantale structure arises from the dual quantale of inf-preserving\nendomaps of L via Raney's transforms and extends to a Girard quantaloid\nstructure on the full subcategory of SLatt (the category of complete lattices\nand sup-preserving maps) whose objects are the completely distributive\nlattices.\n  It is the goal of this talk to illustrate further this connection between the\nquantale structure, Raney's transforms, and complete distributivity. Raney's\ntransforms are indeed mix maps in the isomix category SLatt and most of the\ntheory can be developed relying on naturality of these maps. We complete then\nthe remarks on cyclic elements of [L,L] developed in (Santocanale, 2020) by\ninvestigating its dualizing elements. We argue that if [L,L] has the structure\na Frobenius quantale, that is, if it has a dualizing element, not necessarily a\ncyclic one, then L is once more completely distributive. It follows then from a\ngeneral statement on involutive residuated lattices that there is a bijection\nbetween dualizing elements of [L,L] and automorphisms of L. Finally, we also\nargue that if L is finite and [L,L] is autodual, then L is distributive.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:09:57 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Santocanale", "Luigi", ""]]}, {"id": "2101.10494", "submitter": "EPTCS", "authors": "Richard Statman (Carnegie Mellon University)", "title": "Products in a Category with Only One Object", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 347-353", "doi": "10.4204/EPTCS.333.24", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider certain decision problems for the free model of the theory of\nCartesian monoids. We introduce a model of computation based on the notion of a\nsingle stack one-way PDA due to Ginsburg, Greibach and Harrison. This model\nallows us to solve problems such as\n  (1) Given a finite set B of elements and an element F, is F a product of\nmembers of B?\n  (2) Is the submonoid generated by the finite set B infinite?\n  for certain fragments of the free Cartesian monoid. These fragments include\nthe submonoid of right invertible elements and so our results apply to the\nThompson-Higman groups.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:10:18 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Statman", "Richard", "", "Carnegie Mellon University"]]}, {"id": "2101.10720", "submitter": "Harold Pancho Gordon Eliott", "authors": "Harold Pancho Eliott and Martin Berger", "title": "A program logic for fresh name generation", "comments": "15 core pages accepted for publication in FSEN 2021, +60 pages of\n  proofs included in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a program logic for Pitts and Stark's {\\nu}-calculus, an extension\nof the call-by-value simply-typed {\\lambda}-calculus with a mechanism for the\ngeneration of fresh names. Names can be compared for (in)-equality, producing\nprograms with subtle observable properties. Hidden names produced by\ninteractions between generation and abstraction are captured logically with a\nsecond-order quantifier over type contexts. We illustrate usage of the logic\nthrough reasoning about well-known difficult cases from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 11:27:42 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 21:51:18 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Eliott", "Harold Pancho", ""], ["Berger", "Martin", ""]]}, {"id": "2101.10907", "submitter": "Stephen Wolfram", "authors": "Stephen Wolfram", "title": "Exploring Rulial Space: The Case of Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As an example of the concept of rulial space, we explore the case of simple\nTuring machines. We construct the rulial multiway graph which represents the\nbehavior of all possible Turing machines with a certain class of rules. This\ngraph (which is a Cayley graph of a \"Turing machine group\") gives a map of the\nspace of non-deterministic Turing machines. We investigate the subgraph formed\nby deterministic machines, and explore the relationship to the P vs. NP\nproblem. We also consider the implications of features of rulial space for\nphysics, including estimating the maximum speed \\r{ho} in rulial space,\nrelations between rulial black holes and computational reducibility, and\ninterpretations of hypercomputation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:10:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wolfram", "Stephen", ""]]}, {"id": "2101.11320", "submitter": "Boro Sitnikovski", "authors": "Boro Sitnikovski", "title": "Tutorial on implementing Hoare logic for imperative programs in Haskell", "comments": "Added sample implementation for H-Consequence, H-While, and another\n  example; Added CoI section, tweaks to labels for 'boptimize'; Improved Hoare\n  logic implementation by relying on actual Propositional calculus and Number\n  theory systems, rather than toy optimization functions; improve formula\n  printer; small tweak updates. Associated files are available at\n  https://github.com/bor0/hoare-imp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the programming language Haskell, we introduce an implementation of\npropositional calculus, number theory, and a simple imperative language that\ncan evaluate arithmetic and boolean expressions. Finally, we provide an\nimplementation of Hoare's logic which will allow us to deduce facts about\nprograms without the need for a full evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 11:14:37 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 15:50:23 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 23:14:03 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 10:34:11 GMT"}, {"version": "v5", "created": "Wed, 28 Apr 2021 20:42:29 GMT"}, {"version": "v6", "created": "Tue, 4 May 2021 18:19:11 GMT"}, {"version": "v7", "created": "Tue, 11 May 2021 06:50:03 GMT"}, {"version": "v8", "created": "Wed, 2 Jun 2021 10:36:34 GMT"}, {"version": "v9", "created": "Sun, 6 Jun 2021 20:19:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sitnikovski", "Boro", ""]]}, {"id": "2101.11351", "submitter": "Dario Stein", "authors": "Dario Stein, Sam Staton", "title": "Compositional Semantics for Probabilistic Programs with Exact\n  Conditioning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO math.CT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a probabilistic programming language for Gaussian random variables\nwith a first-class exact conditioning construct. We give operational,\ndenotational and equational semantics for this language, establishing\nconvenient properties like exchangeability of conditions. Conditioning on\nequality of continuous random variables is nontrivial, as the exact observation\nmay have probability zero; this is Borel's paradox. Using categorical\nformulations of conditional probability, we show that the good properties of\nour language are not particular to Gaussians, but can be derived from universal\nproperties, thus generalizing to wider settings. We define the Cond\nconstruction, which internalizes conditioning as a morphism, providing general\ncompositional semantics for probabilistic programming with exact conditioning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 12:31:18 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Stein", "Dario", ""], ["Staton", "Sam", ""]]}, {"id": "2101.11479", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling and Carlo Angiuli", "title": "Normalization for Cubical Type Theory", "comments": "LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove normalization for (univalent, Cartesian) cubical type theory,\nclosing the last major open problem in the syntactic metatheory of cubical type\ntheory. Our normalization result is reduction-free, in the sense of yielding a\nbijection between equivalence classes of terms in context and a tractable\nlanguage of $\\beta/\\eta$-normal forms. As corollaries we obtain both\ndecidability of judgmental equality and the injectivity of type constructors.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 15:14:07 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 23:27:00 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Sterling", "Jonathan", ""], ["Angiuli", "Carlo", ""]]}, {"id": "2101.11686", "submitter": "Tejas Bhojraj", "authors": "Tejas Bhojraj", "title": "Prefix-free quantum Kolmogorov complexity", "comments": "21 pages. This has been submitted to a journal", "journal-ref": null, "doi": "10.1016/j.tcs.2021.05.017", "report-no": "Theoretical Computer Science, Volume 875, 2021, Pages 65-80, ISSN\n  0304-3975,", "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce quantum-K ($QK$), a measure of the descriptive complexity of\ndensity matrices using classical prefix-free Turing machines and show that the\ninitial segments of weak Solovay random and quantum Schnorr random states are\nincompressible in the sense of $QK$. Many properties enjoyed by prefix-free\nKolmogorov complexity ($K$) have analogous versions for $QK$; notably a\ncounting condition.\n  Several connections between Solovay randomness and $K$, including the Chaitin\ntype characterization of Solovay randomness, carry over to those between weak\nSolovay randomness and $QK$. We work towards a Levin-Schnorr type\ncharacterization of weak Solovay randomness in terms of $QK$.\n  Schnorr randomness has a Levin-Schnorr characterization using $K_C$; a\nversion of $K$ using a computable measure machine, $C$. We similarly define\n$QK_C$, a version of $QK$. Quantum Schnorr randomness is shown to have a\nLevin-Schnorr and a Chaitin type characterization using $QK_C$. The latter\nimplies a Chaitin type characterization of classical Schnorr randomness using\n$K_C$.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 21:03:04 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bhojraj", "Tejas", ""]]}, {"id": "2101.11707", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Sarat Varanasi, Farhad Shakerin, Joaquin Arias, Gopal\n  Gupta", "title": "Knowledge-driven Natural Language Understanding of English Text and its\n  Applications", "comments": "Preprint. Accepted by the 35th AAAI Conference (AAAI-21) Main Tracks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of a text is a fundamental challenge of natural\nlanguage understanding (NLU) research. An ideal NLU system should process a\nlanguage in a way that is not exclusive to a single task or a dataset. Keeping\nthis in mind, we have introduced a novel knowledge driven semantic\nrepresentation approach for English text. By leveraging the VerbNet lexicon, we\nare able to map syntax tree of the text to its commonsense meaning represented\nusing basic knowledge primitives. The general purpose knowledge represented\nfrom our approach can be used to build any reasoning based NLU system that can\nalso provide justification. We applied this approach to construct two NLU\napplications that we present here: SQuARE (Semantic-based Question Answering\nand Reasoning Engine) and StaCACK (Stateful Conversational Agent using\nCommonsense Knowledge). Both these systems work by \"truly understanding\" the\nnatural language text they process and both provide natural language\nexplanations for their responses while maintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:02:50 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Basu", "Kinjal", ""], ["Varanasi", "Sarat", ""], ["Shakerin", "Farhad", ""], ["Arias", "Joaquin", ""], ["Gupta", "Gopal", ""]]}, {"id": "2101.11727", "submitter": "Cristina Feier", "authors": "Cristina Feier", "title": "Characterising Fixed Parameter Tractability of Query Evaluation over\n  Guarded TGDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of evaluating Ontology Mediated Queries\n(OMQs) based on Guarded TGDs (GTGDs) and Unions of Conjunctive Queries (UCQs),\nin the case where relational symbols have unrestricted arity and where the\nparameter is the size of the OMQ. We establish exact criteria for\nfixed-parameter tractability (fpt) evaluation of recursively enumerable classes\nof such OMQs (under the widely held Exponential Time Hypothesis). One of the\nmain technical tools introduced in the paper is an fpt-reduction from deciding\nparameterized uniform CSPs to parameterized OMQ evaluation. The reduction\npreserves measures which are known to be essential for classifying recursively\nenumerable classes of parameterized uniform CSPs: submodular width (according\nto the well known result of Marx for unrestricted-arity schemas) and treewidth\n(according to the well known result of Grohe for bounded-arity schemas). As\nsuch, it can be employed to obtain hardness results for evaluation of\nrecursively enumerable classes of parameterized OMQs both in the unrestricted\nand in the bounded arity case. Previously, in the case of bounded arity\nschemas, this has been tackled using a technique requiring full introspection\ninto the construction employed by Grohe.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:32:16 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:08:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feier", "Cristina", ""]]}, {"id": "2101.11730", "submitter": "David Naumann", "authors": "Ramana Nagasamudram and David A. Naumann", "title": "Alignment Completeness for Relational Hoare Logics", "comments": "Minor revision of original. To appear in LICS 2021 but this version\n  has appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Hoare logics (RHL) provide rules for reasoning about relations\nbetween programs. Several RHLs include a rule we call sequential product that\ninfers a relational correctness judgment from judgments of ordinary Hoare logic\n(HL). Other rules embody sensible patterns of reasoning and have been found\nuseful in practice, but sequential product is relatively complete on its own\n(with HL). As a more satisfactory way to evaluate RHLs, a notion of alignment\ncompleteness is introduced, in terms of the inductive assertion method and\nproduct automata. Alignment completeness results are given to account for\nseveral different sets of rules. The notion may serve to guide the design of\nRHLs and relational verifiers for richer programming languages and alignment\npatterns.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:36:28 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 03:07:22 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Nagasamudram", "Ramana", ""], ["Naumann", "David A.", ""]]}, {"id": "2101.11849", "submitter": "Cameron Freer", "authors": "Nathanael Ackerman, Cameron Freer, Rehana Patel", "title": "On computable aspects of algebraic and definable closure", "comments": "20 pages", "journal-ref": "Journal of Logic and Computation 31, no. 1 (2021), pp. 2-19", "doi": "10.1093/logcom/exaa070", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computability of algebraic closure and definable closure\nwith respect to a collection of formulas. We show that for a computable\ncollection of formulas of quantifier rank at most $n$, in any given computable\nstructure, both algebraic and definable closure with respect to that collection\nare $\\Sigma^0_{n+2}$ sets. We further show that these bounds are tight.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 07:39:59 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Ackerman", "Nathanael", ""], ["Freer", "Cameron", ""], ["Patel", "Rehana", ""]]}, {"id": "2101.11996", "submitter": "Guillermo P\\'erez", "authors": "Michael Blondin, Tim Leys, Filip Mazowiecki, Philip Offtermatt, and\n  Guillermo A. P\\'erez", "title": "Continuous One-Counter Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reachability problem for continuous one-counter automata, COCA\nfor short. In such automata, transitions are guarded by upper and lower bound\ntests against the counter value. Additionally, the counter updates associated\nwith taking transitions can be (non-deterministically) scaled down by a nonzero\nfactor between zero and one. Our three main results are as follows: (1) We\nprove that the reachability problem for COCA with global upper and lower bound\ntests is in NC2; (2) that, in general, the problem is decidable in polynomial\ntime; and (3) that it is decidable in the polynomial hierarchy for COCA with\nparametric counter updates and bound tests.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 13:45:56 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 07:36:55 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Blondin", "Michael", ""], ["Leys", "Tim", ""], ["Mazowiecki", "Filip", ""], ["Offtermatt", "Philip", ""], ["P\u00e9rez", "Guillermo A.", ""]]}, {"id": "2101.12029", "submitter": "Georg Moser", "authors": "Martin Hofmann, Lorenz Leutgeb, Georg Moser, David Obwaller, Florian\n  Zuleger", "title": "Type-Based Analysis of Logarithmic Amortised Complexity", "comments": "35 pages. arXiv admin note: text overlap with arXiv:1807.08242", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel amortised resource analysis couched in a type-and-effect\nsystem. Our analysis is formulated in terms of the physicist's method of\namortised analysis, and is potential-based. The type system makes use of\nlogarithmic potential functions and is the first such system to exhibit\n*logarithmic amortised complexity*. With our approach we target the automated\nanalysis of self-adjusting data structures, like splay trees, which so far have\nonly manually been analysed in the literature. In particular, we have\nimplemented a semi-automated prototype, which successfully analyses the zig-zig\ncase of *splaying*, once the type annotations are fixed.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 14:47:45 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 17:45:07 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hofmann", "Martin", ""], ["Leutgeb", "Lorenz", ""], ["Moser", "Georg", ""], ["Obwaller", "David", ""], ["Zuleger", "Florian", ""]]}, {"id": "2101.12045", "submitter": "EPTCS", "authors": "Robert Atkey, Bruno Gavranovi\\'c, Neil Ghani, Clemens Kupke,\n  J\\'er\\'emy Ledent, Fredrik Nordvall Forsberg", "title": "Compositional Game Theory, Compositionally", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 198-214", "doi": "10.4204/EPTCS.333.14", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new compositional approach to compositional game theory (CGT)\nbased upon Arrows, a concept originally from functional programming, closely\nrelated to Tambara modules, and operators to build new Arrows from old. We\nmodel equilibria as a bimodule over an Arrow and define an operator to build a\nnew Arrow from such a bimodule over an existing Arrow. We also model strategies\nas graded Arrows and define an operator which builds a new Arrow by taking the\ncolimit of a graded Arrow. A final operator builds a graded Arrow from a graded\nbimodule. We use this compositional approach to CGT to show how known and\npreviously unknown variants of open games can be proven to form symmetric\nmonoidal categories.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:06:15 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Atkey", "Robert", ""], ["Gavranovi\u0107", "Bruno", ""], ["Ghani", "Neil", ""], ["Kupke", "Clemens", ""], ["Ledent", "J\u00e9r\u00e9my", ""], ["Forsberg", "Fredrik Nordvall", ""]]}, {"id": "2101.12046", "submitter": "EPTCS", "authors": "Evan Patterson (Stanford University), David I. Spivak (MIT), Dmitry\n  Vagner", "title": "Wiring diagrams as normal forms for computing in symmetric monoidal\n  categories", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 49-64", "doi": "10.4204/EPTCS.333.4", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of category theory often involve symmetric monoidal categories\n(SMCs), in which abstract processes or operations can be composed in series and\nparallel. However, in 2020 there remains a dearth of computational tools for\nworking with SMCs. We present an \"unbiased\" approach to implementing symmetric\nmonoidal categories, based on an operad of directed, acyclic wiring diagrams.\nBecause the interchange law and other laws of a SMC hold identically in a\nwiring diagram, no rewrite rules are needed to compare diagrams. We discuss the\nmathematics of the operad of wiring diagrams, as well as its implementation in\nthe software package Catlab.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:02:11 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Patterson", "Evan", "", "Stanford University"], ["Spivak", "David I.", "", "MIT"], ["Vagner", "Dmitry", ""]]}, {"id": "2101.12123", "submitter": "Shankara Narayanan Krishna", "authors": "Adwait Godbole, Shankara Narayanan Krishna, Roland Meyer", "title": "Safety Verification of Parameterized Systems under Release-Acquire", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the safety verification problem for parameterized systems under the\nrelease-acquire (RA) semantics. It has been shown that the problem is\nintractable for systems with unlimited access to atomic compare-and-swap (CAS)\ninstructions. We show that, from a verification perspective where approximate\nresults help, this is overly pessimistic. We study parameterized systems\nconsisting of an unbounded number of environment threads executing identical\nbut CAS-free programs and a fixed number of distinguished threads that are\nunrestricted.\n  Our first contribution is a new semantics that considerably simplifies RA but\nis still equivalent for the above systems as far as safety verification is\nconcerned. We apply this (general) result to two subclasses of our model. We\nshow that safety verification is only \\pspace-complete for the bounded model\nchecking problem where the distinguished threads are loop-free. Interestingly,\nwe can still afford the unbounded environment. We show that the complexity\njumps to \\nexp-complete for thread-modular verification where an unrestricted\ndistinguished `ego' thread interacts with an environment of CAS-free threads\nplus loop-free distinguished threads (as in the earlier setting). Besides the\nusefulness for verification, the results are strong in that they delineate the\ntractability border for an established semantics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 17:13:14 GMT"}], "update_date": "2021-02-13", "authors_parsed": [["Godbole", "Adwait", ""], ["Krishna", "Shankara Narayanan", ""], ["Meyer", "Roland", ""]]}, {"id": "2101.12271", "submitter": "Anton Golov", "authors": "Anton Golov, Sebastiaan A. Terwijn", "title": "Fixpoints and relative precompleteness", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study relative precompleteness in the context of the theory of numberings,\nand relate this to a notion of lowness. We introduce a notion of divisibility\nfor numberings, and use it to show that for the class of divisible numberings,\nlowness and relative precompleteness coincide with being computable.\n  We also study the complexity of Skolem functions arising from Arslanov's\ncompleteness criterion with parameters. We show that for suitably divisible\nnumberings, these Skolem functions have the maximal possible Turing degree. In\nparticular this holds for the standard numberings of the partial computable\nfunctions and the c.e. sets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 20:54:11 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Golov", "Anton", ""], ["Terwijn", "Sebastiaan A.", ""]]}, {"id": "2101.12349", "submitter": "Linh Anh Nguyen D.Sc.", "authors": "Linh Anh Nguyen", "title": "Logical Characterizations of Fuzzy Bisimulations in Fuzzy Modal Logics\n  over Residuated Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two kinds of bisimulation, namely crisp and fuzzy, between fuzzy\nstructures such as fuzzy automata, fuzzy labeled transition systems, fuzzy\nKripke models and fuzzy interpretations in description logics. Fuzzy\nbisimulations between fuzzy automata over a complete residuated lattice have\nbeen introduced by \\'Ciri\\'c et al. in 2012. Logical characterizations of fuzzy\nbisimulations between fuzzy Kripke models (respectively, fuzzy interpretations\nin description logics) over the residuated lattice [0,1] with the G\\\"odel\nt-norm have been provided by Fan in 2015 (respectively, Nguyen et al. in 2020).\nThere was the lack of logical characterizations of fuzzy bisimulations between\nfuzzy graph-based structures over a general residuated lattice, as well as over\nthe residuated lattice [0,1] with the {\\L}ukasiewicz or product t-norm. In this\narticle, we provide and prove logical characterizations of fuzzy bisimulations\nin fuzzy modal logics over residuated lattices. The considered logics are the\nfuzzy propositional dynamic logic and its fragments. Our logical\ncharacterizations concern invariance of formulas under fuzzy bisimulations and\nthe Hennessy-Milner property of fuzzy bisimulations. They can be reformulated\nfor other fuzzy structures such as fuzzy label transition systems and fuzzy\ninterpretations in description logics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 01:39:36 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 09:10:33 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Nguyen", "Linh Anh", ""]]}, {"id": "2101.12607", "submitter": "Daisuke Kimura", "authors": "Tatsuya Abe and Daisuke Kimura", "title": "A Symmetric Lambda-Calculus Corresponding to the Negation-Free Bilateral\n  Natural Deduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Filinski constructed a symmetric lambda-calculus consisting of expressions\nand continuations which are symmetric, and functions which have duality. In his\ncalculus, functions can be encoded to expressions and continuations using\nprimitive operators. That is, the duality of functions is not derived in the\ncalculus but adopted as a principle of the calculus. In this paper, we propose\na simple symmetric lambda-calculus corresponding to the negation-free natural\ndeduction based bilateralism in proof-theoretic semantics. In our calculus,\ncontinuation types are represented as not negations of formulae but formulae\nwith negative polarity. Function types are represented as the implication and\nbut-not connectives in intuitionistic and paraconsistent logics, respectively.\nOur calculus is not only simple but also powerful as it includes a call-value\ncalculus corresponding to the call-by-value dual calculus invented by Wadler.\nWe show that mutual transformations between expressions and continuations are\ndefinable in our calculus to justify the duality of functions. We also show\nthat every typable function has dual types. Thus, the duality of function is\nderived from bilateralism.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 14:39:29 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Abe", "Tatsuya", ""], ["Kimura", "Daisuke", ""]]}, {"id": "2101.12683", "submitter": "Roman Andriushchenko", "authors": "Roman Andriushchenko, Milan Ceska, Sebastian Junges, Joost-Pieter\n  Katoen", "title": "Inductive Synthesis for Probabilistic Programs Reaches New Horizons", "comments": "Full version of TACAS'21 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel method for the automated synthesis of\nprobabilistic programs. The starting point is a program sketch representing a\nfinite family of finite-state Markov chains with related but distinct\ntopologies, and a PCTL specification. The method builds on a novel inductive\noracle that greedily generates counter-examples (CEs) for violating programs\nand uses them to prune the family. These CEs leverage the semantics of the\nfamily in the form of bounds on its best- and worst-case behaviour provided by\na deductive oracle using an MDP abstraction. The method further monitors the\nperformance of the synthesis and adaptively switches between the inductive and\ndeductive reasoning. Our experiments demonstrate that the novel CE construction\nprovides a significantly faster and more effective pruning strategy leading to\nacceleration of the synthesis process on a wide range of benchmarks. For\nchallenging problems, such as the synthesis of decentralized\npartially-observable controllers, we reduce the run-time from a day to minutes.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 16:59:00 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Andriushchenko", "Roman", ""], ["Ceska", "Milan", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2101.12733", "submitter": "Wei-Lin Wu", "authors": "Albert Atserias, Phokion G. Kolaitis, Wei-Lin Wu", "title": "On the Expressive Power of Homomorphism Counts", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical result by Lov\\'asz asserts that two graphs $G$ and $H$ are\nisomorphic if and only if they have the same left profile, that is, for every\ngraph $F$, the number of homomorphisms from $F$ to $G$ coincides with the\nnumber of homomorphisms from $F$ to $H$. Dvor{\\'{a}}k and later on Dell, Grohe,\nand Rattan showed that restrictions of the left profile to a class of graphs\ncan capture several different relaxations of isomorphism, including equivalence\nin counting logics with a fixed number of variables (which contains fractional\nisomorphism as a special case) and co-spectrality (i.e., two graphs having the\nsame characteristic polynomial). On the other side, a result by Chaudhuri and\nVardi asserts that isomorphism is also captured by the right profile, that is,\ntwo graphs $G$ and $H$ are isomorphic if and only if for every graph $F$, the\nnumber of homomorphisms from $G$ to $F$ coincides with the number of\nhomomorphisms from $H$ to $F$. In this paper, we embark on a study of the\nrestrictions of the right profile by investigating relaxations of isomorphism\nthat can or cannot be captured by restricting the right profile to a fixed\nclass of graphs. Our results unveil striking differences between the expressive\npower of the left profile and the right profile. We show that fractional\nisomorphism, equivalence in counting logics with a fixed number of variables,\nand co-spectrality cannot be captured by restricting the right profile to a\nclass of graphs. In the opposite direction, we show that chromatic equivalence\ncannot be captured by restricting the left profile to a class of graphs, while,\nclearly, it can be captured by restricting the right profile to the class of\nall cliques.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 18:45:23 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 19:49:06 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Atserias", "Albert", ""], ["Kolaitis", "Phokion G.", ""], ["Wu", "Wei-Lin", ""]]}]