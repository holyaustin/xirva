[{"id": "1704.00249", "submitter": "Danny Nguyen", "authors": "Danny Nguyen and Igor Pak", "title": "Complexity of short Presburger arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study complexity of short sentences in Presburger arithmetic (Short-PA).\nHere by \"short\" we mean sentences with a bounded number of variables,\nquantifiers, inequalities and Boolean operations; the input consists only of\nthe integers involved in the inequalities. We prove that assuming Kannan's\npartition can be found in polynomial time, the satisfiability of Short-PA\nsentences can be decided in polynomial time. Furthermore, under the same\nassumption, we show that the numbers of satisfying assignments of short\nPresburger sentences can also be computed in polynomial time.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 03:22:40 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 02:04:27 GMT"}, {"version": "v3", "created": "Fri, 28 Apr 2017 23:33:21 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Nguyen", "Danny", ""], ["Pak", "Igor", ""]]}, {"id": "1704.00272", "submitter": "J\\\"urgen Koslowski", "authors": "Steffen van Bakel, Franco Barbanera and Ugo de'Liguoro", "title": "Intersection Types for the lambda-mu Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  10, 2018) lmcs:4194", "doi": "10.23638/LMCS-14(1:2)2018", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an intersection type system for the lambda-mu calculus that is\ninvariant under subject reduction and expansion. The system is obtained by\ndescribing Streicher and Reus's denotational model of continuations in the\ncategory of omega-algebraic lattices via Abramsky's domain-logic approach. This\nprovides at the same time an interpretation of the type system and a proof of\nthe completeness of the system with respect to the continuation models by means\nof a filter model construction. We then define a restriction of our system,\nsuch that a lambda-mu term is typeable if and only if it is strongly\nnormalising. We also show that Parigot's typing of lambda-mu terms with\nclassically valid propositional formulas can be translated into the restricted\nsystem, which then provides an alternative proof of strong normalisability for\nthe typed lambda-mu calculus.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 09:05:56 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 15:38:52 GMT"}, {"version": "v3", "created": "Tue, 9 Jan 2018 09:57:07 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["van Bakel", "Steffen", ""], ["Barbanera", "Franco", ""], ["de'Liguoro", "Ugo", ""]]}, {"id": "1704.00617", "submitter": "James Cheney", "authors": "James Cheney and Alberto Momigliano", "title": "$\\alpha$Check: A mechanized metatheory model-checker", "comments": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming, 17(3), 311-352 (2017)", "doi": "10.1017/S1471068417000035", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of mechanically formalizing and proving metatheoretic properties\nof programming language calculi, type systems, operational semantics, and\nrelated formal systems has received considerable attention recently. However,\nthe dual problem of searching for errors in such formalizations has attracted\ncomparatively little attention. In this article, we present $\\alpha$Check, a\nbounded model-checker for metatheoretic properties of formal systems specified\nusing nominal logic. In contrast to the current state of the art for metatheory\nverification, our approach is fully automatic, does not require expertise in\ntheorem proving on the part of the user, and produces counterexamples in the\ncase that a flaw is detected. We present two implementations of this technique,\none based on negation-as-failure and one based on negation elimination, along\nwith experimental results showing that these techniques are fast enough to be\nused interactively to debug systems as they are developed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 14:31:24 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Cheney", "James", ""], ["Momigliano", "Alberto", ""]]}, {"id": "1704.00869", "submitter": "Zhuoqun Yang", "authors": "Zhuoqun Yang, Zhi Jin, Zhi Li", "title": "Achieving Adaptation for Adaptive Systems via Runtime Verification: A\n  Model-Driven Approach", "comments": "CHN extension of this article has been accepted and online published\n  by Journal of Software. Keywords: Self-adaptive software, model-driven\n  approach, non-functional requirements, verification, probabilistic model\n  checking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-adaptive systems (SASs) are capable of adjusting its behavior in\nresponse to meaningful changes in the operational con-text and itself. The\nadaptation needs to be performed automatically through self-managed reactions\nand decision-making processes at runtime. To support this kind of automatic\nbehavior, SASs must be endowed by a rich runtime support that can detect\nrequirements violations and reason about adaptation decisions. Requirements\nEngineering for SASs primarily aims to model adaptation logic and mechanisms.\nRequirements models will guide the design decisions and runtime behaviors of\nsys-tem-to-be. This paper proposes a model-driven approach for achieving\nadaptation against non-functional requirements (NFRs), i.e. reliability and\nperformances. The approach begins with the models in RE stage and provides\nruntime support for self-adaptation. We capture adaptation mechanisms as\ngraphical elements in the goal model. By assigning reliability and performance\nattributes to related system tasks, we derive the tagged sequential diagram for\nspecifying the reliability and performances of system behaviors. To formalize\nsystem behavior, we transform the requirements model to the corresponding\nbehavior model, expressed by Label Transition Systems (LTS). To analyze the\nreliability requirements and performance requirements, we merged the sequential\ndiagram and LTS to a variable Discrete-Time Markov Chains (DTMC) and a variable\nContinuous-Time Markov Chains (CTMC) respectively. Adaptation candidates are\ncharacterized by the variable states. The optimal decision is derived by\nverifying the concerned NFRs and reducing the decision space. Our approach is\nimplemented through the demonstration of a mobile information system.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 04:30:20 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Yang", "Zhuoqun", ""], ["Jin", "Zhi", ""], ["Li", "Zhi", ""]]}, {"id": "1704.01071", "submitter": "Mikolas Janota", "authors": "Mikol\\'a\\v{s} Janota", "title": "An Achilles' Heel of Term-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Term-resolution provides an elegant mechanism to prove that a quantified\nBoolean formula (QBF) is true. It is a dual to Q-resolution (also referred to\nas clause-resolution) and is practically highly important as it enables\ncertifying answers of DPLL-based QBF solvers. While term-resolution and\nQ-resolution are very similar, they're not completely symmetric. In particular,\nQ-resolution operates on clauses and term-resolution operates on models of the\nmatrix. This paper investigates what impact this asymmetry has. We'll see that\nthere is a large class of formulas (formulas with \"big models\") whose\nterm-resolution proofs are exponential. As a possible remedy, the paper\nsuggests to prove true QBFs by refuting their negation ({\\em negate-refute}),\nrather than proving them by term-resolution. The paper shows that from the\ntheoretical perspective this is indeed a favorable approach. In particular,\nnegation-refutation can p-simulates term-resolution and there is an exponential\nseparation between the two calculi. These observations further our\nunderstanding of proof systems for QBFs and provide a strong theoretical\nunderpinning for the effort towards non-CNF QBF solvers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 15:41:14 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Janota", "Mikol\u00e1\u0161", ""]]}, {"id": "1704.01286", "submitter": "Thomas Zeume", "authors": "Thomas Zeume and Thomas Schwentick", "title": "Dynamic Conjunctive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article investigates classes of queries maintainable by conjunctive\nqueries (CQs) and their extensions and restrictions in the dynamic complexity\nframework of Patnaik and Immerman. Starting from the basic language of\nquantifier-free conjunctions of positive atoms, it studies the impact of\nadditional operators and features - such as union, atomic negation and\nquantification - on the dynamic expressiveness, for the standard semantics as\nwell as for Delta-semantics.\n  Although many different combinations of these features are possible, they\nbasically yield five important fragments for the standard semantics,\ncharacterized by the addition of (1) arbitrary quantification and atomic\nnegation, (2) existential quantification and atomic negation, (3) existential\nquantification, (4) atomic negation (but no quantification), and by (5) no\naddition to the basic language at all. While fragments (3), (4) and (5) can be\nseparated, it remains open whether fragments (1), (2) and (3) are actually\ndifferent. The fragments arising from Delta-semantics are also subsumed by the\nstandard fragments (1), (2) and (4). The main fragments of DynFO that had been\nstudied in previous work, DynQF and DynProp, characterized by quantifier-free\nupdate programs with or without auxiliary functions, respectively, also fit\ninto this hierarchy: DynProp coincides with fragment (4) and DynQF is strictly\nabove fragment (4) and within fragment (3).\n  As a further result, all (statically) FO-definable queries are captured by\nfragment (2) and a complete characterization of these queries in terms of\nnon-recursive dynamic programs with existential update formulas with one\nexistential quantifier is given.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 06:59:15 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Zeume", "Thomas", ""], ["Schwentick", "Thomas", ""]]}, {"id": "1704.01494", "submitter": "Damir Dzhafarov", "authors": "Damir Dzhafarov", "title": "Joins in the strong Weihrauch degrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weihrauch degrees and strong Weihrauch degrees are partially ordered\nstructures representing degrees of unsolvability of various mathematical\nproblems. Their study has been widely applied in computable analysis,\ncomplexity theory, and more recently, also in computable combinatorics. We\nanswer an open question about the algebraic structure of the strong Weihrauch\ndegrees, by exhibiting a join operation that turns these degrees into a\nlattice. Previously, the strong Weihrauch degrees were only known to form a\nlower semi-lattice. We then show that unlike the Weihrauch degrees, which are\nknown to form a distributive lattice, the lattice of strong Weihrauch degrees\nis not distributive. Therefore, the two structures are not isomorphic.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 15:38:53 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Dzhafarov", "Damir", ""]]}, {"id": "1704.01736", "submitter": "Albert Atserias", "authors": "Albert Atserias, Phokion G. Kolaitis and Simone Severini", "title": "Generalized Satisfiability Problems via Operator Assignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schaefer introduced a framework for generalized satisfiability problems on\nthe Boolean domain and characterized the computational complexity of such\nproblems. We investigate an algebraization of Schaefer's framework in which the\nFourier transform is used to represent constraints by multilinear polynomials\nin a unique way. The polynomial representation of constraints gives rise to a\nrelaxation of the notion of satisfiability in which the values to variables are\nlinear operators on some Hilbert space. For the case of constraints given by a\nsystem of linear equations over the two-element field, this relaxation has\nreceived considerable attention in the foundations of quantum mechanics, where\nsuch constructions as the Mermin-Peres magic square show that there are systems\nthat have no solutions in the Boolean domain, but have solutions via operator\nassignments on some finite-dimensional Hilbert space. We obtain a complete\ncharacterization of the classes of Boolean relations for which there is a gap\nbetween satisfiability in the Boolean domain and the relaxation of\nsatisfiability via operator assignments. To establish our main result, we adapt\nthe notion of primitive-positive definability (pp-definability) to our setting,\na notion that has been used extensively in the study of constraint satisfaction\nproblems. Here, we show that pp-definability gives rise to gadget reductions\nthat preserve satisfiability gaps. We also present several additional\napplications of this method. In particular and perhaps surprisingly, we show\nthat the relaxed notion of pp-definability in which the quantified variables\nare allowed to range over operator assignments gives no additional expressive\npower in defining Boolean relations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 07:52:15 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Atserias", "Albert", ""], ["Kolaitis", "Phokion G.", ""], ["Severini", "Simone", ""]]}, {"id": "1704.01814", "submitter": "Jayadev Misra", "authors": "Jayadev Misra", "title": "Bilateral Proofs of Safety and Progress Properties of Concurrent\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests a theomisra@utexas.edury of composable specification of\nconcurrent programs that permits: (1) verification of program code for a given\nspecification, and (2) composition of the specifications of the components to\nyield the specification of a program. The specification consists of both\nterminal properties that hold at the end of a program execution (if the\nexecution terminates) and perpetual properties that hold throughout an\nexecution. We devise (1) proof techniques for verification, and (2) composition\nrules to derive the specification of a program from those of its components. We\nemploy terminal properties of components to derive perpetual properties of a\nprogram and conversely. Hence, this proof strategy is called bilateral. The\ncompositional aspect of the theory is important in assembling a program out of\ncomponents some of whose source code may not be available, as is increasingly\nthe case with cross-vendor program integration.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 17:48:36 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Misra", "Jayadev", ""]]}, {"id": "1704.01866", "submitter": "Fan Yang", "authors": "Ivano Ciardelli, Rosalie Iemhoff and Fan Yang", "title": "Questions and dependency in intuitionistic logic", "comments": null, "journal-ref": "Notre Dame J. Formal Logic 61, no. 1 (2020), 75-115", "doi": "10.1215/00294527-2019-0033", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recent years, the logic of questions and dependencies has been\ninvestigated in the closely related frameworks of inquisitive logic and\ndependence logic. These investigations have assumed classical logic as the\nbackground logic of statements, and added formulas expressing questions and\ndependencies to this classical core. In this paper, we broaden the scope of\nthese investigations by studying questions and dependency in the context of\nintuitionistic logic. We propose an intuitionistic team semantics, where teams\nare embedded within intuitionistic Kripke models. The associated logic is a\nconservative extension of intuitionistic logic with questions and dependence\nformulas. We establish a number of results about this logic, including a normal\nform result, a completeness result, and translations to classical inquisitive\nlogic and modal dependence logic.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 14:41:55 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Ciardelli", "Ivano", ""], ["Iemhoff", "Rosalie", ""], ["Yang", "Fan", ""]]}, {"id": "1704.01930", "submitter": "Christoph Rauch", "authors": "Stefan Hetzl, Tin Lok Wong", "title": "Some observations on the logical foundations of inductive theorem\n  proving", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4, Automated\n  deduction (April 13, 2018) lmcs:4071", "doi": "10.23638/LMCS-13(4:10)2017", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study the logical foundations of automated inductive theorem\nproving. To that aim we first develop a theoretical model that is centered\naround the difficulty of finding induction axioms which are sufficient for\nproving a goal.\n  Based on this model, we then analyze the following aspects: the choice of a\nproof shape, the choice of an induction rule and the language of the induction\nformula. In particular, using model-theoretic techniques, we clarify the\nrelationship between notions of inductiveness that have been considered in the\nliterature on automated inductive theorem proving. This is a corrected version\nof the paper arXiv:1704.01930v5 published originally on Nov.~16, 2017.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 16:53:00 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 09:00:21 GMT"}, {"version": "v3", "created": "Mon, 30 Oct 2017 10:51:20 GMT"}, {"version": "v4", "created": "Mon, 6 Nov 2017 14:19:06 GMT"}, {"version": "v5", "created": "Wed, 15 Nov 2017 09:31:29 GMT"}, {"version": "v6", "created": "Thu, 12 Apr 2018 10:09:37 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hetzl", "Stefan", ""], ["Wong", "Tin Lok", ""]]}, {"id": "1704.01937", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek and Venkatesan Guruswami", "title": "Promise Constraint Satisfaction: Algebraic Structure and a Symmetric\n  Boolean Dichotomy", "comments": "39 pages; various revisions including removal of appendices and\n  updates/corrections to some proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic result due to Schaefer (1978) classifies all constraint\nsatisfaction problems (CSPs) over the Boolean domain as being either in\n$\\mathsf{P}$ or $\\mathsf{NP}$-hard. This paper considers a promise-problem\nvariant of CSPs called PCSPs. A PCSP over a finite set of pairs of constraints\n$\\Gamma$ consists of a pair $(\\Psi_P, \\Psi_Q)$ of CSPs with the same set of\nvariables such that for every $(P, Q) \\in \\Gamma$, $P(x_{i_1}, ..., x_{i_k})$\nis a clause of $\\Psi_P$ if and only if $Q(x_{i_1}, ..., x_{i_k})$ is a clause\nof $\\Psi_Q$. The promise problem $\\operatorname{PCSP}(\\Gamma)$ is to\ndistinguish, given $(\\Psi_P, \\Psi_Q)$, between the cases $\\Psi_P$ is\nsatisfiable and $\\Psi_Q$ is unsatisfiable. Many natural problems including\napproximate graph and hypergraph coloring can be placed in this framework.\n  This paper is motivated by the pursuit of understanding the computational\ncomplexity of Boolean promise CSPs. As our main result, we show that\n$\\operatorname{PCSP}(\\Gamma)$ exhibits a dichotomy (it is either polynomial\ntime solvable or $\\mathsf{NP}$-hard) when the relations in $\\Gamma$ are\nsymmetric and allow for negations of variables. We achieve our dichotomy\ntheorem by extending the weak polymorphism framework of Austrin, Guruswami, and\nH\\aa stad [FOCS '14] which itself is a generalization of the algebraic approach\nto study CSPs. In both the algorithm and hardness portions of our proof, we\nincorporate new ideas and techniques not utilized in the CSP case.\n  Furthermore, we show that the computational complexity of any promise CSP\n(over arbitrary finite domains) is captured entirely by its weak polymorphisms,\na feature known as Galois correspondence, as well as give necessary and\nsufficient conditions for the structure of this set of weak polymorphisms. Such\ninsights call us to question the existence of a general dichotomy for Boolean\nPCSPs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 17:07:10 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 15:34:08 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Guruswami", "Venkatesan", ""]]}, {"id": "1704.02099", "submitter": "Marcel Jackson G", "authors": "Lucy Ham and Marcel Jackson", "title": "Axiomatisability and hardness for universal Horn classes of hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterise finite axiomatisability and intractability of deciding\nmembership for universal Horn classes generated by finite loop-free\nhypergraphs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 06:02:32 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Ham", "Lucy", ""], ["Jackson", "Marcel", ""]]}, {"id": "1704.02145", "submitter": "Marco Voigt", "authors": "Marco Voigt", "title": "A Fine-Grained Hierarchy of Hard Problems in the Separated Fragment", "comments": "Full version of the LICS 2017 extended abstract having the same\n  title, 38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the separated fragment (SF) has been introduced and proved to be\ndecidable. Its defining principle is that universally and existentially\nquantified variables may not occur together in atoms. The known upper bound on\nthe time required to decide SF's satisfiability problem is formulated in terms\nof quantifier alternations: Given an SF sentence $\\exists \\vec{z} \\forall\n\\vec{x}_1 \\exists \\vec{y}_1 \\ldots \\forall \\vec{x}_n \\exists \\vec{y}_n . \\psi$\nin which $\\psi$ is quantifier free, satisfiability can be decided in\nnondeterministic $n$-fold exponential time. In the present paper, we conduct a\nmore fine-grained analysis of the complexity of SF-satisfiability. We derive an\nupper and a lower bound in terms of the degree of interaction of existential\nvariables (short: degree)}---a novel measure of how many separate existential\nquantifier blocks in a sentence are connected via joint occurrences of\nvariables in atoms. Our main result is the $k$-NEXPTIME-completeness of the\nsatisfiability problem for the set $SF_{\\leq k}$ of all SF sentences that have\ndegree $k$ or smaller. Consequently, we show that SF-satisfiability is\nnon-elementary in general, since SF is defined without restrictions on the\ndegree. Beyond trivial lower bounds, nothing has been known about the hardness\nof SF-satisfiability so far.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 09:10:37 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Voigt", "Marco", ""]]}, {"id": "1704.02158", "submitter": "Jonni Virtema", "authors": "Miika Hannula, Juha Kontinen, and Jonni Virtema", "title": "Polyteam Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Team semantics is the mathematical framework of modern logics of dependence\nand independence in which formulae are interpreted by sets of assignments\n(teams) instead of single assignments as in first-order logic. In order to\ndeepen the fruitful interplay between team semantics and database dependency\ntheory, we define \"Polyteam Semantics\" in which formulae are evaluated over a\nfamily of teams. We begin by defining a novel polyteam variant of dependence\natoms and give a finite axiomatisation for the associated implication problem.\nWe relate polyteam semantics to team semantics and investigate in which cases\nlogics over the former can be simulated by logics over the latter. We also\ncharacterise the expressive power of poly-dependence logic by properties of\npolyteams that are downwards closed and definable in existential second-order\nlogic (ESO). The analogous result is shown to hold for poly-independence logic\nand all ESO-definable properties. We also relate poly-inclusion logic to\ngreatest fixed point logic.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 09:41:37 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 09:34:05 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 08:21:42 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Hannula", "Miika", ""], ["Kontinen", "Juha", ""], ["Virtema", "Jonni", ""]]}, {"id": "1704.02230", "submitter": "Jules Hedges", "authors": "Jules Hedges", "title": "Coherence for lenses and open games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categories of polymorphic lenses in computer science, and of open games in\ncompositional game theory, have a curious structure that is reminiscent of\ncompact closed categories, but differs in some crucial ways. Specifically they\nhave a family of morphisms that behave like the counits of a compact closed\ncategory, but have no corresponding units; and they have a `partial' duality\nthat behaves like transposition in a compact closed category when it is\ndefined. We axiomatise this structure, which we refer to as a `teleological\ncategory'. We precisely define a diagrammatic language suitable for these\ncategories, and prove a coherence theorem for them. This underpins the use of\ndiagrammatic reasoning in compositional game theory, which has previously been\nused only informally.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 13:43:42 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 13:36:11 GMT"}, {"version": "v3", "created": "Fri, 15 Sep 2017 21:24:05 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Hedges", "Jules", ""]]}, {"id": "1704.02237", "submitter": "Oleg Verbitsky", "authors": "Oleg Verbitsky and Maksim Zhukovskii", "title": "On the First-Order Complexity of Induced Subgraph Isomorphism", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (March 6,\n  2019) lmcs:5261", "doi": "10.23638/LMCS-15(1:25)2019", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $F$, let $I(F)$ be the class of graphs containing $F$ as an\ninduced subgraph. Let $W[F]$ denote the minimum $k$ such that $I(F)$ is\ndefinable in $k$-variable first-order logic. The recognition problem of $I(F)$,\nknown as Induced Subgraph Isomorphism (for the pattern graph $F$), is solvable\nin time $O(n^{W[F]})$. Motivated by this fact, we are interested in determining\nor estimating the value of $W[F]$. Using Olariu's characterization of paw-free\ngraphs, we show that $I(K_3+e)$ is definable by a first-order sentence of\nquantifier depth 3, where $K_3+e$ denotes the paw graph. This provides an\nexample of a graph $F$ with $W[F]$ strictly less than the number of vertices in\n$F$. On the other hand, we prove that $W[F]=4$ for all $F$ on 4 vertices except\nthe paw graph and its complement. If $F$ is a graph on $t$ vertices, we prove a\ngeneral lower bound $W[F]>(1/2-o(1))t$, where the function in the little-o\nnotation approaches 0 as $t$ inreases. This bound holds true even for a related\nparameter $W^*[F]\\le W[F]$, which is defined as the minimum $k$ such that\n$I(F)$ is definable in the infinitary logic $L^k_{\\infty\\omega}$. We show that\n$W^*[F]$ can be strictly less than $W[F]$. Specifically, $W^*[P_4]=3$ for $P_4$\nbeing the path graph on 4 vertices.\n  Using the lower bound for $W[F]$, we also obtain a succintness result for\nexistential monadic second-order logic: A usage of just one monadic quantifier\nsometimes reduces the first-order quantifier depth at a super-recursive rate.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 14:08:40 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 11:37:15 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 08:25:54 GMT"}, {"version": "v4", "created": "Wed, 19 Dec 2018 15:10:20 GMT"}, {"version": "v5", "created": "Tue, 5 Mar 2019 11:44:15 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Verbitsky", "Oleg", ""], ["Zhukovskii", "Maksim", ""]]}, {"id": "1704.02253", "submitter": "William Farmer", "authors": "Jacques Carette and William M. Farmer", "title": "Formalizing Mathematical Knowledge as a Biform Theory Graph: A Case\n  Study", "comments": "43 pages; published without appendices in: H. Geuvers et al., eds,\n  Intelligent Computer Mathematics (CICM 2017), Lecture Notes in Computer\n  Science, Vol. 10383, pp. 9-24, Springer, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A biform theory is a combination of an axiomatic theory and an algorithmic\ntheory that supports the integration of reasoning and computation. These are\nideal for formalizing algorithms that manipulate mathematical expressions. A\ntheory graph is a network of theories connected by meaning-preserving theory\nmorphisms that map the formulas of one theory to the formulas of another\ntheory. Theory graphs are in turn well suited for formalizing mathematical\nknowledge at the most convenient level of abstraction using the most convenient\nvocabulary. We are interested in the problem of whether a body of mathematical\nknowledge can be effectively formalized as a theory graph of biform theories.\nAs a test case, we look at the graph of theories encoding natural number\narithmetic. We used two different formalisms to do this, which we describe and\ncompare. The first is realized in ${\\rm CTT}_{\\rm uqe}$, a version of Church's\ntype theory with quotation and evaluation, and the second is realized in Agda,\na dependently typed programming language.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 15:22:45 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 20:18:02 GMT"}, {"version": "v3", "created": "Wed, 26 Jul 2017 11:05:04 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Carette", "Jacques", ""], ["Farmer", "William M.", ""]]}, {"id": "1704.02375", "submitter": "Yanhong Annie Liu", "authors": "David S. Warren and Yanhong A. Liu", "title": "AppLP: A Dialogue on Applications of Logic Programming", "comments": "David S. Warren and Yanhong A. Liu (Editors). 33 pages. Including\n  summaries by Christopher Kane and abstracts or position papers by M. Aref, J.\n  Rosenwald, I. Cervesato, E.S.L. Lam, M. Balduccini, J. Lobo, A. Russo, E.\n  Lupu, N. Leone, F. Ricca, G. Gupta, K. Marple, E. Salazar, Z. Chen, A. Sobhi,\n  S. Srirangapalli, C.R. Ramakrishnan, N. Bj{\\o}rner, N.P. Lopes, A.\n  Rybalchenko, and P. Tarau", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the contributions of the 2016 Applications of Logic\nProgramming Workshop (AppLP), which was held on October 17 and associated with\nthe International Conference on Logic Programming (ICLP) in Flushing, New York\nCity.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 21:10:00 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Warren", "David S.", ""], ["Liu", "Yanhong A.", ""]]}, {"id": "1704.02421", "submitter": "EPTCS", "authors": "Erika \\'Abrah\\'am (RWTH Aachen University), Sergiy Bogomolov\n  (Australian National University)", "title": "Proceedings 3rd International Workshop on Symbolic and Numerical Methods\n  for Reachability Analysis", "comments": null, "journal-ref": "EPTCS 247, 2017", "doi": "10.4204/EPTCS.247", "report-no": null, "categories": "cs.SY cs.LO cs.NA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid systems are complex dynamical systems that combine discrete and\ncontinuous components. Reachability questions, regarding whether a system can\nrun into a certain subset of its state space, stand at the core of verification\nand synthesis problems for hybrid systems. This volume contains papers\ndescribing new developments in this area, which were presented at the 3rd\nInternational Workshop on Symbolic and Numerical Methods for Reachability\nAnalysis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 02:00:13 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["\u00c1brah\u00e1m", "Erika", "", "RWTH Aachen University"], ["Bogomolov", "Sergiy", "", "Australian National University"]]}, {"id": "1704.02711", "submitter": "Masahiro Hamano", "authors": "Masahiro Hamano", "title": "A MALL Geometry of Interaction Based on Indexed Linear Logic", "comments": "26 pages", "journal-ref": null, "doi": "10.1017/S0960129521000062", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a geometry of interaction (GoI: dynamic modeling of\nGentzen-style cut elimination) for multiplicative-additive linear logic (MALL)\nby employing Bucciarelli-Ehrhard indexed linear logic MALL(I) to handle the\nadditives. Our construction is an extension to the additives of the\nHaghverdi-Scott categorical formulation (a multiplicative GoI situation in a\ntraced monoidal category) for Girard's original GoI 1. The indices are shown to\nserve not only in their original denotational level, but also at a finer\ngrained dynamic level so that the peculiarities of additive cut elimination\nsuch as superposition, erasure of subproofs, and additive (co-) contraction can\nbe handled with the explicit use of indices. Proofs are interpreted as indexed\nsubsets in the category Rel, but without the explicit relational composition;\ninstead, execution formulas are run pointwise on the interpretation at each\nindex, w.r.t symmetries of cuts, in a traced monoidal category with a reflexive\nobject and a zero morphism. The sets of indices diminish overall when an\nexecution formula is run, corresponding to the additive cut-elimination\nprocedure (erasure), and allowing recovery of the relational composition. The\nmain theorem is the invariance of the execution formulas along cut elimination\nso that the formulas converge to the denotations of (cut-free) proofs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 04:56:02 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 04:50:40 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 03:12:49 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 07:00:17 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hamano", "Masahiro", ""]]}, {"id": "1704.03080", "submitter": "Michael Stay", "authors": "Michael Stay and L. G. Meredith", "title": "Representing operational semantics with enriched Lawvere theories", "comments": "arXiv admin note: text overlap with arXiv:1703.07054", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many term calculi, like lambda calculus or pi calculus, involve binders for\nnames, and the mathematics of bound variable names is subtle. Schoenfinkel\nintroduced the SKI combinator calculus in 1924 to clarify the role of\nquantified variables in intuitionistic logic by eliminating them. Yoshida\ndemonstrated how to eliminate the bound names coming from the input prefix in\nthe asynchronous pi calculus, but her combinators still depend on the new\noperator to bind names. Recently, Meredith and Stay showed how to modify\nYoshida's combinators by replacing new and replication with reflective\noperators to provide the first combinator calculus with no bound names into\nwhich the asynchronous pi calculus has a faithful embedding. Here we provide an\nalternative set of combinators built from SKI plus reflection that also\neliminates all nominal phenomena, yet provides a faithful embedding of a\nreflective higher-order pi calculus. We show that with the nominal features\neffectively eliminated as syntactic sugar, multisorted Lawvere theories\nenriched over graphs suffice to capture the operational semantics of the\ncalculus.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 22:54:54 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Stay", "Michael", ""], ["Meredith", "L. G.", ""]]}, {"id": "1704.03096", "submitter": "EPTCS", "authors": "Francisco Martins (LaSIGE, Faculty of Sciences, University of Lisbon),\n  Vasco Thudichum Vasconcelos (LaSIGE, Faculty of Sciences, University of\n  Lisbon), Hans H\\\"uttel (Department of Computer Science, Aalborg University)", "title": "Inferring Types for Parallel Programs", "comments": "In Proceedings PLACES 2017, arXiv:1704.02418", "journal-ref": "EPTCS 246, 2017, pp. 28-36", "doi": "10.4204/EPTCS.246.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Message Passing Interface (MPI) framework is widely used in implementing\nimperative pro- grams that exhibit a high degree of parallelism. The PARTYPES\napproach proposes a behavioural type discipline for MPI-like programs in which\na type describes the communication protocol followed by the entire program.\nWell-typed programs are guaranteed to be exempt from deadlocks. In this paper\nwe describe a type inference algorithm for a subset of the original system; the\nalgorithm allows to statically extract a type for an MPI program from its\nsource code.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:43:38 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Martins", "Francisco", "", "LaSIGE, Faculty of Sciences, University of Lisbon"], ["Vasconcelos", "Vasco Thudichum", "", "LaSIGE, Faculty of Sciences, University of\n  Lisbon"], ["H\u00fcttel", "Hans", "", "Department of Computer Science, Aalborg University"]]}, {"id": "1704.03099", "submitter": "EPTCS", "authors": "Eva Graversen (Imperial College London), Iain Phillips (Imperial\n  College London), Nobuko Yoshida (Imperial College London)", "title": "Towards a Categorical Representation of Reversible Event Structures", "comments": "In Proceedings PLACES 2017, arXiv:1704.02418", "journal-ref": "EPTCS 246, 2017, pp. 49-60", "doi": "10.4204/EPTCS.246.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study categories for reversible computing, focussing on reversible forms\nof event structures. Event structures are a well-established model of true\nconcurrency. There exist a number of forms of event structures, including prime\nevent structures, asymmetric event structures, and general event structures.\nMore recently, reversible forms of these types of event structures have been\ndefined. We formulate corresponding categories and functors between them. We\nshow that products and co-products exist in many cases. In most work on\nreversible computing, including reversible process calculi, a cause-respecting\ncondition is posited, meaning that the cause of an event may not be reversed\nbefore the event itself. Since reversible event structures are not assumed to\nbe cause-respecting in general, we also define cause-respecting subcategories\nof these event structures. Our longer-term aim is to formulate event structure\nsemantics for reversible process calculi.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:44:23 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Graversen", "Eva", "", "Imperial College London"], ["Phillips", "Iain", "", "Imperial\n  College London"], ["Yoshida", "Nobuko", "", "Imperial College London"]]}, {"id": "1704.03100", "submitter": "EPTCS", "authors": "Sanjiva Prasad (Indian Institute of Technology Delhi)", "title": "Best-by-Simulations: A Framework for Comparing Efficiency of\n  Reconfigurable Multicore Architectures on Workloads with Deadlines", "comments": "In Proceedings PLACES 2017, arXiv:1704.02418", "journal-ref": "EPTCS 246, 2017, pp. 61-71", "doi": "10.4204/EPTCS.246.10", "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy consumption is a major concern in multicore systems. Perhaps the\nsimplest strategy for reducing energy costs is to use only as many cores as\nnecessary while still being able to deliver a desired quality of service.\nMotivated by earlier work on a dynamic (heterogeneous) core allocation scheme\nfor H.264 video decoding that reduces energy costs while delivering desired\nframe rates, we formulate operationally the general problem of executing a\nsequence of actions on a reconfigurable machine while meeting a corresponding\nsequence of absolute deadlines, with the objective of reducing cost. Using a\ntransition system framework that associates costs (e.g., time, energy) with\nexecuting an action on a particular resource configuration, we use the notion\nof amortised cost to formulate in terms of simulation relations appropriate\nnotions for comparing deadline-conformant executions. We believe these notions\ncan provide the basis for an operational theory of optimal cost executions and\nperformance guarantees for approximate solutions, in particular relating the\nnotion of simulation from transition systems to that of competitive analysis\nused for, e.g., online algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:44:42 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Prasad", "Sanjiva", "", "Indian Institute of Technology Delhi"]]}, {"id": "1704.03104", "submitter": "EPTCS", "authors": "Ievgen Ivanov (Taras Shevchenko National University of Kyiv)", "title": "On the Underapproximation of Reach Sets of Abstract Continuous-Time\n  Systems", "comments": "In Proceedings SNR 2017, arXiv:1704.02421", "journal-ref": "EPTCS 247, 2017, pp. 46-51", "doi": "10.4204/EPTCS.247.4", "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of proving that each point in a given set of states\n(\"target set\") can indeed be reached by a given nondeterministic\ncontinuous-time dynamical system from some initial state. We consider this\nproblem for abstract continuous-time models that can be concretized as various\nkinds of continuous and hybrid dynamical systems.\n  The approach to this problem proposed in this paper is based on finding a\nsuitable superset S of the target set which has the property that each partial\ntrajectory of the system which lies entirely in S either is defined as the\ninitial time moment, or can be locally extended backward in time, or can be\nlocally modified in such a way that the resulting trajectory can be locally\nextended back in time.\n  This reformulation of the problem has a relatively simple logical expression\nand is convenient for applying various local existence theorems and local\ndynamics analysis methods to proving reachability which makes it suitable for\nreasoning about the behavior of continuous and hybrid dynamical systems in\nproof assistants such as Mizar, Isabelle, etc.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:57:26 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Ivanov", "Ievgen", "", "Taras Shevchenko National University of Kyiv"]]}, {"id": "1704.03160", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Lean and Full Congruence Formats for Recursion", "comments": "To appear in: Proc. LICS'17, Reykjavik, Iceland, IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I distinguish two (pre)congruence requirements for semantic\nequivalences and preorders on processes given as closed terms in a system\ndescription language with a recursion construct. A lean congruence preserves\nequivalence when replacing closed subexpressions of a process by equivalent\nalternatives. A full congruence moreover allows replacement within a recursive\nspecification of subexpressions that may contain recursion variables bound\noutside of these subexpressions.\n  I establish that bisimilarity is a lean (pre)congruence for recursion for all\nlanguages with a structural operational semantics in the ntyft/ntyxt format.\nAdditionally, it is a full congruence for the tyft/tyxt format.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 06:20:05 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1704.03167", "submitter": "Yijia Chen", "authors": "Yijia Chen, Joerg Flum, Xuangui Huang", "title": "Slicewise definability in first-order logic with bounded quantifier rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For every $q\\in \\mathbb N$ let $\\textrm{FO}_q$ denote the class of sentences\nof first-order logic FO of quantifier rank at most $q$. If a graph property can\nbe defined in $\\textrm{FO}_q$, then it can be decided in time $O(n^q)$. Thus,\nminimizing $q$ has favorable algorithmic consequences. Many graph properties\namount to the existence of a certain set of vertices of size $k$. Usually this\ncan only be expressed by a sentence of quantifier rank at least $k$. We use the\ncolor-coding method to demonstrate that some (hyper)graph problems can be\ndefined in $\\textrm{FO}_q$ where $q$ is independent of $k$. This property of a\ngraph problem is equivalent to the question of whether the corresponding\nparameterized problem is in the class $\\textrm{para-AC}^0$.\n  It is crucial for our results that the FO-sentences have access to built-in\naddition and multiplication. It is known that then FO corresponds to the\ncircuit complexity class uniform $\\textrm{AC}^0$. We explore the connection\nbetween the quantifier rank of FO-sentences and the depth of\n$\\textrm{AC}^0$-circuits, and prove that $\\textrm{FO}_q \\subsetneq\n\\textrm{FO}_{q+1}$ for structures with built-in addition and multiplication.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 06:35:37 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Chen", "Yijia", ""], ["Flum", "Joerg", ""], ["Huang", "Xuangui", ""]]}, {"id": "1704.03202", "submitter": "Laura Kovacs", "authors": "Laura Kovacs", "title": "Symbolic Computation and Automated Reasoning for Program Analysis", "comments": "Paper published at iFM 2016", "journal-ref": null, "doi": "10.1007/978-3-319-33693-0_2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This talk describes how a combination of symbolic computation techniques with\nfirst-order theorem proving can be used for solving some challenges of\nautomating program analysis, in particular for generating and proving\nproperties about the logically complex parts of software. The talk will first\npresent how computer algebra methods, such as Groebner basis computation,\nquantifier elimination and algebraic recurrence solving, help us in inferring\nproperties of program loops with non-trivial arithmetic. Typical properties\ninferred by our work are loop invariants and expressions bounding the number of\nloop iterations. The talk will then describe our work to generate first-order\nproperties of programs with unbounded data structures, such as arrays. For\ndoing so, we use saturation-based first-order theorem proving and extend\nfirst-order provers with support for program analysis. Since program analysis\nrequires reasoning in the combination of first-order theories of data\nstructures, the talk also discusses new features in firstorder theorem proving,\nsuch as inductive reasoning and built-in boolean sort. These extensions allow\nus to express program properties directly in first-order logic and hence use\nfurther first-order theorem provers to reason about program properties.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 08:58:55 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Kovacs", "Laura", ""]]}, {"id": "1704.03275", "submitter": "Bruno Woltzenlogel Paleo", "authors": "Daniyar Itegulov, John Slaney, Bruno Woltzenlogel Paleo", "title": "Scavenger 0.1: A Theorem Prover Based on Conflict Resolution", "comments": "Published at CADE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces Scavenger, the first theorem prover for pure\nfirst-order logic without equality based on the new conflict resolution\ncalculus. Conflict resolution has a restricted resolution inference rule that\nresembles (a first-order generalization of) unit propagation as well as a rule\nfor assuming decision literals and a rule for deriving new clauses by (a\nfirst-order generalization of) conflict-driven clause learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 13:11:57 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 09:09:33 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Itegulov", "Daniyar", ""], ["Slaney", "John", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1704.03292", "submitter": "Arne Meier", "authors": "Arne Meier and Christian Reinbold", "title": "Enumeration Complexity of Poor Man's Propositional Dependence Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependence logics are a modern family of logics of independence and\ndependence which mimic notions of database theory. In this paper, we aim to\ninitiate the study of enumeration complexity in the field of dependence logics\nand thereby get a new point of view on enumerating answers of database queries.\nConsequently, as a first step, we investigate the problem of enumerating all\nsatisfying teams of formulas from a given fragment of propositional dependence\nlogic. We distinguish between restricting the team size by arbitrary functions\nand the parametrised version where the parameter is the team size. We show that\na polynomial delay can be reached for polynomials and otherwise in the\nparametrised setting we reach FPT delay. However, the constructed enumeration\nalgorithm with polynomial delay requires exponential space. We show that an\nincremental polynomial delay algorithm exists which uses polynomial space only.\nNegatively, we show that for the general problem without restricting the team\nsize, an enumeration algorithm running in polynomial space cannot exist.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 14:05:01 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 12:20:50 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Meier", "Arne", ""], ["Reinbold", "Christian", ""]]}, {"id": "1704.03391", "submitter": "Martin Suda", "authors": "Giles Reger and Martin Suda and Andrei Voronkov", "title": "Testing a Saturation-Based Theorem Prover: Experiences and Challenges\n  (Extended Version)", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to address the question of how best to assure the\ncorrectness of saturation-based automated theorem provers using our experience\ndeveloping the theorem prover Vampire. We describe the techniques we currently\nemploy to ensure that Vampire is correct and use this to motivate future\nchallenges that need to be addressed to make this process more straightforward\nand to achieve better correctness guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 16:13:21 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Reger", "Giles", ""], ["Suda", "Martin", ""], ["Voronkov", "Andrei", ""]]}, {"id": "1704.03396", "submitter": "Shahab Ebrahimi", "authors": "Shahab Ebrahimi", "title": "Source-Sensitive Belief Change", "comments": "13 pages", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol.8, No.2, March 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AGM model is the most remarkable framework for modeling belief revision.\nHowever, it is not perfect in all aspects. Paraconsistent belief revision,\nmulti-agent belief revision and non-prioritized belief revision are three\ndifferent extensions to AGM to address three important criticisms applied to\nit. In this article, we propose a framework based on AGM that takes a position\nin each of these categories. Also, we discuss some features of our framework\nand study the satisfiability of AGM postulates in this new context.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 16:20:39 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 08:44:14 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Ebrahimi", "Shahab", ""]]}, {"id": "1704.03738", "submitter": "Lucas Carvalho Cordeiro", "authors": "Rodrigo F. Araujo, Higo F. Albuquerque, Iury V. de Bessa, Lucas C.\n  Cordeiro, Joao Edgar C. Filho", "title": "Counterexample Guided Inductive Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes three variants of a counterexample guided inductive\noptimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT)\nsolvers. In particular, CEGIO relies on iterative executions to constrain a\nverification procedure, in order to perform inductive generalization, based on\ncounterexamples extracted from SMT solvers. CEGIO is able to successfully\noptimize a wide range of functions, including non-linear and non-convex\noptimization problems based on SMT solvers, in which data provided by\ncounterexamples are employed to guide the verification engine, thus reducing\nthe optimization domain. The present algorithms are evaluated using a large set\nof benchmarks typically employed for evaluating optimization techniques.\nExperimental results show the efficiency and effectiveness of the proposed\nalgorithms, which find the optimal solution in all evaluated benchmarks, while\ntraditional techniques are usually trapped by local minima.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:33:50 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Araujo", "Rodrigo F.", ""], ["Albuquerque", "Higo F.", ""], ["de Bessa", "Iury V.", ""], ["Cordeiro", "Lucas C.", ""], ["Filho", "Joao Edgar C.", ""]]}, {"id": "1704.03772", "submitter": "Luigi Santocanale", "authors": "Maria Jo\\~ao Gouveia and Luigi Santocanale", "title": "$\\aleph_1$ and the modal $\\mu$-calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 4 (October\n  15, 2019) lmcs:5808", "doi": "10.23638/LMCS-15(4:1)2019", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a regular cardinal $\\kappa$, a formula of the modal $\\mu$-calculus is\n$\\kappa$-continuous in a variable x if, on every model, its interpretation as a\nunary function of x is monotone and preserves unions of $\\kappa$-directed sets.\nWe define the fragment $C_{\\aleph_1}(x)$ of the modal $\\mu$-calculus and prove\nthat all the formulas in this fragment are $\\aleph_1$-continuous. For each\nformula $\\phi(x)$ of the modal $\\mu$-calculus, we construct a formula $\\psi(x)\n\\in C_{\\aleph_1 }(x)$ such that $\\phi(x)$ is $\\kappa$-continuous, for some\n$\\kappa$, if and only if $\\phi(x)$ is equivalent to $\\psi(x)$. Consequently, we\nprove that (i) the problem whether a formula is $\\kappa$-continuous for some\n$\\kappa$ is decidable, (ii) up to equivalence, there are only two fragments\ndetermined by continuity at some regular cardinal: the fragment\n$C_{\\aleph_0}(x)$ studied by Fontaine and the fragment $C_{\\aleph_1}(x)$. We\napply our considerations to the problem of characterizing closure ordinals of\nformulas of the modal $\\mu$-calculus. An ordinal $\\alpha$ is the closure\nordinal of a formula $\\phi(x)$ if its interpretation on every model converges\nto its least fixed-point in at most $\\alpha$ steps and if there is a model\nwhere the convergence occurs exactly in $\\alpha$ steps. We prove that\n$\\omega_1$, the least uncountable ordinal, is such a closure ordinal. Moreover\nwe prove that closure ordinals are closed under ordinal sum. Thus, any formal\nexpression built from 0, 1, $\\omega$, $\\omega_1$ by using the binary operator\nsymbol + gives rise to a closure ordinal.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 14:37:19 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 22:14:54 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 16:38:05 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2019 11:39:15 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gouveia", "Maria Jo\u00e3o", ""], ["Santocanale", "Luigi", ""]]}, {"id": "1704.03972", "submitter": "Zhilin Wu", "authors": "Yu-Fang Chen, Ondrej Lengal, Tony Tan, Zhilin Wu", "title": "Register automata with linear arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel automata model over the alphabet of rational numbers,\nwhich we call register automata over the rationals (RA-Q). It reads a sequence\nof rational numbers and outputs another rational number. RA-Q is an extension\nof the well-known register automata (RA) over infinite alphabets, which are\nfinite automata equipped with a finite number of registers/variables for\nstoring values. Like in the standard RA, the RA-Q model allows both equality\nand ordering tests between values. It, moreover, allows to perform linear\narithmetic between certain variables. The model is quite expressive: in\naddition to the standard RA, it also generalizes other well-known models such\nas affine programs and arithmetic circuits.\n  The main feature of RA-Q is that despite the use of linear arithmetic, the\nso-called invariant problem---a generalization of the standard non-emptiness\nproblem---is decidable. We also investigate other natural decision problems,\nnamely, commutativity, equivalence, and reachability. For deterministic RA-Q,\ncommutativity and equivalence are polynomial-time inter-reducible with the\ninvariant problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 02:20:25 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 13:13:57 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Lengal", "Ondrej", ""], ["Tan", "Tony", ""], ["Wu", "Zhilin", ""]]}, {"id": "1704.04029", "submitter": "Tom\\'a\\v{s} Jakl", "authors": "Tom\\'a\\v{s} Jakl and Achim Jung", "title": "Free constructions and coproducts of d-frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A general theory of presentations for d-frames does not yet exist. We review\nthe difficulties and give sufficient conditions for when they can be overcome.\nAs an application we prove that the category of d-frames is closed under\ncoproducts.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 08:27:00 GMT"}, {"version": "v2", "created": "Sun, 23 Apr 2017 11:40:54 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Jakl", "Tom\u00e1\u0161", ""], ["Jung", "Achim", ""]]}, {"id": "1704.04190", "submitter": "Javier Esparza", "authors": "Javier Esparza and Anca Muscholl and Igor Walukiewicz", "title": "Static Analysis of Deterministic Negotiations", "comments": "To appear in the Proceedings of LICS 2017, IEEE Computer Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negotiation diagrams are a model of concurrent computation akin to workflow\nPetri nets. Deterministic negotiation diagrams, equivalent to the much studied\nand used free-choice workflow Petri nets, are surprisingly amenable to\nverification. Soundness (a property close to deadlock-freedom) can be decided\nin PTIME. Further, other fundamental questions like computing summaries or the\nexpected cost, can also be solved in PTIME for sound deterministic negotiation\ndiagrams, while they are PSPACE-complete in the general case.\n  In this paper we generalize and explain these results. We extend the\nclassical \"meet-over-all-paths\" (MOP) formulation of static analysis problems\nto our concurrent setting, and introduce Mazurkiewicz-invariant analysis\nproblems, which encompass the questions above and new ones. We show that any\nMazurkiewicz-invariant analysis problem can be solved in PTIME for sound\ndeterministic negotiations whenever it is in PTIME for sequential\nflow-graphs---even though the flow-graph of a deterministic negotiation diagram\ncan be exponentially larger than the diagram itself. This gives a common\nexplanation to the low-complexity of all the analysis questions studied so far.\nFinally, we show that classical gen/kill analyses are also an instance of our\nframework, and obtain a PTIME algorithm for detecting anti-patterns in\nfree-choice workflow Petri nets.\n  Our result is based on a novel decomposition theorem, of independent\ninterest, showing that sound deterministic negotiation diagrams can be\nhierarchically decomposed into (possibly overlapping) smaller sound diagrams.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 16:00:50 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Esparza", "Javier", ""], ["Muscholl", "Anca", ""], ["Walukiewicz", "Igor", ""]]}, {"id": "1704.04215", "submitter": "Steven Obua", "authors": "Steven Obua", "title": "Parameterized Local Lexing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the concept of local lexing the concept of parameterized local\nlexing is introduced.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 17:14:13 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Obua", "Steven", ""]]}, {"id": "1704.04490", "submitter": "Mahsa Shirmohammadi", "authors": "Stefan Kiefer, Richard Mayr, Mahsa Shirmohammadi, Dominik Wojtczak", "title": "Parity Objectives in Countable MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study countably infinite MDPs with parity objectives, and special cases\nwith a bounded number of colors in the Mostowski hierarchy (including\nreachability, safety, Buchi and co-Buchi).\n  In finite MDPs there always exist optimal memoryless deterministic (MD)\nstrategies for parity objectives, but this does not generally hold for\ncountably infinite MDPs. In particular, optimal strategies need not exist. For\ncountable infinite MDPs, we provide a complete picture of the memory\nrequirements of optimal (resp., $\\epsilon$-optimal) strategies for all\nobjectives in the Mostowski hierarchy. In particular, there is a strong\ndichotomy between two different types of objectives. For the first type,\noptimal strategies, if they exist, can be chosen MD, while for the second type\noptimal strategies require infinite memory. (I.e., for all objectives in the\nMostowski hierarchy, if finite-memory randomized strategies suffice then also\nMD strategies suffice.) Similarly, some objectives admit $\\epsilon$-optimal\nMD-strategies, while for others $\\epsilon$-optimal strategies require infinite\nmemory. Such a dichotomy also holds for the subclass of countably infinite MDPs\nthat are finitely branching, though more objectives admit MD-strategies here.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 17:42:24 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 18:11:36 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Kiefer", "Stefan", ""], ["Mayr", "Richard", ""], ["Shirmohammadi", "Mahsa", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1704.04543", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus and Christian Sattler", "title": "Space-Valued Diagrams, Type-Theoretically (Extended Abstract)", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.AT math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topologists are sometimes interested in space-valued diagrams over a given\nindex category, but it is tricky to say what such a diagram even is if we look\nfor a notion that is stable under equivalence. The same happens in (homotopy)\ntype theory, where it is known only for special cases how one can define a type\nof type-valued diagrams over a given index category. We offer several\nconstructions. We first show how to define homotopy coherent diagrams which\ncome with all higher coherence laws explicitly, with two variants that come\nwith assumption on the index category or on the type theory. Further, we\npresent a construction of diagrams over certain Reedy categories. As an\napplication, we add the degeneracies to the well-known construction of\nsemisimplicial types, yielding a construction of simplicial types up to any\ngiven finite level. The current paper is only an extended abstract, and a full\nversion is to follow. In the full paper, we will show that the different\nnotions of diagrams are equivalent to each other and to the known notion of\nReedy fibrant diagrams whenever the statement makes sense. In the current\npaper, we only sketch some core ideas of the proofs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 20:59:08 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Kraus", "Nicolai", ""], ["Sattler", "Christian", ""]]}, {"id": "1704.04620", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago and Ryo Tanaka and Akira Yoshimizu", "title": "The Geometry of Concurrent Interaction: Handling Multiple Ports by Way\n  of Multiple Tokens (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a geometry of interaction model for Mazza's multiport\ninteraction combinators, a graph-theoretic formalism which is able to\nfaithfully capture concurrent computation as embodied by process algebras like\nthe $\\pi$-calculus. The introduced model is based on token machines in which\nnot one but multiple tokens are allowed to traverse the underlying net at the\nsame time. We prove soundness and adequacy of the introduced model. The former\nis proved as a simulation result between the token machines one obtains along\nany reduction sequence. The latter is obtained by a fine analysis of\nconvergence, both in nets and in token machines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 10:49:00 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Tanaka", "Ryo", ""], ["Yoshimizu", "Akira", ""]]}, {"id": "1704.04647", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Francesco Gavazzo, Paul Blain Levy", "title": "Effectful Applicative Bisimilarity: Monads, Relators, and Howe's Method\n  (Long Version)", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Abramsky's applicative bisimilarity abstractly, in the context of\ncall-by-value $\\lambda$-calculi with algebraic effects. We first of all endow a\ncomputational $\\lambda$-calculus with a monadic operational semantics. We then\nshow how the theory of relators provides precisely what is needed to generalise\napplicative bisimilarity to such a calculus, and to single out those monads and\nrelators for which applicative bisimilarity is a congruence, thus a sound\nmethodology for program equivalence. This is done by studying Howe's method in\nthe abstract.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 15:20:11 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Gavazzo", "Francesco", ""], ["Levy", "Paul Blain", ""]]}, {"id": "1704.04747", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "Categories with Dependence and Semantics of Dependent Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper gives a generalization of cartesian closed categories,\ncalled cartesian closed categories with dependence, whose strict version\ninduces categories with families that support 1-, Sigma- and Pi-types in the\nstrict sense. Consequently, we have obtained a new semantics of dependent type\ntheories that is both categorical and true-to-syntax.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 10:56:49 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 03:36:08 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 14:33:22 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1704.04872", "submitter": "Natsuki Urabe", "authors": "Natsuki Urabe, Masaki Hara, Ichiro Hasuo", "title": "Categorical Liveness Checking by Corecursive Algebras", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Final coalgebras as \"categorical greatest fixed points\" play a central role\nin the theory of coalgebras. Somewhat analogously, most proof methods studied\ntherein have focused on greatest fixed-point properties like safety and\nbisimilarity. Here we make a step towards categorical proof methods for least\nfixed-point properties over dynamical systems modeled as coalgebras.\nConcretely, we seek a categorical axiomatization of well-known proof methods\nfor liveness, namely ranking functions (in nondeterministic settings) and\nranking supermartingales (in probabilistic ones). We find an answer in a\nsuitable combination of coalgebraic simulation (studied previously by the\nauthors) and corecursive algebra as a classifier for (non-)well-foundedness.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 05:22:09 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Urabe", "Natsuki", ""], ["Hara", "Masaki", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1704.04882", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic and Muzamil Yahia", "title": "Monoidal computer III: A coalgebraic view of computability and\n  complexity", "comments": "34 pages, 24 figures; in this version: added the Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monoidal computer is a categorical model of intensional computation, where\nmany different programs correspond to the same input-output behavior. The\nupshot of yet another model of computation is that a categorical formalism\nshould provide a much needed high level language for theory of computation,\nflexible enough to allow abstracting away the low level implementation details\nwhen they are irrelevant, or taking them into account when they are genuinely\nneeded. A salient feature of the approach through monoidal categories is the\nformal graphical language of string diagrams, which supports visual reasoning\nabout programs and computations.\n  In the present paper, we provide a coalgebraic characterization of monoidal\ncomputer. It turns out that the availability of interpreters and specializers,\nthat make a monoidal category into a monoidal computer, is equivalent with the\nexistence of a *universal state space*, that carries a weakly final state\nmachine for any pair of input and output types. Being able to program state\nmachines in monoidal computers allows us to represent Turing machines, to\ncapture their execution, count their steps, as well as, e.g., the memory cells\nthat they use. The coalgebraic view of monoidal computer thus provides a\nconvenient diagrammatic language for studying computability and complexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 06:27:29 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 09:00:13 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 01:36:07 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pavlovic", "Dusko", ""], ["Yahia", "Muzamil", ""]]}, {"id": "1704.04969", "submitter": "Paulina Paraponiari", "authors": "Paulina Paraponiari and George Rahonis", "title": "Weighted propositional configuration logics: A specification language\n  for architectures with quantitative features", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and investigate a weighted propositional configuration logic\nover commutative semirings. Our logic is intended to serve as a specification\nlanguage for software architectures with quantitative features. We prove an\nefficient construction of full normal forms and decidability of equivalence of\nformulas in this logic. We illustrate the motivation of this work by describing\nwell-known architectures equipped with quantitative characteristics using\nformulas in our logic.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 14:04:31 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 08:09:32 GMT"}, {"version": "v3", "created": "Fri, 26 May 2017 19:47:09 GMT"}, {"version": "v4", "created": "Mon, 24 Jul 2017 22:28:39 GMT"}, {"version": "v5", "created": "Sun, 6 May 2018 10:59:38 GMT"}, {"version": "v6", "created": "Fri, 17 Jan 2020 12:08:03 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Paraponiari", "Paulina", ""], ["Rahonis", "George", ""]]}, {"id": "1704.05003", "submitter": "Richard Mayr", "authors": "Stefan Kiefer, Richard Mayr, Mahsa Shirmohammadi, Dominik Wojtczak", "title": "On Strong Determinacy of Countable Stochastic Games", "comments": "13 pages", "journal-ref": "LICS 2017", "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study 2-player turn-based perfect-information stochastic games with\ncountably infinite state space. The players aim at maximizing/minimizing the\nprobability of a given event (i.e., measurable set of infinite plays), such as\nreachability, B\\\"uchi, omega-regular or more general objectives.\n  These games are known to be weakly determined, i.e., they have value.\nHowever, strong determinacy of threshold objectives (given by an event and a\nthreshold $c \\in [0,1]$) was open in many cases: is it always the case that the\nmaximizer or the minimizer has a winning strategy, i.e., one that enforces,\nagainst all strategies of the other player, that the objective is satisfied\nwith probability $\\ge c$ (resp. $< c$)?\n  We show that almost-sure objectives (where $c=1$) are strongly determined.\nThis vastly generalizes a previous result on finite games with almost-sure tail\nobjectives. On the other hand we show that $\\ge 1/2$ (co-)B\\\"uchi objectives\nare not strongly determined, not even if the game is finitely branching.\n  Moreover, for almost-sure reachability and almost-sure B\\\"uchi objectives in\nfinitely branching games, we strengthen strong determinacy by showing that one\nof the players must have a memoryless deterministic (MD) winning strategy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 15:36:59 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Kiefer", "Stefan", ""], ["Mayr", "Richard", ""], ["Shirmohammadi", "Mahsa", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1704.05124", "submitter": "Samson Abramsky", "authors": "Samson Abramsky, Anuj Dawar and Pengming Wang", "title": "The pebbling comonad in finite model theory", "comments": "To appear in LiCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pebble games are a powerful tool in the study of finite model theory,\nconstraint satisfaction and database theory. Monads and comonads are basic\nnotions of category theory which are widely used in semantics of computation\nand in modern functional programming. We show that existential k-pebble games\nhave a natural comonadic formulation. Winning strategies for Duplicator in the\nk-pebble game for structures A and B are equivalent to morphisms from A to B in\nthe coKleisli category for this comonad. This leads on to comonadic\ncharacterisations of a number of central concepts in Finite Model Theory: -\nIsomorphism in the co-Kleisli category characterises elementary equivalence in\nthe k-variable logic with counting quantifiers. - Symmetric games corresponding\nto equivalence in full k-variable logic are also characterized. - The treewidth\nof a structure A is characterised in terms of its coalgebra number: the least k\nfor which there is a coalgebra structure on A for the k-pebbling comonad. -\nCo-Kleisli morphisms are used to characterize strong consistency, and to give\nan account of a Cai-F\\\"urer-Immerman construction. - The k-pebbling comonad is\nalso used to give semantics to a novel modal operator. These results lay the\nbasis for some new and promising connections between two areas within logic in\ncomputer science which have largely been disjoint: (1) finite and algorithmic\nmodel theory, and (2) semantics and categorical structures of computation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 21:11:06 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Abramsky", "Samson", ""], ["Dawar", "Anuj", ""], ["Wang", "Pengming", ""]]}, {"id": "1704.05169", "submitter": "EPTCS", "authors": "Guillaume Bonfante (Universit\\'e de Lorraine, France), Georg Moser\n  (Universit\\\"at Innsbruck, Austria)", "title": "Proceedings 8th Workshop on Developments in Implicit Computational\n  Complexity and 5th Workshop on Foundational and Practical Aspects of Resource\n  Analysis", "comments": null, "journal-ref": "EPTCS 248, 2017", "doi": "10.4204/EPTCS.248", "report-no": null, "categories": "cs.LO cs.CC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DICE workshop explores the area of Implicit Computational Complexity\n(ICC), which grew out from several proposals to use logic and formal methods to\nprovide languages for complexity-bounded computation (e.g. Ptime, Logspace\ncomputation). It aims at studying the computational complexity of programs\nwithout referring to external measuring conditions or a particular machine\nmodel, but only by considering language restrictions or logical/computational\nprinciples entailing complexity properties.\n  The FOPARA workshop serves as a forum for presenting original research\nresults that are relevant to the analysis of resource (e.g. time, space,\nenergy) consumption by computer programs. The workshop aims to bring together\nthe researchers that work on foundational issues with the researchers that\nfocus more on practical results. Therefore, both theoretical and practical\ncontributions are encouraged. We also encourage papers that combine theory and\npractice.\n  Given the complementarity and the synergy between these two communities, and\nfollowing the successful experience of co-location of DICE-FOPARA 2015 in\nLondon at ETAPS 2015, we hold these two workshops together at ETAPS 2017, which\ntakes place in Uppsala, Sweden. The provided proceedings collect the papers\naccepted at the workshop.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 01:52:49 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Bonfante", "Guillaume", "", "Universit\u00e9 de Lorraine, France"], ["Moser", "Georg", "", "Universit\u00e4t Innsbruck, Austria"]]}, {"id": "1704.05263", "submitter": "Dennis Nolte", "authors": "Andrea Corradini, Barbara K\\\"onig and Dennis Nolte", "title": "Specifying Graph Languages with Type Graphs", "comments": "(v2): -Fixed some typos -Added more references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate three formalisms to specify graph languages, i.e. sets of\ngraphs, based on type graphs. First, we are interested in (pure) type graphs,\nwhere the corresponding language consists of all graphs that can be mapped\nhomomorphically to a given type graph. In this context, we also study languages\nspecified by restriction graphs and their relation to type graphs. Second, we\nextend this basic approach to a type graph logic and, third, to type graphs\nwith annotations. We present decidability results and closure properties for\neach of the formalisms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 10:35:46 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 15:57:21 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Corradini", "Andrea", ""], ["K\u00f6nig", "Barbara", ""], ["Nolte", "Dennis", ""]]}, {"id": "1704.05320", "submitter": "Mathias Weber", "authors": "Mathias Weber and Annette Bieniusa and Arnd Poetzsch-Heffter", "title": "EPTL - A temporal logic for weakly consistent systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high availability and scalability of weakly-consistent systems attracts\nsystem designers. Yet, writing correct application code for this type of\nsystems is difficult; even how to specify the intended behavior of such systems\nis still an open question. There has not been established any standard method\nto specify the intended dynamic behavior of a weakly consistent system. There\nexist specifications of various consistency models for distributed and\nconcurrent systems; and the semantics of replicated datatypes like CRDTs have\nbeen specified in axiomatic and operational models based on visibility\nrelations.\n  In this paper, we present a temporal logic, EPTL, that is tailored to specify\nproperties of weakly consistent systems. In contrast to LTL and CTL, EPTL takes\ninto account that operations of weakly consistent systems are in many cases not\nserializable and have to be treated respectively to capture the behavior. We\nembed our temporal logic in Isabelle/HOL and can thereby leverage strong\nsemi-automatic proving capabilities.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 13:12:11 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Weber", "Mathias", ""], ["Bieniusa", "Annette", ""], ["Poetzsch-Heffter", "Arnd", ""]]}, {"id": "1704.05477", "submitter": "Mani A", "authors": "A Mani", "title": "Generalized Ideals and Co-Granular Rough Sets", "comments": "20pages. Scheduled to appear in IJCRS'2017 Proceedings, LNCS,\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-theoretic ideals have been used to define and generate non granular\nrough approximations over general approximation spaces over the last few years\nby few authors. The goal of these studies, in relation based rough sets, have\nbeen to obtain nice properties comparable to those of classical rough\napproximations. In this research paper, these ideas are generalized in a severe\nway by the present author and associated semantic features are investigated by\nher. Granules are used in the construction of approximations in implicit ways\nand so a concept of co-granularity is introduced. Knowledge interpretation\nassociable with the approaches is also investigated. This research will be of\nrelevance for a number of logico-algebraic approaches to rough sets that\nproceed from point-wise definitions of approximations and also for using\nalternative approximations in spatial mereological contexts involving actual\ncontact relations. The antichain based semantics invented in earlier papers by\nthe present author also applies to the contexts considered.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 18:02:47 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Mani", "A", ""]]}, {"id": "1704.05585", "submitter": "EPTCS", "authors": "Martin Avanzini (University of Innsbruck), Ugo Dal Lago (University of\n  Bologna and INRIA)", "title": "Automated Sized-Type Inference and Complexity Analysis", "comments": "In Proceedings DICE-FOPARA 2017, arXiv:1704.05169", "journal-ref": "EPTCS 248, 2017, pp. 7-16", "doi": "10.4204/EPTCS.248.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new methodology for the complexity analysis of\nhigher-order functional programs, which is based on three components: a\npowerful type system for size analysis and a sound type inference procedure for\nit, a ticking monadic transformation and a concrete tool for constraint\nsolving. Noticeably, the presented methodology can be fully automated, and is\nable to analyse a series of examples which cannot be handled by most competitor\nmethodologies. This is possible due to various key ingredients, and in\nparticular an abstract index language and index polymorphism at higher ranks. A\nprototype implementation is available.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:19:27 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Avanzini", "Martin", "", "University of Innsbruck"], ["Lago", "Ugo Dal", "", "University of\n  Bologna and INRIA"]]}, {"id": "1704.05586", "submitter": "EPTCS", "authors": "Martin Avanzini, Michael Schaper", "title": "GUBS Upper Bound Solver (Extended Abstract)", "comments": "In Proceedings DICE-FOPARA 2017, arXiv:1704.05169", "journal-ref": "EPTCS 248, 2017, pp. 17-23", "doi": "10.4204/EPTCS.248.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract we present the GUBS Upper Bound Solver. GUBS is a\ndedicated constraint solver over the naturals for inequalities formed over\nuninterpreted function symbols and standard arithmetic operations. GUBS now\nforms the backbone of HoSA, a tool for analysing space and time complexity of\nhigher-order functional programs automatically. We give insights about the\nimplemen- tation and report different case studies.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:19:43 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Avanzini", "Martin", ""], ["Schaper", "Michael", ""]]}, {"id": "1704.05626", "submitter": "Sylvain Schmitz", "authors": "Thomas Colcombet, Marcin Jurdzi\\'nski, Ranko Lazi\\'c, Sylvain Schmitz", "title": "Perfect Half Space Games", "comments": "Accepted at LICS 2017", "journal-ref": "32nd Annual ACM/IEEE Symposium on Logic In Computer Science (LICS\n  2017)", "doi": "10.1109/LICS.2017.8005105", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce perfect half space games, in which the goal of Player 2 is to\nmake the sums of encountered multi-dimensional weights diverge in a direction\nwhich is consistent with a chosen sequence of perfect half spaces (chosen\ndynamically by Player 2). We establish that the bounding games of Jurdzi\\'nski\net al. (ICALP 2015) can be reduced to perfect half space games, which in turn\ncan be translated to the lexicographic energy games of Colcombet and\nNiwi\\'nski, and are positionally determined in a strong sense (Player 2 can\nplay without knowing the current perfect half space). We finally show how\nperfect half space games and bounding games can be employed to solve\nmulti-dimensional energy parity games in pseudo-polynomial time when both the\nnumbers of energy dimensions and of priorities are fixed, regardless of whether\nthe initial credit is given as part of the input or existentially quantified.\nThis also yields an optimal 2-EXPTIME complexity with given initial credit,\nwhere the best known upper bound was non-elementary.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 06:42:10 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 06:18:37 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Colcombet", "Thomas", ""], ["Jurdzi\u0144ski", "Marcin", ""], ["Lazi\u0107", "Ranko", ""], ["Schmitz", "Sylvain", ""]]}, {"id": "1704.06648", "submitter": "Tim Quatmann", "authors": "Tim Quatmann, Sebastian Junges, Joost-Pieter Katoen", "title": "Markov Automata with Multiple Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov automata combine non-determinism, probabilistic branching, and\nexponentially distributed delays. This compositional variant of continuous-time\nMarkov decision processes is used in reliability engineering, performance\nevaluation and stochastic scheduling. Their verification so far focused on\nsingle objectives such as (timed) reachability, and expected costs. In\npractice, often the objectives are mutually dependent and the aim is to reveal\ntrade-offs. We present algorithms to analyze several objectives simultaneously\nand approximate Pareto curves. This includes, e.g., several (timed)\nreachability objectives, or various expected cost objectives. We also consider\ncombinations thereof, such as on-time-within-budget objectives - which policies\nguarantee reaching a goal state within a deadline with at least probability $p$\nwhile keeping the allowed average costs below a threshold? We adopt existing\napproaches for classical Markov decision processes. The main challenge is to\ntreat policies exploiting state residence times, even for untimed objectives.\nExperimental results show the feasibility and scalability of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 17:43:03 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 14:14:49 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Quatmann", "Tim", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1704.06683", "submitter": "Sergey Dovgal", "authors": "Sergey Dovgal and Vlady Ravelomanana", "title": "Shifting the Phase Transition Threshold for Random Graphs and 2-SAT\n  using Degree Constraints", "comments": "19 pages, coloured figures. Black-and-white printing is possible\n  without essential lost of information in most pictures. Accepted to LATIN\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that by restricting the degrees of the vertices of a graph to an\narbitrary set \\( \\Delta \\), the threshold point $ \\alpha(\\Delta) $ of the phase\ntransition for a random graph with $ n $ vertices and $ m = \\alpha(\\Delta) n $\nedges can be either accelerated (e.g., $ \\alpha(\\Delta) \\approx 0.381 $ for $\n\\Delta = \\{0,1,4,5\\} $) or postponed (e.g., $ \\alpha(\\{ 2^0, 2^1, \\cdots, 2^k,\n\\cdots \\}) \\approx 0.795 $) compared to a classical Erd\\H{o}s--R\\'{e}nyi random\ngraph with $ \\alpha(\\mathbb Z_{\\geq 0}) = \\tfrac12 $. In particular, we prove\nthat the probability of graph being nonplanar and the probability of having a\ncomplex component, goes from $ 0 $ to $ 1 $ as $ m $ passes $ \\alpha(\\Delta) n\n$. We investigate these probabilities and also different graph statistics\ninside the critical window of transition (diameter, longest path and\ncircumference of a complex component).\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 19:08:22 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 12:05:44 GMT"}, {"version": "v3", "created": "Wed, 20 Dec 2017 17:40:12 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Dovgal", "Sergey", ""], ["Ravelomanana", "Vlady", ""]]}, {"id": "1704.06781", "submitter": "Ulrik Buchholtz", "authors": "Floris van Doorn, Jakob von Raumer and Ulrik Buchholtz", "title": "Homotopy Type Theory in Lean", "comments": "17 pages, accepted for ITP 2017", "journal-ref": null, "doi": "10.1007/978-3-319-66107-0_30", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the homotopy type theory library in the Lean proof assistant. The\nlibrary is especially geared toward synthetic homotopy theory. Of particular\ninterest is the use of just a few primitive notions of higher inductive types,\nnamely quotients and truncations, and the use of cubical methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 10:30:20 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 09:18:24 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["van Doorn", "Floris", ""], ["von Raumer", "Jakob", ""], ["Buchholtz", "Ulrik", ""]]}, {"id": "1704.07034", "submitter": "EPTCS", "authors": "Daniel Cicala (University of California, Riverside)", "title": "Categorifying the ZX-calculus", "comments": "In Proceedings QPL 2017, arXiv:1802.09737", "journal-ref": "EPTCS 266, 2018, pp. 294-314", "doi": "10.4204/EPTCS.266.19", "report-no": null, "categories": "math.CT cs.LO math-ph math.MP quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a symmetric monoidal and compact closed bicategory by combining\nspans and cospans inside a topos. This can be used as a framework in which to\nstudy open networks and diagrammatic languages. We illustrate this framework\nwith Coecke and Duncan's zx-calculus by constructing a bicategory with the\nnatural numbers for 0-cells, the zx-calculus diagrams for 1-cells, and rewrite\nrules for 2-cells.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 03:56:41 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:52:17 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Cicala", "Daniel", "", "University of California, Riverside"]]}, {"id": "1704.07097", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng and Yassine Hamza and Harald Ruess", "title": "Automated Analysis of Multi-View Software Architectures", "comments": "Timestamping research work conducted under the fortiss Eigenforschung\n  project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software architectures usually are comprised of different views for capturing\nstatic, runtime, and deployment aspects. What is currently missing, however,\nare formal validation and verification techniques of multi-view architecture in\nvery early phases of the software development lifecycle. The main contribution\nof this paper therefore is the construction of a single formal model (in\nPromela) for certain stylized, and widely used, multi-view architectures by\nsuitably interpreting and fusing sub-models from different UML diagrams.\nPossible counter-examples produced by model checking are fed back as test\nscenarios for debugging the multi-view architectural model. We have implemented\nthis algorithm as a plug-in for the Enterprise Architect development tool, and\nsuccessfully used SPIN model checking for debugging some industrial\narchitectural multi-view models by identifying a number of undesirable corner\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 09:07:31 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Hamza", "Yassine", ""], ["Ruess", "Harald", ""]]}, {"id": "1704.07149", "submitter": "Katsuhiko Sano", "authors": "Katsuhiko Sano", "title": "Axiomatizing Epistemic Logic of Friendship via Tree Sequent Calculus", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper positively solves an open problem if it is possible to provide a\nHilbert system to Epistemic Logic of Friendship (EFL) by Seligman, Girard and\nLiu. To find a Hilbert system, we first introduce a sound, complete and\ncut-free tree (or nested) sequent calculus for EFL, which is an integrated\ncombination of Seligman's sequent calculus for basic hybrid logic and a tree\nsequent calculus for modal logic. Then we translate a tree sequent into an\nordinary formula to specify a Hilbert system of EFL and finally show that our\nHilbert system is sound and complete for the intended two-dimensional\nsemantics.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 11:28:24 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 07:27:27 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 14:00:03 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Sano", "Katsuhiko", ""]]}, {"id": "1704.07181", "submitter": "Marco Peressotti", "authors": "Marino Miculan and Marco Peressotti", "title": "Reductions for Transition Systems at Work: Deriving a Logical\n  Characterization of Quantitative Bisimulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted labelled transition systems (WLTSs) are an established meta-model\naiming to provide general results and tools for a wide range of systems such as\nnon-deterministic, stochastic, and probabilistic systems. In order to encompass\nprocesses combining several quantitative aspects, extensions of the WLTS\nframework have been further proposed, state-to-function transition systems\n(FuTSs) and uniform labelled transition systems (ULTraSs) being two prominent\nexamples. In this paper we show that this hierarchy of meta-models collapses\nwhen studied under the lens of bisimulation-coherent encodings. Taking\nadvantage of these reductions, we derive a fully abstract Hennessy-Milner-style\nlogic for FuTSs, i.e., which characterizes quantitative bisimilarity, from a\nfully-abstract logic for WLTSs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 12:43:11 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Miculan", "Marino", ""], ["Peressotti", "Marco", ""]]}, {"id": "1704.07199", "submitter": "Tobias Kapp\\'e", "authors": "Tobias Kapp\\'e, Paul Brunet, Bas Luttik, Alexandra Silva, Fabio Zanasi", "title": "Brzozowski Goes Concurrent - A Kleene Theorem for Pomset Languages", "comments": "Version 2 incorporates changes prompted by comments of the anonymous\n  referees at CONCUR. Besides minor corrections, this includes additions to the\n  introduction and the discussion section, as well as a proof of Lemma 2.5.\n  Version 3 corrects the accent on the first author's surname in the metadata", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2017.25", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concurrent Kleene Algebra (CKA) is a mathematical formalism to study programs\nthat exhibit concurrent behaviour. As with previous extensions of Kleene\nAlgebra, characterizing the free model is crucial in order to develop the\nfoundations of the theory and potential applications. For CKA, this has been an\nopen question for a few years and this paper makes an important step towards an\nanswer. We present a new automaton model and a Kleene-like theorem that relates\na relaxed version of CKA to series-parallel pomset languages, which are a\nnatural candidate for the free model. There are two substantial differences\nwith previous work: from expressions to automata, we use Brzozowski\nderivatives, which enable a direct construction of the automaton; from automata\nto expressions, we provide a syntactic characterization of the automata that\ndenote valid CKA behaviours.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 13:03:52 GMT"}, {"version": "v2", "created": "Thu, 31 Aug 2017 16:12:40 GMT"}, {"version": "v3", "created": "Sun, 22 Oct 2017 11:45:33 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Kapp\u00e9", "Tobias", ""], ["Brunet", "Paul", ""], ["Luttik", "Bas", ""], ["Silva", "Alexandra", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1704.07503", "submitter": "Cheng-Hao Cai", "authors": "Cheng-Hao Cai, Dengfeng Ke, Yanyan Xu, Kaile Su", "title": "Learning of Human-like Algebraic Reasoning Using Deep Feedforward Neural\n  Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.bica.2018.07.004", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a wide gap between symbolic reasoning and deep learning. In this\nresearch, we explore the possibility of using deep learning to improve symbolic\nreasoning. Briefly, in a reasoning system, a deep feedforward neural network is\nused to guide rewriting processes after learning from algebraic reasoning\nexamples produced by humans. To enable the neural network to recognise patterns\nof algebraic expressions with non-deterministic sizes, reduced partial trees\nare used to represent the expressions. Also, to represent both top-down and\nbottom-up information of the expressions, a centralisation technique is used to\nimprove the reduced partial trees. Besides, symbolic association vectors and\nrule application records are used to improve the rewriting processes.\nExperimental results reveal that the algebraic reasoning examples can be\naccurately learnt only if the feedforward neural network has enough hidden\nlayers. Also, the centralisation technique, the symbolic association vectors\nand the rule application records can reduce error rates of reasoning. In\nparticular, the above approaches have led to 4.6% error rate of reasoning on a\ndataset of linear equations, differentials and integrals.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 01:10:09 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Cai", "Cheng-Hao", ""], ["Ke", "Dengfeng", ""], ["Xu", "Yanyan", ""], ["Su", "Kaile", ""]]}, {"id": "1704.07774", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "A Calculus of Truly Concurrent Mobile Processes", "comments": "20 pages. arXiv admin note: text overlap with arXiv:1703.00159,\n  arXiv:1611.09035", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make a mixture of Milner's $\\pi$-calculus and our previous work on truly\nconcurrent process algebra, which is called $\\pi_{tc}$. We introduce syntax and\nsemantics of $\\pi_{tc}$, its properties based on strongly truly concurrent\nbisimilarities. Also, we include an axiomatization of $\\pi_{tc}$. $\\pi_{tc}$\ncan be used as a formal tool in verifying mobile systems in a truly concurrent\nflavor.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 01:20:04 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1704.07883", "submitter": "Eric Goubault", "authors": "Eric Goubault and Sergio Rajsbaum", "title": "Models of fault-tolerant distributed computation via dynamic epistemic\n  logic", "comments": "arXiv admin note: text overlap with arXiv:1703.11005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO cs.MA math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computability power of a distributed computing model is determined by the\ncommunication media available to the processes, the timing assumptions about\nprocesses and communication, and the nature of failures that processes can\nsuffer. In a companion paper we showed how dynamic epistemic logic can be used\nto give a formal semantics to a given distributed computing model, to capture\nprecisely the knowledge needed to solve a distributed task, such as consensus.\nFurthermore, by moving to a dual model of epistemic logic defined by simplicial\ncomplexes, topological invariants are exposed, which determine task\nsolvability. In this paper we show how to extend the setting above to include\nin the knowledge of the processes, knowledge about the model of computation\nitself. The extension describes the knowledge processes gain about the current\nexecution, in problems where processes have no input values at all.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 19:44:49 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Goubault", "Eric", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "1704.07935", "submitter": "Murphy Berzish", "authors": "Murphy Berzish, Yunhui Zheng, Vijay Ganesh", "title": "Z3str3: A String Solver with Theory-aware Branching", "comments": "8 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new string SMT solver, Z3str3, that is faster than its\ncompetitors Z3str2, Norn, CVC4, S3, and S3P over a majority of three\nindustrial-strength benchmarks, namely Kaluza, PISA, and IBM AppScan. Z3str3\nsupports string equations, linear arithmetic over length function, and regular\nlanguage membership predicate. The key algorithmic innovation behind the\nefficiency of Z3str3 is a technique we call theory-aware branching, wherein we\nmodify Z3's branching heuristic to take into account the structure of theory\nliterals to compute branching activities. In the traditional DPLL(T)\narchitecture, the structure of theory literals is hidden from the DPLL(T) SAT\nsolver because of the Boolean abstraction constructed over the input theory\nformula. By contrast, the theory-aware technique presented in this paper\nexposes the structure of theory literals to the DPLL(T) SAT solver's branching\nheuristic, thus enabling it to make much smarter decisions during its search\nthan otherwise. As a consequence, Z3str3 has better performance than its\ncompetitors.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 00:02:12 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Berzish", "Murphy", ""], ["Zheng", "Yunhui", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1704.07998", "submitter": "Thorsten Wissmann", "authors": "Samir Datta, Anish Mukherjee, Thomas Schwentick, Nils Vortmeier,\n  Thomas Zeume", "title": "A Strategy for Dynamic Programs: Start over and Muddle through", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 8,\n  2019) lmcs:5442", "doi": "10.23638/LMCS-15(2:12)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the setting of DynFO, dynamic programs update the stored result of a query\nwhenever the underlying data changes. This update is expressed in terms of\nfirst-order logic. We introduce a strategy for constructing dynamic programs\nthat utilises periodic computation of auxiliary data from scratch and the\nability to maintain a query for a limited number of change steps. We show that\nif some program can maintain a query for log n change steps after an\nAC$^1$-computable initialisation, it can be maintained by a first-order dynamic\nprogram as well, i.e., in DynFO. As an application, it is shown that decision\nand optimisation problems defined by monadic second-order (MSO) formulas are in\nDynFO, if only change sequences that produce graphs of bounded treewidth are\nallowed. To establish this result, a Feferman-Vaught-type composition theorem\nfor MSO is established that might be useful in its own right.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 07:51:09 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 12:28:52 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 09:16:50 GMT"}, {"version": "v4", "created": "Thu, 2 May 2019 16:03:54 GMT"}, {"version": "v5", "created": "Tue, 7 May 2019 11:22:27 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Datta", "Samir", ""], ["Mukherjee", "Anish", ""], ["Schwentick", "Thomas", ""], ["Vortmeier", "Nils", ""], ["Zeume", "Thomas", ""]]}, {"id": "1704.08055", "submitter": "Gerco van Heerdt", "authors": "Gerco van Heerdt and Matteo Sammartino and Alexandra Silva", "title": "Optimizing Automata Learning via Monads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automata learning has been successfully applied in the verification of\nhardware and software. The size of the automaton model learned is a bottleneck\nfor scalability, and hence optimizations that enable learning of compact\nrepresentations are important. This paper exploits monads, both as a\nmathematical structure and a programming construct, to design, prove correct,\nand implement a wide class of such optimizations. The former perspective on\nmonads allows us to develop a new algorithm and accompanying correctness\nproofs, building upon a general framework for automata learning based on\ncategory theory. The new algorithm is parametric on a monad, which provides a\nrich algebraic structure to capture non-determinism and other side-effects. We\nshow that our approach allows us to uniformly capture existing algorithms,\ndevelop new ones, and add optimizations. The latter perspective allows us to\neffortlessly translate the theory into practice: we provide a Haskell library\nimplementing our general framework, and we show experimental results for two\nspecific instances: non-deterministic and weighted automata.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 11:01:34 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 15:00:20 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 12:47:06 GMT"}, {"version": "v4", "created": "Fri, 1 Nov 2019 16:52:25 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["van Heerdt", "Gerco", ""], ["Sammartino", "Matteo", ""], ["Silva", "Alexandra", ""]]}, {"id": "1704.08086", "submitter": "EPTCS", "authors": "Pau Enrique Moliner (University of Edinburgh), Chris Heunen\n  (University of Edinburgh), Sean Tull (University of Oxford)", "title": "Space in Monoidal Categories", "comments": "In Proceedings QPL 2017, arXiv:1802.09737", "journal-ref": "EPTCS 266, 2018, pp. 399-410", "doi": "10.4204/EPTCS.266.25", "report-no": null, "categories": "math.CT cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The category of Hilbert modules may be interpreted as a naive quantum field\ntheory over a base space. Open subsets of the base space are recovered as\nidempotent subunits, which form a meet-semilattice in any firm braided monoidal\ncategory. There is an operation of restriction to an idempotent subunit: it is\na graded monad on the category, and has the universal property of algebraic\nlocalisation. Spacetime structure on the base space induces a closure operator\non the idempotent subunits. Restriction is then interpreted as spacetime\npropagation. This lets us study relativistic quantum information theory using\nmethods entirely internal to monoidal categories. As a proof of concept, we\nshow that quantum teleportation is only successfully supported on the\nintersection of Alice and Bob's causal future.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 12:59:32 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 20:01:23 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 03:55:17 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Moliner", "Pau Enrique", "", "University of Edinburgh"], ["Heunen", "Chris", "", "University of Edinburgh"], ["Tull", "Sean", "", "University of Oxford"]]}, {"id": "1704.08540", "submitter": "Thorsten Wissmann", "authors": "David Baelde and St\\'ephanie Delaune and Lucca Hirschi", "title": "A Reduced Semantics for Deciding Trace Equivalence", "comments": "Accepted for publication in LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (June 8,\n  2017) lmcs:3703", "doi": "10.23638/LMCS-13(2:8)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many privacy-type properties of security protocols can be modelled using\ntrace equivalence properties in suitable process algebras. It has been shown\nthat such properties can be decided for interesting classes of finite processes\n(i.e., without replication) by means of symbolic execution and constraint\nsolving. However, this does not suffice to obtain practical tools. Current\nprototypes suffer from a classical combinatorial explosion problem caused by\nthe exploration of many interleavings in the behaviour of processes.\nM\\\"odersheim et al. have tackled this problem for reachability properties using\npartial order reduction techniques. We revisit their work, generalize it and\nadapt it for equivalence checking. We obtain an optimisation in the form of a\nreduced symbolic semantics that eliminates redundant interleavings on the fly.\nThe obtained partial order reduction technique has been integrated in a tool\ncalled APTE. We conducted complete benchmarks showing dramatic improvements.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 12:46:18 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 12:59:01 GMT"}, {"version": "v3", "created": "Tue, 2 May 2017 09:44:05 GMT"}, {"version": "v4", "created": "Wed, 3 May 2017 08:26:16 GMT"}, {"version": "v5", "created": "Wed, 7 Jun 2017 16:59:57 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Baelde", "David", ""], ["Delaune", "St\u00e9phanie", ""], ["Hirschi", "Lucca", ""]]}, {"id": "1704.08637", "submitter": "J\\\"urgen Koslowski", "authors": "Sebastian Enqvist and Fatemeh Seifan and Yde Venema", "title": "An expressive completeness theorem for coalgebraic modal mu-calculi", "comments": "arXiv admin note: substantial text overlap with arXiv:1501.07215", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (July 3,\n  2017) lmcs:3756", "doi": "10.23638/LMCS-13(2:14)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalizing standard monadic second-order logic for Kripke models, we\nintroduce monadic second-order logic interpreted over coalgebras for an\narbitrary set functor. We then consider invariance under behavioral equivalence\nof MSO-formulas. More specifically, we investigate whether the coalgebraic\nmu-calculus is the bisimulation-invariant fragment of the monadic second-order\nlanguage for a given functor. Using automatatheoretic techniques and building\non recent results by the third author, we show that in order to provide such a\ncharacterization result it suffices to find what we call an adequate uniform\nconstruction for the coalgebraic type functor. As direct applications of this\nresult we obtain a partly new proof of the Janin-Walukiewicz Theorem for the\nmodal mu-calculus, avoiding the use of syntactic normal forms, and bisimulation\ninvariance results for the bag functor (graded modal logic) and all exponential\npolynomial functors (including the \"game functor\"). As a more involved\napplication, involving additional non-trivial ideas, we also derive a\ncharacterization theorem for the monotone modal mu-calculus, with respect to a\nnatural monadic second-order language for monotone neighborhood models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 16:06:19 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 18:09:04 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Enqvist", "Sebastian", ""], ["Seifan", "Fatemeh", ""], ["Venema", "Yde", ""]]}, {"id": "1704.08670", "submitter": "Niel de Beaudrap", "authors": "Niel de Beaudrap and Dominic Horsman", "title": "The ZX calculus is a language for surface code lattice surgery", "comments": "20 pages, many figures. Minor revisions. Accepted to Quantum Journal", "journal-ref": "Quantum 4, 218 (2020)", "doi": "10.22331/q-2020-01-09-218", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A leading choice of error correction for scalable quantum computing is the\nsurface code with lattice surgery. The basic lattice surgery operations, the\nmerging and splitting of logical qubits, act non-unitarily on the logical\nstates and are not easily captured by standard circuit notation. This raises\nthe question of how best to design, verify, and optimise protocols that use\nlattice surgery, in particular in architectures with complex resource\nmanagement issues. In this paper we demonstrate that the operations of the ZX\ncalculus -- a form of quantum diagrammatic reasoning based on bialgebras --\nmatch exactly the operations of lattice surgery. Red and green \"spider\" nodes\nmatch rough and smooth merges and splits, and follow the axioms of a dagger\nspecial associative Frobenius algebra. Some lattice surgery operations require\nnon-trivial correction operations, which are captured natively in the use of\nthe ZX calculus in the form of ensembles of diagrams. We give a first taste of\nthe power of the calculus as a language for lattice surgery by considering two\noperations (T gates and producing a CNOT ) and show how ZX diagram re-write\nrules give lattice surgery procedures for these operations that are novel,\nefficient, and highly configurable.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 17:33:52 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 21:55:25 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 16:54:53 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 15:49:30 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["de Beaudrap", "Niel", ""], ["Horsman", "Dominic", ""]]}, {"id": "1704.08887", "submitter": "Martin Zimmermann", "authors": "Sarah Winter and Martin Zimmermann", "title": "Finite-state Strategies in Delay Games (full version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is a finite-state strategy in a delay game? We answer this surprisingly\nnon-trivial question by presenting a very general framework that allows to\nremove delay: finite-state strategies exist for all winning conditions where\nthe resulting delay-free game admits a finite-state strategy. The framework is\napplicable to games whose winning condition is recognized by an automaton with\nan acceptance condition that satisfies a certain aggregation property. Our\nframework also yields upper bounds on the complexity of determining the winner\nof such delay games and upper bounds on the necessary lookahead to win the\ngame. In particular, we cover all previous results of that kind as special\ncases of our uniform approach.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 12:00:37 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 00:02:43 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 21:13:23 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 10:24:44 GMT"}, {"version": "v5", "created": "Fri, 13 Dec 2019 15:14:27 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Winter", "Sarah", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1704.08909", "submitter": "Francesco Ranzato", "authors": "Francesco Ranzato", "title": "A Constructive Framework for Galois Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract interpretation-based static analyses rely on abstract domains of\nprogram properties, such as intervals or congruences for integer variables.\nGalois connections (GCs) between posets provide the most widespread and useful\nformal tool for mathematically specifying abstract domains. Recently, Darais\nand Van Horn [2016] put forward a notion of constructive Galois connection for\nunordered sets (rather than posets), which allows to define abstract domains in\na so-called mechanized and calculational proof style and therefore enables the\nuse of proof assistants like Coq and Agda for automatically extracting verified\nalgorithms of static analysis. We show here that constructive GCs are\nisomorphic, in a precise and comprehensive meaning including sound abstract\nfunctions, to so-called partitioning GCs--an already known class of GCs which\nallows to cast standard set partitions as an abstract domain. Darais and Van\nHorn [2016] also provide a notion of constructive GC for posets, which we prove\nto be isomorphic to plain GCs and therefore lose their constructive attribute.\nDrawing on these findings, we put forward and advocate the use of purely\npartitioning GCs, a novel class of constructive abstract domains for a\nmechanized approach to abstract interpretation. We show that this class of\nabstract domains allows us to represent a set partition with more flexibility\nwhile retaining a constructive approach to Galois connections.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 12:58:01 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Ranzato", "Francesco", ""]]}, {"id": "1704.09026", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Juan Edi and Andr\\'es Viso and Eduardo Bonelli", "title": "Efficient Type Checking for Path Polymorphism", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.TYPES.2015.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A type system combining type application, constants as types, union types\n(associative, commutative and idempotent) and recursive types has recently been\nproposed for statically typing path polymorphism, the ability to define\nfunctions that can operate uniformly over recursively specified applicative\ndata structures. A typical pattern such functions resort to is $x\\,y$ which\ndecomposes a compound, in other words any applicative tree structure, into its\nparts. We study type-checking for this type system in two stages. First we\npropose algorithms for checking type equivalence and subtyping based on\ncoinductive characterizations of those relations. We then formulate a\nsyntax-directed presentation and prove its equivalence with the original one.\nThis yields a type-checking algorithm which unfortunately has exponential time\ncomplexity in the worst case. A second algorithm is then proposed, based on\nautomata techniques, which yields a polynomial-time type-checking algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 17:50:24 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Edi", "Juan", ""], ["Viso", "Andr\u00e9s", ""], ["Bonelli", "Eduardo", ""]]}]