[{"id": "1505.00061", "submitter": "Marcus Ramos", "authors": "Marcus Vin\\'icius Midena Ramos, Ruy J. G. B. de Queiroz", "title": "Context-Free Language Theory Formalization", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof assistants are software-based tools that are used in the mechanization\nof proof construction and validation in mathematics and computer science, and\nalso in certified program development. Different tools are being increasingly\nused in order to accelerate and simplify proof checking. Context-free language\ntheory is a well-established area of mathematics, relevant to computer science\nfoundations and technology. This proposal aims at formalizing parts of\ncontext-free language theory in the Coq proof assistant. This report presents\nthe underlying theory and general characteristics of proof assistants,\nincluding Coq itself, discusses its use in relevant formalization projects,\npresents the current status of the implementation, addresses related projects\nand the contributions of this work. The results obtained so far include the\nformalization of closure properties for context-free grammars (under union,\nconcatenation and closure) and the formalization of grammar simplification.\nGrammar simplification is a subject of high importance in computer language\nprocessing technology as well as in formal language theory, and the\nformalization refers to the fact that general context-free grammars generate\nlanguages that can be also generated by simpler and equivalent context-free\ngrammars. Namely, useless symbol elimination, inaccessible symbol elimination,\nunit rules elimination and empty rules elimination operations were described\nand proven correct with respect to the preservation of the language generated\nby the original grammar.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2015 00:27:18 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Ramos", "Marcus Vin\u00edcius Midena", ""], ["de Queiroz", "Ruy J. G. B.", ""]]}, {"id": "1505.00343", "submitter": "Aleks Kissinger", "authors": "Aleks Kissinger and David Quick", "title": "A first-order logic for string diagrams", "comments": "15 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Equational reasoning with string diagrams provides an intuitive means of\nproving equations between morphisms in a symmetric monoidal category. This can\nbe extended to proofs of infinite families of equations using a simple\ngraphical syntax called !-box notation. While this does greatly increase the\nproving power of string diagrams, previous attempts to go beyond equational\nreasoning have been largely ad hoc, owing to the lack of a suitable logical\nframework for diagrammatic proofs involving !-boxes. In this paper, we extend\nequational reasoning with !-boxes to a fully-fledged first order logic called\nwith conjunction, implication, and universal quantification over !-boxes. This\nlogic, called !L, is then rich enough to properly formalise an induction\nprinciple for !-boxes. We then build a standard model for !L and give an\nexample proof of a theorem for non-commutative bialgebras using !L, which is\nunobtainable by equational reasoning alone.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2015 13:26:47 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Kissinger", "Aleks", ""], ["Quick", "David", ""]]}, {"id": "1505.00478", "submitter": "Joerg Endrullis", "authors": "J\\\"org Endrullis, Hans Zantema", "title": "Proving Looping and Non-Looping Non-Termination by Finite Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new technique is presented to prove non-termination of term rewriting. The\nbasic idea is to find a non-empty regular language of terms that is closed\nunder rewriting and does not contain normal forms. It is automated by\nrepresenting the language by a tree automaton with a fixed number of states,\nand expressing the mentioned requirements in a SAT formula. Satisfiability of\nthis formula implies non-termination. Our approach succeeds for many examples\nwhere all earlier techniques fail, for instance for the S-rule from combinatory\nlogic.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2015 21:24:19 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Zantema", "Hans", ""]]}, {"id": "1505.00672", "submitter": "Aboubakr Achraf El Ghazi", "authors": "Aboubakr Achraf El Ghazi, Mana Taghdiri", "title": "Analyzing Alloy Formulas using an SMT Solver: A Case Study", "comments": "5th International Workshop on Automated Formal Methods (AFM), 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how Yices, a modern SAT Modulo theories solver, can be\nused to analyze the address-book problem expressed in Alloy, a first-order\nrelational logic with transitive closure. Current analysis of Alloy models - as\nperformed by the Alloy Analyzer - is based on SAT solving and thus, is done\nonly with respect to finitized types. Our analysis generalizes this approach by\ntaking advantage of the background theories available in Yices, and avoiding\ntype finitization when possible. Consequently, it is potentially capable of\nproving that an assertion is a tautology - a capability completely missing from\nthe Alloy Analyzer. This paper also reports on our experimental results that\ncompare the performance of our analysis to that of the Alloy Analyzer for\nvarious versions of the address book problem.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2015 15:14:13 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Ghazi", "Aboubakr Achraf El", ""], ["Taghdiri", "Mana", ""]]}, {"id": "1505.01098", "submitter": "Dusko Pavlovic", "authors": "Toshiki Kataoka and Dusko Pavlovic", "title": "Towards concept analysis in categories: limit inferior as algebra, limit\n  superior as coalgebra", "comments": "22 pages, 5 figures and 9 diagrams", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While computer programs and logical theories begin by declaring the concepts\nof interest, be it as data types or as predicates, network computation does not\nallow such global declarations, and requires *concept mining* and *concept\nanalysis* to extract shared semantics for different network nodes. Powerful\nsemantic analysis systems have been the drivers of nearly all paradigm shifts\non the web. In categorical terms, most of them can be described as\nbicompletions of enriched matrices, generalizing the Dedekind-MacNeille-style\ncompletions from posets to suitably enriched categories. Yet it has been well\nknown for more than 40 years that ordinary categories themselves in general do\nnot permit such completions. Armed with this new semantical view of\nDedekind-MacNeille completions, and of matrix bicompletions, we take another\nlook at this ancient mystery. It turns out that simple categorical versions of\nthe *limit superior* and *limit inferior* operations characterize a general\nnotion of Dedekind-MacNeille completion, that seems to be appropriate for\nordinary categories, and boils down to the more familiar enriched versions when\nthe limits inferior and superior coincide. This explains away the apparent gap\namong the completions of ordinary categories, and broadens the path towards\ncategorical concept mining and analysis, opened in previous work.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 18:02:20 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Kataoka", "Toshiki", ""], ["Pavlovic", "Dusko", ""]]}, {"id": "1505.01128", "submitter": "Joerg Endrullis", "authors": "J\\\"org Endrullis, Helle Hvid Hansen, Dimitri Hendriks, Andrew\n  Polonsky, Alexandra Silva", "title": "A Coinductive Framework for Infinitary Rewriting and Equational\n  Reasoning (Extended Version)", "comments": "arXiv admin note: substantial text overlap with arXiv:1306.6224", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coinductive framework for defining infinitary analogues of\nequational reasoning and rewriting in a uniform way. We define the relation\n=^infty, notion of infinitary equational reasoning, and ->^infty, the standard\nnotion of infinitary rewriting as follows:\n  =^infty := nu R. ( <-_root + ->_root + lift(R) )^*\n  ->^infty := mu R. nu S. ( ->_root + lift(R) )^* ; lift(S)\n  where\n  lift(R) := { (f(s_1,...,s_n), f(t_1,...,t_n)) | s_1 R t_1,...,s_n R t_n } +\nid ,\n  and where mu is the least fixed point operator and nu is the greatest fixed\npoint operator.\n  The setup captures rewrite sequences of arbitrary ordinal length, but it has\nneither the need for ordinals nor for metric convergence. This makes the\nframework especially suitable for formalizations in theorem provers.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 19:11:54 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Hansen", "Helle Hvid", ""], ["Hendriks", "Dimitri", ""], ["Polonsky", "Andrew", ""], ["Silva", "Alexandra", ""]]}, {"id": "1505.01326", "submitter": "EPTCS", "authors": "Satoshi Matsuoka (National Institute of Advanced Industrial Science\n  and Technology)", "title": "Strong Typed B\\\"ohm Theorem and Functional Completeness on the Linear\n  Lambda Calculus", "comments": "In Proceedings MSFP 2016, arXiv:1604.00384", "journal-ref": "EPTCS 207, 2016, pp. 1-22", "doi": "10.4204/EPTCS.207.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove a version of the typed B\\\"ohm theorem on the linear\nlambda calculus, which says, for any given types A and B, when two different\nclosed terms s1 and s2 of A and any closed terms u1 and u2 of B are given,\nthere is a term t such that t s1 is convertible to u1 and t s2 is convertible\nto u2. Several years ago, a weaker version of this theorem was proved, but the\nstronger version was open. As a corollary of this theorem, we prove that if A\nhas two different closed terms s1 and s2, then A is functionally complete with\nregard to s1 and s2. So far, it was only known that a few types are\nfunctionally complete.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 11:49:06 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 09:03:37 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Matsuoka", "Satoshi", "", "National Institute of Advanced Industrial Science\n  and Technology"]]}, {"id": "1505.01337", "submitter": "Julian Nagele", "authors": "Julian Nagele and Ren\\'e Thiemann", "title": "Certification of Confluence Proofs using CeTA", "comments": "5 pages, International Workshop on Confluence 2014", "journal-ref": "In Proceedings of the 3rd International Workshop on Confluence,\n  pages 19 - 23, 2014", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CeTA was originally developed as a tool for certifying termination proofs\nwhich have to be provided as certificates in the CPF-format. Its soundness is\nproven as part of IsaFoR, the Isabelle Formalization of Rewriting. By now, CeTA\ncan also be used for certifying confluence and non-confluence proofs. In this\nsystem description, we give a short overview on what kind of proofs are\nsupported, and what information has to be given in the certificates. As we will\nsee, only a small amount of information is required and so we hope that CSI\nwill not stay the only confluence tool which can produce certificates.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 12:21:52 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Nagele", "Julian", ""], ["Thiemann", "Ren\u00e9", ""]]}, {"id": "1505.01338", "submitter": "Thomas Sternagel", "authors": "Thomas Sternagel", "title": "KBCV 2.0 - Automatic Completion Experiments", "comments": "IWC 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the automatic mode of the new version of the\nKnuth-Bendix Completion Visualizer. The internally used data structures have\nbeen overhauled and the performance was dramatically improved by introducing\ncaching, parallelization, and term- indexing in the computation of critical\npairs and simplification. The new version is much faster and can complete three\nmore systems.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 12:28:58 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Sternagel", "Thomas", ""]]}, {"id": "1505.01358", "submitter": "Jakob Nordstr\\\"om", "authors": "Mladen Mik\\v{s}a and Jakob Nordstr\\\"om", "title": "A Generalized Method for Proving Polynomial Calculus Degree Lower Bounds", "comments": "Full-length version of paper to appear in Proceedings of the 30th\n  Annual Computational Complexity Conference (CCC '15), June 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of obtaining lower bounds for polynomial calculus (PC)\nand polynomial calculus resolution (PCR) on proof degree, and hence by\n[Impagliazzo et al. '99] also on proof size. [Alekhnovich and Razborov '03]\nestablished that if the clause-variable incidence graph of a CNF formula F is a\ngood enough expander, then proving that F is unsatisfiable requires high PC/PCR\ndegree. We further develop the techniques in [AR03] to show that if one can\n\"cluster\" clauses and variables in a way that \"respects the structure\" of the\nformula in a certain sense, then it is sufficient that the incidence graph of\nthis clustered version is an expander. As a corollary of this, we prove that\nthe functional pigeonhole principle (FPHP) formulas require high PC/PCR degree\nwhen restricted to constant-degree expander graphs. This answers an open\nquestion in [Razborov '02], and also implies that the standard CNF encoding of\nthe FPHP formulas require exponential proof size in polynomial calculus\nresolution. Thus, while Onto-FPHP formulas are easy for polynomial calculus, as\nshown in [Riis '93], both FPHP and Onto-PHP formulas are hard even when\nrestricted to bounded-degree expanders.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 13:34:47 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Mik\u0161a", "Mladen", ""], ["Nordstr\u00f6m", "Jakob", ""]]}, {"id": "1505.01620", "submitter": "Dieter Hutter", "authors": "Serge Autexier and Dieter Hutter", "title": "Structure Formation in Large Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structuring theories is one of the main approaches to reduce the\ncombinatorial explosion associated with reasoning and exploring large theories.\nIn the past we developed the notion of development graphs as a means to\nrepresent and maintain structured theories. In this paper we present a\nmethodology and a resulting implementation to reveal the hidden structure of\nflat theories by transforming them into detailed development graphs. We review\nour approach using plain TSTP-representations of MIZAR articles obtaining more\nstructured and also more concise theories.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 08:16:19 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Autexier", "Serge", ""], ["Hutter", "Dieter", ""]]}, {"id": "1505.01629", "submitter": "Christoph Benzmueller", "authors": "Max Wisniewski and Alexander Steen and Christoph Benzm\\\"uller", "title": "LeoPARD --- A Generic Platform for the Implementation of Higher-Order\n  Reasoners", "comments": "6 pages, to appear in the proceedings of CICM'2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LeoPARD supports the implementation of knowledge representation and reasoning\ntools for higher-order logic(s). It combines a sophisticated data structure\nlayer (polymorphically typed {\\lambda}-calculus with nameless spine notation,\nexplicit substitutions, and perfect term sharing) with an ambitious multi-agent\nblackboard architecture (supporting prover parallelism at the term, clause, and\nsearch level). Further features of LeoPARD include a parser for all TPTP\ndialects, a command line interpreter, and generic means for the integration of\nexternal reasoners.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 08:54:19 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Wisniewski", "Max", ""], ["Steen", "Alexander", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "1505.01662", "submitter": "Lawrence C. Paulson", "authors": "Lawrence C. Paulson", "title": "A Formalisation of Finite Automata using Hereditarily Finite Sets", "comments": "Accepted to CADE-25 (International Conference on Automated\n  Deduction), Berlin, August 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hereditarily finite (HF) set theory provides a standard universe of sets, but\nwith no infinite sets. Its utility is demonstrated through a formalisation of\nthe theory of regular languages and finite automata, including the\nMyhill-Nerode theorem and Brzozowski's minimisation algorithm. The states of an\nautomaton are HF sets, possibly constructed by product, sum, powerset and\nsimilar operations.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 10:58:02 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Paulson", "Lawrence C.", ""]]}, {"id": "1505.01682", "submitter": "Evgenii Kotelnikov", "authors": "Evgenii Kotelnikov, Laura Kov\\'acs and Andrei Voronkov", "title": "A First Class Boolean Sort in First-Order Theorem Proving and TPTP", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-20615-8_5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support reasoning about properties of programs operating with boolean\nvalues one needs theorem provers to be able to natively deal with the boolean\nsort. This way, program properties can be translated to first-order logic and\ntheorem provers can be used to prove program properties efficiently. However,\nin the TPTP language, the input language of automated first-order theorem\nprovers, the use of the boolean sort is limited compared to other sorts, thus\nhindering the use of first-order theorem provers in program analysis and\nverification. In this paper, we present an extension FOOL of many-sorted\nfirst-order logic, in which the boolean sort is treated as a first-class sort.\nBoolean terms are indistinguishable from formulas and can appear as arguments\nto functions. In addition, FOOL contains if-then-else and let-in constructs. We\ndefine the syntax and semantics of FOOL and its model-preserving translation to\nfirst-order logic. We also introduce a new technique of dealing with boolean\nsorts in superposition-based theorem provers. Finally, we discuss how the TPTP\nlanguage can be changed to support FOOL.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 12:35:58 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Kotelnikov", "Evgenii", ""], ["Kov\u00e1cs", "Laura", ""], ["Voronkov", "Andrei", ""]]}, {"id": "1505.01695", "submitter": "Barbara K\\\"onig", "authors": "H.J. Sander Bruggink and Barbara K\\\"onig and Dennis Nolte and Hans\n  Zantema", "title": "Proving Termination of Graph Transformation Systems using Weighted Type\n  Graphs over Semirings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce techniques for proving uniform termination of graph\ntransformation systems, based on matrix interpretations for string rewriting.\nWe generalize this technique by adapting it to graph rewriting instead of\nstring rewriting and by generalizing to ordered semirings. In this way we\nobtain a framework which includes the tropical and arctic type graphs\nintroduced in a previous paper and a new variant of arithmetic type graphs.\nThese type graphs can be used to assign weights to graphs and to show that\nthese weights decrease in every rewriting step in order to prove termination.\nWe present an example involving counters and discuss the implementation in the\ntool Grez.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 13:25:26 GMT"}, {"version": "v2", "created": "Fri, 8 May 2015 08:07:01 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Bruggink", "H. J. Sander", ""], ["K\u00f6nig", "Barbara", ""], ["Nolte", "Dennis", ""], ["Zantema", "Hans", ""]]}, {"id": "1505.01964", "submitter": "Arne Meier", "authors": "Andreas Krebs and Arne Meier and Jonni Virtema", "title": "A Team Based Variant of CTL", "comments": "TIME 2015 conference version, modified title and motiviation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two variants of computation tree logic CTL based on team\nsemantics: an asynchronous one and a synchronous one. For both variants we\ninvestigate the computational complexity of the satisfiability as well as the\nmodel checking problem. The satisfiability problem is shown to be\nEXPTIME-complete. Here it does not matter which of the two semantics are\nconsidered. For model checking we prove a PSPACE-completeness for the\nsynchronous case, and show P-completeness for the asynchronous case.\nFurthermore we prove several interesting fundamental properties of both\nsemantics.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 09:25:41 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 12:15:40 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Krebs", "Andreas", ""], ["Meier", "Arne", ""], ["Virtema", "Jonni", ""]]}, {"id": "1505.02075", "submitter": "Marianna Nicolosi Asmundo", "authors": "Domenico Cantone, Cristiano Longo, Marianna Nicolosi-Asmundo, Daniele\n  Francesco Santamaria", "title": "Web ontology representation and reasoning via fragments of set theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use results from Computable Set Theory as a means to\nrepresent and reason about description logics and rule languages for the\nsemantic web.\n  Specifically, we introduce the description logic $\\mathcal{DL}\\langle\n4LQS^R\\rangle(\\D)$--admitting features such as min/max cardinality constructs\non the left-hand/right-hand side of inclusion axioms, role chain axioms, and\ndatatypes--which turns out to be quite expressive if compared with\n$\\mathcal{SROIQ}(\\D)$, the description logic underpinning the Web Ontology\nLanguage OWL. Then we show that the consistency problem for\n$\\mathcal{DL}\\langle 4LQS^R\\rangle(\\D)$-knowledge bases is decidable by\nreducing it, through a suitable translation process, to the satisfiability\nproblem of the stratified fragment $4LQS^R$ of set theory, involving variables\nof four sorts and a restricted form of quantification. We prove also that,\nunder suitable not very restrictive constraints, the consistency problem for\n$\\mathcal{DL}\\langle 4LQS^R\\rangle(\\D)$-knowledge bases is\n\\textbf{NP}-complete. Finally, we provide a $4LQS^R$-translation of rules\nbelonging to the Semantic Web Rule Language (SWRL).\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 16:00:44 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Cantone", "Domenico", ""], ["Longo", "Cristiano", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""]]}, {"id": "1505.02091", "submitter": "Ale\\v{s} Bizjak", "authors": "Arno Pauly, Willem Fouch\\'e, George Davie", "title": "Weihrauch-completeness for layerwise computability", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (May 22,\n  2018) lmcs:4519", "doi": "10.23638/LMCS-14(2:11)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the notion of being Weihrauch-complete for layerwise\ncomputability and provide several natural examples related to complex\noscillations, the law of the iterated logarithm and Birkhoff's theorem. We also\nconsider hitting time operators, which share the Weihrauch degree of the former\nexamples but fail to be layerwise computable.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 16:26:07 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 16:14:53 GMT"}, {"version": "v3", "created": "Sun, 18 Feb 2018 14:15:38 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2018 14:42:54 GMT"}, {"version": "v5", "created": "Sun, 20 May 2018 09:15:39 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Pauly", "Arno", ""], ["Fouch\u00e9", "Willem", ""], ["Davie", "George", ""]]}, {"id": "1505.02140", "submitter": "Umair  Siddique", "authors": "Umair Siddique, Osman Hasan and Sofi\\`ene Tahar", "title": "Towards the Formalization of Fractional Calculus in Higher-Order Logic", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractional calculus is a generalization of classical theories of integration\nand differentiation to arbitrary order (i.e., real or complex numbers). In the\nlast two decades, this new mathematical modeling approach has been widely used\nto analyze a wide class of physical systems in various fields of science and\nengineering. In this paper, we describe an ongoing project which aims at\nformalizing the basic theories of fractional calculus in the HOL Light theorem\nprover. Mainly, we present the motivation and application of such formalization\nefforts, a roadmap to achieve our goals, current status of the project and\nfuture milestones.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 19:13:27 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Siddique", "Umair", ""], ["Hasan", "Osman", ""], ["Tahar", "Sofi\u00e8ne", ""]]}, {"id": "1505.02222", "submitter": "Joshua N. Cooper", "authors": "Joshua Cooper, Ralph Overstreet", "title": "Coloring so that no Pythagorean Triple is Monochromatic", "comments": "14 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:0809.3478", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of the \"partition regularity\" of the Pythagorean\nequation a^2+b^2=c^2; in particular, can the natural numbers be assigned a\n2-coloring, so that no Pythagorean triple (i.e., a solution to the equation) is\nmonochromatic? We prove that the hypergraph of Pythagorean triples can contain\nno Steiner triple systems, a natural obstruction to 2-colorability. Then, after\ntransforming the question into one about 3-CNF satisfiability and applying some\nreductions, a SAT solver is used to find a 2-coloring for {1,...,7664}. Work\ncontinues as we seek to improve the reductions and extend the computation.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 01:26:40 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Cooper", "Joshua", ""], ["Overstreet", "Ralph", ""]]}, {"id": "1505.02318", "submitter": "Oliver Kullmann", "authors": "Oliver Kullmann and Xishun Zhao", "title": "Parameters for minimal unsatisfiability: Smarandache primitive numbers\n  and full clauses", "comments": "19 pages; second version with more explanations and examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a new bridge between propositional logic and elementary number\ntheory. The main objects are \"minimally unsatisfiable clause-sets\", short\n\"MUs\", unsatisfiable conjunctive normal forms rendered satisfiable by\nelimination of any clause. In other words, irredundant coverings of the boolean\nhypercube by subcubes. The main parameter for MUs is the \"deficiency\" k, the\ndifference between the number of clauses and the number of variables (the\ndifference between the number of elements in the covering and the dimension of\nthe hypercube), and the fundamental fact is that k >= 1 holds.\n  A \"full clause\" in an MU contains all variables (corresponding to a singleton\nin the covering). We show the lower bound S_2(k) <= FCM(k), where FCM(k) is the\nmaximal number of full clauses in MUs of deficiency k, while S_2(k) is the\nsmallest n such that 2^k divides n!.\n  The proof rests on two methods: On the logic-combinatorial side, applying\nsubsumption resolution and its inverse, a fundamental method since Boole in\n1854 introduced the \"expansion method\". On the arithmetical side, analysing\ncertain recursions, combining an application-specific recursion with a\nrecursion from the field of meta-Fibonacci sequences (indeed S_2 equals twice\nthe Conolly sequence).\n  A further tool is the consideration of unsatisfiable \"hitting clause-sets\"\n(UHITs), special cases of MUs, which correspond to the partitions of the\nboolean hypercube by subcubes; they are also known as orthogonal or disjoint\nDNF tautologies. We actually show the sharper lower bound S_2(k) <= FCH(k),\nwhere FCH(k) is the maximal number of full clauses in UHITs of deficiency k. We\nconjecture that for all k holds S_2(k) = FCH(k), which would establish a\nsurprising connection between the extremal combinatorics of (un)satisfiability\nand elementary number theory.\n  We apply the lower bound to analyse the structure of MUs and UHITs.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 21:10:15 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 01:30:50 GMT"}], "update_date": "2015-07-09", "authors_parsed": [["Kullmann", "Oliver", ""], ["Zhao", "Xishun", ""]]}, {"id": "1505.02371", "submitter": "Oliver Kullmann", "authors": "Oliver Kullmann and Joao Marques-Silva", "title": "Computing maximal autarkies with few and simple oracle queries", "comments": "18 pages; second version with editorial changes, to appear in LNCS\n  for Theory and Applications of Satisfiability Testing - SAT 2015", "journal-ref": "LNCS 9340, pages 138-155, 2015", "doi": "10.1007/978-3-319-24318-4_11", "report-no": null, "categories": "cs.LO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the algorithmic task of computing a maximal autarky for a\nclause-set F, i.e., a partial assignment which satisfies every clause of F it\ntouches, and where this property is destroyed by adding any non-empty set of\nfurther assignments. We employ SAT solvers as oracles, using various\ncapabilities. Using the standard SAT oracle, log_2(n(F)) oracle calls suffice,\nwhere n(F) is the number of variables, but the drawback is that (translated)\ncardinality constraints are employed, which makes this approach less efficient\nin practice. Using an extended SAT oracle, motivated by the capabilities of\nmodern SAT solvers, we show how to compute maximal autarkies with 2 n(F)^{1/2}\nsimpler oracle calls. This novel algorithm combines the previous two main\napproaches, based on the autarky-resolution duality and on SAT translations.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 11:36:54 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2015 13:09:47 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Kullmann", "Oliver", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1505.02408", "submitter": "Vasco Manquinho", "authors": "Miguel Neves, In\\^es Lynce and Vasco Manquinho", "title": "DistMS: A Non-Portfolio Distributed Solver for Maximum Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most successful parallel SAT and MaxSAT solvers follow a portfolio\napproach, where each thread applies a different algorithm (or the same\nalgorithm configured differently) to solve a given problem instance. The main\ngoal of building a portfolio is to diversify the search process being carried\nout by each thread. As soon as one thread finishes, the instance can be deemed\nsolved. In this paper we present a new open source distributed solver for\nMaxSAT solving that addresses two issues commonly found in multicore parallel\nsolvers, namely memory contention and scalability. Preliminary results show\nthat our non-portfolio distributed MaxSAT solver outperforms its sequential\nversion and is able to solve more instances as the number of processes\nincreases.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 16:55:42 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Neves", "Miguel", ""], ["Lynce", "In\u00eas", ""], ["Manquinho", "Vasco", ""]]}, {"id": "1505.02444", "submitter": "Joanna Ochremiak", "authors": "Filip Mazowiecki, Joanna Ochremiak, Adam Witkowski", "title": "Eliminating Recursion from Monadic Datalog Programs on Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of eliminating recursion from monadic datalog programs\non trees with an infinite set of labels. We show that the boundedness problem,\ni.e., determining whether a datalog program is equivalent to some nonrecursive\none is undecidable but the decidability is regained if the descendant relation\nis disallowed. Under similar restrictions we obtain decidability of the problem\nof equivalence to a given nonrecursive program. We investigate the connection\nbetween these two problems in more detail.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 21:47:29 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Mazowiecki", "Filip", ""], ["Ochremiak", "Joanna", ""], ["Witkowski", "Adam", ""]]}, {"id": "1505.02637", "submitter": "Peizun Liu", "authors": "Peizun Liu and Thomas Wahl", "title": "Unbounded-Thread Reachability via Symbolic Execution and Loop\n  Acceleration (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to parameterized reachability for communicating\nfinite-state threads that formulates the analysis as a satisfiability problem.\nIn addition to the unbounded number of threads, the main challenge for\nSAT/SMT-based reachability methods is the existence of unbounded loops in the\nprogram executed by a thread. We show in this paper how simple loops can be\naccelerated without approximation into Presburger arithmetic constraints. The\nconstraints are obtained via symbolic execution and are satisfiable exactly if\nthe given program state is reachable. We summarize loops nested inside other\nloops using recurrence relations derived from the inner loop's acceleration.\nThis summary abstracts the loop iteration parameter and may thus\noverapproximate. An advantage of our symbolic approach is that the process of\nbuilding the Presburger formulas may instantly reveal their unsatisfiability,\nbefore any arithmetic has been performed. We demonstrate the power of this\ntechnique for proving and refuting safety properties of unbounded-thread\nprograms and other infinite-state transition systems.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 14:28:51 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Liu", "Peizun", ""], ["Wahl", "Thomas", ""]]}, {"id": "1505.02648", "submitter": "Waqar  Ahmed", "authors": "Waqar Ahmed and Osman Hasan", "title": "Towards Formal Fault Tree Analysis using Theorem Proving", "comments": "16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault Tree Analysis (FTA) is a dependability analysis technique that has been\nwidely used to predict reliability, availability and safety of many complex\nengineering systems. Traditionally, these FTA-based analyses are done using\npaper-and-pencil proof methods or computer simulations, which cannot ascertain\nabsolute correctness due to their inherent limitations. As a complementary\napproach, we propose to use the higher-order-logic theorem prover HOL4 to\nconduct the FTA-based analysis of safety-critical systems where accuracy of\nfailure analysis is a dire need. In particular, the paper presents a\nhigher-order-logic formalization of generic Fault Tree gates, i.e., AND, OR,\nNAND, NOR, XOR and NOT and the formal verification of their failure probability\nexpressions. Moreover, we have formally verified the generic probabilistic\ninclusion-exclusion principle, which is one of the foremost requirements for\nconducting the FTA-based failure analysis of any given system. For illustration\npurposes, we conduct the FTA-based failure analysis of a solar array that is\nused as the main source of power for the Dong Fang Hong-3 (DFH-3) satellite.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 05:14:08 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Ahmed", "Waqar", ""], ["Hasan", "Osman", ""]]}, {"id": "1505.02651", "submitter": "EPTCS", "authors": "Brendan Fong, Hugo Nava-Kopp", "title": "Additive monotones for resource theories of parallel-combinable\n  processes with discarding", "comments": "In Proceedings QPL 2015, arXiv:1511.01181", "journal-ref": "EPTCS 195, 2015, pp. 170-178", "doi": "10.4204/EPTCS.195.13", "report-no": null, "categories": "cs.LO cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A partitioned process theory, as defined by Coecke, Fritz, and Spekkens, is a\nsymmetric monoidal category together with an all-object-including symmetric\nmonoidal subcategory. We think of the morphisms of this category as processes,\nand the morphisms of the subcategory as those processes that are freely\nexecutable. Via a construction we refer to as parallel-combinable processes\nwith discarding, we obtain from this data a partially ordered monoid on the set\nof processes, with f > g if one can use the free processes to construct g from\nf. The structure of this partial order can then be probed using additive\nmonotones: order-preserving monoid homomorphisms with values in the real\nnumbers under addition. We first characterise these additive monotones in terms\nof the corresponding partitioned process theory.\n  Given enough monotones, we might hope to be able to reconstruct the order on\nthe monoid. If so, we say that we have a complete family of monotones. In\ngeneral, however, when we require our monotones to be additive monotones, such\nfamilies do not exist or are hard to compute. We show the existence of complete\nfamilies of additive monotones for various partitioned process theories based\non the category of finite sets, in order to shed light on the way such families\ncan be constructed.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 19:02:24 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 01:43:12 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Fong", "Brendan", ""], ["Nava-Kopp", "Hugo", ""]]}, {"id": "1505.02655", "submitter": "Anton\\'in Ku\\v{c}era", "authors": "Tomas Brazdil, Stefan Kiefer, Antonin Kucera, Petr Novotny", "title": "Long-Run Average Behaviour of Probabilistic Vector Addition Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the pattern frequency vector for runs in probabilistic Vector\nAddition Systems with States (pVASS). Intuitively, each configuration of a\ngiven pVASS is assigned one of finitely many patterns, and every run can thus\nbe seen as an infinite sequence of these patterns. The pattern frequency vector\nassigns to each run the limit of pattern frequencies computed for longer and\nlonger prefixes of the run. If the limit does not exist, then the vector is\nundefined. We show that for one-counter pVASS, the pattern frequency vector is\ndefined and takes only finitely many values for almost all runs. Further, these\nvalues and their associated probabilities can be approximated up to an\narbitrarily small relative error in polynomial time. For stable two-counter\npVASS, we show the same result, but we do not provide any upper complexity\nbound. As a byproduct of our study, we discover counterexamples falsifying some\nclassical results about stochastic Petri nets published in the~80s.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 14:58:39 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 13:05:56 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Brazdil", "Tomas", ""], ["Kiefer", "Stefan", ""], ["Kucera", "Antonin", ""], ["Novotny", "Petr", ""]]}, {"id": "1505.03273", "submitter": "Swen Jacobs", "authors": "Simon Au{\\ss}erlechner and Swen Jacobs and Ayrat Khalimov", "title": "Tight Cutoffs for Guarded Protocols with Fairness", "comments": "Accepted for publication at VMCAI 2016. Extended version, revised\n  after conference reviews", "journal-ref": "VMCAI 2016, LNCS 9583, pages 476-494", "doi": "10.1007/978-3-662-49122-5_23", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guarded protocols were introduced in a seminal paper by Emerson and Kahlon\n(2000), and describe systems of processes whose transitions are enabled or\ndisabled depending on the existence of other processes in certain local states.\nWe study parameterized model checking and synthesis of guarded protocols, both\naiming at formal correctness arguments for systems with any number of\nprocesses. Cutoff results reduce reasoning about systems with an arbitrary\nnumber of processes to systems of a determined, fixed size. Our work stems from\nthe observation that existing cutoff results for guarded protocols i) are\nrestricted to closed systems, and ii) are of limited use for liveness\nproperties because reductions do not preserve fairness. We close these gaps and\nobtain new cutoff results for open systems with liveness properties under\nfairness assumptions. Furthermore, we obtain cutoffs for the detection of\nglobal and local deadlocks, which are of paramount importance in synthesis.\nFinally, we prove tightness or asymptotic tightness for the new cutoffs.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 08:34:22 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 14:33:28 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Au\u00dferlechner", "Simon", ""], ["Jacobs", "Swen", ""], ["Khalimov", "Ayrat", ""]]}, {"id": "1505.03340", "submitter": "Tomas Balyo", "authors": "Tomas Balyo, Peter Sanders, Carsten Sinz", "title": "HordeSat: A Massively Parallel Portfolio SAT Solver", "comments": "Accepted for SAT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple yet successful approach to parallel satisfiability (SAT) solving is\nto run several different (a portfolio of) SAT solvers on the input problem at\nthe same time until one solver finds a solution. The SAT solvers in the\nportfolio can be instances of a single solver with different configuration\nsettings. Additionally the solvers can exchange information usually in the form\nof clauses. In this paper we investigate whether this approach is applicable in\nthe case of massively parallel SAT solving. Our solver is intended to run on\nclusters with thousands of processors, hence the name HordeSat. HordeSat is a\nfully distributed portfolio-based SAT solver with a modular design that allows\nit to use any SAT solver that implements a given interface. HordeSat has a\ndecentralized design and features hierarchical parallelism with interleaved\ncommunication and search. We experimentally evaluated it using all the\nbenchmark problems from the application tracks of the 2011 and 2014\nInternational SAT Competitions. The experiments demonstrate that HordeSat is\nscalable up to hundreds or even thousands of processors achieving significant\nspeedups especially for hard instances.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 11:52:25 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2015 14:01:14 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Balyo", "Tomas", ""], ["Sanders", "Peter", ""], ["Sinz", "Carsten", ""]]}, {"id": "1505.03635", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Claudia Faggian, Benoit Valiron, Akira Yoshimizu", "title": "Parallelism and Synchronization in an Infinitary Context (Long Version)", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multitoken interaction machines in the context of a very expressive\nlogical system with exponentials, fixpoints and synchronization. The advantage\nof such machines is to provide models in the style of the Geometry of\nInteraction, i.e., an interactive semantics which is close to low-level\nimplementation. On the one hand, we prove that despite the inherent complexity\nof the framework, interaction is guaranteed to be deadlock free. On the other\nhand, the resulting logical system is powerful enough to embed PCF and to\nadequately model its behaviour, both when call-by-name and when call-by-value\nevaluation are considered. This is not the case for single-token stateless\ninteractive machines.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 07:01:00 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2015 01:06:59 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Faggian", "Claudia", ""], ["Valiron", "Benoit", ""], ["Yoshimizu", "Akira", ""]]}, {"id": "1505.03638", "submitter": "Ugo Dal Lago", "authors": "Rapha\\\"elle Crubill\\'e, Ugo Dal Lago", "title": "Metric Reasoning about $\\lambda$-Terms: the Affine Case (Long Version)", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terms of Church's $\\lambda$-calculus can be considered equivalent along many\ndifferent definitions, but context equivalence is certainly the most direct and\nuniversally accepted one. If the underlying calculus becomes probabilistic,\nhowever, equivalence is too discriminating: terms which have totally unrelated\nbehaviours are treated the same as terms which behave very similarly. We study\nthe problem of evaluating the distance between affine $\\lambda$-terms. The most\nnatural definition for it, namely a natural generalisation of context\nequivalence, is shown to be characterised by a notion of trace distance, and to\nbe bounded from above by a coinductively defined distance based on the\nKantorovich metric on distributions. A different, again fully-abstract,\ntuple-based notion of trace distance is shown to be able to handle nontrivial\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 07:13:58 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Crubill\u00e9", "Rapha\u00eblle", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "1505.03791", "submitter": "Claudio Sacerdoti Coen", "authors": "Beniamino Accattoli, Claudio Sacerdoti Coen", "title": "On the Relative Usefulness of Fireballs", "comments": "Technical report for the LICS 2015 submission with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In CSL-LICS 2014, Accattoli and Dal Lago showed that there is an\nimplementation of the ordinary (i.e. strong, pure, call-by-name)\n$\\lambda$-calculus into models like RAM machines which is polynomial in the\nnumber of $\\beta$-steps, answering a long-standing question. The key ingredient\nwas the use of a calculus with useful sharing, a new notion whose complexity\nwas shown to be polynomial, but whose implementation was not explored. This\npaper, meant to be complementary, studies useful sharing in a call-by-value\nscenario and from a practical point of view. We introduce the Fireball\nCalculus, a natural extension of call-by-value to open terms for which the\nproblem is as hard as for the ordinary lambda-calculus. We present three\nresults. First, we adapt the solution of Accattoli and Dal Lago, improving the\nmeta-theory of useful sharing. Then, we refine the picture by introducing the\nGLAMoUr, a simple abstract machine implementing the Fireball Calculus extended\nwith useful sharing. Its key feature is that usefulness of a step is\ntested---surprisingly---in constant time. Third, we provide a further\noptimization that leads to an implementation having only a linear overhead with\nrespect to the number of $\\beta$-steps.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 16:39:51 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Coen", "Claudio Sacerdoti", ""]]}, {"id": "1505.03950", "submitter": "Jie Fan", "authors": "Jie Fan", "title": "Logics of Strong Noncontingency", "comments": "28 pages", "journal-ref": "Notre Dame J. Formal Logic 60, no. 3 (2019), 407-435", "doi": "10.1215/00294527-2019-0010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by Hintikka's treatment of question embedding verbs in [8] and the\nvariations of noncontingency operator, we propose a logic with strong\nnoncontingency operator $\\blacktriangle$ as the only primitive modality. A\nproposition is strongly noncontingent, if no matter whether it is true or\nfalse, it does it necessarily; otherwise, it is weakly contingent. This logic\nis not a normal modal logic, since\n$\\blacktriangle(\\phi\\to\\psi)\\to(\\blacktriangle\\phi\\to\\blacktriangle\\psi)$ is\ninvalid. We compare the relative expressivity of this logic and other logics,\nsuch as standard modal logic, noncontingency logic, and logic of essence and\naccident, and investigate its frame definability. Apart from these results, we\nalso propose a suitable notion of bisimulation for the logic of strong\nnoncontingency, based on which we characterize this logic within modal logic\nand within first-order logic. We also axiomatize the logic of strong\nnoncontingency over various frame classes. Our work is also related to the\ntreatment of agreement operator in [10].\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 03:14:54 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Fan", "Jie", ""]]}, {"id": "1505.04216", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli and Michael Benedikt", "title": "Finite Open-World Query Answering with Number Restrictions (Extended\n  Version)", "comments": "59 pages. To appear in LICS 2015. Extended version including proofs", "journal-ref": null, "doi": "10.1109/LICS.2015.37", "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-world query answering is the problem of deciding, given a set of facts,\nconjunction of constraints, and query, whether the facts and constraints imply\nthe query. This amounts to reasoning over all instances that include the facts\nand satisfy the constraints. We study finite open-world query answering (FQA),\nwhich assumes that the underlying world is finite and thus only considers the\nfinite completions of the instance. The major known decidable cases of FQA\nderive from the following: the guarded fragment of first-order logic, which can\nexpress referential constraints (data in one place points to data in another)\nbut cannot express number restrictions such as functional dependencies; and the\nguarded fragment with number restrictions but on a signature of arity only two.\nIn this paper, we give the first decidability results for FQA that combine both\nreferential constraints and number restrictions for arbitrary signatures: we\nshow that, for unary inclusion dependencies and functional dependencies, the\nfiniteness assumption of FQA can be lifted up to taking the finite implication\nclosure of the dependencies. Our result relies on new techniques to construct\nfinite universal models of such constraints, for any bound on the maximal query\nsize.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 22:56:35 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Amarilli", "Antoine", ""], ["Benedikt", "Michael", ""]]}, {"id": "1505.04324", "submitter": "Jeremy Avigad", "authors": "Leonardo de Moura, Jeremy Avigad, Soonho Kong, Cody Roux", "title": "Elaboration in Dependent Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be usable in practice, interactive theorem provers need to provide\nconvenient and efficient means of writing expressions, definitions, and proofs.\nThis involves inferring information that is often left implicit in an ordinary\nmathematical text, and resolving ambiguities in mathematical expressions. We\nrefer to the process of passing from a quasi-formal and partially-specified\nexpression to a completely precise formal one as elaboration. We describe an\nelaboration algorithm for dependent type theory that has been implemented in\nthe Lean theorem prover. Lean's elaborator supports higher-order unification,\ntype class inference, ad hoc overloading, insertion of coercions, the use of\ntactics, and the computational reduction of terms. The interactions between\nthese components are subtle and complex, and the elaboration algorithm has been\ncarefully designed to balance efficiency and usability. We describe the central\ndesign goals, and the means by which they are achieved.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 20:32:28 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2015 15:55:52 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["de Moura", "Leonardo", ""], ["Avigad", "Jeremy", ""], ["Kong", "Soonho", ""], ["Roux", "Cody", ""]]}, {"id": "1505.04330", "submitter": "Chris Heunen", "authors": "Chris Heunen and Martti Karvonen", "title": "Reversible monadic computing", "comments": "19 pages", "journal-ref": "Proceedings MFPS, Electronic Notes in Theoretical Computer Science\n  319:217--237, 2015", "doi": "10.1016/j.entcs.2015.12.014", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend categorical semantics of monadic programming to reversible\ncomputing, by considering monoidal closed dagger categories: the dagger gives\nreversibility, whereas closure gives higher-order expressivity. We demonstrate\nthat Frobenius monads model the appropriate notion of coherence between the\ndagger and closure by reinforcing Cayley's theorem; by proving that effectful\ncomputations (Kleisli morphisms) are reversible precisely when the monad is\nFrobenius; by characterizing the largest reversible subcategory of\nEilenberg-Moore algebras; and by identifying the latter algebras as\nmeasurements in our leading example of quantum computing. Strong Frobenius\nmonads are characterized internally by Frobenius monoids.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 21:55:54 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Heunen", "Chris", ""], ["Karvonen", "Martti", ""]]}, {"id": "1505.04365", "submitter": "Joao Marques-Silva", "authors": "M. Fareed Arif, Carlos Menc\\'ia, and Joao Marques-Silva", "title": "Efficient MUS Enumeration of Horn Formulae with Applications to Axiom\n  Pinpointing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enumeration of minimal unsatisfiable subsets (MUSes) finds a growing\nnumber of practical applications, that includes a wide range of diagnosis\nproblems. As a concrete example, the problem of axiom pinpointing in the EL\nfamily of description logics (DLs) can be modeled as the enumeration of the\ngroup-MUSes of Horn formulae. In turn, axiom pinpointing for the EL family of\nDLs finds important applications, such as debugging medical ontologies, of\nwhich SNOMED CT is the best known example. The main contribution of this paper\nis to develop an efficient group-MUS enumerator for Horn formulae, HGMUS, that\nfinds immediate application in axiom pinpointing for the EL family of DLs. In\nthe process of developing HGMUS, the paper also identifies performance\nbottlenecks of existing solutions. The new algorithm is shown to outperform all\nalternative approaches when the problem domain targeted by group-MUS\nenumeration of Horn formulae is axiom pinpointing for the EL family of DLs,\nwith a representative suite of examples taken from different medical\nontologies.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2015 07:24:38 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Arif", "M. Fareed", ""], ["Menc\u00eda", "Carlos", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1505.04409", "submitter": "Abhishek Udupa", "authors": "Rajeev Alur, Mukund Raghothaman, Christos Stergiou, Stavros Tripakis\n  and Abhishek Udupa", "title": "Automatic Completion of Distributed Protocols with Symmetry", "comments": "Full version of paper presented at CAV 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed protocol is typically modeled as a set of communicating\nprocesses, where each process is described as an extended state machine along\nwith fairness assumptions, and its correctness is specified using safety and\nliveness requirements. Designing correct distributed protocols is a challenging\ntask. Aimed at simplifying this task, we allow the designer to leave some of\nthe guards and updates to state variables in the description of extended state\nmachines as unknown functions. The protocol completion problem then is to find\ninterpretations for these unknown functions while guaranteeing correctness. In\nmany distributed protocols, process behaviors are naturally symmetric, and\nthus, synthesized expressions are further required to obey symmetry\nconstraints. Our counterexample-guided synthesis algorithm consists of\nrepeatedly invoking two phases. In the first phase, candidates for unknown\nexpressions are generated using the SMT solver Z3. This phase requires\ncarefully orchestrating constraints to enforce the desired symmetry in\nread/write accesses. In the second phase, the resulting completed protocol is\nchecked for correctness using a custom-built model checker that handles\nfairness assumptions, safety and liveness requirements, and exploits symmetry.\nWhen model checking fails, our tool examines a set of counterexamples to\nsafety/liveness properties to generate constraints on unknown functions that\nmust be satisfied by subsequent completions. For evaluation, we show that our\nprototype is able to automatically discover interesting missing details in\ndistributed protocols for mutual exclusion, self stabilization, and cache\ncoherence.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2015 15:47:49 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Alur", "Rajeev", ""], ["Raghothaman", "Mukund", ""], ["Stergiou", "Christos", ""], ["Tripakis", "Stavros", ""], ["Udupa", "Abhishek", ""]]}, {"id": "1505.04511", "submitter": "Simon Schilling", "authors": "Simon J. Schilling", "title": "Contribution to Temporal Fault Tree Analysis without Modularization and\n  Transformation into the State Space", "comments": "Translation into English of the german doctoral thesis \"Beitrag zur\n  dynamischen Fehlerbaumanalyse ohne Modulbildung und zustandsbasierte\n  Erweiterungen\" of Dr. Ing. Simon J. Schilling at the Bergische Universit\\\"at\n  Wuppertal\n  (http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:de:hbz:468-20100070).\n  This translation is licensed under a Creative Commons Attribution-ShareAlike\n  4.0 License", "journal-ref": null, "doi": null, "report-no": "urn:nbn:de:hbz:468-20100070", "categories": "cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background:\n  Fault tree analysis (FTA) is a well established method for qualitative as\nwell as probabilistic reliability and safety analysis. As a Boolean model it\ndoes not support modelling of dynamic effects like sequence dependencies\nbetween fault events. This work describes a method that allows consideration of\nsequence dependencies without transformations into state-space.\n  Concept:\n  The new temporal fault tree analysis (TFTA) described in this work extends\nthe Boolean FTA. The TFTA is based on a new temporal logic which adds a concept\nof time to the Boolean logic and algebra. This allows modelling of temporal\nrelationships between events using two new temporal operators (PAND and SAND).\nWith a set of temporal logic rules, a given temporal term may be simplified to\nits temporal disjunctive normal form (TDNF) which is similar to the Boolean DNF\nbut includes event sequencies. In TDNF the top event's temporal system function\nmay be reduced to a list of minimal cutset sequences (MCSS). These allow\nqualitative analyses similar to Boolean cutset analysis in normal FTA.\nFurthermore the TFTA may also be used for probabilistic analyses without using\nstate-space models.\n  Results:\n  One significant aspect of the new TFTA described in this work is the\npossibility to take sequence dependencies into account for qualitative and\nprobabilistic analyses without state-space transformations. Among others, this\nallows for modelling of event sequencies at all levels within a fault tree, a\nreal qualitative analysis similar to the FTA's cutset analysis, and\nquantification of sequence dependencies within the same model.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 04:55:26 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Schilling", "Simon J.", ""]]}, {"id": "1505.04581", "submitter": "Peter Schrammel", "authors": "Hong-Yi Chen, Cristina David, Daniel Kroening, Peter Schrammel,\n  Bj\\\"orn Wachter", "title": "Synthesising Interprocedural Bit-Precise Termination Proofs (extended\n  version)", "comments": "extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proving program termination is key to guaranteeing absence of undesirable\nbehaviour, such as hanging programs and even security vulnerabilities such as\ndenial-of-service attacks. To make termination checks scale to large systems,\ninterprocedural termination analysis seems essential, which is a largely\nunexplored area of research in termination analysis, where most effort has\nfocussed on difficult single-procedure problems. We present a modular\ntermination analysis for C programs using template-based interprocedural\nsummarisation. Our analysis combines a context-sensitive, over-approximating\nforward analysis with the inference of under-approximating preconditions for\ntermination. Bit-precise termination arguments are synthesised over\nlexicographic linear ranking function templates. Our experimental results show\nthat our tool 2LS outperforms state-of-the-art alternatives, and demonstrate\nthe clear advantage of interprocedural reasoning over monolithic analysis in\nterms of efficiency, while retaining comparable precision.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 10:18:45 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Chen", "Hong-Yi", ""], ["David", "Cristina", ""], ["Kroening", "Daniel", ""], ["Schrammel", "Peter", ""], ["Wachter", "Bj\u00f6rn", ""]]}, {"id": "1505.04726", "submitter": "Pedro Ribeiro", "authors": "Pedro Ribeiro", "title": "Angelic Processes", "comments": "Extended version of PhD thesis submitted to the University of York,\n  UK, 868 pages, 10 figures, 7 tables (revised to match print version deposited\n  in the White Rose eTheses Online), http://etheses.whiterose.ac.uk/9020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the formal modelling of systems, demonic and angelic nondeterminism play\nfundamental roles as abstraction mechanisms. The angelic nature of a choice\npertains to the property of avoiding failure whenever possible. As a concept,\nangelic choice first appeared in automata theory and Turing machines, where it\ncan be implemented via backtracking. It has traditionally been studied in the\nrefinement calculus, and has proved to be useful in a variety of applications\nand refinement techniques. Recently it has been studied within relational,\nmultirelational and higher-order models. It has been employed for modelling\nuser interactions, game-like scenarios, theorem proving tactics, constraint\nsatisfaction problems and control systems.\n  When the formal modelling of state-rich reactive systems is considered, it\nonly seems natural that both types of nondeterministic choice should be\nconsidered. However, despite several treatments of angelic nondeterminism in\nthe context of process algebras, namely Communicating Sequential Processes, the\ncounterpart to the angelic choice of the refinement calculus has been elusive.\n  In this thesis, we develop a semantics in the relational setting of Hoare and\nHe's Unifying Theories of Programming that enables the characterisation of\nangelic nondeterminism in CSP. Since CSP processes are given semantics in the\nUTP via designs, that is, pre and postcondition pairs, we first introduce a\ntheory of angelic designs, and an isomorphic multirelational model, that is\nsuitable for characterising processes. We then develop a theory of reactive\nangelic designs by enforcing the healthiness conditions of CSP. Finally, by\nintroducing a notion of divergence that can undo the history of events, we\nobtain a model where angelic choice avoids divergence.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 17:21:55 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 11:21:15 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Ribeiro", "Pedro", ""]]}, {"id": "1505.04934", "submitter": "Luc Segoufin", "authors": "Thomas Place (University de Bordeaux), Luc Segoufin (INRIA & ENS\n  Cachan)", "title": "Deciding definability in FO2(<h,<v) on trees", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  1, 2015) lmcs:1581", "doi": "10.2168/LMCS-11(3:5)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a decidable characterization of regular forest languages definable\nin FO2(<h,<v). By FO2(<h,<v) we refer to the two variable fragment of first\norder logic built from the descendant relation and the following sibling\nrelation. In terms of expressive power it corresponds to a fragment of the\nnavigational core of XPath that contains modalities for going up to some\nancestor, down to some descendant, left to some preceding sibling, and right to\nsome following sibling. We also show that our techniques can be applied to\nother two variable first-order logics having exactly the same vertical\nmodalities as FO2(<h,<v) but having different horizontal modalities.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 09:56:51 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2015 16:10:28 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Place", "Thomas", "", "University de Bordeaux"], ["Segoufin", "Luc", "", "INRIA & ENS\n  Cachan"]]}, {"id": "1505.04985", "submitter": "Wan Fokkink", "authors": "Taolue Chen (Middlesex University London), Wan Fokkink (VU University\n  Amsterdam), Rob van Glabbeek (NICTA)", "title": "On the Axiomatizability of Impossible Futures", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  22, 2015) lmcs:1593", "doi": "10.2168/LMCS-11(3:17)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general method is established to derive a ground-complete axiomatization\nfor a weak semantics from such an axiomatization for its concrete counterpart,\nin the context of the process algebra BCCS. This transformation moreover\npreserves omega-completeness. It is applicable to semantics at least as coarse\nas impossible futures semantics. As an application, ground- and omega-complete\naxiomatizations are derived for weak failures, completed trace and trace\nsemantics. We then present a finite, sound, ground-complete axiomatization for\nthe concrete impossible futures preorder, which implies a finite, sound,\nground-complete axiomatization for the weak impossible futures preorder. In\ncontrast, we prove that no finite, sound axiomatization for BCCS modulo\nconcrete and weak impossible futures equivalence is ground-complete. If the\nalphabet of actions is infinite, then the aforementioned ground-complete\naxiomatizations are shown to be omega-complete. If the alphabet is finite, we\nprove that the inequational theories of BCCS modulo the concrete and weak\nimpossible futures preorder lack such a finite basis.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 13:16:32 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2015 05:20:28 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Chen", "Taolue", "", "Middlesex University London"], ["Fokkink", "Wan", "", "VU University\n  Amsterdam"], ["van Glabbeek", "Rob", "", "NICTA"]]}, {"id": "1505.05022", "submitter": "Daniela Inclezan", "authors": "Daniela Inclezan and Michael Gelfond", "title": "Modular Action Language ALM", "comments": "65 pages, 7 figures. To appear in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 16 (2016) 189-235", "doi": "10.1017/S1471068415000095", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a new modular action language, ALM, and illustrates the\nmethodology of its use. It is based on the approach of Gelfond and Lifschitz\n(1993; 1998) in which a high-level action language is used as a front end for a\nlogic programming system description. The resulting logic programming\nrepresentation is used to perform various computational tasks. The methodology\nbased on existing action languages works well for small and even medium size\nsystems, but is not meant to deal with larger systems that require structuring\nof knowledge. ALM is meant to remedy this problem. Structuring of knowledge in\nALM is supported by the concepts of module (a formal description of a specific\npiece of knowledge packaged as a unit), module hierarchy, and library, and by\nthe division of a system description of ALM into two parts: theory and\nstructure. A theory consists of one or more modules with a common theme,\npossibly organized into a module hierarchy based on a dependency relation. It\ncontains declarations of sorts, attributes, and properties of the domain\ntogether with axioms describing them. Structures are used to describe the\ndomain's objects. These features, together with the means for defining classes\nof a domain as special cases of previously defined ones, facilitate the\nstepwise development, testing, and readability of a knowledge base, as well as\nthe creation of knowledge representation libraries. To appear in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 14:44:25 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2015 12:11:09 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Inclezan", "Daniela", ""], ["Gelfond", "Michael", ""]]}, {"id": "1505.05028", "submitter": "Theo Zimmermann", "authors": "Th\\'eo Zimmermann (ENS Paris, PPS), Hugo Herbelin (PPS, PI.R2)", "title": "Automatic and Transparent Transfer of Theorems along Isomorphisms in the\n  Coq Proof Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mathematics, it is common practice to have several constructions for the\nsame objects. Mathematicians will identify them modulo isomorphism and will not\nworry later on which construction they use, as theorems proved for one\nconstruction will be valid for all.\n  When working with proof assistants, it is also common to see several\ndata-types representing the same objects. This work aims at making the use of\nseveral isomorphic constructions as simple and as transparent as it can be done\ninformally in mathematics. This requires inferring automatically the missing\nproof-steps.\n  We are designing an algorithm which finds and fills these missing proof-steps\nand we are implementing it as a plugin for Coq.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 14:50:14 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2015 19:10:17 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2015 20:10:09 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2015 11:45:47 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Zimmermann", "Th\u00e9o", "", "ENS Paris, PPS"], ["Herbelin", "Hugo", "", "PPS, PI.R2"]]}, {"id": "1505.05193", "submitter": "Steven Woodhouse", "authors": "Jasmin Fisher, Ali Sinan K\\\"oksal, Nir Piterman and Steven Woodhouse", "title": "Synthesising Executable Gene Regulatory Networks from Single-cell Gene\n  Expression Data", "comments": "Final published version to appear in Computer Aided Verification\n  (CAV), Springer, July 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental advances in biology allow researchers to obtain gene\nexpression profiles at single-cell resolution over hundreds, or even thousands\nof cells at once. These single-cell measurements provide snapshots of the\nstates of the cells that make up a tissue, instead of the population-level\naverages provided by conventional high-throughput experiments. This new data\ntherefore provides an exciting opportunity for computational modelling. In this\npaper we introduce the idea of viewing single-cell gene expression profiles as\nstates of an asynchronous Boolean network, and frame model inference as the\nproblem of reconstructing a Boolean network from its state space. We then give\na scalable algorithm to solve this synthesis problem. We apply our technique to\nboth simulated and real data. We first apply our technique to data simulated\nfrom a well established model of common myeloid progenitor differentiation. We\nshow that our technique is able to recover the original Boolean network rules.\nWe then apply our technique to a large dataset taken during embryonic\ndevelopment containing thousands of cell measurements. Our technique\nsynthesises matching Boolean networks, and analysis of these models yields new\npredictions about blood development which our experimental collaborators were\nable to verify.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 21:26:46 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 14:15:47 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Fisher", "Jasmin", ""], ["K\u00f6ksal", "Ali Sinan", ""], ["Piterman", "Nir", ""], ["Woodhouse", "Steven", ""]]}, {"id": "1505.05265", "submitter": "Claudio Corrodi", "authors": "Claudio Corrodi", "title": "Modelling and Verifying an Object-Oriented Concurrency Model in GROOVE", "comments": "124 pages, Master's Thesis at ETH Z\\\"urich", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SCOOP is a programming model and language that allows concurrent programming\nat a high level of abstraction. Several approaches to verifying SCOOP programs\nhave been proposed in the past, but none of them operate directly on the source\ncode without modifications or annotations.\n  We propose a fully automatic approach to verifying (a subset of) SCOOP\nprograms by translation to graph-based models. First, we present a graph\ntransformation based semantics for SCOOP. We present an implementation of the\nmodel in the state-of-the-art model checker GROOVE, which can be used to\nsimulate programs and verify concurrency and consistency properties, such as\nthe impossibility of deadlocks occurring or the absence of postcondition\nviolations. Second, we present a translation tool that operates on SCOOP\nprogram code and generates input for the model. We evaluate our approach by\ninspecting a number of programs in the form of case studies.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2015 07:33:14 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Corrodi", "Claudio", ""]]}, {"id": "1505.05531", "submitter": "Sam Buss", "authors": "James Aisenberg, Maria Luisa Bonet, Sam Buss, Adrian Cr\\~aciun,\n  Gabriel Istrate", "title": "Short Proofs of the Kneser-Lov\\'asz Coloring Principle", "comments": "This is a paper to appear in ICALP 2015, plus two appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the propositional translations of the Kneser-Lov\\'asz theorem\nhave polynomial size extended Frege proofs and quasi-polynomial size Frege\nproofs. We present a new counting-based combinatorial proof of the\nKneser-Lov\\'asz theorem that avoids the topological arguments of prior proofs\nfor all but finitely many cases for each k. We introduce a miniaturization of\nthe octahedral Tucker lemma, called the truncated Tucker lemma: it is open\nwhether its propositional translations have (quasi-)polynomial size Frege or\nextended Frege proofs.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2015 20:40:03 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Aisenberg", "James", ""], ["Bonet", "Maria Luisa", ""], ["Buss", "Sam", ""], ["Cr\u00e3ciun", "Adrian", ""], ["Istrate", "Gabriel", ""]]}, {"id": "1505.05646", "submitter": "Rob van Glabbeek", "authors": "Timothy Bourke (INRIA), Robert J. van Glabbeek (NICTA), Peter H\\\"ofner\n  (NICTA)", "title": "A mechanized proof of loop freedom of the (untimed) AODV routing\n  protocol", "comments": "The Isabelle/HOL source files, and a full proof document, are\n  available in the Archive of Formal Proofs, at\n  http://afp.sourceforge.net/entries/AODV.shtml", "journal-ref": "Proc. Automated Technology for Verification and Analysis, ATVA\n  2014 (F. Cassez and J.-F. Raskin, eds.), LNCS 8837, Springer, 2014, pp. 47-63", "doi": "10.1007/978-3-319-11936-6_5", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ad hoc On-demand Distance Vector (AODV) routing protocol allows the nodes\nin a Mobile Ad hoc Network (MANET) or a Wireless Mesh Network (WMN) to know\nwhere to forward data packets. Such a protocol is 'loop free' if it never leads\nto routing decisions that forward packets in circles. This paper describes the\nmechanization of an existing pen-and-paper proof of loop freedom of AODV in the\ninteractive theorem prover Isabelle/HOL. The mechanization relies on a novel\ncompositional approach for lifting invariants to networks of nodes. We exploit\nthe mechanization to analyse several improvements of AODV and show that\nIsabelle/HOL can re-establish most proof obligations automatically and identify\nexactly the steps that are no longer valid.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 08:38:40 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Bourke", "Timothy", "", "INRIA"], ["van Glabbeek", "Robert J.", "", "NICTA"], ["H\u00f6fner", "Peter", "", "NICTA"]]}, {"id": "1505.05832", "submitter": "Vinayak Prabhu", "authors": "Jyotirmoy V. Deshmukh, Rupak Majumdar, Vinayak S. Prabhu", "title": "Quantifying Conformance using the Skorokhod Metric (full version)", "comments": "Full version of CAV 2015 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conformance testing problem for dynamical systems asks, given two\ndynamical models (e.g., as Simulink diagrams), whether their behaviors are\n\"close\" to each other. In the semi-formal approach to conformance testing, the\ntwo systems are simulated on a large set of tests, and a metric, defined on\npairs of real-valued, real-timed trajectories, is used to determine a lower\nbound on the distance. We show how the Skorkhod metric on continuous dynamical\nsystems can be used as the foundation for conformance testing of complex\ndynamical models. The Skorokhod metric allows for both state value mismatches\nand timing distortions, and is thus well suited for checking conformance\nbetween idealized models of dynamical systems and their implementations. We\ndemonstrate the robustness of the system conformance quantification by proving\na \\emph{transference theorem}: trajectories close under the Skorokhod metric\nsatisfy \"close\" logical properties. Specifically, we show the result for the\ntimed linear time logic \\TLTL augmented with a rich class of temporal and\nspatial constraint predicates. We provide a window-based streaming algorithm to\ncompute the Skorokhod metric, and use it as a basis for a conformance testing\ntool for Simulink. We experimentally demonstrate the effectiveness of our tool\nin finding discrepant behaviors on a set of control system benchmarks,\nincluding an industrial challenge problem.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 18:42:33 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Deshmukh", "Jyotirmoy V.", ""], ["Majumdar", "Rupak", ""], ["Prabhu", "Vinayak S.", ""]]}, {"id": "1505.05964", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek, Peter H\\\"ofner", "title": "CCS: It's not Fair! Fair Schedulers cannot be implemented in CCS-like\n  languages even under progress and certain fairness assumptions", "comments": null, "journal-ref": "Acta Informatica 52(2-3), 2015, pp. 175-205", "doi": "10.1007/s00236-015-0221-6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the process algebra community it is sometimes suggested that, on some\nlevel of abstraction, any distributed system can be modelled in standard\nprocess-algebraic specification formalisms like CCS. This sentiment is\nstrengthened by results testifying that CCS, like many similar formalisms, is\nTuring powerful and provides a mechanism for interaction. This paper counters\nthat sentiment by presenting a simple fair scheduler---one that in suitable\nvariations occurs in many distributed systems---of which no implementation can\nbe expressed in CCS, unless CCS is enriched with a fairness assumption.\n  Since Dekker's and Peterson's mutual exclusion protocols implement fair\nschedulers, it follows that these protocols cannot be rendered correctly in CCS\nwithout imposing a fairness assumption. Peterson expressed this algorithm\ncorrectly in pseudocode without resorting to a fairness assumption, so it\nfurthermore follows that CCS lacks the expressive power to accurately capture\nsuch pseudocode.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 06:45:20 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""]]}, {"id": "1505.06056", "submitter": "Andrea Schalk", "authors": "Andrea Schalk (The University of Manchester), Hugh Paul Steele\n  (Universit\\'e Paris 13)", "title": "Constructing Fully Complete Models of Multiplicative Linear Logic", "comments": "72 pages. An extended abstract of this work appeared in the\n  proceedings of LICS 2012", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  3, 2015) lmcs:1582", "doi": "10.2168/LMCS-11(3:6)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiplicative fragment of Linear Logic is the formal system in this\nfamily with the best understood proof theory, and the categorical models which\nbest capture this theory are the fully complete ones. We demonstrate how the\nHyland-Tan double glueing construction produces such categories, either with or\nwithout units, when applied to any of a large family of degenerate models. This\nprocess explains as special cases a number of such models from the literature.\nIn order to achieve this result, we develop a tensor calculus for compact\nclosed categories with finite biproducts. We show how the combinatorial\nproperties required for a fully complete model are obtained by this glueing\nconstruction adding to the structure already available from the original\ncategory.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 13:03:03 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 17:12:17 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Schalk", "Andrea", "", "The University of Manchester"], ["Steele", "Hugh Paul", "", "Universit\u00e9 Paris 13"]]}, {"id": "1505.06307", "submitter": "Takumi Akazaki", "authors": "Takumi Akazaki and Ichiro Hasuo", "title": "Time Robustness in MTL and Expressivity in Hybrid System Falsification\n  (Extended Version)", "comments": "22pages, a long version of the paper accepted in 27th International\n  Conference on Computer Aided Verification (CAV 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the work by Fainekos and Pappas and the one by Donze and Maler,\nwe introduce AvSTL, an extension of metric interval temporal logic by averaged\ntemporal operators. Its expressivity in capturing both space and time\nrobustness helps solving falsification problems, (i.e. searching for a critical\npath in hybrid system models); it does so by communicating a designer's\nintention more faithfully to the stochastic optimization engine employed in a\nfalsification solver. We also introduce a sliding window-like algorithm that\nkeeps the cost of computing truth/robustness values tractable.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 10:33:39 GMT"}, {"version": "v2", "created": "Wed, 27 May 2015 05:30:16 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Akazaki", "Takumi", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1505.06376", "submitter": "Olivier Hermant", "authors": "Richard Bonichon (DIMAP - UFRN), Olivier Hermant", "title": "A syntactic soundness proof for free-variable tableaux with on-the-fly\n  Skolemization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the syntactic soundness of classical tableaux with free variables\nand on-the-fly Skolemization. Soundness proofs are usually built from semantic\narguments, and this is to our knowledge, the first proof that appeals to\nsyntactic means. We actually prove the soundness property with respect to\ncut-free sequent calculus. This requires great care because of the additional\nliberty in freshness checking allowed by the use of Skolem terms. In contrast\nto semantic soundness, we gain the possibility to state a cut elimination\ntheorem for sequent calculus, under the proviso that completeness of the method\nholds. We believe that such techniques can be applied to tableaux in other\nlogics as well.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 20:24:21 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Bonichon", "Richard", "", "DIMAP - UFRN"], ["Hermant", "Olivier", ""]]}, {"id": "1505.06430", "submitter": "Amin Timany", "authors": "Amin Timany, Bart Jacobs", "title": "Category Theory in Coq 8.5", "comments": "This is the abstract for a talk accepted for a presentation at the\n  7th Coq Workshop, Sophia Antipolis, France on June 26, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our experience implementing category theory in Coq 8.5. The\nrepository of this development can be found at\nhttps://bitbucket.org/amintimany/categories/. This implementation most notably\nmakes use of features, primitive projections for records and universe\npolymorphism that are new to Coq 8.5.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2015 11:41:50 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Timany", "Amin", ""], ["Jacobs", "Bart", ""]]}, {"id": "1505.06506", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "Every super-polynomial proof in purely implicational minimal logic has a\n  polynomially sized proof in classical implicational propositional logic", "comments": "This paper has been withdrawn by the author due to a fatal error in\n  the general form of the deduction used for proved the main proposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this article we show how any formula A with a proof in minimal\nimplicational logic that is super-polynomially sized has a polynomially-sized\nproof in classical implicational propositional logic . This fact provides an\nargument in favor that any classical propositional tautology has short proofs,\ni.e., NP=CoNP.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 01:02:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 01:16:00 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2015 16:55:32 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "1505.06588", "submitter": "Pierre Ganty", "authors": "Antoine Durand-Gasselin, Javier Esparza, Pierre Ganty, Rupak Majumdar", "title": "Model Checking Parameterized Asynchronous Shared-Memory Systems", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the complexity of liveness verification for parameterized\nsystems consisting of a leader process and arbitrarily many anonymous and\nidentical contributor processes. Processes communicate through a shared,\nbounded-value register. While each operation on the register is atomic, there\nis no synchronization primitive to execute a sequence of operations atomically.\n  We analyze the case in which processes are modeled by finite-state machines\nor pushdown machines and the property is given by a B\\\"uchi automaton over the\nalphabet of read and write actions of the leader. We show that the problem is\ndecidable, and has a surprisingly low complexity: it is NP-complete when all\nprocesses are finite-state machines, and is PSPACE-hard and in NEXPTIME when\nthey are pushdown machines. This complexity is lower than for the\nnon-parameterized case: liveness verification of finitely many finite-state\nmachines is PSPACE-complete, and undecidable for two pushdown machines.\n  For finite-state machines, our proofs characterize infinite behaviors using\nexistential abstraction and semilinear constraints. For pushdown machines, we\nshow how contributor computations of high stack height can be simulated by\ncomputations of many contributors, each with low stack height. Together, our\nresults characterize the complexity of verification for parameterized systems\nunder the assumptions of anonymity and asynchrony.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 10:17:26 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Durand-Gasselin", "Antoine", ""], ["Esparza", "Javier", ""], ["Ganty", "Pierre", ""], ["Majumdar", "Rupak", ""]]}, {"id": "1505.06617", "submitter": "Tomer Kotek", "authors": "Tomer Kotek and Johann A. Makowsky", "title": "Efficient computation of generalized Ising polynomials on graphs with\n  fixed clique-width", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph polynomials which are definable in Monadic Second Order Logic (MSOL) on\nthe vocabulary of graphs are Fixed-Parameter Tractable (FPT) with respect to\nclique-width. In contrast, graph polynomials which are definable in MSOL on the\nvocabulary of hypergraphs are fixed-parameter tractable with respect to\ntree-width, but not necessarily with respect to clique width. No algorithmic\nmeta-theorem is known for the computation of graph polynomials definable in\nMSOL on the vocabulary of hypergraphs with respect to clique-width. We define\nan infinite class of such graph polynomials extending the class of graph\npolynomials definable in MSOL on the vocabulary of graphs and prove that they\nare Fixed-Parameter Polynomial Time (FPPT) computable, i.e. that they can be\ncomputed in time $O(n^{f(k)})$, where $n$ is the number of vertices and $k$ is\nthe clique-width.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 13:13:25 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Kotek", "Tomer", ""], ["Makowsky", "Johann A.", ""]]}, {"id": "1505.06622", "submitter": "Tomer Kotek", "authors": "Tomer Kotek, Helmut Veith, Florian Zuleger", "title": "Monadic second order finite satisfiability and unbounded tree-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite satisfiability problem of monadic second order logic is decidable\nonly on classes of structures of bounded tree-width by the classic result of\nSeese (1991). We prove the following problem is decidable:\n  Input: (i) A monadic second order logic sentence $\\alpha$, and (ii) a\nsentence $\\beta$ in the two-variable fragment of first order logic extended\nwith counting quantifiers. The vocabularies of $\\alpha$ and $\\beta$ may\nintersect.\n  Output: Is there a finite structure which satisfies $\\alpha\\land\\beta$ such\nthat the restriction of the structure to the vocabulary of $\\alpha$ has bounded\ntree-width? (The tree-width of the desired structure is not bounded.)\n  As a consequence, we prove the decidability of the satisfiability problem by\na finite structure of bounded tree-width of a logic extending monadic second\norder logic with linear cardinality constraints of the form\n$|X_{1}|+\\cdots+|X_{r}|<|Y_{1}|+\\cdots+|Y_{s}|$, where the $X_{i}$ and $Y_{j}$\nare monadic second order variables. We prove the decidability of a similar\nextension of WS1S.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 13:31:45 GMT"}, {"version": "v2", "created": "Sat, 16 Apr 2016 06:44:31 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Kotek", "Tomer", ""], ["Veith", "Helmut", ""], ["Zuleger", "Florian", ""]]}, {"id": "1505.06651", "submitter": "Yanjing Wang", "authors": "Yanjing Wang", "title": "A Logic of Knowing How", "comments": "14 pages, a 12-page version accepted by LORI V", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a single-agent modal logic framework for reasoning\nabout goal-direct \"knowing how\" based on ideas from linguistics, philosophy,\nmodal logic and automated planning. We first define a modal language to express\n\"I know how to guarantee phi given psi\" with a semantics not based on standard\nepistemic models but labelled transition systems that represent the agent's\nknowledge of his own abilities. A sound and complete proof system is given to\ncapture the valid reasoning patterns about \"knowing how\" where the most\nimportant axiom suggests its compositional nature.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 14:43:55 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 08:36:47 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 09:35:29 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Wang", "Yanjing", ""]]}, {"id": "1505.06818", "submitter": "EPTCS", "authors": "Aart Middeldorp (University of Innsbruck), Femke van Raamsdonk (VU\n  University Amsterdam)", "title": "Proceedings 8th International Workshop on Computing with Terms and\n  Graphs", "comments": null, "journal-ref": "EPTCS 183, 2015", "doi": "10.4204/EPTCS.183", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the post-proceedings of the 8th International Workshop\non Computing with Terms and Graphs (TERMGRAPH 2014). The workshop took place in\nVienna on July 13, 2014 and was affiliated with the joint RTA and TLCA\nconference, which was part of the Federated Logic Conference (FLoC), which in\nturn participated in the Vienna Summer of Logic (VSL) 2014.\n  The four regular papers in these proceedings are significantly extended\nversions of their pre-proceedings version. They were subjected to an additional\nround of reviewing. The paper by Samuel Mimram is an invited contribution.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 06:25:48 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Middeldorp", "Aart", "", "University of Innsbruck"], ["van Raamsdonk", "Femke", "", "VU\n  University Amsterdam"]]}, {"id": "1505.06819", "submitter": "Thorsten Wissmann", "authors": "Natsuki Urabe and Ichiro Hasuo", "title": "Coalgebraic Infinite Traces and Kleisli Simulations", "comments": "39 pages, 1 figure", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (September\n  5, 2018) lmcs:4805", "doi": "10.23638/LMCS-14(3:15)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Kleisli simulation is a categorical notion introduced by Hasuo to verify\nfinite trace inclusion. They allow us to give definitions of forward and\nbackward simulation for various types of systems. A generic categorical theory\nbehind Kleisli simulation has been developed and it guarantees the soundness of\nthose simulations with respect to finite trace semantics. Moreover, those\nsimulations can be aided by forward partial execution (FPE)---a categorical\ntransformation of systems previously introduced by the authors.\n  In this paper, we give Kleisli simulation a theoretical foundation that\nassures its soundness also with respect to infinitary traces. There, following\nJacobs' work, infinitary trace semantics is characterized as the \"largest\nhomomorphism.\" It turns out that soundness of forward simulations is rather\nstraightforward; that of backward simulation holds too, although it requires\ncertain additional conditions and its proof is more involved. We also show that\nFPE can be successfully employed in the infinitary trace setting to enhance the\napplicability of Kleisli simulations as witnesses of trace inclusion. Our\nframework is parameterized in the monad for branching as well as in the functor\nfor linear-time behaviors; for the former we mainly use the powerset monad (for\nnondeterminism), the sub-Giry monad (for probability), and the lift monad (for\nexception).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 06:28:17 GMT"}, {"version": "v2", "created": "Wed, 27 May 2015 04:23:38 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 10:52:41 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 06:35:26 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Urabe", "Natsuki", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1505.06862", "submitter": "Leander Tentrup", "authors": "Bernd Finkbeiner (Saarland University), Leander Tentrup (Saarland\n  University)", "title": "Detecting Unrealizability of Distributed Fault-tolerant Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  17, 2015) lmcs:1588", "doi": "10.2168/LMCS-11(3:12)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing formal specifications for distributed systems is difficult. Even\nsimple consistency requirements often turn out to be unrealizable because of\nthe complicated information flow in the distributed system: not all information\nis available in every component, and information transmitted from other\ncomponents may arrive with a delay or not at all, especially in the presence of\nfaults. The problem of checking the distributed realizability of a temporal\nspecification is, in general, undecidable. Semi-algorithms for synthesis, such\nas bounded synthesis, are only useful in the positive case, where they\nconstruct an implementation for a realizable specification, but not in the\nnegative case: if the specification is unrealizable, the search for the\nimplementation never terminates. In this paper, we introduce counterexamples to\ndistributed realizability and present a method for the detection of such\ncounterexamples for specifications given in linear-time temporal logic (LTL). A\ncounterexample consists of a set of paths, each representing a different\nsequence of inputs from the environment, such that, no matter how the\ncomponents are implemented, the specification is violated on at least one of\nthese paths. We present a method for finding such counterexamples both for the\nclassic distributed realizability problem and for the fault-tolerant\nrealizability problem. Our method considers, incrementally, larger and larger\nsets of paths until a counterexample is found. For safety specifications in\nweakly ordered architectures we obtain a decision procedure, while\ncounterexamples for full LTL and arbitrary architectures may consist of\ninfinitely many paths. Experimental results, obtained with a QBF-based\nprototype implementation, show that our method finds simple errors very\nquickly, and even problems with high combinatorial complexity, like the\nByzantine Generals' Problem, are tractable.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 09:08:26 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 17:15:41 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Finkbeiner", "Bernd", "", "Saarland University"], ["Tentrup", "Leander", "", "Saarland\n  University"]]}, {"id": "1505.06896", "submitter": "Lutz Stra", "authors": "Lutz Strassburger (INRIA), Anupam Das (INRIA), Ryuta Arisaka (INRIA)", "title": "On Nested Sequents for Constructive Modal Logics", "comments": "33 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  3, 2015) lmcs:1583", "doi": "10.2168/LMCS-11(3:7)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deductive systems for various modal logics that can be obtained\nfrom the constructive variant of the normal modal logic CK by adding\ncombinations of the axioms d, t, b, 4, and 5. This includes the constructive\nvariants of the standard modal logics K4, S4, and S5. We use for our\npresentation the formalism of nested sequents and give a syntactic proof of cut\nelimination.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 10:55:59 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 19:15:46 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Strassburger", "Lutz", "", "INRIA"], ["Das", "Anupam", "", "INRIA"], ["Arisaka", "Ryuta", "", "INRIA"]]}, {"id": "1505.06953", "submitter": "Martin Zimmermann", "authors": "Martin Zimmermann", "title": "Parameterized Linear Temporal Logics Meet Costs: Still not Costlier than\n  LTL (full version)", "comments": "A short version appears in Proceedings of GandALF 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the investigation of parameterized extensions of Linear Temporal\nLogic (LTL) that retain the attractive algorithmic properties of LTL: a\npolynomial space model checking algorithm and a doubly-exponential time\nalgorithm for solving games. Alur et al. and Kupferman et al. showed that this\nis the case for Parametric LTL (PLTL) and PROMPT-LTL respectively, which have\ntemporal operators equipped with variables that bound their scope in time.\nLater, this was also shown to be true for Parametric LDL (PLDL), which extends\nPLTL to be able to express all omega-regular properties.\n  Here, we generalize PLTL to systems with costs, i.e., we do not bound the\nscope of operators in time, but bound the scope in terms of the cost\naccumulated during time. Again, we show that model checking and solving games\nfor specifications in PLTL with costs is not harder than the corresponding\nproblems for LTL. Finally, we discuss PLDL with costs and extensions to\nmultiple cost functions.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 13:55:46 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 08:11:01 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2015 06:46:13 GMT"}, {"version": "v4", "created": "Mon, 17 Aug 2015 07:43:50 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2016 14:09:18 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Zimmermann", "Martin", ""]]}, {"id": "1505.07161", "submitter": "EPTCS", "authors": "Samuel Mimram (LIX, \\'Ecole Polytechnique)", "title": "Presenting Finite Posets", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818", "journal-ref": "EPTCS 183, 2015, pp. 1-17", "doi": "10.4204/EPTCS.183.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a monoidal category whose morphisms are finite partial orders,\nwith chosen minimal and maximal elements as source and target respectively.\nAfter recalling the notion of presentation of a monoidal category by the means\nof generators and relations, we construct a presentation of our category, which\ncorresponds to a variant of the notion of bialgebra.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:47:42 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Mimram", "Samuel", "", "LIX, \u00c9cole Polytechnique"]]}, {"id": "1505.07162", "submitter": "EPTCS", "authors": "Sergio Antoy, Jacob Johannsen, Steven Libby", "title": "Needed Computations Shortcutting Needed Steps", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818", "journal-ref": "EPTCS 183, 2015, pp. 18-32", "doi": "10.4204/EPTCS.183.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a compilation scheme for a constructor-based, strongly-sequential,\ngraph rewriting system which shortcuts some needed steps. The object code is\nanother constructor-based graph rewriting system. This system is normalizing\nfor the original system when using an innermost strategy. Consequently, the\nobject code can be easily implemented by eager functions in a variety of\nprogramming languages. We modify this object code in a way that avoids total or\npartial construction of the contracta of some needed steps of a computation.\nWhen computing normal forms in this way, both memory consumption and execution\ntime are reduced compared to ordinary rewriting computations in the original\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:47:50 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Antoy", "Sergio", ""], ["Johannsen", "Jacob", ""], ["Libby", "Steven", ""]]}, {"id": "1505.07163", "submitter": "EPTCS", "authors": "Naohi Eguchi (Chiba University)", "title": "Complexity Analysis of Precedence Terminating Infinite Graph Rewrite\n  Systems", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818. arXiv admin note:\n  text overlap with arXiv:1404.6196", "journal-ref": "EPTCS 183, 2015, pp. 33-47", "doi": "10.4204/EPTCS.183.3", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general form of safe recursion (or ramified recurrence) can be expressed\nby an infinite graph rewrite system including unfolding graph rewrite rules\nintroduced by Dal Lago, Martini and Zorzi, in which the size of every normal\nform by innermost rewriting is polynomially bounded. Every unfolding graph\nrewrite rule is precedence terminating in the sense of Middeldorp, Ohsaki and\nZantema. Although precedence terminating infinite rewrite systems cover all the\nprimitive recursive functions, in this paper we consider graph rewrite systems\nprecedence terminating with argument separation, which form a subclass of\nprecedence terminating graph rewrite systems. We show that for any precedence\nterminating infinite graph rewrite system G with a specific argument\nseparation, both the runtime complexity of G and the size of every normal form\nin G can be polynomially bounded. As a corollary, we obtain an alternative\nproof of the original result by Dal Lago et al.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:48:05 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Eguchi", "Naohi", "", "Chiba University"]]}, {"id": "1505.07164", "submitter": "EPTCS", "authors": "Abubakar Hassan (Theory and Practice of Software Ltd), Ian Mackie\n  (LIX, Ecole Polytechnique), Shinya Sato (University of Sussex)", "title": "An Implementation Model for Interaction Nets", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818", "journal-ref": "EPTCS 183, 2015, pp. 66-80", "doi": "10.4204/EPTCS.183.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study implementations and optimisations of interaction net systems we\npropose a calculus to allow us to reason about nets, a concrete data-structure\nthat is in close correspondence with the calculus, and a low-level language to\ncreate and manipulate this data structure. These work together so that we can\ndescribe the compilation process for interaction nets, reason about the\nbehaviours of the implementation, and study the efficiency and properties.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:48:30 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Hassan", "Abubakar", "", "Theory and Practice of Software Ltd"], ["Mackie", "Ian", "", "LIX, Ecole Polytechnique"], ["Sato", "Shinya", "", "University of Sussex"]]}, {"id": "1505.07508", "submitter": "Pietro Codara", "authors": "Pietro Codara and Diego Valota", "title": "Valuations in Nilpotent Minimum Logic", "comments": null, "journal-ref": "IEEE International Symposium on Multiple-Valued Logic (ISMVL), pp.\n  90-95, 2015", "doi": "10.1109/ISMVL.2015.19", "report-no": null, "categories": "cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euler characteristic can be defined as a special kind of valuation on\nfinite distributive lattices. This work begins with some brief consideration on\nthe role of the Euler characteristic on NM algebras, the algebraic counterpart\nof Nilpotent Minimum logic. Then, we introduce a new valuation, a modified\nversion of the Euler characteristic we call idempotent Euler characteristic. We\nshow that the new valuation encodes information about the formul{\\ae} in NM\npropositional logic.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 22:49:19 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Codara", "Pietro", ""], ["Valota", "Diego", ""]]}, {"id": "1505.07578", "submitter": "Emmanuel Jeandel", "authors": "Emmanuel Jeandel (CARTE)", "title": "Enumeration Reducibility in Closure Spaces with Applications to Logic\n  and Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many instances in first order logic or computable algebra, classical\ntheorems show that many problems are undecidable for general structures, but\nbecome decidable if some rigidity is imposed on the structure. For example, the\nset of theorems in many finitely axiomatisable theories is nonrecursive, but\nthe set of theorems for any finitely axiomatisable complete theory is\nrecursive. Finitely presented groups might have an nonrecursive word problem,\nbut finitely presented simple groups have a recursive word problem. In this\narticle we introduce a topological framework based on closure spaces to show\nthat many of these proofs can be obtained in a similar setting. We will show in\nparticular that these statements can be generalized to cover arbitrary\nstructures, with no finite or recursive presentation/axiomatization. This\ngeneralizes in particular work by Kuznetsov and others. Examples from first\norder logic and symbolic dynamics will be discussed at length.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 07:51:24 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 08:23:21 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 14:57:56 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Jeandel", "Emmanuel", "", "CARTE"]]}, {"id": "1505.07712", "submitter": "Eric  Werner", "authors": "Eric Werner", "title": "A Category Theory of Communication Theory", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CL cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theory of how agents can come to understand a language is presented. If\nunderstanding a sentence $\\alpha$ is to associate an operator with $\\alpha$\nthat transforms the representational state of the agent as intended by the\nsender, then coming to know a language involves coming to know the operators\nthat correspond to the meaning of any sentence. This involves a higher order\noperator that operates on the possible transformations that operate on the\nrepresentational capacity of the agent. We formalize these constructs using\nconcepts and diagrams analogous to category theory.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 15:00:27 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Werner", "Eric", ""]]}, {"id": "1505.07736", "submitter": "Thorsten Wi{\\ss}mann", "authors": "Stefan Milius and Thorsten Wi{\\ss}mann", "title": "Finitary Corecursion for the Infinitary Lambda Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Kurz et al. have recently shown that infinite $\\lambda$-trees with finitely\nmany free variables modulo $\\alpha$-equivalence form a final coalgebra for a\nfunctor on the category of nominal sets. Here we investigate the rational\nfixpoint of that functor. We prove that it is formed by all rational\n$\\lambda$-trees, i.e. those $\\lambda$-trees which have only finitely many\nsubtrees (up to isomorphism). This yields a corecursion principle that allows\nthe definition of operations such as substitution on rational $\\lambda$-trees.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 15:54:39 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 08:45:31 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Milius", "Stefan", ""], ["Wi\u00dfmann", "Thorsten", ""]]}, {"id": "1505.07794", "submitter": "Emmanuel Beffara", "authors": "Emmanuel Beffara (I2M)", "title": "Unifying type systems for mobile processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unifying framework for type systems for process calculi. The\ncore of the system provides an accurate correspondence between essentially\nfunctional processes and linear logic proofs; fragments of this system\ncorrespond to previously known connections between proofs and processes. We\nshow how the addition of extra logical axioms can widen the class of typeable\nprocesses in exchange for the loss of some computational properties like\nlock-freeness or termination, allowing us to see various well studied systems\n(like i/o types, linearity, control) as instances of a general pattern. This\nsuggests unified methods for extending existing type systems with new features\nwhile staying in a well structured environment and constitutes a step towards\nthe study of denotational semantics of processes using proof-theoretical\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 18:43:55 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Beffara", "Emmanuel", "", "I2M"]]}, {"id": "1505.07916", "submitter": "Supratik Chakraborty", "authors": "Supratik Chakraborty, Zurab Khasidashvili, Carl-Johan H. Seger,\n  Rajkumar Gajavelly, Tanmay Haldankar, Dinesh Chhatani, Rakesh Mistry", "title": "Word-level Symbolic Trajectory Evaluation", "comments": "19 pages, 3 figures, 2 tables, full version of paper in International\n  Conference on Computer-Aided Verification (CAV) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic trajectory evaluation (STE) is a model checking technique that has\nbeen successfully used to verify industrial designs. Existing implementations\nof STE, however, reason at the level of bits, allowing signals to take values\nin {0, 1, X}. This limits the amount of abstraction that can be achieved, and\npresents inherent limitations to scaling. The main contribution of this paper\nis to show how much more abstract lattices can be derived automatically from\nRTL descriptions, and how a model checker for the general theory of STE\ninstantiated with such abstract lattices can be implemented in practice. This\ngives us the first practical word-level STE engine, called STEWord. Experiments\non a set of designs similar to those used in industry show that STEWord scales\nbetter than word-level BMC and also bit-level STE.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 04:02:55 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Chakraborty", "Supratik", ""], ["Khasidashvili", "Zurab", ""], ["Seger", "Carl-Johan H.", ""], ["Gajavelly", "Rajkumar", ""], ["Haldankar", "Tanmay", ""], ["Chhatani", "Dinesh", ""], ["Mistry", "Rakesh", ""]]}, {"id": "1505.07987", "submitter": "Thomas Gransden", "authors": "Thomas Gransden and Neil Walkinshaw and Rajeev Raman", "title": "SEPIA: Search for Proofs Using Inferred Automata", "comments": "To appear at 25th International Conference on Automated Deduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes SEPIA, a tool for automated proof generation in Coq.\nSEPIA combines model inference with interactive theorem proving. Existing proof\ncorpora are modelled using state-based models inferred from tactic sequences.\nThese can then be traversed automatically to identify proofs. The SEPIA system\nis described and its performance evaluated on three Coq datasets. Our results\nshow that SEPIA provides a useful complement to existing automated tactics in\nCoq.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 10:39:44 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Gransden", "Thomas", ""], ["Walkinshaw", "Neil", ""], ["Raman", "Rajeev", ""]]}, {"id": "1505.08105", "submitter": "Henning Kerstan", "authors": "Paolo Baldan, Filippo Bonchi, Henning Kerstan, Barbara K\\\"onig", "title": "Towards Trace Metrics via Functor Lifting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We investigate the possibility of deriving metric trace semantics in a\ncoalgebraic framework. First, we generalize a technique for systematically\nlifting functors from the category Set of sets to the category PMet of\npseudometric spaces, showing under which conditions also natural\ntransformations, monads and distributive laws can be lifted. By exploiting some\nrecent work on an abstract determinization, these results enable the derivation\nof trace metrics starting from coalgebras in Set. More precisely, for a\ncoalgebra on Set we determinize it, thus obtaining a coalgebra in the\nEilenberg-Moore category of a monad. When the monad can be lifted to PMet, we\ncan equip the final coalgebra with a behavioral distance. The trace distance\nbetween two states of the original coalgebra is the distance between their\nimages in the determinized coalgebra through the unit of the monad. We show how\nour framework applies to nondeterministic automata and probabilistic automata.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 16:23:09 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Baldan", "Paolo", ""], ["Bonchi", "Filippo", ""], ["Kerstan", "Henning", ""], ["K\u00f6nig", "Barbara", ""]]}]