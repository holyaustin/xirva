[{"id": "1810.00041", "submitter": "Carmine Dodaro", "authors": "Francesco Calimeri, Carmine Dodaro, Davide Fusc\\`a, Simona Perri,\n  Jessica Zangari", "title": "Efficiently Coupling the I-DLV Grounder with ASP Solvers", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). 19 pages, 4 figures", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 205-224", "doi": "10.1017/S1471068418000546", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present I-DLV+MS , a new Answer Set Programming (ASP) system that\nintegrates an efficient grounder, namely I-DLV, with an automatic selector that\ninductively chooses a solver: depending on some inherent features of the\ninstantiation produced by I-DLV, machine learning techniques guide the\nselection of the most appropriate solver. The system participated in the latest\n(7th) ASP competition, winning the regular track, category SP (i.e., one\nprocessor allowed). Under consideration in Theory and Practice of Logic\nProgramming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:49:34 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 10:55:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Calimeri", "Francesco", ""], ["Dodaro", "Carmine", ""], ["Fusc\u00e0", "Davide", ""], ["Perri", "Simona", ""], ["Zangari", "Jessica", ""]]}, {"id": "1810.00160", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Quantifier Elimination With Structural Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Quantifier Elimination (QE) problem for propositional CNF\nformulas with existential quantifiers. QE plays a key role in formal\nverification. Earlier, we presented an approach based on the following\nobservation. To perform QE, one just needs to add a set of clauses depending on\nfree variables that makes the quantified clauses (i.e. clauses with quantified\nvariables) redundant. To implement this approach, we introduced a branching\nalgorithm making quantified clauses redundant in subspaces and merging the\nresults of branches. To implement this algorithm we developed the machinery of\nD-sequents. A D-sequent is a record stating that a quantified clause is\nredundant in a specified subspace. Redundancy of a clause is a structural\nproperty (i.e. it holds only for a subset of logically equivalent formulas as\nopposed to a semantic property). So, re-using D-sequents is not as easy as\nre-using conflict clauses in SAT-solving. In this paper, we address this\nproblem. We introduce a new definition of D-sequents that enables their\nre-usability. We develop a theory showing under what conditions a D-sequent can\nbe safely re-used.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 06:38:53 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 18:24:08 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 00:00:41 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "1810.00453", "submitter": "Patrick L\\\"uhne", "authors": "Vladimir Lifschitz, Patrick L\\\"uhne, Torsten Schaub", "title": "anthem: Transforming gringo Programs into First-Order Theories\n  (Preliminary Report)", "comments": "Proceedings of the 11th Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper by Harrison et al., the concept of program completion is\nextended to a large class of programs in the input language of the ASP grounder\ngringo. We would like to automate the process of generating and simplifying\ncompletion formulas for programs in that language, because examining the output\nproduced by this kind of software may help programmers to see more clearly what\ntheir program does and to what degree its set of stable models conforms with\ntheir intentions. If a formal specification for the program is available, then\nit may be possible to use this software, in combination with automated\nreasoning tools, to verify that the program is correct. This note is a\npreliminary report on a project motivated by this idea.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 19:27:19 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Lifschitz", "Vladimir", ""], ["L\u00fchne", "Patrick", ""], ["Schaub", "Torsten", ""]]}, {"id": "1810.00635", "submitter": "Jorge A. P\\'erez", "authors": "Ornela Dardha and Jorge A. P\\'erez", "title": "Comparing Type Systems for Deadlock Freedom", "comments": "39 pages, plus appendices. Extended version of an EXPRESS/SOS'15\n  paper (https://doi.org/10.4204/EPTCS.190.1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message-passing software systems exhibit non-trivial forms of concurrency and\ndistribution; they are expected to follow intended protocols among\ncommunicating services, but also to never \"get stuck\". This intuitive\nrequirement has been expressed by liveness properties such as progress or\n(dead)lock freedom and various type systems ensure these properties for\nconcurrent processes. Unfortunately, very little is known about the precise\nrelationship between these type systems and the classes of typed processes they\ninduce.\n  This paper puts forward the first comparative study of different type systems\nfor message-passing processes that guarantee deadlock freedom. We compare two\nclasses of deadlock-free typed processes, here denoted L and K. The class L\nstands out for its canonicity: it results from Curry-Howard interpretations of\nlinear logic propositions as session types. The class K, obtained by encoding\nsession types into Kobayashi's linear types with usages, includes processes not\ntypable in other type systems. We show that L is strictly included in K, and\nidentify the precise conditions under which they coincide. We also provide two\ntype-preserving translations of processes in K into processes in L.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 11:55:05 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 12:45:08 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 13:03:18 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Dardha", "Ornela", ""], ["P\u00e9rez", "Jorge A.", ""]]}, {"id": "1810.00724", "submitter": "Josep Silva", "authors": "Josep Silva", "title": "Pre-proceedings of the 26th International Workshop on Functional and\n  Logic Programming (WFLP 2018)", "comments": "Papers selected for presentation at WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume constitutes the pre-proceedings of the 26th International\nWorkshop on Functional and Logic Programming (WFLP 2018). It is formed of those\npapers selected by the program committee for presentation at the workshop.\nAfter discussion at the workshop, the program committee will select a number of\npapers to be invited for the second round of refereeing and selection for the\nformal proceedings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:34:14 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Silva", "Josep", ""]]}, {"id": "1810.00771", "submitter": "Theofrastos Mantadelis", "authors": "Theofrastos Mantadelis, Stefano Bistarelli", "title": "A Preliminary Report on Probabilistic Attack Normal Form for\n  Constellation Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  After Dung's founding work in Abstract Argumentation Frameworks there has\nbeen a growing interest in extending the Dung's semantics in order to describe\nmore complex or real life situations. Several of these approaches take the\ndirection of weighted or probabilistic extensions. One of the most prominent\nprobabilistic approaches is that of constellation Probabilistic Abstract\nArgumentation Frameworks from Li~et~al. In this paper, we present a normal form\nfor constellation probabilistic abstract argumentation frameworks. Furthermore,\nwe present a transformation from general constellation probabilistic abstract\nargumentation frameworks to the presented normal form. In this way we\nillustrate that the simpler normal form has equal representation power with the\ngeneral one.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 13:42:13 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Mantadelis", "Theofrastos", ""], ["Bistarelli", "Stefano", ""]]}, {"id": "1810.00868", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Truly Concurrent Process Algebra Is Reversible", "comments": "43 pages. arXiv admin note: substantial text overlap with\n  arXiv:1611.09035, arXiv:1709.01217", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on our previous process algebra for concurrency APTC, we prove that it\nis reversible with a little modifications. The reversible algebra has four\nparts: Basic Algebra for Reversible True Concurrency (BARTC), Algebra for\nParallelism in Reversible True Concurrency (APRTC), recursion and abstraction.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 01:43:31 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1810.00950", "submitter": "Ashutosh Trivedi", "authors": "Ernst Moritz Hahn and Mateo Perez and Sven Schewe and Fabio Somenzi\n  and Ashutosh Trivedi and Dominik Wojtczak", "title": "Omega-Regular Objectives in Model-Free Reinforcement Learning", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first solution for model-free reinforcement learning of\n{\\omega}-regular objectives for Markov decision processes (MDPs). We present a\nconstructive reduction from the almost-sure satisfaction of {\\omega}-regular\nobjectives to an almost- sure reachability problem and extend this technique to\nlearning how to control an unknown model so that the chance of satisfying the\nobjective is maximized. A key feature of our technique is the compilation of\n{\\omega}-regular properties into limit- deterministic Buechi automata instead\nof the traditional Rabin automata; this choice sidesteps difficulties that have\nmarred previous proposals. Our approach allows us to apply model-free,\noff-the-shelf reinforcement learning algorithms to compute optimal strategies\nfrom the observations of the MDP. We present an experimental evaluation of our\ntechnique on benchmark learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:04:56 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Perez", "Mateo", ""], ["Schewe", "Sven", ""], ["Somenzi", "Fabio", ""], ["Trivedi", "Ashutosh", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1810.01252", "submitter": "EPTCS", "authors": "Paolo Pistone", "title": "Proof Nets, Coends and the Yoneda Isomorphism", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 148-167", "doi": "10.4204/EPTCS.292.9", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof nets provide permutation-independent representations of proofs and are\nused to investigate coherence problems for monoidal categories. We investigate\na coherence problem concerning Second Order Multiplicative Linear Logic (MLL2),\nthat is, the one of characterizing the equivalence over proofs generated by the\ninterpretation of quantifiers by means of ends and coends.\n  We provide a compact representation of proof nets for a fragment of MLL2\nrelated to the Yoneda isomorphism. By adapting the \"rewiring approach\" used in\ncoherence results for star-autonomous categories, we define an equivalence\nrelation over proof nets called \"re-witnessing\". We prove that this relation\ncharacterizes, in this fragment, the equivalence generated by coends.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:57:48 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 05:18:18 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Pistone", "Paolo", ""]]}, {"id": "1810.01486", "submitter": "Gerhard Dueck", "authors": "Evandro C. Ferraz and Jeferson de Lima Muniz and Alexandre C. R. da\n  Silva and Gerhard W. Dueck", "title": "Synthesis of Majority Expressions through Primitive Function\n  Manipulation", "comments": "16 pages", "journal-ref": "13th International Workshop on Boolean Problems, September 19-21,\n  2018, Bremen, Germany, pp. 117-132", "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to technology advancements and circuits miniaturization, the study of\nlogic systems that can be applied to nanotechnology has been progressing\nsteadily. Among the creation of nanoeletronic circuits reversible and majority\nlogic stand out. This paper proposes the MPC (Majority Primitives Combination)\nalgorithm, used for majority logic synthesis. The algorithm receives a truth\ntable as input and returns a majority function that covers the same set of\nminterms. The formulation of a valid output function is made with the\ncombination of previously optimized functions. As cost criteria the algorithm\nsearches for a function with the least number of levels, followed by the least\nnumber of gates, inverters, and gate inputs. In this paper it's also presented\na comparison between the MPC and the exact_mig, currently considered the best\nalgorithm for majority synthesis. The exact_mig encode the exact synthesis of\nmajority functions using the number of levels and gates as cost criteria. The\nMPC considers two additional cost criteria, the number of inverters and the\nnumber of gate inputs, with the goal to further improve exact_mig results.\nTests have shown that both algorithms return optimal solutions for all\nfunctions with 3 input variables. For functions with 4 inputs, the MPC is able\nto further improve 42,987 (66%) functions and achieves equal results for 7,198\n(11%). For functions with 5 input variables, out of a sample of 1,000 randomly\ngenerated functions, the MPC further improved 477 (48%) functions and achieved\nequal results for 112 (11%).\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:07:53 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Ferraz", "Evandro C.", ""], ["Muniz", "Jeferson de Lima", ""], ["da Silva", "Alexandre C. R.", ""], ["Dueck", "Gerhard W.", ""]]}, {"id": "1810.01516", "submitter": "Alisa Kovtunova", "authors": "Alisa Kovtunova and Rafael Pe\\~naloza", "title": "Cutting Diamonds: Temporal DLs with Probabilistic Distributions over\n  Data", "comments": "Full version of the paper accepted for 31st International Workshop on\n  Description Logics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has studied a probabilistic extension of the temporal logic LTL\nthat refines the eventuality (or diamond) constructor with a probability\ndistribution on when will this eventuality be satisfied. In this paper, we\nadapt this notion to a well established temporal extension of DL-Lite, allowing\nthe new probabilistic constructor only in the ABox assertions. We investigate\nthe satisfiability problem of this new temporal DL over equiparametric\ngeometric distributions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 21:13:22 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Kovtunova", "Alisa", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1810.02047", "submitter": "Sergey Slavnov A", "authors": "Sergey Slavnov", "title": "Classical linear logic, cobordisms and categorical semantics of\n  categorial grammars", "comments": "A precursor of this work was posted and shortly removed under the\n  title \"\"Commutative linear logic as a multiple context-free grammar\". This\n  contained a wrong proof and a wrong claim. Linear logic grammars in general\n  are not multiple context-free and are at least as expressive as ACG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a categorial grammar based on classical multiplicative linear\nlogic.\n  This can be seen as an extension of abstract categorial grammars (ACG) and is\nat least as expressive. However, constituents of {\\it linear logic grammars\n(LLG)} are not abstract ${\\lambda}$-terms, but simply tuples of words with\nlabeled endpoints, we call them {\\it multiwords}. At least, this gives a\nconcrete and intuitive representation of ACG.\n  A key observation is that the class of multiwords has a fundamental algebraic\nstructure. Namely, multiwords can be organized in a category, very similar to\nthe category of topological cobordisms. This category is symmetric monoidal\nclosed and compact closed and thus is a model of linear $\\lambda$-calculus and\nclassical linear logic. We think that this category is interesting on its own\nright. In particular, it might provide categorical representation for other\nformalisms.\n  On the other hand, many models of language semantics are based on commutative\nlogic or, more generally, on symmetric monoidal closed categories. But the\ncategory of {\\it word cobordisms} is a category of language elements, which is\nitself symmetric monoidal closed and independent of any grammar. Thus, it might\nprove useful in understanding language semantics as well.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 04:02:11 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 16:51:16 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 08:26:26 GMT"}, {"version": "v4", "created": "Sun, 16 Dec 2018 17:52:41 GMT"}, {"version": "v5", "created": "Sun, 20 Jan 2019 19:31:35 GMT"}, {"version": "v6", "created": "Sat, 9 Feb 2019 18:20:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "1810.02053", "submitter": "EPTCS", "authors": "Massimo Bartoletti (University of Cagliari, Italy), Sophia Knight\n  (Uppsala University, Sweden)", "title": "Proceedings 11th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 279, 2018", "doi": "10.4204/EPTCS.279", "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE'18, the 11th Interaction and\nConcurrency Experience, which was held in Madrid, Spain on the 20th and 21st of\nJune 2018 as a satellite event of DisCoTec'18.\n  The ICE workshop series features a distinguishing review and selection\nprocedure, allowing PC members to interact anonymously with authors. As in the\npast ten editions, this interaction considerably improved the accuracy of the\nfeedback from the reviewers and the quality of accepted papers, and offered the\nbasis for lively discussion during the workshop. For the second time, the 2018\nedition of ICE included double blind reviewing of original research papers, in\norder to increase fairness and avoid bias in reviewing.\n  Each paper was reviewed by three PC members, and altogether six papers were\naccepted for publication (the workshop also featured four oral presentations\nwhich are not part of this volume). We were proud to host three invited talks,\nby Elvira Albert, Silvia Crafa, and Alexey Gotsman. The abstracts of these\ntalks are included in this volume together with the regular papers. Final\nversions of the contributions, taking into account the discussion at the\nworkshop, are included.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 04:44:13 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Bartoletti", "Massimo", "", "University of Cagliari, Italy"], ["Knight", "Sophia", "", "Uppsala University, Sweden"]]}, {"id": "1810.02132", "submitter": "Marie-Laure Mugnier", "authors": "Michel Leclere, Marie-Laure Mugnier, Michael Thomazo, Federico Ulliana", "title": "A Single Approach to Decide Chase Termination on Linear Existential\n  Rules", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules, long known as tuple-generating dependencies in database\ntheory, have been intensively studied in the last decade as a powerful\nformalism to represent ontological knowledge in the context of ontology-based\nquery answering. A knowledge base is then composed of an instance that contains\nincomplete data and a set of existential rules, and answers to queries are\nlogically entailed from the knowledge base. This brought again to light the\nfundamental chase tool, and its different variants that have been proposed in\nthe literature. It is well-known that the problem of determining, given a chase\nvariant and a set of existential rules, whether the chase will halt on any\ninstance, is undecidable. Hence, a crucial issue is whether it becomes\ndecidable for known subclasses of existential rules. In this work, we consider\nlinear existential rules, a simple yet important subclass of existential rules\nthat generalizes inclusion dependencies. We show the decidability of the all\ninstance chase termination problem on linear rules for three main chase\nvariants, namely semi-oblivious, restricted and core chase. To obtain these\nresults, we introduce a novel approach based on so-called derivation trees and\na single notion of forbidden pattern. Besides the theoretical interest of a\nunified approach and new proofs, we provide the first positive decidability\nresults concerning the termination of the restricted chase, proving that chase\ntermination on linear existential rules is decidable for both versions of the\nproblem: Does every fair chase sequence terminate? Does some fair chase\nsequence terminate?\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 10:09:11 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Leclere", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Thomazo", "Michael", ""], ["Ulliana", "Federico", ""]]}, {"id": "1810.02142", "submitter": "Alban Ponse", "authors": "Jan A. Bergstra, Alban Ponse, Daan J.C. Staudt", "title": "Propositional logic with short-circuit evaluation: a non-commutative and\n  a commutative variant", "comments": "34 pages, 6 tables. Considerable parts of the text below stem from\n  arXiv:1206.1936, arXiv:1010.3674, and arXiv:1707.05718. Together with\n  arXiv:1707.05718, this paper subsumes most of arXiv:1010.3674", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-circuit evaluation denotes the semantics of propositional connectives\nin which the second argument is evaluated only if the first argument does not\nsuffice to determine the value of the expression. Short-circuit evaluation is\nwidely used in programming, with sequential conjunction and disjunction as\nprimitive connectives.\n  We study the question which logical laws axiomatize short-circuit evaluation\nunder the following assumptions: compound statements are evaluated from left to\nright, each atom (propositional variable) evaluates to either true or false,\nand atomic evaluations can cause a side effect. The answer to this question\ndepends on the kind of atomic side effects that can occur and leads to\ndifferent \"short-circuit logics\". The basic case is FSCL (free short-circuit\nlogic), which characterizes the setting in which each atomic evaluation can\ncause a side effect. We recall some main results and then relate FSCL to MSCL\n(memorizing short-circuit logic), where in the evaluation of a compound\nstatement, the first evaluation result of each atom is memorized. MSCL can be\nseen as a sequential variant of propositional logic: atomic evaluations cannot\ncause a side effect and the sequential connectives are not commutative. Then we\nrelate MSCL to SSCL (static short-circuit logic), the variant of propositional\nlogic that prescribes short-circuit evaluation with commutative sequential\nconnectives.\n  We present evaluation trees as an intuitive semantics for short-circuit\nevaluation, and simple equational axiomatizations for the short-circuit logics\nmentioned that use negation and the sequential connectives only.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 10:42:37 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Bergstra", "Jan A.", ""], ["Ponse", "Alban", ""], ["Staudt", "Daan J. C.", ""]]}, {"id": "1810.02239", "submitter": "Christoph Rauch", "authors": "Andrew Polonsky", "title": "Fixed point combinators as fixed points of higher-order fixed point\n  generators", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (July 23,\n  2020) lmcs:6659", "doi": "10.23638/LMCS-16(3:7)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Corrado B\\\"ohm once observed that if $Y$ is any fixed point combinator (fpc),\nthen $Y(\\lambda yx.x(yx))$ is again fpc. He thus discovered the first \"fpc\ngenerating scheme\" -- a generic way to build new fpcs from old. Continuing this\nidea, define an $\\textit{fpc generator}$ to be any sequence of terms\n$G_1,\\dots,G_n$ such that \\[ Y \\in FPC \\Rightarrow Y G_1 \\cdots G_n \\in FPC \\]\nIn this contribution, we take first steps in studying the structure of (weak)\nfpc generators. We isolate several robust classes of such generators, by\nexamining their elementary properties like injectivity and (weak) constancy. We\nprovide sufficient conditions for existence of fixed points of a given\ngenerator $(G_1,\\cdots,G_n)$: an fpc $Y$ such that $Y = Y G_1 \\cdots G_n$. We\nconjecture that weak constancy is a necessary condition for existence of such\n(higher-order) fixed points. This statement generalizes Statman's conjecture on\nnon-existence of \"double fpcs\": fixed points of the generator $(G) = (\\lambda\nyx.x(yx))$ discovered by B\\\"ohm.\n  Finally, we define and make a few observations about the monoid of (weak) fpc\ngenerators. This enables us to formulate new a conjecture about their\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:24:37 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 09:57:43 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 13:52:01 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Polonsky", "Andrew", ""]]}, {"id": "1810.02241", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Arnaud Durand and Sabrina Ouazzani", "title": "Recursion schemes, discrete differential equations and characterization\n  of polynomial time computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers studies the expressive and computational power of discrete\nOrdinary Differential Equations (ODEs). It presents a new framework using\ndiscrete ODEs as a central tool for computation and provides several implicit\ncharacterizations of complexity and computability classes.\n  The proposed framework presents an original point of view on complexity and\ncomputability classes. It also unifies in an elegant settings various\nconstructions that have been proposed for characterizing these classes. This\nincludes Cobham's and, Bellantoni and Cook's definition of polynomial time and\nlater extensions on the approach, as well as recent characterizations of\ncomputability and complexity by classes of ordinary differential equations. It\nalso helps understanding the relationships between analog computations and\nclassical discrete models of computation theory.\n  At a more technical point of view, this paper points out the fundamental role\nof linear (discrete) ordinary differential equations and classical ODE tools\nsuch as changes of variables to capture computability and complexity measures,\nor as a tool for programming various algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:27:25 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 20:36:16 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bournez", "Olivier", ""], ["Durand", "Arnaud", ""], ["Ouazzani", "Sabrina", ""]]}, {"id": "1810.02389", "submitter": "Sebastian Siebertz", "authors": "Jakub Gajarsk\\'y, Stephan Kreutzer, Jaroslav Ne\\v{s}et\\v{r}il, Patrice\n  Ossona de Mendez, Micha{\\l} Pilipczuk, Sebastian Siebertz, Szymon Toru\\'nczyk", "title": "First-order interpretations of bounded expansion classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of bounded expansion captures uniform sparsity of graph classes\nand renders various algorithmic problems that are hard in general tractable. In\nparticular, the model-checking problem for first-order logic is fixed-parameter\ntractable over such graph classes. With the aim of generalizing such results to\ndense graphs, we introduce classes of graphs with structurally bounded\nexpansion, defined as first-order interpretations of classes of bounded\nexpansion. As a first step towards their algorithmic treatment, we provide\ntheir characterization analogous to the characterization of classes of bounded\nexpansion via low treedepth decompositions, replacing treedepth by its dense\nanalogue called shrubdepth.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 18:40:46 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Gajarsk\u00fd", "Jakub", ""], ["Kreutzer", "Stephan", ""], ["Ne\u0161et\u0159il", "Jaroslav", ""], ["de Mendez", "Patrice Ossona", ""], ["Pilipczuk", "Micha\u0142", ""], ["Siebertz", "Sebastian", ""], ["Toru\u0144czyk", "Szymon", ""]]}, {"id": "1810.02434", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Abstracting Probabilistic Models: A Logical Perspective", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence,\n  2020. (This is the extended version.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is a powerful idea widely used in science, to model, reason and\nexplain the behavior of systems in a more tractable search space, by omitting\nirrelevant details. While notions of abstraction have matured for deterministic\nsystems, the case for abstracting probabilistic models is not yet fully\nunderstood.\n  In this paper, we provide a semantical framework for analyzing such\nabstractions from first principles. We develop the framework in a general way,\nallowing for expressive languages, including logic-based ones that admit\nrelational and hierarchical constructs with stochastic primitives. We motivate\na definition of consistency between a high-level model and its low-level\ncounterpart, but also treat the case when the high-level model is missing\ncritical information present in the low-level model. We prove properties of\nabstractions, both at the level of the parameter as well as the structure of\nthe models. We conclude with some observations about how abstractions can be\nderived automatically.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:39:38 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:25:44 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 13:44:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "1810.02438", "submitter": "EPTCS", "authors": "Bart Jacobs (Radboud University)", "title": "Lower and Upper Conditioning in Quantum Bayesian Theory", "comments": "In Proceedings QPL 2018, arXiv:1901.09476", "journal-ref": "EPTCS 287, 2019, pp. 225-238", "doi": "10.4204/EPTCS.287.13", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Updating a probability distribution in the light of new evidence is a very\nbasic operation in Bayesian probability theory. It is also known as state\nrevision or simply as conditioning. This paper recalls how locally updating a\njoint state can equivalently be described via inference using the channel\nextracted from the state (via disintegration). This paper also investigates the\nquantum analogues of conditioning, and in particular the analogues of this\nequivalence between updating a joint state and inference. The main finding is\nthat in order to obtain a similar equivalence, we have to distinguish two forms\nof quantum conditioning, which we call lower and upper conditioning. They are\nknown from the literature, but the common framework in which we describe them\nand the equivalence result are new.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:55:14 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 05:38:53 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Jacobs", "Bart", "", "Radboud University"]]}, {"id": "1810.02468", "submitter": "EPTCS", "authors": "Franco Barbanera (Dipartimento di Matematica e Informatica, University\n  of Catania), Ugo de'Liguoro (Dipartimento di Informatica, University of\n  Torino), Rolf Hennicker (Institute of Informatics, LMU Munich)", "title": "Global Types for Open Systems", "comments": "In Proceedings ICE 2018, arXiv:1810.02053", "journal-ref": "EPTCS 279, 2018, pp. 4-20", "doi": "10.4204/EPTCS.279.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global-type formalisms enable to describe the overall behaviour of\ndistributed systems and at the same time to enforce safety properties for\ncommunications between system components. Our goal is that of amending a\nweakness of such formalisms: the difficulty in describing open systems, i.e.\nsystems which can be connected and interact with other open systems. We\nparametrically extend, with the notion of interface role and interface\nconnection, the syntax of global-type formalisms. Semantically, global types\nwith interface roles denote open systems of communicating finite state machines\nconnected by means of gateways obtained from compatible interfaces. We show\nthat safety properties are preserved when open systems are connected that way.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:33:49 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Barbanera", "Franco", "", "Dipartimento di Matematica e Informatica, University\n  of Catania"], ["de'Liguoro", "Ugo", "", "Dipartimento di Informatica, University of\n  Torino"], ["Hennicker", "Rolf", "", "Institute of Informatics, LMU Munich"]]}, {"id": "1810.02469", "submitter": "EPTCS", "authors": "Roberto Guanciale Dr (KTH Royal Institute of Technology), Emilio\n  Tuosto Dr (University of Leicester)", "title": "Realisability of Pomsets via Communicating Automata", "comments": "In Proceedings ICE 2018, arXiv:1810.02053", "journal-ref": "EPTCS 279, 2018, pp. 37-51", "doi": "10.4204/EPTCS.279.6", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pomsets are a model of concurrent computations introduced by Pratt. They can\nprovide a syntax-oblivious description of semantics of coordination models\nbased on asynchronous message-passing, such as Message Sequence Charts (MSCs).\nIn this paper, we study conditions that ensure a specification expressed as a\nset of pomsets can be faithfully realised via communicating automata. Our main\ncontributions are (i) the definition of a realisability condition accounting\nfor termination soundness, (ii) conditions for global specifications with\n\"multi-threaded\" participants, and (iii) the definition of realisability\nconditions that can be decided directly over pomsets. A positive by-product of\nour approach is the efficiency gain in the verification of the realisability\nconditions obtained when restricting to specific classes of choreographies\ncharacterisable in term of behavioural types.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:34:36 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Dr", "Roberto Guanciale", "", "KTH Royal Institute of Technology"], ["Dr", "Emilio Tuosto", "", "University of Leicester"]]}, {"id": "1810.02471", "submitter": "EPTCS", "authors": "Alexandre Mansard (LIM - University of La R\\'eunion)", "title": "Unfolding of Finite Concurrent Automata", "comments": "In Proceedings ICE 2018, arXiv:1810.02053", "journal-ref": "EPTCS 279, 2018, pp. 68-84", "doi": "10.4204/EPTCS.279.8", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider recognizable trace rewriting systems with level-regular contexts\n(RTL). A trace language is level-regular if the set of Foata normal forms of\nits elements is regular. We prove that the rewriting graph of a RTL is\nword-automatic. Thus its first-order theory is decidable. Then, we prove that\nthe concurrent unfolding of a finite concurrent automaton with the reachability\nrelation is a RTL graph. It follows that the first-order theory with the\nreachability predicate (FO[Reach] theory) of such an unfolding is decidable. It\nis known that this property holds also for the ground term rewriting graphs. We\nprovide examples of finite concurrent automata of which the concurrent\nunfoldings fail to be ground term rewriting graphs. The infinite grid tree (for\neach vertex of an infinite grid, there is an edge from this vertex to the\norigin of a copy of the infinite grid) is such an unfolding. We prove that the\ninfinite grid tree is not a ground term rewriting graph. We have thus obtained\na new class of graphs for with a decidable FO[Reach] theory.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:35:24 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Mansard", "Alexandre", "", "LIM - University of La R\u00e9union"]]}, {"id": "1810.02472", "submitter": "EPTCS", "authors": "Maurizio Murgia (University of Kent)", "title": "On Urgency in Asynchronous Timed Session Types", "comments": "In Proceedings ICE 2018, arXiv:1810.02053", "journal-ref": "EPTCS 279, 2018, pp. 85-94", "doi": "10.4204/EPTCS.279.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an urgent semantics of asynchronous timed session types, where input\nactions happen as soon as possible. We show that with this semantics we can\nrecover to the timed setting an appealing property of untimed session types:\nnamely, deadlock-freedom is preserved when passing from synchronous to\nasynchronous communication.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:35:45 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Murgia", "Maurizio", "", "University of Kent"]]}, {"id": "1810.02769", "submitter": "Rustam Galimullin", "authors": "Rustam Galimullin and Natasha Alechina", "title": "Coalition and Group Announcement Logic", "comments": "This is a corrected version of arXiv:1707.08746v1, which appeared in\n  Proceedings TARK 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic epistemic logics which model abilities of agents to make various\nannouncements and influence each other's knowledge have been studied\nextensively in recent years. Two notable examples of such logics are Group\nAnnouncement Logic and Coalition Announcement Logic. They allow us to reason\nabout what groups of agents can achieve through joint announcements in\nnon-competitive and competitive environments. In this paper, we consider a\ncombination of these logics -- Coalition and Relativised Group Announcement\nLogic and provide its complete axiomatisation. Moreover, we partially answer\nthe question of how group and coalition announcement operators interact, and\nsettle some other open problems.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:49:25 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Galimullin", "Rustam", ""], ["Alechina", "Natasha", ""]]}, {"id": "1810.02929", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "System Consequence", "comments": "18 pages, 2 figures, 17th International Conference on Conceptual\n  Structures, ICCS'09, Conceptual Structures: Leveraging Semantic Technologies,\n  July 26-31, 2009, Moscow, Russia", "journal-ref": "Lecture Notes in Computer Science 5662, Springer 2009, ISBN\n  978-3-642-03078-9", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses system consequence, a central idea in the project to\nlift the theory of information flow to the abstract level of universal logic\nand the theory of institutions. The theory of information flow is a theory of\ndistributed logic. The theory of institutions is abstract model theory. A\nsystem is a collection of interconnected parts, where the whole may have\nproperties that cannot be known from an analysis of the constituent parts in\nisolation. In an information system, the parts represent information resources\nand the interconnections represent constraints between the parts. System\nconsequence, which is the extension of the consequence operator from theories\nto systems, models the available regularities represented by an information\nsystem as a whole. System consequence (without part-to-part constraints) is\ndefined for a specific logical system (institution) in the theory of\ninformation flow. This paper generalizes the idea of system consequence to\narbitrary logical systems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 03:47:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.03386", "submitter": "Jef Wijsen", "authors": "Paraschos Koutris and Jef Wijsen", "title": "Consistent Query Answering for Primary Keys in Logspace", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of consistent query answering on databases that may\nviolate primary key constraints. A repair of such a database is any consistent\ndatabase that can be obtained by deleting a minimal set of tuples. For every\nBoolean query q, CERTAINTY(q) is the problem that takes a database as input and\nasks whether q evaluates to true on every repair. In [KW17], the authors show\nthat for every self-join-free Boolean conjunctive query q, the problem\nCERTAINTY(q) is either in P or coNP-complete, and it is decidable which of the\ntwo cases applies. In this paper, we sharpen this result by showing that for\nevery self-join-free Boolean conjunctive query q, the problem CERTAINTY(q) is\neither expressible in symmetric stratified Datalog or coNP-complete. Since\nsymmetric stratified Datalog is in L, we thus obtain a complexity-theoretic\ndichotomy between L and coNP-complete. Another new finding of practical\nimportance is that CERTAINTY(q) is on the logspace side of the dichotomy for\nqueries q where all join conditions express foreign-to-primary key matches,\nwhich is undoubtedly the most common type of join condition.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:50:20 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Koutris", "Paraschos", ""], ["Wijsen", "Jef", ""]]}, {"id": "1810.03395", "submitter": "J\\'er\\'emie Chalopin", "authors": "J\\'er\\'emie Chalopin and Victor Chepoi", "title": "1-Safe Petri nets and special cube complexes: equivalence and\n  applications", "comments": null, "journal-ref": null, "doi": "10.1145/3322095", "report-no": null, "categories": "cs.LO cs.DM cs.FL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nielsen, Plotkin, and Winskel (1981) proved that every 1-safe Petri net $N$\nunfolds into an event structure $\\mathcal{E}_N$. By a result of Thiagarajan\n(1996 and 2002), these unfoldings are exactly the trace regular event\nstructures. Thiagarajan (1996 and 2002) conjectured that regular event\nstructures correspond exactly to trace regular event structures. In a recent\npaper (Chalopin and Chepoi, 2017, 2018), we disproved this conjecture, based on\nthe striking bijection between domains of event structures, median graphs, and\nCAT(0) cube complexes. On the other hand, in Chalopin and Chepoi (2018) we\nproved that Thiagarajan's conjecture is true for regular event structures whose\ndomains are principal filters of universal covers of (virtually) finite special\ncube complexes.\n  In the current paper, we prove the converse: to any finite 1-safe Petri net\n$N$ one can associate a finite special cube complex ${X}_N$ such that the\ndomain of the event structure $\\mathcal{E}_N$ (obtained as the unfolding of\n$N$) is a principal filter of the universal cover $\\widetilde{X}_N$ of $X_N$.\nThis establishes a bijection between 1-safe Petri nets and finite special cube\ncomplexes and provides a combinatorial characterization of trace regular event\nstructures.\n  Using this bijection and techniques from graph theory and geometry (MSO\ntheory of graphs, bounded treewidth, and bounded hyperbolicity) we disprove yet\nanother conjecture by Thiagarajan (from the paper with S. Yang from 2014) that\nthe monadic second order logic of a 1-safe Petri net is decidable if and only\nif its unfolding is grid-free.\n  Our counterexample is the trace regular event structure $\\mathcal{\\dot E}_Z$\nwhich arises from a virtually special square complex $\\dot Z$. The domain of\n$\\mathcal{\\dot E}_Z$ is grid-free (because it is hyperbolic), but the MSO\ntheory of the event structure $\\mathcal{\\dot E}_Z$ is undecidable.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:15:45 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 12:39:24 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Chalopin", "J\u00e9r\u00e9mie", ""], ["Chepoi", "Victor", ""]]}, {"id": "1810.03736", "submitter": "Lewis Hammond", "authors": "Lewis Hammond and Vaishak Belle", "title": "Learning Tractable Probabilistic Models for Moral Responsibility and\n  Blame", "comments": "Published in Data Mining and Knowledge Discovery (2021)", "journal-ref": null, "doi": "10.1007/s10618-020-00726-4", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moral responsibility is a major concern in autonomous systems, with\napplications ranging from self-driving cars to kidney exchanges. Although there\nhave been recent attempts to formalise responsibility and blame, among similar\nnotions, the problem of learning within these formalisms has been unaddressed.\nFrom the viewpoint of such systems, the urgent questions are: (a) How can\nmodels of moral scenarios and blameworthiness be extracted and learnt\nautomatically from data? (b) How can judgements be computed effectively and\nefficiently, given the split-second decision points faced by some systems? By\nbuilding on constrained tractable probabilistic learning, we propose and\nimplement a hybrid (between data-driven and rule-based methods) learning\nframework for inducing models of such scenarios automatically from data and\nreasoning tractably from them. We report on experiments that compare our system\nwith human judgement in three illustrative domains: lung cancer staging,\nteamwork management, and trolley problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:51:17 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:09:05 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 19:37:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hammond", "Lewis", ""], ["Belle", "Vaishak", ""]]}, {"id": "1810.03762", "submitter": "EPTCS", "authors": "Shilpi Goel (Centaur Technology, Inc.), Matt Kaufmann (The University\n  of Texas at Austin)", "title": "Proceedings of the 15th International Workshop on the ACL2 Theorem\n  Prover and Its Applications", "comments": null, "journal-ref": "EPTCS 280, 2018", "doi": "10.4204/EPTCS.280", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Fifteenth International Workshop\non the ACL2 Theorem Prover and Its Applications (ACL2-2018), a two-day workshop\nheld in Austin, Texas, USA, on November 5-6, 2018, immediately after FMCAD'18.\nThe proceedings of ACL2-2018 include eleven long papers and two extended\nabstracts.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 00:41:08 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 04:51:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Goel", "Shilpi", "", "Centaur Technology, Inc."], ["Kaufmann", "Matt", "", "The University\n  of Texas at Austin"]]}, {"id": "1810.04309", "submitter": "EPTCS", "authors": "Mihir Parang Mehta (UT Austin)", "title": "Formalising Filesystems in the ACL2 Theorem Prover: an Application to\n  FAT32", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 18-29", "doi": "10.4204/EPTCS.280.2", "report-no": null, "categories": "cs.LO cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an approach towards constructing executable\nspecifications of existing filesystems and verifying their functional\nproperties in a theorem proving environment. We detail an application of this\napproach to the FAT32 filesystem.\n  We also detail the methodology used to build up this type of executable\nspecification through a series of models which incrementally add features of\nthe target filesystem. This methodology has the benefit of allowing the\nverification effort to start from simple models which encapsulate features\ncommon to many filesystems and which are thus suitable for reuse.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:35:05 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Mehta", "Mihir Parang", "", "UT Austin"]]}, {"id": "1810.04310", "submitter": "EPTCS", "authors": "David Greve (Rockwell Collins), Andrew Gacek (Rockwell Collins)", "title": "Trapezoidal Generalization over Linear Constraints", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 30-46", "doi": "10.4204/EPTCS.280.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are developing a model-based fuzzing framework that employs mathematical\nmodels of system behavior to guide the fuzzing process. Whereas traditional\nfuzzing frameworks generate tests randomly, a model-based framework can deduce\ntests from a behavioral model using a constraint solver. Because the state\nspace being explored by the fuzzer is often large, the rapid generation of test\nvectors is crucial. The need to generate tests quickly, however, is\nantithetical to the use of a constraint solver. Our solution to this problem is\nto use the constraint solver to generate an initial solution, to generalize\nthat solution relative to the system model, and then to perform rapid,\nrepeated, randomized sampling of the generalized solution space to generate\nfuzzing tests. Crucial to the success of this endeavor is a generalization\nprocedure with reasonable size and performance costs that produces generalized\nsolution spaces that can be sampled efficiently. This paper describes a\ngeneralization technique for logical formulae expressed in terms of Boolean\ncombinations of linear constraints that meets the unique performance\nrequirements of model-based fuzzing. The technique represents generalizations\nusing trapezoidal solution sets consisting of ordered, hierarchical\nconjunctions of linear constraints that are more expressive than simple\nintervals but are more efficient to manipulate and sample than generic\npolytopes. Supporting materials contain an ACL2 proof that verifies the\ncorrectness of a low-level implementation of the generalization algorithm\nagainst a specification of generalization correctness. Finally a\npost-processing procedure is described that results in a restricted trapezoidal\nsolution that can be sampled (solved) rapidly and efficiently without\nbacktracking, even for integer domains. While informal correctness arguments\nare provided, a formal proof of the correctness of the restriction algorithm\nremains as future work.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:35:27 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Greve", "David", "", "Rockwell Collins"], ["Gacek", "Andrew", "", "Rockwell Collins"]]}, {"id": "1810.04311", "submitter": "EPTCS", "authors": "Sol Swords (Centaur Technology, Inc.)", "title": "Incremental SAT Library Integration Using Abstract Stobjs", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 47-60", "doi": "10.4204/EPTCS.280.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an effort to soundly use off-the-shelf incremental SAT solvers\nwithin ACL2 by modeling the behavior of a SAT solver library as an abstract\nstobj. The interface allows ACL2 programs to use incremental SAT solvers, and\nthe abstract stobj model allows us to reason about the behavior of an\nincremental SAT library so as to show that algorithms implemented using it are\ncorrect, as long as the library is bug-free.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:35:47 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Swords", "Sol", "", "Centaur Technology, Inc."]]}, {"id": "1810.04312", "submitter": "EPTCS", "authors": "David Hardin (Rockwell Collins), Konrad Slind (Rockwell Collins)", "title": "Using ACL2 in the Design of Efficient, Verifiable Data Structures for\n  High-Assurance Systems", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 61-76", "doi": "10.4204/EPTCS.280.5", "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of algorithms and data structures utilized in modern autonomous\nand semi-autonomous vehicles for land, sea, air, and space presents a\nsignificant challenge. Autonomy algorithms, e.g., route planning, pattern\nmatching, and inference, are based on complex data structures such as directed\ngraphs and algebraic data types. Proof techniques for these data structures\nexist, but are oriented to unbounded, functional realizations, which are not\ntypically efficient in either space or time. Autonomous systems designers, on\nthe other hand, generally limit the space and time allocations for any given\nfunction, and require that algorithms deliver results within a finite time, or\nsuffer a watchdog timeout. Furthermore, high-assurance design rules frown on\ndynamic memory allocation, preferring simple array-based data structure\nimplementations.\n  In order to provide efficient implementations of high-level data structures\nused in autonomous systems with the high assurance needed for accreditation, we\nhave developed a verifying compilation technique that supports the \"natural\"\nfunctional proof style, but yet applies to more efficient data structure\nimplementations. Our toolchain features code generation to mainstream\nprogramming languages, as well as GPU-based and hardware-based realizations. We\nbase the Intermediate Verification Language for our toolchain upon higher-order\nlogic; however, we have used ACL2 to develop our efficient yet verifiable data\nstructure design. ACL2 is particularly well-suited for this work, with its\nsophisticated libraries for reasoning about aggregate data structures of\narbitrary size, efficient execution of formal specifications, as well as its\nsupport for \"single-threaded objects\" -- functional datatypes with imperative\n\"under the hood\" implementations.\n  In this paper, we detail our high-assurance data structure design approach,\nincluding examples in ACL2 of common algebraic data types implemented using\nthis design approach, proofs of correctness for those data types carried out in\nACL2, as well as sample ACL2 implementations of relevant algorithms utilizing\nthese efficient, high-assurance data structures.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:36:03 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Hardin", "David", "", "Rockwell Collins"], ["Slind", "Konrad", "", "Rockwell Collins"]]}, {"id": "1810.04313", "submitter": "EPTCS", "authors": "Alessandro Coglio (Kestrel Technology LLC, Palo Alto, CA (USA)),\n  Shilpi Goel (Centaur Technology, Inc., Austin, TX (USA))", "title": "Adding 32-bit Mode to the ACL2 Model of the x86 ISA", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 77-94", "doi": "10.4204/EPTCS.280.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ACL2 model of the x86 Instruction Set Architecture was built for the\n64-bit mode of operation of the processor. This paper reports on our work to\nextend the model with support for 32-bit mode, recounting the salient aspects\nof this activity and identifying the ones that required the most work.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:36:20 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Coglio", "Alessandro", "", "Kestrel Technology LLC, Palo Alto, CA"], ["Goel", "Shilpi", "", "Centaur Technology, Inc., Austin, TX"]]}, {"id": "1810.04314", "submitter": "EPTCS", "authors": "Ruben Gamboa (University of Wyoming), John Cowles (University of\n  Wyoming)", "title": "The Fundamental Theorem of Algebra in ACL2", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 98-110", "doi": "10.4204/EPTCS.280.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on a verification of the Fundamental Theorem of Algebra in ACL2(r).\nThe proof consists of four parts. First, continuity for both complex-valued and\nreal-valued functions of complex numbers is defined, and it is shown that\ncontinuous functions from the complex to the real numbers achieve a minimum\nvalue over a closed square region. An important case of continuous real-valued,\ncomplex functions results from taking the traditional complex norm of a\ncontinuous complex function. We think of these continuous functions as having\nonly one (complex) argument, but in ACL2(r) they appear as functions of two\narguments. The extra argument is a \"context\", which is uninterpreted. For\nexample, it could be other arguments that are held fixed, as in an exponential\nfunction which has a base and an exponent, either of which could be held fixed.\nSecond, it is shown that complex polynomials are continuous, so the norm of a\ncomplex polynomial is a continuous real-valued function and it achieves its\nminimum over an arbitrary square region centered at the origin. This part of\nthe proof benefits from the introduction of the \"context\" argument, and it\nillustrates an innovation that simplifies the proofs of classical properties\nwith unbound parameters. Third, we derive lower and upper bounds on the norm of\nnon-constant polynomials for inputs that are sufficiently far away from the\norigin. This means that a sufficiently large square can be found to guarantee\nthat it contains the global minimum of the norm of the polynomial. Fourth, it\nis shown that if a given number is not a root of a non-constant polynomial,\nthen it cannot be the global minimum. Finally, these results are combined to\nshow that the global minimum must be a root of the polynomial. This result is\npart of a larger effort in the formalization of complex polynomials in ACL2(r).\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:36:54 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Gamboa", "Ruben", "", "University of Wyoming"], ["Cowles", "John", "", "University of\n  Wyoming"]]}, {"id": "1810.04315", "submitter": "EPTCS", "authors": "Carl Kwan (University of British Columbia), Mark R. Greenstreet\n  (University of British Columbia)", "title": "Real Vector Spaces and the Cauchy-Schwarz Inequality in ACL2(r)", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 111-127", "doi": "10.4204/EPTCS.280.9", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanical proof of the Cauchy-Schwarz inequality in ACL2(r) and\na formalisation of the necessary mathematics to undertake such a proof. This\nincludes the formalisation of $\\mathbb{R}^n$ as an inner product space. We also\nprovide an application of Cauchy-Schwarz by formalising $\\mathbb R^n$ as a\nmetric space and exhibiting continuity for some simple functions $\\mathbb\nR^n\\to\\mathbb R$. The Cauchy-Schwarz inequality relates the magnitude of a\nvector to its projection (or inner product) with another: \\[|\\langle\nu,v\\rangle| \\leq \\|u\\| \\|v\\|\\] with equality iff the vectors are linearly\ndependent. It finds frequent use in many branches of mathematics including\nlinear algebra, real analysis, functional analysis, probability, etc. Indeed,\nthe inequality is considered to be among \"The Hundred Greatest Theorems\" and is\nlisted in the \"Formalizing 100 Theorems\" project. To the best of our knowledge,\nour formalisation is the first published proof using ACL2(r) or any other\nfirst-order theorem prover.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:37:12 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kwan", "Carl", "", "University of British Columbia"], ["Greenstreet", "Mark R.", "", "University of British Columbia"]]}, {"id": "1810.04316", "submitter": "EPTCS", "authors": "Carl Kwan (University of British Columbia), Mark R. Greenstreet\n  (University of British Columbia)", "title": "Convex Functions in ACL2(r)", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 128-142", "doi": "10.4204/EPTCS.280.10", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds upon our prior formalisation of R^n in ACL2(r) by\npresenting a set of theorems for reasoning about convex functions. This is a\ndemonstration of the higher-dimensional analytical reasoning possible in our\nmetric space formalisation of R^n. Among the introduced theorems is a set of\nequivalent conditions for convex functions with Lipschitz continuous gradients\nfrom Yurii Nesterov's classic text on convex optimisation. To the best of our\nknowledge a full proof of the theorem has yet to be published in a single piece\nof literature. We also explore \"proof engineering\" issues, such as how to state\nNesterov's theorem in a manner that is both clear and useful.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:37:29 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kwan", "Carl", "", "University of British Columbia"], ["Greenstreet", "Mark R.", "", "University of British Columbia"]]}, {"id": "1810.04317", "submitter": "EPTCS", "authors": "Yan Peng (University of British Columbia), Mark R. Greenstreet\n  (University of British Columbia)", "title": "Smtlink 2.0", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 143-160", "doi": "10.4204/EPTCS.280.11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smtlink is an extension of ACL2 with Satisfiability Modulo Theories (SMT)\nsolvers. We presented an earlier version at ACL2'2015. Smtlink 2.0 makes major\nimprovements over the initial version with respect to soundness, extensibility,\nease-of-use, and the range of types and associated theory-solvers supported.\nMost theorems that one would want to prove using an SMT solver must first be\ntranslated to use only the primitive operations supported by the SMT solver --\nthis translation includes function expansion and type inference. Smtlink 2.0\nperforms this translation using a sequence of steps performed by verified\nclause processors and computed hints. These steps are ensured to be sound. The\nfinal transliteration from ACL2 to Z3's Python interface requires a trusted\nclause processor. This is a great improvement in soundness and extensibility\nover the original Smtlink which was implemented as a single, monolithic,\ntrusted clause processor. Smtlink 2.0 provides support for FTY defprod,\ndeflist, defalist, and defoption types by using Z3's arrays and user-defined\ndata types. We have identified common usage patterns and simplified the\nconfiguration and hint information needed to use Smtlink.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:37:47 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Peng", "Yan", "", "University of British Columbia"], ["Greenstreet", "Mark R.", "", "University of British Columbia"]]}, {"id": "1810.04318", "submitter": "EPTCS", "authors": "Sol Swords (Centaur Technology, Inc.)", "title": "Hint Orchestration Using ACL2's Simplifier", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 164-171", "doi": "10.4204/EPTCS.280.13", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a strategy for providing hints during an ACL2 proof,\nimplemented in a utility called use-termhint. An extra literal is added to the\ngoal clause and simplified along with the rest of the goal until it is stable\nunder simplification, after which the simplified literal is examined and a hint\nextracted from it. This simple technique supports some commonly desirable yet\nelusive features. It supports providing different hints to different cases of a\ncase split, as well as binding variables so as to avoid repeating multiply\nreferenced subterms. Since terms used in these hints are simplified in the same\nway as the rest of the goal, this strategy is also more robust against changes\nin the rewriting normal form than hints in which terms from the goal are\nwritten out explicitly.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:38:04 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Swords", "Sol", "", "Centaur Technology, Inc."]]}, {"id": "1810.04363", "submitter": "Denis Ponomaryov", "authors": "Denis Ponomaryov and Stepan Yakovenko", "title": "DeFind: A Protege Plugin for Computing Concept Definitions in EL\n  Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension to the Protege ontology editor, which allows for\ndiscovering concept definitions, which are not explicitly present in axioms,\nbut are logically implied by an ontology. The plugin supports ontologies\nformulated in the Description Logic EL, which underpins the OWL 2 EL profile of\nthe Web Ontology Language and despite its limited expressiveness captures most\nof the biomedical ontologies published on the Web. The developed tool allows to\nverify whether a concept can be defined using a vocabulary of interest\nspecified by a user. In particular, it allows to decide whether some vocabulary\nitems can be omitted in a formulation of a complex concept. The corresponding\ndefinitions are presented to the user and are provided with explanations\ngenerated by an ontology reasoner.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 04:14:59 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Ponomaryov", "Denis", ""], ["Yakovenko", "Stepan", ""]]}, {"id": "1810.04412", "submitter": "Ankit Kumar Shukla", "authors": "Ashutosh Gupta, Somya Mani, and Ankit Shukla", "title": "Synthesis for Vesicle Traffic Systems", "comments": "18 pages, 2 figures, 1 table", "journal-ref": null, "doi": "10.1007/978-3-319-99429-1_6", "report-no": null, "categories": "q-bio.SC cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vesicle Traffic Systems (VTSs) are the material transport mechanisms among\nthe compartments inside the biological cells. The compartments are viewed as\nnodes that are labeled with the containing chemicals and the transport channels\nare similarly viewed as labeled edges between the nodes. Understanding VTSs is\nan ongoing area of research and for many cells they are partially known. For\nexample, there may be undiscovered edges, nodes, or their labels in a VTS of a\ncell. It has been speculated that there are properties that the VTSs must\nsatisfy. For example, stability, i.e., every chemical that is leaving a\ncompartment comes back. Many synthesis questions may arise in this scenario,\nwhere we want to complete a partially known VTS under a given property. In the\npaper, we present novel encodings of the above questions into the QBF\n(quantified Boolean formula) satisfiability problems. We have implemented the\nencodings in a highly configurable tool and applied to a couple of\nfound-in-nature VTSs and several synthetic graphs. Our results demonstrate that\nour method can scale up to the graphs of interest.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 08:34:50 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Gupta", "Ashutosh", ""], ["Mani", "Somya", ""], ["Shukla", "Ankit", ""]]}, {"id": "1810.04707", "submitter": "Houssam Nassif", "authors": "Houssam Nassif, Hassan Al-Ali, Sawsan Khuri, Walid Keirouz, and David\n  Page", "title": "An Inductive Logic Programming Approach to Validate Hexose Binding\n  Biochemical Knowledge", "comments": null, "journal-ref": "International Conference on Inductive Logic Programming (ILP'09),\n  Leuven, Belgium, pp. 149-165, 2009", "doi": "10.1007/978-3-642-13840-9_14", "report-no": null, "categories": "q-bio.OT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hexoses are simple sugars that play a key role in many cellular pathways, and\nin the regulation of development and disease mechanisms. Current protein-sugar\ncomputational models are based, at least partially, on prior biochemical\nfindings and knowledge. They incorporate different parts of these findings in\npredictive black-box models. We investigate the empirical support for\nbiochemical findings by comparing Inductive Logic Programming (ILP) induced\nrules to actual biochemical results. We mine the Protein Data Bank for a\nrepresentative data set of hexose binding sites, non-hexose binding sites and\nsurface grooves. We build an ILP model of hexose-binding sites and evaluate our\nresults against several baseline machine learning classifiers. Our method\nachieves an accuracy similar to that of other black-box classifiers while\nproviding insight into the discriminating process. In addition, it confirms\nwet-lab findings and reveals a previously unreported Trp-Glu amino acids\ndependency.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:59:18 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Nassif", "Houssam", ""], ["Al-Ali", "Hassan", ""], ["Khuri", "Sawsan", ""], ["Keirouz", "Walid", ""], ["Page", "David", ""]]}, {"id": "1810.04722", "submitter": "Paul Wild", "authors": "Paul Wild, Lutz Schr\\\"oder, Dirk Pattinson, Barbara K\\\"onig", "title": "A van Benthem Theorem for Quantitative Probabilistic Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In probabilistic transition systems, behavioural metrics provide a more\nfine-grained and stable measure of system equivalence than crisp notions of\nbisimilarity. They correlate strongly to quantitative probabilistic logics, and\nin fact the distance induced by a probabilistic modal logic taking values in\nthe real unit interval has been shown to coincide with behavioural distance.\nFor probabilistic systems, probabilistic modal logic thus plays an analogous\nrole to that of Hennessy-Milner logic on classical labelled transition systems.\nIn the quantitative setting, invariance of modal logic under bisimilarity\nbecomes non-expansivity of formula evaluation w.r.t. behavioural distance. In\nthe present paper, we provide a characterization of the expressive power of\nprobabilistic modal logic based on this observation: We prove a probabilistic\nanalogue of the classical van Benthem theorem, which states that modal logic is\nprecisely the bisimulation-invariant fragment of first-order logic.\nSpecifically, we show that quantitative probabilistic modal logic lies dense in\nthe bisimulation-invariant fragment, in the indicated sense of non-expansive\nformula evaluation, of quantitative probabilistic first-order logic; more\nprecisely, bisimulation-invariant first-order formulas are approximable by\nmodal formulas of bounded rank.\n  For a description logic perspective on the same result, see arXiv:1906.00784.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:31:46 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 13:07:12 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wild", "Paul", ""], ["Schr\u00f6der", "Lutz", ""], ["Pattinson", "Dirk", ""], ["K\u00f6nig", "Barbara", ""]]}, {"id": "1810.04763", "submitter": "Thorsten Wissmann", "authors": "Pawe{\\l} Parys", "title": "Recursion Schemes, the MSO Logic, and the U quantifier", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  18, 2020) lmcs:6111", "doi": "10.23638/LMCS-16(1:20)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the model-checking problem for recursion schemes: does the tree\ngenerated by a given higher-order recursion scheme satisfy a given logical\nsentence. The problem is known to be decidable for sentences of the MSO logic.\nWe prove decidability for an extension of MSO in which we additionally have an\nunbounding quantifier U, saying that a subformula is true for arbitrarily large\nfinite sets. This quantifier can be used only for subformulae in which all free\nvariables represent finite sets (while an unrestricted use of the quantifier\nleads to undecidability). We also show that the logic has the properties of\nreflection and effective selection for trees generated by recursion schemes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 22:14:01 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 05:01:16 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 06:50:17 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Parys", "Pawe\u0142", ""]]}, {"id": "1810.04774", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Distributed Conceptual Structures", "comments": "14 pages, 2 figures, Sixth International Workshop on Relational\n  Methods in Computer Science, RelMiCS 2001, Oisterwijk, The Netherlands,\n  October 16-21, 2001", "journal-ref": "Harre de Swart, editor, volume 2561, Lecture Notes in Computer\n  Science, pages 104-123. Springer, 2002", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of distributed conceptual structures, as outlined in this paper,\nis concerned with the distribution and conception of knowledge. It rests upon\ntwo related theories, Information Flow and Formal Concept Analysis, which it\nseeks to unify. Information Flow (IF) is concerned with the distribution of\nknowledge. The foundations of Information Flow is explicitly based upon a\nmathematical theory known as the Chu Construction in *-autonomous categories\nand implicitly based upon the mathematics of closed categories. Formal Concept\nAnalysis (FCA) is concerned with the conception and analysis of knowledge. In\nthis paper we connect these two studies by extending the basic theorem of\nFormal Concept Analysis to the distributed realm of Information Flow. The main\nresults are the categorical equivalence between classifications and concept\nlattices at the level of functions, and the categorical equivalence between\nbonds and complete adjoints at the level of relations. With this we hope to\naccomplish a rapprochement between Information Flow and Formal Concept\nAnalysis.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:13:23 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.04866", "submitter": "Vivek Nigam", "authors": "Vivek Nigam and Alexander Pretschner and Harald Ruess", "title": "Model-Based Safety and Security Engineering", "comments": "White paper on Safety and Security Engineering using Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By exploiting the increasing surface attack of systems, cyber-attacks can\ncause catastrophic events, such as, remotely disable safety mechanisms. This\nmeans that in order to avoid hazards, safety and security need to be\nintegrated, exchanging information, such as, key hazards/threats, risk\nevaluations, mechanisms used. This white paper describes some steps towards\nthis integration by using models. We start by identifying some key technical\nchallenges. Then we demonstrate how models, such as Goal Structured Notation\n(GSN) for safety and Attack Defense Trees (ADT) for security, can address these\nchallenges. In particular, (1) we demonstrate how to extract in an automated\nfashion security relevant information from safety assessments by translating\nGSN-Models into ADTs; (2) We show how security results can impact the\nconfidence of safety assessments; (3) We propose a collaborative development\nprocess where safety and security assessments are built by incrementally taking\ninto account safety and security analysis; (4) We describe how to carry out\ntrade-off analysis in an automated fashion, such as identifying when safety and\nsecurity arguments contradict each other and how to solve such contradictions.\nWe conclude pointing out that these are the first steps towards a wide range of\ntechniques to support Safety and Security Engineering. As a white paper, we\navoid being too technical, preferring to illustrate features by using examples\nand thus being more accessible.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 07:09:28 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 07:00:04 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Nigam", "Vivek", ""], ["Pretschner", "Alexander", ""], ["Ruess", "Harald", ""]]}, {"id": "1810.05010", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Dialectical logic: the Process Calculus", "comments": "34 pages, 1 figure, 3 tables.arXiv admin note: text overlap with\n  arXiv:1109.2247", "journal-ref": "Studia Scientiarum Mathematicarum Hungarica, Vol. 28, Nos. 1-2,\n  1993, pages 17-61 (invited paper)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialectical logic is the logic of dialectical processes. The goal of\ndialectical logic is to reveal the dynamical notions inherent in logical\ncomputational systems. The fundamental notions of proposition and truth-value\nin standard logic are subsumed by the notions of process and flow in\ndialectical logic. Standard logic motivates the core sequential aspect of\ndialectical logic. Horn-clause logic requires types and nonsymmetry and also\nmotivates the parallel aspect of dialectical logic. The process logics of\nMilner and Hoare reveal the internal/external aspects of dialectical logic. The\nsequential internal aspect of dialectical logic should be viewed as a typed or\ndistributed version of Girard's linear logic with nonsymmetric tensor. The\nsimplest version of dialectical logic is inherently intuitionistic. However, by\nfollowing Glivenko's approach in standard logic using double negation closure,\nwe can define a classical version of dialectical logic.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:59:05 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.05106", "submitter": "Nathana\\\"el Fijalkow", "authors": "Thomas Colcombet and Nathana\\\"el Fijalkow", "title": "Parity games and universal graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a contribution to the study of parity games and the recent\nconstructions of three quasipolynomial time algorithms for solving them. We\nrevisit a result of Czerwi\\'nski, Daviaud, Fijalkow, Jurdzi\\'nski, Lazi\\'c, and\nParys witnessing a quasipolynomial barrier for all three quasipolynomial time\nalgorithms. The argument is that all three algorithms can be understood as\nconstructing a so-called separating automaton, and to give a quasipolynomial\nlower bond on the size of separating automata.\n  We give an alternative proof of this result. The key innovations of this\npaper are the notion of universal graphs and the idea of saturation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 16:19:18 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 13:34:27 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Colcombet", "Thomas", ""], ["Fijalkow", "Nathana\u00ebl", ""]]}, {"id": "1810.05377", "submitter": "Emmanuel Jeandel", "authors": "Emmanuel Jeandel (MOCQUA)", "title": "The rational fragment of the ZX-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce here a new axiomatisation of the rational fragment of the\nZX-calculus, a diagrammatic language for quantum mechanics. Compared to the\nprevious axiomatisation introduced in [8], our axiomatisation does not use any\nmetarule , but relies instead on a more natural rule, called the cyclotomic\nsupplementarity rule, that was introduced previously in the literature. Our\naxiomatisation is only complete for diagrams using rational angles , and is not\ncomplete in the general case. Using results on diophantine geometry, we\ncharacterize precisely which diagram equality involving arbitrary angles are\nprovable in our framework without any new axioms, and we show that our\naxiomatisation is continuous, in the sense that a diagram equality involving\narbitrary angles is provable iff it is a limit of diagram equalities involving\nrational angles. We use this result to give a complete characterization of all\nEuler equations that are provable in this axiomatisation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 06:55:56 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Jeandel", "Emmanuel", "", "MOCQUA"]]}, {"id": "1810.05392", "submitter": "EPTCS", "authors": "Stefano Berardi (University of Torino (Italy)), Alexandre Miquel\n  (Universidad de la Republica (Montevideo))", "title": "Proceedings Seventh International Workshop on Classical Logic and\n  Computation", "comments": null, "journal-ref": "EPTCS 281, 2018", "doi": "10.4204/EPTCS.281", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This special issue cover the seventh and last conference of the CL&C series,\nstarted in 2006 in San Servolo. Topics are the computational content of logics\nbetween intuitionistic logic and classical logic, through normalization, and a\nnew topic, cyclic proofs and the complexity of checking the correctness of a\ncyclic proof. Accepted papers include an empirical comparison of time\nconsumption of different normalization algorithms, and new reductions sets for\nseveral extensions of intuitionistic logic having the Herbrand disjunction\nproperty. Another paper provides a reduction set for admissible rules for\nintuitionistic logic. A paper describes a subset of cyclic proofs having a\npolynomial-time algorithm checking correctness.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:03:44 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Berardi", "Stefano", "", "University of Torino"], ["Miquel", "Alexandre", "", "Universidad de la Republica"]]}, {"id": "1810.05395", "submitter": "Giovanna D'Agostino", "authors": "Giovanna D'Agostino", "title": "Uniform Interpolation for Propositional and Modal Team Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider Modal Team Logic, a generalization of Classical\nModal Logic in which it is possible to describe dependence phenomena between\ndata. We prove that most known fragment of Full Modal Team Logic allow the\nelimination of the so called \"existential bisimulation quantifiers\", where the\nexistence of a certain set is made modulo bisimulation. As a consequence, we\nprove that these fragments enjoy the Uniform Interpolation Property.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:12:08 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["D'Agostino", "Giovanna", ""]]}, {"id": "1810.05410", "submitter": "Alessio Mansutti", "authors": "St\\'ephane Demri, Etienne Lozes, Alessio Mansutti", "title": "The Effects of Adding Reachability Predicates in Quantifier-Free\n  Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The list segment predicate ls used in separation logic for verifying programs\nwith pointers is well-suited to express properties on singly-linked lists. We\nstudy the effects of adding ls to the full quantifier-free separation logic\nwith the separating conjunction and implication, which is motivated by the\nrecent design of new fragments in which all these ingredients are used\nindifferently and verification tools start to handle the magic wand connective.\nThis is a very natural extension that has not been studied so far. We show that\nthe restriction without the separating implication can be solved in polynomial\nspace by using an appropriate abstraction for memory states whereas the full\nextension is shown undecidable by reduction from first-order separation logic.\nMany variants of the logic and fragments are also investigated from the\ncomputational point of view when ls is added, providing numerous results about\nadding reachability predicates to quantifier-free separation logic.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:49:57 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 19:53:00 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Demri", "St\u00e9phane", ""], ["Lozes", "Etienne", ""], ["Mansutti", "Alessio", ""]]}, {"id": "1810.05495", "submitter": "Mauricio Toro", "authors": "Mauricio Toro", "title": "Towards a correct and efficient implementation of simulation and\n  verification tools for probabilistic ntcc", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extended our simulation tool Ntccrt for probabilistic ntcc (pntcc) models.\nIn addition, we developed a verification tool for pntcc models. Using this tool\nwe can prove properties such as the system will go to a successful state with\nprobability p under t discrete time- units. Currently, we are facing a few\nproblems. We can only verify pntcc models using a finite domain constraint\nsystem and the encoding of cells ( mathematical entities that can update their\nvalue ) is experimental. In addition, in order to reduce the states generated\nduring the verification process we need to implement a procedure to calculate\nwhether two processes are equivalent. In the future, we want to provide\nmultiple interfaces for the tools (e.g., a web ap- plication, a graphical\ninterface and command line interface). We also want to support constraint\nsystems over trees, graph and sets. We want to show the relevance of our tool\nto model biological and multimedia interaction systems in our tool, verify some\nproperties about them, and simulate such systems in our real-time capable\ninterpreter.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 03:08:47 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Toro", "Mauricio", ""]]}, {"id": "1810.05666", "submitter": "EPTCS", "authors": "Matt Kaufmann (UT Austin)", "title": "DefunT: A Tool for Automating Termination Proofs by Using the Community\n  Books (Extended Abstract)", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 161-163", "doi": "10.4204/EPTCS.280.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a tool that automates termination proofs for recursive definitions\nby mining existing termination theorems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:39:14 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Kaufmann", "Matt", "", "UT Austin"]]}, {"id": "1810.05703", "submitter": "Robert Kent", "authors": "Robert E. Kent and John Brady", "title": "Formal Concept Analysis with Many-sorted Attributes", "comments": "11 pages, 6 tables, Proceedings of the Fifth International Conference\n  on Computing and Information (ICCI'93), Sudbury, Ontario, Canada, May 1993", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper unites two problem-solving traditions in computer science: (1)\nconstraint-based reasoning, and (2) formal concept analysis. For basic\ndefinitions and properties of networks of constraints, we follow the\nfoundational approach of Montanari and Rossi. This paper advocates distributed\nrelations as a more semantic version of networks of constraints. The theory\ndeveloped here uses the theory of formal concept analysis, pioneered by Rudolf\nWille and his colleagues, as a key for unlocking the hidden semantic structure\nwithin distributed relations. Conversely, this paper offers distributed\nrelations as a seamless many-sorted extension to the formal contexts of formal\nconcept analysis. Some of the intuitions underlying our approach were discussed\nin a preliminary fashion by Freuder and Wallace.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:54:11 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Kent", "Robert E.", ""], ["Brady", "John", ""]]}, {"id": "1810.05879", "submitter": "Joao Marcos", "authors": "Carlos Caleiro and S\\'ergio Marcelino and Jo\\~ao Marcos", "title": "Combining fragments of classical logic: When are interaction principles\n  needed?", "comments": "Authors' affiliations and funding information added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the combination of fragments of classical logic as a way of\nconservatively extending a given Boolean logic by the addition of new\nconnectives, and we precisely characterize the circumstances in which such a\ncombination produces the corresponding fragment of classical logic over the\nsignature containing connectives from both fragments given as input. If the\nthereby produced combined fragment is only incompletely characterized by the\ncomponents given as input, this means that connectives from one component need\nto interact with connectives from the other component, giving rise to\ninteraction principles. The main contributions strongly rely on the\n(well-known) description of the 2-valued clones made by Post, on the (not so\nwell-known) axiomatization procedures for 2-valued matrices laid out by\nRautenberg, and on Avron's non-deterministic matrices, which have (recently)\nbeen used to produce a significant advance on the understanding of the\nsemantics of fibring.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 15:46:09 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 13:40:50 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Caleiro", "Carlos", ""], ["Marcelino", "S\u00e9rgio", ""], ["Marcos", "Jo\u00e3o", ""]]}, {"id": "1810.05961", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Introduction to Dialectical Nets", "comments": "19 pages", "journal-ref": "Proceedings of the 25th Allerton Conference on Communication,\n  Control, and Computing, pages 1204-1213, October 1987", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper initiates the dialectical approach to net theory. This approach\nviews nets as special, but very important and natural, dialectical systems. By\nfollowing this approach, a suitably generalized version of nets, called\ndialectical nets, can be defined in terms of the \"fundamental contradiction\"\ninherent in the structure of closed preorders. Dialectical nets are the least\nconceptual upper bound subsuming the notions of Petri nets, Kan quantification\nand transition systems. The nature of dialectical nets is that of logical\ndynamics, and is succinctly defined and summarized in the statement that\n\"dialectical nets are transition systems relativized to closed preorders, and\nhence are general predicate transformers\".\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 03:34:36 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.06037", "submitter": "Paolo Perrone", "authors": "Tobias Fritz and Paolo Perrone", "title": "Monads, partial evaluations, and rewriting", "comments": "Originally written for the ACT Adjoint School 2019. To appear in\n  Proceedings of MFPS 2020", "journal-ref": "ENTCS 353, 129-148 (2020)", "doi": "10.1016/j.entcs.2020.09.007", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monads can be interpreted as encoding formal expressions, or formal\noperations in the sense of universal algebra. We give a construction which\nformalizes the idea of \"evaluating an expression partially\": for example, \"2+3\"\ncan be obtained as a partial evaluation of \"2+2+1\". This construction can be\ngiven for any monad, and it is linked to the famous bar construction, of which\nit gives an operational interpretation: the bar construction induces a\nsimplicial set, and its 1-cells are partial evaluations.\n  We study the properties of partial evaluations for general monads. We prove\nthat whenever the monad is weakly cartesian, partial evaluations can be\ncomposed via the usual Kan filler property of simplicial sets, of which we give\nan interpretation in terms of substitution of terms.\n  In terms of rewritings, partial evaluations give an abstract reduction system\nwhich is reflexive, confluent, and transitive whenever the monad is weakly\ncartesian.\n  For the case of probability monads, partial evaluations correspond to what\nprobabilists call conditional expectation of random variables.\n  This manuscript is part of a work in progress on a general rewriting\ninterpretation of the bar construction.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 14:09:05 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 15:18:24 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 00:29:25 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Fritz", "Tobias", ""], ["Perrone", "Paolo", ""]]}, {"id": "1810.06911", "submitter": "Mario Lezoche", "authors": "Mario Lezoche (CRAN), Herv\\'e Panetto (CRAN)", "title": "Cyber-Physical Systems, a new formal paradigm to model redundancy and\n  resiliency", "comments": null, "journal-ref": "Enterprise Information Systems, Taylor \\& Francis, 2018", "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) are systems composed by a physical component\nthat is controlled or monitored by a cyber-component, a computer-based\nalgorithm. Advances in CPS technologies and science are enabling capability,\nadaptability, scalability, resiliency, safety, security, and usability that\nwill far exceed the simple embedded systems of today. CPS technologies are\ntransforming the way people interact with engineered systems. New smart CPS are\ndriving innovation in various sectors such as agriculture, energy,\ntransportation, healthcare, and manufacturing. They are leading the 4-th\nIndustrial Revolution (Industry 4.0) that is having benefits thanks to the high\nflexibility of production. The Industry 4.0 production paradigm is\ncharacterized by high intercommunicating properties of its production elements\nin all the manufacturing processes. This is the reason it is a core concept how\nthe systems should be structurally optimized to have the adequate level of\nredundancy to be satisfactorily resilient. This goal can benefit from formal\nmethods well known in various scientific domains such as artificial\nintelligence. So, the current research concerns the proposal of a CPS\nmeta-model and its instantiation. In this way it lists all kind of\nrelationships that may occur between the CPSs themselves and between their\n(cyber-and physical-) components. Using the CPS meta-model formalization, with\nan adaptation of the Formal Concept Analysis (FCA) formal approach, this paper\npresents a way to optimize the modelling of CPS systems emphasizing their\nredundancy and their resiliency.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 10:10:06 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Lezoche", "Mario", "", "CRAN"], ["Panetto", "Herv\u00e9", "", "CRAN"]]}, {"id": "1810.06985", "submitter": "Yakov Savelyev", "authors": "Yasha Savelyev", "title": "Non-computability of human intelligence", "comments": "This paper is completely superseded by arXiv:2001.07592. The latter\n  paper is a completely mathematical approach to the problem, fixing issues in\n  formalization of the thought experiment used in the former", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the question (most famously) initiated by Turing: can human\nintelligence be completely modeled by a Turing machine? We show that the answer\nis \\emph{no}, assuming a certain weak soundness hypothesis. More specifically\nwe show that at least some meaningful thought processes of the brain cannot be\nTuring computable. In particular some physical processes are not Turing\ncomputable, which is not entirely expected. There are some similarities of our\nargument with the well known Lucas-Penrose argument, but we work purely on the\nlevel of Turing machines, and do not use G\\\"odel's incompleteness theorem or\nany direct analogue. Instead we construct directly and use a weak analogue of a\nG\\\"odel statement for a certain system which involves our human, this allows us\nto side-step some (possible) meta-logical issues with their argument.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:16:21 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 20:18:45 GMT"}, {"version": "v3", "created": "Mon, 31 Dec 2018 15:12:29 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 18:49:29 GMT"}, {"version": "v5", "created": "Mon, 4 Feb 2019 20:46:00 GMT"}, {"version": "v6", "created": "Sun, 31 Mar 2019 20:59:56 GMT"}, {"version": "v7", "created": "Tue, 18 Jun 2019 19:52:54 GMT"}, {"version": "v8", "created": "Wed, 22 Jan 2020 14:11:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Savelyev", "Yasha", ""]]}, {"id": "1810.06991", "submitter": "Tom Hirschowitz", "authors": "Clovis Eberhart, Tom Hirschowitz and Alexis Laouar", "title": "Simple game semantics and Day convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game semantics has provided adequate models for a variety of programming\nlanguages, in which types are interpreted as two-player games and programs as\nstrategies. Melli\\`es (2018) suggested that such categories of games and\nstrategies may be obtained as instances of a simple abstract construction on\nweak double categories. However, in the particular case of simple games, his\nconstruction slightly differs from the standard category. We refine the\nabstract construction using factorisation systems, and show that the new\nconstruction yields the standard category of simple games and strategies.\nAnother perhaps surprising instance is Day's convolution monoidal structure on\nthe category of presheaves over a strict monoidal category.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:39:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Eberhart", "Clovis", ""], ["Hirschowitz", "Tom", ""], ["Laouar", "Alexis", ""]]}, {"id": "1810.07372", "submitter": "EPTCS", "authors": "Andrea Condoluci, Matteo Manighetti", "title": "Admissible Tools in the Kitchen of Intuitionistic Logic", "comments": "In Proceedings CL&C 2018, arXiv:1810.05392", "journal-ref": "EPTCS 281, 2018, pp. 10-23", "doi": "10.4204/EPTCS.281.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usual reading of logical implication \"A implies B\" as \"if A then B\" fails\nin intuitionistic logic: there are formulas A and B such that \"A implies B\" is\nnot provable, even though B is provable whenever A is provable. Intuitionistic\nrules apparently do not capture interesting meta-properties of the logic and,\nfrom a computational perspective, the programs corresponding to intuitionistic\nproofs are not powerful enough. Such non-provable implications are nevertheless\nadmissible, and we study their behavior by means of a proof term assignment and\nrelated rules of reduction. We introduce V, a calculus that is able to\nrepresent admissible inferences, while remaining in the intuitionistic world by\nhaving normal forms that are just intuitionistic terms. We then extend\nintuitionistic logic with principles corresponding to admissible rules. As an\nexample, we consider the Kreisel-Putnam logic KP, for which we prove the strong\nnormalization and the disjunction property through our term assignment. This is\nour first step in understanding the essence of admissible rules for\nintuitionistic logic.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:23:32 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Condoluci", "Andrea", ""], ["Manighetti", "Matteo", ""]]}, {"id": "1810.07373", "submitter": "EPTCS", "authors": "Gabriel Ebner (TU Wien, Austria)", "title": "Fast Cut-Elimination using Proof Terms: An Empirical Study", "comments": "In Proceedings CL&C 2018, arXiv:1810.05392", "journal-ref": "EPTCS 281, 2018, pp. 24-38", "doi": "10.4204/EPTCS.281.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban and Bierman introduced a calculus of proof terms for the sequent\ncalculus LK with a strongly normalizing reduction relation. We extend this\ncalculus to simply-typed higher-order logic with inferences for induction and\nequality, albeit without strong normalization. We implement thiscalculus in\nGAPT, our library for proof transformations. Evaluating the normalization on\nboth artificial and real-world benchmarks, we show that this algorithm is\ntypically several orders of magnitude faster than the existing Gentzen-like\ncut-reduction, and an order of magnitude faster than any other cut-elimination\nprocedure implemented in GAPT.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:23:48 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Ebner", "Gabriel", "", "TU Wien, Austria"]]}, {"id": "1810.07374", "submitter": "EPTCS", "authors": "Sorin Stratulat (Universit\\'e de Lorraine)", "title": "Validating Back-links of FOLID Cyclic Pre-proofs", "comments": "In Proceedings CL&C 2018, arXiv:1810.05392", "journal-ref": "EPTCS 281, 2018, pp. 39-53", "doi": "10.4204/EPTCS.281.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyclic pre-proofs can be represented as sets of finite tree derivations with\nback-links. In the frame of the first-order logic with inductive definitions,\nthe nodes of the tree derivations are labelled by sequents and the back-links\nconnect particular terminal nodes, referred to as buds, to other nodes labelled\nby a same sequent. However, only some back-links can constitute sound\npre-proofs. Previously, it has been shown that special ordering and\nderivability conditions, defined along the minimal cycles of the digraph\nrepresenting a particular normal form of the cyclic pre-proof, are sufficient\nfor validating the back-links. In that approach, a same constraint could be\nchecked several times when processing different minimal cycles, hence one may\nrequire additional recording mechanisms to avoid redundant computation in order\nto downgrade the time complexity to polynomial.\n  We present a new approach that does not need to process minimal cycles. It\nbased on a normal form that allows to define the validation conditions by\ntaking into account only the root-bud paths from the non-singleton strongly\nconnected components of its digraph.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:24:08 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Stratulat", "Sorin", "", "Universit\u00e9 de Lorraine"]]}, {"id": "1810.07414", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek and Peter H\\\"ofner", "title": "Progress, Justness and Fairness", "comments": null, "journal-ref": "ACM Computing Surveys 52(4):69, 2019", "doi": "10.1145/3329125", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness assumptions are a valuable tool when reasoning about systems. In\nthis paper, we classify several fairness properties found in the literature and\nargue that most of them are too restrictive for many applications. As an\nalternative we introduce the concept of justness.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 07:39:41 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 07:37:51 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""]]}, {"id": "1810.07488", "submitter": "Rob van Glabbeek", "authors": "Nick Fischer and Rob van Glabbeek", "title": "Axiomatising Infinitary Probabilistic Weak Bisimilarity of Finite-State\n  Behaviours", "comments": null, "journal-ref": null, "doi": "10.1016/j.jlamp.2018.09.006", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In concurrency theory, weak bisimilarity is often used to relate processes\nexhibiting the same observable behaviour. The probabilistic environment gives\nrise to several generalisations; we study the infinitary semantics, which\nabstracts from a potentially unbounded number of internal actions being\nperformed when something observable happens. Arguing that this notion yields\nthe most desirable properties, we provide a sound and complete axiomatisation\ncapturing its essence. Previous research has failed to achieve completeness in\nthe presence of unguarded recursion, as only the finitary variant has been\naxiomatised, yet.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 11:50:51 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Fischer", "Nick", ""], ["van Glabbeek", "Rob", ""]]}, {"id": "1810.07667", "submitter": "Fer-jan De vries", "authors": "Fer-Jan de Vries", "title": "Encoding many-valued logic in $\\lambda$-calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (June 29,\n  2021) lmcs:7630", "doi": "10.46298/lmcs-:4)2021", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We will extend the well-known Church encoding of Boolean logic into\n$\\lambda$-calculus to an encoding of McCarthy's $3$-valued logic into a\nsuitable infinitary extension of $\\lambda$-calculus that identifies all\nunsolvables by $\\bot$, where $\\bot$ is a fresh constant. This encoding refines\nto $n$-valued logic for $n\\in\\{4,5\\}$. Such encodings also exist for Church's\noriginal $\\lambda\\mathbf{I}$-calculus. By way of motivation we consider\nRussell's paradox, exploiting the fact that the same encoding allows us also to\ncalculate truth values of infinite closed propositions in this infinitary\nsetting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 17:00:49 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 01:29:15 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 02:33:35 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 02:11:11 GMT"}, {"version": "v5", "created": "Sun, 28 Mar 2021 22:02:07 GMT"}, {"version": "v6", "created": "Sat, 26 Jun 2021 15:19:39 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["de Vries", "Fer-Jan", ""]]}, {"id": "1810.07822", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli and Michael Benedikt", "title": "When Can We Answer Queries Using Result-Bounded Data Interfaces?", "comments": "75 pages; journal version of the PODS'18 paper arXiv:1706.07936. Many\n  errors fixed relative to the previous version, and some erroneous results\n  removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider answering queries on data available through access methods, that\nprovide lookup access to the tuples matching a given binding. Such interfaces\nare common on the Web; further, they often have bounds on how many results they\ncan return, e.g., because of pagination or rate limits. We thus study\nresult-bounded methods, which may return only a limited number of tuples. We\nstudy how to decide if a query is answerable using result-bounded methods,\ni.e., how to compute a plan that returns all answers to the query using the\nmethods, assuming that the underlying data satisfies some integrity\nconstraints. We first show how to reduce answerability to a query containment\nproblem with constraints. Second, we show \"schema simplification\" theorems\ndescribing when and how result-bounded services can be used. Finally, we use\nthese theorems to give decidability and complexity results about answerability\nfor common constraint classes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 22:32:15 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 17:49:56 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Amarilli", "Antoine", ""], ["Benedikt", "Michael", ""]]}, {"id": "1810.07972", "submitter": "Thorsten Wissmann", "authors": "Shin-ya Katsumata, Tetsuya Sato, Tarmo Uustalu", "title": "Codensity Lifting of Monads and its Dual", "comments": "Extended version of the paper presented at CALCO 2015, accepted for\n  publication in LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (October\n  29, 2018) lmcs:4924", "doi": "10.23638/LMCS-14(4:6)2018", "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a method to lift monads on the base category of a fibration to\nits total category. This method, which we call codensity lifting, is applicable\nto various fibrations which were not supported by its precursor, categorical\nTT-lifting. After introducing the codensity lifting, we illustrate some\nexamples of codensity liftings of monads along the fibrations from the category\nof preorders, topological spaces and extended pseudometric spaces to the\ncategory of sets, and also the fibration from the category of binary relations\nbetween measurable spaces. We also introduce the dual method called density\nlifting of comonads. We next study the liftings of algebraic operations to the\ncodensity liftings of monads. We also give a characterisation of the class of\nliftings of monads along posetal fibrations with fibred small meets as a limit\nof a certain large diagram.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 09:44:08 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 15:19:45 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Katsumata", "Shin-ya", ""], ["Sato", "Tetsuya", ""], ["Uustalu", "Tarmo", ""]]}, {"id": "1810.08038", "submitter": "EPTCS", "authors": "Eric Fabre (INRIA Rennes - Bretagne Atlantique, France), G. Michele\n  Pinna (Universit\\`a degli Studi di Cagliari, Italy)", "title": "Toward a Uniform Approach to the Unfolding of Nets", "comments": "In Proceedings ICE 2018, arXiv:1810.02053", "journal-ref": "EPTCS 279, 2018, pp. 21-36", "doi": "10.4204/EPTCS.279.5", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the notion of spread net. Spread nets are (safe)\nPetri nets equipped with vector clocks on places and with ticking functions on\ntransitions, and are such that vector clocks are consistent with the ticking of\ntransitions. Such nets generalize previous families of nets like unfoldings,\nmerged processes and trellis processes, and can thus be used to represent runs\nof a net in a true concurrency semantics through an operation called the\nspreading of a net. By contrast with previous constructions, which may identify\nconflicts, spread nets allow loops in time\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:34:11 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Fabre", "Eric", "", "INRIA Rennes - Bretagne Atlantique, France"], ["Pinna", "G. Michele", "", "Universit\u00e0 degli Studi di Cagliari, Italy"]]}, {"id": "1810.08040", "submitter": "Radom\\'ir Hala\\v{s}", "authors": "Radom\\'ir Hala\\v{s}, Radko Mesiar, Jozef P\\'ocs", "title": "Description of sup- and inf-preserving aggregation functions via\n  families of clusters in data tables", "comments": "24 pages", "journal-ref": null, "doi": "10.1016/j.ins.2017.02.060", "report-no": null, "categories": "cs.LO cs.AI math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connection between the theory of aggregation functions and formal concept\nanalysis is discussed and studied, thus filling a gap in the literature by\nbuilding a bridge between these two theories, one of them living in the world\nof data fusion, the second one in the area of data mining. We show how Galois\nconnections can be used to describe an important class of aggregation functions\npreserving suprema, and, by duality, to describe aggregation functions\npreserving infima. Our discovered method gives an elegant and complete\ndescription of these classes. Also possible applications of our results within\ncertain biclustering fuzzy FCA-based methods are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 07:51:48 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Hala\u0161", "Radom\u00edr", ""], ["Mesiar", "Radko", ""], ["P\u00f3cs", "Jozef", ""]]}, {"id": "1810.08074", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The Institutional Approach", "comments": "24 pages, 8 figures. The original publication is available at\n  https://link.springer.com/chapter/10.1007/978-90-481-8847-5_23", "journal-ref": "In: Poli R., Healy M., Kameas A. (eds.). Pages 533-563. Theory and\n  Applications of Ontology: Computer Applications. 12 August 2010. Springer,\n  Dordrecht", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter discusses the institutional approach for organizing and\nmaintaining ontologies. The theory of institutions was named and initially\ndeveloped by Joseph Goguen and Rod Burstall. This theory, a metatheory based on\ncategory theory, regards ontologies as logical theories or local logics. The\ntheory of institutions uses the category-theoretic ideas of fibrations and\nindexed categories to develop logical theories. Institutions unite the lattice\napproach of Formal Concept Analysis of Ganter and Wille with the distributed\nlogic of Information Flow of Barwise and Seligman. The institutional approach\nincorporates locally the lattice of theories idea of Sowa from the theory of\nknowledge representation. The Information Flow Framework, which was initiated\nwithin the IEEE Standard Upper Ontology project, uses the institutional\napproach in its applied aspect for the comparison, semantic integration and\nmaintenance of ontologies. This chapter explains the central ideas of the\ninstitutional approach to ontologies in a careful and detailed manner.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 17:59:56 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.08096", "submitter": "Liang-Ting Chen", "authors": "Liang-Ting Chen, Markus Roggenbach, John V. Tucker", "title": "An algebraic theory for data linkage", "comments": "For WADT'18", "journal-ref": null, "doi": "10.1007/978-3-030-23220-7_3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are countless sources of data available to governments, companies, and\ncitizens, which can be combined for good or evil. We analyse the concepts of\ncombining data from common sources and linking data from different sources. We\nmodel the data and its information content to be found in a single source by a\npartial ordered monoid, and the transfer of information between sources by\ndifferent types of morphisms. To capture the linkage between a family of\nsources, we use a form of Grothendieck construction to create a partial ordered\nmonoid that brings together the global data of the family in a single\nstructure. We apply our approach to database theory and axiomatic structures in\napproximate reasoning. Thus, partial ordered monoids provide a foundation for\nthe algebraic study for information gathering in its most primitive form.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 17:00:13 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Liang-Ting", ""], ["Roggenbach", "Markus", ""], ["Tucker", "John V.", ""]]}, {"id": "1810.08170", "submitter": "Daniel Rodr\\'iguez-Chavarr\\'ia", "authors": "Daniel Rodr\\'iguez-Chavarr\\'ia, Miguel A. Guti\\'errez-Naranjo and\n  Joaqu\\'in Borrego-D\\'iaz", "title": "Logic Negation with Spiking Neural P Systems", "comments": "25 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the success of neural networks as reasoning systems is doubtless.\nNonetheless, one of the drawbacks of such reasoning systems is that they work\nas black-boxes and the acquired knowledge is not human readable. In this paper,\nwe present a new step in order to close the gap between connectionist and logic\nbased reasoning systems. We show that two of the most used inference rules for\nobtaining negative information in rule based reasoning systems, the so-called\nClosed World Assumption and Negation as Finite Failure can be characterized by\nmeans of spiking neural P systems, a formal model of the third generation of\nneural networks born in the framework of membrane computing.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:22:30 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 16:26:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rodr\u00edguez-Chavarr\u00eda", "Daniel", ""], ["Guti\u00e9rrez-Naranjo", "Miguel A.", ""], ["Borrego-D\u00edaz", "Joaqu\u00edn", ""]]}, {"id": "1810.08236", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Semantic Integration in the Information Flow Framework", "comments": "12 pages, 2 figures. Dagstuhl Seminar Proceedings 04391, Semantic\n  Interoperability and Integration, Schloss Dagstuhl, Leibniz-Zentrum fur\n  Informatik GmbH, 2005 Online at:\n  http://drops.dagstuhl.de/opus/portals/index.php?semnr=04391", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Flow Framework (IFF) is a descriptive category metatheory\ncurrently under development, which is being offered as the structural aspect of\nthe Standard Upper Ontology (SUO). The architecture of the IFF is composed of\nmetalevels, namespaces and meta-ontologies. The main application of the IFF is\ninstitutional: the notion of institutions and their morphisms are being\naxiomatized in the upper metalevels of the IFF, and the lower metalevel of the\nIFF has axiomatized various institutions in which semantic integration has a\nnatural expression as the colimit of theories.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:50:37 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.08380", "submitter": "Mario Carneiro", "authors": "Mario Carneiro", "title": "Formalizing computability theory via partial recursive functions", "comments": "16 pages, accepted to ITP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension to the $\\mathtt{mathlib}$ library of the Lean theorem\nprover formalizing the foundations of computability theory. We use primitive\nrecursive functions and partial recursive functions as the main objects of\nstudy, and we use a constructive encoding of partial functions such that they\nare executable when the programs in question provably halt. Main theorems\ninclude the construction of a universal partial recursive function and a proof\nof the undecidability of the halting problem. Type class inference provides a\ntransparent way to supply G\\\"{o}del numberings where needed and encapsulate the\nencoding details.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:37:46 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 01:06:15 GMT"}, {"version": "v3", "created": "Thu, 18 Jul 2019 09:16:07 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Carneiro", "Mario", ""]]}, {"id": "1810.08684", "submitter": "Kira Adaricheva V", "authors": "Kira Adaricheva and Taylor Ninesling", "title": "Direct and Binary Direct Bases for One-set Updates of a Closure System", "comments": "17 pages, 1 table, 1 figure, poster session presentation ICFCA-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a concept of a binary-direct implicational basis and show that\nthe shortest binary-direct basis exists and it is known as the $D$-basis\nintroduced in Adaricheva, Nation, Rand [Disc.Appl.Math. 2013]. Using this\nconcept we approach the algorithmic solution to the Singleton Horn Extension\nproblem, as well as the one set removal problem, when the closure system is\ngiven by the canonical direct or binary-direct basis. In this problem, a new\nclosed set is added to or removed from the closure system forcing the re-write\nof a given basis. Our goal is to obtain the same type of implicational basis\nfor the new closure system as was given for original closure system and to make\nthe basis update an optimal process.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:35:02 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Adaricheva", "Kira", ""], ["Ninesling", "Taylor", ""]]}, {"id": "1810.08739", "submitter": "EPTCS", "authors": "John Derrick (University of Sheffield), Brijesh Dongol (University of\n  Surrey), Steve Reeves (University of Waikato)", "title": "Proceedings 18th Refinement Workshop", "comments": null, "journal-ref": "EPTCS 282, 2018", "doi": "10.4204/EPTCS.282", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refinement is one of the cornerstones of a formal approach to software\nengineering. Refinement is the process of developing a more detailed design or\nimplementation from an abstract specification through a sequence of\nmathematically-based steps that maintain correctness with respect to the\noriginal specification. Work on the foundations of languages such as Z, B, VDM\nand CSP have led to their widespread use in certain industrial sectors, e.g.,\nthose with security or safety critical concerns. In addition to precise\nspecification, formal methods also allow the possibility of precise and\nverifiable development, as captured by the concept of refinement.\n  The 18th Refinement Workshop was held as part of FLoC 2018 at Oxford, UK.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 02:55:10 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Derrick", "John", "", "University of Sheffield"], ["Dongol", "Brijesh", "", "University of\n  Surrey"], ["Reeves", "Steve", "", "University of Waikato"]]}, {"id": "1810.08831", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Enriched Interpretation", "comments": "10 pages, Conference Proceedings of the Third International Workshop\n  on Rough Sets and Soft Computing (RSSC'94), T.Y. Lin, editor, pages 116-123,\n  San Jose State University, San Jose, California, USA, November 1994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory introduced, presented and developed in this paper, is concerned\nwith an enriched extension of the theory of Rough Sets pioneered by Zdzislaw\nPawlak. The enrichment discussed here is in the sense of valuated categories as\ndeveloped by F.W. Lawvere. This paper relates Rough Sets to an abstraction of\nthe theory of Fuzzy Sets pioneered by Lotfi Zadeh, and provides a natural\nfoundation for \"soft computation\". To paraphrase Lotfi Zadeh, the impetus for\nthe transition from a hard theory to a soft theory derives from the fact that\nboth the generality of a theory and its applicability to real-world problems\nare substantially enhanced by replacing various hard concepts with their soft\ncounterparts. Here we discuss the corresponding enriched notions for\nindiscernibility, subsets, upper/lower approximations, and rough sets.\nThroughout, we indicate linkages with the theory of Formal Concept Analysis\npioneered by Rudolf Wille. We pay particular attention to the all-important\nnotion of a \"linguistic variable\" - developing its enriched extension,\ncomparing it with the notion of conceptual scale from Formal Concept Analysis,\nand discussing the pragmatic issues of its creation and use in the\ninterpretation of data. These pragmatic issues are exemplified by the\ndiscovery, conceptual analysis, interpretation, and categorization of networked\ninformation resources in WAVE, the Web Analysis and Visualization Environment\ncurrently being developed for the management and interpretation of the universe\nof resource information distributed over the World-Wide Web.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 17:41:16 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.09142", "submitter": "Dmitry Shkatov", "authors": "Mikhail Rybakov and Dmitry Shkatov", "title": "Complexity and Expressivity of Branching- and Alternating-Time Temporal\n  Logics with Finitely Many Variables", "comments": "Prefinal version of the published paper", "journal-ref": "Bernd Fischer and Tarmo Uustalu (eds.) Theoretical Aspects of\n  Computing -- ICTAC 2018. Lecture Notes in Computer Science,Vol. 11187,\n  Springer 2018, pp. 396--414", "doi": "10.1007/978-3-030-02508-3_21", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Branching-time temporal logics CTL and CTL*, as well as\nAlternating-time temporal logics ATL and ATL*, are as semantically expressive\nin the language with a single propositional variable as they are in the full\nlanguage, i.e., with an unlimited supply of propositional variables. It follows\nthat satisfiability for CTL, as well as for ATL, with a single variable is\nEXPTIME-complete, while satisfiability for CTL*, as well as for ATL*, with a\nsingle variable is 2EXPTIME-complete,--i.e., for these logics, the\nsatisfiability for formulas with only one variable is as hard as satisfiability\nfor arbitrary formulas.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:52:23 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 20:08:42 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Rybakov", "Mikhail", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "1810.09146", "submitter": "Natsuki Urabe", "authors": "Natsuki Urabe, Ichiro Hasuo", "title": "Quantitative Simulations by Matrices", "comments": "Extended version of [Urabe & Hasuo, CONCUR 2014]", "journal-ref": "Information and Computation, Volume 252, February 2017, Pages\n  110-137", "doi": "10.1016/j.ic.2016.03.007", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce notions of simulation between semiring-weighted automata as\nmodels of quantitative systems. Our simulations are instances of the\ncategorical/coalgebraic notions previously studied by Hasuo---hence soundness\nagainst language inclusion comes for free---but are concretely presented as\nmatrices that are subject to linear inequality constraints. Pervasiveness of\nthese formalisms allows us to exploit existing algorithms in: searching for a\nsimulation, and hence verifying quantitative correctness that is formulated as\nlanguage inclusion. Transformations of automata that aid search for simulations\nare introduced, too. This verification workflow is implemented for the\nplus-times and max-plus semirings. Furthermore, an extension to weighted tree\nautomata is presented and implemented.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:22:16 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 12:51:49 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Urabe", "Natsuki", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1810.09611", "submitter": "EPTCS", "authors": "Ian J. Hayes (The University of Queensland)", "title": "Some Challenges of Specifying Concurrent Program Components", "comments": "In Proceedings Refine 2018, arXiv:1810.08739", "journal-ref": "EPTCS 282, 2018, pp. 10-22", "doi": "10.4204/EPTCS.282.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to address some of the challenges of formally\nspecifying components of shared-memory concurrent programs. The focus is to\nprovide an abstract specification of a component that is suitable for use both\nby clients of the component and as a starting point for refinement to an\nimplementation of the component. We present some approaches to devising\nspecifications, investigating different forms suitable for different contexts.\nWe examine handling atomicity of access to data structures, blocking operations\nand progress properties, and transactional operations that may fail and need to\nbe retried.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 00:47:50 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Hayes", "Ian J.", "", "The University of Queensland"]]}, {"id": "1810.09612", "submitter": "EPTCS", "authors": "Graeme Smith, Kirsten Winter, Robert J. Colvin", "title": "Correctness of Concurrent Objects under Weak Memory Models", "comments": "In Proceedings Refine 2018, arXiv:1810.08739. arXiv admin note: text\n  overlap with arXiv:1802.04954", "journal-ref": "EPTCS 282, 2018, pp. 53-67", "doi": "10.4204/EPTCS.282.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a theory for correctness of concurrent objects under\nweak memory models. Central to our definitions is the concept of observations\nwhich determine when effects of operations become visible, and hence determine\nthe semantics of objects, under a given memory model. The resulting notion of\ncorrectness, called object refinement, is generic as it is parameterised by the\nmemory model under consideration. Our theory enforces the minimal constraints\non the placing of observations and on the semantics of objects that underlie\nobject refinement. Object refinement is suitable as a reference for correctness\nwhen proving new proof methods for objects under weak memory models to be sound\nand complete.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 00:48:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Smith", "Graeme", ""], ["Winter", "Kirsten", ""], ["Colvin", "Robert J.", ""]]}, {"id": "1810.09613", "submitter": "EPTCS", "authors": "Emil Sekerinski (McMaster University), Shucai Yao (McMaster\n  University)", "title": "Refining Santa: An Exercise in Efficient Synchronization", "comments": "In Proceedings Refine 2018, arXiv:1810.08739", "journal-ref": "EPTCS 282, 2018, pp. 68-86", "doi": "10.4204/EPTCS.282.6", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Santa Claus Problem is an intricate exercise for concurrent programming.\nThis paper outlines the refinement steps to develop a highly efficient\nimplementation with concurrent objects, starting from a simple specification.\nThe efficiency of the implementation is compared to those in other languages.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 00:48:21 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sekerinski", "Emil", "", "McMaster University"], ["Yao", "Shucai", "", "McMaster\n  University"]]}, {"id": "1810.09615", "submitter": "EPTCS", "authors": "Mathieu Montin, Marc Pantel", "title": "Ordering Strict Partial Orders to Model Behavioral Refinement", "comments": "In Proceedings Refine 2018, arXiv:1810.08739", "journal-ref": "EPTCS 282, 2018, pp. 23-38", "doi": "10.4204/EPTCS.282.3", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software is now ubiquitous and involved in complex interactions with the\nhuman users and the physical world in so-called cyber-physical systems where\nthe management of time is a major issue. Separation of concerns is a key asset\nin the development of these ever more complex systems. Two different kinds of\nseparation exist: a first one corresponds to the different steps in a\ndevelopment leading from the abstract requirements to the system implementation\nand is qualified as vertical. It matches the commonly used notion of\nrefinement. A second one corresponds to the various components in the system\narchitecture at a given level of refinement and is called horizontal.\nRefinement has been studied thoroughly for the data, functional and concurrency\nconcerns while our work focuses on the time modeling concern. This contribution\naims at providing a formal construct for the verification of refinement in time\nmodels, through the definition of an order between strict partial orders used\nto relate the different instants in asynchronous systems. This relation allows\nthe designer at the concrete level to distinguish events that are coincident at\nthe abstract level while preserving the properties assessed at the abstract\nlevel. This work has been conducted using the proof assistant Agda and is\nconnected to a previous work on the asynchronous language CCSL, which has also\nbeen modelled using the same tool.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 00:51:56 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Montin", "Mathieu", ""], ["Pantel", "Marc", ""]]}, {"id": "1810.10143", "submitter": "Simon Hudon", "authors": "Simon Hudon and Thai Son Hoang and Jonathan S. Ostroff", "title": "The Unit-B Method -- Refinement Guided by Progress Concerns", "comments": null, "journal-ref": "Software and Systems Modeling (SoSym), Springer, Volume 15: Issue\n  4, pp. 1091-1116, October 2016", "doi": "10.1007/s10270-015-0456-2", "report-no": null, "categories": "cs.SE cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Unit-B, a formal method inspired by Event-B and UNITY. Unit-B aims\nat the stepwise design of software systems satisfying safety and liveness\nproperties. The method features the novel notion of coarse and fine schedules,\na generalisation of weak and strong fairness for specifying events' scheduling\nassumptions. Based on events schedules, we propose proof rules to reason about\nprogress properties and a refinement order preserving both liveness and safety\nproperties. We illustrate our approach by an example to show that systems\ndevelopment can be driven by not only safety but also liveness requirements.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 00:50:41 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 17:55:16 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Hudon", "Simon", ""], ["Hoang", "Thai Son", ""], ["Ostroff", "Jonathan S.", ""]]}, {"id": "1810.10257", "submitter": "Tomer Libal", "authors": "Tomer Libal and Marco Volpe", "title": "A general proof certification framework for modal logic", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 29 (2019) 1344-1378", "doi": "10.1017/S0960129518000440", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main issues in proof certification is that different theorem\nprovers, even when designed for the same logic, tend to use different proof\nformalisms and produce outputs in different formats. The project ProofCert\npromotes the usage of a common specification language and of a small and\ntrusted kernel in order to check proofs coming from different sources and for\ndifferent logics. By relying on that idea and by using a classical focused\nsequent calculus as a kernel, we propose here a general framework for checking\nmodal proofs. We present the implementation of the framework in a Prolog-like\nlanguage and show how it is possible to specialize it in a simple and modular\nway in order to cover different proof formalisms, such as labeled systems,\ntableaux, sequent calculi and nested sequent calculi. We illustrate the method\nfor the logic K by providing several examples and discuss how to further extend\nthe approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 09:07:54 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Libal", "Tomer", ""], ["Volpe", "Marco", ""]]}, {"id": "1810.10297", "submitter": "Gijs Wijnholds", "authors": "Gijs Jasper Wijnholds", "title": "A Proof-Theoretic Approach to Scope Ambiguity in Compositional Vector\n  Space Models", "comments": "This is a preprint of a paper to appear in: Journal of Language\n  Modelling, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the extent to which compositional vector space models can be\nused to account for scope ambiguity in quantified sentences (of the form \"Every\nman loves some woman\"). Such sentences containing two quantifiers introduce two\nreadings, a direct scope reading and an inverse scope reading. This ambiguity\nhas been treated in a vector space model using bialgebras by (Hedges and\nSadrzadeh, 2016) and (Sadrzadeh, 2016), though without an explanation of the\nmechanism by which the ambiguity arises. We combine a polarised focussed\nsequent calculus for the non-associative Lambek calculus NL, as described in\n(Moortgat and Moot, 2011), with the vector based approach to quantifier scope\nambiguity. In particular, we establish a procedure for obtaining a vector space\nmodel for quantifier scope ambiguity in a derivational way.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 11:20:02 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 10:37:03 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wijnholds", "Gijs Jasper", ""]]}, {"id": "1810.10826", "submitter": "Thorsten Wissmann", "authors": "Andrei Stefanescu, Stefan Ciobaca, Radu Mereuta, Brandon Moore, Traian\n  Florin Serbanuta, and Grigore Rosu", "title": "All-Path Reachability Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (April 30,\n  2019) lmcs:5408", "doi": "10.23638/LMCS-15(2:5)2019", "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a language-independent proof system for reachability\nproperties of programs written in non-deterministic (e.g., concurrent)\nlanguages, referred to as all-path reachability logic. It derives\npartial-correctness properties with all-path semantics (a state satisfying a\ngiven precondition reaches states satisfying a given postcondition on all\nterminating execution paths). The proof system takes as axioms any\nunconditional operational semantics, and is sound (partially correct) and\n(relatively) complete, independent of the object language. The soundness has\nalso been mechanized in Coq. This approach is implemented in a tool for\nsemantics-based verification as part of the K framework (http://kframework.org)\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 10:49:00 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 08:18:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Stefanescu", "Andrei", ""], ["Ciobaca", "Stefan", ""], ["Mereuta", "Radu", ""], ["Moore", "Brandon", ""], ["Serbanuta", "Traian Florin", ""], ["Rosu", "Grigore", ""]]}, {"id": "1810.10899", "submitter": "Bartosz Bednarczyk", "authors": "Bartosz Bednarczyk", "title": "One-Variable Logic Meets Presburger Arithmetic", "comments": "A short note accepted to TCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the one-variable fragment of first-order logic extended with\nPresburger constraints. The logic is designed in such a way that it subsumes\nthe previously-known fragments extended with counting, modulo counting or\ncardinality comparison and combines their expressive powers. We prove\nNP-completeness of the logic by presenting an optimal algorithm for solving its\nfinite satisfiability problem.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:38:19 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 12:33:29 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 16:41:10 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Bednarczyk", "Bartosz", ""]]}, {"id": "1810.11334", "submitter": "Yangjia Li", "authors": "Mingsheng Ying, Li Zhou and Yangjia Li", "title": "Reasoning about Parallel Quantum Programs", "comments": "Added an application on formal verification of\n  Bravyi-Gosset-K\\\"onig's algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of parallel quantum programming by defining the\noperational and denotational semantics of parallel quantum programs. The\ntechnical contributions of this paper include: (1) find a series of useful\nproof rules for reasoning about correctness of parallel quantum programs; (2)\nprove a (relative) completeness of our proof rules for partial correctness of\ndisjoint parallel quantum programs; and (3) prove a strong soundness theorem of\nthe proof rules showing that partial correctness is well maintained at each\nstep of transitions in the operational semantics of a general parallel quantum\nprogram (with shared variables). This is achieved by partially overcoming the\nfollowing conceptual challenges that are never present in classical parallel\nprogramming: (i) the intertwining of nondeterminism caused by quantum\nmeasurements and introduced by parallelism; (ii) entanglement between component\nquantum programs; and (iii) combining quantum predicates in the overlap of\nstate Hilbert spaces of component quantum programs with shared variables.\nApplications of the techniques developed in this paper are illustrated by a\nformal verification of Bravyi-Gosset-K\\\"onig's parallel quantum algorithm\nsolving a linear algebra problem, which gives for the first time an\nunconditional proof of a computational quantum advantage.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:10:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 13:35:51 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ying", "Mingsheng", ""], ["Zhou", "Li", ""], ["Li", "Yangjia", ""]]}, {"id": "1810.11404", "submitter": "Barbara K\\\"onig", "authors": "Paolo Baldan, Barbara K\\\"onig, Tommaso Padoan, Christina\n  Mika-Michalski", "title": "Fixpoint Games on Continuous Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many analysis and verifications tasks, such as static program analyses and\nmodel-checking for temporal logics reduce to the solution of systems of\nequations over suitable lattices. Inspired by recent work on lattice-theoretic\nprogress measures, we develop a game-theoretical approach to the solution of\nsystems of monotone equations over lattices, where for each single equation\neither the least or greatest solution is taken. A simple parity game, referred\nto as fixpoint game, is defined that provides a correct and complete\ncharacterisation of the solution of equation systems over continuous lattices,\na quite general class of lattices widely used in semantics. For powerset\nlattices the fixpoint game is intimately connected with classical parity games\nfor $\\mu$-calculus model-checking, whose solution can exploit as a key tool\nJurdzi\\'nski's small progress measures. We show how the notion of progress\nmeasure can be naturally generalised to fixpoint games over continuous lattices\nand we prove the existence of small progress measures. Our results lead to a\nconstructive formulation of progress measures as (least) fixpoints. We refine\nthis characterisation by introducing the notion of selection that allows one to\nconstrain the plays in the parity game, enabling an effective (and possibly\nefficient) solution of the game, and thus of the associated verification\nproblem. We also propose a logic for specifying the moves of the existential\nplayer that can be used to systematically derive simplified equations for\nefficiently computing progress measures. We discuss potential applications to\nthe model-checking of latticed $\\mu$-calculi and to the solution of fixpoint\nequations systems over the reals.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 16:04:06 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 11:20:25 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Baldan", "Paolo", ""], ["K\u00f6nig", "Barbara", ""], ["Padoan", "Tommaso", ""], ["Mika-Michalski", "Christina", ""]]}, {"id": "1810.11582", "submitter": "Yan Zhang", "authors": "Yan X Zhang", "title": "Applying Fourier Analysis to Judgment Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Arrow's Theorem answers \"how can $n$ voters obtain a collective\npreference on a set of outcomes, if they have to obey certain constraints?\" We\ngive an analogue in the judgment aggregation framework of List and Pettit,\nanswering \"how can $n$ judges obtain a collective judgment on a set of logical\npropositions, if they have to obey certain constraints?\" We abstract this\nnotion with the concept of \"normal pairs\" of functions on the Hamming cube,\nwhich we analyze with Fourier analysis and elementary combinatorics. We obtain\njudgment aggregation results in the special case of \"symbol-complete\" agendas\nand compare them with existing theorems in the literature. Amusingly, the\nnon-dictatorial classes of functions that arise are precisely the classical\nlogical functions OR, AND, and XOR.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:52:10 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Yan X", ""]]}, {"id": "1810.11979", "submitter": "Stephan Merz", "authors": "Ran Chen, Cyril Cohen (MARELLE), Jean-Jacques Levy (PI.R2), Stephan\n  Merz (VERIDIS), Laurent Thery (MARELLE)", "title": "Formal Proofs of Tarjan's Algorithm in Why3, Coq, and Isabelle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing provers on a formalization of the same problem is always a valuable\nexercise. In this paper, we present the formal proof of correctness of a\nnon-trivial algorithm from graph theory that was carried out in three proof\nassistants: Why3, Coq, and Isabelle.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 07:21:42 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chen", "Ran", "", "MARELLE"], ["Cohen", "Cyril", "", "MARELLE"], ["Levy", "Jean-Jacques", "", "PI.R2"], ["Merz", "Stephan", "", "VERIDIS"], ["Thery", "Laurent", "", "MARELLE"]]}, {"id": "1810.12041", "submitter": "Lucas Carvalho Cordeiro", "authors": "Mikhail R. Gadelha, Enrico Steffinlongo, Lucas C. Cordeiro, Bernd\n  Fischer and Denis A. Nicole", "title": "SMT-Based Refutation of Spurious Bug Reports in the Clang Static\n  Analyzer", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and evaluate a bug refutation extension for the Clang Static\nAnalyzer (CSA) that addresses the limitations of the existing built-in\nconstraint solver. In particular, we complement CSA's existing heuristics that\nremove spurious bug reports. We encode the path constraints produced by CSA as\nSatisfiability Modulo Theories (SMT) problems, use SMT solvers to precisely\ncheck them for satisfiability, and remove bug reports whose associated path\nconstraints are unsatisfiable. Our refutation extension refutes spurious bug\nreports in 8 out of 12 widely used open-source applications; on average, it\nrefutes ca. 7% of all bug reports, and never refutes any true bug report. It\nincurs only negligible performance overheads, and on average adds 1.2% to the\nruntime of the full Clang/LLVM toolchain. A demonstration is available at {\\tt\nhttps://www.youtube.com/watch?v=ylW5iRYNsGA}.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:27:24 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 05:32:18 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Gadelha", "Mikhail R.", ""], ["Steffinlongo", "Enrico", ""], ["Cordeiro", "Lucas C.", ""], ["Fischer", "Bernd", ""], ["Nicole", "Denis A.", ""]]}, {"id": "1810.12077", "submitter": "Andr\\'e Frochaux", "authors": "Andr\\'e Frochaux and Lucas Heimberg", "title": "An Optimal Construction for the Barthelmann-Schwentick Normal Form on\n  Classes of Structures of Bounded Degree", "comments": "Preliminary Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the locality conditions for first-order logic by Hanf and\nGaifman, Barthelmann and Schwentick showed in 1999 that every first-order\nformula is equivalent to a formula of the shape $\\exists x_1 \\dotsc \\exists x_k\n\\forall y\\,\\phi$ where quantification in $\\phi$ is relativised to elements of\ndistance $\\leq r$ from $y$. Such a formula will be called\nBarthelmann-Schwentick normal form (BSNF) in the following. However, although\nthe proof is effective, it leads to a non-elementary blow-up of the BSNF in\nterms of the size of the original formula.\n  We show that, if equivalence on the class of all structures, or even only\nfinite forests, is required, this non-elementary blow-up is indeed unavoidable.\nWe then examine restricted classes of structures where more efficient\nalgorithms are possible. In this direction, we show that on any class of\nstructures of degree $\\leq 2$, BSNF can be computed in 2-fold exponential time\nwith respect to the size of the input formula. And for any class of structures\nof degree $\\leq d$ for some $d\\geq 3$, this is possible in 3-fold exponential\ntime. For both cases, we provide matching lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 12:57:10 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Frochaux", "Andr\u00e9", ""], ["Heimberg", "Lucas", ""]]}, {"id": "1810.12100", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The FOLE Table", "comments": "48 pages, 21 figures, 9 tables, submitted to T.A.C. for review in\n  August 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues the discussion of the representation of ontologies in\nthe first-order logical environment FOLE. According to Gruber, an ontology\ndefines the primitives with which to model the knowledge resources for a\ncommunity of discourse. These primitives, consisting of classes, relationships\nand properties, are represented by the entity-relationship-attribute ERA data\nmodel of Chen. An ontology uses formal axioms to constrain the interpretation\nof these primitives. In short, an ontology specifies a logical theory. A series\nof three papers by the author provide a rigorous mathematical representation\nfor the ERA data model in particular, and ontologies in general, within FOLE.\nThe first two papers, which provide a foundation and superstructure for FOLE,\nrepresent the formalism and semantics of (many-sorted) first-order logic in a\nclassification form corresponding to ideas discussed in the Information Flow\nFramework (IFF). The third paper will define an interpretation of FOLE in terms\nof the transformational passage, first described in (Kent, 2013), from the\nclassification form of first-order logic to an equivalent interpretation form,\nthereby defining the formalism and semantics of first-order logical/relational\ndatabase systems. Two papers will provide a precise mathematical basis for FOLE\ninterpretation: the current paper develops the notion of a FOLE relational\ntable following the relational model of Codd, and a follow-up paper will\ndevelop the notion of a FOLE relational database. Both of these papers expand\non material found in the paper (Kent, 2011). Although the classification form\nfollows the entity-relationship-attribute data model of Chen, the\ninterpretation form follows the relational data model of Codd. In general, the\nFOLE representation uses a conceptual structures approach, that is completely\ncompatible with formal concept analysis and information flow.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 18:24:41 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.12619", "submitter": "Atsushi Igarashi", "authors": "Yusuke Miyazaki and Taro Sekiyama and Atsushi Igarashi", "title": "Dynamic Type Inference for Gradual Hindley--Milner Typing", "comments": "Some typos are corrected in v2", "journal-ref": "PACMPL 3(POPL): 18:1-18:29 (2019)", "doi": "10.1145/3290331", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Garcia and Cimini study a type inference problem for the ITGL, an implicitly\nand gradually typed language with let-polymorphism, and develop a sound and\ncomplete inference algorithm for it. Soundness and completeness mean that, if\nthe algorithm succeeds, the input term can be translated to a well-typed term\nof an explicitly typed blame calculus by cast insertion and vice versa.\nHowever, in general, there are many possible translations depending on how type\nvariables that were left undecided by static type inference are instantiated\nwith concrete static types. Worse, the translated terms may behave\ndifferently---some evaluate to values but others raise blame.\n  In this paper, we propose and formalize a new blame calculus\n$\\lambda^{\\textsf{DTI}}_{\\textsf{B}}$ that avoids such divergence as an\nintermediate language for the ITGL. A main idea is to allow a term to contain\ntype variables (that have not been instantiated during static type inference)\nand defer instantiation of these type variables to run time. We introduce\ndynamic type inference (DTI) into the semantics of\n$\\lambda^{\\textsf{DTI}}_{\\textsf{B}}$ so that type variables are instantiated\nalong reduction. The DTI-based semantics not only avoids the divergence\ndescribed above but also is sound and complete with respect to the semantics of\nfully instantiated terms in the following sense: if the evaluation of a term\nsucceeds (i.e., terminates with a value) in the DTI-based semantics, then there\nis a fully instantiated version of the term that also succeeds in the\nexplicitly typed blame calculus and vice versa.\n  Finally, we prove the gradual guarantee, which is an important correctness\ncriterion of a gradually typed language, for the ITGL.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 10:06:46 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 10:27:15 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Miyazaki", "Yusuke", ""], ["Sekiyama", "Taro", ""], ["Igarashi", "Atsushi", ""]]}, {"id": "1810.12906", "submitter": "Mohammed Almukaynizi", "authors": "Mohammed Almukaynizi, Vivin Paliath, Malay Shah, Malav Shah, Paulo\n  Shakarian", "title": "Finding Cryptocurrency Attack Indicators Using Temporal Logic and\n  Darkweb Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent prevalence of darkweb/deepweb (D2web) sites specializing in\nthe trade of exploit kits and malware, malicious actors have easy-access to a\nwide-range of tools that can empower their offensive capability. In this study,\nwe apply concepts from causal reasoning, itemset mining, and logic programming\non historical cryptocurrency-related cyber incidents with intelligence\ncollected from over 400 D2web hacker forums. Our goal was to find indicators of\ncyber threats targeting cryptocurrency traders and exchange platforms from\nhacker activity. Our approach found interesting activities that, when observed\ntogether in the D2web, subsequent cryptocurrency-related incidents are at least\ntwice as likely to occur than they would if no activity was observed. We also\npresent an algorithmic extension to a previously-introduced algorithm called\nAPT-Extract that allows to model new semantic structures that are specific to\nour application.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:35:54 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Almukaynizi", "Mohammed", ""], ["Paliath", "Vivin", ""], ["Shah", "Malay", ""], ["Shah", "Malav", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1810.12975", "submitter": "Ed Wynn", "authors": "Ed Wynn", "title": "A comparison of encodings for cardinality constraints in a SAT solver", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality constraints are important in many Sat problems; previous studies\nprovide contradictory conclusions about the best encoding to use. Here, three\nencodings are compared: Sinz's sequential-counter, Bailleux and Boufkhad's\ntree-based, and Ab\\'{\\i}o and coworkers' sort-based approaches. The\nsequential-counter approach is found to be the fastest of these for a range of\nrelated, combinatorial test cases. All encodings permit multiple solutions in\nthe auxiliary variables for a single solution to the main variables; the\nnumbers of multiple solutions can be very large, and might impede a Sat solver.\nVariants of the encodings are developed, where extra clauses reduce the numbers\nof multiple solutions. These variants are found to have remarkably little\neffect on solution time, even when the number of clauses is approximately\ndoubled. The results accentuate the well-known observation that clause count\nand other measures of encoding size are not reliable indicators of the\ndifficulty of a Sat problem.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 16:16:59 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wynn", "Ed", ""]]}, {"id": "1810.13129", "submitter": "Omar Al-Bataineh I.", "authors": "Omar Al-Bataineh, David Rosenblum, and Mark Reynolds", "title": "Efficient LTL Decentralized Monitoring Framework Using Formula\n  Simplification Table", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new technique for optimizing formal analysis of\npropositional logic formulas and Linear Temporal Logic (LTL) formulas, namely\nthe formula simplification table. A formula simplification table is a\nmathematical table that shows all possible simplifications of the formula under\ndifferent truth assignments of its variables. The advantages of constructing a\nsimplification table of a formula are two-fold. First, it can be used to\ncompute the logical influence weight of each variable in the formula, which is\na metric that shows the importance of the variable in affecting the outcome of\nthe formula. Second, it can be used to identify variables that have the highest\nlogical influences on the outcome of the formula. %The simplification table can\nbe used to optimize %existing solutions for several interesting %LTL\nverification problems. We demonstrate the effectiveness of formula\nsimplification table in the context of software verification by developing\nefficient framework to the well-known decentralized LTL monitoring problem.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 06:52:07 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Al-Bataineh", "Omar", ""], ["Rosenblum", "David", ""], ["Reynolds", "Mark", ""]]}, {"id": "1810.13261", "submitter": "Niccol\\`o Veltri", "authors": "Rasmus Ejlers M{\\o}gelberg and Niccol\\`o Veltri", "title": "Bisimulation as path type for guarded recursive types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In type theory, coinductive types are used to represent processes, and are\nthus crucial for the formal verification of non-terminating reactive programs\nin proof assistants based on type theory, such as Coq and Agda. Currently,\nprogramming and reasoning about coinductive types is difficult for two reasons:\nThe need for recursive definitions to be productive, and the lack of\ncoincidence of the built-in identity types and the important notion of\nbisimilarity.\n  Guarded recursion in the sense of Nakano has recently been suggested as a\npossible approach to dealing with the problem of productivity, allowing this to\nbe encoded in types. Indeed, coinductive types can be encoded using a\ncombination of guarded recursion and universal quantification over clocks. This\npaper studies the notion of bisimilarity for guarded recursive types in Ticked\nCubical Type Theory, an extension of Cubical Type Theory with guarded\nrecursion. We prove that, for any functor, an abstract, category theoretic\nnotion of bisimilarity for the final guarded coalgebra is equivalent (in the\nsense of homotopy type theory) to path equality (the primitive notion of\nequality in cubical type theory). As a worked example we study a guarded notion\nof labelled transition systems, and show that, as a special case of the general\ntheorem, path equality coincides with an adaptation of the usual notion of\nbisimulation for processes. In particular, this implies that guarded recursion\ncan be used to give simple equational reasoning proofs of bisimilarity. This\nwork should be seen as a step towards obtaining bisimilarity as path equality\nfor coinductive types using the encodings mentioned above.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:59:02 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["M\u00f8gelberg", "Rasmus Ejlers", ""], ["Veltri", "Niccol\u00f2", ""]]}, {"id": "1810.13335", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky", "title": "Finite Relation Algebras with Normal Representations", "comments": "14 pages. Presented at Ramics'18. Postprint to printed conference\n  proceedings published by Springer", "journal-ref": "LNCS, volume 11194, 2018", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the traditional applications of relation algebras is to provide a\nsetting for infinite-domain constraint satisfaction problems. Complexity\nclassification for these computational problems has been one of the major open\nresearch challenges of this application field. The past decade has brought\nsignificant progress on the theory of constraint satisfaction, both over finite\nand infinite domains. This progress has been achieved independently from the\nrelation algebra approach. The present article translates the recent findings\ninto the traditional relation algebra setting, and points out a series of open\nproblems at the interface between model theory and the theory of relation\nalgebras.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:27:36 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Bodirsky", "Manuel", ""]]}, {"id": "1810.13430", "submitter": "Jan Malakhovski", "authors": "Jan Malakhovski", "title": "Exceptionally Monadic Error Handling", "comments": "fixed several typos, added more references, better abstract, and a\n  bunch of random changes here and there (mostly clarifications and\n  terminology)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We notice that the type of catch :: c a -> (e -> c a) -> c a operator is a\nspecial case of monadic bind operator (>>=) :: m a -> (a -> m b) -> m b, the\nsemantics (surprisingly) matches, and this observation has many interesting\nconsequences.\n  For instance, the reader is probably aware that the monadic essence of the\n(>>=) operator of the error monad $\\lambda A.E \\lor A$ is to behave like\nidentity monad for \"normal\" values and to stop on \"errors\". The unappreciated\nfact is that handling of said \"errors\" with a catch operator of the \"flipped\"\n\"conjoined\" error monad $\\lambda E.E \\lor A$ is, too, a monadic computation\nthat treats still unhandled \"errors\" as \"normal\" values and stops when an\n\"error\" is finally handled.\n  We show that for an appropriately indexed type of computations such a\n\"conjoined\" structure naturally follows from the conventional operational\nsemantics of throw and catch operators. Consequently, we show that this\nstructure uniformly generalizes all conventional monadic error handling\nmechanisms we are aware of. We also demonstrate several more interesting\ninstances of this structure of which at least bi-indexed monadic parser\ncombinators and conventional exceptions implemented via continuations have\nimmediate practical applications. Finally, we notice that these observations\nprovide surprising perspectives on error handling in general and point to a\nlargely unexplored trail in programming language design space.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:42:58 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 07:14:43 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 20:39:54 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Malakhovski", "Jan", ""]]}, {"id": "1810.13446", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Structured Parallel Programming", "comments": "32 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on our previous work on algebraic laws for true concurrency, we design\na structured parallel programming language for true concurrency called SPPL.\nDifferent to most programming languages, SPPL has an explicit parallel operator\nas an essential operator, including its operational, denotational and axiomatic\nsemantics. SPPL can structure a truly concurrent graph to a normal form which\nmeans that it is possible to implement a compiler for SPPL.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:51:42 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 14:56:45 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 10:32:50 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wang", "Yong", ""]]}]