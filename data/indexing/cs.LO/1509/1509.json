[{"id": "1509.00164", "submitter": "Saeed Salehi", "authors": "Saeed Salehi", "title": "Theorems of Tarski's Undefinability and Godel's Second\n  Incompleteness-Computationally", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a version of G\\\"odel's Second Incompleteness Theorem for\nrecursively enumerable consistent extensions of a fixed axiomatizable theory,\nby incorporating some bi-theoretic version of the derivability conditions. We\nalso argue that Tarski's theorem on the Undefinability of Truth is G\\\"odel's\nFirst Incompleteness Theorem relativized to definable oracles; a unification of\nthese two theorems is given.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 07:36:12 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 09:05:16 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 08:00:16 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Salehi", "Saeed", ""]]}, {"id": "1509.00608", "submitter": "Jakub Michaliszyn", "authors": "Alessio Lomuscio and Jakub Michaliszyn", "title": "Model Checking Epistemic Halpern-Shoham Logic Extended with Regular\n  Expressions", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Epistemic Halpern-Shoham logic (EHS) is a temporal-epistemic logic that\ncombines the interval operators of the Halpern-Shoham logic with epistemic\nmodalities. The semantics of EHS is based on interpreted systems whose\nlabelling function is defined on the endpoints of intervals. We show that this\ndefinition can be generalised by allowing the labelling function to be based on\nthe whole interval by means of regular expressions. We prove that all the\npositive results known for EHS, notably the attractive complexity of its model\nchecking problem for some of its fragments, still hold for its generalisation.\nWe also propose the new logic EHSre which operates on standard Kripke\nstructures and has expressive power equivalent to that of EHS with regular\nexpressions. We compare the expressive power of EHSre with standard temporal\nlogics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 09:14:02 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Lomuscio", "Alessio", ""], ["Michaliszyn", "Jakub", ""]]}, {"id": "1509.00649", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (DEDUCTEAM)", "title": "Termination of rewrite relations on $\\lambda$-terms based on Girard's\n  notion of reducibility", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2015.07.045", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how to extend the notion of reducibility introduced by\nGirard for proving the termination of $\\beta$-reduction in the polymorphic\n$\\lambda$-calculus, to prove the termination of various kinds of rewrite\nrelations on $\\lambda$-terms, including rewriting modulo some equational theory\nand rewriting with matching modulo $\\beta$$\\eta$, by using the notion of\ncomputability closure. This provides a powerful termination criterion for\nvarious higher-order rewriting frameworks, including Klop's Combinatory\nReductions Systems with simple types and Nipkow's Higher-order Rewrite Systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 11:45:12 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "DEDUCTEAM"]]}, {"id": "1509.00666", "submitter": "Lev Beklemishev", "authors": "Lev D. Beklemishev", "title": "A note on strictly positive logics and word rewriting systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a natural translation from word rewriting systems to strictly\npositive polymodal logics. Thereby, the latter can be considered as a\ngeneralization of the former. As a corollary we obtain examples of undecidable\nstrictly positive normal modal logics. The translation has its counterpart on\nthe level of proofs: we formulate a natural deep inference proof system for\nstrictly positive logics generalizing derivations in word rewriting systems. We\nalso formulate some open questions related to the theory of modal companions of\nsuperintuitionistic logics that was initiated by L.L. Maximova and V.V.\nRybakov.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 12:39:29 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 08:59:41 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Beklemishev", "Lev D.", ""]]}, {"id": "1509.00926", "submitter": "Ricardo Monge", "authors": "Osvaldo Skliar, Ricardo E. Monge, Sherry Gapper", "title": "Using Inclusion Diagrams as an Alternative to Venn Diagrams to Determine\n  the Validity of Categorical Syllogisms", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inclusion diagrams are introduced as an alternative to using Venn diagrams to\ndetermine the validity of categorical syllogisms, and are used here for the\nanalysis of diverse categorical syllogisms. As a preliminary example of a\npossible generalization of the use of inclusion diagrams, consideration is\ngiven also to an argument that includes more than two premises and more than\nthree terms, the classic major, middle and minor terms in categorical\nsyllogisms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 03:10:10 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 21:18:50 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 00:30:13 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Skliar", "Osvaldo", ""], ["Monge", "Ricardo E.", ""], ["Gapper", "Sherry", ""]]}, {"id": "1509.00996", "submitter": "Pablo Barenbaum", "authors": "Beniamino Accattoli, Pablo Barenbaum, Damiano Mazza", "title": "A Strong Distillery", "comments": "Accepted at APLAS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract machines for the strong evaluation of lambda-terms (that is, under\nabstractions) are a mostly neglected topic, despite their use in the\nimplementation of proof assistants and higher-order logic programming\nlanguages. This paper introduces a machine for the simplest form of strong\nevaluation, leftmost-outermost (call-by-name) evaluation to normal form,\nproving it correct, complete, and bounding its overhead. Such a machine, deemed\nStrong Milner Abstract Machine, is a variant of the KAM computing normal forms\nand using just one global environment. Its properties are studied via a special\nform of decoding, called a distillation, into the Linear Substitution Calculus,\nneatly reformulating the machine as a standard micro-step strategy for explicit\nsubstitutions, namely linear leftmost-outermost reduction, i.e., the extension\nto normal form of linear head reduction. Additionally, the overhead of the\nmachine is shown to be linear both in the number of steps and in the size of\nthe initial term, validating its design. The study highlights two distinguished\nfeatures of strong machines, namely backtracking phases and their interactions\nwith abstractions and environments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 09:10:28 GMT"}, {"version": "v2", "created": "Wed, 16 Mar 2016 21:15:59 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Barenbaum", "Pablo", ""], ["Mazza", "Damiano", ""]]}, {"id": "1509.01660", "submitter": "Shuling  Wang", "authors": "Yu Peng, Shuling Wang, Naijun Zhan, and Lijun Zhang", "title": "Extending Hybrid CSP with Probability and Stochasticity", "comments": "The conference version of this paper is accepted by SETTA 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic and stochastic behavior are omnipresent in computer controlled\nsystems, in particular, so-called safety-critical hybrid systems, because of\nfundamental properties of nature, uncertain environments, or simplifications to\novercome complexity. Tightly intertwining discrete, continuous and stochastic\ndynamics complicates modelling, analysis and verification of stochastic hybrid\nsystems (SHSs). In the literature, this issue has been extensively\ninvestigated, but unfortunately it still remains challenging as no promising\ngeneral solutions are available yet. In this paper, we give our effort by\nproposing a general compositional approach for modelling and verification of\nSHSs. First, we extend Hybrid CSP (HCSP), a very expressive and process\nalgebra-like formal modeling language for hybrid systems, by introducing\nprobability and stochasticity to model SHSs, which is called stochastic HCSP\n(SHCSP). To this end, ordinary differential equations (ODEs) are generalized by\nstochastic differential equations (SDEs) and non-deterministic choice is\nreplaced by probabilistic choice. Then, we extend Hybrid Hoare Logic (HHL) to\nspecify and reason about SHCSP processes. We demonstrate our approach by an\nexample from real-world.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 03:50:11 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Peng", "Yu", ""], ["Wang", "Shuling", ""], ["Zhan", "Naijun", ""], ["Zhang", "Lijun", ""]]}, {"id": "1509.01682", "submitter": "Lucas Carvalho Cordeiro", "authors": "Felipe R. M. Sousa, Lucas C. Cordeiro, and Eddie B. de Lima Filho", "title": "Bounded Model Checking of C++ Programs Based on the Qt Framework\n  (extended version)", "comments": "extended version of paper published at GCCE'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software development process for embedded systems is getting faster and\nfaster, which generally incurs an increase in the associated complexity. As a\nconsequence, consumer electronics companies usually invest a lot of resources\nin fast and automatic verification processes, in order to create robust systems\nand reduce product recall rates. Because of that, the present paper proposes a\nsimplified version of the Qt framework, which is integrated into the Efficient\nSMT-Based Bounded Model Checking tool to verify actual applications that use\nthe mentioned framework. The method proposed in this paper presents a success\nrate of 94.45%, for the developed test suite.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 09:00:04 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Sousa", "Felipe R. M.", ""], ["Cordeiro", "Lucas C.", ""], ["Filho", "Eddie B. de Lima", ""]]}, {"id": "1509.01683", "submitter": "Michael Benedikt", "authors": "Michael Benedikt, Pierre Bourhis, Balder ten Cate, Gabriele Puppis,\n  Michael Vanden Boom", "title": "Inference From Visible Information And Background Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a wide-ranging study of the scenario where a subset of the\nrelations in a relational vocabulary are visible to a user --- that is, their\ncomplete contents are known --- while the remaining relations are invisible. We\nalso have a background theory --- invariants given by logical sentences ---\nwhich may relate the visible relations to invisible ones, and also may\nconstrain both the visible and invisible relations in isolation. We want to\ndetermine whether some other information, given as a positive existential\nformula, can be inferred using only the visible information and the background\ntheory. This formula whose inference we are concered with is denoted as the\n\\emph{query}. We consider whether positive information about the query can be\ninferred, and also whether negative information -- the sentence does not hold\n-- can be inferred. We further consider both the instance-level version of the\nproblem, where both the query and the visible instance are given, and the\nschema-level version, where we want to know whether truth or falsity of the\nquery can be inferred in some instance of the schema.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 09:21:17 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 13:48:45 GMT"}, {"version": "v3", "created": "Mon, 23 Jan 2017 14:07:59 GMT"}, {"version": "v4", "created": "Fri, 11 May 2018 21:54:01 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Benedikt", "Michael", ""], ["Bourhis", "Pierre", ""], ["Cate", "Balder ten", ""], ["Puppis", "Gabriele", ""], ["Boom", "Michael Vanden", ""]]}, {"id": "1509.02060", "submitter": "Agi Kurucz", "authors": "Christopher Hampson and Stanislav Kikot and Agi Kurucz", "title": "The decision problem of modal product logics with a diagonal, and faulty\n  counter machines", "comments": null, "journal-ref": null, "doi": "10.1007/s11225-015-9647-7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the propositional modal (and algebraic) treatment of two-variable\nfirst-order logic equality is modelled by a `diagonal' constant, interpreted in\nsquare products of universal frames as the identity (also known as the\n`diagonal') relation. Here we study the decision problem of products of two\narbitrary modal logics equipped with such a diagonal. As the presence or\nabsence of equality in two-variable first-order logic does not influence the\ncomplexity of its satisfiability problem, one might expect that adding a\ndiagonal to product logics in general is similarly harmless. We show that this\nis far from being the case, and there can be quite a big jump in complexity,\neven from decidable to the highly undecidable. Our undecidable logics can also\nbe viewed as new fragments of first- order logic where adding equality changes\na decidable fragment to undecidable. We prove our results by a novel\napplication of counter machine problems. While our formalism apparently cannot\nforce reliable counter machine computations directly, the presence of a unique\ndiagonal in the models makes it possible to encode both lossy and\ninsertion-error computations, for the same sequence of instructions. We show\nthat, given such a pair of faulty computations, it is then possible to\nreconstruct a reliable run from them.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 14:38:20 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Hampson", "Christopher", ""], ["Kikot", "Stanislav", ""], ["Kurucz", "Agi", ""]]}, {"id": "1509.02471", "submitter": "Lucas Carvalho Cordeiro", "authors": "Herbert Rocha, Hussama Ismail, Lucas Cordeiro, Raimundo Barreto", "title": "Model Checking Embedded C Software using k-Induction and Invariants\n  (extended version)", "comments": "extended version of paper published at SBESC'15. arXiv admin note:\n  substantial text overlap with arXiv:1502.02327", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a proof by induction algorithm, which combines k-induction with\ninvariants to model check embedded C software with bounded and unbounded loops.\nThe k-induction algorithm consists of three cases: in the base case, we aim to\nfind a counterexample with up to k loop unwindings; in the forward condition,\nwe check whether loops have been fully unrolled and that the safety property P\nholds in all states reachable within k unwindings; and in the inductive step,\nwe check that whenever P holds for k unwindings, it also holds after the next\nunwinding of the system. For each step of the k-induction algorithm, we infer\ninvariants using affine constraints (i.e., polyhedral) to specify pre- and\npost-conditions. Experimental results show that our approach can handle a wide\nvariety of safety properties in typical embedded software applications from\ntelecommunications, control systems, and medical devices; we demonstrate an\nimprovement of the induction algorithm effectiveness if compared to other\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:54:27 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Rocha", "Herbert", ""], ["Ismail", "Hussama", ""], ["Cordeiro", "Lucas", ""], ["Barreto", "Raimundo", ""]]}, {"id": "1509.02479", "submitter": "Pierre Letouzey", "authors": "Pierre Letouzey", "title": "Hofstadter's problem for curious readers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document summarizes the proofs made during a Coq development inSummer\n2015. This development investigates the function G introducedby Hofstadter in\nhis famous \"G{\\\"o}del, Escher, Bach\" bookas well as a related infinite tree.\nThe left/right flipped variantof this G tree has also been studied here,\nfollowingHofstadter's \"problem for the curious reader\".The initial G function\nis refered as sequence A005206 inOEIS, while the flipped version is the\nsequence A123070.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 18:11:31 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 10:21:56 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 12:17:01 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Letouzey", "Pierre", ""]]}, {"id": "1509.02490", "submitter": "Lucas Carvalho Cordeiro", "authors": "Erickson H. da S. Alves, Lucas C. Cordeiro, Eddie B. de Lima Filho", "title": "Fault Localization in Multi-Threaded C Programs using Bounded Model\n  Checking (extended version)", "comments": "extended version of paper published at SBESC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software debugging is a very time-consuming process, which is even worse for\nmulti-threaded programs, due to the non-deterministic behavior of\nthread-scheduling algorithms. However, the debugging time may be greatly\nreduced, if automatic methods are used for localizing faults. In this study, a\nnew method for fault localization, in multi-threaded C programs, is proposed.\nIt transforms a multi-threaded program into a corresponding sequential one and\nthen uses a fault-diagnosis method suitable for this type of program, in order\nto localize faults. The code transformation is implemented with rules and\ncontext switch information from counterexamples, which are typically generated\nby bounded model checkers. Experimental results show that the proposed method\nis effective, in such a way that sequential fault-localization methods can be\nextended to multi-threaded programs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 18:29:49 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Alves", "Erickson H. da S.", ""], ["Cordeiro", "Lucas C.", ""], ["Filho", "Eddie B. de Lima", ""]]}, {"id": "1509.02492", "submitter": "Lucas Carvalho Cordeiro", "authors": "Alessandro Trindade, Hussama Ismail, and Lucas Cordeiro", "title": "Applying Multi-Core Model Checking to Hardware-Software Partitioning in\n  Embedded Systems (extended version)", "comments": "extended version of paper published at SBESC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative approach to solve the hardware (HW) and software\n(SW) partitioning problem, which uses Bounded Model Checking (BMC) based on\nSatisfiability Modulo Theories (SMT) in conjunction with a multi-core support\nusing Open Multi-Processing. The multi-core SMT-based BMC approach allows\ninitializing many verification instances based on processors cores numbers\navailable to the model checker. Each instance checks for a different optimum\nvalue until the optimization problem is satisfied. The goal is to show that\nmulti-core model-checking techniques can be effective, in particular cases, to\nfind the optimal solution of the HW-SW partitioning problem using an SMT-based\nBMC approach. We compare the experimental results of our proposed approach with\nInteger Linear Programming and the Genetic Algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 18:39:18 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Trindade", "Alessandro", ""], ["Ismail", "Hussama", ""], ["Cordeiro", "Lucas", ""]]}, {"id": "1509.02826", "submitter": "EPTCS", "authors": "Ralph Matthes (IRIT - CNRS & Univ. of Toulouse), Matteo Mio (CNRS &\n  ENS Lyon)", "title": "Proceedings Tenth International Workshop on Fixed Points in Computer\n  Science", "comments": null, "journal-ref": "EPTCS 191, 2015", "doi": "10.4204/EPTCS.191", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Tenth International Workshop on\nFixed Points in Computer Science (FICS 2015) which took place on September 11th\nand 12th, 2015 in Berlin, Germany, as a satellite event of the conference\nComputer Science Logic (CSL 2015).\n  Fixed points play a fundamental role in several areas of computer science.\nThey are used to justify (co)recursive definitions and associated reasoning\ntechniques. The construction and properties of fixed points have been\ninvestigated in many different settings such as: design and implementation of\nprogramming languages, logics, verification, databases. The aim of this\nworkshop is to provide a forum for researchers to present their results to\nthose members of the computer science and logic communities who study or apply\nthe theory of fixed points.\n  Each of the 11 contributed papers of this volume were evaluated by three or\nfour reviewers. Some of the papers were re-reviewed after revision.\n  Additionally, this volume contains the abstracts of the FICS 2015 invited\ntalks given by Bartek Klin and James Worrell.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 16:02:13 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Matthes", "Ralph", "", "IRIT - CNRS & Univ. of Toulouse"], ["Mio", "Matteo", "", "CNRS &\n  ENS Lyon"]]}, {"id": "1509.02908", "submitter": "Jonathan Bowen", "authors": "Jonathan P. Bowen", "title": "Provably Correct Systems: Community, connections, and citations", "comments": "15 pages, 4 figures. Presented at Festschrift for Prof. Dr\n  Ernst-R\\\"udiger Olderog, University of Oldenburg, Germany, 8-9 September 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original European ESPRIT ProCoS I and II projects on Provably Correct\nSystems} took place around a quarter of a century ago. Since then the legacy of\nthe initiative has spawned many researchers with careers in formal methods. One\nof the leaders on the ProCoS projects was Ernst-R\\\"udiger Olderog. This paper\ncharts the influence of the ProCoS projects and the subsequent ProCoS-WG\nWorking Group, using Prof. Dr Olderog as an example. The community of\nresearchers surrounding an initiative such as ProCoS is considered in the\ncontext of the social science concept of a Community of Practice (CoP) and the\ncollaborations undertaken through coauthorship of and citations to\npublications. Consideration of citation metrics is also included.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 15:05:48 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2015 14:56:08 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Bowen", "Jonathan P.", ""]]}, {"id": "1509.02992", "submitter": "Cameron Freer", "authors": "Nathanael L. Ackerman and Cameron E. Freer and Daniel M. Roy", "title": "On computability and disintegration", "comments": "28 pages. Substantially updated following referee suggestions", "journal-ref": "Mathematical Structures in Computer Science, 27:8 (2017), pp.\n  1287-1314", "doi": "10.1017/S0960129516000098", "report-no": null, "categories": "math.LO cs.LO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the disintegration operator on a complete separable metric space\nalong a projection map, restricted to measures for which there is a unique\ncontinuous disintegration, is strongly Weihrauch equivalent to the limit\noperator Lim. When a measure does not have a unique continuous disintegration,\nwe may still obtain a disintegration when some basis of continuity sets has the\nVitali covering property with respect to the measure; the disintegration,\nhowever, may depend on the choice of sets. We show that, when the basis is\ncomputable, the resulting disintegration is strongly Weihrauch reducible to\nLim, and further exhibit a single distribution realizing this upper bound.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 02:56:21 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 18:51:35 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Ackerman", "Nathanael L.", ""], ["Freer", "Cameron E.", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1509.03013", "submitter": "EPTCS", "authors": "Angelos Charalambidis, Panos Rondogiannis, Ioanna Symeonidou", "title": "Equivalence of two Fixed-Point Semantics for Definitional Higher-Order\n  Logic Programs", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 18-32", "doi": "10.4204/EPTCS.191.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two distinct research approaches have been proposed for assigning a purely\nextensional semantics to higher-order logic programming. The former approach\nuses classical domain theoretic tools while the latter builds on a fixed-point\nconstruction defined on a syntactic instantiation of the source program. The\nrelationships between these two approaches had not been investigated until now.\nIn this paper we demonstrate that for a very broad class of programs, namely\nthe class of definitional programs introduced by W. W. Wadge, the two\napproaches coincide (with respect to ground atoms that involve symbols of the\nprogram). On the other hand, we argue that if existential higher-order\nvariables are allowed to appear in the bodies of program rules, the two\napproaches are in general different. The results of the paper contribute to a\nbetter understanding of the semantics of higher-order logic programming.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:31:21 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Charalambidis", "Angelos", ""], ["Rondogiannis", "Panos", ""], ["Symeonidou", "Ioanna", ""]]}, {"id": "1509.03014", "submitter": "EPTCS", "authors": "Naohi Eguchi", "title": "Formalizing Termination Proofs under Polynomial Quasi-interpretations", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 33-47", "doi": "10.4204/EPTCS.191.5", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usual termination proofs for a functional program require to check all the\npossible reduction paths. Due to an exponential gap between the height and size\nof such the reduction tree, no naive formalization of termination proofs yields\na connection to the polynomial complexity of the given program. We solve this\nproblem employing the notion of minimal function graph, a set of pairs of a\nterm and its normal form, which is defined as the least fixed point of a\nmonotone operator. We show that termination proofs for programs reducing under\nlexicographic path orders (LPOs for short) and polynomially quasi-interpretable\ncan be optimally performed in a weak fragment of Peano arithmetic. This yields\nan alternative proof of the fact that every function computed by an\nLPO-terminating, polynomially quasi-interpretable program is computable in\npolynomial space. The formalization is indeed optimal since every\npolynomial-space computable function can be computed by such a program. The\ncrucial observation is that inductive definitions of minimal function graphs\nunder LPO-terminating programs can be approximated with transfinite induction\nalong LPOs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:31:31 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Eguchi", "Naohi", ""]]}, {"id": "1509.03015", "submitter": "EPTCS", "authors": "Zolt\\'an \\'Esik (University of Szeged), Uli Fahrenberg (Inria Rennes),\n  Axel Legay (Inria Rennes)", "title": "*-Continuous Kleene $\\omega$-Algebras for Energy Problems", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 48-59", "doi": "10.4204/EPTCS.191.6", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy problems are important in the formal analysis of embedded or\nautonomous systems. Using recent results on star-continuous Kleene\nomega-algebras, we show here that energy problems can be solved by algebraic\nmanipulations on the transition matrix of energy automata. To this end, we\nprove general results about certain classes of finitely additive functions on\ncomplete lattices which should be of a more general interest.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:31:35 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["\u00c9sik", "Zolt\u00e1n", "", "University of Szeged"], ["Fahrenberg", "Uli", "", "Inria Rennes"], ["Legay", "Axel", "", "Inria Rennes"]]}, {"id": "1509.03017", "submitter": "EPTCS", "authors": "Helle Hvid Hansen (Delft University of Technology, Delft, The\n  Netherlands), Clemens Kupke (University of Strathclyde, Glasgow, United\n  Kingdom)", "title": "Weak Completeness of Coalgebraic Dynamic Logics", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 90-104", "doi": "10.4204/EPTCS.191.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coalgebraic generalisation of Fischer and Ladner's Propositional\nDynamic Logic (PDL) and Parikh's Game Logic (GL). In earlier work, we proved a\ngeneric strong completeness result for coalgebraic dynamic logics without\niteration. The coalgebraic semantics of such programs is given by a monad T,\nand modalities are interpreted via a predicate lifting \\^I whose transpose is a\nmonad morphism from T to the neighbourhood monad. In this paper, we show that\nif the monad T carries a complete semilattice structure, then we can define an\niteration construct, and suitable notions of diamond-likeness and box-likeness\nof predicate-liftings which allows for the definition of an axiomatisation\nparametric in T, \\^I and a chosen set of pointwise program operations. As our\nmain result, we show that if the pointwise operations are \"negation-free\" and\nKleisli composition left-distributes over the induced join on Kleisli arrows,\nthen this axiomatisation is weakly complete with respect to the class of\nstandard models. As special instances, we recover the weak completeness of PDL\nand of dual-free Game Logic. As a modest new result we obtain completeness for\ndual-free GL extended with intersection (demonic choice) of games.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:32:04 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Hansen", "Helle Hvid", "", "Delft University of Technology, Delft, The\n  Netherlands"], ["Kupke", "Clemens", "", "University of Strathclyde, Glasgow, United\n  Kingdom"]]}, {"id": "1509.03018", "submitter": "EPTCS", "authors": "Martin Lange (University of Kassel)", "title": "The Arity Hierarchy in the Polyadic $\\mu$-Calculus", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 105-116", "doi": "10.4204/EPTCS.191.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polyadic mu-calculus is a modal fixpoint logic whose formulas define\nrelations of nodes rather than just sets in labelled transition systems. It can\nexpress exactly the polynomial-time computable and bisimulation-invariant\nqueries on finite graphs. In this paper we show a hierarchy result with respect\nto expressive power inside the polyadic mu-calculus: for every level of\nfixpoint alternation, greater arity of relations gives rise to higher\nexpressive power. The proof uses a diagonalisation argument.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:32:11 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Lange", "Martin", "", "University of Kassel"]]}, {"id": "1509.03019", "submitter": "EPTCS", "authors": "Karoliina Lehtinen", "title": "Disjunctive form and the modal $\\mu$ alternation hierarchy", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 117-131", "doi": "10.4204/EPTCS.191.11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the relationship between disjunctive form, a syntactic\nnormal form for the modal mu calculus, and the alternation hierarchy. First it\nshows that all disjunctive formulas which have equivalent tableau have the same\nsyntactic alternation depth. However, tableau equivalence only preserves\nalternation depth for the disjunctive fragment: there are disjunctive formulas\nwith arbitrarily high alternation depth that are tableau equivalent to\nalternation-free non-disjunctive formulas. Conversely, there are\nnon-disjunctive formulas of arbitrarily high alternation depth that are tableau\nequivalent to disjunctive formulas without alternations. This answers\nnegatively the so far open question of whether disjunctive form preserves\nalternation depth. The classes of formulas studied here illustrate a previously\nundocumented type of avoidable syntactic complexity which may contribute to our\nunderstanding of why deciding the alternation hierarchy is still an open\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:32:21 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Lehtinen", "Karoliina", ""]]}, {"id": "1509.03020", "submitter": "EPTCS", "authors": "Etienne Lozes (ENS Cachan, CNRS)", "title": "A Type-Directed Negation Elimination", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 132-142", "doi": "10.4204/EPTCS.191.12", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modal mu-calculus, a formula is well-formed if each recursive variable\noccurs underneath an even number of negations. By means of De Morgan's laws, it\nis easy to transform any well-formed formula into an equivalent formula without\nnegations -- its negation normal form. Moreover, if the formula is of size n,\nits negation normal form of is of the same size O(n). The full modal\nmu-calculus and the negation normal form fragment are thus equally expressive\nand concise.\n  In this paper we extend this result to the higher-order modal fixed point\nlogic (HFL), an extension of the modal mu-calculus with higher-order recursive\npredicate transformers. We present a procedure that converts a formula into an\nequivalent formula without negations of quadratic size in the worst case and of\nlinear size when the number of variables of the formula is fixed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:32:29 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Lozes", "Etienne", "", "ENS Cachan, CNRS"]]}, {"id": "1509.03021", "submitter": "EPTCS", "authors": "Paolo Torrini (KU Leuven), Tom Schrijvers (KU Leuven)", "title": "Reasoning about modular datatypes with Mendler induction", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 143-157", "doi": "10.4204/EPTCS.191.13", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In functional programming, datatypes a la carte provide a convenient modular\nrepresentation of recursive datatypes, based on their initial algebra\nsemantics. Unfortunately it is highly challenging to implement this technique\nin proof assistants that are based on type theory, like Coq. The reason is that\nit involves type definitions, such as those of type-level fixpoint operators,\nthat are not strictly positive. The known work-around of impredicative\nencodings is problematic, insofar as it impedes conventional inductive\nreasoning. Weak induction principles can be used instead, but they considerably\ncomplicate proofs.\n  This paper proposes a novel and simpler technique to reason inductively about\nimpredicative encodings, based on Mendler-style induction. This technique\ninvolves dispensing with dependent induction, ensuring that datatypes can be\nlifted to predicates and relying on relational formulations. A case study on\nproving subject reduction for structural operational semantics illustrates that\nthe approach enables modular proofs, and that these proofs are essentially\nsimilar to conventional ones.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 05:32:36 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Torrini", "Paolo", "", "KU Leuven"], ["Schrijvers", "Tom", "", "KU Leuven"]]}, {"id": "1509.03048", "submitter": "Jan Krajicek", "authors": "Jan Krajicek", "title": "Consistency of circuit evaluation, extended resolution and total NP\n  search problems", "comments": "Preliminary version 10.September 2015", "journal-ref": "Forum of Mathematics, Sigma / Volume 4 / 2016, e15", "doi": "10.1017/fms.2016.13", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sets $\\Gamma(n,s,k)$ of narrow clauses expressing that no\ndefinition of a size $s$ circuit with $n$ inputs is refutable in resolution R\nin $k$ steps. We show that every CNF shortly refutable in Extended R, ER, can\nbe easily reduced to an instance of $\\Gamma(0,s,k)$ (with $s,k$ depending on\nthe size of the ER-refutation) and, in particular, that $\\Gamma(0,s,k)$ when\ninterpreted as a relativized NP search problem is complete among all such\nproblems provably total in bounded arithmetic theory $V^1_1$.\n  We use the ideas of implicit proofs to define from $\\Gamma(0,s,k)$ a\nnon-relativized NP search problem $i\\Gamma$ and we show that it is complete\namong all such problems provably total in bounded arithmetic theory $V^1_2$.\nThe reductions are definable in $S^1_2$.\n  We indicate how similar results can be proved for some other propositional\nproof systems and bounded arithmetic theories and how the construction can be\nused to define specific random unsatisfiable formulas, and we formulate two\nopen problems about them.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 07:49:05 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Krajicek", "Jan", ""]]}, {"id": "1509.03339", "submitter": "Robbert Krebbers", "authors": "Robbert Krebbers", "title": "A Formal C Memory Model for Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core of a formal semantics of an imperative programming language is a\nmemory model that describes the behavior of operations on the memory. Defining\na memory model that matches the description of C in the C11 standard is\nchallenging because C allows both high-level (by means of typed expressions)\nand low-level (by means of bit manipulation) memory accesses. The C11 standard\nhas restricted the interaction between these two levels to make more effective\ncompiler optimizations possible, on the expense of making the memory model\ncomplicated.\n  We describe a formal memory model of the (non-concurrent part of the) C11\nstandard that incorporates these restrictions, and at the same time describes\nlow-level memory operations. This formal memory model includes a rich\npermission model to make it usable in separation logic and supports reasoning\nabout program transformations. The memory model and essential properties of it\nhave been fully formalized using the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 21:16:41 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Krebbers", "Robbert", ""]]}, {"id": "1509.03391", "submitter": "Yuxin Deng", "authors": "Yuxin Deng, Wenjie Du, Daniel Gebler", "title": "Modal Characterisations of Behavioural Pseudometrics", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For the model of probabilistic labelled transition systems that allow for the\nco-existence of nondeterminism and probabilities, we present two notions of\nbisimulation metrics: one is state-based and the other is distribution-based.\nWe provide a sound and complete modal characterisation for each of them, using\nreal-valued modal logics based on the Hennessy-Milner logic. The logic for\ncharacterising the state-based metric is much simpler than an earlier logic by\nDesharnais et al. as it uses only two non-expansive operators rather than the\ngeneral class of non-expansive operators.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 05:33:30 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Deng", "Yuxin", ""], ["Du", "Wenjie", ""], ["Gebler", "Daniel", ""]]}, {"id": "1509.03424", "submitter": "George Karpenkov", "authors": "George Karpenkov, David Monniaux and Philipp Wendler", "title": "Program Analysis with Local Policy Iteration", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-49122-5_6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for deriving numerical invariants that combines\nthe precision of max-policy iteration with the flexibility and scalability of\nconventional Kleene iterations. It is defined in the Configurable Program\nAnalysis (CPA) framework, thus allowing inter-analysis communication.\n  It uses adjustable-block encoding in order to traverse loop-free program\nsections, possibly containing branching, without introducing extra abstraction.\nOur technique operates over any template linear constraint domain, including\nthe interval and octagon domains; templates can also be derived from the\nprogram source.\n  The implementation is evaluated on a set of benchmarks from the Software\nVerification Competition (SV-Comp). It competes favorably with state-of-the-art\nanalyzers.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 09:02:31 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2015 15:39:54 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2015 10:54:03 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Karpenkov", "George", ""], ["Monniaux", "David", ""], ["Wendler", "Philipp", ""]]}, {"id": "1509.03476", "submitter": "Justin Hsu", "authors": "Gilles Barthe, Thomas Espitau, Benjamin Gr\\'egoire, Justin Hsu, L\\'eo\n  Stefanesco, Pierre-Yves Strub", "title": "Relational reasoning via probabilistic coupling", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-48899-7_27", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic coupling is a powerful tool for analyzing pairs of\nprobabilistic processes. Roughly, coupling two processes requires finding an\nappropriate witness process that models both processes in the same probability\nspace. Couplings are powerful tools proving properties about the relation\nbetween two processes, include reasoning about convergence of distributions and\nstochastic dominance---a probabilistic version of a monotonicity property.\n  While the mathematical definition of coupling looks rather complex and\ncumbersome to manipulate, we show that the relational program logic pRHL---the\nlogic underlying the EasyCrypt cryptographic proof assistant---already\ninternalizes a generalization of probabilistic coupling. With this insight,\nconstructing couplings is no harder than constructing logical proofs. We\ndemonstrate how to express and verify classic examples of couplings in pRHL,\nand we mechanically verify several couplings in EasyCrypt.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 12:29:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 21:26:37 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Barthe", "Gilles", ""], ["Espitau", "Thomas", ""], ["Gr\u00e9goire", "Benjamin", ""], ["Hsu", "Justin", ""], ["Stefanesco", "L\u00e9o", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1509.03705", "submitter": "Yuting Wang", "authors": "Yuting Wang and Gopalan Nadathur", "title": "A Higher-Order Abstract Syntax Approach to Verified Transformations on\n  Functional Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to the verified implementation of transformations on\nfunctional programs that exploits the higher-order representation of syntax. In\nthis approach, transformations are specified using the logic of hereditary\nHarrop formulas. On the one hand, these specifications serve directly as\nimplementations, being programs in the language Lambda Prolog. On the other\nhand, they can be used as input to the Abella system which allows us to prove\nproperties about them and thereby about the implementations. We argue that this\napproach is especially effective in realizing transformations that analyze\nbinding structure. We do this by describing concise encodings in Lambda Prolog\nfor transformations like typed closure conversion and code hoisting that are\nsensitive to such structure and by showing how to prove their correctness using\nAbella.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 05:22:52 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 21:48:25 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2016 21:12:03 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Wang", "Yuting", ""], ["Nadathur", "Gopalan", ""]]}, {"id": "1509.03853", "submitter": "Sergey Slavnov A", "authors": "Sergey Slavnov", "title": "On Banach spaces of sequences and free linear logic exponential modality", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 29 (2019) 215-242", "doi": "10.1017/S0960129517000251", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a category of vector spaces modelling full propositional linear\nlogic, similar to probabilistic coherence spaces and to Koethe sequences\nspaces. Its objects are {\\it rigged sequences spaces}, Banach spaces of\nsequences, with norms defined from pairing with finite sequences, and morphisms\nare bounded linear maps, continuous in a suitable topology. The main interest\nof the work is that our model gives a realization of the free linear logic\nexponentials construction.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 14:44:00 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 14:46:22 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "1509.04116", "submitter": "Vojtech Forejt", "authors": "Vojt\\v{e}ch Forejt, Jan Kr\\v{c}\\'al and Jan K\\v{r}et\\'insk\\'y", "title": "Controller synthesis for MDPs and Frequency LTL$\\setminus$GU", "comments": "Extended version of a paper presented at LPAR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative extensions of temporal logics have recently attracted\nsignificant attention. In this work, we study frequency LTL (fLTL), an\nextension of LTL which allows to speak about frequencies of events along an\nexecution. Such an extension is particularly useful for probabilistic systems\nthat often cannot fulfil strict qualitative guarantees on the behaviour. It has\nbeen recently shown that controller synthesis for Markov decision processes and\nfLTL is decidable when all the bounds on frequencies are 1. As a step towards a\ncomplete quantitative solution, we show that the problem is decidable for the\nfragment fLTL$\\setminus$GU, where U does not occur in the scope of G (but still\nF can). Our solution is based on a novel translation of such quantitative\nformulae into equivalent deterministic automata.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 14:36:18 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Forejt", "Vojt\u011bch", ""], ["Kr\u010d\u00e1l", "Jan", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""]]}, {"id": "1509.04153", "submitter": "Bart van Delft", "authors": "Bart van Delft, Richard Bubel", "title": "Dependency-Based Information Flow Analysis with Declassification in a\n  Program Logic", "comments": "Technical Report; 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deductive approach for the analysis of secure information flows\nwith support for fine-grained policies that include declassifications in the\nform of delimited information release. By explicitly tracking the dependencies\nof program locations as a computation history, we maintain high precision,\nwhile avoiding the need for comparing independent program runs. By considering\nan explicit heap model, we argue that the proposed analysis can\nstraightforwardly be applied on object-oriented programs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 15:33:04 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["van Delft", "Bart", ""], ["Bubel", "Richard", ""]]}, {"id": "1509.04699", "submitter": "Jean-Pierre Jouannaud", "authors": "Jean-Pierre Jouannaud (UP11, LIX), Jiaxiang Liu (LIX), Mizuhito Ogawa\n  (JAIST)", "title": "Confluence of Layered Rewrite Systems", "comments": null, "journal-ref": "Stephan Kreutzer. Proceedings, 24th annual EATCS Computer Science\n  Logic, Sep 2015, Berlin, Germany. LIPICS, vol 41, 2015, Proceedings, 24th\n  annual EATCS Computer Science Logic.\n  \\&lt;http://drops.dagstuhl.de/portals/extern/index.php?semnr=15014\\&gt;", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the new, Turing-complete class of layered systems, whose\nlefthand sides of rules can only be overlapped at a multiset of disjoint or\nequal positions. Layered systems define a natural notion of rank for terms: the\nmaximal number of non-overlapping redexes along a path from the root to a leaf.\nOverlappings are allowed in finite or infinite trees. Rules may be\nnon-terminating, non-left-linear, or non-right-linear. Using a novel\nunification technique, cyclic unification, and the so-alled subrewriting\nrelation, we show that rank non-increasing layered systems are confluent\nprovided their cyclic critical pairs have cyclic-joinable decreasing diagrams.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 19:48:43 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Jouannaud", "Jean-Pierre", "", "UP11, LIX"], ["Liu", "Jiaxiang", "", "LIX"], ["Ogawa", "Mizuhito", "", "JAIST"]]}, {"id": "1509.05144", "submitter": "EPTCS", "authors": "Swen Jacobs, Leander Tentrup, Martin Zimmermann", "title": "Distributed PROMPT-LTL Synthesis", "comments": "In Proceedings GandALF 2016, arXiv:1609.03648", "journal-ref": "EPTCS 226, 2016, pp. 228-241", "doi": "10.4204/EPTCS.226.16", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the synthesis of distributed implementations for specifications\nin Prompt Linear Temporal Logic (PROMPT-LTL), which extends LTL by temporal\noperators equipped with parameters that bound their scope. For single process\nsynthesis it is well-established that such parametric extensions do not\nincrease worst-case complexities.\n  For synchronous systems, we show that, despite being more powerful, the\ndistributed realizability problem for PROMPT-LTL is not harder than its LTL\ncounterpart. For asynchronous systems we have to consider an assume-guarantee\nsynthesis problem, as we have to express scheduling assumptions. As\nasynchronous distributed synthesis is already undecidable for LTL, we give a\nsemi-decision procedure for the PROMPT-LTL assume-guarantee synthesis problem\nbased on bounded synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 06:39:09 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 08:14:36 GMT"}, {"version": "v3", "created": "Wed, 14 Sep 2016 00:59:54 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Jacobs", "Swen", ""], ["Tentrup", "Leander", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1509.05318", "submitter": "jesus dominguez", "authors": "Jes\\'us Dom\\'inguez (King's College London), Maribel Fern\\'andez\n  (King's College London)", "title": "From nominal to higher-order rewriting and back again", "comments": "41 pages, journal", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  14, 2015) lmcs:1610", "doi": "10.2168/LMCS-11(4:9)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a translation function from nominal rewriting systems (NRSs) to\ncombinatory reduction systems (CRSs), transforming closed nominal rules and\nground nominal terms to CRSs rules and terms, respectively, while preserving\nthe rewriting relation. We also provide a reduction-preserving translation in\nthe other direction, from CRSs to NRSs, improving over a previously defined\ntranslation. These tools, together with existing translations between CRSs and\nother higher-order rewriting formalisms, open up the path for a transfer of\nresults between higher-order and nominal rewriting. In particular, techniques\nand properties of the rewriting relation, such as termination, can be exported\nfrom one formalism to the other.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 16:29:53 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2015 14:44:28 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Dom\u00ednguez", "Jes\u00fas", "", "King's College London"], ["Fern\u00e1ndez", "Maribel", "", "King's College London"]]}, {"id": "1509.05376", "submitter": "EPTCS", "authors": "Makoto Hamana (Department of Computer Science, Gunma University)", "title": "Iteration Algebras for UnQL Graphs and Completeness for Bisimulation", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 75-89", "doi": "10.4204/EPTCS.191.8", "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows an application of Bloom and Esik's iteration algebras to\nmodel graph data in a graph database query language. About twenty years ago,\nBuneman et al. developed a graph database query language UnQL on the top of a\nfunctional meta-language UnCAL for describing and manipulating graphs.\nRecently, the functional programming community has shown renewed interest in\nUnCAL, because it provides an efficient graph transformation language which is\nuseful for various applications, such as bidirectional computation. However, no\nmathematical semantics of UnQL/UnCAL graphs has been developed. In this paper,\nwe give an equational axiomatisation and algebraic semantics of UnCAL graphs.\nThe main result of this paper is to prove that completeness of our equational\naxioms for UnCAL for the original bisimulation of UnCAL graphs via iteration\nalgebras. Another benefit of algebraic semantics is a clean characterisation of\nstructural recursion on graphs using free iteration algebra.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 19:06:38 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Hamana", "Makoto", "", "Department of Computer Science, Gunma University"]]}, {"id": "1509.05526", "submitter": "EPTCS", "authors": "Matt Kaufmann, David L. Rager", "title": "Proceedings Thirteenth International Workshop on the ACL2 Theorem Prover\n  and Its Applications", "comments": "Celebrating the 25th anniversary of ACL2", "journal-ref": "EPTCS 192, 2015", "doi": "10.4204/EPTCS.192", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Thirteenth International Workshop\non the ACL2 Theorem Prover and Its Applications, ACL2 2015, a two-day workshop\nheld in Austin, Texas, USA, on October 1-2, 2015. ACL2 workshops occur at\napproximately 18-month intervals and provide a major technical forum for\nresearchers to present and discuss improvements and extensions to the theorem\nprover, comparisons of ACL2 with other systems, and applications of ACL2 in\nformal verification.\n  ACL2 is a state-of-the-art automated reasoning system that has been\nsuccessfully applied in academia, government, and industry for specification\nand verification of computing systems and in teaching computer science courses.\nIn 2005, Boyer, Kaufmann, and Moore were awarded the 2005 ACM Software System\nAward for their work on ACL2 and the other theorem provers in the Boyer-Moore\nfamily.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 07:40:46 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Kaufmann", "Matt", ""], ["Rager", "David L.", ""]]}, {"id": "1509.05659", "submitter": "Ferruccio Damiani", "authors": "Ferruccio Damiani (University of Torino), Mirko Viroli (University of\n  Bologna)", "title": "Type-based Self-stabilisation for Computational Fields", "comments": "Logical Methods in Computer Science accepted paper, 53 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  31, 2015) lmcs:1622", "doi": "10.2168/LMCS-11(4:21)2015", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging network scenarios require the development of solid large-scale\nsituated systems. Unfortunately, the diffusion/aggregation computational\nprocesses therein often introduce a source of complexity that hampers\npredictability of the overall system behaviour. Computational fields have been\nintroduced to help engineering such systems: they are spatially distributed\ndata structures designed to adapt their shape to the topology of the underlying\n(mobile) network and to the events occurring in it, with notable applications\nto pervasive computing, sensor networks, and mobile robots. To assure\nbehavioural correctness, namely, correspondence of micro-level specification\n(single device behaviour) with macro-level behaviour (resulting global spatial\npattern), we investigate the issue of self-stabilisation for computational\nfields. We present a tiny, expressive, and type-sound calculus of computational\nfields, and define sufficient conditions for self-stabilisation, defined as the\nability to react to changes in the environment finding a new stable state in\nfinite time. A type-based approach is used to provide a correct checking\nprocedure for self-stabilisation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 15:19:59 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2015 21:43:19 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Damiani", "Ferruccio", "", "University of Torino"], ["Viroli", "Mirko", "", "University of\n  Bologna"]]}, {"id": "1509.05842", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Structure Preserving Bisimilarity, Supporting an Operational Petri Net\n  Semantics of CCSP", "comments": null, "journal-ref": "Proc. Correct System Design - Symposium in Honor of\n  Ernst-R\\\"udiger Olderog on the Occasion of His 60th Birthday (R. Meyer, A.\n  Platzer & H. Wehrheim, eds.), Oldenburg, Germany, September 8-9, 2015, LNCS\n  9360, Springer, pp. 99-130", "doi": "10.1007/978-3-319-23506-6_9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1987 Ernst-R\\\"udiger Olderog provided an operational Petri net semantics\nfor a subset of CCSP, the union of Milner's CCS and Hoare's CSP. It assigns to\neach process term in the subset a labelled, safe place/transition net. To\ndemonstrate the correctness of the approach, Olderog established agreement (1)\nwith the standard interleaving semantics of CCSP up to strong bisimulation\nequivalence, and (2) with standard denotational interpretations of CCSP\noperators in terms of Petri nets up to a suitable semantic equivalence that\nfully respects the causal structure of nets. For the latter he employed a\nlinear-time semantic equivalence, namely having the same causal nets.\n  This paper strengthens (2), employing a novel branching-time version of this\nsemantics---structure preserving bisimilarity---that moreover preserves\ninevitability. I establish that it is a congruence for the operators of CCSP.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 02:21:49 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1509.06079", "submitter": "EPTCS", "authors": "Sol Swords (Centaur Technology, Inc.), Jared Davis (Centaur\n  Technology, Inc.)", "title": "Fix Your Types", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 3-16", "doi": "10.4204/EPTCS.192.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using existing ACL2 datatype frameworks, many theorems require type\nhypotheses. These hypotheses slow down the theorem prover, are tedious to\nwrite, and are easy to forget. We describe a principled approach to types that\nprovides strong type safety and execution efficiency while avoiding type\nhypotheses, and we present a library that automates this approach. Using this\napproach, types help you catch programming errors and then get out of the way\nof theorem proving.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:34:37 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Swords", "Sol", "", "Centaur Technology, Inc."], ["Davis", "Jared", "", "Centaur\n  Technology, Inc."]]}, {"id": "1509.06080", "submitter": "EPTCS", "authors": "Alessandro Coglio", "title": "Second-Order Functions and Theorems in ACL2", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 17-33", "doi": "10.4204/EPTCS.192.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SOFT ('Second-Order Functions and Theorems') is a tool to mimic second-order\nfunctions and theorems in the first-order logic of ACL2. Second-order functions\nare mimicked by first-order functions that reference explicitly designated\nuninterpreted functions that mimic function variables. First-order theorems\nover these second-order functions mimic second-order theorems universally\nquantified over function variables. Instances of second-order functions and\ntheorems are systematically generated by replacing function variables with\nfunctions. SOFT can be used to carry out program refinement inside ACL2, by\nconstructing a sequence of increasingly stronger second-order predicates over\none or more target functions: the sequence starts with a predicate that\nspecifies requirements for the target functions, and ends with a predicate that\nprovides executable definitions for the target functions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:34:48 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Coglio", "Alessandro", ""]]}, {"id": "1509.06081", "submitter": "EPTCS", "authors": "John Cowles (University of Wyoming), Ruben Gamboa (University of\n  Wyoming)", "title": "Perfect Numbers in ACL2", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 53-59", "doi": "10.4204/EPTCS.192.5", "report-no": null, "categories": "cs.LO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A perfect number is a positive integer n such that n equals the sum of all\npositive integer divisors of n that are less than n. That is, although n is a\ndivisor of n, n is excluded from this sum. Thus 6 = 1 + 2 + 3 is perfect, but\n12 < 1 + 2 + 3 + 4 + 6 is not perfect. An ACL2 theory of perfect numbers is\ndeveloped and used to prove, in ACL2(r), this bit of mathematical folklore:\nEven if there are infinitely many perfect numbers the series of the reciprocals\nof all perfect numbers converges.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:35:06 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Cowles", "John", "", "University of Wyoming"], ["Gamboa", "Ruben", "", "University of\n  Wyoming"]]}, {"id": "1509.06082", "submitter": "EPTCS", "authors": "Yan Peng (University of British Columbia), Mark Greenstreet\n  (University of British Columbia)", "title": "Extending ACL2 with SMT Solvers", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 61-77", "doi": "10.4204/EPTCS.192.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our extension of ACL2 with Satisfiability Modulo Theories (SMT)\nsolvers using ACL2's trusted clause processor mechanism. We are particularly\ninterested in the verification of physical systems including Analog and\nMixed-Signal (AMS) designs. ACL2 offers strong induction abilities for\nreasoning about sequences and SMT complements deduction methods like ACL2 with\nfast nonlinear arithmetic solving procedures. While SAT solvers have been\nintegrated into ACL2 in previous work, SMT methods raise new issues because of\ntheir support for a broader range of domains including real numbers and\nuninterpreted functions. This paper presents Smtlink, our clause processor for\nintegrating SMT solvers into ACL2. We describe key design and implementation\nissues and describe our experience with its use.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:35:21 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Peng", "Yan", "", "University of British Columbia"], ["Greenstreet", "Mark", "", "University of British Columbia"]]}, {"id": "1509.06083", "submitter": "EPTCS", "authors": "David S. Hardin (Rockwell Collins)", "title": "Reasoning About LLVM Code Using Codewalker", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 79-92", "doi": "10.4204/EPTCS.192.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on initial experiments using J Moore's Codewalker to\nreason about programs compiled to the Low-Level Virtual Machine (LLVM)\nintermediate form. Previously, we reported on a translator from LLVM to the\napplicative subset of Common Lisp accepted by the ACL2 theorem prover,\nproducing executable ACL2 formal models, and allowing us to both prove theorems\nabout the translated models as well as validate those models by testing. That\ntranslator provided many of the benefits of a pure decompilation into logic\napproach, but had the disadvantage of not being verified. The availability of\nCodewalker as of ACL2 7.0 has provided an opportunity to revisit this idea, and\nemploy a more trustworthy decompilation into logic tool. Thus, we have employed\nthe Codewalker method to create an interpreter for a subset of the LLVM\ninstruction set, and have used Codewalker to analyze some simple array-based C\nprograms compiled to LLVM form. We discuss advantages and limitations of the\nCodewalker-based method compared to the previous method, and provide some\nchallenge problems for future Codewalker development.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:35:28 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Hardin", "David S.", "", "Rockwell Collins"]]}, {"id": "1509.06084", "submitter": "EPTCS", "authors": "J. Strother Moore (Department of Computer Science, The University of\n  Texas at Austin)", "title": "Stateman: Using Metafunctions to Manage Large Terms Representing Machine\n  States", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 93-109", "doi": "10.4204/EPTCS.192.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When ACL2 is used to model the operational semantics of computing machines,\nmachine states are typically represented by terms recording the contents of the\nstate components. When models are realistic and are stepped through thousands\nof machine cycles, these terms can grow quite large and the cost of simplifying\nthem on each step grows. In this paper we describe an ACL2 book that uses HIDE\nand metafunctions to facilitate the management of large terms representing such\nstates. Because the metafunctions for each state component updater are solely\nresponsible for creating state expressions (i.e., \"writing\") and the\nmetafunctions for each state component accessor are solely responsible for\nextracting values (i.e., \"reading\") from such state expressions, they can\nmaintain their own normal form, use HIDE to prevent other parts of ACL2 from\ninspecting them, and use honsing to uniquely represent state expressions. The\nlast feature makes it possible to memoize the metafunctions, which can improve\nproof performance in some machine models. This paper describes a\ngeneral-purpose ACL2 book modeling a byte-addressed memory supporting \"mixed\"\nreads and writes. By \"mixed\" we mean that reads need not correspond (in address\nor number of bytes) with writes. Verified metafunctions simplify such\n\"read-over-write\" expressions while hiding the potentially large state\nexpression. A key utility is a function that determines an upper bound on the\nvalue of a symbolic arithmetic expression, which plays a role in resolving\nwrites to addresses given by symbolic expressions. We also report on a\npreliminary experiment with the book, which involves the production of states\ncontaining several million function calls.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:35:40 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Moore", "J. Strother", "", "Department of Computer Science, The University of\n  Texas at Austin"]]}, {"id": "1509.06085", "submitter": "EPTCS", "authors": "Mitesh Jain (Northeastern University), Panagiotis Manolios\n  (Northeastern University)", "title": "Proving Skipping Refinement with ACL2s", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526. arXiv admin note: text\n  overlap with arXiv:1502.02942", "journal-ref": "EPTCS 192, 2015, pp. 111-127", "doi": "10.4204/EPTCS.192.9", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe three case studies illustrating the use of ACL2s to prove the\ncorrectness of optimized reactive systems using skipping refinement. Reasoning\nabout reactive systems using refinement involves defining an abstract,\nhigh-level specification system and a concrete, low-level system. Next, one\nshows that the behaviors of the implementation system are allowed by the\nspecification system. Skipping refinement allows us to reason about\nimplementation systems that can \"skip\" specification states due to\noptimizations that allow the implementation system to take several\nspecification steps at once. Skipping refinement also allows implementation\nsystems to, i.e., to take several steps before completing a specification step.\nWe show how ACL2s can be used to prove skipping refinement theorems by modeling\nand proving the correctness of three systems: a JVM-inspired stack machine, a\nsimple memory controller, and a scalar to vector compiler transformation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:35:48 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Jain", "Mitesh", "", "Northeastern University"], ["Manolios", "Panagiotis", "", "Northeastern University"]]}, {"id": "1509.06087", "submitter": "EPTCS", "authors": "Cuong K. Chau (The University of Texas at Austin), Matt Kaufmann (The\n  University of Texas at Austin), Warren A. Hunt Jr. (The University of Texas\n  at Austin)", "title": "Fourier Series Formalization in ACL2(r)", "comments": "In Proceedings ACL2 2015, arXiv:1509.05526", "journal-ref": "EPTCS 192, 2015, pp. 35-51", "doi": "10.4204/EPTCS.192.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize some basic properties of Fourier series in the logic of ACL2(r),\nwhich is a variant of ACL2 that supports reasoning about the real and complex\nnumbers by way of non-standard analysis. More specifically, we extend a\nframework for formally evaluating definite integrals of real-valued, continuous\nfunctions using the Second Fundamental Theorem of Calculus. Our extended\nframework is also applied to functions containing free arguments. Using this\nframework, we are able to prove the orthogonality relationships between\ntrigonometric functions, which are the essential properties in Fourier series\nanalysis. The sum rule for definite integrals of indexed sums is also\nformalized by applying the extended framework along with the First Fundamental\nTheorem of Calculus and the sum rule for differentiation. The Fourier\ncoefficient formulas of periodic functions are then formalized from the\northogonality relations and the sum rule for integration. Consequently, the\nuniqueness of Fourier sums is a straightforward corollary.\n  We also present our formalization of the sum rule for definite integrals of\ninfinite series in ACL2(r). Part of this task is to prove the Dini Uniform\nConvergence Theorem and the continuity of a limit function under certain\nconditions. A key technique in our proofs of these theorems is to apply the\noverspill principle from non-standard analysis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 00:44:27 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Chau", "Cuong K.", "", "The University of Texas at Austin"], ["Kaufmann", "Matt", "", "The\n  University of Texas at Austin"], ["Hunt", "Warren A.", "Jr.", "The University of Texas\n  at Austin"]]}, {"id": "1509.06139", "submitter": "Zbigniew Golebiewski", "authors": "Bernhard Gittenberger and Zbigniew Go{\\l}\\k{e}biewski", "title": "On the number of lambda terms with prescribed size of their De Bruijn\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  John Tromp introduced the so-called 'binary lambda calculus' as a way to\nencode lambda terms in terms of binary words. Later, Grygiel and Lescanne\nconjectured that the number of binary lambda terms with $m$ free indices and of\nsize $n$ (encoded as binary words of length $n$) is $o(n^{-3/2} \\tau^{-n})$ for\n$\\tau \\approx 1.963448\\ldots$. We generalize the proposed notion of size and\nshow that for several classes of lambda terms, including binary lambda terms\nwith $m$ free indices, the number of terms of size $n$ is $\\Theta(n^{-3/2}\n\\rho^{-n})$ with some class dependent constant $\\rho$, which in particular\ndisproves the above mentioned conjecture. A way to obtain lower and upper\nbounds for the constant near the leading term is presented and numerical\nresults for a few previously introduced classes of lambda terms are given.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 08:23:01 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Gittenberger", "Bernhard", ""], ["Go\u0142\u0119biewski", "Zbigniew", ""]]}, {"id": "1509.06207", "submitter": "Tobias Walter", "authors": "Manfred Kufleitner and Tobias Walter", "title": "Level Two of the Quantifier Alternation Hierarchy over Infinite Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of various decision problems for logic fragments has a long history\nin computer science. This paper is on the membership problem for a fragment of\nfirst-order logic over infinite words; the membership problem asks for a given\nlanguage whether it is definable in some fixed fragment. The alphabetic\ntopology was introduced as part of an effective characterization of the\nfragment $\\Sigma_2$ over infinite words. Here, $\\Sigma_2$ consists of the\nfirst-order formulas with two blocks of quantifiers, starting with an\nexistential quantifier. Its Boolean closure is $\\mathbb{B}\\Sigma_2$. Our first\nmain result is an effective characterization of the Boolean closure of the\nalphabetic topology, that is, given an $\\omega$-regular language $L$, it is\ndecidable whether $L$ is a Boolean combination of open sets in the alphabetic\ntopology. This is then used for transferring Place and Zeitoun's recent\ndecidability result for $\\mathbb{B}\\Sigma_2$ from finite to infinite words.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 12:46:16 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Kufleitner", "Manfred", ""], ["Walter", "Tobias", ""]]}, {"id": "1509.06220", "submitter": "Ilya Sergey", "authors": "Ilya Sergey, Aleksandar Nanevski, Anindya Banerjee, German Andres\n  Delbianco", "title": "Hoare-style Specifications as Correctness Conditions for\n  Non-linearizable Concurrent Objects", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing scalable concurrent objects, which can be efficiently used on\nmulticore processors, often requires one to abandon standard specification\ntechniques, such as linearizability, in favor of more relaxed consistency\nrequirements. However, the variety of alternative correctness conditions makes\nit difficult to choose which one to employ in a particular case, and to compose\nthem when using objects whose behaviors are specified via different criteria.\nThe lack of syntactic verification methods for most of these criteria poses\nchallenges in their systematic adoption and application.\n  In this paper, we argue for using Hoare-style program logics as an\nalternative and uniform approach for specification and compositional formal\nverification of safety properties for concurrent objects and their client\nprograms. Through a series of case studies, we demonstrate how an existing\nprogram logic for concurrency can be employed off-the-shelf to capture\nimportant state and history invariants, allowing one to explicitly quantify\nover interference of environment threads and provide intuitive and expressive\nHoare-style specifications for several non-linearizable concurrent objects that\nwere previously specified only via dedicated correctness criteria. We\nillustrate the adequacy of our specifications by verifying a number of\nconcurrent client scenarios, that make use of the previously specified\nconcurrent objects, capturing the essence of such correctness conditions as\nconcurrency-aware linearizability, quiescent, and quantitative quiescent\nconsistency. All examples described in this paper are verified mechanically in\nCoq.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 13:33:33 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 13:23:15 GMT"}, {"version": "v3", "created": "Thu, 21 Jul 2016 12:37:44 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Sergey", "Ilya", ""], ["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""], ["Delbianco", "German Andres", ""]]}, {"id": "1509.06429", "submitter": "Arthur Ramos BSCS", "authors": "Arthur F. Ramos, Ruy J. G. B. de Queiroz, Anjolina de Oliveira", "title": "On Computational Paths and the Fundamental Groupoid of a Type", "comments": "15 pages, submitted to LFCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this work is to study mathematical properties of\ncomputational paths. Originally proposed by de Queiroz \\& Gabbay (1994) as\n`sequences of rewrites', computational paths can be seen as the grounds on\nwhich the propositional equality between two computational objects stand. Using\ncomputational paths and categorical semantics, we take any type $A$ of type\ntheory and construct a groupoid for this type. We call this groupoid the\nfundamental groupoid of a type $A$, since it is similar to the one obtained\nusing the homotopical interpretation of the identity type. The main difference\nis that instead of being just a semantical interpretation, computational paths\nare entities of the syntax of type theory. We also expand our results, using\ncomputational paths to construct fundamental groupoids of higher levels.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 23:46:26 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Ramos", "Arthur F.", ""], ["de Queiroz", "Ruy J. G. B.", ""], ["de Oliveira", "Anjolina", ""]]}, {"id": "1509.06507", "submitter": "Silvano Dal Zilio", "authors": "Silvano Dal Zilio (LAAS-VERTICS), Bernard Berthomieu (LAAS-VERTICS)", "title": "Automating the Verification of Realtime Observers using Probes and the\n  Modal mu-calculus", "comments": "This work was presented at TTCS 2015, the First IFIP International\n  Conference on Topics in Theoretical Computer Science, August 26-28,2015.\n  Institute for Research in Fundamental Sciences (IPM), Tehran, Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical method for model-checking timed properties-such as those\nexpressed using timed extensions of temporal logic-is to rely on the use of\nobservers. In this context, a major problem is to prove the correctness of\nobservers. Essentially, this boils down to proving that: (1) every trace that\ncontradicts a property can be detected by the observer; but also that (2) the\nobserver is innocuous, meaning that it cannot interfere with the system under\nobservation. In this paper, we describe a method for automatically testing the\ncorrectness of realtime observers. This method is obtained by automating an\napproach often referred to as visual verification, in which the correctness of\na system is performed by inspecting a graphical representation of its state\nspace. Our approach has been implemented on the tool Tina, a model-checking\ntoolbox for Time Petri Net.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 08:41:17 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Zilio", "Silvano Dal", "", "LAAS-VERTICS"], ["Berthomieu", "Bernard", "", "LAAS-VERTICS"]]}, {"id": "1509.06837", "submitter": "Xaver Newberry", "authors": "X. Y. Newberry", "title": "Generalization of the Truth-relevant Semantics to the Predicate Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In 1952 P. F. Strawson proposed a logic of presuppositions. It is an\ninterpretation of Aristotelian logic, i.e. of the logic of the traditional\nsyllogism. In 1981 Richard Diaz published a monograph in which he presented\ntruth-relevant logic. This paper shows that truth-relevant logic is but a\npropositional version of the logic of presuppositions. A semantics of the logic\nof presuppositions is developed using truth-relevant logic. The semantics is\nthen further extended to polyadic logic and some consequences discussed.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 03:45:00 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 02:08:51 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 00:29:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Newberry", "X. Y.", ""]]}, {"id": "1509.06858", "submitter": "EPTCS", "authors": "Javier Esparza, Enrico Tronci", "title": "Proceedings Sixth International Symposium on Games, Automata, Logics and\n  Formal Verification", "comments": null, "journal-ref": "EPTCS 193, 2015", "doi": "10.4204/EPTCS.193", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Sixth International Symposium on\nGames, Automata, Logic and Formal Verification (GandALF 2015). The symposium\ntook place in Genoa, Italy, on the 21st and 22nd of September 2015. The\nproceedings of the symposium contain the abstracts of three invited talks and\n13 papers that were accepted after a careful evaluation for presentation at the\nconference. The topics of the accepted papers cover algorithmic game theory,\nautomata theory, formal verification, and modal and temporal logics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 06:43:22 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Esparza", "Javier", ""], ["Tronci", "Enrico", ""]]}, {"id": "1509.07199", "submitter": "EPTCS", "authors": "Philipp Hoffmann (Technische Universit\\\"at M\\\"unchen)", "title": "Negotiation Games", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858. arXiv admin note:\n  substantial text overlap with arXiv:1405.6820", "journal-ref": "EPTCS 193, 2015, pp. 31-42", "doi": "10.4204/EPTCS.193.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negotiations, a model of concurrency with multi party negotiation as\nprimitive, have been recently introduced by J. Desel and J. Esparza. We\ninitiate the study of games for this model. We study coalition problems: can a\ngiven coalition of agents force that a negotiation terminates (resp. block the\nnegotiation so that it goes on forever)?; can the coalition force a given\noutcome of the negotiation? We show that for arbitrary negotiations the\nproblems are EXPTIME-complete. Then we show that for sound and deterministic or\neven weakly deterministic negotiations the problems can be solved in PTIME.\nNotice that the input of the problems is a negotiation, which can be\nexponentially more compact than its state space.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:52:31 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Hoffmann", "Philipp", "", "Technische Universit\u00e4t M\u00fcnchen"]]}, {"id": "1509.07203", "submitter": "EPTCS", "authors": "Parosh Abdulla (Uppsala University), Giorgio Delzanno (University of\n  Genova), Marco Montali (Free University Bolzano)", "title": "Well Structured Transition Systems with History", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 115-128", "doi": "10.4204/EPTCS.193.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal model of concurrent systems in which the history of a\ncomputation is explicitly represented as a collection of events that provide a\nview of a sequence of configurations. In our model events generated by\ntransitions become part of the system configurations leading to operational\nsemantics with historical data. This model allows us to formalize what is\nusually done in symbolic verification algorithms. Indeed, search algorithms\noften use meta-information, e.g., names of fired transitions, selected\nprocesses, etc., to reconstruct (error) traces from symbolic state exploration.\nThe other interesting point of the proposed model is related to a possible new\napplication of the theory of well-structured transition systems (wsts). In our\nsetting wsts theory can be applied to formally extend the class of properties\nthat can be verified using coverability to take into consideration (ordered and\nunordered) historical data. This can be done by using different types of\nrepresentation of collections of events and by combining them with wsts by\nusing closure properties of well-quasi orderings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:53:12 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Abdulla", "Parosh", "", "Uppsala University"], ["Delzanno", "Giorgio", "", "University of\n  Genova"], ["Montali", "Marco", "", "Free University Bolzano"]]}, {"id": "1509.07204", "submitter": "EPTCS", "authors": "Lauri Hella (University of Tampere), Johanna Stumpf (TU Darmstadt)", "title": "The expressive power of modal logic with inclusion atoms", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 129-143", "doi": "10.4204/EPTCS.193.10", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modal inclusion logic is the extension of basic modal logic with inclusion\natoms, and its semantics is defined on Kripke models with teams. A team of a\nKripke model is just a subset of its domain. In this paper we give a complete\ncharacterisation for the expressive power of modal inclusion logic: a class of\nKripke models with teams is definable in modal inclusion logic if and only if\nit is closed under k-bisimulation for some integer k, it is closed under\nunions, and it has the empty team property. We also prove that the same\nexpressive power can be obtained by adding a single unary nonemptiness operator\nto modal logic. Furthermore, we establish an exponential lower bound for the\nsize of the translation from modal inclusion logic to modal logic with the\nnonemptiness operator.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:53:29 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Hella", "Lauri", "", "University of Tampere"], ["Stumpf", "Johanna", "", "TU Darmstadt"]]}, {"id": "1509.07205", "submitter": "EPTCS", "authors": "Patricia Bouyer (LSV - CNRS and ENS Cachan - France), Nicolas Markey\n  (LSV - CNRS and ENS Cachan - France), Mickael Randour (LSV - CNRS and ENS\n  Cachan - France), Kim G. Larsen (Aalborg University - Denmark), Simon Laursen\n  (Aalborg University - Denmark)", "title": "Average-energy games", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 1-15", "doi": "10.4204/EPTCS.193.1", "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player quantitative zero-sum games provide a natural framework to\nsynthesize controllers with performance guarantees for reactive systems within\nan uncontrollable environment. Classical settings include mean-payoff games,\nwhere the objective is to optimize the long-run average gain per action, and\nenergy games, where the system has to avoid running out of energy.\n  We study average-energy games, where the goal is to optimize the long-run\naverage of the accumulated energy. We show that this objective arises naturally\nin several applications, and that it yields interesting connections with\nprevious concepts in the literature. We prove that deciding the winner in such\ngames is in NP inter coNP and at least as hard as solving mean-payoff games,\nand we establish that memoryless strategies suffice to win. We also consider\nthe case where the system has to minimize the average-energy while maintaining\nthe accumulated energy within predefined bounds at all times: this corresponds\nto operating with a finite-capacity storage for energy. We give results for\none-player and two-player games, and establish complexity bounds and memory\nrequirements.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:53:39 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Bouyer", "Patricia", "", "LSV - CNRS and ENS Cachan - France"], ["Markey", "Nicolas", "", "LSV - CNRS and ENS Cachan - France"], ["Randour", "Mickael", "", "LSV - CNRS and ENS\n  Cachan - France"], ["Larsen", "Kim G.", "", "Aalborg University - Denmark"], ["Laursen", "Simon", "", "Aalborg University - Denmark"]]}, {"id": "1509.07206", "submitter": "EPTCS", "authors": "Martin Zimmermann (Saarland University)", "title": "Parameterized Linear Temporal Logics Meet Costs: Still not Costlier than\n  LTL", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 144-157", "doi": "10.4204/EPTCS.193.11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the investigation of parameterized extensions of Linear Temporal\nLogic (LTL) that retain the attractive algorithmic properties of LTL: a\npolynomial space model checking algorithm and a doubly-exponential time\nalgorithm for solving games. Alur et al. and Kupferman et al. showed that this\nis the case for Parametric LTL (PLTL) and PROMPT-LTL respectively, which have\ntemporal operators equipped with variables that bound their scope in time.\nLater, this was also shown to be true for Parametric LDL (PLDL), which extends\nPLTL to be able to express all omega-regular properties.\n  Here, we generalize PLTL to systems with costs, i.e., we do not bound the\nscope of operators in time, but bound the scope in terms of the cost\naccumulated during time. Again, we show that model checking and solving games\nfor specifications in PLTL with costs is not harder than the corresponding\nproblems for LTL. Finally, we discuss PLDL with costs and extensions to\nmultiple cost functions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:53:39 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Zimmermann", "Martin", "", "Saarland University"]]}, {"id": "1509.07207", "submitter": "EPTCS", "authors": "Maciej Gazda, Tim A.C. Willemse", "title": "Improvement in Small Progress Measures", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 158-171", "doi": "10.4204/EPTCS.193.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small Progress Measures is one of the classical parity game solving\nalgorithms. For games with n vertices, m edges and d different priorities, the\noriginal algorithm computes the winning regions and a winning strategy for one\nof the players in O(dm.(n/floor(d/2))^floor(d/2)) time. Computing a winning\nstrategy for the other player requires a re-run of the algorithm on that\nplayer's winning region, thus increasing the runtime complexity to\nO(dm.(n/ceil(d/2))^ceil(d/2)) for computing the winning regions and winning\nstrategies for both players. We modify the algorithm so that it derives the\nwinning strategy for both players in one pass. This reduces the upper bound on\nstrategy derivation for SPM to O(dm.(n/floor(d/2))^floor(d/2)). At the basis of\nour modification is a novel operational interpretation of the least progress\nmeasure that we provide.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:53:52 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Gazda", "Maciej", ""], ["Willemse", "Tim A. C.", ""]]}, {"id": "1509.07208", "submitter": "EPTCS", "authors": "Fran\\c{c}ois Laroussinie (LIAFA, Univ. Paris Diderot and CNRS,\n  France), Nicolas Markey (LSV, ENS Cachan and CNRS, France), Arnaud Sangnier\n  (LIAFA, Univ. Paris Diderot and CNRS, France)", "title": "ATLsc with partial observation", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 43-57", "doi": "10.4204/EPTCS.193.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating-time temporal logic with strategy contexts (ATLsc) is a powerful\nformalism for expressing properties of multi-agent systems: it extends CTL with\nstrategy quantifiers, offering a convenient way of expressing both\ncollaboration and antagonism between several agents. Incomplete observation of\nthe state space is a desirable feature in such a framework, but it quickly\nleads to undecidable verification problems. In this paper, we prove that\nuniform incomplete observation (where all players have the same observation)\npreserves decidability of the model-checking problem, even for very expressive\nlogics such as ATLsc.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 01:53:57 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Laroussinie", "Fran\u00e7ois", "", "LIAFA, Univ. Paris Diderot and CNRS,\n  France"], ["Markey", "Nicolas", "", "LSV, ENS Cachan and CNRS, France"], ["Sangnier", "Arnaud", "", "LIAFA, Univ. Paris Diderot and CNRS, France"]]}, {"id": "1509.07209", "submitter": "EPTCS", "authors": "Ryoma Sin'ya (Tokyo Institute of Technology)", "title": "An Automata Theoretic Approach to the Zero-One Law for Regular\n  Languages: Algorithmic and Logical Aspects", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 172-185", "doi": "10.4204/EPTCS.193.13", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A zero-one language L is a regular language whose asymptotic probability\nconverges to either zero or one. In this case, we say that L obeys the zero-one\nlaw. We prove that a regular language obeys the zero-one law if and only if its\nsyntactic monoid has a zero element, by means of Eilenberg's variety theoretic\napproach. Our proof gives an effective automata characterisation of the\nzero-one law for regular languages, and it leads to a linear time algorithm for\ntesting whether a given regular language is zero-one. In addition, we discuss\nthe logical aspects of the zero-one law for regular languages.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 02:05:55 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Sin'ya", "Ryoma", "", "Tokyo Institute of Technology"]]}, {"id": "1509.07596", "submitter": "Noam Zeilberger", "authors": "Noam Zeilberger", "title": "Counting isomorphism classes of $\\beta$-normal linear lambda terms", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unanticipated connections between different fragments of lambda calculus and\ndifferent families of embedded graphs (a.k.a. \"maps\") motivate the problem of\nenumerating $\\beta$-normal linear lambda terms. In this brief note, it is shown\n(by appeal to a theorem of Arqu\\`es and Beraud) that the sequence counting\nisomorphism classes of $\\beta$-normal linear lambda terms up to free exchange\nof adjacent lambda abstractions coincides with the sequence counting\nisomorphism classes of rooted maps on oriented surfaces (A000698).\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 06:23:04 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Zeilberger", "Noam", ""]]}, {"id": "1509.08003", "submitter": "Timothy Armstrong", "authors": "Timothy J. Armstrong", "title": "Avoiding Contradictions in the Paradoxes, the Halting Problem, and\n  Diagonalization", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fundamental proposal in this article is that logical formulas of the form\n(f <-> ~f) are not contradictions, and that formulas of the form (t <-> t) are\nnot tautologies. Such formulas, wherever they appear in mathematics, are\ninstead reason to conclude that f and t have a third truth value, different\nfrom true and false. These formulas are circular definitions of f and t. We can\ninterpret the implication formula (f <-> ~f) as a rule, a procedure, to find\nthe truth value of f on the left side: we just need to find the truth value of\nf on the right side. When we use the rules to ask if f and t are true or false,\nwe need to keep asking if they are true or false over and over, forever.\n  Russell's paradox and the liar paradox have the form (f <-> ~f). The truth\nvalue provides a straightforward means of avoiding contradictions in these\nproblems. One broad consequence is that the technique of proof by contradiction\ninvolving formulas of the form (f <-> ~f) becomes invalid. One such proof by\ncontradiction is one form of proof that the halting problem is uncomputable.\nThe truth value also appears in Cantor's diagonal argument, Berry's paradox,\nand the Grelling-Nelson paradox.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2015 16:16:12 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2015 09:45:22 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Armstrong", "Timothy J.", ""]]}, {"id": "1509.08169", "submitter": "EPTCS", "authors": "Nathalie Bertrand (Inria Rennes, France), Mirco Tribastone (IMT -\n  Institute for Advanced Studies Lucca, Italy)", "title": "Proceedings Thirteenth Workshop on Quantitative Aspects of Programming\n  Languages and Systems", "comments": null, "journal-ref": "EPTCS 194, 2015", "doi": "10.4204/EPTCS.194", "report-no": null, "categories": "cs.LO cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Thirteenth Workshop on\nQuantitative Aspects of Programming Languages and Systems (QAPL 2015), held in\nLondon, UK, on 11 and 12 April, 2015. QAPL 2015 was a satellite event of the\nEuropean Joint Conferences on Theory and Practice of Software (ETAPS) focussing\non quantitative aspects of computation. The Program Committee of QAPL 2015\nselected 8 regular papers and 2 presentation-only papers. The workshop\nprogramme included two QAPL keynote presentations by Catuscia Palamidessi\n(Inria/LIX, France) on \"Quantitative Aspects of Privacy and Information Flow,\"\nand Holger Hermanns (Saarland University, Germany) on \"Optimal Continuous Time\nMarkov Decisions.\"\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 01:23:36 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Bertrand", "Nathalie", "", "Inria Rennes, France"], ["Tribastone", "Mirco", "", "IMT -\n  Institute for Advanced Studies Lucca, Italy"]]}, {"id": "1509.08315", "submitter": "Lars Jaffke", "authors": "Lars Jaffke and Hans L. Bodlaender", "title": "Definability Equals Recognizability for $k$-Outerplanar Graphs", "comments": "40 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most famous algorithmic meta-theorems states that every graph\nproperty that can be defined by a sentence in counting monadic second order\nlogic (CMSOL) can be checked in linear time for graphs of bounded treewidth,\nwhich is known as Courcelle's Theorem. These algorithms are constructed as\nfinite state tree automata, and hence every CMSOL-definable graph property is\nrecognizable. Courcelle also conjectured that the converse holds, i.e. every\nrecognizable graph property is definable in CMSOL for graphs of bounded\ntreewidth. We prove this conjecture for $k$-outerplanar graphs, which are known\nto have treewidth at most $3k-1$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 13:42:34 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Jaffke", "Lars", ""], ["Bodlaender", "Hans L.", ""]]}, {"id": "1509.08559", "submitter": "EPTCS", "authors": "Alessandro Aldini (University of Urbino), Marco Bernardo (University\n  of Urbino)", "title": "Expected-Delay-Summing Weak Bisimilarity for Markov Automata", "comments": "In Proceedings QAPL 2015, arXiv:1509.08169", "journal-ref": "EPTCS 194, 2015, pp. 1-15", "doi": "10.4204/EPTCS.194.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new weak bisimulation semantics is defined for Markov automata that, in\naddition to abstracting from internal actions, sums up the expected values of\nconsecutive exponentially distributed delays possibly intertwined with internal\nactions. The resulting equivalence is shown to be a congruence with respect to\nparallel composition for Markov automata. Moreover, it turns out to be\ncomparable with weak bisimilarity for timed labeled transition systems, thus\nconstituting a step towards reconciling the semantics for stochastic time and\ndeterministic time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 02:10:09 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Aldini", "Alessandro", "", "University of Urbino"], ["Bernardo", "Marco", "", "University\n  of Urbino"]]}, {"id": "1509.08561", "submitter": "EPTCS", "authors": "Luca Bortolussi (University of Trieste), Jane Hillston (University of\n  Edinburgh)", "title": "Efficient Checking of Individual Rewards Properties in Markov Population\n  Models", "comments": "In Proceedings QAPL 2015, arXiv:1509.08169", "journal-ref": "EPTCS 194, 2015, pp. 32-47", "doi": "10.4204/EPTCS.194.3", "report-no": null, "categories": "cs.LO cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years fluid approaches to the analysis of Markov populations models\nhave been demonstrated to have great pragmatic value. Initially developed to\nestimate the behaviour of the system in terms of the expected values of\npopulation counts, the fluid approach has subsequently been extended to more\nsophisticated interrogations of models through its embedding within model\nchecking procedures. In this paper we extend recent work on checking CSL\nproperties of individual agents within a Markovian population model, to\nconsider the checking of properties which incorporate rewards.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 02:10:30 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Bortolussi", "Luca", "", "University of Trieste"], ["Hillston", "Jane", "", "University of\n  Edinburgh"]]}, {"id": "1509.08563", "submitter": "EPTCS", "authors": "Diego Latella (CNR/ISTI, Pisa), Mieke Massink (CNR/ISTI, Pisa), Erik\n  de Vink (TU/e, Eindhoven)", "title": "A Definition Scheme for Quantitative Bisimulation", "comments": "In Proceedings QAPL 2015, arXiv:1509.08169", "journal-ref": "EPTCS 194, 2015, pp. 63-78", "doi": "10.4204/EPTCS.194.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FuTS, state-to-function transition systems are generalizations of labeled\ntransition systems and of familiar notions of quantitative semantical models as\ncontinuous-time Markov chains, interactive Markov chains, and Markov automata.\nA general scheme for the definition of a notion of strong bisimulation\nassociated with a FuTS is proposed. It is shown that this notion of\nbisimulation for a FuTS coincides with the coalgebraic notion of behavioral\nequivalence associated to the functor on Set given by the type of the FuTS. For\na series of concrete quantitative semantical models the notion of bisimulation\nas reported in the literature is proven to coincide with the notion of\nquantitative bisimulation obtained from the scheme. The comparison includes\nmodels with orthogonal behaviour, like interactive Markov chains, and with\nmultiple levels of behavior, like Markov automata. As a consequence of the\ngeneral result relating FuTS bisimulation and behavioral equivalence we obtain,\nin a systematic way, a coalgebraic underpinning of all quantitative\nbisimulations discussed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 02:10:46 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Latella", "Diego", "", "CNR/ISTI, Pisa"], ["Massink", "Mieke", "", "CNR/ISTI, Pisa"], ["de Vink", "Erik", "", "TU/e, Eindhoven"]]}, {"id": "1509.08564", "submitter": "EPTCS", "authors": "Matias D. Lee (FaMAF, UNC-CONICET, Cordoba), Erik P. de Vink (TU/e,\n  Eindhoven)", "title": "Rooted branching bisimulation as a congruence for probabilistic\n  transition systems", "comments": "In Proceedings QAPL 2015, arXiv:1509.08169. arXiv admin note: text\n  overlap with arXiv:1508.06710", "journal-ref": "EPTCS 194, 2015, pp. 79-94", "doi": "10.4204/EPTCS.194.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic transition system specification format, referred\nto as probabilistic RBB safe, for which rooted branching bisimulation is a\ncongruence. The congruence theorem is based on the approach of Fokkink for the\nqualitative case. For this to work, the theory of transition system\nspecifications in the setting of labeled transition systems needs to be\nextended to deal with probability distributions, both syntactically and\nsemantically. We provide a scheduler-free characterization of probabilistic\nbranching bisimulation as adapted from work of Andova et al. for the\nalternating model. Counter examples are given to justify the various conditions\nrequired by the format.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 02:10:58 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Lee", "Matias D.", "", "FaMAF, UNC-CONICET, Cordoba"], ["de Vink", "Erik P.", "", "TU/e,\n  Eindhoven"]]}, {"id": "1509.08565", "submitter": "EPTCS", "authors": "Fabio Martinelli (IIT-CNR), Ilaria Matteucci (IIT-CNR), Francesco\n  Santini (IIT-CNR)", "title": "Semiring-based Specification Approaches for Quantitative Security", "comments": "In Proceedings QAPL 2015, arXiv:1509.08169", "journal-ref": "EPTCS 194, 2015, pp. 95-109", "doi": "10.4204/EPTCS.194.7", "report-no": null, "categories": "cs.LO cs.CR cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to provide different semiring-based formal tools for the\nspecification of security requirements: we quantitatively enhance the\nopen-system approach, according to which a system is partially specified.\nTherefore, we suppose the existence of an unknown and possibly malicious agent\nthat interacts in parallel with the system. Two specification frameworks are\ndesigned along two different (but still related) lines. First, by comparing the\nbehaviour of a system with the expected one, or by checking if such system\nsatisfies some security requirements: we investigate a novel approximate\nbehavioural-equivalence for comparing processes behaviour, thus extending the\nGeneralised Non Deducibility on Composition (GNDC) approach with scores. As a\nsecond result, we equip a modal logic with semiring values with the purpose to\nhave a weight related to the satisfaction of a formula that specifies some\nrequested property. Finally, we generalise the classical partial model-checking\nfunction, and we name it as quantitative partial model-checking in such a way\nto point out the necessary and sufficient conditions that a system has to\nsatisfy in order to be considered as secure, with respect to a fixed\nsecurity/functionality threshold-value.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 02:11:07 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Martinelli", "Fabio", "", "IIT-CNR"], ["Matteucci", "Ilaria", "", "IIT-CNR"], ["Santini", "Francesco", "", "IIT-CNR"]]}, {"id": "1509.08605", "submitter": "Bj\\\"orn Engelmann", "authors": "Bj\\\"orn Engelmann and Ernst-R\\\"udiger Olderog", "title": "A Sound and Complete Hoare Logic for Dynamically-Typed, Object-Oriented\n  Programs -- Extended Version --", "comments": "Extended Version -- contains all proofs, proof rules and additional\n  information; new version -- elaborated explanations in section 7, added\n  reference, minor visual improvements; new version -- incorporated reviews &\n  improved formalizations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple dynamically-typed, (purely) object-oriented language is defined. A\nstructural operational semantics as well as a Hoare-style program logic for\nreasoning about programs in the language in multiple notions of correctness are\ngiven. The Hoare logic is proved to be both sound and (relative) complete and\nis -- to the best of our knowledge -- the first such logic presented for a\ndynamically-typed language.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 06:38:40 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2015 22:10:59 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 23:06:08 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Engelmann", "Bj\u00f6rn", ""], ["Olderog", "Ernst-R\u00fcdiger", ""]]}, {"id": "1509.08717", "submitter": "Nourh\\`ene Alaya", "authors": "Nourh\\`ene Alaya and Sadok Ben Yahia and Myriam Lamolle", "title": "Towards Unveiling the Ontology Key Features Altering Reasoner\n  Performances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning with ontologies is one of the core fields of research in\nDescription Logics. A variety of efficient reasoner with highly optimized\nalgorithms have been developed to allow inference tasks on expressive ontology\nlanguages such as OWL(DL). However, reasoner reported computing times have\nexceeded and sometimes fall behind the expected theoretical values. From an\nempirical perspective, it is not yet well understood, which particular aspects\nin the ontology are reasoner performance degrading factors. In this paper, we\nconducted an investigation about state of art works that attempted to portray\npotential correlation between reasoner empirical behaviour and particular\nontological features. These works were analysed and then broken down into\ncategories. Further, we proposed a set of ontology features covering a broad\nrange of structural and syntactic ontology characteristics. We claim that these\nfeatures are good indicators of the ontology hardness level against reasoning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 12:31:03 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Alaya", "Nourh\u00e8ne", ""], ["Yahia", "Sadok Ben", ""], ["Lamolle", "Myriam", ""]]}, {"id": "1509.08761", "submitter": "Rafael Pe\\~naloza", "authors": "Stefan Borgwardt and Rafael Pe\\~naloza", "title": "Reasoning in Infinitely Valued G-IALCQ", "comments": "Workshop on Weighted Logics for Artificial Intelligence, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy Description Logics (FDLs) are logic-based formalisms used to represent\nand reason with vague or imprecise knowledge. It has been recently shown that\nreasoning in most FDLs using truth values from the interval [0,1] becomes\nundecidable in the presence of a negation constructor and general concept\ninclusion axioms. One exception to this negative result are FDLs whose\nsemantics is based on the infinitely valued G\\\"odel t-norm (G). In this paper,\nwe extend previous decidability results for G-IALC to deal also with qualified\nnumber restrictions. Our novel approach is based on a combination of the known\ncrispification technique for finitely valued FDLs and the automata-based\nprocedure originally developed for reasoning in G-IALC. The proposed approach\ncombines the advantages of these two methods, while removing their respective\ndrawbacks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 14:18:09 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Borgwardt", "Stefan", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1509.08979", "submitter": "Diego Calvanese", "authors": "Diego Calvanese, Giuseppe De Giacomo, Maurizio Lenzerini, Moshe Y.\n  Vardi", "title": "Fixpoint Node Selection Query Languages for Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of node selection query languages for (finite) trees has been a\nmajor topic in the recent research on query languages for Web documents. On one\nhand, there has been an extensive study of XPath and its various extensions. On\nthe other hand, query languages based on classical logics, such as first-order\nlogic (FO) or Monadic Second-Order Logic (MSO), have been considered. Results\nin this area typically relate an XPath-based language to a classical logic.\nWhat has yet to emerge is an XPath-related language that is as expressive as\nMSO, and at the same time enjoys the computational properties of XPath, which\nare linear time query evaluation and exponential time query-containment test.\nIn this paper we propose muXPath, which is the alternation-free fragment of\nXPath extended with fixpoint operators. Using two-way alternating automata, we\nshow that this language does combine desired expressiveness and computational\nproperties, placing it as an attractive candidate for the definite\nnode-selection query language for trees.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 00:12:55 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 17:48:36 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 05:31:19 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Calvanese", "Diego", ""], ["De Giacomo", "Giuseppe", ""], ["Lenzerini", "Maurizio", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1509.09092", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG), Laure Gonnord (LIP)", "title": "An encoding of array verification problems into array-free Horn clauses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically verifying safety properties of programs is hard, and it is even\nharder if the program acts upon arrays or other forms of maps. Many approaches\nexist for verifying programs operating upon Boolean and integer values (e.g.\nabstract interpretation, counterexample-guided abstraction refinement using\ninterpolants), but transposing them to array properties has been fraught with\ndifficulties.In contrast to most preceding approaches, we do not introduce a\nnew abstract domain or a new interpolation procedure for arrays. Instead, we\ngenerate an abstraction as a scalar problem and feed it to a preexisting\nsolver, with tunable precision.Our transformed problem is expressed using Horn\nclauses, a common format with clear and unambiguous logical semantics for\nverification problems. An important characteristic of our encoding is that it\ncreates a nonlinear Horn problem, with tree unfoldings, even though following\n\"flatly\" the control-graph structure ordinarily yields a linear Horn problem,\nwith linear unfoldings. That is, our encoding cannot be expressed by an\nencoding into another control-flow graph problem, and truly leverages the\ncapacity of the Horn clause format.We illustrate our approach with a completely\nautomated proof of the functional correctness of selection sort.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 09:29:09 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"], ["Gonnord", "Laure", "", "LIP"]]}]