[{"id": "1606.00175", "submitter": "Philipp Hoffmann", "authors": "Javier Esparza, Philipp Hoffmann, Ratul Saha", "title": "Polynomial Analysis Algorithms for Free Choice Probabilistic Workflow\n  Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Probabilistic Workflow Nets (PWNs), a model extending van der\nAalst's workflow nets with probabilities. We give a semantics for PWNs in terms\nof Markov Decision Processes and introduce a reward model. Using a result by\nVaracca and Nielsen, we show that the expected reward of a complete execution\nof the PWN is independent of the scheduler. Extending previous work on\nreduction of non-probabilistic workflow nets, we present reduction rules that\npreserve the expected reward. The rules lead to a polynomial-time algorithm in\nthe size of the PWN (not of the Markov decision process) for the computation of\nthe expected reward. In contrast, since the Markov decision process of PWN can\nbe exponentially larger than the PWN itself, all algorithms based on\nconstructing the Markov decision process require exponential time. We report on\na sample implementation and its performance on a collection of benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 08:48:43 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Esparza", "Javier", ""], ["Hoffmann", "Philipp", ""], ["Saha", "Ratul", ""]]}, {"id": "1606.00280", "submitter": "Luc Pellissier", "authors": "Giulio Guerrieri (I2M), Luc Pellissier (LIPN), Lorenzo Tortora de\n  Falco", "title": "Relational type-checking for MELL proof-structures. Part 1:\n  Multiplicatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational semantics for linear logic is a form of non-idempotent\nintersection type system, from which several informations on the execution of a\nproof-structure can be recovered. An element of the relational interpretation\nof a proof-structure R with conclusion $\\Gamma$ acts thus as a type (refining\n$\\Gamma$) having R as an inhabitant. We are interested in the following\ntype-checking question: given a proof-structure R, a list of formulae $\\Gamma$,\nand a point x in the relational interpretation of $\\Gamma$, is x in the\ninterpretation of R? This question is decidable. We present here an algorithm\nthat decides it in time linear in the size of R, if R is a proof-structure in\nthe multiplicative fragment of linear logic. This algorithm can be extended to\nlarger fragments of multiplicative-exponential linear logic containing\n$\\lambda$-calculus.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 13:31:34 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Guerrieri", "Giulio", "", "I2M"], ["Pellissier", "Luc", "", "LIPN"], ["de Falco", "Lorenzo Tortora", ""]]}, {"id": "1606.00502", "submitter": "EPTCS", "authors": "Nafi Diallo (NJIT, Newark NJ), Wided Ghardallou (FST, Tunis, Tunisia),\n  Ali Mili (NJIT, Newark NJ)", "title": "Program Repair by Stepwise Correctness Enhancement", "comments": "In Proceedings PrePost 2016, arXiv:1605.08096", "journal-ref": "EPTCS 208, 2016, pp. 1-15", "doi": "10.4204/EPTCS.208.1", "report-no": null, "categories": "cs.SE cs.DM cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative correctness is the property of a program to be more-correct than\nanother with respect to a given specification. Whereas the traditional\ndefinition of (absolute) correctness divides candidate program into two classes\n(correct, and incorrect), relative correctness arranges candidate programs on\nthe richer structure of a partial ordering. In other venues we discuss the\nimpact of relative correctness on program derivation, and on program\nverification. In this paper, we discuss the impact of relative correctness on\nprogram testing; specifically, we argue that when we remove a fault from a\nprogram, we ought to test the new program for relative correctness over the old\nprogram, rather than for absolute correctness. We present analytical arguments\nto support our position, as well as an empirical argument in the form of a\nsmall program whose faults are removed in a stepwise manner as its relative\ncorrectness rises with each fault removal until we obtain a correct program.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 23:59:02 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Diallo", "Nafi", "", "NJIT, Newark NJ"], ["Ghardallou", "Wided", "", "FST, Tunis, Tunisia"], ["Mili", "Ali", "", "NJIT, Newark NJ"]]}, {"id": "1606.00505", "submitter": "EPTCS", "authors": "Oleg Sokolsky, Teng Zhang, Insup Lee, Michael McDougall", "title": "Monitoring Assumptions in Assume-Guarantee Contracts", "comments": "In Proceedings PrePost 2016, arXiv:1605.08096", "journal-ref": "EPTCS 208, 2016, pp. 46-53", "doi": "10.4204/EPTCS.208.4", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-deployment verification of software components with respect to behavioral\nspecifications in the assume-guarantee form does not, in general, guarantee\nabsence of errors at run time. This is because assumptions about the\nenvironment cannot be discharged until the environment is fixed. An intuitive\napproach is to complement pre-deployment verification of guarantees, up to the\nassumptions, with post-deployment monitoring of environment behavior to check\nthat the assumptions are satisfied at run time. Such a monitor is typically\nimplemented by instrumenting the application code of the component. An\nadditional challenge for the monitoring step is that environment behaviors are\ntypically obtained through an I/O library, which may alter the component's view\nof the input format. This transformation requires us to introduce a second\npre-deployment verification step to ensure that alarms raised by the monitor\nwould indeed correspond to violations of the environment assumptions. In this\npaper, we describe an approach for constructing monitors and verifying them\nagainst the component assumption. We also discuss limitations of\ninstrumentation-based monitoring and potential ways to overcome it.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 23:59:31 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Sokolsky", "Oleg", ""], ["Zhang", "Teng", ""], ["Lee", "Insup", ""], ["McDougall", "Michael", ""]]}, {"id": "1606.00506", "submitter": "EPTCS", "authors": "Annalizz Vella (University of Malta), Adrian Francalanza (University\n  of Malta)", "title": "Preliminary Results Towards Contract Monitorability", "comments": "In Proceedings PrePost 2016, arXiv:1605.08096", "journal-ref": "EPTCS 208, 2016, pp. 54-63", "doi": "10.4204/EPTCS.208.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses preliminary investigations on the monitorability of\ncontracts for web service descriptions. There are settings where servers do not\nguarantee statically whether they satisfy some specified contract, which forces\nthe client (i.e., the entity interacting with the server) to perform dynamic\nchecks. This scenario may be viewed as an instance of Runtime Verification,\nwhere a pertinent question is whether contracts can be monitored for adequately\nat runtime, otherwise stated as the monitorability of contracts. We consider a\nsimple language of finitary contracts describing both clients and servers, and\ndevelop a formal framework that describes server contract monitoring. We define\nmonitor properties that potentially contribute towards a comprehensive notion\nof contract monitorability and show that our simple contract language satisfies\nthese properties.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 23:59:40 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Vella", "Annalizz", "", "University of Malta"], ["Francalanza", "Adrian", "", "University\n  of Malta"]]}, {"id": "1606.01014", "submitter": "Jianhua Gao", "authors": "Jianhua Gao, Ying Jiang", "title": "Model Checking : A Co-algebraic Approach", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State explosion problem is the main obstacle of model checking. In this\npaper, we try to solve this problem from a coalgebraic approach. We establish\nan effective method to prove uniformly the existence of the smallest Kripke\nstructure with respect to bisimilarity, which describes all behaviors of the\nKripke structures and no redundancy. We show then this smallest Kripke\nstructure generates a concrete smallest one for each given finite Kripke\nstructure and some kind of infinite ones. This method is based on the existence\nof the final coalgebra of a suitable endofunctor and can be generalized\nsmoothly to other coalgebraic structures. A naive implementation of this method\nis developed in Ocaml.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 09:24:42 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Gao", "Jianhua", ""], ["Jiang", "Ying", ""]]}, {"id": "1606.01148", "submitter": "Nachum Dershowitz", "authors": "Nachum Dershowitz", "title": "Tripartite Unions", "comments": null, "journal-ref": "IJCAR, Oxford, Springer, Lecture Notes in Computer Science, vol.\n  10900, pp. 117-133 (2018)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides conditions under which the union of three well-founded\nbinary relations is also well-founded.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 15:41:55 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dershowitz", "Nachum", ""]]}, {"id": "1606.01172", "submitter": "Alexander Ushakov", "authors": "Alexei Miasnikov, Alexander Ushakov", "title": "Generic case completeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we introduce a notion of a generically (strongly generically)\nNP-complete problem and show that the randomized bounded version of the halting\nproblem is strongly generically NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 19:56:51 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Miasnikov", "Alexei", ""], ["Ushakov", "Alexander", ""]]}, {"id": "1606.01206", "submitter": "Pablo Barcelo", "authors": "Pablo Barcelo and Miguel Romero", "title": "The complexity of reverse engineering problems for conjunctive queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse engineering problems for conjunctive queries (CQs), such as query by\nexample (QBE) or definability, take a set of user examples and convert them\ninto an explanatory CQ. Despite their importance, the complexity of these\nproblems is prohibitively high (coNEXPTIME-complete). We isolate their two main\nsources of complexity and propose relaxations of them that reduce the\ncomplexity while having meaningful theoretical interpretations. The first\nrelaxation is based on the idea of using existential pebble games for\napproximating homomorphism tests. We show that this characterizes\nQBE/definability for CQs up to treewidth $k$, while reducing the complexity to\nEXPTIME. As a side result, we obtain that the complexity of the\nQBE/definability problems for CQs of treewidth $k$ is EXPTIME-complete for each\n$k \\geq 1$. The second relaxation is based on the idea of \"desynchronizing\"\ndirect products, which characterizes QBE/definability for unions of CQs and\nreduces the complexity to coNP. The combination of these two relaxations yields\ntractability for QBE and characterizes it in terms of unions of CQs of\ntreewidth at most $k$. We also study the complexity of these problems for\nconjunctive regular path queries over graph databases, showing them to be no\nmore difficult than for CQs.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 18:14:35 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 19:28:17 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Barcelo", "Pablo", ""], ["Romero", "Miguel", ""]]}, {"id": "1606.01344", "submitter": "EPTCS", "authors": "John Derrick, Eerke Boiten, Steve Reeves", "title": "Proceedings 17th International Workshop on Refinement", "comments": null, "journal-ref": "EPTCS 209, 2016", "doi": "10.4204/EPTCS.209", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are proud to present the papers from the 17th Refinement Workshop,\nco-located with FM 2015 held in Oslo, Norway on June 22nd, 2015.\n  Refinement is one of the cornerstones of a formal approach to software\nengineering: the process of developing a more detailed design or implementation\nfrom an abstract specification through a sequence of mathematically-based steps\nthat maintain correctness with respect to the original specification.\n  This 17th workshop continued a 20+ year tradition under the auspices of the\nBritish Computer Society (BCS) FACS special interest group.\n  This is the third volume that has appeared as an EPTCS proceedings, and we\nwould like to thank the editorial board (and in particular Rob van Glabbeek)\nfor their help and cooperation in making this happen.\n  The organisers would like to thank everyone: the authors, BCS-FACS, EPTCS,\nand the organisers of FM 2015 for their help in organising this workshop, the\nparticipants of the workshop, and the reviewers involved in selecting the\npapers.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 08:32:00 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Derrick", "John", ""], ["Boiten", "Eerke", ""], ["Reeves", "Steve", ""]]}, {"id": "1606.01387", "submitter": "Saksham Chand", "authors": "Saksham Chand, Yanhong A. Liu, Scott D. Stoller", "title": "Formal Verification of Multi-Paxos for Distributed Consensus", "comments": null, "journal-ref": "FM 2016: Proceedings of the 21st International Symposium on Formal\n  Methods. LNCS 9995. Pages 119-136. Springer,", "doi": "10.1007/978-3-319-48989-6_8", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paxos is an important algorithm for a set of distributed processes to agree\non a single value or a sequence of values, for which it is called Basic Paxos\nor Multi-Paxos, respectively. Consensus is critical when distributed services\nare replicated for fault-tolerance, because non-faulty replicas must agree on\nthe state of the system or the sequence of operations that have been performed.\nUnfortunately, consensus algorithms including Multi-Paxos in particular are\nwell-known to be difficult to understand, and their accurate specifications and\ncorrectness proofs remain challenging, despite extensive studies ever since\nLamport introduced Paxos.\n  This article describes formal specification and verification of Lamport's\nMulti-Paxos algorithm for distributed consensus. The specification is written\nin TLA+, Lamport's Temporal Logic of Actions. The proof is written and\nautomatically checked using TLAPS, the TLA+ Proof System. The proof is for the\nsafety property of the algorithm. Building on Lamport, Merz, and Doligez's\nspecification and proof for Basic Paxos, we aim to facilitate the understanding\nof Multi-Paxos and its proof by minimizing the difference from those for Basic\nPaxos, and to demonstrate a general way of proving other variants of Paxos and\nother sophisticated distributed algorithms. We also discuss our general\nstrategies and results for proving complex invariants using invariance lemmas\nand increments, for proving properties about sets and tuples to help the proof\ncheck succeed in significantly reduced time, and for overall proof improvement\nleading to considerably reduced proof size.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 15:48:20 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 02:25:41 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 19:08:49 GMT"}, {"version": "v4", "created": "Mon, 11 Nov 2019 13:28:19 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Chand", "Saksham", ""], ["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1606.01451", "submitter": "Anthony Widjaja Lin", "authors": "Anthony W. Lin, Philipp Ruemmer", "title": "Liveness of Randomised Parameterised Systems under Arbitrary Schedulers\n  (Technical Report)", "comments": "Full version of CAV'16 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of verifying liveness for systems with a finite, but\nunbounded, number of processes, commonly known as parameterised systems.\nTypical examples of such systems include distributed protocols (e.g. for the\ndining philosopher problem). Unlike the case of verifying safety, proving\nliveness is still considered extremely challenging, especially in the presence\nof randomness in the system. In this paper we consider liveness under arbitrary\n(including unfair) schedulers, which is often considered a desirable property\nin the literature of self-stabilising systems. We introduce an automatic method\nof proving liveness for randomised parameterised systems under arbitrary\nschedulers. Viewing liveness as a two-player reachability game (between\nScheduler and Process), our method is a CEGAR approach that synthesises a\nprogress relation for Process that can be symbolically represented as a\nfinite-state automaton. The method is incremental and exploits both\nAngluin-style L*-learning and SAT-solvers. Our experiments show that our\nalgorithm is able to prove liveness automatically for well-known randomised\ndistributed protocols, including Lehmann-Rabin Randomised Dining Philosopher\nProtocol and randomised self-stabilising protocols (such as the Israeli-Jalfon\nProtocol). To the best of our knowledge, this is the first fully-automatic\nmethod that can prove liveness for randomised protocols.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 02:29:19 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Lin", "Anthony W.", ""], ["Ruemmer", "Philipp", ""]]}, {"id": "1606.01642", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (IRIF)", "title": "An introduction to Differential Linear Logic: proof-nets, models and\n  antiderivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Linear Logic enriches Linear Logic with additional logical rules\nfor the exponential connectives, dual to the usual rules of dereliction,\nweakening and contraction. We present a proof-net syntax for Differential\nLinear Logic and a categorical axiomatization of its denotational models. We\nalso introduce a simple categorical condition on these models under which a\ngeneral antiderivative operation becomes available. Last we briefly describe\nthe model of sets and relations and give a more detailed account of the model\nof finiteness spaces and linear and continuous functions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 07:28:39 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"]]}, {"id": "1606.01720", "submitter": "Richard Moot", "authors": "Richard Moot (LaBRI)", "title": "Proof nets for the Displacement calculus", "comments": "Formal Grammar, Aug 2016, Bolzano, Italy. Springer, Proceedings of\n  Formal Grammar 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a proof net calculus for the Displacement calculus and show its\ncorrectness. This is the first proof net calculus which models the Displacement\ncalculus directly and not by some sort of translation into another formalism.\nThe proof net calculus opens up new possibilities for parsing and proof search\nwith the Displacement calculus.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 12:55:57 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Moot", "Richard", "", "LaBRI"]]}, {"id": "1606.01763", "submitter": "Sandro Skansi", "authors": "Sandro Skansi", "title": "A Constructive Proof of Cut Elimination for a System of Full Second\n  Order Logic", "comments": "This paper has been withdrawn by the author due to crucial errors\n  noted by reviewers: no cut-elimination proof for second-order logic can be\n  formalized in second-order arithmetic. The author's arguments are\n  formalizable in a subsystem of Kalmar-elementary arithmetic. So the purported\n  proof seems patently wrong", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a constructive proof of cut elimination for a system\nof full second order logic with the structural rules absorbed and using sets\ninstead of sequences. The standard problem of the cutrank growth is avoided by\nusing a new parameter for the induction, the cutweight. This technique can also\nbe applied to first order logic.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 14:34:24 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 11:29:18 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Skansi", "Sandro", ""]]}, {"id": "1606.01831", "submitter": "EPTCS", "authors": "V\\'eronique Bruy\\`ere, Quentin Hautem, Mickael Randour", "title": "Window Parity Games: An Alternative Approach Toward Parity Games with\n  Time Bounds", "comments": "In Proceedings GandALF 2016, arXiv:1609.03648", "journal-ref": "EPTCS 226, 2016, pp. 135-148", "doi": "10.4204/EPTCS.226.10", "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical objectives in two-player zero-sum games played on graphs often deal\nwith limit behaviors of infinite plays: e.g., mean-payoff and total-payoff in\nthe quantitative setting, or parity in the qualitative one (a canonical way to\nencode omega-regular properties). Those objectives offer powerful abstraction\nmechanisms and often yield nice properties such as memoryless determinacy.\nHowever, their very nature provides no guarantee on time bounds within which\nsomething good can be witnessed. In this work, we consider two approaches\ntoward inclusion of time bounds in parity games. The first one, parity-response\ngames, is based on the notion of finitary parity games [CHH09] and parity games\nwith costs [FZ14,WZ16]. The second one, window parity games, is inspired by\nwindow mean-payoff games [CDRR15]. We compare the two approaches and show that\nwhile they prove to be equivalent in some contexts, window parity games offer a\nmore tractable alternative when the time bound is given as a parameter (P-c.\nvs. PSPACE-c.). In particular, it provides a conservative approximation of\nparity games computable in polynomial time. Furthermore, we extend both\napproaches to the multi-dimension setting. We give the full picture for both\ntypes of games with regard to complexity and memory bounds.\n  [CHH09] K. Chatterjee, T.A. Henzinger, F. Horn (2009): Finitary winning in\nomega-regular games. ACM Trans. Comput. Log. 11(1). [FZ14] N. Fijalkow, M.\nZimmermann (2014): Parity and Streett Games with Costs. LMCS 10(2). [WZ16] A.\nWeinert, M. Zimmermann (2016): Easy to Win, Hard to Master: Optimal Strategies\nin Parity Games with Costs. Proc. of CSL, LIPIcs, Schloss Dagstuhl - LZI. To\nappear. [CDRR15] K. Chatterjee, L. Doyen, M. Randour, J.-F. Raskin (2015):\nLooking at mean-payoff and total-payoff through windows. Information and\nComputation 242, pp. 25-52.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 17:10:22 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 00:58:57 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Bruy\u00e8re", "V\u00e9ronique", ""], ["Hautem", "Quentin", ""], ["Randour", "Mickael", ""]]}, {"id": "1606.01930", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Loreto Bravo", "title": "Consistency and Trust in Peer Data Exchange Systems", "comments": "To appear in Theory and Practice of Logic Programming (TPLP). It\n  includes appendix that will be published only in electronic format", "journal-ref": null, "doi": "10.1017/S147106841600017X", "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate a semantics for \"peer data exchange systems\" where\ndifferent peers are related by data exchange constraints and trust\nrelationships. These two elements plus the data at the peers' sites and their\nlocal integrity constraints are made compatible via a semantics that\ncharacterizes sets of \"solution instances\" for the peers. They are the intended\n-possibly virtual- instances for a peer that are obtained through a data repair\nsemantics that we introduce and investigate. The semantically correct answers\nfrom a peer to a query, the so-called \"peer consistent answers\", are defined as\nthose answers that are invariant under all its different solution instances. We\nshow that solution instances can be specified as the models of logic programs\nwith a stable model semantics. The repair semantics is based on null values as\nused in SQL databases, and is also of independent interest for repairs of\nsingle databases with respect to integrity constraints.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 20:26:42 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Bravo", "Loreto", ""]]}, {"id": "1606.02018", "submitter": "EPTCS", "authors": "Gerard Ekembe Ngondi", "title": "Unifying Theories of Mobile Channels", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 24-39", "doi": "10.4204/EPTCS.209.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the denotational semantics for channel mobility in\nthe Unifying Theories of Programming (UTP) semantics framework. The basis for\nthe model is the UTP theory of reactive processes (precisely, the UTP semantics\nfor Communicating Sequential Processes (CSP)), which is slightly extended to\nallow the mobility of channels: the set of actions in which a process is\nauthorised to participate, originally static or constant (set during the\nprocess's definition), is now made dynamic or variable: it can change during\nthe process's execution. A channel is thus moved around by communicating it via\nother channels and then allowing the receiving process to extend its alphabet\nwith the received channel. New healthiness conditions are stated to ensure an\nappropriate use of mobile channels.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:09:09 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Ngondi", "Gerard Ekembe", ""]]}, {"id": "1606.02019", "submitter": "EPTCS", "authors": "Alexandre Madeira (HASLab INESC TEC and Universidade do Minho), Manuel\n  A. Martins (CIDMA and Dep Matem\\'atica Universidade de Aveiro), Lu\\'is S.\n  Barbosa (HASLab INESC TEC and Universidade do Minho)", "title": "A logic for n-dimensional hierarchical refinement", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 40-56", "doi": "10.4204/EPTCS.209.4", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical transition systems provide a popular mathematical structure to\nrepresent state-based software applications in which different layers of\nabstraction are represented by inter-related state machines. The decomposition\nof high level states into inner sub-states, and of their transitions into inner\nsub-transitions is common refinement procedure adopted in a number of\nspecification formalisms.\n  This paper introduces a hybrid modal logic for k-layered transition systems,\nits first-order standard translation, a notion of bisimulation, and a modal\ninvariance result. Layered and hierarchical notions of refinement are also\ndiscussed in this setting.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:09:19 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Madeira", "Alexandre", "", "HASLab INESC TEC and Universidade do Minho"], ["Martins", "Manuel A.", "", "CIDMA and Dep Matem\u00e1tica Universidade de Aveiro"], ["Barbosa", "Lu\u00eds S.", "", "HASLab INESC TEC and Universidade do Minho"]]}, {"id": "1606.02020", "submitter": "EPTCS", "authors": "Nafi Diallo (NJIT, USA), Wided Ghardallou (FST, Tunisia), Jules\n  Desharnais (Laval University, Canada), Ali Mili (NJIT, USA)", "title": "Program Derivation by Correctness Enhacements", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 57-70", "doi": "10.4204/EPTCS.209.5", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative correctness is the property of a program to be more-correct than\nanother program with respect to a given specification. Among the many\nproperties of relative correctness, that which we found most intriguing is the\nproperty that program P' refines program P if and only if P' is more-correct\nthan P with respect to any specification. This inspires us to reconsider\nprogram derivation by successive refinements: each step of this process\nmandates that we transform a program P into a program P' that refines P, i.e.\nP' is more-correct than P with respect to any specification. This raises the\nquestion: why should we want to make P' more-correct than P with respect to any\nspecification, when we only have to satisfy specification R? In this paper, we\ndiscuss a process of program derivation that replaces traditional sequence of\nrefinement-based correctness-preserving transformations starting from\nspecification R by a sequence of relative correctness-based\ncorrectness-enhancing transformations starting from abort.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:09:28 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Diallo", "Nafi", "", "NJIT, USA"], ["Ghardallou", "Wided", "", "FST, Tunisia"], ["Desharnais", "Jules", "", "Laval University, Canada"], ["Mili", "Ali", "", "NJIT, USA"]]}, {"id": "1606.02021", "submitter": "EPTCS", "authors": "Alvaro Miyazawa (University of York), Ana Cavalcanti (University of\n  York)", "title": "SCJ-Circus: a refinement-oriented formal notation for Safety-Critical\n  Java", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 71-86", "doi": "10.4204/EPTCS.209.6", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety-Critical Java (SCJ) is a version of Java whose goal is to support the\ndevelopment of real-time, embedded, safety-critical software. In particular,\nSCJ supports certification of such software by introducing abstractions that\nenforce a simpler architecture, and simpler concurrency and memory models. In\nthis paper, we present SCJ-Circus, a refinement-oriented formal notation that\nsupports the specification and verification of low-level programming models\nthat include the new abstractions introduced by SCJ. SCJ-Circus is part of the\nfamily of state-rich process algebra Circus, as such, SCJ-Circus includes the\nCircus constructs for modelling sequential and concurrent behaviour, real-time\nand object orientation. We present here the syntax and semantics of SCJ-Circus,\nwhich is defined by mapping SCJ-Circus constructs to those of standard Circus.\nThis is based on an existing approach for modelling SCJ programs. We also\nextend an existing Circus-based refinement strategy that targets SCJ programs\nto account for the generation of SCJ-Circus models close to implementations in\nSCJ.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:09:36 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Miyazawa", "Alvaro", "", "University of York"], ["Cavalcanti", "Ana", "", "University of\n  York"]]}, {"id": "1606.02023", "submitter": "EPTCS", "authors": "Brijesh Dongol (Brunel University London), Lindsay Groves (Victoria\n  University of Wellington)", "title": "Towards linking correctness conditions for concurrent objects and\n  contextual trace refinement", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 107-111", "doi": "10.4204/EPTCS.209.8", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctness conditions for concurrent objects describe how atomicity of an\nabstract sequential object may be decomposed. Many different concurrent objects\nand proof methods for them have been developed. However, arguments about\ncorrectness are conducted with respect to an object in isolation. This is in\ncontrast to real-world practice, where concurrent objects are often implemented\nas part of a programming language library (e.g., java.util.concurrent) and are\ninstantiated within a client program. A natural question to ask, then is: How\ndoes a correctness condition for a concurrent object ensure correctness of a\nclient program that uses the concurrent object? This paper presents the main\nissues that surround this question and provides some answers by linking\ndifferent correctness conditions with a form of trace refinement.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:09:53 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Dongol", "Brijesh", "", "Brunel University London"], ["Groves", "Lindsay", "", "Victoria\n  University of Wellington"]]}, {"id": "1606.02024", "submitter": "EPTCS", "authors": "Mats Neovius ({\\AA}bo Akademi University, Faculty of Science and\n  Engineering), Luigia Petre ({\\AA}bo Akademi University, Faculty of Science\n  and Engineering), Kaisa Sere ({\\AA}bo Akademi University, Faculty of Science\n  and Engineering)", "title": "A Theory of Service Dependency", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 112-128", "doi": "10.4204/EPTCS.209.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service composition has become commonplace nowadays, in large part due to the\nincreased complexity of software and supporting networks. Composition can be of\nmany types, for instance sequential, prioritising, non-deterministic. However,\na fundamental feature of the services to be composed consists in their\ndependencies with respect to each other. In this paper we propose a theory of\nservice dependency, modelled around a dependency operator in the Action Systems\nformalism. We analyze its properties, composition behaviour, and refinement\nconditions with accompanying examples.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:10:01 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Neovius", "Mats", "", "\u00c5bo Akademi University, Faculty of Science and\n  Engineering"], ["Petre", "Luigia", "", "\u00c5bo Akademi University, Faculty of Science\n  and Engineering"], ["Sere", "Kaisa", "", "\u00c5bo Akademi University, Faculty of Science\n  and Engineering"]]}, {"id": "1606.02311", "submitter": "A Achouri A Achouri", "authors": "Amine Achouri and Leila Jemni ben Ayed", "title": "A Formal Semantic for UML 2.0 Activity Diagram based on Institution\n  Theory", "comments": "6 pages, 2 figures, 2013", "journal-ref": "International Journal of Soft Computing and Software Engineering\n  [JSCSE], Vol. 3, No. 3.30, 2013", "doi": "10.7321/jscse.v3.n3.30", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giving a formal semantic to an UML Activity diagram (UML AD) is a hard task.\nThe reason of this difficulty is the ambiguity and the absence of a precise\nformal semantic of such semi-formal formalism. A variety of semantics exist in\nthe literature having tackled the aspects covered by this language. We can give\nas example denotational, functional and compositional semantics. To cope with\nthe recent tendency which gave a heterogeneous semantic to UML diagrams, we aim\nto define an algebraic presentation of the semantic of UML AD. In this work, we\ndefine a formal semantic of UML 2.0 AD based on institution theory. For UML AD\nformalism, which is a graphical language, no precise formal semantic is given\nto it. We use the institution theory to define the intended semantic. Thus, the\nUML AD formalism will be defined in its own natural semantic.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 20:00:37 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Achouri", "Amine", ""], ["Ayed", "Leila Jemni ben", ""]]}, {"id": "1606.02347", "submitter": "Ashish Darbari", "authors": "Ashish Darbari and Iain Singleton", "title": "Industrial Strength Formal Using Abstractions", "comments": "23 pages, 6 figures, minor revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of concurrent systems with thousands of multiple threads and\ntransactions is a challenging problem not just for simulation or emulation but\nalso for formal. To get designs to work correctly and provide optimal PPA the\ndesigners often use complex optimizations requiring sharing of multiple\nresources amongst active threads and transactions using FIFOs, stallers,\npipelining, out-of-order scheduling, and complex layered arbitration. This is\ntrue of most non-trivial designs irrespective of a specific application domain\nsuch as CPU, GPU or communication. At the outset a lot of these application\ndomains look diverse and complex; however at some level of detail all of these\nemploy common design principles of sequencing, load balancing, arbitration and\nhazard prevention. We present in this paper a key abstraction based methodology\nfor verifying ordering correctness and arbitration across a range of designs\nwhich are derived from different application domains. We show how by using\nabstractions and supporting them with invariants one can not only find deep\ncorner case bugs in sequentially very deep designs; we can also build\nexhaustive proofs to prove the absence of critical bugs such as deadlock,\nstarvation, and loss of data integrity. We present experimental results on a\nrange of different designs and show that on some of the designs such as FIFOs\nwe can verify over 100 different types of FIFOs for ordering correctness using\na single assertion in a single testbench. We also show how the methodology of\nFIFO verification can be adapted to verify over half-a-dozen different types of\narbiters including a very complex memory subsystem arbiter. We verify a\nmulti-clocked synchronizer and a packet based design from a networking domain\nusing the same abstraction as used in FIFO verification. The results\ndemonstrate the strength of our methodology which is both reusable and compact.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 22:30:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 18:10:45 GMT"}, {"version": "v3", "created": "Sun, 30 Apr 2017 10:15:02 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Darbari", "Ashish", ""], ["Singleton", "Iain", ""]]}, {"id": "1606.02643", "submitter": "Ale\\v{s} Bizjak", "authors": "Antonia Lechner, Richard Mayr, Jo\\\"el Ouaknine, Amaury Pouly, James\n  Worrell", "title": "Model Checking Flat Freeze LTL on One-Counter Automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (December\n  7, 2018) lmcs:5019", "doi": "10.23638/LMCS-14(4:20)2018", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Freeze LTL is a temporal logic with registers that is suitable for specifying\nproperties of data words. In this paper we study the model checking problem for\nFreeze LTL on one-counter automata. This problem is known to be undecidable in\ngeneral and PSPACE-complete for the special case of deterministic one-counter\nautomata. Several years ago, Demri and Sangnier investigated the model checking\nproblem for the flat fragment of Freeze LTL on several classes of counter\nautomata and posed the decidability of model checking flat Freeze LTL on\none-counter automata as an open problem. In this paper we resolve this problem\npositively, utilising a known reduction to a reachability problem on\none-counter automata with parameterised equality and disequality tests. Our\nmain technical contribution is to show decidability of the latter problem by\ntranslation to Presburger arithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 17:27:41 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 12:20:56 GMT"}, {"version": "v3", "created": "Mon, 30 Jan 2017 16:17:31 GMT"}, {"version": "v4", "created": "Thu, 18 Oct 2018 14:34:19 GMT"}, {"version": "v5", "created": "Thu, 6 Dec 2018 15:11:39 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Lechner", "Antonia", ""], ["Mayr", "Richard", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Pouly", "Amaury", ""], ["Worrell", "James", ""]]}, {"id": "1606.02941", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima and Ramana Kumar", "title": "A Proof Strategy Language and Proof Script Generation for Isabelle/HOL", "comments": "This paper has been submitted to CADE26", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a language, PSL, designed to capture high level proof strategies\nin Isabelle/HOL. Given a strategy and a proof obligation, PSL's runtime system\ngenerates and combines various tactics to explore a large search space with low\nmemory usage. Upon success, PSL generates an efficient proof script, which\nbypasses a large part of the proof search. We also present PSL's monadic\ninterpreter to show that the underlying idea of PSL is transferable to other\nITPs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 13:04:03 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 02:11:09 GMT"}, {"version": "v3", "created": "Wed, 20 Jul 2016 06:42:04 GMT"}, {"version": "v4", "created": "Sat, 6 Aug 2016 06:26:16 GMT"}, {"version": "v5", "created": "Fri, 9 Sep 2016 08:48:35 GMT"}, {"version": "v6", "created": "Mon, 31 Oct 2016 06:42:08 GMT"}, {"version": "v7", "created": "Sun, 13 Nov 2016 07:30:40 GMT"}, {"version": "v8", "created": "Mon, 16 Jan 2017 05:53:14 GMT"}, {"version": "v9", "created": "Thu, 2 Mar 2017 02:56:32 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Nagashima", "Yutaka", ""], ["Kumar", "Ramana", ""]]}, {"id": "1606.03180", "submitter": "Yoshihiko Kakutani", "authors": "Yoshihiko Kakutani", "title": "Calculi for Intuitionistic Normal Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a call-by-name and a call-by-value term calculus, both of\nwhich have a Curry-Howard correspondence to the box fragment of the\nintuitionistic modal logic IK. The strong normalizability and the confluency of\nthe calculi are shown. Moreover, we define a CPS transformation from the\ncall-by-value calculus to the call-by-name calculus, and show its soundness and\ncompleteness.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 05:19:27 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Kakutani", "Yoshihiko", ""]]}, {"id": "1606.03289", "submitter": "Jaroslav Bendik", "authors": "Jaroslav Bendik, Nikola Benes, Ivana Cerna, Jiri Barnat", "title": "Tunable Online MUS/MSS Enumeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various areas of computer science, the problem of dealing with a set of\nconstraints arises. If the set of constraints is unsatisfiable, one may ask for\na minimal description of the reason for this unsatisifi- ability. Minimal\nunsatisifable subsets (MUSes) and maximal satisifiable subsets (MSSes) are two\nkinds of such minimal descriptions. The goal of this work is the enumeration of\nMUSes and MSSes for a given constraint system. As such full enumeration may be\nintractable in general, we focus on building an online algorithm, which\nproduces MUSes/MSSes in an on-the-fly manner as soon as they are discovered.\nThe problem has been studied before even in its online version. However, our\nalgorithm uses a novel approach that is able to outperform current state-of-the\nart algorithms for online MUS/MSS enumeration. Moreover, the performance of our\nalgorithm can be adjusted using tunable parameters. We evaluate the algorithm\non a set of benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 12:24:35 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Bendik", "Jaroslav", ""], ["Benes", "Nikola", ""], ["Cerna", "Ivana", ""], ["Barnat", "Jiri", ""]]}, {"id": "1606.03598", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Thomas A. Henzinger and Jan Otop", "title": "Nested Weighted Limit-Average Automata of Bounded Width", "comments": "A conference version will appear in MFCS 2016. arXiv admin note: text\n  overlap with arXiv:1604.06764", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While weighted automata provide a natural framework to express quantitative\nproperties, many basic properties like average response time cannot be\nexpressed with weighted automata. Nested weighted automata extend weighted\nautomata and consist of a master automaton and a set of slave automata that are\ninvoked by the master automaton. Nested weighted automata are strictly more\nexpressive than weighted automata (e.g., average response time can be expressed\nwith nested weighted automata), but the basic decision questions have higher\ncomplexity (e.g., for deterministic automata, the emptiness question for nested\nweighted automata is PSPACE-hard, whereas the corresponding complexity for\nweighted automata is PTIME). We consider a natural subclass of nested weighted\nautomata where at any point at most a bounded number k of slave automata can be\nactive. We focus on automata whose master value function is the limit average.\nWe show that these nested weighted automata with bounded width are strictly\nmore expressive than weighted automata (e.g., average response time with no\noverlapping requests can be expressed with bound k=1, but not with non-nested\nweighted automata). We show that the complexity of the basic decision problems\n(i.e., emptiness and universality) for the subclass with k constant matches the\ncomplexity for weighted automata. Moreover, when k is part of the input given\nin unary we establish PSPACE-completeness.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 14:00:14 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Henzinger", "Thomas A.", ""], ["Otop", "Jan", ""]]}, {"id": "1606.03634", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra, David E. Narv\\'aez", "title": "The Opacity of Backbones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper approaches, using structural complexity theory, the question of\nwhether there is a chasm between knowing an object exists and getting one's\nhands on the object or its properties. In particular, we study the\nnontransparency of so-called backbones. A backbone of a boolean formula $F$ is\na collection $S$ of its variables for which there is a unique partial\nassignment $a_S$ such that $F[a_S]$ is satisfiable [MZK+99,WGS03]. We show\nthat, under the widely believed assumption that integer factoring is hard,\nthere exist sets of boolean formulas that have obvious, nontrivial backbones\nyet finding the values, $a_S$, of those backbones is intractable. We also show\nthat, under the same assumption, there exist sets of boolean formulas that\nobviously have large backbones yet producing such a backbone $S$ is\nintractable. Furthermore, we show that if integer factoring is not merely\nworst-case hard but is frequently hard, as is widely believed, then the\nfrequency of hardness in our two results is not too much less than that\nfrequency. These results hold more generally, namely, in the settings where,\nrespectively, one's assumption is that P $\\neq$ NP $\\cap$ coNP or that some\nproblem in NP $\\cap$ coNP is frequently hard.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 21:49:24 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 16:12:11 GMT"}, {"version": "v3", "created": "Sun, 18 Dec 2016 23:54:22 GMT"}, {"version": "v4", "created": "Sat, 28 Jan 2017 20:47:18 GMT"}, {"version": "v5", "created": "Mon, 14 Jan 2019 15:13:28 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "1606.03663", "submitter": "Rob van Glabbeek", "authors": "Emile Bres, Rob van Glabbeek and Peter H\\\"ofner", "title": "A Timed Process Algebra for Wireless Networks", "comments": "An extended abstract of this paper---everything but the\n  appendices---appeared in Proc. ESOP'16. arXiv admin note: text overlap with\n  arXiv:1312.7645", "journal-ref": "Proc. 25th European Symposium on Programming, ESOP'16, (Peter\n  Thiemann, ed.), LNCS 9632, Springer, 2016, pp. 95-122", "doi": "10.1007/978-3-662-49498-1_5", "report-no": "Technical Report 9145, NICTA, 2016", "categories": "cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a timed process algebra for wireless networks, an\nextension of the Algebra for Wireless Networks. It combines treatments of local\nbroadcast, conditional unicast and data structures, which are essential\nfeatures for the modelling of network protocols. In this framework we model and\nanalyse the Ad hoc On-Demand Distance Vector routing protocol, and show that,\ncontrary to claims in the literature, it fails to be loop free. We also present\nboundary conditions for a fix ensuring that the resulting protocol is indeed\nloop free.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2016 04:00:54 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Bres", "Emile", ""], ["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""]]}, {"id": "1606.03888", "submitter": "Jan Jakubuv", "authors": "Jan Jakub\\r{u}v, Josef Urban", "title": "Extending E Prover with Similarity Based Clause Selection Strategies", "comments": "Based on the version submitted to CICM'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E prover is a state-of-the-art theorem prover for first-order logic with\nequality. E prover is built around a saturation loop, where new clauses are\nderived by inference rules from previously derived clauses. Selection of\nclauses for the inference provides the main source of non-determinism and an\nimportant choice-point of the loop where the right choice can dramatically\ninfluence the proof search. In this work we extend E Prover with several new\nclause selection strategies based on similarity of a clause with the\nconjecture. In particular, clauses which are more related to the conjecture are\npreferred. We implement different strategies that define the relationship with\na conjecture in different ways. We provide an implementation of the proposed\nselection strategies and we evaluate their efficiency on an extensive benchmark\nset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 10:39:35 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1606.04006", "submitter": "Joao Marcos", "authors": "Ori Lahav, Jo\\~ao Marcos, Yoni Zohar", "title": "It ain't necessarily so: Basic sequent systems for negative modalities", "comments": "20 pages, to appear in Advances in Modal Logic Vol 11 (a few typos\n  corrected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look at non-classical negations and their corresponding adjustment\nconnectives from a modal viewpoint, over complete distributive lattices, and\napply a very general mechanism in order to offer adequate analytic proof\nsystems to logics that are based on them. Defining non-classical negations\nwithin usual modal semantics automatically allows one to treat equivalent\nformulas as synonymous, and to have a natural justification for a global\nversion of the contraposition rule. From that perspective, our study offers a\nparticularly useful environment in which negative modalities and their\ncompanions may be used for dealing with inconsistency and indeterminacy. After\ninvestigating modal logics based on arbitrary frames, we extend the results to\nserial frames, reflexive frames, functional frames, and symmetric frames. In\neach case we also investigate when and how classical negation may thereby be\ndefined.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 15:58:35 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 09:44:50 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Lahav", "Ori", ""], ["Marcos", "Jo\u00e3o", ""], ["Zohar", "Yoni", ""]]}, {"id": "1606.04126", "submitter": "Arno Pauly", "authors": "Takayuki Kihara and Arno Pauly", "title": "Dividing by zero - how bad is it, really?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computable analysis testing a real number for being zero is a fundamental\nexample of a non-computable task. This causes problems for division: We cannot\nensure that the number we want to divide by is not zero. In many cases, any\nreal number would be an acceptable outcome if the divisor is zero - but even\nthis cannot be done in a computable way.\n  In this note we investigate the strength of the computational problem \"Robust\ndivision\": Given a pair of real numbers, the first not greater than the other,\noutput their quotient if well-defined and any real number else. The formal\nframework is provided by Weihrauch reducibility. One particular result is that\nhaving later calls to the problem depending on the outcomes of earlier ones is\nstrictly more powerful than performing all calls concurrently. However, having\na nesting depths of two already provides the full power. This solves an open\nproblem raised at a recent Dagstuhl meeting on Weihrauch reducibility.\n  As application for \"Robust division\", we show that it suffices to execute\nGaussian elimination.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 20:31:08 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Kihara", "Takayuki", ""], ["Pauly", "Arno", ""]]}, {"id": "1606.04422", "submitter": "Artur Garcez", "authors": "Luciano Serafini and Artur d'Avila Garcez", "title": "Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and\n  Knowledge", "comments": "12 pages, 2 figs, 1 table, 27 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Logic Tensor Networks: a uniform framework for integrating\nautomatic learning and reasoning. A logic formalism called Real Logic is\ndefined on a first-order language whereby formulas have truth-value in the\ninterval [0,1] and semantics defined concretely on the domain of real numbers.\nLogical constants are interpreted as feature vectors of real numbers. Real\nLogic promotes a well-founded integration of deductive reasoning on a\nknowledge-base and efficient data-driven relational machine learning. We show\nhow Real Logic can be implemented in deep Tensor Neural Networks with the use\nof Google's tensorflow primitives. The paper concludes with experiments\napplying Logic Tensor Networks on a simple but representative example of\nknowledge completion.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:25:28 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 12:28:57 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Serafini", "Luciano", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "1606.04442", "submitter": "Christian Szegedy", "authors": "Alex A. Alemi, Francois Chollet, Niklas Een, Geoffrey Irving,\n  Christian Szegedy and Josef Urban", "title": "DeepMath - Deep Sequence Models for Premise Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of neural sequence models for premise selection in\nautomated theorem proving, one of the main bottlenecks in the formalization of\nmathematics. We propose a two stage approach for this task that yields good\nresults for the premise selection task on the Mizar corpus while avoiding the\nhand-engineered features of existing state-of-the-art models. To our knowledge,\nthis is the first time deep learning has been applied to theorem proving on a\nlarge scale.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 16:27:41 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 19:35:16 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Alemi", "Alex A.", ""], ["Chollet", "Francois", ""], ["Een", "Niklas", ""], ["Irving", "Geoffrey", ""], ["Szegedy", "Christian", ""], ["Urban", "Josef", ""]]}, {"id": "1606.04680", "submitter": "Thorsten Wissmann", "authors": "Natsuki Urabe and Ichiro Hasuo", "title": "Fair Simulation for Nondeterministic and Probabilistic Buechi Automata:\n  a Coalgebraic Perspective", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  6, 2017) lmcs:3907", "doi": "10.23638/LMCS-13(3:20)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Notions of simulation, among other uses, provide a computationally tractable\nand sound (but not necessarily complete) proof method for language inclusion.\nThey have been comprehensively studied by Lynch and Vaandrager for\nnondeterministic and timed systems; for B\\\"{u}chi automata the notion of fair\nsimulation has been introduced by Henzinger, Kupferman and Rajamani. We\ncontribute to a generalization of fair simulation in two different directions:\none for nondeterministic tree automata previously studied by Bomhard; and the\nother for probabilistic word automata with finite state spaces, both under the\nB\\\"{u}chi acceptance condition. The former nondeterministic definition is\nformulated in terms of systems of fixed-point equations, hence is readily\ntranslated to parity games and is then amenable to Jurdzi\\'{n}ski's algorithm;\nthe latter probabilistic definition bears a strong ranking-function flavor.\nThese two different-looking definitions are derived from one source, namely our\ncoalgebraic modeling of B\\\"{u}chi automata. Based on these coalgebraic\nobservations, we also prove their soundness: a simulation indeed witnesses\nlanguage inclusion.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 08:51:10 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 02:59:45 GMT"}, {"version": "v3", "created": "Thu, 29 Jun 2017 15:36:57 GMT"}, {"version": "v4", "created": "Tue, 5 Sep 2017 11:06:40 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Urabe", "Natsuki", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1606.04786", "submitter": "David Monniaux", "authors": "David Monniaux", "title": "A Survey of Satisfiability Modulo Theory", "comments": "Computer Algebra in Scientific Computing, Sep 2016, Bucharest,\n  Romania. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability modulo theory (SMT) consists in testing the satisfiability of\nfirst-order formulas over linear integer or real arithmetic, or other theories.\nIn this survey, we explain the combination of propositional satisfiability and\ndecision procedures for conjunctions known as DPLL(T), and the alternative\n\"natural domain\" approaches. We also cover quantifiers, Craig interpolants,\npolynomial arithmetic, and how SMT solvers are used in automated software\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 14:41:36 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Monniaux", "David", ""]]}, {"id": "1606.05050", "submitter": "Michael A. Forbes", "authors": "Michael A. Forbes, Amir Shpilka, Iddo Tzameret, Avi Wigderson", "title": "Proof Complexity Lower Bounds from Algebraic Circuit Complexity", "comments": null, "journal-ref": "Conference on Computational Complexity (CCC 2016)", "doi": "10.4230/LIPIcs.CCC.2016.32", "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give upper and lower bounds on the power of subsystems of the Ideal Proof\nSystem (IPS), the algebraic proof system recently proposed by Grochow and\nPitassi, where the circuits comprising the proof come from various restricted\nalgebraic circuit classes. This mimics an established research direction in the\nboolean setting for subsystems of Extended Frege proofs, where proof-lines are\ncircuits from restricted boolean circuit classes. Except one, all of the\nsubsystems considered in this paper can simulate the well-studied\nNullstellensatz proof system, and prior to this work there were no known lower\nbounds when measuring proof size by the algebraic complexity of the polynomials\n(except with respect to degree, or to sparsity).\n  We give two general methods of converting certain algebraic lower bounds into\nproof complexity ones. Our methods require stronger notions of lower bounds,\nwhich lower bound a polynomial as well as an entire family of polynomials it\ndefines. Our techniques are reminiscent of existing methods for converting\nboolean circuit lower bounds into related proof complexity results, such as\nfeasible interpolation. We obtain the relevant types of lower bounds for a\nvariety of classes (sparse polynomials, depth-3 powering formulas, read-once\noblivious algebraic branching programs, and multilinear formulas), and infer\nthe relevant proof complexity results. We complement our lower bounds by giving\nshort refutations of the previously-studied subset-sum axiom using IPS\nsubsystems, allowing us to conclude strict separations between some of these\nsubsystems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 05:01:58 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Forbes", "Michael A.", ""], ["Shpilka", "Amir", ""], ["Tzameret", "Iddo", ""], ["Wigderson", "Avi", ""]]}, {"id": "1606.05223", "submitter": "Hans Bugge Grathwohl", "authors": "Lars Birkedal, Ale\\v{s} Bizjak, Ranald Clouston, Hans Bugge Grathwohl,\n  Bas Spitters, Andrea Vezzosi", "title": "Guarded Cubical Type Theory: Path Equality for Guarded Recursion", "comments": "17 pages, to be published in proceedings of CSL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper improves the treatment of equality in guarded dependent type\ntheory (GDTT), by combining it with cubical type theory (CTT). GDTT is an\nextensional type theory with guarded recursive types, which are useful for\nbuilding models of program logics, and for programming and reasoning with\ncoinductive types. We wish to implement GDTT with decidable type-checking,\nwhile still supporting non-trivial equality proofs that reason about the\nextensions of guarded recursive constructions. CTT is a variation of\nMartin-L\\\"of type theory in which the identity type is replaced by abstract\npaths between terms. CTT provides a computational interpretation of functional\nextensionality, is conjectured to have decidable type checking, and has an\nimplemented type-checker. Our new type theory, called guarded cubical type\ntheory, provides a computational interpretation of extensionality for guarded\nrecursive types. This further expands the foundations of CTT as a basis for\nformalisation in mathematics and computer science. We present examples to\ndemonstrate the expressivity of our type theory, all of which have been checked\nusing a prototype type-checker implementation, and present semantics in a\npresheaf category.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 15:32:47 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 11:42:40 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Birkedal", "Lars", ""], ["Bizjak", "Ale\u0161", ""], ["Clouston", "Ranald", ""], ["Grathwohl", "Hans Bugge", ""], ["Spitters", "Bas", ""], ["Vezzosi", "Andrea", ""]]}, {"id": "1606.05427", "submitter": "EPTCS", "authors": "Jasmin Christian Blanchette, Cezary Kaliszyk", "title": "Proceedings First International Workshop on Hammers for Type Theories", "comments": null, "journal-ref": "EPTCS 210, 2016", "doi": "10.4204/EPTCS.210", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume of EPTCS contains the proceedings of the First Workshop on\nHammers for Type Theories (HaTT 2016), held on 1 July 2016 as part of the\nInternational Joint Conference on Automated Reasoning (IJCAR 2016) in Coimbra,\nPortugal. The proceedings contain four regular papers, as well as abstracts of\nthe two invited talks by Pierre Corbineau (Verimag, France) and Aleksy Schubert\n(University of Warsaw, Poland).\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 06:52:32 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Blanchette", "Jasmin Christian", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1606.05435", "submitter": "Chinmay Narayan", "authors": "Chinmay Narayan, Subodh Sharma, S.Arun-Kumar", "title": "Efficient Verification of Concurrent Programs Over TSO Memory Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of efficient verification of multi-threaded programs\nrunning over Total Store Order (TSO) memory model. It has been shown that even\nwith finite data domain programs, the complexity of control state reachability\nunder TSO is non-primitive recursive. In this paper, we first present a\nbounded-buffer verification approach wherein a bound on the size of buffers is\nplaced; verification is performed incrementally by increasing the size of the\nbuffer with each iteration of the verification procedure until the said bound\nis reached. For programs operating on finite data domains, we also demonstrate\nthe existence of a buffer bound k such that if the program is safe under that\nbound, then it is also safe for unbounded buffers. We have implemented this\ntechnique in a tool ProofTraPar. Our results against memorax [2], a\nstate-of-the-art sound and complete verifier for TSO memory model, have been\nencouraging.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 07:47:02 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Narayan", "Chinmay", ""], ["Sharma", "Subodh", ""], ["Arun-Kumar", "S.", ""]]}, {"id": "1606.05473", "submitter": "Rajarshi Ray", "authors": "Amit Gurung, Arup Deka, Ezio Bartocci, Sergiy Bogomolov, Radu Grosu\n  and Rajarshi Ray", "title": "Parallel Reachability Analysis for Hybrid Systems", "comments": "16 Pages, LNCS style", "journal-ref": null, "doi": "10.1109/MEMCOD.2016.7797741", "report-no": null, "categories": "cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two parallel state-space exploration algorithms for hybrid systems\nwith the goal of enhancing performance on multi-core shared memory systems. The\nfirst is an adaption of the parallel breadth first search in the SPIN model\nchecker. We show that the adapted algorithm does not provide the desired load\nbalancing for many hybrid systems benchmarks. The second is a task parallel\nalgorithm based on cheaply precomputing cost of post (continuous and discrete)\noperations for effective load balancing. We illustrate the task parallel\nalgorithm and the cost precomputation of post operators on a\nsupport-function-based algorithm for state-space exploration. The performance\ncomparison of the two algorithms displays a better CPU\nutilization/load-balancing of the second over the first, except for certain\ncases. The algorithms are implemented in the model checker XSpeed and our\nexperiments show a maximum speed-up of $900\\times$ on a navigation benchmark\nwith respect to SpaceEx LGG scenario, comparing on the basis of equal number of\npost operations evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 10:54:45 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Gurung", "Amit", ""], ["Deka", "Arup", ""], ["Bartocci", "Ezio", ""], ["Bogomolov", "Sergiy", ""], ["Grosu", "Radu", ""], ["Ray", "Rajarshi", ""]]}, {"id": "1606.05490", "submitter": "Marvin Triebel", "authors": "Marvin Triebel and Jan S\\\"urmeli", "title": "Homogeneous Equations of Algebraic Petri Nets", "comments": "Preprint of Paper accepted for CONCUR 2016 including full proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic Petri nets are a formalism for modeling distributed systems and\nalgorithms, describing control and data flow by combining Petri nets and\nalgebraic specification. One way to specify correctness of an algebraic Petri\nnet model $N$ is to specify a linear equation $E$ over the places of $N$ based\non term substitution, and coefficients from an abelian group $G$. Then, $E$ is\nvalid in $N$ iff $E$ is valid in each reachable marking of $N$ . Due to the\nexpressive power of Algebraic Petri nets, validity is generally undecidable.\nStable linear equations form a class of linear equations for which validity is\ndecidable. Place invariants yield a well-understood but incomplete\ncharacterization of all stable linear equations. In this paper, we provide a\ncomplete characterization of stability for the subclass of homogeneous linear\nequations, by restricting ourselves to the interpretation of terms over the\nHerbrand structure without considering further equality axioms. Based thereon,\nwe show that stability is decidable for homogeneous linear equations if $G$ is\na cyclic group.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 11:51:08 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 14:45:34 GMT"}, {"version": "v3", "created": "Wed, 22 Jun 2016 07:53:23 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Triebel", "Marvin", ""], ["S\u00fcrmeli", "Jan", ""]]}, {"id": "1606.05820", "submitter": "EPTCS", "authors": "Ulrich Kohlenbach, Steffen van Bakel, Stefano Berardi", "title": "Proceedings Sixth International Workshop on Classical Logic and\n  Computation", "comments": null, "journal-ref": "EPTCS 213, 2016", "doi": "10.4204/EPTCS.213", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workshop series intends to cover research that investigates the\ncomputational aspects of classical logic and mathematics. Its focus is on\nunwinding the computational content of logical principles and proof in\nmathematics based on these principles, aiming to bring together researchers\nfrom both fields and exchange ideas.\n  Classical Logic and Computation (CL&C) 2016 was the sixth edition of this\nworkshop series held as a satellite to FSCD 2016 on June 23, 2016 in Porto,\nPortugal.\n  In this sixth edition we received 11 submissions of both short and full\npapers. Eight (8) of these were selected to present at the meeting in Porto,\nand five (5) full papers were initially accepted to appear at this EPTCS\nspecial volume of which one was subsequently withdrawn by its authors. An\ninvited talk was given by Marc Bezem (U. of Bergen): Coherent Logic - an\noverview. Other topics covered by this years submissions included:\ncomputational content of proofs using nonstandard analysis, a structured\ngrammar-based approach to the Herbrand content of proofs, semantics of the\nlambda-mu calculus, normalization of classical natural deduction proofs, proof\nmining of noneffective proofs in convex optimization and algebra by functional\ninterpretations. I like to thank the members of the program committee for their\nexcellent work: Steffen van Bakel (London), Stefano Berardi (Torino), Fernando\nFerreira (Lisboa), Hugo de'Liguoro (Torino), Alexandre Miquel (Montevideo).\n  Ulrich Kohlenbach (Darmstadt, PC Chair)\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 01:39:58 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Kohlenbach", "Ulrich", ""], ["van Bakel", "Steffen", ""], ["Berardi", "Stefano", ""]]}, {"id": "1606.05839", "submitter": "EPTCS", "authors": "Olivier Danvy (University of Aarhus), Ugo de'Liguoro (Universit\\`a di\n  Torino)", "title": "Proceedings of the Workshop on Continuations", "comments": null, "journal-ref": "EPTCS 212, 2016", "doi": "10.4204/EPTCS.212", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of continuation is ubiquitous in many different areas of computer\nscience, including systems programming, programming languages, algorithmics,\nsemantics, logic, and constructive mathematics. In fact the concept of\ncontinuation nicely realizes sophisticated control mechanisms, which are widely\nused in a variety of applications. Since we cannot escape control features, it\nbecomes a challenge to provide them with sound reasoning principles.\n  Indeed there is much research activity on understanding, representing, and\nreasoning about elaborated non-local control structures, in particular in\ndeclarative programming languages such as functional and logic languages. The\nproceedings of the Workshop on Continuations 2015, held in London in April\n2015, illustrate some of the afore mentioned topics and hopefully they will\ninspire further research work on the subject.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 07:25:03 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Danvy", "Olivier", "", "University of Aarhus"], ["de'Liguoro", "Ugo", "", "Universit\u00e0 di\n  Torino"]]}, {"id": "1606.05916", "submitter": "Guillaume Brunerie", "authors": "Guillaume Brunerie", "title": "On the homotopy groups of spheres in homotopy type theory", "comments": "PhD thesis, 187 pages, summary in French at the end", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this thesis is to prove that $\\pi_4(S^3) \\simeq\n\\mathbb{Z}/2\\mathbb{Z}$ in homotopy type theory. In particular it is a\nconstructive and purely homotopy-theoretic proof. We first recall the basic\nconcepts of homotopy type theory, and we prove some well-known results about\nthe homotopy groups of spheres: the computation of the homotopy groups of the\ncircle, the triviality of those of the form $\\pi_k(S^n)$ with $k < n$, and the\nconstruction of the Hopf fibration. We then move to more advanced tools. In\nparticular, we define the James construction which allows us to prove the\nFreudenthal suspension theorem and the fact that there exists a natural number\n$n$ such that $\\pi_4(S^3) \\simeq \\mathbb{Z}/n\\mathbb{Z}$. Then we study the\nsmash product of spheres, we construct the cohomology ring of a space, and we\nintroduce the Hopf invariant, allowing us to narrow down the $n$ to either $1$\nor $2$. The Hopf invariant also allows us to prove that all the groups of the\nform $\\pi_{4n-1}(S^{2n})$ are infinite. Finally we construct the Gysin exact\nsequence, allowing us to compute the cohomology of $\\mathbb{C}P^2$ and to prove\nthat $\\pi_4(S^3) \\simeq \\mathbb{Z}/2\\mathbb{Z}$ and that more generally\n$\\pi_{n+1}(S^n) \\simeq \\mathbb{Z}/2\\mathbb{Z}$ for every $n \\ge 3$.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 22:10:45 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Brunerie", "Guillaume", ""]]}, {"id": "1606.05936", "submitter": "EPTCS", "authors": "Ilaria Castellani (INRIA Sophia Antipolis, France), Mariangiola\n  Dezani-Ciancaglini (Universit\\`a di Torino, Italia), Ugo de'Liguoro\n  (Universit\\`a di Torino, Italia)", "title": "Secure Multiparty Sessions with Topics", "comments": "In Proceedings PLACES 2016, arXiv:1606.05403", "journal-ref": "EPTCS 211, 2016, pp. 1-12", "doi": "10.4204/EPTCS.211.1", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiparty session calculi have been recently equipped with security\nrequirements, in order to guarantee properties such as access control and leak\nfreedom. However, the proposed security requirements seem to be overly\nrestrictive in some cases. In particular, a party is not allowed to communicate\nany kind of public information after receiving a secret information. This does\nnot seem justified in case the two pieces of information are totally unrelated.\nThe aim of the present paper is to overcome this restriction, by designing a\ntype discipline for a simple multiparty session calculus, which classifies\nmessages according to their topics and allows unrestricted sequencing of\nmessages on independent topics.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:08:38 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Castellani", "Ilaria", "", "INRIA Sophia Antipolis, France"], ["Dezani-Ciancaglini", "Mariangiola", "", "Universit\u00e0 di Torino, Italia"], ["de'Liguoro", "Ugo", "", "Universit\u00e0 di Torino, Italia"]]}, {"id": "1606.05937", "submitter": "EPTCS", "authors": "Tiago Cogumbreiro (Rice University), Jun Shirako (Rice University),\n  Vivek Sarkar (Rice University)", "title": "Formalization of Phase Ordering", "comments": "In Proceedings PLACES 2016, arXiv:1606.05403", "journal-ref": "EPTCS 211, 2016, pp. 13-24", "doi": "10.4204/EPTCS.211.2", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phasers pose an interesting synchronization mechanism that generalizes many\ncollective synchronization patterns seen in parallel programming languages,\nincluding barriers, clocks, and point-to-point synchronization using latches or\nsemaphores. This work characterizes scheduling constraints on phaser\noperations, by relating the execution state of two tasks that operate on the\nsame phaser. We propose a formalization of Habanero phasers,\nMay-Happen-In-Parallel, and Happens-Before relations for phaser operations, and\nshow that these relations conform with the semantics. Our formalization and\nproofs are fully mechanized using the Coq proof assistant, and are available\nonline.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:08:47 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Cogumbreiro", "Tiago", "", "Rice University"], ["Shirako", "Jun", "", "Rice University"], ["Sarkar", "Vivek", "", "Rice University"]]}, {"id": "1606.05938", "submitter": "EPTCS", "authors": "Mario Coppo (Universit\\`a di Torino, Italia), Mariangiola\n  Dezani-Ciancaglini (Universit\\`a di Torino, Italia), Betti Venneri\n  (Universit\\`a di Firenze, Italia)", "title": "Parallel Monitors for Self-adaptive Sessions", "comments": "In Proceedings PLACES 2016, arXiv:1606.05403", "journal-ref": "EPTCS 211, 2016, pp. 25-36", "doi": "10.4204/EPTCS.211.3", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a data-driven model of self-adaptivity for multiparty\nsessions. System choreography is prescribed by a global type. Participants are\nincarnated by processes associated with monitors, which control their\nbehaviour. Each participant can access and modify a set of global data, which\nare able to trigger adaptations in the presence of critical changes of values.\n  The use of the parallel composition for building global types, monitors and\nprocesses enables a significant degree of flexibility: an adaptation step can\ndynamically reconfigure a set of participants only, without altering the\nremaining participants, even if the two groups communicate.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:08:57 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Coppo", "Mario", "", "Universit\u00e0 di Torino, Italia"], ["Dezani-Ciancaglini", "Mariangiola", "", "Universit\u00e0 di Torino, Italia"], ["Venneri", "Betti", "", "Universit\u00e0 di Firenze, Italia"]]}, {"id": "1606.05941", "submitter": "EPTCS", "authors": "Claudio A. Mezzina (IMT School for Advanced Studies Lucca, Italy),\n  Jorge A. P\\'erez (University of Groningen, The Netherlands)", "title": "Reversible Sessions Using Monitors", "comments": "In Proceedings PLACES 2016, arXiv:1606.05403", "journal-ref": "EPTCS 211, 2016, pp. 56-64", "doi": "10.4204/EPTCS.211.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research has studied foundations for correct and reliable\ncommunication-centric systems. A salient approach to correctness uses session\ntypes to enforce structured communications; a recent approach to reliability\nuses reversible actions as a way of reacting to unanticipated events or\nfailures. This note develops a simple observation: the machinery required to\ndefine asynchronous semantics and monitoring can also support reversible\nprotocols. We propose a process framework of session communication in which\nmonitors support reversibility. A key novelty in our approach are session types\nwith present and past, which allow us to streamline the semantics of reversible\nactions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:09:25 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Mezzina", "Claudio A.", "", "IMT School for Advanced Studies Lucca, Italy"], ["P\u00e9rez", "Jorge A.", "", "University of Groningen, The Netherlands"]]}, {"id": "1606.05942", "submitter": "EPTCS", "authors": "Wytse Oortwijn (University of Twente), Stefan Blom (University of\n  Twente), Marieke Huisman (University of Twente)", "title": "Future-based Static Analysis of Message Passing Programs", "comments": "In Proceedings PLACES 2016, arXiv:1606.05403", "journal-ref": "EPTCS 211, 2016, pp. 65-72", "doi": "10.4204/EPTCS.211.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing is widely used in industry to develop programs consisting of\nseveral distributed communicating components. Developing functionally correct\nmessage passing software is very challenging due to the concurrent nature of\nmessage exchanges. Nonetheless, many safety-critical applications rely on the\nmessage passing paradigm, including air traffic control systems and emergency\nservices, which makes proving their correctness crucial. We focus on the\nmodular verification of MPI programs by statically verifying concrete Java\ncode. We use separation logic to reason about local correctness and define\nabstractions of the communication protocol in the process algebra used by\nmCRL2. We call these abstractions futures as they predict how components will\ninteract during program execution. We establish a provable link between futures\nand program code and analyse the abstract futures via model checking to prove\nglobal correctness. Finally, we verify a leader election protocol to\ndemonstrate our approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:09:35 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Oortwijn", "Wytse", "", "University of Twente"], ["Blom", "Stefan", "", "University of\n  Twente"], ["Huisman", "Marieke", "", "University of Twente"]]}, {"id": "1606.05945", "submitter": "EPTCS", "authors": "Simon Cruanes (Inria Nancy -- Grand Est), Jasmin Christian Blanchette\n  (Inria Nancy -- Grand Est, Max-Planck-Institut f\\\"ur Informatik)", "title": "Extending Nunchaku to Dependent Type Theory", "comments": "In Proceedings HaTT 2016, arXiv:1606.05427", "journal-ref": "EPTCS 210, 2016, pp. 3-12", "doi": "10.4204/EPTCS.210.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nunchaku is a new higher-order counterexample generator based on a sequence\nof transformations from polymorphic higher-order logic to first-order logic.\nUnlike its predecessor Nitpick for Isabelle, it is designed as a stand-alone\ntool, with frontends for various proof assistants. In this short paper, we\npresent some ideas to extend Nunchaku with partial support for dependent types\nand type classes, to make frontends for Coq and other systems based on\ndependent type theory more useful.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:14:19 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Cruanes", "Simon", "", "Inria Nancy -- Grand Est"], ["Blanchette", "Jasmin Christian", "", "Inria Nancy -- Grand Est, Max-Planck-Institut f\u00fcr Informatik"]]}, {"id": "1606.05946", "submitter": "EPTCS", "authors": "{\\L}ukasz Czajka (University of Innsbruck), Cezary Kaliszyk\n  (University of Innsbruck)", "title": "Goal Translation for a Hammer for Coq (Extended Abstract)", "comments": "In Proceedings HaTT 2016, arXiv:1606.05427", "journal-ref": "EPTCS 210, 2016, pp. 13-20", "doi": "10.4204/EPTCS.210.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hammers are tools that provide general purpose automation for formal proof\nassistants. Despite the gaining popularity of the more advanced versions of\ntype theory, there are no hammers for such systems. We present an extension of\nthe various hammer components to type theory: (i) a translation of a\nsignificant part of the Coq logic into the format of automated proof systems;\n(ii) a proof reconstruction mechanism based on a Ben-Yelles-type algorithm\ncombined with limited rewriting, congruence closure and a first-order\ngeneralization of the left rules of Dyckhoff's system LJT.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:14:28 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Czajka", "\u0141ukasz", "", "University of Innsbruck"], ["Kaliszyk", "Cezary", "", "University of Innsbruck"]]}, {"id": "1606.05947", "submitter": "EPTCS", "authors": "Burak Ekici (The University of Iowa), Guy Katz (New York University),\n  Chantal Keller (LRI, Univ. Paris-Sud), Alain Mebsout (The University of\n  Iowa), Andrew J. Reynolds (The University of Iowa), Cesare Tinelli (The\n  University of Iowa)", "title": "Extending SMTCoq, a Certified Checker for SMT (Extended Abstract)", "comments": "In Proceedings HaTT 2016, arXiv:1606.05427", "journal-ref": "EPTCS 210, 2016, pp. 21-29", "doi": "10.4204/EPTCS.210.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract reports on current progress of SMTCoq, a communication\ntool between the Coq proof assistant and external SAT and SMT solvers. Based on\na checker for generic first-order certificates implemented and proved correct\nin Coq, SMTCoq offers facilities both to check external SAT and SMT answers and\nto improve Coq's automation using such solvers, in a safe way. Currently\nsupporting the SAT solver zChaff, and the SMT solver veriT for the combination\nof the theories of congruence closure and linear integer arithmetic, SMTCoq is\nmeant to be extendable with a reasonable amount of effort: we present work in\nprogress to support the SMT solver CVC4 and the theory of bit vectors.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:14:37 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Ekici", "Burak", "", "The University of Iowa"], ["Katz", "Guy", "", "New York University"], ["Keller", "Chantal", "", "LRI, Univ. Paris-Sud"], ["Mebsout", "Alain", "", "The University of\n  Iowa"], ["Reynolds", "Andrew J.", "", "The University of Iowa"], ["Tinelli", "Cesare", "", "The\n  University of Iowa"]]}, {"id": "1606.05948", "submitter": "EPTCS", "authors": "Fabian Kunze (Saarland University)", "title": "Towards the Integration of an Intuitionistic First-Order Prover into Coq", "comments": "In Proceedings HaTT 2016, arXiv:1606.05427", "journal-ref": "EPTCS 210, 2016, pp. 30-35", "doi": "10.4204/EPTCS.210.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient intuitionistic first-order prover integrated into Coq is useful\nto replay proofs found by external automated theorem provers. We propose a\ntwo-phase approach: An intuitionistic prover generates a certificate based on\nthe matrix characterization of intuitionistic first-order logic; the\ncertificate is then translated into a sequent-style proof.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 01:14:48 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Kunze", "Fabian", "", "Saarland University"]]}, {"id": "1606.06005", "submitter": "Alain Prout\\'e", "authors": "Matthieu Herrmann and Alain Prout\\'e", "title": "On the dependent conjunction and implication", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a theoretical model of conjunctions $E\\wedge F$ and implications\n$E\\implies F$ where $F$ is meaningful only when $E$ is true, a situation which\nis very often encountered in everyday mathematics, and which was already\nformalized by several type theorists. We present a version of these concepts\nwhich should be more attractive for mathematicians and in particular for non\nlogicians, by using an extension of Lawvere's definition of the quantifiers. We\nexplain the link of this phenomenon with the principle of description, why this\ndependency is obtained through the use of a \"hidden\" variable, and more\ngenerally the link of these concepts with the vernacular language of\nmathematics, which is actually our main motivation. Despite its links with\ntopos theory, this article is readable by non specialists.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 08:20:12 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 08:14:01 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 11:27:11 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Herrmann", "Matthieu", ""], ["Prout\u00e9", "Alain", ""]]}, {"id": "1606.06269", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller", "title": "Founded Semantics and Constraint Semantics of Logic Rules", "comments": null, "journal-ref": "Journal of Logic and Computation, Volume 30, Issue 8, December\n  2020, Pages 1609-1668", "doi": "10.1093/logcom/exaa056", "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic rules and inference are fundamental in computer science and have been\nstudied extensively. However, prior semantics of logic languages can have\nsubtle implications and can disagree significantly, on even very simple\nprograms, including in attempting to solve the well-known Russell's paradox.\nThese semantics are often non-intuitive and hard-to-understand when\nunrestricted negation is used in recursion.\n  This paper describes a simple new semantics for logic rules, founded\nsemantics, and its straightforward extension to another simple new semantics,\nconstraint semantics, that unify the core of different prior semantics. The new\nsemantics support unrestricted negation, as well as unrestricted existential\nand universal quantifications. They are uniquely expressive and intuitive by\nallowing assumptions about the predicates, rules, and reasoning to be specified\nexplicitly, as simple and precise binary choices. They are completely\ndeclarative and relate cleanly to prior semantics. In addition, founded\nsemantics can be computed in linear time in the size of the ground program.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 19:48:20 GMT"}, {"version": "v2", "created": "Sun, 11 Sep 2016 18:28:29 GMT"}, {"version": "v3", "created": "Sat, 15 Apr 2017 00:24:14 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 15:34:32 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1606.06376", "submitter": "EPTCS", "authors": "Tristan Crolard", "title": "A verified abstract machine for functional coroutines", "comments": "In Proceedings WoC 2015, arXiv:1606.05839", "journal-ref": "EPTCS 212, 2016, pp. 1-17", "doi": "10.4204/EPTCS.212.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional coroutines are a restricted form of control mechanism, where each\ncoroutine is represented with both a continuation and an environment. This\nrestriction was originally obtained by considering a constructive version of\nParigot's classical natural deduction which is sound and complete for the\nConstant Domain logic. In this article, we present a refinement of de Groote's\nabstract machine for functional coroutines and we prove its correctness.\nTherefore, this abstract machine also provides a direct computational\ninterpretation of the Constant Domain logic.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:45:32 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Crolard", "Tristan", ""]]}, {"id": "1606.06379", "submitter": "EPTCS", "authors": "Ikuo Kobori, Yukiyoshi Kameyama, Oleg Kiselyov", "title": "Answer-Type Modification without Tears: Prompt-Passing Style Translation\n  for Typed Delimited-Control Operators", "comments": "In Proceedings WoC 2015, arXiv:1606.05839", "journal-ref": "EPTCS 212, 2016, pp. 36-52", "doi": "10.4204/EPTCS.212.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The salient feature of delimited-control operators is their ability to modify\nanswer types during computation. The feature, answer-type modification (ATM for\nshort), allows one to express various interesting programs such as typed printf\ncompactly and nicely, while it makes it difficult to embed these operators in\nstandard functional languages.\n  In this paper, we present a typed translation of delimited-control operators\nshift and reset with ATM into a familiar language with multi-prompt shift and\nreset without ATM, which lets us use ATM in standard languages without\nmodifying the type system. Our translation generalizes Kiselyov's direct-style\nimplementation of typed printf, which uses two prompts to emulate the\nmodification of answer types, and passes them during computation. We prove that\nour translation preserves typing. As the naive prompt-passing style translation\ngenerates and passes many prompts even for pure terms, we show an optimized\ntranslation that generate prompts only when needed, which is also\ntype-preserving. Finally, we give an implementation in the tagless-final style\nwhich respects typing by construction.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:45:51 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Kobori", "Ikuo", ""], ["Kameyama", "Yukiyoshi", ""], ["Kiselyov", "Oleg", ""]]}, {"id": "1606.06382", "submitter": "EPTCS", "authors": "Hayo Thielecke (Computer Science, University of Birmingham)", "title": "Command injection attacks, continuations, and the Lambek calculus", "comments": "In Proceedings WoC 2015, arXiv:1606.05839", "journal-ref": "EPTCS 212, 2016, pp. 81-96", "doi": "10.4204/EPTCS.212.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows connections between command injection attacks,\ncontinuations, and the Lambek calculus: certain command injections, such as the\ntautology attack on SQL, are shown to be a form of control effect that can be\ntyped using the Lambek calculus, generalizing the double-negation typing of\ncontinuations. Lambek's syntactic calculus is a logic with two implicational\nconnectives taking their arguments from the left and right, respectively. These\nconnectives describe how strings interact with their left and right contexts\nwhen building up syntactic structures. The calculus is a form of propositional\nlogic without structural rules, and so a forerunner of substructural logics\nlike Linear Logic and Separation Logic.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:46:23 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Thielecke", "Hayo", "", "Computer Science, University of Birmingham"]]}, {"id": "1606.06384", "submitter": "EPTCS", "authors": "Bahareh Afshari, Stefan Hetzl, Graham E. Leigh", "title": "On the Herbrand content of LK", "comments": "In Proceedings CL&C 2016, arXiv:1606.05820", "journal-ref": "EPTCS 213, 2016, pp. 1-10", "doi": "10.4204/EPTCS.213.1", "report-no": null, "categories": "cs.LO cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a structural representation of the Herbrand content of LK-proofs\nwith cuts of complexity prenex Sigma-2/Pi-2. The representation takes the form\nof a typed non-deterministic tree grammar of order 2 which generates a finite\nlanguage of first-order terms that appear in the Herbrand expansions obtained\nthrough cut-elimination. In particular, for every Gentzen-style reduction\nbetween LK-proofs we study the induced grammars and classify the cases in which\nlanguage equality and inclusion hold.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:49:44 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Afshari", "Bahareh", ""], ["Hetzl", "Stefan", ""], ["Leigh", "Graham E.", ""]]}, {"id": "1606.06385", "submitter": "EPTCS", "authors": "Ken Akiba (Virginia Commonwealth University)", "title": "Denotational Semantics of the Simplified Lambda-Mu Calculus and a New\n  Deduction System of Classical Type Theory", "comments": "In Proceedings CL&C 2016, arXiv:1606.05820", "journal-ref": "EPTCS 213, 2016, pp. 11-23", "doi": "10.4204/EPTCS.213.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical (or Boolean) type theory is the type theory that allows the type\ninference $\\sigma \\to \\bot) \\to \\bot => \\sigma$ (the type counterpart of\ndouble-negation elimination), where $\\sigma$ is any type and $\\bot$ is\nabsurdity type. This paper first presents a denotational semantics for a\nsimplified version of Parigot's lambda-mu calculus, a premier example of\nclassical type theory. In this semantics the domain of each type is divided\ninto infinitely many ranks and contains not only the usual members of the type\nat rank 0 but also their negative, conjunctive, and disjunctive shadows in the\nhigher ranks, which form an infinitely nested Boolean structure. Absurdity type\n$\\bot$ is identified as the type of truth values. The paper then presents a new\ndeduction system of classical type theory, a sequent calculus called the\nclassical type system (CTS), which involves the standard logical operators such\nas negation, conjunction, and disjunction and thus reflects the discussed\nsemantic structure in a more straightforward fashion.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:49:53 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Akiba", "Ken", "", "Virginia Commonwealth University"]]}, {"id": "1606.06386", "submitter": "EPTCS", "authors": "Sam Sanders (LMU Munich and Ghent University)", "title": "The computational content of Nonstandard Analysis", "comments": "In Proceedings CL&C 2016, arXiv:1606.05820", "journal-ref": "EPTCS 213, 2016, pp. 24-40", "doi": "10.4204/EPTCS.213.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kohlenbach's proof mining program deals with the extraction of effective\ninformation from typically ineffective proofs. Proof mining has its roots in\nKreisel's pioneering work on the so-called unwinding of proofs. The proof\nmining of classical mathematics is rather restricted in scope due to the\nexistence of sentences without computational content which are provable from\nthe law of excluded middle and which involve only two quantifier alternations.\nBy contrast, we show that the proof mining of classical Nonstandard Analysis\nhas a very large scope. In particular, we will observe that this scope includes\nany theorem of pure Nonstandard Analysis, where `pure' means that only\nnonstandard definitions (and not the epsilon-delta kind) are used. In this\nnote, we survey results in analysis, computability theory, and Reverse\nMathematics.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:50:08 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Sanders", "Sam", "", "LMU Munich and Ghent University"]]}, {"id": "1606.06387", "submitter": "EPTCS", "authors": "Jos\\'e Esp\\'irito Santo (Centro de Matem\\'atica, Universidade do\n  Minho)", "title": "A note on strong normalization in classical natural deduction", "comments": "In Proceedings CL&C 2016, arXiv:1606.05820", "journal-ref": "EPTCS 213, 2016, pp. 41-51", "doi": "10.4204/EPTCS.213.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of natural deduction for propositional classical logic, with\nclassicality given by the inference rule reductio ad absurdum, we investigate\nthe De Morgan translation of disjunction in terms of negation and conjunction.\nOnce the translation is extended to proofs, it obtains a reduction of\nprovability to provability in the disjunction-free subsystem. It is natural to\nask whether a reduction is also obtained for, say, strong normalization; that\nis, whether strong normalization for the disjunction-free system implies the\nsame property for the full system, and whether such lifting of the property can\nbe done along the De Morgan translation. Although natural, these questions are\nneglected by the literature. We spell out the map of reduction steps induced by\nthe De Morgan translation of proofs. But we need to \"optimize\" such a map in\norder to show that a reduction sequence in the full system from a proof\ndetermines, in a length-preserving way, a reduction sequence in the\ndisjunction-free system from the De Morgan translation of the proof. In this\nsense, the above questions have a positive answer.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:50:21 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Santo", "Jos\u00e9 Esp\u00edrito", "", "Centro de Matem\u00e1tica, Universidade do\n  Minho"]]}, {"id": "1606.06422", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Weakly True Concurrency and Its Logic", "comments": "arXiv admin note: text overlap with arXiv:1110.4094 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We firstly find the existence of silent event $\\tau$ in true concurrency\n(named weakly true concurrency) by defining weakly true concurrent behaviors\nand weakly true concurrent logics. Based on Paolo Baldan and Silvia Crafa's\ncomprehensive work on (strongly) true concurrency, we find the correspondence\nbetween weakly true concurrent equivalences and weakly true concurrent logics.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 04:49:02 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1606.06557", "submitter": "Marlin Frickenschmidt", "authors": "Michael Elberfeld, Marlin Frickenschmidt, Martin Grohe", "title": "Order Invariance on Decomposable Structures", "comments": "Accepted for LICS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order-invariant formulas access an ordering on a structure's universe, but\nthe model relation is independent of the used ordering. Order invariance is\nfrequently used for logic-based approaches in computer science. Order-invariant\nformulas capture unordered problems of complexity classes and they model the\nindependence of the answer to a database query from low-level aspects of\ndatabases. We study the expressive power of order-invariant monadic\nsecond-order (MSO) and first-order (FO) logic on restricted classes of\nstructures that admit certain forms of tree decompositions (not necessarily of\nbounded width).\n  While order-invariant MSO is more expressive than MSO and, even, CMSO (MSO\nwith modulo-counting predicates), we show that order-invariant MSO and CMSO are\nequally expressive on graphs of bounded tree width and on planar graphs. This\nextends an earlier result for trees due to Courcelle. Moreover, we show that\nall properties definable in order-invariant FO are also definable in MSO on\nthese classes. These results are applications of a theorem that shows how to\nlift up definability results for order-invariant logics from the bags of a\ngraph's tree decomposition to the graph itself.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 13:23:26 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Elberfeld", "Michael", ""], ["Frickenschmidt", "Marlin", ""], ["Grohe", "Martin", ""]]}, {"id": "1606.06799", "submitter": "EPTCS", "authors": "Cameron Beebe (GSN/MCMP)", "title": "Sequent Calculus Representations for Quantum Circuits", "comments": "In Proceedings PC 2016, arXiv:1606.06513", "journal-ref": "EPTCS 214, 2016, pp. 3-15", "doi": "10.4204/EPTCS.214.3", "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering a sequent-style proof system for quantum programs, there are\ncertain elements of quantum mechanics that we may wish to capture, such as\nphase, dynamics of unitary transformations, and measurement probabilities.\nTraditional quantum logics which focus primarily on the abstract orthomodular\nlattice theory and structures of Hilbert spaces have not satisfactorily\ncaptured some of these elements. We can start from 'scratch' in an attempt to\nconceptually characterize the types of proof rules which should be in a system\nthat represents elements necessary for quantum algorithms. This present work\nattempts to do this from the perspective of the quantum circuit model of\nquantum computation. A sequent calculus based on single quantum circuits is\nsuggested, and its ability to incorporate important conceptual and dynamic\naspects of quantum computing is discussed. In particular, preserving the\nrepresentation of phase helps illustrate the role of interference as a resource\nin quantum computation. Interference also provides an intuitive basis for a\nnon-monotonic calculus.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 01:58:51 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Beebe", "Cameron", "", "GSN/MCMP"]]}, {"id": "1606.06877", "submitter": "Waqar  Ahmed", "authors": "Waqar Ahmed, Osman Hasan and Sofiene Tahar", "title": "Formal Dependability Modeling and Analysis: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependability is an umbrella concept that subsumes many key properties about\na system, including reliability, maintainability, safety, availability,\nconfidentiality, and integrity. Various dependability modeling techniques have\nbeen developed to effectively capture the failure characteristics of systems\nover time. Traditionally, dependability models are analyzed using\npaper-and-pencil proof methods and computer based simulation tools but their\nresults cannot be trusted due to their inherent inaccuracy limitations. The\nrecent developments in probabilistic analysis support using formal methods have\nenabled the possibility of accurate and rigorous dependability analysis. Thus,\nthe usage of formal methods for dependability analysis is widely advocated for\nsafety-critical domains, such as transportation, aerospace and health. Given\nthe complementary strengths of mainstream formal methods, like theorem proving\nand model checking, and the variety of dependability models judging the most\nsuitable formal technique for a given dependability model is not a\nstraightforward task. In this paper, we present a comprehensive review of\nexisting formal dependability analysis techniques along with their pros and\ncons for handling a particular dependability model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 10:19:06 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Ahmed", "Waqar", ""], ["Hasan", "Osman", ""], ["Tahar", "Sofiene", ""]]}, {"id": "1606.06974", "submitter": "Anushri Jana", "authors": "Anushri Jana, Uday P. Khedker, Advaita Datar, R Venkatesh, C Niyas", "title": "Scaling Bounded Model Checking By Transforming Programs With Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded Model Checking is one the most successful techniques for finding bugs\nin program. However, model checkers are resource hungry and are often unable to\nverify programs with loops iterating over large arrays.We present a\ntransformation that enables bounded model checkers to verify a certain class of\narray properties. Our technique transforms an array-manipulating (ANSI-C)\nprogram to an array-free and loop-free (ANSI-C) program thereby reducing the\nresource requirements of a model checker significantly. Model checking of the\ntransformed program using an off-the-shelf bounded model checker simulates the\nloop iterations efficiently. Thus, our transformed program is a sound\nabstraction of the original program and is also precise in a large number of\ncases - we formally characterize the class of programs for which it is\nguaranteed to be precise. We demonstrate the applicability and usefulness of\nour technique on both industry code as well as academic benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 15:01:42 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 10:42:47 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2016 13:15:56 GMT"}, {"version": "v4", "created": "Tue, 7 Mar 2017 08:43:20 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Jana", "Anushri", ""], ["Khedker", "Uday P.", ""], ["Datar", "Advaita", ""], ["Venkatesh", "R", ""], ["Niyas", "C", ""]]}, {"id": "1606.07047", "submitter": "Christopher Hahn", "authors": "Bernd Finkbeiner and Christopher Hahn", "title": "Deciding Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties, like observational determinism or symmetry, cannot be\nexpressed as properties of individual computation traces, because they describe\na relation between multiple computation traces. HyperLTL is a temporal logic\nthat captures such relations through trace variables, which are introduced\nthrough existential and universal trace quantifiers and can be used to refer to\nmultiple computations at the same time. In this paper, we study the\nsatisfiability problem of HyperLTL. We show that the problem is PSPACE-complete\nfor alternation-free formulas (and, hence, no more expensive than LTL\nsatisfiability), EXPSPACE-complete for exists-forall-formulas, and undecidable\nfor forall-exists-formulas. Many practical hyperproperties can be expressed as\nalternation-free formulas. Our results show that both satisfiability and\nimplication are decidable for such properties.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 19:23:00 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Hahn", "Christopher", ""]]}, {"id": "1606.07095", "submitter": "Michael Beeson", "authors": "Michael Beeson and Larry Wos", "title": "Finding Proofs in Tarskian Geometry", "comments": "32 pages, 4 figures, 4 tables. Supplementary computer code published\n  separately", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on a project to use a theorem prover to find proofs of the theorems\nin Tarskian geometry. These theorems start with fundamental properties of\nbetweenness, proceed through the derivations of several famous theorems due to\nGupta and end with the derivation from Tarski's axioms of Hilbert's 1899 axioms\nfor geometry. They include the four challenge problems left unsolved by Quaife,\nwho two decades ago found some \\Otter proofs in Tarskian geometry (solving\nchallenges issued in Wos's 1998 book). There are 212 theorems in this\ncollection. We were able to find \\Otter proofs of all these theorems. We\ndeveloped a methodology for the automated preparation and checking of the input\nfiles for those theorems, to ensure that no human error has corrupted the\nformal development of an entire theory as embodied in two hundred input files\nand proofs. We distinguish between proofs that were found completely\nmechanically (without reference to the steps of a book proof) and proofs that\nwere constructed by some technique that involved a human knowing the steps of a\nbook proof. Proofs of length 40--100, roughly speaking, are difficult exercises\nfor a human, and proofs of 100-250 steps belong in a Ph.D. thesis or\npublication. 29 of the proofs in our collection are longer than 40 steps, and\nten are longer than 90 steps. We were able to derive completely mechanically\nall but 26 of the 183 theorems that have \"short\" proofs (40 or fewer deduction\nsteps). We found proofs of the rest, as well as the 29 \"hard\" theorems, using a\nmethod that requires consulting the book proof at the outset. Our \"subformula\nstrategy\" enabled us to prove four of the 29 hard theorems completely\nmechanically. These are Ph.D. level proofs, of length up to 108.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 20:39:23 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Beeson", "Michael", ""], ["Wos", "Larry", ""]]}, {"id": "1606.07124", "submitter": "Benjamin Monmege", "authors": "Thomas Brihaye, Morgane Esti\\'evenart, Gilles Geeraerts, Hsi-Ming Ho,\n  Benjamin Monmege, Nathalie Sznajder", "title": "Real-Time Synthesis is Hard!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reactive synthesis problem (RS) for specifications given in\nMetric Interval Temporal Logic (MITL). RS is known to be undecidable in a very\ngeneral setting, but on infinite words only; and only the very restrictive BRRS\nsubcase is known to be decidable (see D'Souza et al. and Bouyer et al.). In\nthis paper, we precise the decidability border of MITL synthesis. We show RS is\nundecidable on finite words too, and present a landscape of restrictions (both\non the logic and on the possible controllers) that are still undecidable. On\nthe positive side, we revisit BRRS and introduce an efficient on-the-fly\nalgorithm to solve it.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 22:01:31 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Brihaye", "Thomas", ""], ["Esti\u00e9venart", "Morgane", ""], ["Geeraerts", "Gilles", ""], ["Ho", "Hsi-Ming", ""], ["Monmege", "Benjamin", ""], ["Sznajder", "Nathalie", ""]]}, {"id": "1606.07143", "submitter": "Justin Hsu", "authors": "Gilles Barthe, No\\'emie Fong, Marco Gaboardi, Benjamin Gr\\'egoire,\n  Justin Hsu, Pierre-Yves Strub", "title": "Advanced Probabilistic Couplings for Differential Privacy", "comments": null, "journal-ref": null, "doi": "10.1145/2976749.2978391", "report-no": null, "categories": "cs.LO cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a promising formal approach to data privacy, which\nprovides a quantitative bound on the privacy cost of an algorithm that operates\non sensitive information. Several tools have been developed for the formal\nverification of differentially private algorithms, including program logics and\ntype systems. However, these tools do not capture fundamental techniques that\nhave emerged in recent years, and cannot be used for reasoning about\ncutting-edge differentially private algorithms. Existing techniques fail to\nhandle three broad classes of algorithms: 1) algorithms where privacy depends\naccuracy guarantees, 2) algorithms that are analyzed with the advanced\ncomposition theorem, which shows slower growth in the privacy cost, 3)\nalgorithms that interactively accept adaptive inputs.\n  We address these limitations with a new formalism extending apRHL, a\nrelational program logic that has been used for proving differential privacy of\nnon-interactive algorithms, and incorporating aHL, a (non-relational) program\nlogic for accuracy properties. We illustrate our approach through a single\nrunning example, which exemplifies the three classes of algorithms and explores\nnew variants of the Sparse Vector technique, a well-studied algorithm from the\nprivacy literature. We implement our logic in EasyCrypt, and formally verify\nprivacy. We also introduce a novel coupling technique called \\emph{optimal\nsubset coupling} that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 00:11:57 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 16:22:57 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Barthe", "Gilles", ""], ["Fong", "No\u00e9mie", ""], ["Gaboardi", "Marco", ""], ["Gr\u00e9goire", "Benjamin", ""], ["Hsu", "Justin", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1606.07295", "submitter": "EPTCS", "authors": "R Ramanujam (IMSc, Chennai, India)", "title": "Proceedings Fifteenth Conference on Theoretical Aspects of Rationality\n  and Knowledge", "comments": null, "journal-ref": "EPTCS 215, 2016", "doi": "10.4204/EPTCS.215", "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 15th Conference on Theoretical Aspects of Rationality and Knowledge\n(TARK) took place in Carnegie Mellon University, Pittsburgh, USA from June 4 to\n6, 2015.\n  The mission of the TARK conferences is to bring together researchers from a\nwide variety of fields, including Artificial Intelligence, Cryptography,\nDistributed Computing, Economics and Game Theory, Linguistics, Philosophy, and\nPsychology, in order to further our understanding of interdisciplinary issues\ninvolving reasoning about rationality and knowledge.\n  These proceedings consist of a subset of the papers / abstracts presented at\nthe TARK conference.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 12:50:36 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Ramanujam", "R", "", "IMSc, Chennai, India"]]}, {"id": "1606.07337", "submitter": "Marianna Nicolosi Asmundo", "authors": "Domenico Cantone, Marianna Nicolosi-Asmundo, Daniele Francesco\n  Santamaria", "title": "Conjunctive Query Answering via a Fragment of Set Theory (Extended\n  Version)", "comments": "Extended version of the paper entitled \"Conjunctive Query Answering\n  via a Fragment of Set Theory\" submitted to the Conference ICTCS 2016. arXiv\n  admin note: text overlap with arXiv:1505.02075", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of Conjunctive Query Answering (CQA) for the\ndescription logic $\\dlssx$ ($\\shdlssx$, for short) which extends the logic\n$\\dlss$ with Boolean operations on concrete roles and with the product of\nconcepts.\n  The result is obtained by formalizing $\\shdlssx$-knowledge bases and\n$\\shdlssx$-conjunctive queries in terms of formulae of the four-level\nset-theoretic fragment $\\flqsr$, which admits a restricted form of\nquantification on variables of the first three levels and on pair terms. We\nsolve the CQA problem for $\\shdlssx$ through a decision procedure for the\nsatisfiability problem of $\\flqsr$. We further define a \\ke\\space based\nprocedure for the same problem, more suitable for implementation purposes, and\nanalyze its computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 14:57:27 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Cantone", "Domenico", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""]]}, {"id": "1606.07513", "submitter": "EPTCS", "authors": "Simon M. Huttegger (University of California, USA)", "title": "The Problem of Analogical Inference in Inductive Logic", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 1-12", "doi": "10.4204/EPTCS.215.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider one problem that was largely left open by Rudolf Carnap in his\nwork on inductive logic, the problem of analogical inference. After discussing\nsome previous attempts to solve this problem, we propose a new solution that is\nbased on the ideas of Bruno de Finetti on probabilistic symmetries. We explain\nhow our new inductive logic can be developed within the Carnapian paradigm of\ninductive logic-deriving an inductive rule from a set of simple postulates\nabout the observational process-and discuss some of its properties.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:29:55 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Huttegger", "Simon M.", "", "University of California, USA"]]}, {"id": "1606.07515", "submitter": "EPTCS", "authors": "Thomas {\\AA}gotnes (University of Bergen), Y\\`i N. W\\'ang (Zhejiang\n  University)", "title": "Resolving Distributed Knowledge", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 31-50", "doi": "10.4204/EPTCS.215.4", "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed knowledge is the sum of the knowledge in a group; what someone\nwho is able to discern between two possible worlds whenever any member of the\ngroup can discern between them, would know. Sometimes distributed knowledge is\nreferred to as the potential knowledge of a group, or the joint knowledge they\ncould obtain if they had unlimited means of communication. In epistemic logic,\nthe formula D_G{\\phi} is intended to express the fact that group G has\ndistributed knowledge of {\\phi}, that there is enough information in the group\nto infer {\\phi}. But this is not the same as reasoning about what happens if\nthe members of the group share their information. In this paper we introduce an\noperator R_G, such that R_G{\\phi} means that {\\phi} is true after G have shared\nall their information with each other - after G's distributed knowledge has\nbeen resolved. The R_G operators are called resolution operators. Semantically,\nwe say that an expression R_G{\\phi} is true iff {\\phi} is true in what van\nBenthem [11, p. 249] calls (G's) communication core; the model update obtained\nby removing links to states for members of G that are not linked by all members\nof G. We study logics with different combinations of resolution operators and\noperators for common and distributed knowledge. Of particular interest is the\nrelationship between distributed and common knowledge. The main results are\nsound and complete axiomatizations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:30:18 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["\u00c5gotnes", "Thomas", "", "University of Bergen"], ["W\u00e1ng", "Y\u00ec N.", "", "Zhejiang\n  University"]]}, {"id": "1606.07516", "submitter": "EPTCS", "authors": "Krzysztof R. Apt (Centrum Wiskunde Informatica), Davide Grossi\n  (University of Liverpool), Wiebe van der Hoek (University of Liverpool)", "title": "Epistemic Protocols for Distributed Gossiping", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 51-66", "doi": "10.4204/EPTCS.215.5", "report-no": null, "categories": "cs.AI cs.DC cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip protocols aim at arriving, by means of point-to-point or group\ncommunications, at a situation in which all the agents know each other's\nsecrets. We consider distributed gossip protocols which are expressed by means\nof epistemic logic. We provide an operational semantics of such protocols and\nset up an appropriate framework to argue about their correctness. Then we\nanalyze specific protocols for complete graphs and for directed rings.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:30:33 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Apt", "Krzysztof R.", "", "Centrum Wiskunde Informatica"], ["Grossi", "Davide", "", "University of Liverpool"], ["van der Hoek", "Wiebe", "", "University of Liverpool"]]}, {"id": "1606.07518", "submitter": "EPTCS", "authors": "Alexandru Baltag (Institute for logic, Language and Computation.\n  University of Amsterdam), Nina Gierasimczuk (Institute for Logic, Language\n  and Computation. University of Amsterdam), Sonja Smets (Institute for Logic,\n  Language and Computation. University of Amsterdam)", "title": "On the Solvability of Inductive Problems: A Study in Epistemic Topology", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 81-98", "doi": "10.4204/EPTCS.215.7", "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the issues of inductive problem-solving and learning by\ndoxastic agents. We provide topological characterizations of solvability and\nlearnability, and we use them to prove that AGM-style belief revision is\n\"universal\", i.e., that every solvable problem is solvable by AGM conditioning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:30:59 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Baltag", "Alexandru", "", "Institute for logic, Language and Computation.\n  University of Amsterdam"], ["Gierasimczuk", "Nina", "", "Institute for Logic, Language\n  and Computation. University of Amsterdam"], ["Smets", "Sonja", "", "Institute for Logic,\n  Language and Computation. University of Amsterdam"]]}, {"id": "1606.07520", "submitter": "EPTCS", "authors": "Peter Fritz (University of Oslo), Harvey Lederman (New York\n  University)", "title": "Standard State Space Models of Unawareness (Extended Abstract)", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 141-158", "doi": "10.4204/EPTCS.215.11", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impossibility theorem of Dekel, Lipman and Rustichini has been thought to\ndemonstrate that standard state-space models cannot be used to represent\nunawareness. We first show that Dekel, Lipman and Rustichini do not establish\nthis claim. We then distinguish three notions of awareness, and argue that\nalthough one of them may not be adequately modeled using standard state spaces,\nthere is no reason to think that standard state spaces cannot provide models of\nthe other two notions. In fact, standard space models of these forms of\nawareness are attractively simple. They allow us to prove completeness and\ndecidability results with ease, to carry over standard techniques from decision\ntheory, and to add propositional quantifiers straightforwardly.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:31:42 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Fritz", "Peter", "", "University of Oslo"], ["Lederman", "Harvey", "", "New York\n  University"]]}, {"id": "1606.07522", "submitter": "EPTCS", "authors": "Patrick Girard, Marcus Anthony Triplett", "title": "Ceteris paribus logic in counterfactual reasoning", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 176-193", "doi": "10.4204/EPTCS.215.13", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantics for counterfactuals due to David Lewis has been challenged on\nthe basis of unlikely, or impossible, events. Such events may skew a given\nsimilarity order in favour of those possible worlds which exhibit them. By\nupdating the relational structure of a model according to a ceteris paribus\nclause one forces out, in a natural manner, those possible worlds which do not\nsatisfy the requirements of the clause. We develop a ceteris paribus logic for\ncounterfactual reasoning capable of performing such actions, and offer several\nalternative (relaxed) interpretations of ceteris paribus. We apply this\nframework in a way which allows us to reason counterfactually without having\nour similarity order skewed by unlikely events. This continues the\ninvestigation of formal ceteris paribus reasoning, which has previously been\napplied to preferences, logics of game forms, and questions in decision-making,\namong other areas.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:05 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Girard", "Patrick", ""], ["Triplett", "Marcus Anthony", ""]]}, {"id": "1606.07524", "submitter": "EPTCS", "authors": "Chanjuan Liu", "title": "Preference at First Sight", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 207-226", "doi": "10.4204/EPTCS.215.15", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider decision-making and game scenarios in which an agent is limited\nby his/her computational ability to foresee all the available moves towards the\nfuture - that is, we study scenarios with short sight. We focus on how short\nsight affects the logical properties of decision making in multi-agent\nsettings. We start with single-agent sequential decision making (SSDM)\nprocesses, modeling them by a new structure of \"preference-sight trees\". Using\nthis model, we first explore the relation between a new natural solution\nconcept of Sight-Compatible Backward Induction (SCBI) and the histories\nproduced by classical Backward Induction (BI). In particular, we find necessary\nand sufficient conditions for the two analyses to be equivalent. Next, we study\nwhether larger sight always contributes to better outcomes. Then we develop a\nsimple logical special-purpose language to formally express some key properties\nof our preference-sight models. Lastly, we show how short-sight SSDM scenarios\ncall for substantial enrichments of existing fixed-point logics that have been\ndeveloped for the classical BI solution concept. We also discuss changes in\nearlier modal logics expressing \"surface reasoning\" about best actions in the\npresence of short sight. Our analysis may point the way to logical and\ncomputational analysis of more realistic game models.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:31 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Liu", "Chanjuan", ""]]}, {"id": "1606.07525", "submitter": "EPTCS", "authors": "Yoram Moses", "title": "Relating Knowledge and Coordinated Action: The Knowledge of\n  Preconditions Principle", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 231-245", "doi": "10.4204/EPTCS.215.17", "report-no": null, "categories": "cs.MA cs.AI cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Knowledge of Preconditions principle (KoP) is proposed as a widely\napplicable connection between knowledge and action in multi-agent systems.\nRoughly speaking, it asserts that if some condition is a necessary condition\nfor performing a given action A, then knowing that this condition holds is also\na necessary condition for performing A. Since the specifications of tasks often\ninvolve necessary conditions for actions, the KoP principle shows that such\nspecifications induce knowledge preconditions for the actions. Distributed\nprotocols or multi-agent plans that satisfy the specifications must ensure that\nthis knowledge be attained, and that it is detected by the agents as a\ncondition for action. The knowledge of preconditions principle is formalised in\nthe runs and systems framework, and is proven to hold in a wide class of\nsettings. Well-known connections between knowledge and coordinated action are\nextended and shown to derive directly from the KoP principle: a \"common\nknowledge of preconditions\" principle is established showing that common\nknowledge is a necessary condition for performing simultaneous actions, and a\n\"nested knowledge of preconditions\" principle is proven, showing that\ncoordinating actions to be performed in linear temporal order requires a\ncorresponding form of nested knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:41 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Moses", "Yoram", ""]]}, {"id": "1606.07526", "submitter": "EPTCS", "authors": "Iris van de Pol (University of Amsterdam, ILLC), Iris van Rooij\n  (Radboud University Nijmegen, Donders Institute for Brain, Cognition and\n  Behaviour), Jakub Szymanik (University of Amsterdam, ILLC)", "title": "Parameterized Complexity Results for a Model of Theory of Mind Based on\n  Dynamic Epistemic Logic", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 246-263", "doi": "10.4204/EPTCS.215.18", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a computational-level model of theory of mind\n(ToM) based on dynamic epistemic logic (DEL), and we analyze its computational\ncomplexity. The model is a special case of DEL model checking. We provide a\nparameterized complexity analysis, considering several aspects of DEL (e.g.,\nnumber of agents, size of preconditions, etc.) as parameters. We show that\nmodel checking for DEL is PSPACE-hard, also when restricted to single-pointed\nmodels and S5 relations, thereby solving an open problem in the literature. Our\napproach is aimed at formalizing current intractability claims in the cognitive\nscience literature regarding computational models of ToM.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:51 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["van de Pol", "Iris", "", "University of Amsterdam, ILLC"], ["van Rooij", "Iris", "", "Radboud University Nijmegen, Donders Institute for Brain, Cognition and\n  Behaviour"], ["Szymanik", "Jakub", "", "University of Amsterdam, ILLC"]]}, {"id": "1606.07527", "submitter": "EPTCS", "authors": "Hans van Ditmarsch, Sophia Knight, Ayb\\\"uke \\\"Ozg\\\"un", "title": "Announcement as effort on topological spaces", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 283-297", "doi": "10.4204/EPTCS.215.20", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-agent logic of knowledge, public and arbitrary\nannouncements, that is interpreted on topological spaces in the style of subset\nspace semantics. The arbitrary announcement modality functions similarly to the\neffort modality in subset space logics, however, it comes with intuitive and\nsemantic differences. We provide axiomatizations for three logics based on this\nsetting, and demonstrate their completeness.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:33:09 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["van Ditmarsch", "Hans", ""], ["Knight", "Sophia", ""], ["\u00d6zg\u00fcn", "Ayb\u00fcke", ""]]}, {"id": "1606.07528", "submitter": "EPTCS", "authors": "Quan Yu (Sun Yat-sen University, Qiannan Normal College for\n  Nationalities), Yanjun Li (Peking University, University of Groningen),\n  Yanjing Wang (Peking University)", "title": "A Dynamic Epistemic Framework for Conformant Planning", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 298-318", "doi": "10.4204/EPTCS.215.21", "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a lightweight dynamic epistemic logical framework\nfor automated planning under initial uncertainty. We reduce plan verification\nand conformant planning to model checking problems of our logic. We show that\nthe model checking problem of the iteration-free fragment is PSPACE-complete.\nBy using two non-standard (but equivalent) semantics, we give novel model\nchecking algorithms to the full language and the iteration-free language.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:33:19 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Yu", "Quan", "", "Sun Yat-sen University, Qiannan Normal College for\n  Nationalities"], ["Li", "Yanjun", "", "Peking University, University of Groningen"], ["Wang", "Yanjing", "", "Peking University"]]}, {"id": "1606.07886", "submitter": "Vivek Nigam", "authors": "Max Kanovich, Tajana Ban Kirigin, Vivek Nigam, Andre Scedrov, Carolyn\n  Talcott", "title": "Timed Multiset Rewriting and the Verification of Time-Sensitive\n  Distributed Systems", "comments": "Updated version with corrected proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-Sensitive Distributed Systems (TSDS), such as applications using\nautonomous drones, achieve goals under possible environment interference (\\eg,\nwinds). Moreover, goals are often specified using explicit time constraints\nwhich must be satisfied by the system \\emph{perpetually}. For example, drones\ncarrying out the surveillance of some area must always have \\emph{recent\npictures}, \\ie, at most $M$ time units old, of some strategic locations. This\npaper proposes a Multiset Rewriting language with explicit time for specifying\nand analysing TSDSes. We introduce two properties, \\emph{realizability} (some\ntrace is good) and \\emph{survivability} (where, in addition, all admissible\ntraces are good). A good trace is an infinite trace in which goals are\nperpetually satisfied. We propose a class of systems called \\emph{progressive\ntimed systems} (PTS), where intuitively only a finite number of actions can be\ncarried out in a bounded time period. We prove that for this class of systems\nboth the realizability and the survivability problems are PSPACE-complete.\nFurthermore, if we impose a bound on time (as in bounded model-checking), we\nshow that for PTS, realizability becomes NP-complete, while survivability is in\nthe $\\Delta_2^p$ class of the polynomial hierarchy. Finally, we demonstrate\nthat the rewriting logic system Maude can be used to automate time bounded\nverification of PTS.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 08:55:19 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 09:45:04 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Kanovich", "Max", ""], ["Kirigin", "Tajana Ban", ""], ["Nigam", "Vivek", ""], ["Scedrov", "Andre", ""], ["Talcott", "Carolyn", ""]]}, {"id": "1606.08116", "submitter": "Yong Li", "authors": "Yong Li and Lei Song and Yuan Feng and Lijun Zhang", "title": "Verify LTL with Fairness Assumptions Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with model checking problems with respect to LTL properties\nunder fairness assumptions. We first present an efficient algorithm to deal\nwith a fragment of fairness assumptions and then extend the algorithm to handle\narbitrary %fairness assumptions ones. Notably, by making use of some syntactic\ntransformations, our algorithm avoids to construct corresponding B\\\"uchi\nautomata for the whole fairness assumptions, which can be very large in\npractice. We implement our algorithm in NuSMV and consider a large selection of\nformulas. Our experiments show that in many cases our approach exceeds the\nautomata-theoretic approach up to several orders of magnitude, in both time and\nmemory.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 02:57:21 GMT"}, {"version": "v2", "created": "Wed, 10 Aug 2016 13:22:52 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Li", "Yong", ""], ["Song", "Lei", ""], ["Feng", "Yuan", ""], ["Zhang", "Lijun", ""]]}, {"id": "1606.08130", "submitter": "Bart Bogaerts", "authors": "Bart Bogaerts, Eugenia Ternovska, David Mitchell", "title": "Propagators and Solvers for the Algebra of Modular Systems", "comments": "To appear in the proceedings of LPAR 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear in the proceedings of LPAR 21.\n  Solving complex problems can involve non-trivial combinations of distinct\nknowledge bases and problem solvers. The Algebra of Modular Systems is a\nknowledge representation framework that provides a method for formally\nspecifying such systems in purely semantic terms. Formally, an expression of\nthe algebra defines a class of structures. Many expressive formalism used in\npractice solve the model expansion task, where a structure is given on the\ninput and an expansion of this structure in the defined class of structures is\nsearched (this practice overcomes the common undecidability problem for\nexpressive logics). In this paper, we construct a solver for the model\nexpansion task for a complex modular systems from an expression in the algebra\nand black-box propagators or solvers for the primitive modules. To this end, we\ndefine a general notion of propagators equipped with an explanation mechanism,\nan extension of the alge- bra to propagators, and a lazy conflict-driven\nlearning algorithm. The result is a framework for seamlessly combining solving\ntechnology from different domains to produce a solver for a combined system.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 05:53:57 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 07:50:50 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Bogaerts", "Bart", ""], ["Ternovska", "Eugenia", ""], ["Mitchell", "David", ""]]}, {"id": "1606.08280", "submitter": "Christoph Matheja", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja", "title": "Inferring Covariances for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study weakest precondition reasoning about the (co)variance of outcomes\nand the variance of run-times of probabilistic programs with conditioning. For\noutcomes, we show that approximating (co)variances is computationally more\ndifficult than approximating expected values. In particular, we prove that\ncomputing both lower and upper bounds for (co)variances is\n$\\Sigma^{0}_{2}$-complete. As a consequence, neither lower nor upper bounds are\ncomputably enumerable. We therefore present invariant-based techniques that do\nenable enumeration of both upper and lower bounds, once appropriate invariants\nare found. Finally, we extend this approach to reasoning about run-time\nvariances.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 13:56:56 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Matheja", "Christoph", ""]]}, {"id": "1606.08333", "submitter": "Hans van Ditmarsch", "authors": "Thomas {\\AA}gotnes, Hans van Ditmarsch, Yanjing Wang", "title": "True Lies", "comments": null, "journal-ref": null, "doi": "10.1007/s11229-017-1423-y", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A true lie is a lie that becomes true when announced. In a logic of\nannouncements, where the announcing agent is not modelled, a true lie is a\nformula (that is false and) that becomes true when announced. We investigate\ntrue lies and other types of interaction between announced formulas, their\npreconditions and their postconditions, in the setting of Gerbrandy's logic of\nbelieved announcements, wherein agents may have or obtain incorrect beliefs.\nOur results are on the satisfiability and validity of instantiations of these\nsemantically defined categories, on iterated announcements, including\narbitrarily often iterated announcements, and on syntactic characterization. We\nclose with results for iterated announcements in the logic of knowledge\n(instead of belief), and for lying as private announcements (instead of public\nannouncements) to different agents. Detailed examples illustrate our lying\nconcepts.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 15:59:32 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 16:08:35 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["\u00c5gotnes", "Thomas", ""], ["van Ditmarsch", "Hans", ""], ["Wang", "Yanjing", ""]]}, {"id": "1606.08660", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic and Wannes Meert and Hendrik Blockeel", "title": "Theory reconstruction: a representation learning view on predicate\n  invention", "comments": "3 pages, StaRAI 2016 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With this positional paper we present a representation learning view on\npredicate invention. The intention of this proposal is to bridge the relational\nand deep learning communities on the problem of predicate invention. We propose\na theory reconstruction approach, a formalism that extends autoencoder approach\nto representation learning to the relational settings. Our intention is to\nstart a discussion to define a unifying framework for predicate invention and\ntheory revision.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 11:41:03 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 11:29:35 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Meert", "Wannes", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1606.08668", "submitter": "Jian Liu", "authors": "Ying Jiang and Jian Liu and Gilles Dowek and Kailiang Ji", "title": "SCTL: Towards Combining Model Checking and Proof Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking and automated theorem proving are two pillars of formal\nmethods. This paper investigates model checking from an automated theorem\nproving perspective, aiming at combining the expressiveness of automated\ntheorem proving and the complete automaticity of model checking. The focus of\nthis paper is on the verification of temporal logic properties of Kripke\nmodels. The main contributions of this paper are: first the definition of an\nextended computation tree logic that allows polyadic predicate symbols, then a\nproof system for this logic, taking Kripke models as parameters, then, the\ndesign of a proof-search algorithm for this calculus and a new automated\ntheorem prover to implement it. The verification process is completely\nautomatic, and produces either a counterexample when the property does not\nhold, or a certificate when it does. The experimental result compares well to\nexisting state-of-the-art tools on some benchmarks, including an application to\nair traffic control and the design choices that lead to this efficiency are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 12:15:43 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 05:30:57 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Jiang", "Ying", ""], ["Liu", "Jian", ""], ["Dowek", "Gilles", ""], ["Ji", "Kailiang", ""]]}, {"id": "1606.08699", "submitter": "Eric Hehner", "authors": "Eric C. R. Hehner", "title": "How to Compute Halting", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A consistently specified halting function may be computed.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 19:38:10 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Hehner", "Eric C. R.", ""]]}, {"id": "1606.08703", "submitter": "Eric Hehner", "authors": "Eric C. R. Hehner", "title": "Observations on the Halting Problem", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Halting Problem is ill-conceived and ill-defined.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 19:44:20 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Hehner", "Eric C. R.", ""]]}, {"id": "1606.08707", "submitter": "Marie Fortin", "authors": "Marie Fortin, Anca Muscholl, Igor Walukiewicz", "title": "On parametrized verification of asynchronous, shared-memory pushdown\n  systems", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of parametrized asynchronous shared-memory pushdown\nsystems, as introduced in [Hague'11]. In a series of recent papers it has been\nshown that reachability in this model is PSPACE-complete [Esparza, Ganty,\nMajumdar'13] and that liveness is decidable in NEXPTIME [Durand-Gasselin,\nEsparza, Ganty, Majumdar'15]. We show here that the liveness problem is\nPSPACE-complete. We also introduce the universal reachability problem. We show\nthat it is decidable, and coNEXPTIME-complete. Finally, using these results, we\nprove that the verifying regular properties of traces of executions, satisfying\nsome stuttering condition, is also decidable in NEXPTIME for this model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 13:58:20 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 20:01:37 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Fortin", "Marie", ""], ["Muscholl", "Anca", ""], ["Walukiewicz", "Igor", ""]]}, {"id": "1606.08722", "submitter": "Eric Hehner", "authors": "Eric C. R. Hehner", "title": "Epimenides, G\\\"odel, Turing: an Eternal G\\\"olden Tangle", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Halting Problem is a version of the Liar's Paradox.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 19:33:39 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Hehner", "Eric C. R.", ""]]}, {"id": "1606.08815", "submitter": "EPTCS", "authors": "R van der Meyden (UNSW Australia), M K Patra (UNSW Australia)", "title": "Undecidable Cases of Model Checking Probabilistic Temporal-Epistemic\n  Logic (Extended Abstract)", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 264-282", "doi": "10.4204/EPTCS.215.19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the decidability of model-checking logics of time, knowledge\nand probability, with respect to two epistemic semantics: the clock and\nsynchronous perfect recall semantics in partially observed discrete-time Markov\nchains. Decidability results are known for certain restricted logics with\nrespect to these semantics, subject to a variety of restrictions that are\neither unexplained or involve a longstanding unsolved mathematical problem. We\nshow that mild generalizations of the known decidable cases suffice to render\nthe model checking problem definitively undecidable. In particular, for a\nsynchronous perfect recall, a generalization from temporal operators with\nfinite reach to operators with infinite reach renders model checking\nundecidable. The case of the clock semantics is closely related to a monadic\nsecond order logic of time and probability that is known to be decidable,\nexcept on a set of measure zero. We show that two distinct extensions of this\nlogic make model checking undecidable. One of these involves polynomial\ncombinations of probability terms, the other involves monadic second order\nquantification into the scope of probability operators. These results explain\nsome of the restrictions in previous work.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:33:00 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["van der Meyden", "R", "", "UNSW Australia"], ["Patra", "M K", "", "UNSW Australia"]]}, {"id": "1606.09016", "submitter": "EPTCS", "authors": "Matteo Acclavio", "title": "Proof Diagrams for Multiplicative Linear Logic", "comments": "In Proceedings LINEARITY 2016, arXiv:1701.04522", "journal-ref": "EPTCS 238, 2017, pp. 11-23", "doi": "10.4204/EPTCS.238.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original idea of proof nets can be formulated by means of interaction\nnets syntax. Additional machinery as switching, jumps and graph connectivity is\nneeded in order to ensure correspondence between a proof structure and a\ncorrect proof in sequent calculus.\n  In this paper we give an interpretation of proof nets in the syntax of string\ndiagrams. Even though we lose standard proof equivalence, our construction\nallows to define a framework where soundness and well-typeness of a diagram can\nbe verified in linear time.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 09:27:11 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 12:45:54 GMT"}, {"version": "v3", "created": "Wed, 18 Jan 2017 01:29:46 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Acclavio", "Matteo", ""]]}, {"id": "1606.09035", "submitter": "Lars Luthmann M.Sc.", "authors": "Lars Luthmann (1), Stephan Mennicke (2), Malte Lochau (1) ((1)\n  Real-Time Systems Lab, TU Darmstadt, (2) Institute for Programming and\n  Reactive Systems, TU Braunschweig)", "title": "Compositionality, Decompositionality and Refinement in Input/Output\n  Conformance Testing - Technical Report", "comments": "36 pages, 14 figures", "journal-ref": null, "doi": "10.1007/978-3-319-57666-4_5", "report-no": null, "categories": "cs.LO cs.FL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an input/output conformance testing theory utilizing Modal\nInterface Automata with Input Refusals (IR-MIA) as novel behavioral formalism\nfor both the specification and the implementation under test. A modal\nrefinement relation on IR-MIA allows distinguishing between obligatory and\nallowed output behaviors, as well as between implicitly underspecified and\nexplicitly forbidden input behaviors. The theory therefore supports positive\nand negative conformance testing with optimistic and pessimistic environmental\nassumptions. We further show that the resulting conformance relation on IR-MIA,\ncalled modal-irioco, enjoys many desirable properties concerning\ncomponent-based behaviors. First, modal-irioco is preserved under modal\nrefinement and constitutes a preorder under certain restrictions which can be\nensured by a canonical input completion for IR-MIA. Second, under the same\nrestrictions, modal-irioco is compositional with respect to parallel\ncomposition of IR-MIA with multi-cast and hiding. Finally, the quotient\noperator on IR-MIA, as the inverse to parallel composition, facilitates\ndecompositionality in conformance testing to solve the unknown-component\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 10:29:45 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 12:01:09 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2016 11:57:37 GMT"}, {"version": "v4", "created": "Sun, 16 Oct 2016 14:17:59 GMT"}, {"version": "v5", "created": "Fri, 23 Jun 2017 14:35:54 GMT"}, {"version": "v6", "created": "Fri, 13 Oct 2017 07:59:26 GMT"}, {"version": "v7", "created": "Thu, 14 Feb 2019 09:12:48 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Luthmann", "Lars", ""], ["Mennicke", "Stephan", ""], ["Lochau", "Malte", ""]]}, {"id": "1606.09110", "submitter": "J\\\"urgen Koslowski", "authors": "Konstantinos Mamouras (University of Pennsylvania)", "title": "Synthesis of Strategies Using the Hoare Logic of Angelic and Demonic\n  Nondeterminism", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 3 (April 27,\n  2017) lmcs:2017", "doi": "10.2168/LMCS-12(3:6)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a propositional variant of Hoare logic that can be used for\nreasoning about programs that exhibit both angelic and demonic nondeterminism.\nWe work in an uninterpreted setting, where the meaning of the atomic actions is\nspecified axiomatically using hypotheses of a certain form. Our logical\nformalism is entirely compositional and it subsumes the non-compositional\nformalism of safety games on finite graphs. We present sound and complete\nHoare-style calculi that are useful for establishing partial-correctness\nassertions, as well as for synthesizing implementations. The computational\ncomplexity of the Hoare theory of dual nondeterminism is investigated using\noperational models, and it is shown that the theory is complete for exponential\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 14:13:00 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 18:54:30 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Mamouras", "Konstantinos", "", "University of Pennsylvania"]]}, {"id": "1606.09399", "submitter": "Ichiro Hasuo", "authors": "Natsuki Urabe and Shunsuke Shimizu and Ichiro Hasuo", "title": "Coalgebraic Trace Semantics for Buechi and Parity Automata", "comments": "A preprint version of the paper to appear in CONCUR 2016; with\n  appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its success in producing numerous general results on state-based\ndynamics, the theory of coalgebra has struggled to accommodate the Buechi\nacceptance condition---a basic notion in the theory of automata for infinite\nwords or trees. In this paper we present a clean answer to the question that\nbuilds on the \"maximality\" characterization of infinite traces (by Jacobs and\nCirstea): the accepted language of a Buechi automaton is characterized by two\ncommuting diagrams, one for a least homomorphism and the other for a greatest,\nmuch like in a system of (least and greatest) fixed-point equations. This\ncharacterization works uniformly for the nondeterministic branching and the\nprobabilistic one; and for words and trees alike. We present our results in\nterms of the parity acceptance condition that generalizes Buechi's.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 09:11:28 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Urabe", "Natsuki", ""], ["Shimizu", "Shunsuke", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1606.09455", "submitter": "J\\\"urgen Koslowski", "authors": "Ranald Clouston, Ale\\v{s} Bizjak, Hans Bugge Grathwohl, Lars Birkedal\n  (Aarhus University, Denmark)", "title": "The Guarded Lambda-Calculus: Programming and Reasoning with Guarded\n  Recursion for Coinductive Types", "comments": "Accepted to Logical Methods in Computer Science special issue on the\n  18th International Conference on Foundations of Software Science and\n  Computation Structures (FoSSaCS 2015)", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 3 (April 27,\n  2017) lmcs:2019", "doi": "10.2168/LMCS-12(3:7)2016", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the guarded lambda-calculus, an extension of the simply typed\nlambda-calculus with guarded recursive and coinductive types. The use of\nguarded recursive types ensures the productivity of well-typed programs.\nGuarded recursive types may be transformed into coinductive types by a\ntype-former inspired by modal logic and Atkey-McBride clock quantification,\nallowing the typing of acausal functions. We give a call-by-name operational\nsemantics for the calculus, and define adequate denotational semantics in the\ntopos of trees. The adequacy proof entails that the evaluation of a program\nalways terminates. We introduce a program logic with L\\\"ob induction for\nreasoning about the contextual equivalence of programs. We demonstrate the\nexpressiveness of the calculus by showing the definability of solutions to\nRutten's behavioural differential equations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 12:22:29 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 17:56:25 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Clouston", "Ranald", "", "Aarhus University, Denmark"], ["Bizjak", "Ale\u0161", "", "Aarhus University, Denmark"], ["Grathwohl", "Hans Bugge", "", "Aarhus University, Denmark"], ["Birkedal", "Lars", "", "Aarhus University, Denmark"]]}, {"id": "1606.09521", "submitter": "Rafael Pe\\~naloza", "authors": "Rafael Pe\\~naloza, Nico Potyka", "title": "Probabilistic Reasoning in the Description Logic ALCP with the Principle\n  of Maximum Entropy (Full Version)", "comments": "Full version of paper accepted at the Tenth International Conference\n  on Scalable Uncertainty Management (SUM 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question for knowledge representation is how to encode and handle\nuncertain knowledge adequately. We introduce the probabilistic description\nlogic ALCP that is designed for representing context-dependent knowledge, where\nthe actual context taking place is uncertain. ALCP allows the expression of\nlogical dependencies on the domain and probabilistic dependencies on the\npossible contexts. In order to draw probabilistic conclusions, we employ the\nprinciple of maximum entropy. We provide reasoning algorithms for this logic,\nand show that it satisfies several desirable properties of probabilistic\nlogics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 14:49:01 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Pe\u00f1aloza", "Rafael", ""], ["Potyka", "Nico", ""]]}, {"id": "1606.09638", "submitter": "Carlo Angiuli", "authors": "Carlo Angiuli, Robert Harper", "title": "Computational Higher Type Theory II: Dependent Cubical Realizability", "comments": "65 pages. v2: added sections A.1, A.2. v3: added sections A.3, A.4.\n  arXiv admin note: text overlap with arXiv:1604.08873", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the second in a series of papers extending Martin-L\\\"{o}f's meaning\nexplanation of dependent type theory to account for higher-dimensional types.\nWe build on the cubical realizability framework for simple types developed in\nPart I, and extend it to a meaning explanation of dependent higher-dimensional\ntype theory. This extension requires generalizing the computational Kan\ncondition given in Part I, and considering the action of type families on\npaths. We define identification types, which classify identifications (paths)\nin a type, and dependent function and pair types. The main result is a\ncanonicity theorem, which states that a closed term of boolean type evaluates\nto either true or false. This result establishes the first computational\ninterpretation of higher dependent type theory by giving a deterministic\noperational semantics for its programs, including operations that realize the\nKan condition.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 19:52:43 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 23:00:56 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 18:19:23 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Angiuli", "Carlo", ""], ["Harper", "Robert", ""]]}]