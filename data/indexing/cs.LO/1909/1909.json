[{"id": "1909.00216", "submitter": "Francesco Giannini", "authors": "Francesco Giannini and Marco Maggini", "title": "Conditions for Unnecessary Logical Constraints in Kernel Machines", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30484-3_49", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main property of support vector machines consists in the fact that only a\nsmall portion of the training data is significant to determine the maximum\nmargin separating hyperplane in the feature space, the so called support\nvectors. In a similar way, in the general scheme of learning from constraints,\nwhere possibly several constraints are considered, some of them may turn out to\nbe unnecessary with respect to the learning optimization, even if they are\nactive for a given optimal solution. In this paper we extend the definition of\nsupport vector to support constraint and we provide some criteria to determine\nwhich constraints can be removed from the learning problem still yielding the\nsame optimal solutions. In particular, we discuss the case of logical\nconstraints expressed by Lukasiewicz logic, where both inferential and\nalgebraic arguments can be considered. Some theoretical results that\ncharacterize the concept of unnecessary constraint are proved and explained by\nmeans of examples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 14:00:04 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 13:38:07 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Giannini", "Francesco", ""], ["Maggini", "Marco", ""]]}, {"id": "1909.00286", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Justness: A Completeness Criterion for Capturing Liveness Properties", "comments": "An extended abstract of this paper appears in Proc. FoSSaCS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper poses that transition systems constitute a good model of\ndistributed systems only in combination with a criterion telling which paths\nmodel complete runs of the represented systems. Among such criteria, progress\nis too weak to capture relevant liveness properties, and fairness is often too\nstrong; for typical applications we advocate the intermediate criterion of\njustness. Previously, we proposed a definition of justness in terms of an\nasymmetric concurrency relation between transitions. Here we define such a\nconcurrency relation for the transition systems associated to the process\nalgebra CCS as well as its extensions with broadcast communication and signals,\nthereby making these process algebras suitable for capturing liveness\nproperties requiring justness.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 21:07:14 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1909.00436", "submitter": "Agathoklis Kritsimallis", "authors": "Agathoklis Kritsimallis, Ioannis Refanidis", "title": "ExpTime Tableaux for Type PDL", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The system of Type PDL ($\\tau$PDL) is an extension of Propositional Dynamic\nLogic (PDL) and its main goal is to provide a formal basis for reasoning about\ntypes of actions (modeled by their preconditions and effects) and agent\ncapabilities. The system has two equivalent interpretations, namely the\nstandard relational semantics and the type semantics, where process terms are\ninterpreted as types, i.e. sets of binary relations. Its satisfiability problem\nis decidable, as a NExpTime decision procedure was provided based on a\nfiltration argument and it was suggested that the satisfiability problem for\n$\\tau$PDL should be solvable in deterministic, single exponential time. In this\npaper, we address the problem of the complexity of the satisfiability problem\nof $\\tau$PDL. We present a deterministic tableau-based satisfiability algorithm\nand prove that it is sound and complete and that it runs in ExpTime.\nAdditionally, the algorithm detects satisfiability as earlier as possible, by\nrestricting or-branching whenever possible.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 17:31:29 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kritsimallis", "Agathoklis", ""], ["Refanidis", "Ioannis", ""]]}, {"id": "1909.00520", "submitter": "Sam Buss", "authors": "Sam Buss and Neil Thapen", "title": "DRAT and Propagation Redundancy Proofs Without New Variables", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 23,\n  2021) lmcs:7400", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the complexity of a range of propositional proof systems which allow\ninference rules of the form: from a set of clauses $\\Gamma$ derive the set of\nclauses $\\Gamma \\cup \\{ C \\}$ where, due to some syntactic condition, $\\Gamma\n\\cup \\{ C \\}$ is satisfiable if $\\Gamma$ is, but where $\\Gamma$ does not\nnecessarily imply $C$. These inference rules include BC, RAT, SPR and PR\n(respectively short for blocked clauses, resolution asymmetric tautologies,\nsubset propagation redundancy and propagation redundancy), which arose from\nwork in satisfiability (SAT) solving. We introduce a new, more general rule SR\n(substitution redundancy).\n  If the new clause $C$ is allowed to include new variables then the systems\nbased on these rules are all equivalent to extended resolution. We focus on\nrestricted systems that do not allow new variables. The systems with deletion,\nwhere we can delete a clause from our set at any time, are denoted DBC${}^-$,\nDRAT${}^-$, DSPR${}^-$, DPR${}^-$ and DSR${}^-$. The systems without deletion\nare BC${}^-$, RAT${}^-$, SPR${}^-$, PR${}^-$ and SR${}^-$.\n  With deletion, we show that DRAT${}^-$, DSPR${}^-$ and DPR${}^-$ are\nequivalent. By earlier work of Kiesl, Rebola-Pardo and Heule, they are also\nequivalent to DBC${}^-$. Without deletion, we show that SPR${}^-$ can simulate\nPR${}^-$ provided only short clauses are inferred by SPR inferences. We also\nshow that many of the well-known \"hard\" principles have small SPR${}^-$\nrefutations. These include the pigeonhole principle, bit pigeonhole principle,\nparity principle, Tseitin tautologies and clique-coloring tautologies.\nSPR${}^-$ can also handle or-fication and xor-ification, and lifting with an\nindex gadget. Our final result is an exponential size lower bound for RAT${}^-$\nrefutations, giving exponential separations between RAT${}^-$ and both\nDRAT${}^-$ and SPR${}^-$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:11:40 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 21:22:36 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 23:08:22 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 18:03:24 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 18:28:32 GMT"}, {"version": "v6", "created": "Thu, 22 Apr 2021 13:07:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Buss", "Sam", ""], ["Thapen", "Neil", ""]]}, {"id": "1909.00584", "submitter": "EPTCS", "authors": "Mircea Marin (West University of Timi\\c{s}oara), Adrian Cr\\u{a}ciun\n  (West University of Timi\\c{s}oara)", "title": "Proceedings Third Symposium on Working Formal Methods", "comments": null, "journal-ref": "EPTCS 303, 2019", "doi": "10.4204/EPTCS.303", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of FROM 2019: the Third Symposium on\nWorking Formal Methods, held on September 3-5, 2019 in Timi\\c{s}oara (Romania).\nFROM aims to bring together researchers and practitioners who work on formal\nmethods by contributing new theoretical results, methods, techniques, and\nframeworks, and/or make the formal methods to work by creating or using\nsoftware tools that apply theoretical contributions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 07:49:49 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Marin", "Mircea", "", "West University of Timi\u015foara"], ["Cr\u0103ciun", "Adrian", "", "West University of Timi\u015foara"]]}, {"id": "1909.00668", "submitter": "Daniel Murfet", "authors": "James Clift, Dmitry Doryn, Daniel Murfet, James Wallbridge", "title": "Logic and the $2$-Simplicial Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the $2$-simplicial Transformer, an extension of the Transformer\nwhich includes a form of higher-dimensional attention generalising the\ndot-product attention, and uses this attention to update entity representations\nwith tensor products of value vectors. We show that this architecture is a\nuseful inductive bias for logical reasoning in the context of deep\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 11:11:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Clift", "James", ""], ["Doryn", "Dmitry", ""], ["Murfet", "Daniel", ""], ["Wallbridge", "James", ""]]}, {"id": "1909.00989", "submitter": "Andreas Pavlogiannis", "authors": "Krishnendu Chatterjee and Andreas Pavlogiannis and Viktor Toman", "title": "Value-centric Dynamic Partial Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification of concurrent programs remains an open challenge, as thread\ninteraction has to be accounted for, which leads to state-space explosion.\nStateless model checking battles this problem by exploring traces rather than\nstates of the program. As there are exponentially many traces, dynamic\npartial-order reduction (DPOR) techniques are used to partition the trace space\ninto equivalence classes, and explore a few representatives from each class.\nThe standard equivalence that underlies most DPOR techniques is the\nhappens-before equivalence, however recent works have spawned a vivid interest\ntowards coarser equivalences. The efficiency of such approaches is a product of\ntwo parameters: (i) the size of the partitioning induced by the equivalence,\nand (ii) the time spent by the exploration algorithm in each class of the\npartitioning.\n  In this work, we present a new equivalence, called value-happens-before and\nshow that it has two appealing features. First, value-happens-before is always\nat least as coarse as the happens-before equivalence, and can be even\nexponentially coarser. Second, the value-happens-before partitioning is\nefficiently explorable when the number of threads is bounded. We present an\nalgorithm called value-centric DPOR (VCDPOR), which explores the underlying\npartitioning using polynomial time per class. Finally, we perform an\nexperimental evaluation of VCDPOR on various benchmarks, and compare it against\nother state-of-the-art approaches. Our results show that value-happens-before\ntypically induces a significant reduction in the size of the underlying\npartitioning, which leads to a considerable reduction in the running time for\nexploring the whole partitioning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:06:03 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Pavlogiannis", "Andreas", ""], ["Toman", "Viktor", ""]]}, {"id": "1909.01564", "submitter": "Sebastian Siebertz", "authors": "Jaroslav Nesetril, Patrice Ossona de Mendez, Roman Rabinovich,\n  Sebastian Siebertz", "title": "Classes of graphs with low complexity: the case of classes with bounded\n  linear rankwidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classes with bounded rankwidth are MSO-transductions of trees and classes\nwith bounded linear rankwidth are MSO-transductions of paths -- a result that\nshows a strong link between the properties of these graph classes considered\nfrom the point of view of structural graph theory and from the point of view of\nfinite model theory. We take both views on classes with bounded linear\nrankwidth and prove structural and model theoretic properties of these classes.\nThe structural results we obtain are the following.\n  1) The number of unlabeled graphs of order $n$ with linear rank-width at\nmost~$r$ is at most $\\bigl[(r/2)!\\,2^{\\binom{r}{2}}3^{r+2}\\bigr]^n$.\n  2) Graphs with linear rankwidth at most $r$ are linearly $\\chi$-bounded.\nActually, they have bounded $c$-chromatic number, meaning that they can be\ncolored with $f(r)$ colors, each color inducing a cograph.\n  3) To the contrary, based on a Ramsey-like argument, we prove for every\nproper hereditary family $F$ of graphs (like cographs) that there is a class\nwith bounded rankwidth that does not have the property that graphs in it can be\ncolored by a bounded number of colors, each inducing a subgraph in $F$.\n  From the model theoretical side we obtain the following results:\n  1) A direct short proof that graphs with linear rankwidth at most $r$ are\nfirst-order transductions of linear orders. This result could also be derived\nfrom Colcombet's theorem on first-order transduction of linear orders and the\nequivalence of linear rankwidth with linear cliquewidth.\n  2) For a class $C$ with bounded linear rankwidth the following conditions are\nequivalent: a) $C$ is stable, b) $C$ excludes some half-graph as a semi-induced\nsubgraph, c) $C$ is a first-order transduction of a class with bounded\npathwidth.\n  These results open the perspective to study classes admitting low linear\nrankwidth covers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:11:21 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Nesetril", "Jaroslav", ""], ["de Mendez", "Patrice Ossona", ""], ["Rabinovich", "Roman", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1909.01667", "submitter": "Balasubramanian A.R", "authors": "A. R. Balasubramanian", "title": "Complexity of controlled bad sequences over finite sets of\n  $\\mathbb{N}^d$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide upper and lower bounds for the length of controlled bad sequences\nover the majoring and the minoring orderings of finite sets of $\\mathbb{N}^d$.\nThe results are obtained by bounding the length of such sequences by functions\nfrom the Cichon hierarchy. This allows us to translate these results to bounds\nover the fast-growing complexity classes.\n  The obtained bounds are proven to be tight for the majoring ordering, which\nsolves a problem left open by Abriola, Figueira and Senno (Theor. Comp. Sci,\nVol. 603). Finally, we use the results on controlled bad sequences to prove\nupper bounds for the emptiness problem of some classes of automata.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:58:31 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 16:15:01 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 19:59:17 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 10:30:08 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2020 10:21:46 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Balasubramanian", "A. R.", ""]]}, {"id": "1909.01697", "submitter": "J\\'an Komara", "authors": "J\\'an Komara", "title": "Efficient elimination of Skolem functions in $\\text{LK}^{\\text{h}}$", "comments": "31 pages; generalization of main results for calculus with cuts,\n  added section on cut elimination, added discussion on eigenvariable condition", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elimination of a single Skolem function in pure logic increases the length of\nproofs only linearly. The result is shown for derivations with cuts that are\nfree for the Skolem function in a sequent calculus with strong locality\nproperty.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 11:16:40 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 11:06:23 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 15:35:56 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 17:34:09 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Komara", "J\u00e1n", ""]]}, {"id": "1909.01743", "submitter": "EPTCS", "authors": "Cezar-Constantin Andrici (Alexandru Ioan Cuza University), \\c{S}tefan\n  Ciob\\^ac\\u{a} (Alexandru Ioan Cuza University)", "title": "Verifying the DPLL Algorithm in Dafny", "comments": "In Proceedings FROM 2019, arXiv:1909.00584", "journal-ref": "EPTCS 303, 2019, pp. 3-15", "doi": "10.4204/EPTCS.303.1", "report-no": null, "categories": "cs.LO cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern high-performance SAT solvers quickly solve large satisfiability\ninstances that occur in practice. If the instance is satisfiable, then the SAT\nsolver can provide a witness which can be checked independently in the form of\na satisfying truth assignment. However, if the instance is unsatisfiable, the\ncertificates could be exponentially large or the SAT solver might not be able\nto output certificates. The implementation of the SAT solver should then be\ntrusted not to contain bugs. However, the data structures and algorithms\nimplemented by a typical high-performance SAT solver are complex enough to\nallow for subtle programming errors. To counter this issue, we build a verified\nSAT solver using the Dafny system. We discuss its implementation in the present\narticle.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:48:13 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Andrici", "Cezar-Constantin", "", "Alexandru Ioan Cuza University"], ["Ciob\u00e2c\u0103", "\u015etefan", "", "Alexandru Ioan Cuza University"]]}, {"id": "1909.01744", "submitter": "EPTCS", "authors": "Vlad Rusu, David Nowak", "title": "(Co)inductive Proof Systems for Compositional Proofs in Reachability\n  Logic", "comments": "In Proceedings FROM 2019, arXiv:1909.00584", "journal-ref": "EPTCS 303, 2019, pp. 32-47", "doi": "10.4204/EPTCS.303.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reachability Logic is a formalism that can be used, among others, for\nexpressing partial-correctness properties of transition systems. In this paper\nwe present three proof systems for this formalism, all of which are sound and\ncomplete and inherit the coinductive nature of the logic. The proof systems\ndiffer, however, in several aspects. First, they use induction and coinduction\nin different proportions. The second aspect regards compositionality, broadly\nmeaning their ability to prove simpler formulas on smaller systems, and to\nreuse those formulas as lemmas for more complex formulas on larger systems. The\nthird aspect is the difficulty of their soundness proofs. We show that the more\ninduction a proof system uses, and the more specialised is its use of\ncoinduction (with respect to our problem domain), the more compositional the\nproof system is, but the more difficult its soundness proof becomes. We also\nbriefly present mechanisations of these results in the Isabelle/HOL and Coq\nproof assistants.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:48:35 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Rusu", "Vlad", ""], ["Nowak", "David", ""]]}, {"id": "1909.01747", "submitter": "EPTCS", "authors": "Isabela Dr\\u{a}mnesc (Department of Computer Science West University\n  Timisoara, Romania), Tudor Jebelean (Research Institute for Symbolic\n  Computation, Johannes Kepler University, Linz, Austria)", "title": "Proof-Based Synthesis of Sorting Algorithms Using Multisets in Theorema", "comments": "In Proceedings FROM 2019, arXiv:1909.00584", "journal-ref": "EPTCS 303, 2019, pp. 76-91", "doi": "10.4204/EPTCS.303.6", "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using multisets, we develop novel techniques for mechanizing the proofs of\nthe synthesis conjectures for list-sorting algorithms, and we demonstrate them\nin the Theorema system. We use the classical principle of extracting the\nalgorithm as a set of rewrite rules based on the witnesses found in the proof\nof the synthesis conjecture produced from the specification of the desired\nfunction (input and output conditions). The proofs are in natural style, using\nstandard rules, but most importantly domain specific inference rules and\nstrategies. In particular the use of multisets allows us to develop powerful\nstrategies for the synthesis of arbitrarily structured recursive algorithms by\ngeneral Noetherian induction, as well as for the automatic generation of the\nspecifications of all necessary auxiliary functions (insert, merge, split),\nwhose synthesis is performed using the same method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:49:23 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Dr\u0103mnesc", "Isabela", "", "Department of Computer Science West University\n  Timisoara, Romania"], ["Jebelean", "Tudor", "", "Research Institute for Symbolic\n  Computation, Johannes Kepler University, Linz, Austria"]]}, {"id": "1909.01748", "submitter": "EPTCS", "authors": "Bogdan Aman (Romanian Academy, Institute of Computer Science and\n  A.I.Cuza University, Iasi, Romania), Gabriel Ciobanu (A.I.Cuza University and\n  Romanian Academy, Iasi, Romania)", "title": "Probabilities in Session Types", "comments": "In Proceedings FROM 2019, arXiv:1909.00584", "journal-ref": "EPTCS 303, 2019, pp. 92-106", "doi": "10.4204/EPTCS.303.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the probabilistic behaviours of distributed systems\ndescribed by a process calculus considering both probabilistic internal choices\nand nondeterministic external choices. For this calculus we define and study a\ntyping system which extends the multiparty session types in order to deal also\nwith probabilistic behaviours. The calculus and its typing system are motivated\nand illustrated by a running example.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:49:39 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Aman", "Bogdan", "", "Romanian Academy, Institute of Computer Science and\n  A.I.Cuza University, Iasi, Romania"], ["Ciobanu", "Gabriel", "", "A.I.Cuza University and\n  Romanian Academy, Iasi, Romania"]]}, {"id": "1909.01751", "submitter": "EPTCS", "authors": "Andrei Alexandru (Romanian Academy, Institute of Computer Science,\n  Iasi, Romania), Gabriel Ciobanu (A.I.Cuza University and Romanian Academy,\n  Iasi, Romania)", "title": "Finitely Supported Sets Containing Infinite Uniformly Supported Subsets", "comments": "In Proceedings FROM 2019, arXiv:1909.00584", "journal-ref": "EPTCS 303, 2019, pp. 120-134", "doi": "10.4204/EPTCS.303.9", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of finitely supported algebraic structures represents a\nreformulation of Zermelo-Fraenkel set theory in which every construction is\nfinitely supported according to the action of a group of permutations of some\nbasic elements named atoms. In this paper we study the properties of finitely\nsupported sets that contain infinite uniformly supported subsets, as well as\nthe properties of finitely supported sets that do not contain infinite\nuniformly supported subsets. For classical atomic sets, we study whether they\ncontain or not infinite uniformly supported subsets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:50:10 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Alexandru", "Andrei", "", "Romanian Academy, Institute of Computer Science,\n  Iasi, Romania"], ["Ciobanu", "Gabriel", "", "A.I.Cuza University and Romanian Academy,\n  Iasi, Romania"]]}, {"id": "1909.01796", "submitter": "Harsh Beohar", "authors": "Harsh Beohar and Sebastian K\\\"upper", "title": "Bisimulation maps in presheaf categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The category of presheaves on a (small) category is a suitable semantic\nuniverse to study behaviour of various dynamical systems. In particular,\npresheaves can be used to record the executions of a system and their morphisms\ncorrespond to simulation maps for various kinds of state-based systems. In this\npaper, we introduce a notion of bisimulation maps between presheaves (or\nexecutions) to capture well known behavioural equivalences in an abstract way.\nWe demonstrate the versatility of this framework by working out the\ncharacterisations for standard bisimulation, $\\forall$-fair bisimulation, and\nbranching bisimulation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:39:53 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Beohar", "Harsh", ""], ["K\u00fcpper", "Sebastian", ""]]}, {"id": "1909.02259", "submitter": "Heinz-Peter Gumm", "authors": "H. Peter Gumm", "title": "Connected monads weakly preserve products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If $F$ is a (not necessarily associative) monad on $Set$, then the natural\ntransformation $F(A\\times B)\\to F(A)\\times F(B)$ is surjective if and only if\n$F(\\boldsymbol{1})=\\boldsymbol{1}$. Specializing $F$ to $F_{\\mathcal{V}}$, the\nfree algebra functor for a variety $\\mathcal{V}$, this result generalizes and\nclarifies an observation by Dent, Kearnes and Szendrei.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:38:38 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gumm", "H. Peter", ""]]}, {"id": "1909.02579", "submitter": "Michael Blondin", "authors": "Michael Blondin and Mikhail Raskin", "title": "The Complexity of Reachability in Affine Vector Addition Systems with\n  States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vector addition systems with states (VASS) are widely used for the formal\nverification of concurrent systems. Given their tremendous computational\ncomplexity, practical approaches have relied on techniques such as reachability\nrelaxations, e.g., allowing for negative intermediate counter values. It is\nnatural to question their feasibility for VASS enriched with primitives that\ntypically translate into undecidability. Spurred by this concern, we pinpoint\nthe complexity of integer relaxations with respect to arbitrary classes of\naffine operations.\n  More specifically, we provide a trichotomy on the complexity of integer\nreachability in VASS extended with affine operations (affine VASS). Namely, we\nshow that it is NP-complete for VASS with resets, PSPACE-complete for VASS with\n(pseudo-)transfers and VASS with (pseudo-)copies, and undecidable for any other\nclass. We further present a dichotomy for standard reachability in affine VASS:\nit is decidable for VASS with permutations, and undecidable for any other\nclass. This yields a complete and unified complexity landscape of reachability\nin affine VASS. We also consider the reachability problem parameterized by a\nfixed affine VASS, rather than a class, and we show that the complexity\nlandscape is arbitrary in this setting.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:01:22 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 14:54:24 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 19:48:44 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 15:01:48 GMT"}, {"version": "v5", "created": "Mon, 19 Jul 2021 13:00:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blondin", "Michael", ""], ["Raskin", "Mikhail", ""]]}, {"id": "1909.03263", "submitter": "Eric Goubault", "authors": "Eric Goubault and Marijana Lazic and Jeremy Ledent and Sergio Rajsbaum", "title": "A dynamic epistemic logic analysis of the equality negation task", "comments": null, "journal-ref": "Long version of DaLI 2019 conference paper", "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the solvability of the equality negation task in a\nsimple wait-free model where processes communicate by reading and writing\nshared variables or exchanging messages. In this task, two processes start with\na private input value in the set {0,1,2}, and after communicating, each one\nmust decide a binary output value, so that the outputs of the processes are the\nsame if and only if the input values of the processes are different. This task\nis already known to be unsolvable; our goal here is to prove this result using\nthe dynamic epistemic logic (DEL) approach introduced by Goubault, Ledent and\nRajsbaum in GandALF 2018. We show that in fact, there is no epistemic logic\nformula that explains why the task is unsolvable. We fix this issue by\nextending the language of our DEL framework, which allows us to construct such\na formula, and discuss its utility.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 12:45:14 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Goubault", "Eric", ""], ["Lazic", "Marijana", ""], ["Ledent", "Jeremy", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "1909.03703", "submitter": "Lars Luthmann M.Sc.", "authors": "Lars Luthmann (1), Hendrik G\\\"ottmann (1), Malte Lochau (1) ((1)\n  Real-Time Systems Lab, TU Darmstadt)", "title": "Compositional Liveness-Preserving Conformance Testing of Timed I/O\n  Automata -- Technical Report", "comments": "22 pages, 6 figures. Author version of the paper of the same name\n  accepted for the 16th International Conference on Formal Aspects of Component\n  Software (FACS 2019). This version is slightly extended as it contains all\n  proofs", "journal-ref": null, "doi": "10.1007/978-3-030-40914-2_8", "report-no": null, "categories": "cs.LO cs.FL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I/O conformance testing theories (e.g., ioco) are concerned with formally\ndefining when observable output behaviors of an implementation conform to those\npermitted by a specification. Thereupon, several real-time extensions of ioco,\nusually called tioco, have been proposed, further taking into account permitted\ndelays between actions. In this paper, we propose an improved version of tioco,\ncalled live timed ioco (ltioco), tackling various weaknesses of existing\ndefinitions. Here, a reasonable adaptation of quiescence (i.e., observable\nabsence of any outputs) to real-time behaviors has to be done with care: ltioco\ntherefore distinguishes safe outputs being allowed to happen, from live outputs\nbeing enforced to happen within a certain time period thus inducing two\ndifferent facets of quiescence. Furthermore, tioco is frequently defined on\nTimed I/O Labeled Transition Systems (TIOLTS), a semantic model of Timed I/O\nAutomata (TIOA) which is infinitely branching and thus infeasible for practical\ntesting tools. Instead, we extend the theory of zone graphs to enable ltioco\ntesting on a finite semantic model of TIOA. Finally, we investigate\ncompositionality of ltioco with respect to parallel composition including a\nproper treatment of silent transitions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 08:46:13 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 11:14:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Luthmann", "Lars", ""], ["G\u00f6ttmann", "Hendrik", ""], ["Lochau", "Malte", ""]]}, {"id": "1909.03721", "submitter": "Carla Ferreira", "authors": "Filipe Meirim and M\\'ario Pereira and Carla Ferreira", "title": "CISE3: Verifica\\c{c}\\~ao de aplica\\c{c}\\~oes com consist\\^encia fraca em\n  Why3", "comments": "Article in Portuguese, accepted in the national informatics\n  conference INForum 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a tool for the verification of programs built on\ntop replicated databases. The tool evaluates a sequential specification and\ndeduces which operations need to be synchronized for the program to function\nproperly in a distributed environment. Our prototype is built over the\ndeductive verification platform Why3. The Why3 Framework provides a\nsophisticated user experience, the possibility to scale to realistic case\nstudies, as well as a high degree of automation. A case study is presented and\ndiscussed, with the purpose of experimentally validating our approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:36:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Meirim", "Filipe", ""], ["Pereira", "M\u00e1rio", ""], ["Ferreira", "Carla", ""]]}, {"id": "1909.03764", "submitter": "Thorsten Wissmann", "authors": "Bin Wang, Jun Shen, Shutao Zhang, Zhizheng Zhang", "title": "On the Strong Equivalences for LPMLN Programs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (January\n  22, 2021) lmcs:7122", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  LPMLN is a powerful knowledge representation and reasoning tool that combines\nthe non-monotonic reasoning ability of Answer Set Programming (ASP) and the\nprobabilistic reasoning ability of Markov Logic Networks (MLN). In this paper,\nwe study the strong equivalence for LPMLN programs, which is an important tool\nfor program rewriting and theoretical investigations in the field of logic\nprogramming. First of all, we present the notion of p-strong equivalence for\nLPMLN and present a model-theoretical characterization for the notion. And we\ninvestigate the relationships among the p-strong equivalence and other existing\nnotions of strong equivalences for LPMLN. Then, we investigate several\nproperties of the p-strong equivalence from the following four aspects.\nFirstly, we investigate two relaxed notions of the p-strong equivalence\naccording to practical scenarios of program rewriting, and present\ncorresponding characterizations for the notions. Secondly, we analyze the\ncomputational complexities of deciding strong equivalences for LPMLN programs.\nThirdly, we investigate the relationships among the strong equivalences of\nLPMLN and two extensions of ASP: ASP with weak constraints and ordered\ndisjunctions. Finally, we investigate LPMLN program simplification via the\np-strong equivalence and present some syntactic conditions that decide the\np-strong equivalence between a single LPMLN rule and the empty program. The\ncontributions of the paper are as follows. Firstly, all of the results\npresented in this paper provide a better understanding of LPMLN programming,\nwhich helps us further explore the properties of LPMLN. Secondly, the\nrelationships among the strong equivalences open a way to study the strong\nequivalences for some logic formalisms by translating into LPMLN. Thirdly, the\nprogram simplification can be used to enhance the implementations of the LPMLN\nsolvers ...\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:15:30 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 11:31:14 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 08:52:13 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 08:14:29 GMT"}, {"version": "v5", "created": "Thu, 21 Jan 2021 09:13:51 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Wang", "Bin", ""], ["Shen", "Jun", ""], ["Zhang", "Shutao", ""], ["Zhang", "Zhizheng", ""]]}, {"id": "1909.03819", "submitter": "Camilo Rocha", "authors": "Miguel Romero, Sergio Ram\\'irez, Camilo Rocha, Frank Valencia", "title": "A Rewriting Logic Approach to Stochastic and Spatial Constraint System\n  Specification and Verification", "comments": "arXiv admin note: text overlap with arXiv:1805.07434", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses the issue of specifying, simulating, and verifying\nreactive systems in rewriting logic. It presents an executable semantics for\nprobabilistic, timed, and spatial concurrent constraint programming ---here\ncalled stochastic and spatial concurrent constraint systems (SSCC)--- in the\nrewriting logic semantic framework. The approach is based on an enhanced and\ngeneralized model of concurrent constraint programming (CCP) where\ncomputational hierarchical spaces can be assigned to belong to agents. The\nexecutable semantics faithfully represents and operationally captures the\nhighly concurrent nature, uncertain behavior, and spatial and epistemic\ncharacteristics of reactive systems with flow of information. In SSCC, timing\nattributes ---represented by stochastic duration--- can be associated to\nprocesses, and exclusive and independent probabilistic choice is also\nsupported. SMT solving technology, available from the Maude system, is used to\nrealize the underlying constraint system of SSCC with quantifier-free formulas\nover integers and reals. This results in a fully executable real-time symbolic\nspecification that can be used for quantitative analysis in the form of\nstatistical model checking. The main features and capabilities of SSCC are\nillustrated with examples throughout the paper. This contribution is part of a\nlarger research effort aimed at making available formal analysis techniques and\ntools, mathematically founded on the CCP approach, to the research community.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:56:37 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Romero", "Miguel", ""], ["Ram\u00edrez", "Sergio", ""], ["Rocha", "Camilo", ""], ["Valencia", "Frank", ""]]}, {"id": "1909.03820", "submitter": "Steffen Van Bergerem", "authors": "Steffen van Bergerem", "title": "Learning Concepts Definable in First-Order Logic with Counting", "comments": null, "journal-ref": "34th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS\n  2019, Vancouver, BC, Canada, June 24-27, 2019", "doi": "10.1109/LICS.2019.8785811", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study classification problems over relational background structures for\nhypotheses that are defined using logics with counting. The aim of this paper\nis to find learning algorithms running in time sublinear in the size of the\nbackground structure. We show that hypotheses defined by FOCN(P)-formulas over\nstructures of polylogarithmic degree can be learned in sublinear time.\nFurthermore, we prove that for structures of unbounded degree there is no\nsublinear learning algorithm for first-order formulas.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:57:29 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["van Bergerem", "Steffen", ""]]}, {"id": "1909.04135", "submitter": "Nathan Mull", "authors": "Nathan Mull, Shuo Pang, Alexander Razborov", "title": "On CDCL-based proof systems with the ordered decision strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that conflict-driven clause learning SAT-solvers with the ordered\ndecision strategy and the DECISION learning scheme are equivalent to ordered\nresolution. We also prove that, by replacing this learning scheme with its\nopposite that stops after the first new clause when backtracking, they become\nequivalent to general resolution. To the best of our knowledge, this is the\nfirst theoretical study of the interplay between specific decision strategies\nand clause learning.\n  For both results, we allow nondeterminism in the solver's ability to perform\nunit propagation, conflict analysis, and restarts, in a way that is similar to\nprevious works in the literature. To aid the presentation of our results, and\npossibly future research, we define a model and language for discussing\nCDCL-based proof systems that allows for succinct and precise theorem\nstatements.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:13:31 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Mull", "Nathan", ""], ["Pang", "Shuo", ""], ["Razborov", "Alexander", ""]]}, {"id": "1909.04309", "submitter": "Loic Pauleve", "authors": "St\\'ephanie Chevalier (BioInfo - LRI), Christine Froidevaux (BioInfo -\n  LRI), Lo\\\"ic Paulev\\'e (LaBRI), Andrei Zinovyev", "title": "Synthesis of Boolean Networks from Biological Dynamical Constraints\n  using Answer-Set Programming", "comments": null, "journal-ref": "31st International Conference on Tools with Artificial\n  Intelligence, 2019, Portland, Oregon, United States", "doi": null, "report-no": null, "categories": "cs.AI cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean networks model finite discrete dynamical systems with complex\nbehaviours. The state of each component is determined by a Boolean function of\nthe state of (a subset of) the components of the network. This paper addresses\nthe synthesis of these Boolean functions from constraints on their domain and\nemerging dynamical properties of the resulting network. The dynamical\nproperties relate to the existence and absence of trajectories between\npartially observed configurations, and to the stable behaviours (fixpoints and\ncyclic attractors). The synthesis is expressed as a Boolean satisfiability\nproblem relying on Answer-Set Programming with a parametrized complexity, and\nleads to a complete non-redundant characterization of the set of solutions.\nConsidered constraints are particularly suited to address the synthesis of\nmodels of cellular differentiation processes, as illustrated on a case study.\nThe scalability of the approach is demonstrated on random networks with\nscale-free structures up to 100 to 1,000 nodes depending on the type of\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:14:23 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 09:18:11 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Chevalier", "St\u00e9phanie", "", "BioInfo - LRI"], ["Froidevaux", "Christine", "", "BioInfo -\n  LRI"], ["Paulev\u00e9", "Lo\u00efc", "", "LaBRI"], ["Zinovyev", "Andrei", ""]]}, {"id": "1909.04319", "submitter": "Hiroyuki Kido", "authors": "Hiroyuki Kido and Beishui Liao", "title": "A Bayesian Approach to Direct and Inverse Abstract Argumentation\n  Problems", "comments": "This paper was submitted to the journal of Artificial Intelligence\n  (AIJ) and rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a fundamental mechanism of how to detect a conflict\nbetween arguments given sentiments regarding acceptability of the arguments. We\nintroduce a concept of the inverse problem of the abstract argumentation to\ntackle the problem. Given noisy sets of acceptable arguments, it aims to find\nattack relations explaining the sets well in terms of acceptability semantics.\nIt is the inverse of the direct problem corresponding to the traditional\nproblem of the abstract argumentation that focuses on finding sets of\nacceptable arguments in terms of the semantics given an attack relation between\nthe arguments. We give a probabilistic model handling both of the problems in a\nway that is faithful to the acceptability semantics. From a theoretical point\nof view, we show that a solution to both the direct and inverse problems is a\nspecial case of the probabilistic inference on the model. We discuss that the\nmodel provides a natural extension of the semantics to cope with uncertain\nattack relations distributed probabilistically. From en empirical point of\nview, we argue that it reasonably predicts individuals sentiments regarding\nacceptability of arguments. This paper contributes to lay the foundation for\nmaking acceptability semantics data-driven and to provide a way to tackle the\nknowledge acquisition bottleneck.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:37:12 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 17:51:56 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kido", "Hiroyuki", ""], ["Liao", "Beishui", ""]]}, {"id": "1909.04396", "submitter": "Tapani Toivonen Mr.", "authors": "Tapani Toivonen and Janne Karttunen", "title": "Constant factor approximation of MAX CLIQUE", "comments": "the reduction does not preserve the approximation ratio", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAX CLIQUE problem (MCP) is an NPO problem, which asks to find the largest\ncomplete sub-graph in a graph $G, G = (V, E)$ (directed or undirected). MCP is\nwell known to be $NP-Hard$ to approximate in polynomial time with an\napproximation ratio of $1 + \\epsilon$, for every $\\epsilon > 0$ [9] (and even a\npolynomial time approximation algorithm with a ratio $n^{1 - \\epsilon}$ has\nbeen conjectured to be non-existent [2] for MCP). Up to this date, the best\nknown approximation ratio for MCP of a polynomial time algorithm is\n$O(n(log_2(log_2(n)))^2 / (log_2(n))^3)$ given by Feige [1]. In this paper, we\nshow that MCP can be approximated with a constant factor in polynomial time\nthrough approximation ratio preserving reductions from MCP to MAX DNF and from\nMAX DNF to MIN SAT. A 2-approximation algorithm for MIN SAT was presented in\n[6]. An approximation ratio preserving reduction from MIN SAT to min vertex\ncover improves the approximation ratio to $2 - \\Theta(1/ \\sqrt{n})$ [10]. Hence\nwe prove false the infamous conjecture, which argues that there cannot be a\npolynomial time algorithm for MCP with an approximation ratio of any constant\nfactor.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:42:37 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 06:04:07 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 14:43:08 GMT"}, {"version": "v4", "created": "Wed, 18 Sep 2019 18:54:00 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Toivonen", "Tapani", ""], ["Karttunen", "Janne", ""]]}, {"id": "1909.04569", "submitter": "Sebastian Oberhoff", "authors": "Sebastian Oberhoff", "title": "Incompleteness Ex Machina", "comments": "First published on https://www.scottaaronson.com/blog/ on December\n  30. 2018", "journal-ref": "Bulletin of the European Association for Theoretical Computer\n  Science, No 128, June 2019", "doi": null, "report-no": null, "categories": "cs.LO math.HO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this essay we'll prove G\\\"odel's incompleteness theorems twice. First,\nwe'll prove them the good old-fashioned way. Then we'll repeat the feat in the\nsetting of computation. In the process we'll discover that G\\\"odel's work,\nrightly viewed, needs to be split into two parts: the transport of computation\ninto the arena of arithmetic on the one hand and the actual incompleteness\ntheorems on the other. After we're done there will be cake.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:53:14 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Oberhoff", "Sebastian", ""]]}, {"id": "1909.04850", "submitter": "Karena Cai", "authors": "Tung Phan-Minh and Karena X. Cai and Richard M. Murray", "title": "Towards Assume-Guarantee Profiles for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rules or specifications for autonomous vehicles are currently formulated on a\ncase-by-case basis, and put together in a rather ad-hoc fashion. As a step\ntowards eliminating this practice, we propose a systematic procedure for\ngenerating a set of supervisory specifications for self-driving cars that are\n1) associated with a distributed assume-guarantee structure and 2)\ncharacterizable by the notion of consistency and completeness. Besides helping\nautonomous vehicles make better decisions on the road, the assume-guarantee\ncontract structure also helps address the notion of blame when undesirable\nevents occur. We give several game-theoretic examples to demonstrate\napplicability of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:49:26 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 07:12:58 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Phan-Minh", "Tung", ""], ["Cai", "Karena X.", ""], ["Murray", "Richard M.", ""]]}, {"id": "1909.04983", "submitter": "Alexander Svozil", "authors": "Krishnendu Chatterjee and Wolfgang Dvo\\v{r}\\'ak and Monika Henzinger\n  and Alexander Svozil", "title": "Quasipolynomial Set-Based Symbolic Algorithms for Parity Games", "comments": "Published at LPAR-22 in 2018", "journal-ref": null, "doi": "10.29007/5z5k", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving parity games, which are equivalent to modal $\\mu$-calculus model\nchecking, is a central algorithmic problem in formal methods. Besides the\nstandard computation model with the explicit representation of games, another\nimportant theoretical model of computation is that of set-based symbolic\nalgorithms. Set-based symbolic algorithms use basic set operations and one-step\npredecessor operations on the implicit description of games, rather than the\nexplicit representation. The significance of symbolic algorithms is that they\nprovide scalable algorithms for large finite-state systems, as well as for\ninfinite-state systems with finite quotient. Consider parity games on graphs\nwith $n$ vertices and parity conditions with $d$ priorities. While there is a\nrich literature of explicit algorithms for parity games, the main results for\nset-based symbolic algorithms are as follows: (a) an algorithm that requires\n$O(n^d)$ symbolic operations and $O(d)$ symbolic space; and (b) an improved\nalgorithm that requires $O(n^{d/3+1})$ symbolic operations and $O(n)$ symbolic\nspace. Our contributions are as follows: (1) We present a black-box set-based\nsymbolic algorithm based on the explicit progress measure algorithm. Two\nimportant consequences of our algorithm are as follows: (a) a set-based\nsymbolic algorithm for parity games that requires quasi-polynomially many\nsymbolic operations and $O(n)$ symbolic space; and (b) any future improvement\nin progress measure based explicit algorithms imply an efficiency improvement\nin our set-based symbolic algorithm for parity games. (2) We present a\nset-based symbolic algorithm that requires quasi-polynomially many symbolic\noperations and $O(d \\cdot \\log n)$ symbolic space. Moreover, for the important\nspecial case of $d \\leq \\log n$, our algorithm requires only polynomially many\nsymbolic operations and poly-logarithmic symbolic space.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 11:45:25 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Svozil", "Alexander", ""]]}, {"id": "1909.04998", "submitter": "Zeynep G\\\"ozen Saribatur", "authors": "Thomas Eiter, Zeynep G. Saribatur, Peter Sch\\\"uller", "title": "Abstraction for Zooming-In to Unsolvability Reasons of Grid-Cell\n  Problems", "comments": "Presented at the IJCAI 2019 Workshop on Explainable Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of abstracting away irrelevant details when studying\nproblems. This is especially noticeable for problems over grid-cells, as humans\nare able to disregard certain parts of the grid and focus on the key elements\nimportant for the problem. Recently, the notion of abstraction has been\nintroduced for Answer Set Programming (ASP), a knowledge representation and\nreasoning paradigm widely used in problem solving, with the potential to\nunderstand the key elements of a program that play a role in finding a\nsolution. The present paper takes this further and empowers abstraction to deal\nwith structural aspects, and in particular with hierarchical abstraction over\nthe domain. We focus on obtaining the reasons for unsolvability of problems on\ngrids, and show the possibility to automatically achieve human-like\nabstractions that distinguish only the relevant part of the grid. A user study\non abstract explanations confirms the similarity of the focus points in machine\nvs. human explanations and reaffirms the challenge of employing abstraction to\nobtain machine explanations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 12:17:09 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Eiter", "Thomas", ""], ["Saribatur", "Zeynep G.", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1909.05242", "submitter": "EPTCS", "authors": "Massimo Bartoletti (University of Cagliari, Italy), Ludovic Henrio\n  (CNRS, LIP, Lyon, France), Anastasia Mavridou (NASA Ames, USA), Alceste\n  Scalas (Aston University, Birmingham, UK)", "title": "Proceedings 12th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 304, 2019", "doi": "10.4204/EPTCS.304", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE'19, the 12th Interaction and\nConcurrency Experience, which was held in Copenhagen, Denmark on the 20th and\n21st of June 2019, as a satellite event of DisCoTec'19. The ICE workshop series\nfeatures a distinguishing review and selection procedure, allowing PC members\nto interact anonymously with authors. As in the past 11 editions, this\ninteraction considerably improved the accuracy of the feedback from the\nreviewers and the quality of accepted papers, and offered the basis for lively\ndiscussion during the workshop. The 2019 edition of ICE included double blind\nreviewing of original research papers, in order to increase fairness and avoid\nbias in reviewing. Each paper was reviewed by three PC members, and altogether\n9 papers were accepted for publication - plus 2 oral presentations which are\nnot part of this volume. We were proud to host 4 invited talks, by Dilian\nGurov, Fritz Henglein, Sophia Knight, and Hern\\'an Melgratti. The abstracts of\nthese talks are included in this volume together with the regular papers. Final\nversions of the contributions, taking into account the discussion at the\nworkshop, are included.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:57:03 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bartoletti", "Massimo", "", "University of Cagliari, Italy"], ["Henrio", "Ludovic", "", "CNRS, LIP, Lyon, France"], ["Mavridou", "Anastasia", "", "NASA Ames, USA"], ["Scalas", "Alceste", "", "Aston University, Birmingham, UK"]]}, {"id": "1909.05304", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Yiannis Kantaros, Alessandro Abate, Daniel\n  Kroening, George J. Pappas, Insup Lee", "title": "Reinforcement Learning for Temporal Logic Control Synthesis with\n  Probabilistic Satisfaction Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has emerged as an efficient method of choice for\nsolving complex sequential decision making problems in automatic control,\ncomputer science, economics, and biology. In this paper we present a model-free\nRL algorithm to synthesize control policies that maximize the probability of\nsatisfying high-level control objectives given as Linear Temporal Logic (LTL)\nformulas. Uncertainty is considered in the workspace properties, the structure\nof the workspace, and the agent actions, giving rise to a\nProbabilistically-Labeled Markov Decision Process (PL-MDP) with unknown graph\nstructure and stochastic behaviour, which is even more general case than a\nfully unknown MDP. We first translate the LTL specification into a Limit\nDeterministic Buchi Automaton (LDBA), which is then used in an on-the-fly\nproduct with the PL-MDP. Thereafter, we define a synchronous reward function\nbased on the acceptance condition of the LDBA. Finally, we show that the RL\nalgorithm delivers a policy that maximizes the satisfaction probability\nasymptotically. We provide experimental results that showcase the efficiency of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:48:02 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Kantaros", "Yiannis", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""], ["Pappas", "George J.", ""], ["Lee", "Insup", ""]]}, {"id": "1909.05539", "submitter": "Alexander Svozil", "authors": "Krishnendu Chatterjee and Wolfgang Dvor\\'ak and Monika Henzinger and\n  Alexander Svozil", "title": "Near-Linear Time Algorithms for Streett Objectives in Graphs and MDPs", "comments": "Published at CONCUR 2019", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2019.7", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental model-checking problem, given as input a model and a\nspecification, asks for the algorithmic verification of whether the model\nsatisfies the specification. Two classical models for reactive systems are\ngraphs and Markov decision processes (MDPs). A basic specification formalism in\nthe verification of reactive systems is the strong fairness (aka Streett)\nobjective, where given different types of requests and corresponding grants,\nthe requirement is that for each type, if the request event happens infinitely\noften, then the corresponding grant event must also happen infinitely often.\nAll omega-regular objectives can be expressed as Streett objectives and hence\nthey are canonical in verification. Consider graphs/MDPs with n vertices, m\nedges, and a Streett objectives with k pairs, and let b denote the size of the\ndescription of the Streett objective for the sets of requests and grants. The\ncurrent best-known algorithm for the problem requires time $O(min(n^2, m\n\\sqrt{m \\log n}) + b \\log n)$. In this work, we present randomized near-linear\ntime algorithms, with expected running time $\\widetilde{O}(m + b)$, where the\n$\\widetilde{O}$ notation hides poly-log factors. Our randomized algorithms are\nnear-linear in the size of the input, and hence optimal up to poly-log factors.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 09:56:24 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvor\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Svozil", "Alexander", ""]]}, {"id": "1909.05618", "submitter": "Jonathan Huerta y Munive", "authors": "Jonathan Juli\\'an Huerta y Munive and Georg Struth", "title": "Predicate Transformer Semantics for Hybrid Systems: Verification\n  Components for Isabelle/HOL", "comments": "38 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semantic framework for the deductive verification of hybrid\nsystems with Isabelle/HOL. It supports reasoning about the temporal evolutions\nof hybrid programs in the style of differential dynamic logic modelled by flows\nor invariant sets for vector fields. We introduce the semantic foundations of\nour approach and summarise their Isabelle formalisation as well as the\nresulting verification components. A series of examples shows our approach at\nwork.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 13:13:43 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 15:24:28 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Munive", "Jonathan Juli\u00e1n Huerta y", ""], ["Struth", "Georg", ""]]}, {"id": "1909.05972", "submitter": "EPTCS", "authors": "Franco Barbanera (University of Catania), Mariangiola\n  Dezani-Ciancaglini (University of Torino)", "title": "Open Multiparty Sessions", "comments": "In Proceedings ICE 2019, arXiv:1909.05242", "journal-ref": "EPTCS 304, 2019, pp. 77-96", "doi": "10.4204/EPTCS.304.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiparty sessions are systems of concurrent processes, which allow several\nparticipants to communicate by sending and receiving messages. Their overall\nbehaviour can be described by means of global types. Typable multiparty session\nenjoy lock-freedom. We look at multiparty sessions as open systems by a\nsuitable definition of connection transforming compatible processes into\ngateways (forwarders). A relation resembling the standard subtyping relation\nfor session types is used to formalise compatibility. We show that the session\nobtained by connection can be typed by manipulating the global types of the\nstarting sessions. This allows us to prove that lock-freedom is preserved by\nconnection.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:24:46 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Barbanera", "Franco", "", "University of Catania"], ["Dezani-Ciancaglini", "Mariangiola", "", "University of Torino"]]}, {"id": "1909.05973", "submitter": "EPTCS", "authors": "Diego Marmsoler (Technische Universit\\\"at M\\\"unchen), Ana Petrovska\n  (Technische Universit\\\"at M\\\"unchen)", "title": "Detecting Architectural Erosion using Runtime Verification", "comments": "In Proceedings ICE 2019, arXiv:1909.05242", "journal-ref": "EPTCS 304, 2019, pp. 97-114", "doi": "10.4204/EPTCS.304.7", "report-no": null, "categories": "cs.SE cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture of a system captures important design decisions for the\nsystem. Over time, changes in a system's implementation may lead to violations\nof specific design decisions. This problem is common in industry and known as\narchitectural erosion. Since it may have severe consequences on the quality of\na system, research has focused on the development of tools and techniques to\naddress the presented problem. As of today, most of the approaches to detect\narchitectural erosion employ static analysis techniques. While these techniques\nare well-suited for the analysis of static architectures, they reach their\nlimit when it comes to dynamic architectures. Thus, in this paper, we propose\nan alternative approach based on runtime verification. To this end, we propose\na systematic way to translate a formal specification of architectural\nconstraints to monitors, which can be used to detect violations of these\nconstraints. The approach is implemented in Eclipse/EMF, demonstrated through a\nrunning example, and evaluated using two case studies.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:25:13 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Marmsoler", "Diego", "", "Technische Universit\u00e4t M\u00fcnchen"], ["Petrovska", "Ana", "", "Technische Universit\u00e4t M\u00fcnchen"]]}, {"id": "1909.05979", "submitter": "EPTCS", "authors": "J\\'er\\^ome Leroux (Univ. Bordeaux, CNRS, Bordeaux-INP), Jean-Francois\n  Raskin (Universit\\'e libre de Bruxelles (ULB))", "title": "Proceedings Tenth International Symposium on Games, Automata, Logics,\n  and Formal Verification", "comments": null, "journal-ref": "EPTCS 305, 2019", "doi": "10.4204/EPTCS.305", "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Tenth International Symposium on\nGames, Automata, Logic and Formal Verification (GandALF 2019). The symposium\ntook place in Bordeaux, France, from the 2nd to the 3rd of September 2010. The\nGandALF symposium was established by a group of Italian computer scientists\ninterested in mathematical logic, automata theory, game theory, and their\napplications to the specification, design, and verification of complex systems.\nIts aim is to provide a forum where people from different areas, and possibly\nwith different backgrounds, can fruitfully interact. GandALF has a truly\ninternational spirit, as witnessed by the composition of the program and\nsteering committee and by the country distribution of the submitted papers.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:46:49 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Leroux", "J\u00e9r\u00f4me", "", "Univ. Bordeaux, CNRS, Bordeaux-INP"], ["Raskin", "Jean-Francois", "", "Universit\u00e9 libre de Bruxelles"]]}, {"id": "1909.06201", "submitter": "Michael Pinsker", "authors": "Libor Barto and Michael Pinsker", "title": "Topology is irrelevant (in a dichotomy conjecture for infinite domain\n  constraint satisfaction problems)", "comments": "arXiv admin note: substantial text overlap with arXiv:1602.04353", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tractability conjecture for finite domain Constraint Satisfaction\nProblems (CSPs) stated that such CSPs are solvable in polynomial time whenever\nthere is no natural reduction, in some precise technical sense, from the 3-SAT\nproblem; otherwise, they are NP-complete. Its recent resolution draws on an\nalgebraic characterization of the conjectured borderline: the CSP of a finite\nstructure permits no natural reduction from 3-SAT if and only if the stabilizer\nof the polymorphism clone of the core of the structure satisfies some\nnontrivial system of identities, and such satisfaction is always witnessed by\nseveral specific nontrivial systems of identities which do not depend on the\nstructure.\n  The tractability conjecture has been generalized in the above formulation to\na certain class of infinite domain CSPs, namely, CSPs of reducts of finitely\nbounded homogeneous structures. It was subsequently shown that the conjectured\nborderline between hardness and tractability, i.e., a natural reduction from\n3-SAT, can be characterized for this class by a combination of algebraic and\ntopological properties. However, it was not known whether the topological\ncomponent is essential in this characterization.\n  We provide a negative answer to this question by proving that the borderline\nis characterized by one specific algebraic identity, namely the pseudo-Siggers\nidentity $\\alpha s(x,y,x,z,y,z) \\approx \\beta s(y,x,z,x,z,y)$. This\naccomplishes one of the steps of a proposed strategy for reducing the infinite\ndomain CSP dichotomy conjecture to the finite case. Our main theorem is also of\nindependent mathematical interest, characterizing a topological property of any\n$\\omega$-categorical core structure (the existence of a continuous homomorphism\nof a stabilizer of its polymorphism clone to the projections) in purely\nalgebraic terms (the failure of an identity as above).\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:33:11 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 11:15:38 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Barto", "Libor", ""], ["Pinsker", "Michael", ""]]}, {"id": "1909.06215", "submitter": "Krzysztof R. Apt", "authors": "Krzysztof R. Apt and Frank S. de Boer", "title": "Reasoning about call-by-value: a missing result in the history of\n  Hoare's logic", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a sound and relatively complete Hoare-like proof system for\nreasoning about partial correctness of recursive procedures in presence of\nlocal variables and the call-by-value parameter mechanism, and in which the\ncorrectness proofs are linear in the length of the program. We argue that in\nspite of the fact that Hoare-like proof systems for recursive procedures were\nintensively studied, no such proof system has been proposed in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:18:54 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Apt", "Krzysztof R.", ""], ["de Boer", "Frank S.", ""]]}, {"id": "1909.06420", "submitter": "Patrick Totzke", "authors": "Corto Mascle, Mahsa Shirmohammadi, Patrick Totzke", "title": "Controlling a Random Population is EXPTIME-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bertrand et al. [1] (LMCS 2019) describe two-player zero-sum games in which\none player tries to achieve a reachability objective in $n$ games (on the same\nfinite arena) simultaneously by broadcasting actions, and where the opponent\nhas full control of resolving non-deterministic choices. They show EXPTIME\ncompleteness for the question if such games can be won for every number $n$ of\ngames.\n  We consider the almost-sure variant in which the opponent randomizes their\nactions, and where the player tries to achieve the reachability objective\neventually with probability one. The lower bound construction in [1] does not\ndirectly carry over to this randomized setting. In this note we show EXPTIME\nhardness for the almost-sure problem by reduction from Countdown Games.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 19:51:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mascle", "Corto", ""], ["Shirmohammadi", "Mahsa", ""], ["Totzke", "Patrick", ""]]}, {"id": "1909.06588", "submitter": "Jingyue Lu", "authors": "Rudy Bunel, Jingyue Lu, Ilker Turkaslan, Philip H.S. Torr, Pushmeet\n  Kohli, M. Pawan Kumar", "title": "Branch and Bound for Piecewise Linear Neural Network Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Learning and its potential use in many safety-critical\napplications has motivated research on formal verification of Neural Network\n(NN) models. In this context, verification involves proving or disproving that\nan NN model satisfies certain input-output properties. Despite the reputation\nof learned NN models as black boxes, and the theoretical hardness of proving\nuseful properties about them, researchers have been successful in verifying\nsome classes of models by exploiting their piecewise linear structure and\ntaking insights from formal methods such as Satisifiability Modulo Theory.\nHowever, these methods are still far from scaling to realistic neural networks.\nTo facilitate progress on this crucial area, we exploit the Mixed Integer\nLinear Programming (MIP) formulation of verification to propose a family of\nalgorithms based on Branch-and-Bound (BaB). We show that our family contains\nprevious verification methods as special cases. With the help of the BaB\nframework, we make three key contributions. Firstly, we identify new methods\nthat combine the strengths of multiple existing approaches, accomplishing\nsignificant performance improvements over previous state of the art. Secondly,\nwe introduce an effective branching strategy on ReLU non-linearities. This\nbranching strategy allows us to efficiently and successfully deal with high\ninput dimensional problems with convolutional network architecture, on which\nprevious methods fail frequently. Finally, we propose comprehensive test data\nsets and benchmarks which includes a collection of previously released\ntestcases. We use the data sets to conduct a thorough experimental comparison\nof existing and new algorithms and to provide an inclusive analysis of the\nfactors impacting the hardness of verification problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 12:44:35 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:50:30 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 23:49:41 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:33:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bunel", "Rudy", ""], ["Lu", "Jingyue", ""], ["Turkaslan", "Ilker", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1909.06673", "submitter": "Petr Savick\\'y", "authors": "Petr Ku\\v{c}era, Petr Savick\\'y", "title": "Propagation complete encodings of smooth DNNF theories", "comments": "29 pages, correction of the example in Section 2.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate conjunctive normal form (CNF) encodings of a function\nrepresented with a smooth decomposable negation normal form (DNNF). Several\nencodings of DNNFs and decision diagrams were considered by (Abio et al. 2016).\nThe authors differentiate between encodings which implement consistency or\ndomain consistency from encodings which implement unit refutation completeness\nor propagation completeness (in both cases implements means by unit\npropagation). The difference is that in the former case we do not care about\nproperties of the encoding with respect to the auxiliary variables while in the\nlatter case we treat all variables (the input ones and the auxiliary ones) in\nthe same way. The latter case is useful if a DNNF is a part of a problem\ncontaining also other constraints and a SAT solver is used to test\nsatisfiability. The currently known encodings of smooth DNNF theories implement\ndomain consistency. Building on this and the result of (Abio et al. 2016) on an\nencoding of decision diagrams which implements propagation completeness, we\npresent a new encoding of a smooth DNNF which implements propagation\ncompleteness. This closes the gap left open in the literature on encodings of\nDNNFs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 20:43:41 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 10:40:55 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ku\u010dera", "Petr", ""], ["Savick\u00fd", "Petr", ""]]}, {"id": "1909.06692", "submitter": "Thorsten Wissmann", "authors": "Johannes {\\AA}man Pohjola", "title": "Psi-Calculi Revisited: Connectivity and Compositionality", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (December\n  15, 2020) lmcs:6981", "doi": "10.23638/LMCS-16(4:16)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Psi-calculi is a parametric framework for process calculi similar to popular\npi-calculus extensions such as the explicit fusion calculus, the applied\npi-calculus and the spi calculus. Mechanised proofs of standard algebraic and\ncongruence properties of bisimilarity apply to all calculi within the\nframework. A limitation of psi-calculi is that communication channels must be\nsymmetric and transitive. In this paper, we give a new operational semantics to\npsi-calculi that allows us to lift these restrictions and simplify some of the\nproofs. The key technical innovation is to annotate transitions with a\nprovenance -- a description of the scope and channel they originate from. We\ngive mechanised proofs that our extension is conservative, and that the\nstandard algebraic and congruence properties of strong and weak bisimilarity\nare maintained. We show correspondence with a reduction semantics and barbed\nbisimulation. We show how a pi-calculus with preorders that was previously\nbeyond the scope of psi-calculi can be captured, and how to encode mixed choice\nunder very strong quality criteria.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 23:07:21 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 07:56:26 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 05:08:09 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 12:09:37 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Pohjola", "Johannes \u00c5man", ""]]}, {"id": "1909.07095", "submitter": "Cristina Cornelio PhD", "authors": "Cristina Cornelio and Veronika Thost", "title": "RuDaS: Synthetic Datasets for Rule Learning and Evaluation Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical rules are a popular knowledge representation language in many\ndomains, representing background knowledge and encoding information that can be\nderived from given facts in a compact form. However, rule formulation is a\ncomplex process that requires deep domain expertise,and is further challenged\nby today's often large, heterogeneous, and incomplete knowledge graphs. Several\napproaches for learning rules automatically, given a set of input example\nfacts,have been proposed over time, including, more recently, neural systems.\nYet, the area is missing adequate datasets and evaluation approaches: existing\ndatasets often resemble toy examples that neither cover the various kinds of\ndependencies between rules nor allow for testing scalability. We present a tool\nfor generating different kinds of datasets and for evaluating rule learning\nsystems, including new performance measures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:56:06 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 14:20:34 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Cornelio", "Cristina", ""], ["Thost", "Veronika", ""]]}, {"id": "1909.07296", "submitter": "David Pym", "authors": "Didier Galmiche, Pierre Kimmel, David Pym", "title": "A Substructural Epistemic Resource Logic: Theory and Modelling\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a substructural epistemic logic, based on Boolean BI, in which the\nepistemic modalities are parametrized on agents' local resources. The new\nmodalities can be seen as generalizations of the usual epistemic modalities.\nThe logic combines Boolean BI's resource semantics --- we introduce BI and its\nresource semantics at some length --- with epistemic agency. We illustrate the\nuse of the logic in systems modelling by discussing some examples about access\ncontrol, including semaphores, using resource tokens. We also give a labelled\ntableaux calculus and establish soundness and completeness with respect to the\nresource semantics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:53:11 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Galmiche", "Didier", ""], ["Kimmel", "Pierre", ""], ["Pym", "David", ""]]}, {"id": "1909.07479", "submitter": "W{\\l}odzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "On correctness of an n queens program", "comments": "14 pages, 1 figure. This version: various modifications, mainly in\n  Section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thom Fr\\\"uhwirth presented a short, elegant and efficient Prolog program for\nthe n queens problem. However the program may be seen as rather tricky and one\nmay be not convinced about its correctness. This paper explains the program in\na declarative way, and provides proofs of its correctness and completeness. The\nspecification and the proofs are declarative, i.e. they abstract from any\noperational semantics. The specification is approximate, it is unnecessary to\ndescribe the program's semantics exactly. Despite the program works on\nnon-ground terms, this work employs the standard semantics, based on logical\nconsequence and Herbrand interpretations.\n  Another purpose of the paper is to present an example of precise declarative\nreasoning about the semantics of a logic program.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:55:54 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 10:12:01 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 22:53:30 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 15:51:21 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 19:01:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}, {"id": "1909.07589", "submitter": "Masahiro Hamano", "authors": "Masahiro Hamano", "title": "A Linear Exponential Comonad in s-finite Transition Kernels and\n  Probabilistic Coherent Spaces", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns a stochastic construction of probabilistic coherent\nspaces by employing novel ingredients (i) linear exponential comonads arising\nproperly in the measure-theory (ii) continuous orthogonality between measures\nand measurable functions. A linear exponential comonad is constructed over a\nsymmetric monoidal category of transition kernels, relaxing Markov kernels of\nPanangaden's stochastic relations into s-finite kernels. The model supports an\northogonality in terms of an integral between measures and measurable\nfunctions, which can be seen as a continuous extension of\nGirard-Danos-Ehrhard's linear duality for probabilistic coherent spaces. The\northogonality is formulated by a Hyland-Schalk double glueing construction,\ninto which our measure theoretic monoidal comonad structure is accommodated. As\nan application to countable measurable spaces, a dagger compact closed category\nis obtained, whose double glueing gives rise to the familiar category of\nprobabilistic coherent spaces.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:54:03 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 04:20:58 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Hamano", "Masahiro", ""]]}, {"id": "1909.07646", "submitter": "EPTCS", "authors": "Bart Bogaerts (Vrije Universiteit Brussel), Esra Erdem (Sabanci\n  University), Paul Fodor (Stony Brook University), Andrea Formisano\n  (Universit\\`a di Perugia), Giovambattista Ianni (University of Calabria),\n  Daniela Inclezan (Miami University), German Vidal (Universitat Politecnica de\n  Valencia), Alicia Villanueva (Universitat Politecnica de Valencia), Marina De\n  Vos (University of Bath), Fangkai Yang (NVIDIA Corporation)", "title": "Proceedings 35th International Conference on Logic Programming\n  (Technical Communications)", "comments": null, "journal-ref": "EPTCS 306, 2019", "doi": "10.4204/EPTCS.306", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first conference held in Marseille in 1982, ICLP has been the\npremier international event for presenting research in logic programming.\nContributions are sought in all areas of logic programming, including but not\nrestricted to:\n  Foundations: Semantics, Formalisms, Nonmonotonic reasoning, Knowledge\nrepresentation.\n  Languages: Concurrency, Objects, Coordination, Mobility, Higher Order, Types,\nModes, Assertions, Modules, Meta-programming, Logic-based domain-specific\nlanguages, Programming Techniques.\n  Declarative programming: Declarative program development, Analysis, Type and\nmode inference, Partial evaluation, Abstract interpretation, Transformation,\nValidation, Verification, Debugging, Profiling, Testing, Execution\nvisualization\n  Implementation: Virtual machines, Compilation, Memory management,\nParallel/distributed execution, Constraint handling rules, Tabling, Foreign\ninterfaces, User interfaces.\n  Related Paradigms and Synergies: Inductive and Co-inductive Logic\nProgramming, Constraint Logic Programming, Answer Set Programming, Interaction\nwith SAT, SMT and CSP solvers, Logic programming techniques for type inference\nand theorem proving, Argumentation, Probabilistic Logic Programming, Relations\nto object-oriented and Functional programming.\n  Applications: Databases, Big Data, Data integration and federation, Software\nengineering, Natural language processing, Web and Semantic Web, Agents,\nArtificial intelligence, Computational life sciences, Education, Cybersecurity,\nand Robotics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:33:12 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bogaerts", "Bart", "", "Vrije Universiteit Brussel"], ["Erdem", "Esra", "", "Sabanci\n  University"], ["Fodor", "Paul", "", "Stony Brook University"], ["Formisano", "Andrea", "", "Universit\u00e0 di Perugia"], ["Ianni", "Giovambattista", "", "University of Calabria"], ["Inclezan", "Daniela", "", "Miami University"], ["Vidal", "German", "", "Universitat Politecnica de\n  Valencia"], ["Villanueva", "Alicia", "", "Universitat Politecnica de Valencia"], ["De Vos", "Marina", "", "University of Bath"], ["Yang", "Fangkai", "", "NVIDIA Corporation"]]}, {"id": "1909.07656", "submitter": "EPTCS", "authors": "Corina C\\^irstea", "title": "Resource-Aware Automata and Games for Optimal Synthesis", "comments": "In Proceedings GandALF 2019, arXiv:1909.05979", "journal-ref": "EPTCS 305, 2019, pp. 50-65", "doi": "10.4204/EPTCS.305.4", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider quantitative notions of parity automaton and parity game aimed at\nmodelling resource-aware behaviour, and study (memory-full) strategies for\nexhibiting accepting runs that require a minimum amount of initial resources,\nrespectively for winning a game with minimum initial resources. We also show\nhow such strategies can be simplified to consist of only two types of moves:\nthe former aimed at increasing resources, the latter aimed at satisfying the\nacceptance condition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:54:28 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["C\u00eerstea", "Corina", ""]]}, {"id": "1909.07659", "submitter": "EPTCS", "authors": "Tom van Dijk (University of Twente), Bob Rubbens (University of\n  Twente)", "title": "Simple Fixpoint Iteration To Solve Parity Games", "comments": "In Proceedings GandALF 2019, arXiv:1909.05979", "journal-ref": "EPTCS 305, 2019, pp. 123-139", "doi": "10.4204/EPTCS.305.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A naive way to solve the model-checking problem of the mu-calculus uses\nfixpoint iteration. Traditionally however mu-calculus model-checking is solved\nby a reduction in linear time to a parity game, which is then solved using one\nof the many algorithms for parity games. We now consider a method of solving\nparity games by means of a naive fixpoint iteration. Several fixpoint\nalgorithms for parity games have been proposed in the literature. In this work,\nwe introduce an algorithm that relies on the notion of a distraction. The idea\nis that this offers a novel perspective for understanding parity games. We then\nshow that this algorithm is in fact identical to two earlier published fixpoint\nalgorithms for parity games and thus that these earlier algorithms are the\nsame. Furthermore, we modify our algorithm to only partially recompute deeper\nfixpoints after updating a higher set and show that this modification enables a\nsimple method to obtain winning strategies. We show that the resulting\nalgorithm is simple to implement and offers good performance on practical\nparity games. We empirically demonstrate this using games derived from\nmodel-checking, equivalence checking and reactive synthesis and show that our\nfixpoint algorithm is the fastest solution for model-checking games.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:02:58 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["van Dijk", "Tom", "", "University of Twente"], ["Rubbens", "Bob", "", "University of\n  Twente"]]}, {"id": "1909.07674", "submitter": "Amanda Vidal", "authors": "Amanda Vidal, Francesc Esteva, Lluis Godo", "title": "Axiomatizing logics of fuzzy preferences using graded modalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of this paper is to propose a many-valued modal framework to\nformalize reasoning with both graded preferences and propositions, in the style\nof van Benthem et al.'s classical modal logics for preferences. To do so, we\nstart from Bou et al.'s minimal modal logic over a finite and linearly ordered\nresiduated lattice. We then define appropriate extensions on a multi-modal\nlanguage with graded modalities, both for weak and strict preferences, and with\ntruth-constants. Actually, the presence of truth-constants in the language\nallows us to show that the modal operators Box and Diamond of the minimal modal\nlogic are inter-definable. Finally, we propose an axiomatic system for this\nlogic in an extended language (where the preference modal operators are\ndefinable), and prove completeness with respect to the intended graded\npreference semantics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:33:43 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 10:42:49 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Vidal", "Amanda", ""], ["Esteva", "Francesc", ""], ["Godo", "Lluis", ""]]}, {"id": "1909.08017", "submitter": "Elizabeth Polgreen", "authors": "Elizabeth Polgreen, Martin Brain, Martin Fraenzle and Alessandro Abate", "title": "Verifying Reachability Properties in Markov Chains via Incremental\n  Induction", "comments": "16 pages plus appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a scalability gap between probabilistic and non-probabilistic\nverification. Probabilistic model checking tools are based either on explicit\nengines or on (Multi-Terminal) Binary Decision Diagrams. These structures are\ncomplemented in areas of non-probabilistic verification by more scalable\ntechniques, such as IC3. We present a symbolic probabilistic model checking\nalgorithm based on IC3-like incremental construction of inductive clauses to\npartition the state space, interleaved with incremental construction of a\nsystem of linear inequalities. This paper compares our implementation to\nstandard quantitative verification alternatives: our experiments show that our\nalgorithm is a step to more scalable symbolic verification of rare events in\nfinite-state Markov chains.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:32:50 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 16:55:36 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Polgreen", "Elizabeth", ""], ["Brain", "Martin", ""], ["Fraenzle", "Martin", ""], ["Abate", "Alessandro", ""]]}, {"id": "1909.08230", "submitter": "EPTCS", "authors": "Falco Nogatz (University of W\\\"urzburg, Germany), Philipp K\\\"orner\n  (University of D\\\"usseldorf, Germany), Sebastian Krings (Niederrhein\n  University of Applied Sciences, Germany)", "title": "Prolog Coding Guidelines: Status and Tool Support", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 8-21", "doi": "10.4204/EPTCS.306.8", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of coding guidelines is generally accepted throughout\ndevelopers of every programming language. Naturally, Prolog makes no exception.\nHowever, establishing coding guidelines is fraught with obstacles: Finding\ncommon ground on kind and selection of rules is matter of debate; once found,\nadhering to or enforcing rules is complicated as well, not least because of\nProlog's flexible syntax without keywords. In this paper, we evaluate the\nstatus of coding guidelines in the Prolog community and discuss to what extent\nthey can be automatically verified. We implemented a linter for Prolog and\napplied it to several packages to get a hold on the current state of the\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 06:59:16 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nogatz", "Falco", "", "University of W\u00fcrzburg, Germany"], ["K\u00f6rner", "Philipp", "", "University of D\u00fcsseldorf, Germany"], ["Krings", "Sebastian", "", "Niederrhein\n  University of Applied Sciences, Germany"]]}, {"id": "1909.08231", "submitter": "EPTCS", "authors": "Richard Taupe (Siemens AG \\\"Osterreich, Vienna, Austria, and\n  Alpen-Adria-Universit\\\"at, Klagenfurt, Austria), Konstantin Schekotihin\n  (Alpen-Adria-Universit\\\"at, Klagenfurt, Austria), Peter Sch\\\"uller\n  (Technische Universit\\\"at Wien, Institut f\\\"ur Logic and Computation, KBS\n  Group), Antonius Weinzierl (Technische Universit\\\"at Wien, Institut f\\\"ur\n  Logic and Computation, KBS Group, and Aalto University, Department of\n  Computer Science), Gerhard Friedrich (Alpen-Adria-Universit\\\"at, Klagenfurt,\n  Austria)", "title": "Exploiting Partial Knowledge in Declarative Domain-Specific Heuristics\n  for ASP", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 22-35", "doi": "10.4204/EPTCS.306.9", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific heuristics are an important technique for solving\ncombinatorial problems efficiently. We propose a novel semantics for\ndeclarative specifications of domain-specific heuristics in Answer Set\nProgramming (ASP). Decision procedures that are based on a partial solution are\na frequent ingredient of existing domain-specific heuristics, e.g., for placing\nan item that has not been placed yet in bin packing. Therefore, in our novel\nsemantics negation as failure and aggregates in heuristic conditions are\nevaluated on a partial solver state. State-of-the-art solvers do not allow such\na declarative specification. Our implementation in the lazy-grounding ASP\nsystem Alpha supports heuristic directives under this semantics. By that, we\nalso provide the first implementation for incorporating declaratively specified\ndomain-specific heuristics in a lazy-grounding setting. Experiments confirm\nthat the combination of ASP solving with lazy grounding and our novel\nheuristics can be a vital ingredient for solving industrial-size problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 06:59:51 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Taupe", "Richard", "", "Siemens AG \u00d6sterreich, Vienna, Austria, and\n  Alpen-Adria-Universit\u00e4t, Klagenfurt, Austria"], ["Schekotihin", "Konstantin", "", "Alpen-Adria-Universit\u00e4t, Klagenfurt, Austria"], ["Sch\u00fcller", "Peter", "", "Technische Universit\u00e4t Wien, Institut f\u00fcr Logic and Computation, KBS\n  Group"], ["Weinzierl", "Antonius", "", "Technische Universit\u00e4t Wien, Institut f\u00fcr\n  Logic and Computation, KBS Group, and Aalto University, Department of\n  Computer Science"], ["Friedrich", "Gerhard", "", "Alpen-Adria-Universit\u00e4t, Klagenfurt,\n  Austria"]]}, {"id": "1909.08232", "submitter": "EPTCS", "authors": "Jo\\~ao Barbosa (Faculty of Science of the University of Porto),\n  M\\'ario Florido (Faculty of Science of the University of Porto), V\\'itor\n  Santos Costa (Faculty of Science of the University of Porto)", "title": "A Three-Valued Semantics for Typed Logic Programming", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 36-51", "doi": "10.4204/EPTCS.306.10", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Types in logic programming have focused on conservative approximations of\nprogram semantics by regular types, on one hand, and on type systems based on a\nprescriptive semantics defined for typed programs, on the other. In this paper,\nwe define a new semantics for logic programming, where programs evaluate to\ntrue, false, and to a new semantic value called wrong, corresponding to a\nrun-time type error. We then have a type language with a separated semantics of\ntypes. Finally, we define a type system for logic programming and prove that it\nis semantically sound with respect to a semantic relation between programs and\ntypes where, if a program has a type, then its semantics is not wrong. Our work\nfollows Milner's approach for typed functional languages where the semantics of\nprograms is independent from the semantic of types, and the type system is\nproved to be sound with respect to a relation between both semantics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:00:16 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Barbosa", "Jo\u00e3o", "", "Faculty of Science of the University of Porto"], ["Florido", "M\u00e1rio", "", "Faculty of Science of the University of Porto"], ["Costa", "V\u00edtor Santos", "", "Faculty of Science of the University of Porto"]]}, {"id": "1909.08233", "submitter": "EPTCS", "authors": "Michael Morak", "title": "Epistemic Logic Programs: A Different World View", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 52-64", "doi": "10.4204/EPTCS.306.11", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic Logic Programs (ELPs), an extension of Answer Set Programming (ASP)\nwith epistemic operators, have received renewed attention from the research\ncommunity in recent years. Classically, evaluating an ELP yields a set of world\nviews, with each being a set of answer sets. In this paper, we propose an\nalternative definition of world views that represents them as three-valued\nassignments, where each atom can be either always true, always false, or\nneither. Based on several examples, we show that this definition is natural and\nintuitive. We also investigate relevant computational properties of these new\nsemantics, and explore how other notions, like strong equivalence, are\naffected.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:00:47 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Morak", "Michael", ""]]}, {"id": "1909.08236", "submitter": "EPTCS", "authors": "Adrien Husson (Universit\\'e de Paris, IRIF, CNRS), Jean Krivine\n  (Universit\\'e de Paris, IRIF, CNRS)", "title": "A Tractable Logic for Molecular Biology", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 101-113", "doi": "10.4204/EPTCS.306.17", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logic for knowledge representation and reasoning on\nprotein-protein interactions. Modulo a theory, formulas describe protein\nstructures and dynamic changes. They can be composed in order to add or remove\nstatic and dynamic observations. A second-order circumscription operator then\nenables nonmonotonic reasoning on the changes implied by a formula. We\nintroduce deduction rules that produce formulas which are, up to equivalence,\nin a first-order fragment with decidable satisfiability and validity.\nImportantly, the rules can produce circumscribed formulas.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:03:29 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Husson", "Adrien", "", "Universit\u00e9 de Paris, IRIF, CNRS"], ["Krivine", "Jean", "", "Universit\u00e9 de Paris, IRIF, CNRS"]]}, {"id": "1909.08238", "submitter": "EPTCS", "authors": "Bin Wang (Southeast University, China), Jun Shen (Southeast\n  University, China), Shutao Zhang (Southeast University, China), Zhizheng\n  Zhang (Southeast University, China)", "title": "On the Strong Equivalences of LPMLN Programs", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note:\n  substantial text overlap with arXiv:1909.03764", "journal-ref": "EPTCS 306, 2019, pp. 114-125", "doi": "10.4204/EPTCS.306.18", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By incorporating the methods of Answer Set Programming (ASP) and Markov Logic\nNetworks (MLN), LPMLN becomes a powerful tool for non-monotonic, inconsistent\nand uncertain knowledge representation and reasoning. To facilitate the\napplications and extend the understandings of LPMLN, we investigate the strong\nequivalences between LPMLN programs in this paper, which is regarded as an\nimportant property in the field of logic programming. In the field of ASP, two\nprograms P and Q are strongly equivalent, iff for any ASP program R, the\nprograms P and Q extended by R have the same stable models. In other words, an\nASP program can be replaced by one of its strong equivalent without considering\nits context, which helps us to simplify logic programs, enhance inference\nengines, construct human-friendly knowledge bases etc. Since LPMLN is a\ncombination of ASP and MLN, the notions of strong equivalences in LPMLN is\nquite different from that in ASP. Firstly, we present the notions of p-strong\nand w-strong equivalences between LPMLN programs. Secondly, we present a\ncharacterization of the notions by generalizing the SE-model approach in ASP.\nFinally, we show the use of strong equivalences in simplifying LPMLN programs,\nand present a sufficient and necessary syntactic condition that guarantees the\nstrong equivalence between a single LPMLN rule and the empty program.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:04:00 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wang", "Bin", "", "Southeast University, China"], ["Shen", "Jun", "", "Southeast\n  University, China"], ["Zhang", "Shutao", "", "Southeast University, China"], ["Zhang", "Zhizheng", "", "Southeast University, China"]]}, {"id": "1909.08239", "submitter": "EPTCS", "authors": "Daniela Inclezan (Miami University)", "title": "RestKB: A Library of Commonsense Knowledge about Dining at a Restaurant", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 126-139", "doi": "10.4204/EPTCS.306.19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a library of commonsense knowledge, RestKB, developed in\nmodular action language ALM and containing background knowledge relevant to the\nunderstanding of restaurant narratives, including stories that describe\nexceptions to the normal unfolding of such scenarios. We highlight features\nthat KR languages must possess in order to be able to express pertinent\nknowledge, and expand action language ALM as needed. We show that encoding the\nknowledge base in ALM facilitates its piecewise construction and testing, and\nimproves the generality and quality of the captured information, in comparison\nto an initial ASP encoding. The knowledge base was used in a system for\nreasoning about stereotypical activities, evaluated on the restaurant domain.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:04:28 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Inclezan", "Daniela", "", "Miami University"]]}, {"id": "1909.08241", "submitter": "EPTCS", "authors": "Santiago Escobar (VRAIN, Valencian Research Institute for Artificial\n  Intelligence, Universitat Polit\\`ecnica de Val\\`encia), Julia Sapi\\~na\n  (VRAIN, Valencian Research Institute for Artificial Intelligence, Universitat\n  Polit\\`ecnica de Val\\`encia)", "title": "Most General Variant Unifiers", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 154-167", "doi": "10.4204/EPTCS.306.21", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equational unification of two terms consists of finding a substitution that,\nwhen applied to both terms, makes them equal modulo some equational properties.\nEquational unification is of special relevance to automated deduction, theorem\nproving, protocol analysis, partial evaluation, model checking, etc. Several\nalgorithms have been developed in the literature for specific equational\ntheories, such as associative-commutative symbols, exclusive-or,\nDiffie-Hellman, or Abelian Groups. Narrowing was proved to be complete for\nunification and several cases have been studied where narrowing provides a\ndecidable unification algorithm. A new narrowing-based equational unification\nalgorithm relying on the concept of the variants of a term has been developed\nand it is available in the most recent version of Maude, version 2.7.1, which\nprovides quite sophisticated unification features. A variant of a term t is a\npair consisting of a substitution sigma and the canonical form of tsigma.\nVariant-based unification is decidable when the equational theory satisfies the\nfinite variant property. However, it may compute many more unifiers than the\nnecessary and, in this paper, we explore how to strengthen the variant-based\nunification algorithm implemented in Maude to produce a minimal set of most\ngeneral variant unifiers. Our experiments suggest that this new adaptation of\nthe variant-based unification is more efficient both in execution time and in\nthe number of computed variant unifiers than the original algorithm available\nin Maude.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:05:13 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Escobar", "Santiago", "", "VRAIN, Valencian Research Institute for Artificial\n  Intelligence, Universitat Polit\u00e8cnica de Val\u00e8ncia"], ["Sapi\u00f1a", "Julia", "", "VRAIN, Valencian Research Institute for Artificial Intelligence, Universitat\n  Polit\u00e8cnica de Val\u00e8ncia"]]}, {"id": "1909.08246", "submitter": "EPTCS", "authors": "K. Tuncay Tekle (Stony Brook University), Yanhong A. Liu (Stony Brook\n  University)", "title": "Extended Magic for Negation: Efficient Demand-Driven Evaluation of\n  Stratified Datalog with Precise Complexity Guarantees", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 241-254", "doi": "10.4204/EPTCS.306.28", "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of Datalog rules, facts, and a query, answers to the query can be\ninferred bottom-up starting from the facts or top-down starting from the query.\nFor efficiency, top-down evaluation is extended with memoization of inferred\nfacts, and bottom-up evaluation is performed after transformations to make\nrules driven by the demand from the query. Prior work has shown their precise\ncomplexity analysis and relationships. However, when Datalog is extended with\neven stratified negation, which has a simple and universally accepted\nsemantics, transformations to make rules demand-driven may result in\nnon-stratified negation, which has had many complex semantics and evaluation\nmethods.\n  This paper presents (1) a simple extension to demand transformation, a\ntransformation to make rules demand-driven for Datalog without negation, to\nsupport stratified negation, and (2) a simple extension to an optimal bottom-up\nevaluation method for Datalog with stratified negation, to handle\nnon-stratified negation in the resulting rules. We show that the method\nprovides precise complexity guarantees. It is also optimal in that only facts\nneeded for top-down evaluation of the query are inferred and each firing of a\nrule to infer such a fact takes worst-case constant time. We extend the precise\nrelationship between top-down evaluation and demand-driven bottom-up evaluation\nto Datalog with stratified negation. Finally, we show experimental results for\nperformance, as well as applications to previously challenging examples.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:07:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tekle", "K. Tuncay", "", "Stony Brook University"], ["Liu", "Yanhong A.", "", "Stony Brook\n  University"]]}, {"id": "1909.08248", "submitter": "EPTCS", "authors": "Felicidad Aguado (IRLab, CITIC Research Center, University of A\n  Coru\\~na, Spain), Pedro Cabalar (IRLab, CITIC Research Center, University of\n  A Coru\\~na, Spain), Jorge Fandinno (University of Potsdam, Germany), Brais\n  Mu\\~niz (IRLab, CITIC Research Center, University of A Coru\\~na, Spain),\n  Gilberto P\\'erez (IRLab, CITIC Research Center, University of A Coru\\~na,\n  Spain), Francisco Su\\'arez (Digestive Service, Complexo Hospitalario\n  Universitario de A Coru\\~na (CHUAC), Instituto de Investigaci\\'on Biom\\'edica\n  de A Coru\\~na (INIBIC), Coru\\~na, Spain)", "title": "A Rule-Based System for Explainable Donor-Patient Matching in Liver\n  Transplantation", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 266-272", "doi": "10.4204/EPTCS.306.31", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present web-liver, a rule-based system for decision support\nin the medical domain, focusing on its application in a liver transplantation\nunit for implementing policies for donor-patient matching. The rule-based\nsystem is built on top of an interpreter for logic programs with partial\nfunctions, called lppf, that extends the paradigm of Answer Set Programming\n(ASP) adding two main features: (1) the inclusion of partial functions and (2)\nthe computation of causal explanations for the obtained solutions. The final\ngoal of web-liver is assisting the medical experts in the design of new\ndonor-patient matching policies that take into account not only the patient\nseverity but also the transplantation utility. As an example, we illustrate the\ntool behaviour with a set of rules that implement the utility index called\nSOFT.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:08:25 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Aguado", "Felicidad", "", "IRLab, CITIC Research Center, University of A\n  Coru\u00f1a, Spain"], ["Cabalar", "Pedro", "", "IRLab, CITIC Research Center, University of\n  A Coru\u00f1a, Spain"], ["Fandinno", "Jorge", "", "University of Potsdam, Germany"], ["Mu\u00f1iz", "Brais", "", "IRLab, CITIC Research Center, University of A Coru\u00f1a, Spain"], ["P\u00e9rez", "Gilberto", "", "IRLab, CITIC Research Center, University of A Coru\u00f1a,\n  Spain"], ["Su\u00e1rez", "Francisco", "", "Digestive Service, Complexo Hospitalario\n  Universitario de A Coru\u00f1a"]]}, {"id": "1909.08249", "submitter": "EPTCS", "authors": "Ariyam Das (University of California, Los Angeles, USA), Youfu Li\n  (University of California, Los Angeles, USA), Jin Wang (University of\n  California, Los Angeles, USA), Mingda Li (University of California, Los\n  Angeles, USA), Carlo Zaniolo (University of California, Los Angeles, USA)", "title": "BigData Applications from Graph Analytics to Machine Learning by\n  Aggregates in Recursion", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. Paper presented at the\n  35th International Conference on Logic Programming (ICLP 2019), Las Cruces,\n  New Mexico, USA, 20-25 September 2019, 7 pages (short paper - applications\n  track)", "journal-ref": "EPTCS 306, 2019, pp. 273-279", "doi": "10.4204/EPTCS.306.32", "report-no": null, "categories": "cs.LO cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past, the semantic issues raised by the non-monotonic nature of\naggregates often prevented their use in the recursive statements of logic\nprograms and deductive databases. However, the recently introduced notion of\nPre-mappability (PreM) has shown that, in key applications of interest,\naggregates can be used in recursion to optimize the perfect-model semantics of\naggregate-stratified programs. Therefore we can preserve the declarative formal\nsemantics of such programs while achieving a highly efficient operational\nsemantics that is conducive to scalable implementations on parallel and\ndistributed platforms. In this paper, we show that with PreM, a wide spectrum\nof classical algorithms of practical interest, ranging from graph analytics and\ndynamic programming based optimization problems to data mining and machine\nlearning applications can be concisely expressed in declarative languages by\nusing aggregates in recursion. Our examples are also used to show that PreM can\nbe checked using simple techniques and templatized verification strategies. A\nwide range of advanced BigData applications can now be expressed declaratively\nin logic-based languages, including Datalog, Prolog, and even SQL, while\nenabling their execution with superior performance and scalability.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:08:44 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Das", "Ariyam", "", "University of California, Los Angeles, USA"], ["Li", "Youfu", "", "University of California, Los Angeles, USA"], ["Wang", "Jin", "", "University of\n  California, Los Angeles, USA"], ["Li", "Mingda", "", "University of California, Los\n  Angeles, USA"], ["Zaniolo", "Carlo", "", "University of California, Los Angeles, USA"]]}, {"id": "1909.08251", "submitter": "EPTCS", "authors": "Tarek Khaled (Aix-Marseille University), Bela\\\"id Benhamou\n  (Aix-Marseille University)", "title": "An ASP-based Approach for Attractor Enumeration in Synchronous and\n  Asynchronous Boolean Networks", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 295-301", "doi": "10.4204/EPTCS.306.34", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean networks are conventionally used to represent and simulate gene\nregulatory networks. In the analysis of the dynamic of a Boolean network, the\nattractors are the objects of a special attention. In this work, we propose a\nnovel approach based on Answer Set Programming (ASP) to express Boolean\nnetworks and simulate the dynamics of such networks. Our work focuses on the\nidentification of the attractors, it relies on the exhaustive enumeration of\nall the attractors of synchronous and asynchronous Boolean networks. We applied\nand evaluated the proposed approach on real biological networks, and the\nobtained results indicate that this novel approach is promising.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:09:27 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Khaled", "Tarek", "", "Aix-Marseille University"], ["Benhamou", "Bela\u00efd", "", "Aix-Marseille University"]]}, {"id": "1909.08254", "submitter": "EPTCS", "authors": "Nicos Angelopoulos (Department of Computer Science and Electronic\n  Engineering, University of Essex), Jan Wielemaker (Centrum voor Wiskunde en\n  Informatica (CWI), Amsterdam, The Netherlands)", "title": "Advances in Big Data Bio Analytics", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 309-322", "doi": "10.4204/EPTCS.306.36", "report-no": null, "categories": "cs.LO cs.DB q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delivering effective data analytics is of crucial importance to the\ninterpretation of the multitude of biological datasets currently generated by\nan ever increasing number of high throughput techniques. Logic programming has\nmuch to offer in this area. Here, we detail advances that highlight two of the\nstrengths of logical formalisms in developing data analytic solutions in\nbiological settings: access to large relational databases and building\nanalytical pipelines collecting graph information from multiple sources. We\npresent significant advances on the bio_db package which serves biological\ndatabases as Prolog facts that can be served either by in-memory loading or via\ndatabase backends. These advances include modularising the underlying\narchitecture and the incorporation of datasets from a second organism (mouse).\nIn addition, we introduce a number of data analytics tools that operate on\nthese datasets and are bundled in the analysis package: bio_analytics. Emphasis\nin both packages is on ease of installation and use. We highlight the general\narchitecture of our components based approach. An experimental graphical user\ninterface via SWISH for local installation is also available. Finally, we\nadvocate that biological data analytics is a fertile area which can drive\nfurther innovation in applied logic programming.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:10:12 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Angelopoulos", "Nicos", "", "Department of Computer Science and Electronic\n  Engineering, University of Essex"], ["Wielemaker", "Jan", "", "Centrum voor Wiskunde en\n  Informatica"]]}, {"id": "1909.08255", "submitter": "EPTCS", "authors": "Abeer Dyoub (University of L'Aquila), Stefania Costantini (University\n  of L'Aquila), Francesca A. Lisi (University of Bari)", "title": "Towards Ethical Machines Via Logic Programming", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 333-339", "doi": "10.4204/EPTCS.306.39", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous intelligent agents are playing increasingly important roles in our\nlives. They contain information about us and start to perform tasks on our\nbehalves. Chatbots are an example of such agents that need to engage in a\ncomplex conversations with humans. Thus, we need to ensure that they behave\nethically. In this work we propose a hybrid logic-based approach for ethical\nchatbots.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:10:55 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Dyoub", "Abeer", "", "University of L'Aquila"], ["Costantini", "Stefania", "", "University\n  of L'Aquila"], ["Lisi", "Francesca A.", "", "University of Bari"]]}, {"id": "1909.08256", "submitter": "EPTCS", "authors": "Valentina Pitoni (University of L'Aquila), Stefania Costantini\n  (University of L'Aquila)", "title": "A Temporal Module for Logical Frameworks", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 340-346", "doi": "10.4204/EPTCS.306.40", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In artificial intelligence, multi agent systems constitute an interesting\ntypology of society modeling, and have in this regard vast fields of\napplication, which extend to the human sciences. Logic is often used to model\nsuch kind of systems as it is easier to verify than other approaches, and\nprovides explainability and potential validation. In this paper we define a\ntime module suitable to add time to many logic representations of agents.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:11:22 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Pitoni", "Valentina", "", "University of L'Aquila"], ["Costantini", "Stefania", "", "University of L'Aquila"]]}, {"id": "1909.08257", "submitter": "EPTCS", "authors": "Yusuf Izmirlioglu (Sabanci University, Turkey)", "title": "Reasoning about Qualitative Direction and Distance between Extended\n  Objects using Answer Set Programming", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 371-378", "doi": "10.4204/EPTCS.306.50", "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we introduce a novel formal framework to represent and reason\nabout qualitative direction and distance relations between extended objects\nusing Answer Set Programming (ASP). We take Cardinal Directional Calculus (CDC)\nas a starting point and extend CDC with new sorts of constraints which involve\ndefaults, preferences and negation. We call this extended version as nCDC. Then\nwe further extend nCDC by augmenting qualitative distance relation and name\nthis extension as nCDC+. For CDC, nCDC, nCDC+, we introduce an ASP-based\ngeneral framework to solve consistency checking problems, address composition\nand inversion of qualitative spatial relations, infer unknown or missing\nrelations between objects, and find a suitable configuration of objects which\nfulfills a given inquiry.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:12:13 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Izmirlioglu", "Yusuf", "", "Sabanci University, Turkey"]]}, {"id": "1909.08258", "submitter": "EPTCS", "authors": "Kinjal Basu", "title": "Conversational AI : Open Domain Question Answering and Commonsense\n  Reasoning", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 396-402", "doi": "10.4204/EPTCS.306.53", "report-no": null, "categories": "cs.AI cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research is focused on making a human-like question answering system\nwhich can answer rationally. The distinguishing characteristic of our approach\nis that it will use automated common sense reasoning to truly \"understand\"\ndialogues, allowing it to converse like a human. Humans often make many\nassumptions during conversations. We infer facts not told explicitly by using\nour common sense. Incorporating commonsense knowledge in a question answering\nsystem will simply make it more robust.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:13:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Basu", "Kinjal", ""]]}, {"id": "1909.08259", "submitter": "EPTCS", "authors": "Francesco Fabiano (University of Udine)", "title": "Design of a Solver for Multi-Agent Epistemic Planning", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note: text\n  overlap with arXiv:1511.01960 by other authors", "journal-ref": "EPTCS 306, 2019, pp. 403-412", "doi": "10.4204/EPTCS.306.54", "report-no": null, "categories": "cs.AI cs.IT cs.LO cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the interest in Artificial Intelligence continues to grow it is becoming\nmore and more important to investigate formalization and tools that allow us to\nexploit logic to reason about the world. In particular, given the increasing\nnumber of multi-agents systems that could benefit from techniques of automated\nreasoning, exploring new ways to define not only the world's status but also\nthe agents' information is constantly growing in importance. This type of\nreasoning, i.e., about agents' perception of the world and also about agents'\nknowledge of her and others' knowledge, is referred to as epistemic reasoning.\n  In our work we will try to formalize this concept, expressed through\nepistemic logic, for dynamic domains. In particular we will attempt to define a\nnew action-based language for multi-agent epistemic planning and to implement\nan epistemic planner based on it. This solver should provide a tool flexible\nenough to be able to reason on different domains, e.g., economy, security,\njustice and politics, where reasoning about others' beliefs could lead to\nwinning strategies or help in changing a group of agents' view of the world.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:14:28 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Fabiano", "Francesco", "", "University of Udine"]]}, {"id": "1909.08260", "submitter": "EPTCS", "authors": "Francesco Pacenza (University of Calabria - Department of Mathematics\n  and Computer Science)", "title": "Reasoning in Highly Reactive Environments", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 420-426", "doi": "10.4204/EPTCS.306.57", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of my Ph.D. thesis concerns Reasoning in Highly Reactive\nEnvironments. As reasoning in highly reactive environments, we identify the\nsetting in which a knowledge-based agent, with given goals, is deployed in an\nenvironment subject to repeated, sudden and possibly unknown changes. This is\nfor instance the typical setting in which, e.g., artificial agents for\nvideo-games (the so called \"bots\"), cleaning robots, bomb clearing robots, and\nso on are deployed. In all these settings one can follow the classical approach\nin which the operations of the agent are distinguished in \"sensing\" the\nenvironment with proper interface devices, \"thinking\", and then behaving\naccordingly using proper actuators. In order to operate in an highly reactive\nenvironment, an artificial agent needs to be: 1. Responsive -> The agent must\nbe able to react repeatedly and in a reasonable amount of time; 2. Elastic ->\nThe agent must stay reactive also under varying workload; 3. Resilient -> The\nagent must stay responsive also in case of internal failure or failure of one\nof the programmed actions in the environment. Nowadays, thanks to new\ntechnologies in the field of Artificial Intelligence, it is already technically\npossible to create AI agents that are able to operate in reactive environments.\nNevertheless, several issues stay unsolved, and are subject of ongoing\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:15:09 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Pacenza", "Francesco", "", "University of Calabria - Department of Mathematics\n  and Computer Science"]]}, {"id": "1909.08263", "submitter": "EPTCS", "authors": "Marco De Bortoli (Graz University of Technology)", "title": "Distributed Answer Set Coloring: Stable Models Computation via Graph\n  Coloring", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 441-451", "doi": "10.4204/EPTCS.306.60", "report-no": null, "categories": "cs.DC cs.AI cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a famous logic language for knowledge\nrepresentation, which has been really successful in the last years, as\nwitnessed by the great interest into the development of efficient solvers for\nASP. Yet, the great request of resources for certain types of problems, as the\nplanning ones, still constitutes a big limitation for problem solving.\nParticularly, in the case the program is grounded before the resolving phase,\nan exponential blow up of the grounding can generate a huge ground file,\ninfeasible for single machines with limited resources, thus preventing even the\ndiscovering of a single non-optimal solution. To address this problem, in this\npaper we present a distributed approach to ASP solving, exploiting distributed\ncomputation benefits in order to overcome the just explained limitations. The\nhere presented tool, which is called Distributed Answer Set Coloring (DASC), is\na pure solver based on the well-known Graph Coloring algorithm. DASC is part of\na bigger project aiming to bring logic programming into a distributed system,\nstarted in 2017 by Federico Igne with mASPreduce and continued in 2018 by\nPietro Totis with a distributed grounder. In this paper we present a low level\nimplementation of the Graph Coloring algorithm, via the Boost and MPI libraries\nfor C++. Finally, we provide a few results of the very first working version of\nour tool, at the moment without any strong optimization or heuristic.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:16:15 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["De Bortoli", "Marco", "", "Graz University of Technology"]]}, {"id": "1909.08538", "submitter": "EPTCS", "authors": "Daniel Neider (Max Planck Institute for Software Systems), Alexander\n  Weinert (German Aerospace Center (DLR), Simulation and Software Technology),\n  Martin Zimmermann (University of Liverpool)", "title": "Robust, Expressive, and Quantitative Linear Temporal Logics: Pick any\n  Two for Free", "comments": "In Proceedings GandALF 2019, arXiv:1909.05979. arXiv admin note:\n  substantial text overlap with arXiv:1808.09028", "journal-ref": "EPTCS 305, 2019, pp. 1-16", "doi": "10.4204/EPTCS.305.1", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Temporal Logic (LTL) is the standard specification language for\nreactive systems and is successfully applied in industrial settings. However,\nmany shortcomings of LTL have been identified in the literature, among them the\nlimited expressiveness, the lack of quantitative features, and the inability to\nexpress robustness. There is work on overcoming these shortcomings, but each of\nthese is typically addressed in isolation. This is insufficient for\napplications where all shortcomings manifest themselves simultaneously. Here,\nwe tackle this issue by introducing logics that address more than one\nshortcoming. To this end, we combine the logics Linear Dynamic Logic,\nPrompt-LTL, and robust LTL, each addressing one aspect, to new logics. For all\ncombinations of two aspects, the resulting logic has the same desirable\nalgorithmic properties as plain LTL. In particular, the highly efficient\nalgorithmic backends that have been developed for LTL are also applicable to\nthese new logics. Finally, we discuss how to address all three aspects\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:51:09 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Neider", "Daniel", "", "Max Planck Institute for Software Systems"], ["Weinert", "Alexander", "", "German Aerospace Center"], ["Zimmermann", "Martin", "", "University of Liverpool"]]}, {"id": "1909.08541", "submitter": "EPTCS", "authors": "Paritosh K. Pandya (Tata Institute of Fundamental Research, Mumbai),\n  Amol Wakankar (Homi Bhabha National Institute, Mumbai and Bhabha Atomic\n  Research Centre, Mumbai)", "title": "Specification and Optimal Reactive Synthesis of Run-time Enforcement\n  Shields", "comments": "In Proceedings GandALF 2019, arXiv:1909.05979. arXiv admin note: text\n  overlap with arXiv:1905.11157", "journal-ref": "EPTCS 305, 2019, pp. 91-106", "doi": "10.4204/EPTCS.305.7", "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system with sporadic errors (SSE) is a controller which produces high\nquality output but it may occasionally violate a critical requirement REQ(I,O).\nA run-time enforcement shield is a controller which takes (I,O) (coming from\nSSE) as its input, and it produces a corrected output O' which guarantees the\ninvariance of requirement REQ(I,O'). Moreover, the output sequence O' must\ndeviate from O \"as little as possible\" to maintain the quality. In this paper,\nwe give a method for logical specification of shields using formulas of logic\nQuantified Discrete Duration Calculus (QDDC). The specification consists of a\ncorrectness requirement REQ as well as a hard deviation constraint HDC which\nmust both be mandatorily and invariantly satisfied by the shield. Moreover, we\nalso use quantitative optimization to give a shield which minimizes the\nexpected value of cumulative deviation in an H-optimal fashion. We show how\ntool DCSynth implementing soft requirement guided synthesis can be used for\nautomatic synthesis of shields from a given specification. Next, we give\nlogical formulas specifying several notions of shields including the\nk-Stabilizing shield of Bloem \"et al.\" as well as the Burst-error shield of Wu\n\"et al.\", and a new e,d-shield. Shields can be automatically synthesized for\nall these specifications using the tool DCSynth. We give experimental results\nshowing the performance of our shield synthesis tool in relation to previous\nwork. We also compare the performance of the shields synthesized under diverse\nhard deviation constraints in terms of their expected deviation and the worst\ncase burst-deviation latency.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:59:14 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Pandya", "Paritosh K.", "", "Tata Institute of Fundamental Research, Mumbai"], ["Wakankar", "Amol", "", "Homi Bhabha National Institute, Mumbai and Bhabha Atomic\n  Research Centre, Mumbai"]]}, {"id": "1909.08559", "submitter": "Dazhu Li", "authors": "Alexandru Baltag, Dazhu Li, and Mina Young Pedersen", "title": "On the Right Path: A Modal Logic for Supervised Learning", "comments": "The paper was accepted by LORI 2019. But due to the page-limit\n  constraints, that Proceedings version does not include any proofs. In this\n  version, we show the proofs for the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal learning theory formalizes the process of inferring a general result\nfrom examples, as in the case of inferring grammars from sentences when\nlearning a language. Although empirical evidence suggests that children can\nlearn a language without responding to the correction of linguistic mistakes,\nthe importance of Teacher in many other paradigms is significant. Instead of\nfocusing only on learner(s), this work develops a general framework---the\nsupervised learning game (SLG)---to investigate the interaction between Teacher\nand Learner. In particular, our proposal highlights several interesting\nfeatures of the agents: on the one hand,Learner may make mistakes in the\nlearning process, and she may also ignore the potential relation between\ndifferent hypotheses; on the other hand, Teacher is able to correct Learner's\nmistakes, eliminate potential mistakes and point out the facts ignored by\nLearner. To reason about strategies in this game, we develop a modal logic of\nsupervised learning (SLL). Broadly, this work takes a small step towards\nstudying the interaction between graph games, logics and formal learning\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:28:13 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Baltag", "Alexandru", ""], ["Li", "Dazhu", ""], ["Pedersen", "Mina Young", ""]]}, {"id": "1909.08998", "submitter": "EPTCS", "authors": "Joohyung Lee (Arizona State University), Man Luo (Arizona State\n  University)", "title": "Strong Equivalence for LPMLN Programs", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note: text\n  overlap with arXiv:1905.07550", "journal-ref": "EPTCS 306, 2019, pp. 196-209", "doi": "10.4204/EPTCS.306.24", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LPMLN is a probabilistic extension of answer set programs with the weight\nscheme adapted from Markov Logic. We study the concept of strong equivalence in\nLPMLN, which is a useful mathematical tool for simplifying a part of an LPMLN\nprogram without looking at the rest of it. We show that the verification of\nstrong equivalence in LPMLN can be reduced to equivalence checking in classical\nlogic via a reduct and choice rules as well as to equivalence checking under\nthe \"soft\" logic of here-and-there. The result allows us to leverage an answer\nset solver for LPMLN strong equivalence checking. The study also suggests us a\nfew reformulations of the LPMLN semantics using choice rules, the logic of\nhere-and-there, and classical logic.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:06:51 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Lee", "Joohyung", "", "Arizona State University"], ["Luo", "Man", "", "Arizona State\n  University"]]}, {"id": "1909.09017", "submitter": "EPTCS", "authors": "Farhad Shakerin (The University of Texas at Dallas)", "title": "Induction of Non-monotonic Logic Programs To Explain Statistical\n  Learning Models", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note:\n  substantial text overlap with arXiv:1808.00629, arXiv:1905.11226,\n  arXiv:1802.06462, arXiv:1707.02693", "journal-ref": "EPTCS 306, 2019, pp. 379-388", "doi": "10.4204/EPTCS.306.51", "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast and scalable algorithm to induce non-monotonic logic\nprograms from statistical learning models. We reduce the problem of search for\nbest clauses to instances of the High-Utility Itemset Mining (HUIM) problem. In\nthe HUIM problem, feature values and their importance are treated as\ntransactions and utilities respectively. We make use of TreeExplainer, a fast\nand scalable implementation of the Explainable AI tool SHAP, to extract locally\nimportant features and their weights from ensemble tree models. Our experiments\nwith UCI standard benchmarks suggest a significant improvement in terms of\nclassification evaluation metrics and running time of the training algorithm\ncompared to ALEPH, a state-of-the-art Inductive Logic Programming (ILP) system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:12:42 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shakerin", "Farhad", "", "The University of Texas at Dallas"]]}, {"id": "1909.09058", "submitter": "EPTCS", "authors": "Sarat Chandra Varanasi", "title": "Imperative Program Synthesis from Answer Set Programs", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 413-417", "doi": "10.4204/EPTCS.306.55", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research concerns generating imperative programs from Answer Set\nProgramming Specifications. ASP is highly declarative and is ideal for writing\nspecifications. Further with negation-as-failure it is easy to succinctly\nrepresent combinatorial search problems. We are currently working on\nsynthesizing imperative programs from ASP programs by turning the negation into\nuseful computations. This opens up a novel way to synthesize programs from\nexecutable specifications.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:56:47 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Varanasi", "Sarat Chandra", ""]]}, {"id": "1909.09142", "submitter": "Sai Krishnan Chandrasekar", "authors": "Hao Ren, Sai Krishnan Chandrasekar, Anitha Murugesan", "title": "Using Quantifier Elimination to Enhance the Safety Assurance of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the field of Machine Learning and Deep Neural Networks (DNNs) has\nenabled rapid development of sophisticated and autonomous systems. However, the\ninherent complexity to rigorously assure the safe operation of such systems\nhinders their real-world adoption in safety-critical domains such as aerospace\nand medical devices. Hence, there is a surge in interest to explore the use of\nadvanced mathematical techniques such as formal methods to address this\nchallenge. In fact, the initial results of such efforts are promising. Along\nthese lines, we propose the use of quantifier elimination (QE) - a formal\nmethod technique, as a complimentary technique to the state-of-the-art static\nanalysis and verification procedures. Using an airborne collision avoidance DNN\nas a case example, we illustrate the use of QE to formulate the precise range\nforward propagation through a network as well as analyze its robustness. We\ndiscuss the initial results of this ongoing work and explore the future\npossibilities of extending this approach and/or integrating it with other\napproaches to perform advanced safety assurance of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:54:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ren", "Hao", ""], ["Chandrasekar", "Sai Krishnan", ""], ["Murugesan", "Anitha", ""]]}, {"id": "1909.09209", "submitter": "EPTCS", "authors": "Daoming Lyu (Auburn University), Fangkai Yang (NVIDIA Corporation), Bo\n  Liu (Auburn University), Steven Gustafson (Maana Inc.)", "title": "A Human-Centered Data-Driven Planner-Actor-Critic Architecture via Logic\n  Programming", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note:\n  significant text overlap with arXiv:1906.07268", "journal-ref": "EPTCS 306, 2019, pp. 182-195", "doi": "10.4204/EPTCS.306.23", "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes of Reinforcement Learning (RL) allow an agent to learn\npolicies that surpass human experts but suffers from being time-hungry and\ndata-hungry. By contrast, human learning is significantly faster because prior\nand general knowledge and multiple information resources are utilized. In this\npaper, we propose a Planner-Actor-Critic architecture for huMAN-centered\nplanning and learning (PACMAN), where an agent uses its prior, high-level,\ndeterministic symbolic knowledge to plan for goal-directed actions, and also\nintegrates the Actor-Critic algorithm of RL to fine-tune its behavior towards\nboth environmental rewards and human feedback. This work is the first unified\nframework where knowledge-based planning, RL, and human teaching jointly\ncontribute to the policy learning of an agent. Our experiments demonstrate that\nPACMAN leads to a significant jump-start at the early stage of learning,\nconverges rapidly and with small variance, and is robust to inconsistent,\ninfrequent, and misleading feedback.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:06:06 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lyu", "Daoming", "", "Auburn University"], ["Yang", "Fangkai", "", "NVIDIA Corporation"], ["Liu", "Bo", "", "Auburn University"], ["Gustafson", "Steven", "", "Maana Inc."]]}, {"id": "1909.09454", "submitter": "EPTCS", "authors": "Valentina Pitoni (University of L'Aquila)", "title": "Memory Management in Resource-Bounded Agents", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note:\n  substantial text overlap with arXiv:1909.08256", "journal-ref": "EPTCS 306, 2019, pp. 452-460", "doi": "10.4204/EPTCS.306.61", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In artificial intelligence, multi agent systems constitute an interesting\ntypology of society modeling, and have in this regard vast fields of\napplication, which extend to the human sciences. Logic is often used to model\nsuch kind of systems as it is easier to verify the explainability and\nvalidation, so for this reason we have tried to manage agents' memory extending\na previous work by inserting the concept of time.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:16:45 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Pitoni", "Valentina", "", "University of L'Aquila"]]}, {"id": "1909.10493", "submitter": "Chunhui Guo", "authors": "Chunhui Guo, Zhicheng Fu, Zhenyu Zhang, Shangping Ren, Lui Sha", "title": "Formalism for Supporting the Development of Verifiably Safe Medical\n  Guidelines with Statecharts", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the effectiveness and safety of patient care is the ultimate\nobjective for medical cyber-physical systems. Many medical best practice\nguidelines exist, but most of the existing guidelines in handbooks are\ndifficult for medical staff to remember and apply clinically. Furthermore,\nalthough the guidelines have gone through clinical validations, validations by\nmedical professionals alone do not provide guarantees for the safety of medical\ncyber-physical systems. Hence, formal verification is also needed. The paper\npresents the formal semantics for a framework that we developed to support the\ndevelopment of verifiably safe medical guidelines.\n  The framework allows computer scientists to work together with medical\nprofessionals to transform medical best practice guidelines into executable\nstatechart models, Yakindu in particular, so that medical functionalities and\nproperties can be quickly prototyped and validated. Existing formal\nverification technologies, UPPAAL timed automata in particular, is integrated\ninto the framework to provide formal verification capabilities to verify safety\nproperties. However, some components used/built into the framework, such as the\nopen-source Yakindu statecharts as well as the transformation rules from\nstatecharts to timed automata, do not have built-in semantics. The ambiguity\nbecomes unavoidable unless formal semantics is defined for the framework, which\nis what the paper is to present.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:25:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Guo", "Chunhui", ""], ["Fu", "Zhicheng", ""], ["Zhang", "Zhenyu", ""], ["Ren", "Shangping", ""], ["Sha", "Lui", ""]]}, {"id": "1909.10824", "submitter": "Jeroen Keiren", "authors": "David N. Jansen, Jan Friso Groote, Jeroen J.A. Keiren and Anton Wijs", "title": "A simpler O(m log n) algorithm for branching bisimilarity on labelled\n  transition systems", "comments": "This technical report is also filed as Eindhoven Computer Science\n  report 19-03", "journal-ref": null, "doi": null, "report-no": "CSR-19-03", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branching bisimilarity is a behavioural equivalence relation on labelled\ntransition systems that takes internal actions into account. It has the\ntraditional advantage that algorithms for branching bisimilarity are more\nefficient than all algorithms for other weak behavioural equivalences,\nespecially weak bisimilarity. With $m$ the number of transitions and $n$ the\nnumber of states, the classic $O(m n)$ algorithm was recently replaced by an\n$O(m (\\log \\lvert \\mathit{Act}\\rvert + \\log n))$ algorithm, which is\nunfortunately rather complex. This paper combines its ideas with the ideas from\nValmari. This results in a simpler algorithm with complexity $O(m \\log n)$.\nBenchmarks show that this new algorithm is also faster and often far more\nmemory efficient than its predecessors. This makes it the best option for\nbranching bisimulation minimisation and preprocessing for weak bisimulation of\nLTSs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:48:02 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 07:49:02 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Jansen", "David N.", ""], ["Groote", "Jan Friso", ""], ["Keiren", "Jeroen J. A.", ""], ["Wijs", "Anton", ""]]}, {"id": "1909.10835", "submitter": "Takayuki Kihara", "authors": "Takayuki Kihara and Victor Selivanov", "title": "Wadge-like degrees of Borel bqo-valued functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unite two well known generalisations of the Wadge theory. The first one\nconsiders more general reducing functions than the continuous functions in the\nclassical case, and the second one extends Wadge reducibility from sets (i.e.,\n$\\{0,1\\}$-valued functions) to $Q$-valued functions, for a better quasiorder\n$Q$. In this article, we consider more general reducibilities on the $Q$-valued\nfunctions and generalise some results of L. Motto Ros in the first direction\nand of T. Kihara and A. Montalb\\'an in the second direction: Our main result\nstates that the structure of the $\\mathbf{\\Delta}^0_\\alpha$-degrees of\n$\\mathbf{\\Delta}^0_{\\alpha+\\gamma}$-measurable $Q$-valued functions is\nisomorphic to the $\\mathbf{\\Delta}^0_\\beta$-degrees of\n$\\mathbf{\\Delta}^0_{\\beta+\\gamma}$-measurable $Q$-valued functions, and these\nare isomorphic to the generalized homomorphism order on the $\\gamma$-th\niterated $Q$-labeled forests.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:21:00 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Kihara", "Takayuki", ""], ["Selivanov", "Victor", ""]]}, {"id": "1909.10869", "submitter": "Sam Thompson", "authors": "Dominik D. Freydenberger and Sam M. Thompson", "title": "Dynamic Complexity of Document Spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper investigates the dynamic complexity of document spanners, a\nformal framework for information extraction introduced by Fagin, Kimelfeld,\nReiss, and Vansummeren (JACM 2015). We first look at the class of regular\nspanners and prove that any regular spanner can be maintained in the dynamic\ncomplexity class DynPROP. This result follows from work done previously on the\ndynamic complexity of formal languages by Gelade, Marquardt, and Schwentick\n(TOCL 2012).\n  To investigate core spanners we use SpLog, a concatenation logic that exactly\ncaptures core spanners. We show that the dynamic complexity class DynCQ, is\nmore expressive than SpLog and therefore can maintain any core spanner. This\nresult is then extended to show that DynFO can maintain any generalized core\nspanner and that DynFO is at least as powerful as SpLog with negation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:13:37 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 14:01:43 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Freydenberger", "Dominik D.", ""], ["Thompson", "Sam M.", ""]]}, {"id": "1909.10994", "submitter": "Martin Ritzert", "authors": "Emilie Grienenberger and Martin Ritzert", "title": "Learning definable hypotheses on trees", "comments": "Full version of ICDT 2019 paper", "journal-ref": null, "doi": "10.4230/LIPIcs.ICDT.2019.24", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning properties of nodes in tree structures.\nThose properties are specified by logical formulas, such as formulas from\nfirst-order or monadic second-order logic. We think of the tree as a database\nencoding a large dataset and therefore aim for learning algorithms which depend\nat most sublinearly on the size of the tree. We present a learning algorithm\nfor quantifier-free formulas where the running time only depends polynomially\non the number of training examples, but not on the size of the background\nstructure. By a previous result on strings we know that for general first-order\nor monadic second-order (MSO) formulas a sublinear running time cannot be\nachieved. However, we show that by building an index on the tree in a linear\ntime preprocessing phase, we can achieve a learning algorithm for MSO formulas\nwith a logarithmic learning phase.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 15:22:39 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Grienenberger", "Emilie", ""], ["Ritzert", "Martin", ""]]}, {"id": "1909.11342", "submitter": "Robert Y. Lewis", "authors": "Robert Y. Lewis", "title": "A formal proof of Hensel's lemma over the p-adic integers", "comments": "CPP 2019", "journal-ref": null, "doi": "10.1145/3293880.3294089", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of $p$-adic numbers $\\mathbb{Q}_p$ and the ring of $p$-adic\nintegers $\\mathbb{Z}_p$ are essential constructions of modern number theory.\nHensel's lemma, described by Gouv\\^ea as the \"most important algebraic property\nof the $p$-adic numbers,\" shows the existence of roots of polynomials over\n$\\mathbb{Z}_p$ provided an initial seed point. The theorem can be proved for\nthe $p$-adics with significantly weaker hypotheses than for general rings. We\nconstruct $\\mathbb{Q}_p$ and $\\mathbb{Z}_p$ in the Lean proof assistant, with\nvarious associated algebraic properties, and formally prove a strong form of\nHensel's lemma. The proof lies at the intersection of algebraic and analytic\nreasoning and demonstrates how the Lean mathematical library handles such a\nheterogeneous topic.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 08:42:11 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Lewis", "Robert Y.", ""]]}, {"id": "1909.11350", "submitter": "Igor Sedl\\'ar", "authors": "Igor Sedl\\'ar", "title": "Iterative division in the Distributive Full Non-associative Lambek\n  Calculus", "comments": "2nd DaL\\'i Workshop, Dynamic Logic: New Trends and Applications,\n  Porto 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of the Distributive Full Non-associative Lambek\nCalculus with iterative division operators. The iterative operators can be seen\nas representing iterative composition of linguistic resources or of actions. A\ncomplete axiomatization of the logic is provided and decidability is\nestablished via a proof of the finite model property.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:00:57 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 14:13:40 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Sedl\u00e1r", "Igor", ""]]}, {"id": "1909.11363", "submitter": "Igor Sedl\\'ar", "authors": "Igor Sedl\\'ar and V\\'it Pun\\v{c}och\\'a\\v{r} and Andrew Tedder", "title": "First Degree Entailment with Group Attitudes and Information Updates", "comments": "To appear in the proceedings of the 7th International Conference on\n  Logic, Rationality and Interaction (LORI-VII), Chongquing 2019, to be\n  published by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the epistemic logic with De Morgan negation by Fagin et al. (Artif.\nIntell. 79, 203-240, 1995) by adding operators for universal and common\nknowledge in a group of agents, and with a formalization of information update\nusing a generalized version of the left division connective of the\nnon-associative Lambek calculus. We provide sound and complete axiomatizations\nof the basic logic with the group operators and the basic logic with group\noperators and updates. Both logics are shown to be decidable.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:24:41 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Sedl\u00e1r", "Igor", ""], ["Pun\u010doch\u00e1\u0159", "V\u00edt", ""], ["Tedder", "Andrew", ""]]}, {"id": "1909.11369", "submitter": "M. Praveen", "authors": "Agnishom Chattopadhyay and M. Praveen", "title": "Query Preserving Watermarking Schemes for Locally Treelike Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking is a way of embedding information in digital documents. Much\nresearch has been done on techniques for watermarking relational databases and\nXML documents, where the process of embedding information shouldn't distort\nquery outputs too much. Recently, techniques have been proposed to watermark\nsome classes of relational structures preserving first-order and monadic second\norder queries. For relational structures whose Gaifman graphs have bounded\ndegree, watermarking can be done preserving first-order queries.\n  We extend this line of work and study watermarking schemes for other classes\nof structures. We prove that for relational structures whose Gaifman graphs\nbelong to a class of graphs that have locally bounded tree-width and is closed\nunder minors, watermarking schemes exist that preserve first-order queries. We\nuse previously known properties of logical formulas and graphs, and build on\nthem with some technical work to make them work in our context. This\nconstitutes a part of the first steps to understand the extent to which\ntechniques from algorithm design and computational learning theory can be\nadapted for watermarking.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:36:39 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Chattopadhyay", "Agnishom", ""], ["Praveen", "M.", ""]]}, {"id": "1909.11521", "submitter": "Martin Otto", "authors": "Felix Canavoi and Martin Otto", "title": "Cayley structures and common knowledge", "comments": "journal submission, revised April 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate multi-agent epistemic modal logic with common knowledge\nmodalities for groups of agents and obtain van Benthem style model-theoretic\ncharacterisations, in terms of bisimulation invariance of classical first-order\nlogic over the non-elementary classes of (finite or arbitrary) common knowledge\nKripke frames. The technical challenges posed by the reachability and\ntransitive closure features of the derived accessibility relations are dealt\nwith through passage to (finite) bisimilar coverings of epistemic frames by\nCayley graphs of permutation groups whose generators are associated with the\nagents. Epistemic frame structure is here induced by an algebraic coset\nstructure. Cayley structures with specific acyclicity properties support a\nlocality analysis at different levels of granularity as induced by distance\nmeasures w.r.t. various coalitions of agents.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:27:33 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 07:40:23 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 13:22:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Canavoi", "Felix", ""], ["Otto", "Martin", ""]]}, {"id": "1909.11588", "submitter": "Zhanfu Yang", "authors": "Ziliang Chen, Zhanfu Yang", "title": "Graph Neural Reasoning May Fail in Certifying Boolean Unsatisfiability", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is feasible and practically-valuable to bridge the characteristics between\ngraph neural networks (GNNs) and logical reasoning. Despite considerable\nefforts and successes witnessed to solve Boolean satisfiability (SAT), it\nremains a mystery of GNN-based solvers for more complex predicate logic\nformulae. In this work, we conjectures with some evidences, that\ngenerally-defined GNNs present several limitations to certify the\nunsatisfiability (UNSAT) in Boolean formulae. It implies that GNNs may probably\nfail in learning the logical reasoning tasks if they contain proving UNSAT as\nthe sub-problem included by most predicate logic formulae.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:24:50 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 16:57:26 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chen", "Ziliang", ""], ["Yang", "Zhanfu", ""]]}, {"id": "1909.11591", "submitter": "Mohammadhosein Hasanbeig", "authors": "Lim Zun Yuan, Mohammadhosein Hasanbeig, Alessandro Abate, Daniel\n  Kroening", "title": "Modular Deep Reinforcement Learning with Temporal Logic Specifications", "comments": "arXiv admin note: text overlap with arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an actor-critic, model-free, and online Reinforcement Learning\n(RL) framework for continuous-state continuous-action Markov Decision Processes\n(MDPs) when the reward is highly sparse but encompasses a high-level temporal\nstructure. We represent this temporal structure by a finite-state machine and\nconstruct an on-the-fly synchronised product with the MDP and the finite\nmachine. The temporal structure acts as a guide for the RL agent within the\nproduct, where a modular Deep Deterministic Policy Gradient (DDPG) architecture\nis proposed to generate a low-level control policy. We evaluate our framework\nin a Mars rover experiment and we present the success rate of the synthesised\npolicy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:10:00 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 12:57:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yuan", "Lim Zun", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1909.11593", "submitter": "Felix Klaedtke", "authors": "David Basin and Felix Klaedtke and Eugen Zalinescu", "title": "Runtime Verification over Out-of-order Streams", "comments": "preprint of journal article (ACM Transactions of Computational\n  Logic). arXiv admin note: text overlap with arXiv:1707.05555", "journal-ref": null, "doi": "10.1145/3355609", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for verifying systems at runtime. Our approach targets\ndistributed systems whose components communicate with monitors over unreliable\nchannels, where messages can be delayed, reordered, or even lost. Furthermore,\nour approach handles an expressive specification language that extends the\nreal-time logic MTL with freeze quantifiers for reasoning about data values.\nThe logic's main novelty is a new three-valued semantics that is well suited\nfor runtime verification as it accounts for partial knowledge about a system's\nbehavior. Based on this semantics, we present online algorithms that reason\nsoundly and completely about streams where events can occur out of order. We\nalso evaluate our algorithms experimentally. Depending on the specification,\nour prototype implementation scales to out-of-order streams with hundreds to\nthousands of events per second.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 08:06:50 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Basin", "David", ""], ["Klaedtke", "Felix", ""], ["Zalinescu", "Eugen", ""]]}, {"id": "1909.11693", "submitter": "Bernardo Anibal Subercaseaux Roa", "authors": "Pablo Barcel\\'o, Nelson Higuera, Jorge P\\'erez and Bernardo\n  Subercaseaux", "title": "On the Expressiveness of LARA: A Unified Language for Linear and\n  Relational Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressive power of the LARA language -- a recently proposed\nunified model for expressing relational and linear algebra operations -- both\nin terms of traditional database query languages and some analytic tasks often\nperformed in machine learning pipelines. We start by showing LARA to be\nexpressive complete with respect to first-order logic with aggregation. Since\nLARA is parameterized by a set of user-defined functions which allow to\ntransform values in tables, the exact expressive power of the language depends\non how these functions are defined. We distinguish two main cases depending on\nthe level of genericity queries are enforced to satisfy. Under strong\ngenericity assumptions the language cannot express matrix convolution, a very\nimportant operation in current machine learning operations. This language is\nalso local, and thus cannot express operations such as matrix inverse that\nexhibit a recursive behavior. For expressing convolution, one can relax the\ngenericity requirement by adding an underlying linear order on the domain.\nThis, however, destroys locality and turns the expressive power of the language\nmuch more difficult to understand. In particular, although under complexity\nassumptions the resulting language can still not express matrix inverse, a\nproof of this fact without such assumptions seems challenging to obtain.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:20:52 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Barcel\u00f3", "Pablo", ""], ["Higuera", "Nelson", ""], ["P\u00e9rez", "Jorge", ""], ["Subercaseaux", "Bernardo", ""]]}, {"id": "1909.12135", "submitter": "Blai Bonet", "authors": "Blai Bonet, Giuseppe De Giacomo, Hector Geffner, Sasha Rubin", "title": "Generalized Planning: Non-Deterministic Abstractions and Trajectory\n  Constraints", "comments": "Proceedings IJCAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the characterization and computation of general policies for\nfamilies of problems that share a structure characterized by a common reduction\ninto a single abstract problem. Policies $\\mu$ that solve the abstract problem\nP have been shown to solve all problems Q that reduce to P provided that $\\mu$\nterminates in Q. In this work, we shed light on why this termination condition\nis needed and how it can be removed. The key observation is that the abstract\nproblem P captures the common structure among the concrete problems Q that is\nlocal (Markovian) but misses common structure that is global. We show how such\nglobal structure can be captured by means of trajectory constraints that in\nmany cases can be expressed as LTL formulas, thus reducing generalized planning\nto LTL synthesis. Moreover, for a broad class of problems that involve integer\nvariables that can be increased or decreased, trajectory constraints can be\ncompiled away, reducing generalized planning to fully observable\nnon-deterministic planning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:17:04 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bonet", "Blai", ""], ["De Giacomo", "Giuseppe", ""], ["Geffner", "Hector", ""], ["Rubin", "Sasha", ""]]}, {"id": "1909.12211", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "On the complexity of the clone membership problem", "comments": "30 pages", "journal-ref": "Theory of Computing Systems 65 (2021), no. 5, pp. 839--868", "doi": "10.1007/s00224-020-10016-7", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of the Boolean clone membership problem (CMP):\ngiven a set of Boolean functions $F$ and a Boolean function $f$, determine if\n$f$ is in the clone generated by $F$, i.e., if it can be expressed by a circuit\nwith $F$-gates. Here, $f$ and elements of $F$ are given as circuits or formulas\nover the usual De Morgan basis. B\\\"ohler and Schnoor (2007) proved that for any\nfixed $F$, the problem is coNP-complete, with a few exceptions where it is in\nP. Vollmer (2009) incorrectly claimed that the full problem CMP is also\ncoNP-complete. We prove that CMP is in fact $\\Theta^P_2$-complete, and we\ncomplement B\\\"ohler and Schnoor's results by showing that for fixed $f$, the\nproblem is NP-complete unless $f$ is a projection.\n  More generally, we study the problem $B$-CMP where $F$ and $f$ are given by\ncircuits using gates from $B$. For most choices of $B$, we classify the\ncomplexity of $B$-CMP as being $\\Theta^P_2$-complete (possibly under randomized\nreductions), coDP-complete, or in P.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:03:17 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 07:32:11 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 17:06:23 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 16:53:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1909.12386", "submitter": "Michael Blondin", "authors": "Michael Blondin and Christoph Haase and Filip Mazowiecki and Mikhail\n  Raskin", "title": "Affine Extensions of Integer Vector Addition Systems with States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the reachability problem for affine $\\mathbb{Z}$-VASS, which are\ninteger vector addition systems with states in which transitions perform affine\ntransformations on the counters. This problem is easily seen to be undecidable\nin general, and we therefore restrict ourselves to affine $\\mathbb{Z}$-VASS\nwith the finite-monoid property (afmp-$\\mathbb{Z}$-VASS). The latter have the\nproperty that the monoid generated by the matrices appearing in their affine\ntransformations is finite. The class of afmp-$\\mathbb{Z}$-VASS encompasses\nclassical operations of counter machines such as resets, permutations,\ntransfers and copies. We show that reachability in an afmp-$\\mathbb{Z}$-VASS\nreduces to reachability in a $\\mathbb{Z}$-VASS whose control-states grow\nlinearly in the size of the matrix monoid. Our construction shows that\nreachability relations of afmp-$\\mathbb{Z}$-VASS are semilinear, and in\nparticular enables us to show that reachability in $\\mathbb{Z}$-VASS with\ntransfers and $\\mathbb{Z}$-VASS with copies is PSPACE-complete. We then focus\non the reachability problem for affine $\\mathbb{Z}$-VASS with monogenic\nmonoids: (possibly infinite) matrix monoids generated by a single matrix. We\nshow that, in a particular case, the reachability problem is decidable for this\nclass, disproving a conjecture about affine $\\mathbb{Z}$-VASS with infinite\nmatrix monoids we raised in a preliminary version of this paper. We complement\nthis result by presenting an affine $\\mathbb{Z}$-VASS with monogenic matrix\nmonoid and undecidable reachability relation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:00:13 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 14:48:50 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 11:52:44 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blondin", "Michael", ""], ["Haase", "Christoph", ""], ["Mazowiecki", "Filip", ""], ["Raskin", "Mikhail", ""]]}, {"id": "1909.12582", "submitter": "Lionel Rieg", "authors": "G\\'erard Berry and Lionel Rieg", "title": "Towards Coq-verified Esterel Semantics and Compiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on semantics of the Esterel synchronous programming\nlanguage. In particular, in addition to the usual behavioral (CBS) and state\n(CSS) semantics, it introduces a novel microstep semantics which does not need\nthe Can potential function. Formal proofs in Coq of the equivalence between the\nCBS and CSS semantics and of the refinement between the CSS and microstep\nsemantics are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 09:43:14 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Berry", "G\u00e9rard", ""], ["Rieg", "Lionel", ""]]}, {"id": "1909.12635", "submitter": "Tayssir Touili", "authors": "Tayssir Touili and Xin Ye", "title": "LTL Model Checking of Self Modifying Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self modifying code is code that can modify its own instructions during the\nexecution of the program. It is extensively used by malware writers to\nobfuscate their malicious code. Thus, analysing self modifying code is nowadays\na big challenge. In this paper, we consider the LTL model-checking problem of\nself modifying code. We model such programs using self-modifying pushdown\nsystems (SM-PDS), an extension of pushdown systems that can modify its own set\nof transitions during execution. We reduce the LTL model-checking problem to\nthe emptiness problem of self-modifying B\\\"uchi pushdown systems (SM-BPDS). We\nimplemented our techniques in a tool that we successfully applied for the\ndetection of several self-modifying malware. Our tool was also able to detect\nseveral malwares that well-known antiviruses such as BitDefender, Kinsoft,\nAvira, eScan, Kaspersky, Qihoo-360, Baidu, Avast, and Symantec failed to\ndetect.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 11:49:26 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Touili", "Tayssir", ""], ["Ye", "Xin", ""]]}, {"id": "1909.12656", "submitter": "Lhouari Nourine", "authors": "Lhouari Nourine and Jean Marc Petit and Simon Vilmin", "title": "Towards declarative comparabilities: application to functional\n  dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether two values can be considered as equal is more subtle and complex than\nit seems. In practice, only domain experts could tell what does \"equality\"\nmean. Surprisingly, declarative frameworks allowing to specify equality at a\nhighlevel of abstraction are missing. Thus, we introduce a lattice-based\ndeclarative framework to cope with this issue.\n  First, we assign a comparability function to each attribute of the relation\nscheme.\n  This function maps each pair of the attribute's domain to a truth value in a\ntruth lattice.\n  Then, we associate a lattice of comparabilities to every relation, comparing\npairwise its tuples.\n  We define realities being {0,1}-interpretations of this lattice. Realities\nmodel several interpretations of equality. In this setting, we define abstract\nFDs, from which the semantics of classical FDs can be recovered with realities.\n  Eventually, we apply the notions of possible/certain answers in databases to\nFDs and study associated complexity and problems.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:45:20 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 16:26:26 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 17:27:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Nourine", "Lhouari", ""], ["Petit", "Jean Marc", ""], ["Vilmin", "Simon", ""]]}, {"id": "1909.12738", "submitter": "Riccardo De Masellis", "authors": "Riccardo De Masellis and Chiara Di Francescomarino and Chiara Ghidini\n  and Sergio Tessaris", "title": "Solving reachability problems on data-aware workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the field of Business Process Management have brought\nabout several suites able to model complex data objects along with the\ntraditional control flow perspective. Nonetheless, when it comes to formal\nverification there is still the lack of effective verification tools on\nimperative data-aware process models and executions: the data perspective is\noften abstracted away and verification tools are often missing. In this paper\nwe provide a concrete framework for formal verification of reachability\nproperties on imperative data-aware business processes. We start with an\nexpressive, yet empirically tractable class of data-aware process models, an\nextension of Workflow Nets, and we provide a rigorous mapping between the\nsemantics of such models and that of three important paradigms for reasoning\nabout dynamic systems: Action Languages, Classical Planning, and Model\nChecking. Then we perform a comprehensive assessment of the performance of\nthree popular tools supporting the above paradigms in solving reachability\nproblems for imperative data-aware business processes, which paves the way for\na theoretically well founded and practically viable exploitation of formal\nverification techniques on data-aware business processes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:15:55 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 15:07:02 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["De Masellis", "Riccardo", ""], ["Di Francescomarino", "Chiara", ""], ["Ghidini", "Chiara", ""], ["Tessaris", "Sergio", ""]]}, {"id": "1909.13376", "submitter": "Thorsten Wissmann", "authors": "Wen Kokke, J. Garrett Morris, Philip Wadler", "title": "Towards Races in Linear Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (December\n  15, 2020) lmcs:6979", "doi": "10.23638/LMCS-16(4:15)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Process calculi based in logic, such as $\\pi$DILL and CP, provide a\nfoundation for deadlock-free concurrent programming, but exclude\nnon-determinism and races. HCP is a reformulation of CP which addresses a\nfundamental shortcoming: the fundamental operator for parallel composition from\nthe $\\pi$-calculus does not correspond to any rule of linear logic, and\ntherefore not to any term construct in CP.\n  We introduce non-deterministic HCP, which extends HCP with a novel account of\nnon-determinism. Our approach draws on bounded linear logic to provide a\nstrongly-typed account of standard process calculus expressions of\nnon-determinism. We show that our extension is expressive enough to capture\nmany uses of non-determinism in untyped calculi, such as non-deterministic\nchoice, while preserving HCP's meta-theoretic properties, including deadlock\nfreedom.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:49:53 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 21:27:39 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 17:16:13 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2020 13:06:13 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kokke", "Wen", ""], ["Morris", "J. Garrett", ""], ["Wadler", "Philip", ""]]}, {"id": "1909.13444", "submitter": "Hiromi Tanaka", "authors": "Hiromi Tanaka", "title": "A note on undecidability of propositional non-associative linear logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a non-associative and non-commutative version of propositional\nintuitionistic linear logic, called propositional non-associative\nnon-commutative intuitionistic linear logic (NACILL for short). We prove that\nNACILL and any of its extensions by the rules of exchange and/or contraction\nare undecidable. Furthermore, we introduce two types of classical versions of\nNACILL, i.e., an involutive version of NACILL and a cyclic and involutive\nversion of NACILL. We show that both of these logics are also undecidable.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 03:42:36 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Tanaka", "Hiromi", ""]]}, {"id": "1909.13514", "submitter": "J\\'an Komara", "authors": "Paul J. Voda, J\\'an Komara", "title": "On Herbrand Skeletons", "comments": "24 pages; reprint of the revision of the technical report", "journal-ref": null, "doi": null, "report-no": "Technical Report mff-ii-02-1995", "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herbrand's theorem plays an important role both in proof theory and in\ncomputer science. Given a Herbrand skeleton, which is basically a number\nspecifying the count of disjunctions of the matrix, we would like to get a\ncomputable bound on the size of terms which make the disjunction into a\nquasitautology. This is an important problem in logic, specifically in the\ncomplexity of proofs. In computer science, specifically in automated theorem\nproving, one hopes for an algorithm which avoids the guesses of existential\nsubstitution axioms involved in proving a theorem. Herbrand's theorem forms the\nvery basis of automated theorem proving where for a given number $n$ we would\nlike to have an algorithm which finds the terms in the $n$ disjunctions of\nmatrices solely from the shape of the matrix. The main result of this paper is\nthat both problems have negative solutions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:33:44 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Voda", "Paul J.", ""], ["Komara", "J\u00e1n", ""]]}, {"id": "1909.13768", "submitter": "Damiano Mazza", "authors": "Alois Brunel, Damiano Mazza, Michele Pagani", "title": "Backpropagation in the Simply Typed Lambda-calculus with Linear Negation", "comments": "27 pages", "journal-ref": "Proc. ACM Program. Lang. 4, POPL, Article 64 (January 2020)", "doi": "10.1145/3371132", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation is a classic automatic differentiation algorithm computing\nthe gradient of functions specified by a certain class of simple, first-order\nprograms, called computational graphs. It is a fundamental tool in several\nfields, most notably machine learning, where it is the key for efficiently\ntraining (deep) neural networks. Recent years have witnessed the quick growth\nof a research field called differentiable programming, the aim of which is to\nexpress computational graphs more synthetically and modularly by resorting to\nactual programming languages endowed with control flow operators and\nhigher-order combinators, such as map and fold. In this paper, we extend the\nbackpropagation algorithm to a paradigmatic example of such a programming\nlanguage: we define a compositional program transformation from the\nsimply-typed lambda-calculus to itself augmented with a notion of linear\nnegation, and prove that this computes the gradient of the source program with\nthe same efficiency as first-order backpropagation. The transformation is\ncompletely effect-free and thus provides a purely logical understanding of the\ndynamics of backpropagation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:18:49 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 13:04:53 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Brunel", "Alois", ""], ["Mazza", "Damiano", ""], ["Pagani", "Michele", ""]]}]