[{"id": "1410.0306", "submitter": "Ilya Sergey", "authors": "Ilya Sergey, Aleksandar Nanevski, Anindya Banerjee", "title": "Specifying and Verifying Concurrent Algorithms with Histories and\n  Subjectivity", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a lightweight approach to Hoare-style specifications for\nfine-grained concurrency, based on a notion of time-stamped histories that\nabstractly capture atomic changes in the program state. Our key observation is\nthat histories form a partial commutative monoid, a structure fundamental for\nrepresentation of concurrent resources. This insight provides us with a\nunifying mechanism that allows us to treat histories just like heaps in\nseparation logic. For example, both are subject to the same assertion logic and\ninference rules (e.g., the frame rule). Moreover, the notion of ownership\ntransfer, which usually applies to heaps, has an equivalent in histories. It\ncan be used to formally represent helping---an important design pattern for\nconcurrent algorithms whereby one thread can execute code on behalf of another.\nSpecifications in terms of histories naturally abstract granularity, in the\nsense that sophisticated fine-grained algorithms can be given the same\nspecifications as their simplified coarse-grained counterparts, making them\nequally convenient for client-side reasoning. We illustrate our approach on a\nnumber of examples and validate all of them in Coq.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 17:51:55 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Sergey", "Ilya", ""], ["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""]]}, {"id": "1410.0589", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "An Algorithmic Metatheorem for Directed Treewidth", "comments": "41 pages, 6 figures, Accepted to Discrete Applied Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of directed treewidth was introduced by Johnson, Robertson,\nSeymour and Thomas [Journal of Combinatorial Theory, Series B, Vol 82, 2001] as\na first step towards an algorithmic metatheory for digraphs. They showed that\nsome NP-complete properties such as Hamiltonicity can be decided in polynomial\ntime on digraphs of constant directed treewidth. Nevertheless, despite more\nthan one decade of intensive research, the list of hard combinatorial problems\nthat are known to be solvable in polynomial time when restricted to digraphs of\nconstant directed treewidth has remained scarce. In this work we enrich this\nlist by providing for the first time an algorithmic metatheorem connecting the\nmonadic second order logic of graphs to directed treewidth. We show that most\nof the known positive algorithmic results for digraphs of constant directed\ntreewidth can be reformulated in terms of our metatheorem. Additionally, we\nshow how to use our metatheorem to provide polynomial time algorithms for two\nclasses of combinatorial problems that have not yet been studied in the context\nof directed width measures. More precisely, for each fixed $k,w \\in\n\\mathbb{N}$, we show how to count in polynomial time on digraphs of directed\ntreewidth $w$, the number of minimum spanning strong subgraphs that are the\nunion of $k$ directed paths, and the number of maximal subgraphs that are the\nunion of $k$ directed paths and satisfy a given minor closed property. To prove\nour metatheorem we devise two technical tools which we believe to be of\nindependent interest. First, we introduce the notion of tree-zig-zag number of\na digraph, a new directed width measure that is at most a constant times\ndirected treewidth. Second, we introduce the notion of $z$-saturated tree slice\nlanguage, a new formalism for the specification and manipulation of infinite\nsets of digraphs.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 15:27:00 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2015 07:16:23 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "1410.0833", "submitter": "J\\\"urgen Koslowski", "authors": "Krishnendu Chatterjee, Monika Henzinger, Veronika Loitzenbauer", "title": "Improved Algorithms for Parity and Streett objectives", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  26, 2017) lmcs:3953", "doi": "10.23638/LMCS-13(3:26)2017", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of the winning set for parity objectives and for Streett\nobjectives in graphs as well as in game graphs are central problems in\ncomputer-aided verification, with application to the verification of closed\nsystems with strong fairness conditions, the verification of open systems,\nchecking interface compatibility, well-formedness of specifications, and the\nsynthesis of reactive systems. We show how to compute the winning set on $n$\nvertices for (1) parity-3 (aka one-pair Streett) objectives in game graphs in\ntime $O(n^{5/2})$ and for (2) k-pair Streett objectives in graphs in time\n$O(n^2 + nk \\log n)$. For both problems this gives faster algorithms for dense\ngraphs and represents the first improvement in asymptotic running time in 15\nyears.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 12:24:33 GMT"}, {"version": "v2", "created": "Tue, 7 Oct 2014 09:12:00 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 09:01:29 GMT"}, {"version": "v4", "created": "Fri, 22 Sep 2017 19:01:16 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Henzinger", "Monika", ""], ["Loitzenbauer", "Veronika", ""]]}, {"id": "1410.0893", "submitter": "Marco Peressotti", "authors": "Marino Miculan and Marco Peressotti", "title": "Structural operational semantics for non-deterministic processes with\n  quantitative aspects", "comments": "Extended version of arXiv:1406.2066", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General frameworks have been recently proposed as unifying theories for\nprocesses combining non-determinism with quantitative aspects (such as\nprobabilistic or stochastically timed executions), aiming to provide general\nresults and tools. This paper provides two contributions in this respect.\nFirst, we present a general GSOS specification format and a corresponding\nnotion of bisimulation for non-deterministic processes with quantitative\naspects. These specifications define labelled transition systems according to\nthe ULTraS model, an extension of the usual LTSs where the transition relation\nassociates any source state and transition label with state reachability weight\nfunctions (like, e.g., probability distributions). This format, hence called\nWeight Function GSOS (WF-GSOS), covers many known systems and their\nbisimulations (e.g. PEPA, TIPP, PCSP) and GSOS formats (e.g. GSOS, Weighted\nGSOS, Segala-GSOS, among others).\n  The second contribution is a characterization of these systems as coalgebras\nof a class of functors, parametric on the weight structure. This result allows\nus to prove soundness and completeness of the WF-GSOS specification format, and\nthat bisimilarities induced by these specifications are always congruences.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 16:06:32 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 14:37:44 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Miculan", "Marino", ""], ["Peressotti", "Marco", ""]]}, {"id": "1410.1478", "submitter": "Apostolos Syropoulos", "authors": "Apostolos Syropoulos", "title": "Fuzzy Categories", "comments": null, "journal-ref": "Published in Critical Review, a Publication of Society for\n  Mathematics of Uncertainty, Volume VII, pp 24-29, 2013", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since categories are graphs with additional \"structure\", one should start\nfrom fuzzy graphs in order to define a theory of fuzzy categories. Thus is\nmakes sense to introduce categories whose morphisms are associated with a\nplausibility degree that determines to what extend it is possible to \"go\" from\none object to another one. These categories are called {\\em fuzzy categories}.\nOf course, the basic properties of these categories are similar but not\nidentical to their ordinary counterparts. Thus, it is necessary to introduce\nnotion like fuzzy commutative diagrams, fuzzy initial and fuzzy terminal\nobjects, etc.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 17:59:52 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Syropoulos", "Apostolos", ""]]}, {"id": "1410.2022", "submitter": "Gabriele Puppis", "authors": "Gabriele Puppis (LaBRI - CNRS), Thomas Colcombet (LIAFA - CNRS),\n  Clemens Ley (Independent researcher)", "title": "Logics with rigidly guarded data tests", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  17, 2015) lmcs:1586", "doi": "10.2168/LMCS-11(3:10)2015", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of orbit finite data monoid was recently introduced by Bojanczyk\nas an algebraic object for defining recognizable languages of data words.\nFollowing Buchi's approach, we introduce a variant of monadic second-order\nlogic with data equality tests that captures precisely the data languages\nrecognizable by orbit finite data monoids. We also establish, following this\ntime the approach of Schutzenberger, McNaughton and Papert, that the\nfirst-order fragment of this logic defines exactly the data languages\nrecognizable by aperiodic orbit finite data monoids. Finally, we consider\nanother variant of the logic that can be interpreted over generic structures\nwith data. The data languages defined in this variant are also recognized by\nunambiguous finite memory automata.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 08:39:41 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 15:58:23 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2015 07:53:12 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Puppis", "Gabriele", "", "LaBRI - CNRS"], ["Colcombet", "Thomas", "", "LIAFA - CNRS"], ["Ley", "Clemens", "", "Independent researcher"]]}, {"id": "1410.2128", "submitter": "Nathalie Bertrand", "authors": "Nathalie Bertrand (INRIA Rennes - Bretagne Atlantique), Patricia\n  Bouyer (LSV & ENS Cachan), Thomas Brihaye (Universit\\'e de Mons), Quentin\n  Menet (Universit\\'e de Mons), Christel Baier (Technische Universit\\\"at\n  Dresden), Marcus Groesser (Technische Universit\\\"at Dresden), Marcin\n  Jurdzinski (University of Warwick)", "title": "Stochastic Timed Automata", "comments": "40 pages + appendix", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  9, 2014) lmcs:1092", "doi": "10.2168/LMCS-10(4:6)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic timed automaton is a purely stochastic process defined on a\ntimed automaton, in which both delays and discrete choices are made randomly.\nWe study the almost-sure model-checking problem for this model, that is, given\na stochastic timed automaton A and a property $\\Phi$, we want to decide whether\nA satisfies $\\Phi$ with probability 1. In this paper, we identify several\nclasses of automata and of properties for which this can be decided. The proof\nrelies on the construction of a finite abstraction, called the thick graph,\nthat we interpret as a finite Markov chain, and for which we can decide the\nalmost-sure model-checking problem. Correctness of the abstraction holds when\nautomata are almost-surely fair, which we show, is the case for two large\nclasses of systems, single- clock automata and so-called weak-reactive\nautomata. Techniques employed in this article gather tools from real-time\nverification and probabilistic verification, as well as topological games\nplayed on timed automata.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 14:15:01 GMT"}, {"version": "v2", "created": "Sun, 7 Dec 2014 21:15:14 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bertrand", "Nathalie", "", "INRIA Rennes - Bretagne Atlantique"], ["Bouyer", "Patricia", "", "LSV & ENS Cachan"], ["Brihaye", "Thomas", "", "Universit\u00e9 de Mons"], ["Menet", "Quentin", "", "Universit\u00e9 de Mons"], ["Baier", "Christel", "", "Technische Universit\u00e4t\n  Dresden"], ["Groesser", "Marcus", "", "Technische Universit\u00e4t Dresden"], ["Jurdzinski", "Marcin", "", "University of Warwick"]]}, {"id": "1410.2463", "submitter": "Lutz Schr\\\"oder", "authors": "Alexander Kurz, Stefan Milius, Dirk Pattinson, Lutz Schr\\\"oder", "title": "Simplified Coalgebraic Trace Equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of concurrent and reactive systems is based to a large degree on\nvarious notions of process equivalence, ranging, on the so-called\nlinear-time/branching-time spectrum, from fine-grained equivalences such as\nstrong bisimilarity to coarse-grained ones such as trace equivalence. The\ntheory of concurrent systems at large has benefited from developments in\ncoalgebra, which has enabled uniform definitions and results that provide a\ncommon umbrella for seemingly disparate system types including\nnon-deterministic, weighted, probabilistic, and game-based systems. In\nparticular, there has been some success in identifying a generic coalgebraic\ntheory of bisimulation that matches known definitions in many concrete cases.\nThe situation is currently somewhat less settled regarding trace equivalence. A\nnumber of coalgebraic approaches to trace equivalence have been proposed, none\nof which however cover all cases of interest; notably, all these approaches\ndepend on explicit termination, which is not always imposed in standard\nsystems, e.g. LTS. Here, we discuss a joint generalization of these approaches\nbased on embedding functors modelling various aspects of the system, such as\ntransition and braching, into a global monad; this approach appears to cover\nall cases considered previously and some additional ones, notably standard LTS\nand probabilistic labelled transition systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 13:54:41 GMT"}, {"version": "v2", "created": "Thu, 16 Oct 2014 10:46:36 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Kurz", "Alexander", ""], ["Milius", "Stefan", ""], ["Pattinson", "Dirk", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "1410.2833", "submitter": "Jean-Marie Madiot", "authors": "Ryan Kavanagh and Jean-Marie Madiot", "title": "On Coupled Logical Bisimulation for the Lambda-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study coupled logical bisimulation (CLB) to reason about contextual\nequivalence in the lambda-calculus. CLB originates in a work by Dal Lago,\nSangiorgi and Alberti, as a tool to reason about a lambda-calculus with\nprobabilistic constructs. We adapt the original definition to the pure\nlambda-calculus. We develop the metatheory of CLB in call-by-name and in\ncall-by-value, and draw comparisons with applicative bisimulation (due to\nAbramsky) and logical bisimulation (due to Sangiorgi, Kobayashi and Sumii). We\nalso study enhancements of the bisimulation method for CLB by developing a\ntheory of up-to techniques for cases where the functional corresponding to\nbisimulation is not necessarily monotone.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 16:25:54 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Kavanagh", "Ryan", ""], ["Madiot", "Jean-Marie", ""]]}, {"id": "1410.2901", "submitter": "Thomas Genet", "authors": "Thomas Genet", "title": "Towards Static Analysis of Functional Programs using Tree Automata\n  Completion", "comments": "Proceedings of WRLA'14. 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first step of a wider research effort to apply tree\nautomata completion to the static analysis of functional programs. Tree\nAutomata Completion is a family of techniques for computing or approximating\nthe set of terms reachable by a rewriting relation. The completion algorithm we\nfocus on is parameterized by a set E of equations controlling the precision of\nthe approximation and influencing its termination. For completion to be used as\na static analysis, the first step is to guarantee its termination. In this\nwork, we thus give a sufficient condition on E and T(F) for completion\nalgorithm to always terminate. In the particular setting of functional\nprograms, this condition can be relaxed into a condition on E and T(C) (terms\nbuilt on the set of constructors) that is closer to what is done in the field\nof static analysis, where abstractions are performed on data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 15:11:02 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Genet", "Thomas", ""]]}, {"id": "1410.2910", "submitter": "Daoud Clarke", "authors": "Daoud Clarke", "title": "Riesz Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Riesz Logic, whose models are abelian lattice ordered groups,\nwhich generalise Riesz spaces (vector lattices), and show soundness and\ncompleteness. Our motivation is to provide a logic for distributional semantics\nof natural language, where words are typically represented as elements of a\nvector space whose dimensions correspond to contexts in which words may occur.\nThis basis provides a lattice ordering on the space, and this ordering may be\ninterpreted as \"distributional entailment\". Several axioms of Riesz Logic are\nfamiliar from Basic Fuzzy Logic, and we show how the models of these two logics\nmay be related; Riesz Logic may thus be considered a new fuzzy logic. In\naddition to applications in natural language processing, there is potential for\napplying the theory to neuro-fuzzy systems.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 21:14:02 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Clarke", "Daoud", ""]]}, {"id": "1410.3059", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Computabilities of Validity and Satisfiability in Probability Logics\n  over Finite and Countable Models", "comments": "47 pages, 4 tables. Comments welcome. Fixed errors found by Rutger\n  Kuyper", "journal-ref": "Journal of Applied Non-Classical Logics 25, no. 4 (2015): 324-72", "doi": "10.1080/11663081.2016.1139967", "report-no": null, "categories": "cs.LO cs.LG math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\epsilon$-logic (which is called $\\epsilon$E-logic in this paper) of\nKuyper and Terwijn is a variant of first order logic with the same syntax, in\nwhich the models are equipped with probability measures and in which the\n$\\forall x$ quantifier is interpreted as \"there exists a set $A$ of measure\n$\\ge 1 - \\epsilon$ such that for each $x \\in A$, ....\" Previously, Kuyper and\nTerwijn proved that the general satisfiability and validity problems for this\nlogic are, i) for rational $\\epsilon \\in (0, 1)$, respectively\n$\\Sigma^1_1$-complete and $\\Pi^1_1$-hard, and ii) for $\\epsilon = 0$,\nrespectively decidable and $\\Sigma^0_1$-complete. The adjective \"general\" here\nmeans \"uniformly over all languages.\"\n  We extend these results in the scenario of finite models. In particular, we\nshow that the problems of satisfiability by and validity over finite models in\n$\\epsilon$E-logic are, i) for rational $\\epsilon \\in (0, 1)$, respectively\n$\\Sigma^0_1$- and $\\Pi^0_1$-complete, and ii) for $\\epsilon = 0$, respectively\ndecidable and $\\Pi^0_1$-complete. Although partial results toward the countable\ncase are also achieved, the computability of $\\epsilon$E-logic over countable\nmodels still remains largely unsolved. In addition, most of the results, of\nthis paper and of Kuyper and Terwijn, do not apply to individual languages with\na finite number of unary predicates. Reducing this requirement continues to be\na major point of research.\n  On the positive side, we derive the decidability of the corresponding\nproblems for monadic relational languages --- equality- and function-free\nlanguages with finitely many unary and zero other predicates. This result holds\nfor all three of the unrestricted, the countable, and the finite model cases.\n  Applications in computational learning theory, weighted graphs, and neural\nnetworks are discussed in the context of these decidability and undecidability\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 07:53:00 GMT"}, {"version": "v2", "created": "Fri, 12 Dec 2014 16:47:40 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1410.3125", "submitter": "Martin Mladenov", "authors": "Kristian Kersting, Martin Mladenov, Pavel Tokmakov", "title": "Relational Linear Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose relational linear programming, a simple framework for combing\nlinear programs (LPs) and logic programs. A relational linear program (RLP) is\na declarative LP template defining the objective and the constraints through\nthe logical concepts of objects, relations, and quantified variables. This\nallows one to express the LP objective and constraints relationally for a\nvarying number of individuals and relations among them without enumerating\nthem. Together with a logical knowledge base, effectively a logical program\nconsisting of logical facts and rules, it induces a ground LP. This ground LP\nis solved using lifted linear programming. That is, symmetries within the\nground LP are employed to reduce its dimensionality, if possible, and the\nreduced program is solved using any off-the-shelf LP solver. In contrast to\nmainstream LP template languages like AMPL, which features a mixture of\ndeclarative and imperative programming styles, RLP's relational nature allows a\nmore intuitive representation of optimization problems over relational domains.\nWe illustrate this empirically by experiments on approximate inference in\nMarkov logic networks using LP relaxations, on solving Markov decision\nprocesses, and on collective inference using LP support vector machines.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 18:06:07 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Kersting", "Kristian", ""], ["Mladenov", "Martin", ""], ["Tokmakov", "Pavel", ""]]}, {"id": "1410.3385", "submitter": "Henning Kerstan", "authors": "Paolo Baldan, Filippo Bonchi, Henning Kerstan and Barbara K\\\"onig", "title": "Behavioral Metrics via Functor Lifting", "comments": "to be published in: Proceedings of FSTTCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study behavioral metrics in an abstract coalgebraic setting. Given a\ncoalgebra alpha: X -> FX in Set, where the functor F specifies the branching\ntype, we define a framework for deriving pseudometrics on X which measure the\nbehavioral distance of states.\n  A first crucial step is the lifting of the functor F on Set to a functor in\nthe category PMet of pseudometric spaces. We present two different approaches\nwhich can be viewed as generalizations of the Kantorovich and Wasserstein\npseudometrics for probability measures. We show that the pseudometrics provided\nby the two approaches coincide on several natural examples, but in general they\ndiffer.\n  Then a final coalgebra for F in Set can be endowed with a behavioral distance\nresulting as the smallest solution of a fixed-point equation, yielding the\nfinal coalgebra in PMet. The same technique, applied to an arbitrary coalgebra\nalpha: X -> FX in Set, provides the behavioral distance on X. Under some\nconstraints we can prove that two states are at distance 0 if and only if they\nare behaviorally equivalent.\n", "versions": [{"version": "v1", "created": "Mon, 13 Oct 2014 16:36:01 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Baldan", "Paolo", ""], ["Bonchi", "Filippo", ""], ["Kerstan", "Henning", ""], ["K\u00f6nig", "Barbara", ""]]}, {"id": "1410.3694", "submitter": "John Mullins", "authors": "Sardaouna Hamadou, Abdelouahed Gherbi, John Mullins and Sofiene Beji", "title": "A Time-Triggered Constraint-Based Calculus for Avionic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Integrated Modular Avionics (IMA) architec- ture and the Time-Triggered\nEthernet (TTEthernet) network have emerged as the key components of a typical\narchitecture model for recent civil aircrafts. We propose a real-time\nconstraint-based calculus targeted at the analysis of such concepts of avionic\nembedded systems. We show our framework at work on the modelisation of both the\n(IMA) architecture and the TTEthernet network, illustrating their behavior by\nthe well-known Flight Management System (FMS).\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 00:18:51 GMT"}], "update_date": "2014-10-15", "authors_parsed": [["Hamadou", "Sardaouna", ""], ["Gherbi", "Abdelouahed", ""], ["Mullins", "John", ""], ["Beji", "Sofiene", ""]]}, {"id": "1410.3773", "submitter": "Guozheng Li", "authors": "Guozheng Li, Zining Cao, Zheng Gao", "title": "Refinement Checking for Multirate Hybrid ZIA", "comments": "11pages, 3figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid system is a dynamical system with both discrete and continuous\ncomponents. In order to study the modeling and verification aspects of hybrid\nsystem, in this paper we first introduce a specification approach combining\ninterface automata, initialized multirate hybrid automata and Z language, which\nis named MZIA. Meanwhile we propose a refinement relation on MZIAs. Then we\ngive an algorithm for checking refinement relation between MZIAs with finite\ndomain and demonstrate the correctness of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Oct 2014 08:10:14 GMT"}], "update_date": "2014-10-15", "authors_parsed": [["Li", "Guozheng", ""], ["Cao", "Zining", ""], ["Gao", "Zheng", ""]]}, {"id": "1410.3981", "submitter": "Marcel Jackson G", "authors": "Robin Hirsch, Marcel Jackson and Szabolcs Mikul\\'as", "title": "The algebra of functions with antidomain and range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give complete, finite quasiequational axiomatisations for algebras of\nunary partial functions under the operations of composition, domain,\nantidomain, range and intersection. This completes the extensive programme of\nclassifying algebras of unary partial functions under combinations of these\noperations. We look at the complexity of the equational theories and provide a\nnondeterministic polynomial upper bound. Finally we look at the problem of\nfinite representability and show that finite algebras can be represented as a\ncollection of unary functions over a finite base set provided that intersection\nis not in the signature.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 09:20:50 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Hirsch", "Robin", ""], ["Jackson", "Marcel", ""], ["Mikul\u00e1s", "Szabolcs", ""]]}, {"id": "1410.4011", "submitter": "EPTCS", "authors": "Amir M. Ben-Amram, Aviad Pineles", "title": "Flowchart Programs, Regular Expressions, and Decidability of Polynomial\n  Growth-Rate", "comments": "In Proceedings VPT 2016, arXiv:1607.01835", "journal-ref": "EPTCS 216, 2016, pp. 24-49", "doi": "10.4204/EPTCS.216.2", "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for inferring complexity properties for a class of\nprograms in the form of flowcharts annotated with loop information.\nSpecifically, our method can (soundly and completely) decide if computed values\nare polynomially bounded as a function of the input; and similarly for the\nrunning time. Such complexity properties are undecidable for a Turing-complete\nprogramming language, and a common work-around in program analysis is to settle\nfor sound but incomplete solutions. In contrast, we consider a class of\nprograms that is Turing-incomplete, but strong enough to include several\nchallenges for this kind of analysis. For a related language that has\nwell-structured syntax, similar to Meyer and Ritchie's LOOP programs, the\nproblem has been previously proved to be decidable. The analysis relied on the\ncompositionality of programs, hence the challenge in obtaining similar results\nfor flowchart programs with arbitrary control-flow graphs. Our answer to the\nchallenge is twofold: first, we propose a class of loop-annotated flowcharts,\nwhich is more general than the class of flowcharts that directly represent\nstructured programs; secondly, we present a technique to reuse the ideas from\nthe work on tructured programs and apply them to such flowcharts. The technique\nis inspired by the classic translation of non-deterministic automata to regular\nexpressions, but we obviate the exponential cost of constructing such an\nexpression, obtaining a polynomial-time analysis. These ideas may well be\napplicable to other analysis problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 11:16:16 GMT"}, {"version": "v2", "created": "Sun, 13 Mar 2016 14:40:47 GMT"}, {"version": "v3", "created": "Sun, 20 Mar 2016 10:01:27 GMT"}, {"version": "v4", "created": "Wed, 1 Jun 2016 16:30:18 GMT"}, {"version": "v5", "created": "Fri, 8 Jul 2016 05:30:33 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Ben-Amram", "Amir M.", ""], ["Pineles", "Aviad", ""]]}, {"id": "1410.4027", "submitter": "Paolo Ballarini", "authors": "Paolo Ballarini", "title": "Analysing oscillatory trends of discrete-state stochastic processes\n  through HASL statistical model checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of formal methods to the analysis of stochastic oscillators\nhas been at the focus of several research works in recent times. In this paper\nwe provide insights on the application of an expressive temporal logic\nformalism, namely the Hybrid Automata Stochastic Logic (HASL), to that issue.\nWe show how one can take advantage of the expressive power of the HASL logic to\ndefine and assess relevant characteristics of (stochastic) oscillators.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 11:59:09 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Ballarini", "Paolo", ""]]}, {"id": "1410.4044", "submitter": "Arne Meier", "authors": "Martin L\\\"uck and Arne Meier and Irina Schindler", "title": "Parameterized Complexity of CTL: A Generalization of Courcelle's Theorem", "comments": "Conference version: \"L\\\"uck, Meier, Schindler. Parameterized\n  Complexity of CTL: A Generalization of Courcelle's Theorem. Language and\n  Automata Theory and Applications - 9th International Conference, LATA 2015,\n  Nice, France. Lecture Notes in Computer Science, Volume 8977, pp. 549-560,\n  Springer\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an almost complete classification of the parameterized complexity\nof all operator fragments of the satisfiability problem in computation tree\nlogic CTL. The investigated parameterization is the sum of temporal depth and\nstructural pathwidth. The classification shows a dichotomy between W[1]-hard\nand fixed-parameter tractable fragments. The only real operator fragment which\nis confirmed to be in FPT is the fragment containing solely AX. Also we prove a\ngeneralization of Courcelle's theorem to infinite signatures which will be used\nto proof the FPT-membership case.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 12:49:40 GMT"}, {"version": "v2", "created": "Sun, 23 Nov 2014 15:47:20 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2015 15:26:51 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["L\u00fcck", "Martin", ""], ["Meier", "Arne", ""], ["Schindler", "Irina", ""]]}, {"id": "1410.4235", "submitter": "Brijesh Dongol", "authors": "Brijesh Dongol and Ian J. Hayes and Georg Struth", "title": "Convolution, Separation and Concurrency", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notion of convolution is presented in the context of formal power series\ntogether with lifting constructions characterising algebras of such series,\nwhich usually are quantales. A number of examples underpin the universality of\nthese constructions, the most prominent ones being separation logics, where\nconvolution is separating conjunction in an assertion quantale; interval\nlogics, where convolution is the chop operation; and stream interval functions,\nwhere convolution is used for analysing the trajectories of dynamical or\nreal-time systems. A Hoare logic is constructed in a generic fashion on the\npower series quantale, which applies to each of these examples. In many cases,\ncommutative notions of convolution have natural interpretations as concurrency\noperations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 21:26:30 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Dongol", "Brijesh", ""], ["Hayes", "Ian J.", ""], ["Struth", "Georg", ""]]}, {"id": "1410.4303", "submitter": "EPTCS", "authors": "Nourhene Ellouze (Communication Networks and Security Research Lab,\n  University of Carthage, Tunisia), Slim Rekhis (Communication Networks and\n  Security Research Lab, University of Carthage, Tunisia), Mohamed Allouche\n  (Department of Forensic Medicine of Charles Nicolle, University of Tunis El\n  Manar, Tunisia), Noureddine Boudriga (Communication Networks and Security\n  Research Lab, University of Carthage, Tunisia)", "title": "Digital Investigation of Security Attacks on Cardiac Implantable Medical\n  Devices", "comments": "In Proceedings AIDP 2014, arXiv:1410.3226", "journal-ref": "EPTCS 165, 2014, pp. 15-30", "doi": "10.4204/EPTCS.165.2", "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Cardiac Implantable Medical device (IMD) is a device, which is surgically\nimplanted into a patient's body, and wirelessly configured using an external\nprogrammer by prescribing physicians and doctors. A set of lethal attacks\ntargeting these devices can be conducted due to the use of vulnerable wireless\ncommunication and security protocols, and the lack of security protection\nmechanisms deployed on IMDs. In this paper, we propose a system for postmortem\nanalysis of lethal attack scenarios targeting cardiac IMDs. Such a system\nreconciles in the same framework conclusions derived by technical investigators\nand deductions generated by pathologists. An inference system integrating a\nlibrary of medical rules is used to automatically infer potential medical\nscenarios that could have led to the death of a patient. A Model Checking based\nformal technique allowing the reconstruction of potential technical attack\nscenarios on the IMD, starting from the collected evidence, is also proposed. A\ncorrelation between the results obtained by the two techniques allows to prove\nwhether a potential attack scenario is the source of the patient's death.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 05:53:40 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Ellouze", "Nourhene", "", "Communication Networks and Security Research Lab,\n  University of Carthage, Tunisia"], ["Rekhis", "Slim", "", "Communication Networks and\n  Security Research Lab, University of Carthage, Tunisia"], ["Allouche", "Mohamed", "", "Department of Forensic Medicine of Charles Nicolle, University of Tunis El\n  Manar, Tunisia"], ["Boudriga", "Noureddine", "", "Communication Networks and Security\n  Research Lab, University of Carthage, Tunisia"]]}, {"id": "1410.4353", "submitter": "Paulo Oliva", "authors": "Martin Escardo and Paulo Oliva", "title": "The Herbrand Functional Interpretation of the Double Negation Shift", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a generalisation of selection functions over an\narbitrary strong monad $T$, as functionals of type $J^T_R X = (X \\to R) \\to T\nX$. It is assumed throughout that $R$ is a $T$-algebra. We show that $J^T_R$ is\nalso a strong monad, and that it embeds into the continuation monad $K_R X = (X\n\\to R) \\to R$. We use this to derive that the explicitly controlled product of\n$T$-selection functions is definable from the explicitly controlled product of\nquantifiers, and hence from Spector's bar recursion. We then prove several\nproperties of this product in the special case when $T$ is the finite power set\nmonad ${\\mathcal P}(\\cdot)$. These are used to show that when $T X = {\\mathcal\nP}(X)$ the explicitly controlled product of $T$-selection functions calculates\na witness to the Herbrand functional interpretation of the double negation\nshift.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 09:51:12 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 13:48:03 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Escardo", "Martin", ""], ["Oliva", "Paulo", ""]]}, {"id": "1410.4364", "submitter": "Paulo Oliva", "authors": "Paulo Oliva", "title": "Unifying Functional Interpretations: Past and Future", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article surveys work done in the last six years on the unification of\nvarious functional interpretations including G\\\"odel's dialectica\ninterpretation, its Diller-Nahm variant, Kreisel modified realizability,\nStein's family of functional interpretations, functional interpretations \"with\ntruth\", and bounded functional interpretations. Our goal in the present paper\nis twofold: (1) to look back and single out the main lessons learnt so far, and\n(2) to look forward and list several open questions and possible directions for\nfurther research.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 10:28:04 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Oliva", "Paulo", ""]]}, {"id": "1410.4381", "submitter": "Bernhard Rumpe", "authors": "Borislav Gajanovic, Bernhard Rumpe", "title": "ALICE: An Advanced Logic for Interactive Component Engineering", "comments": "15 pages, 2 figures, 3 tables, Bernhard Beckert (Ed.) 4th\n  International Verification Workshop (Verify'07). Proceedings, Bremen, July\n  2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an overview of the verification framework ALICE in its\ncurrent version 0.7. It is based on the generic theorem prover Isabelle\n[Pau03a]. Within ALICE a software or hardware component is specified as a\nstate-full black-box with directed communication channels. Components send and\nreceive asynchronous messages via these channels. The behavior of a component\nis generally described as a relation on the observations in form of streams of\nmessages flowing over its input and output channels. Untimed and timed as well\nas state-based, recursive, relational, equational, assumption/guarantee, and\nfunctional styles of specification are supported. Hence, ALICE is well suited\nfor the formalization and verification of distributed systems modeled with this\nstream-processing paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 11:46:00 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Gajanovic", "Borislav", ""], ["Rumpe", "Bernhard", ""]]}, {"id": "1410.4416", "submitter": "J\\\"urgen Koslowski", "authors": "Stefan Schulze Frielinghaus, Michael Petter, Helmut Seidl", "title": "Inter-procedural Two-Variable Herbrand Equalities", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (May 12,\n  2017) lmcs:3655", "doi": "10.23638/LMCS-13(2:5)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that all valid Herbrand equalities can be inter-procedurally\ninferred for programs where all assignments whose right-hand sides depend on at\nmost one variable are taken into account. The analysis is based on procedure\nsummaries representing the weakest pre-conditions for finitely many generic\npost-conditions with template variables. In order to arrive at effective\nrepresentations for all occurring weakest pre-conditions, we show for almost\nall values possibly computed at run-time, that they can be uniquely factorized\ninto tree patterns and a ground term. Moreover, we introduce an approximate\nnotion of subsumption which is effectively decidable and ensures that finite\nconjunctions of equalities may not grow infinitely. Based on these technical\nresults, we realize an effective fixpoint iteration to infer all\ninter-procedurally valid Herbrand equalities for these programs. Finally we\nshow that an invariant candidate with a constant number of variables, can be\nverified in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 13:34:39 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 08:28:33 GMT"}, {"version": "v3", "created": "Wed, 10 May 2017 21:39:31 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Frielinghaus", "Stefan Schulze", ""], ["Petter", "Michael", ""], ["Seidl", "Helmut", ""]]}, {"id": "1410.4439", "submitter": "Victor Gomes", "authors": "Brijesh Dongol and Victor B. F. Gomes and Georg Struth", "title": "Principles for Verification Tools: Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A principled approach to the design of program verification and con-\nstruction tools is applied to separation logic. The control flow is modelled by\npower series with convolution as separating conjunction. A generic construction\nlifts resource monoids to assertion and predicate transformer quantales. The\ndata flow is captured by concrete store/heap models. These are linked to the\nseparation algebra by soundness proofs. Verification conditions and\ntransformation laws are derived by equational reasoning within the predicate\ntransformer quantale. This separation of concerns makes an implementation in\nthe Isabelle/HOL proof as- sistant simple and highly automatic. The resulting\ntool is correct by construction; it is explained on the classical linked list\nreversal example.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 16:08:19 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Dongol", "Brijesh", ""], ["Gomes", "Victor B. F.", ""], ["Struth", "Georg", ""]]}, {"id": "1410.4448", "submitter": "Juergen Koslowski", "authors": "Parosh Aziz Abdulla, Lorenzo Clemente, Richard Mayr, Sven Sandberg", "title": "Stochastic Parity Games on Lossy Channel Systems", "comments": "QEST'13 special issue, to appear in Logical Methods in Computer\n  Science (LMCS-2014-964). arXiv admin note: substantial text overlap with\n  arXiv:1305.5228", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (January\n  5, 2015) lmcs:944", "doi": "10.2168/LMCS-10(4:21)2014", "report-no": "LMCS-2014-964", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm for solving stochastic parity games with almost-sure\nwinning conditions on {\\it lossy channel systems}, under the constraint that\nboth players are restricted to finite-memory strategies. First, we describe a\ngeneral framework, where we consider the class of 2 1/2-player games with\nalmost-sure parity winning conditions on possibly infinite game graphs,\nassuming that the game contains a {\\it finite attractor}. An attractor is a set\nof states (not necessarily absorbing) that is almost surely re-visited\nregardless of the players' decisions. We present a scheme that characterizes\nthe set of winning states for each player. Then, we instantiate this scheme to\nobtain an algorithm for {\\it stochastic game lossy channel systems}.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 14:20:00 GMT"}, {"version": "v2", "created": "Thu, 1 Jan 2015 13:59:20 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Clemente", "Lorenzo", ""], ["Mayr", "Richard", ""], ["Sandberg", "Sven", ""]]}, {"id": "1410.4507", "submitter": "Tobias Isenberg", "authors": "Tobias Isenberg and Heike Wehrheim", "title": "Proof-Carrying Hardware via IC3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-carrying hardware (PCH) is an approach to achieving safety of\ndynamically reconfigurable hardware, transferring the idea of proof-carrying\ncode to the hardware domain. Current PCH approaches are, however, either\nlimited to combinational and bounded unfoldings of sequential circuits, or only\nprovide semi-automatic proof generation. We propose a new approach to PCH which\nemploys IC3 as proof generator, making automatic PCH applicable to sequential\ncircuits in their full generality. We demonstrate feasibility of our approach\nby showing that proof validation is several orders of magnitude faster than\noriginal proof generation while (most often) generating smaller proofs than\ncurrent PCHs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 12:38:49 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Isenberg", "Tobias", ""], ["Wehrheim", "Heike", ""]]}, {"id": "1410.4509", "submitter": "Fr\\'ed\\'eric Herbreteau", "authors": "Aakash Deshpande and Fr\\'ed\\'eric Herbreteau and B. Srivathsan and\n  Thanh-Tung Tran and Igor Walukiewicz", "title": "Fast detection of cycles in timed automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new efficient algorithm for detecting if a cycle in a timed\nautomaton can be iterated infinitely often. Existing methods for this problem\nhave a complexity which is exponential in the number of clocks. Our method is\npolynomial: it essentially does a logarithmic number of zone canonicalizations.\nThis method can be incorporated in algorithms for verifying B\\\"uchi properties\non timed automata. We report on some experiments that show a significant\nreduction in search space when our iteratability test is used.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 11:45:23 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Deshpande", "Aakash", ""], ["Herbreteau", "Fr\u00e9d\u00e9ric", ""], ["Srivathsan", "B.", ""], ["Tran", "Thanh-Tung", ""], ["Walukiewicz", "Igor", ""]]}, {"id": "1410.4512", "submitter": "Thorsten Wissmann", "authors": "Bas Luttik and Fei Yang", "title": "The $\\pi$-Calculus is Behaviourally Complete and Orbit-Finitely\n  Executable", "comments": "arXiv admin note: text overlap with arXiv:1508.04850", "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  10, 2021) lmcs:7165", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reactive Turing machines extend classical Turing machines with a facility to\nmodel observable interactive behaviour. We call a behaviour (finitely)\nexecutable if, and only if, it is equivalent to the behaviour of a (finite)\nreactive Turing machine. In this paper, we study the relationship between\nexecutable behaviour and behaviour that can be specified in the $\\pi$-calculus.\nWe establish that every finitely executable behaviour can be specified in the\n$\\pi$-calculus up to divergence-preserving branching bisimilarity. The\nconverse, however, is not true due to (intended) limitations of the model of\nreactive Turing machines. That is, the $\\pi$-calculus allows the specification\nof behaviour that is not finitely executable up to divergence-preserving\nbranching bisimilarity. We shall prove, however, that if the finiteness\nrequirement on reactive Turing machines and the associated notion of\nexecutability is relaxed to orbit-finiteness, then the $\\pi$-calculus is\nexecutable up to (divergence-insensitive) branching bisimilarity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 21:39:30 GMT"}, {"version": "v10", "created": "Tue, 9 Feb 2021 13:23:43 GMT"}, {"version": "v2", "created": "Fri, 17 Oct 2014 20:53:37 GMT"}, {"version": "v3", "created": "Wed, 29 Oct 2014 16:49:07 GMT"}, {"version": "v4", "created": "Mon, 10 Nov 2014 14:12:24 GMT"}, {"version": "v5", "created": "Wed, 18 Mar 2015 15:53:17 GMT"}, {"version": "v6", "created": "Fri, 27 Mar 2015 10:36:26 GMT"}, {"version": "v7", "created": "Wed, 22 Jan 2020 17:30:27 GMT"}, {"version": "v8", "created": "Thu, 9 Jul 2020 16:51:56 GMT"}, {"version": "v9", "created": "Sun, 24 Jan 2021 15:51:38 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Luttik", "Bas", ""], ["Yang", "Fei", ""]]}, {"id": "1410.4801", "submitter": "Mickael Randour", "authors": "Mickael Randour and Jean-Fran\\c{c}ois Raskin and Ocan Sankur", "title": "Percentile Queries in Multi-Dimensional Markov Decision Processes", "comments": "Extended version of CAV 2015 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) with multi-dimensional weights are useful to\nanalyze systems with multiple objectives that may be conflicting and require\nthe analysis of trade-offs. We study the complexity of percentile queries in\nsuch MDPs and give algorithms to synthesize strategies that enforce such\nconstraints. Given a multi-dimensional weighted MDP and a quantitative payoff\nfunction $f$, thresholds $v_i$ (one per dimension), and probability thresholds\n$\\alpha_i$, we show how to compute a single strategy to enforce that for all\ndimensions $i$, the probability of outcomes $\\rho$ satisfying $f_i(\\rho) \\geq\nv_i$ is at least $\\alpha_i$. We consider classical quantitative payoffs from\nthe literature (sup, inf, lim sup, lim inf, mean-payoff, truncated sum,\ndiscounted sum). Our work extends to the quantitative case the multi-objective\nmodel checking problem studied by Etessami et al. in unweighted MDPs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 17:33:33 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 12:15:00 GMT"}, {"version": "v3", "created": "Wed, 7 Dec 2016 14:37:17 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Randour", "Mickael", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""]]}, {"id": "1410.4925", "submitter": "Tuomo Kauranne", "authors": "Tuomo Kauranne", "title": "Finitely unstable theories and computational complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity class $NP$ can be logically characterized both through\nexistential second order logic $SO\\exists$, as proven by Fagin, and through\nsimulating a Turing machine via the satisfiability problem of propositional\nlogic SAT, as proven by Cook. Both theorems involve encoding a Turing machine\nby a formula in the corresponding logic and stating that a model of this\nformula exists if and only if the Turing machine halts, i.e. the formula is\nsatisfiable iff the Turing machine accepts its input. Trakhtenbrot's theorem\ndoes the same in first order logic $FO$. Such different orders of encoding are\npossible because the set of all possible configurations of any Turing machine\nup to any given finite time instant can be defined by a finite set of\npropositional variables, or is locally represented by a model of fixed finite\nsize. In the current paper, we first encode such time-limited computations of a\ndeterministic Turing machine (DTM) in first order logic. We then take a closer\nlook at DTMs that solve SAT. When the length of the input string to such a DTM\nthat contains effectively encoded instances of SAT is parameterized by the\nnatural number $M$, we proceed to show that the corresponding $FO$ theory\n$SAT_M$ has a lower bound on the size of its models that grows almost\nexponentially with $M$. This lower bound on model size also translates into a\nlower bound on the deterministic time complexity of SAT.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 09:13:25 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Kauranne", "Tuomo", ""]]}, {"id": "1410.4950", "submitter": "Shota Nakagawa", "authors": "Shota Nakagawa and Ichiro Hasuo", "title": "Near-Optimal Scheduling for LTL with Future Discounting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the search problem for optimal schedulers for the linear temporal\nlogic (LTL) with future discounting. The logic, introduced by Almagor, Boker\nand Kupferman, is a quantitative variant of LTL in which an event in the far\nfuture has only discounted contribution to a truth value (that is a real number\nin the unit interval [0, 1]). The precise problem we study---it naturally\narises e.g. in search for a scheduler that recovers from an internal error\nstate as soon as possible---is the following: given a Kripke frame, a formula\nand a number in [0, 1] called a margin, find a path of the Kripke frame that is\noptimal with respect to the formula up to the prescribed margin (a truly\noptimal path may not exist). We present an algorithm for the problem; it works\neven in the extended setting with propositional quality operators, a setting\nwhere (threshold) model-checking is known to be undecidable.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 12:12:05 GMT"}, {"version": "v2", "created": "Thu, 20 Nov 2014 04:39:27 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2015 04:44:20 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2015 04:28:53 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Nakagawa", "Shota", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1410.4980", "submitter": "Ulrich Sch", "authors": "Ulrich Sch\\\"opp (Ludwig-Maximilians-Universit\\\"at M\\\"unchen, Germany)", "title": "On the Relation of Interaction Semantics to Continuations and\n  Defunctionalization", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  16, 2014) lmcs:977", "doi": "10.2168/LMCS-10(4:10)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In game semantics and related approaches to programming language semantics,\nprograms are modelled by interaction dialogues. Such models have recently been\nused in the design of new compilation methods, e.g. for hardware synthesis or\nfor programming with sublinear space. This paper relates such semantically\nmotivated non-standard compilation methods to more standard techniques in the\ncompilation of functional programming languages, namely continuation passing\nand defunctionalization. We first show for the linear {\\lambda}-calculus that\ninterpretation in a model of computation by interaction can be described as a\ncall-by-name CPS-translation followed by a defunctionalization procedure that\ntakes into account control-flow information. We then establish a relation\nbetween these two compilation methods for the simply-typed {\\lambda}-calculus\nand end by considering recursion.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 17:28:54 GMT"}, {"version": "v2", "created": "Sun, 14 Dec 2014 20:47:26 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Sch\u00f6pp", "Ulrich", "", "Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"]]}, {"id": "1410.5000", "submitter": "Jad Hamza", "authors": "Jad Hamza", "title": "On the complexity of Linearizability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was shown in Alur et al. [1] that the problem of verifying finite\nconcurrent systems through Linearizability is in EXPSPACE. However, there was\nstill a complexity gap between the easy to obtain PSPACE lower bound and the\nEXPSPACE upper bound. We show in this paper that Linearizability is\nEXPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 20:17:36 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 12:28:49 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Hamza", "Jad", ""]]}, {"id": "1410.5037", "submitter": "Jonni Virtema", "authors": "Juha Kontinen, Antti Kuusisto, Jonni Virtema", "title": "Decidability of predicate logics with team semantics", "comments": "Extended version of a MFCS 2016 article. Changes on the earlier arXiv\n  version: title changed, added the result on validity of two-variable\n  dependence logic, restructuring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of predicate logics based on team semantics. We show\nthat the satisfiability problems of two-variable independence logic and\ninclusion logic are both NEXPTIME-complete. Furthermore, we show that the\nvalidity problem of two-variable dependence logic is undecidable, thereby\nsolving an open problem from the team semantics literature. We also briefly\nanalyse the complexity of the Bernays-Sch\\\"onfinkel-Ramsey prefix classes of\ndependence logic.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 05:14:54 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2016 10:49:23 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Kontinen", "Juha", ""], ["Kuusisto", "Antti", ""], ["Virtema", "Jonni", ""]]}, {"id": "1410.5038", "submitter": "Jonni Virtema", "authors": "Katsuhiko Sano, Jonni Virtema", "title": "Axiomatizing Propositional Dependence Logics", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give sound and complete Hilbert-style axiomatizations for propositional\ndependence logic (PD), modal dependence logic (MDL), and extended modal\ndependence logic (EMDL) by extending existing axiomatizations for propositional\nlogic and modal logic. In addition, we give novel labeled tableau calculi for\nPD, MDL, and EMDL. We prove soundness, completeness and termination for each of\nthe labeled calculi.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 05:25:05 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Sano", "Katsuhiko", ""], ["Virtema", "Jonni", ""]]}, {"id": "1410.5056", "submitter": "Radu Iosif", "authors": "Radu Iosif and Adam Rogalewicz and Tomas Vojnar", "title": "Abstraction Refinement for Trace Inclusion of Infinite State Systems", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \\emph{data automaton} is a finite automaton equipped with variables\n(counters or registers) ranging over infinite data domains. A trace of a data\nautomaton is an alternating sequence of alphabet symbols and values taken by\nthe counters during an execution of the automaton. The problem addressed in\nthis paper is the inclusion between the sets of traces (data languages)\nrecognized by such automata. Since the problem is undecidable in general, we\ngive a semi-algorithm based on abstraction refinement, which is proved to be\nsound and complete, but whose termination is not guaranteed. We have\nimplemented our technique in a~prototype tool and show promising results on\nseveral non-trivial examples.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 10:49:53 GMT"}, {"version": "v2", "created": "Mon, 9 Feb 2015 18:32:16 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2015 12:03:19 GMT"}], "update_date": "2015-10-22", "authors_parsed": [["Iosif", "Radu", ""], ["Rogalewicz", "Adam", ""], ["Vojnar", "Tomas", ""]]}, {"id": "1410.5088", "submitter": "Matt Lewis", "authors": "Cristina David and Daniel Kroening and Matt Lewis", "title": "Propositional Reasoning about Safety and Termination of\n  Heap-Manipulating Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that it is possible to reason about the safety and\ntermination of programs handling potentially cyclic, singly-linked lists using\npropositional reasoning even when the safety invariants and termination\narguments depend on constraints over the lengths of lists. For this purpose, we\npropose the theory SLH of singly-linked lists with length, which is able to\ncapture non-trivial interactions between shape and arithmetic. When using the\ntheory of bit-vector arithmetic as a background, SLH is efficiently decidable\nvia a reduction to SAT. We show the utility of SLH for software verification by\nusing it to express safety invariants and termination arguments for programs\nmanipulating potentially cyclic, singly-linked lists with unrestricted,\nunspecified sharing. We also provide an implementation of the decision\nprocedure and use it to check safety and termination proofs for several\nheap-manipulating programs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 16:29:27 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["David", "Cristina", ""], ["Kroening", "Daniel", ""], ["Lewis", "Matt", ""]]}, {"id": "1410.5089", "submitter": "Matt Lewis", "authors": "Cristina David and Daniel Kroening and Matt Lewis", "title": "Unrestricted Termination and Non-Termination Arguments for Bit-Vector\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proving program termination is typically done by finding a well-founded\nranking function for the program states. Existing termination provers typically\nfind ranking functions using either linear algebra or templates. As such they\nare often restricted to finding linear ranking functions over mathematical\nintegers. This class of functions is insufficient for proving termination of\nmany terminating programs, and furthermore a termination argument for a program\noperating on mathematical integers does not always lead to a termination\nargument for the same program operating on fixed-width machine integers. We\npropose a termination analysis able to generate nonlinear, lexicographic\nranking functions and nonlinear recurrence sets that are correct for\nfixed-width machine arithmetic and floating-point arithmetic Our technique is\nbased on a reduction from program \\emph{termination} to second-order\n\\emph{satisfaction}. We provide formulations for termination and\nnon-termination in a fragment of second-order logic with restricted\nquantification which is decidable over finite domains. The resulted technique\nis a sound and complete analysis for the termination of finite-state programs\nwith fixed-width integers and IEEE floating-point arithmetic.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 16:39:26 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["David", "Cristina", ""], ["Kroening", "Daniel", ""], ["Lewis", "Matt", ""]]}, {"id": "1410.5131", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "An Algebra of Reversible Computation", "comments": "74 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process algebra ACP based on the interleaving semantics can not be reversed.\nWe design a reversible version of APTC called RAPTC. It has algebraic laws of\nreversible choice, sequence, parallelism, communication, silent step and\nabstraction, and also the soundness and completeness modulo strongly\nforward-reverse truly concurrent bisimulations and weakly forward-reverse truly\nconcurrent bisimulations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 00:50:25 GMT"}, {"version": "v2", "created": "Sat, 15 Nov 2014 02:00:43 GMT"}, {"version": "v3", "created": "Wed, 31 Dec 2014 01:59:29 GMT"}, {"version": "v4", "created": "Thu, 15 Jan 2015 08:05:27 GMT"}, {"version": "v5", "created": "Mon, 13 Jul 2015 07:53:01 GMT"}, {"version": "v6", "created": "Thu, 26 May 2016 06:54:27 GMT"}, {"version": "v7", "created": "Wed, 2 May 2018 15:22:26 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1410.5467", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Lionel Mamane, Josef Urban", "title": "Machine Learning of Coq Proof Guidance: First Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the results of the first experiments with learning proof\ndependencies from the formalizations done with the Coq system. We explain the\nprocess of obtaining the dependencies from the Coq proofs, the characterization\nof formulas that is used for the learning, and the evaluation method. Various\nmachine learning methods are compared on a dataset of 5021 toplevel Coq proofs\ncoming from the CoRN repository. The best resulting method covers on average\n75% of the needed proof dependencies among the first 100 predictions, which is\na comparable performance of such initial experiments on other large-theory\ncorpora.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 21:16:52 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Mamane", "Lionel", ""], ["Urban", "Josef", ""]]}, {"id": "1410.5476", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Josef Urban, Jiri Vyskocil", "title": "Certified Connection Tableaux Proofs for HOL Light and TPTP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years, the Metis prover based on ordered paramodulation and\nmodel elimination has replaced the earlier built-in methods for general-purpose\nproof automation in HOL4 and Isabelle/HOL. In the annual CASC competition, the\nleanCoP system based on connection tableaux has however performed better than\nMetis. In this paper we show how the leanCoP's core algorithm can be\nimplemented inside HOLLight. leanCoP's flagship feature, namely its\nminimalistic core, results in a very simple proof system. This plays a crucial\nrole in extending the MESON proof reconstruction mechanism to connection\ntableaux proofs, providing an implementation of leanCoP that certifies its\nproofs. We discuss the differences between our direct implementation using an\nexplicit Prolog stack, to the continuation passing implementation of MESON\npresent in HOLLight and compare their performance on all core HOLLight goals.\nThe resulting prover can be also used as a general purpose TPTP prover. We\ncompare its performance against the resolution based Metis on TPTP and other\ninteresting datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 21:36:47 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Vyskocil", "Jiri", ""]]}, {"id": "1410.5568", "submitter": "Patrick Trentin", "authors": "Roberto Sebastiani and Patrick Trentin", "title": "Pushing the envelope of Optimization Modulo Theories with\n  Linear-Arithmetic Cost Functions", "comments": "A slightly-shorter version of this paper is published at TACAS 2015\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade we have witnessed an impressive progress in the\nexpressiveness and efficiency of Satisfiability Modulo Theories (SMT) solving\ntechniques. This has brought previously-intractable problems at the reach of\nstate-of-the-art SMT solvers, in particular in the domain of SW and HW\nverification. Many SMT-encodable problems of interest, however, require also\nthe capability of finding models that are optimal wrt. some cost functions. In\nprevious work, namely \"Optimization Modulo Theory with Linear Rational Cost\nFunctions -- OMT(LAR U T )\", we have leveraged SMT solving to handle the\nminimization of cost functions on linear arithmetic over the rationals, by\nmeans of a combination of SMT and LP minimization techniques. In this paper we\npush the envelope of our OMT approach along three directions: first, we extend\nit to work also with linear arithmetic on the mixed integer/rational domain, by\nmeans of a combination of SMT, LP and ILP minimization techniques; second, we\ndevelop a multi-objective version of OMT, so that to handle many cost functions\nsimultaneously; third, we develop an incremental version of OMT, so that to\nexploit the incrementality of some OMT-encodable problems. An empirical\nevaluation performed on OMT-encoded verification problems demonstrates the\nusefulness and efficiency of these extensions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 08:14:19 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 15:05:26 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Sebastiani", "Roberto", ""], ["Trentin", "Patrick", ""]]}, {"id": "1410.5703", "submitter": "Yaron Velner", "authors": "Yaron Velner", "title": "Robust Multidimensional Mean-Payoff Games are Undecidable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean-payoff games play a central role in quantitative synthesis and\nverification. In a single-dimensional game a weight is assigned to every\ntransition and the objective of the protagonist is to assure a non-negative\nlimit-average weight. In the multidimensional setting, a weight vector is\nassigned to every transition and the objective of the protagonist is to satisfy\na boolean condition over the limit-average weight of each dimension, e.g.,\n$\\LimAvg(x_1) \\leq 0 \\vee \\LimAvg(x_2)\\geq 0 \\wedge \\LimAvg(x_3) \\geq 0$. We\nrecently proved that when one of the players is restricted to finite-memory\nstrategies then the decidability of determining the winner is inter-reducible\nwith Hilbert's Tenth problem over rationals (a fundamental long-standing open\nproblem). In this work we allow arbitrary (infinite-memory) strategies for both\nplayers and we show that the problem is undecidable.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 19:57:42 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Velner", "Yaron", ""]]}, {"id": "1410.5764", "submitter": "Matt Lewis", "authors": "Daniel Kroening and Matt Lewis and Georg Weissenbacher", "title": "Proving Safety with Trace Automata and Bounded Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loop under-approximation is a technique that enriches C programs with\nadditional branches that represent the effect of a (limited) range of loop\niterations. While this technique can speed up the detection of bugs\nsignificantly, it introduces redundant execution traces which may complicate\nthe verification of the program. This holds particularly true for verification\ntools based on Bounded Model Checking, which incorporate simplistic heuristics\nto determine whether all feasible iterations of a loop have been considered.\n  We present a technique that uses \\emph{trace automata} to eliminate redundant\nexecutions after performing loop acceleration. The method reduces the diameter\nof the program under analysis, which is in certain cases sufficient to allow a\nsafety proof using Bounded Model Checking. Our transformation is precise---it\ndoes not introduce false positives, nor does it mask any errors. We have\nimplemented the analysis as a source-to-source transformation, and present\nexperimental results showing the applicability of the technique.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 18:02:00 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Kroening", "Daniel", ""], ["Lewis", "Matt", ""], ["Weissenbacher", "Georg", ""]]}, {"id": "1410.5782", "submitter": "Sean Sedwards", "authors": "Axel Legay, Sean Sedwards and Louis-Marie Traonouez", "title": "Lightweight Monte Carlo Verification of Markov Decision Processes with\n  Rewards", "comments": "16 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes are useful models of concurrency optimisation\nproblems, but are often intractable for exhaustive verification methods. Recent\nwork has introduced lightweight approximative techniques that sample directly\nfrom scheduler space, bringing the prospect of scalable alternatives to\nstandard numerical model checking algorithms. The focus so far has been on\noptimising the probability of a property, but many problems require\nquantitative analysis of rewards. In this work we therefore present lightweight\nstatistical model checking algorithms to optimise the rewards of Markov\ndecision processes. We consider the standard definitions of rewards used in\nmodel checking, introducing an auxiliary hypothesis test to accommodate\nreachability rewards. We demonstrate the performance of our approach on a\nnumber of standard case studies.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 05:56:26 GMT"}, {"version": "v2", "created": "Sun, 15 Feb 2015 10:25:43 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2015 11:54:05 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Legay", "Axel", ""], ["Sedwards", "Sean", ""], ["Traonouez", "Louis-Marie", ""]]}, {"id": "1410.5993", "submitter": "Henning Schnoor", "authors": "Henning Schnoor", "title": "The Relative Succinctness and Expressiveness of Modal Logics Can Be\n  Arbitrarily Complex", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relative succinctness and expressiveness of modal logics, and\nprove that these relationships can be as complex as any countable partial\norder. For this, we use two uniform formalisms to define modal operators, and\nobtain results on succinctness and expressiveness in these two settings. Our\nproofs are based on formula size games introduced by Adler and Immerman and\nbisimulations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 10:59:54 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Schnoor", "Henning", ""]]}, {"id": "1410.6026", "submitter": "Manfred Kufleitner", "authors": "Volker Diekert and Manfred Kufleitner", "title": "A Survey on the Local Divisor Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local divisors allow a powerful induction scheme on the size of a monoid. We\nsurvey this technique by giving several examples of this proof method. These\napplications include linear temporal logic, rational expressions with Kleene\nstars restricted to prefix codes with bounded synchronization delay,\nChurch-Rosser congruential languages, and Simon's Factorization Forest Theorem.\nWe also introduce the notion of localizable language class as a new abstract\nconcept which unifies some of the proofs for the results above.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 12:46:35 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2015 08:51:35 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2015 13:02:31 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["Diekert", "Volker", ""], ["Kufleitner", "Manfred", ""]]}, {"id": "1410.6039", "submitter": "Roberto Sebastiani", "authors": "Roberto Sebastiani and Silvia Tomasi", "title": "Optimization Modulo Theories with Linear Rational Costs", "comments": "Submitted on january 2014 to ACM Transactions on Computational Logic,\n  currently under revision. arXiv admin note: text overlap with arXiv:1202.1409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contexts of automated reasoning (AR) and formal verification (FV),\nimportant decision problems are effectively encoded into Satisfiability Modulo\nTheories (SMT). In the last decade efficient SMT solvers have been developed\nfor several theories of practical interest (e.g., linear arithmetic, arrays,\nbit-vectors). Surprisingly, little work has been done to extend SMT to deal\nwith optimization problems; in particular, we are not aware of any previous\nwork on SMT solvers able to produce solutions which minimize cost functions\nover arithmetical variables. This is unfortunate, since some problems of\ninterest require this functionality.\n  In the work described in this paper we start filling this gap. We present and\ndiscuss two general procedures for leveraging SMT to handle the minimization of\nlinear rational cost functions, combining SMT with standard minimization\ntechniques. We have implemented the procedures within the MathSAT SMT solver.\nDue to the absence of competitors in the AR, FV and SMT domains, we have\nexperimentally evaluated our implementation against state-of-the-art tools for\nthe domain of linear generalized disjunctive programming (LGDP), which is\nclosest in spirit to our domain, on sets of problems which have been previously\nproposed as benchmarks for the latter tools. The results show that our tool is\nvery competitive with, and often outperforms, these tools on these problems,\nclearly demonstrating the potential of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 13:39:31 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Sebastiani", "Roberto", ""], ["Tomasi", "Silvia", ""]]}, {"id": "1410.6044", "submitter": "Bj\\\"orn Wachter", "authors": "Daniel Kroening, Subodh Sharma, Bj\\\"orn Wachter", "title": "AbPress: Flexing Partial-Order Reduction and Abstraction", "comments": "15 pages, 7 figures, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial-order reduction (POR) and lazy abstraction with interpolants are two\ncomplementary techniques that have been successfully employed to make model\nchecking tools for concurrent programs effective. In this work, we present\nAbPress - Abstraction-based Partial-order Reduction with Source-Sets - an\nalgorithm that fuses a recently proposed and powerful dynamic POR technique\nbased on source-sets and lazy abstraction to obtain an efficient software model\nchecker for multi-threaded programs. It trims the inter- leaving space by\ntaking the abstraction and source-sets into account. We amplify the\neffectiveness of AbPress with a novel solution that summarizes the accesses to\nshared variables over a collection of interleavings. We have implemented\nAbPress in a tool that analyzes concurrent programs using lazy abstraction,\nviz., Impara. Our evaluation on the effectiveness of the presented approach has\nbeen encouraging. AbPress compares favorably to existing state-of-the-art tools\nin the landscape.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 14:06:01 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Kroening", "Daniel", ""], ["Sharma", "Subodh", ""], ["Wachter", "Bj\u00f6rn", ""]]}, {"id": "1410.6118", "submitter": "Francesca Spezzano", "authors": "Edoardo Serra, Francesca Spezzano, V.S. Subrahmanian", "title": "ChoiceGAPs: Competitive Diffusion as a Massive Multi-Player Game in\n  Social Networks", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of modeling competitive diffusion in real world\nsocial networks via the notion of ChoiceGAPs which combine choice logic\nprograms due to Sacca` and Zaniolo and Generalized Annotated Programs due to\nKifer and Subrahmanian. We assume that each vertex in a social network is a\nplayer in a multi-player game (with a huge number of players) - the choice part\nof the ChoiceGAPs describe utilities of players for acting in various ways\nbased on utilities of their neighbors in those and other situations. We define\nmulti-player Nash equilibrium for such programs - but because they require some\nconditions that are hard to satisfy in the real world, we introduce a new\nmodel-theoretic concept of strong equilibrium. We show that stable equilibria\ncan capture all Nash equilibria. We prove a host of complexity (intractability)\nresults for checking existence of strong equilibria (as well as related\ncounting complexity results), together with algorithms to find them. We then\nidentify a class of ChoiceGAPs for which stable equilibria can be polynomially\ncomputed. We develop algorithms for computing these equilibria under various\nrestrictions. We come up with the important concept of an estimation query\nwhich can compute quantities w.r.t. a given strong equilibrium, and approximate\nranges of values (answers) across the space of strong equilibria. Even though\nwe show that computing range answers to estimation queries exactly is\nintractable, we are able to identify classes of estimation queries that can be\nanswered in polynomial time. We report on experiments we conducted with a\nreal-world FaceBook data set surrounding the 2013 Italian election showing that\nour algorithms have good predictive accuracy with an Area Under a ROC Curve\nthat, on average, is over 0.76.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 17:36:10 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 16:43:46 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2016 17:45:09 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Serra", "Edoardo", ""], ["Spezzano", "Francesca", ""], ["Subrahmanian", "V. S.", ""]]}, {"id": "1410.6268", "submitter": "Brijesh Dongol", "authors": "Brijesh Dongol and John Derrick", "title": "Verifying linearizability: A comparative survey", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability has become the key correctness criterion for concurrent data\nstructures, ensuring that histories of the concurrent object under\nconsideration are consistent, where consistency is judged with respect to a\nsequential history of a corresponding abstract data structure. Linearizability\nallows any order of concurrent (i.e., overlapping) calls to operations to be\npicked, but requires the real-time order of non-overlapping to be preserved.\nOver the years numerous techniques for verifying linearizability have been\ndeveloped, using a variety of formal foundations such as refinement, shape\nanalysis, reduction, etc. However, as the underlying framework, nomenclature\nand terminology for each method differs, it has become difficult for\npractitioners to judge the differences between each approach, and hence, judge\nthe methodology most appropriate for the data structure at hand. We compare the\nmajor of methods used to verify linearizability, describe the main contribution\nof each method, and compare their advantages and limitations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 07:28:11 GMT"}, {"version": "v2", "created": "Sat, 31 Jan 2015 09:21:40 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Dongol", "Brijesh", ""], ["Derrick", "John", ""]]}, {"id": "1410.6298", "submitter": "Erika De Benedetti", "authors": "Erika De Benedetti and Simona Ronchi Della Rocca", "title": "A type assignment for lambda-calculus complete both for FPTIME and\n  strong normalization", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the aims of Implicit Computational Complexity is the design of\nprogramming languages with bounded computational complexity; indeed,\nguaranteeing and certifying a limited resources usage is of central importance\nfor various aspects of computer science. One of the more promising approaches\nto this aim is based on the use of lambda-calculus as paradigmatic programming\nlanguage and the design of type assignment systems for lambda-terms, where\ntypes guarantee both the functional correctness and the complexity bound. Here\nwe propose a system of stratified types, inspired by intersection types, where\nintersection is a non-associative operator. The system, called STR, is correct\nand complete for polynomial time computations; moreover, all the strongly\nnormalizing terms are typed in it, thus increasing the typing power with\nrespect to the previous proposals. Moreover, STR enjoys a stronger expressivity\nwith respect to the previous system STA, since it allows to type a restricted\nversion of iteration.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 09:19:36 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["De Benedetti", "Erika", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "1410.6361", "submitter": "Thomas Powell", "authors": "Paulo Oliva and Thomas Powell", "title": "Spector bar recursion over finite partial functions", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new, demand-driven variant of Spector's bar recursion in the\nspirit of the Berardi-Bezem-Coquand functional. The recursion takes place over\nfinite partial functions $u$, where the control parameter $\\varphi$, used in\nSpector's bar recursion to terminate the computation at sequences $s$\nsatisfying $\\varphi(\\hat{s})<|s|$, now acts as a guide for deciding exactly\nwhere to make bar recursive updates, terminating the computation whenever\n$\\varphi(\\hat{u})\\in\\mbox{dom}(u)$. We begin by exploring theoretical aspects\nof this new form of recursion, then in the main part of the paper we show that\ndemand-driven bar recursion can be directly used to give an alternative\nfunctional interpretation of classical countable choice. We provide a short\ncase study as an illustration, in which we extract a new bar recursive program\nfrom the proof that there is no injection from $\\mathbb{N}\\to\\mathbb{N}$ to\n$\\mathbb{N}$, and compare this to the program that would be obtained using\nSpector's original variant. We conclude by formally establishing that our new\nbar recursor is primitive recursively equivalent to the original Spector bar\nrecursion, and thus defines the same class of functionals when added to\nG\\\"odel's system $\\sf T$.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 13:27:00 GMT"}, {"version": "v2", "created": "Fri, 24 Oct 2014 09:17:33 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2015 13:37:33 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Oliva", "Paulo", ""], ["Powell", "Thomas", ""]]}, {"id": "1410.6505", "submitter": "Levon Haykazyan", "authors": "Levon Haykazyan", "title": "Decidability of the Clark's Completion Semantics for Monadic Programs\n  and Queries", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 15 (3): 402-412, 2015", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many different semantics for general logic programs (i.e. programs\nthat use negation in the bodies of clauses). Most of these semantics are Turing\ncomplete (in a sense that can be made precise), implying that they are\nundecidable. To obtain decidability one needs to put additional restrictions on\nprograms and queries. In logic programming it is natural to put restrictions on\nthe underlying first-order language. In this note we show the decidability of\nthe Clark's completion semantics for monadic general programs and queries.\n  To appear in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 21:06:06 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Haykazyan", "Levon", ""]]}, {"id": "1410.6648", "submitter": "Henning Schnoor", "authors": "Juha Kontinen, Julian-Steffen M\\\"uller, Henning Schnoor, Heribert\n  Vollmer", "title": "A Van Benthem Theorem for Modal Team Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous van Benthem theorem states that modal logic corresponds exactly to\nthe fragment of first-order logic that is invariant under bisimulation. In this\narticle we prove an exact analogue of this theorem in the framework of modal\ndependence logic MDL and team semantics. We show that modal team logic MTL,\nextending MDL by classical negation, captures exactly the FO-definable\nbisimulation invariant properties of Kripke structures and teams. We also\ncompare the expressive power of MTL to most of the variants and extensions of\nMDL recently studied in the area.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 11:12:52 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2015 18:39:11 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Kontinen", "Juha", ""], ["M\u00fcller", "Julian-Steffen", ""], ["Schnoor", "Henning", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1410.6652", "submitter": "Daniyar Shamkanov", "authors": "Daniyar Shamkanov", "title": "Nested Sequents for Provability Logic GLP", "comments": null, "journal-ref": "Logic Journal of the IGPL, 23:5 (2015), 789-815", "doi": "10.1093/jigpal/jzv029", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a proof system for the provability logic GLP in the formalism of\nnested sequents and prove the cut elimination theorem for it. As an\napplication, we obtain the reduction of GLP to its important fragment called J\nsyntactically.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 11:44:07 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Shamkanov", "Daniyar", ""]]}, {"id": "1410.7013", "submitter": "EPTCS", "authors": "Ivan Lanese (Focus Team, University of Bologna/INRIA (Italy)), Alberto\n  Lluch Lafuente (DTU Compute, Technical University of Denmark (Denmark)), Ana\n  Sokolova (University of Salzburg (Austria)), Hugo Torres Vieira (LaSIGE,\n  University of Lisbon (Portugal))", "title": "Proceedings 7th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 166, 2014", "doi": "10.4204/EPTCS.166", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE 2014, the 7th Interaction and\nConcurrency Experience, which was held in Berlin, Germany on the 6th of June\n2014 as a satellite event of DisCoTec 2014. The ICE procedure for paper\nselection allows PC members to interact, anonymously, with authors. During the\nreview phase, each submitted paper is published on a Wiki and associated with a\ndiscussion forum whose access is restricted to the authors and to all the PC\nmembers not declaring a conflict of interests. The PC members post comments and\nquestions that the authors reply to. Each paper was reviewed by three PC\nmembers, and altogether 8 papers (including 3 short papers) were accepted for\npublication. We were proud to host two invited talks, by Pavol Cerny and Kim\nLarsen, whose abstracts are included in this volume together with the regular\npapers.\n", "versions": [{"version": "v1", "created": "Sun, 26 Oct 2014 10:49:11 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Lanese", "Ivan", "", "Focus Team, University of Bologna/INRIA"], ["Lafuente", "Alberto Lluch", "", "DTU Compute, Technical University of Denmark"], ["Sokolova", "Ana", "", "University of Salzburg"], ["Vieira", "Hugo Torres", "", "LaSIGE,\n  University of Lisbon"]]}, {"id": "1410.7103", "submitter": "Jose Vergara JV", "authors": "Barry Jay and Jose Vergara", "title": "Confusion in the Church-Turing Thesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The Church-Turing Thesis confuses numerical computations with symbolic\ncomputations. In particular, any model of computability in which equality is\nnot definable, such as the lambda-models underpinning higher-order programming\nlanguages, is not equivalent to the Turing model. However, a modern combinatory\ncalculus, the SF-calculus, can define equality of its closed normal forms, and\nso yields a model of computability that is equivalent to the Turing model. This\nhas profound implications for programming language design.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 00:38:47 GMT"}, {"version": "v2", "created": "Thu, 6 Nov 2014 02:06:02 GMT"}], "update_date": "2014-11-07", "authors_parsed": [["Jay", "Barry", ""], ["Vergara", "Jose", ""]]}, {"id": "1410.7225", "submitter": "Benjamin Lucien Kaminski", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen", "title": "Analyzing Expected Outcomes and Almost-Sure Termination of Probabilistic\n  Programs is Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the computational hardness of computing expected\noutcomes and deciding almost-sure termination of probabilistic programs. We\nshow that deciding almost-sure termination and deciding whether the expected\noutcome of a program equals a given rational value is $\\Pi^0_2$-complete.\nComputing lower and upper bounds on the expected outcome is shown to be\nrecursively enumerable and $\\Sigma^0_2$-complete, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 13:31:45 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1410.7346", "submitter": "Paolo Zuliani", "authors": "Bing Liu, Soonho Kong, Sicun Gao, Paolo Zuliani, Edmund M. Clarke", "title": "Towards Personalized Prostate Cancer Therapy Using Delta-Reachability\n  Analysis", "comments": "HSCC 2015", "journal-ref": null, "doi": "10.1145/2728606.2728634", "report-no": null, "categories": "q-bio.QM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent clinical studies suggest that the efficacy of hormone therapy for\nprostate cancer depends on the characteristics of individual patients. In this\npaper, we develop a computational framework for identifying patient-specific\nandrogen ablation therapy schedules for postponing the potential cancer\nrelapse. We model the population dynamics of heterogeneous prostate cancer\ncells in response to androgen suppression as a nonlinear hybrid automaton. We\nestimate personalized kinetic parameters to characterize patients and employ\n$\\delta$-reachability analysis to predict patient-specific therapeutic\nstrategies. The results show that our methods are promising and may lead to a\nprognostic tool for personalized cancer therapy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 18:36:40 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2015 09:33:47 GMT"}, {"version": "v3", "created": "Tue, 19 May 2015 13:17:29 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Liu", "Bing", ""], ["Kong", "Soonho", ""], ["Gao", "Sicun", ""], ["Zuliani", "Paolo", ""], ["Clarke", "Edmund M.", ""]]}, {"id": "1410.7466", "submitter": "EPTCS", "authors": "H{\\aa}kon Normann (IT University of Copenhagen), Cristian Prisacariu\n  (Institute for Informatics, University of Oslo), Thomas Hildebrandt (IT\n  University of Copenhagen)", "title": "Concurrency Models with Causality and Events as Psi-calculi", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 4-20", "doi": "10.4204/EPTCS.166.3", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psi-calculi are a parametric framework for nominal calculi, where standard\ncalculi are found as instances, like the pi-calculus, or the cryptographic\nspi-calculus and applied-pi. Psi-calculi have an interleaving operational\nsemantics, with a strong foundation on the theory of nominal sets and process\nalgebras. Much of the expressive power of psi-calculi comes from their logical\npart, i.e., assertions, conditions, and entailment, which are left quite open\nthus accommodating a wide range of logics. We are interested in how this\nexpressiveness can deal with event-based models of concurrency. We thus take\nthe popular prime event structures model and give an encoding into an instance\nof psi-calculi. We also take the recent and expressive model of Dynamic\nCondition Response Graphs (in which event structures are strictly included) and\ngive an encoding into another corresponding instance of psi-calculi. The\nencodings that we achieve look rather natural and intuitive. Additional results\nabout these encodings give us more confidence in their correctness.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 00:40:29 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Normann", "H\u00e5kon", "", "IT University of Copenhagen"], ["Prisacariu", "Cristian", "", "Institute for Informatics, University of Oslo"], ["Hildebrandt", "Thomas", "", "IT\n  University of Copenhagen"]]}, {"id": "1410.7469", "submitter": "EPTCS", "authors": "Diego Latella (ISTI - CNR), Michele Loreti (Universit\\`a di Firenze),\n  Mieke Massink (ISTI - CNR)", "title": "On-the-fly Probabilistic Model Checking", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 45-59", "doi": "10.4204/EPTCS.166.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking approaches can be divided into two broad categories: global\napproaches that determine the set of all states in a model M that satisfy a\ntemporal logic formula f, and local approaches in which, given a state s in M,\nthe procedure determines whether s satisfies f. When s is a term of a process\nlanguage, the model checking procedure can be executed \"on-the-fly\", driven by\nthe syntactical structure of s. For certain classes of systems, e.g. those\ncomposed of many parallel components, the local approach is preferable because,\ndepending on the specific property, it may be sufficient to generate and\ninspect only a relatively small part of the state space. We propose an\nefficient, on-the-fly, PCTL model checking procedure that is parametric with\nrespect to the semantic interpretation of the language. The procedure comprises\nboth bounded and unbounded until modalities. The correctness of the procedure\nis shown and its efficiency is compared with a global PCTL model checker on\nrepresentative applications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 00:41:09 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Latella", "Diego", "", "ISTI - CNR"], ["Loreti", "Michele", "", "Universit\u00e0 di Firenze"], ["Massink", "Mieke", "", "ISTI - CNR"]]}, {"id": "1410.7470", "submitter": "EPTCS", "authors": "Nicolas Ninin (CEA, LIST and University Paris-Sud, France), Emmanuel\n  Haucourt (CEA, LIST)", "title": "The Boolean Algebra of Cubical Areas as a Tensor Product in the Category\n  of Semilattices with Zero", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 60-66", "doi": "10.4204/EPTCS.166.7", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a model of concurrency together with an algebraic\nstructure reflecting the parallel composition. For the sake of simplicity we\nrestrict to linear concurrent programs i.e. the ones with no loops nor\nbranching. Such programs are given a semantics using cubical areas. Such a\nsemantics is said to be geometric. The collection of all these cubical areas\nenjoys a structure of tensor product in the category of semi-lattice with zero.\nThese results naturally extend to fully fledged concurrent programs up to some\ntechnical tricks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 00:41:23 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Ninin", "Nicolas", "", "CEA, LIST and University Paris-Sud, France"], ["Haucourt", "Emmanuel", "", "CEA, LIST"]]}, {"id": "1410.7471", "submitter": "EPTCS", "authors": "Davide Basile (Dipartimento di Informatica, Universita' di Pisa,\n  Italy), Pierpaolo Degano (Dipartimento di Informatica, Universita' di Pisa,\n  Italy), Gian-Luigi Ferrari (Dipartimento di Informatica, Universita' di Pisa,\n  Italy), Emilio Tuosto (Computer Science Department, University of Leicester)", "title": "From Orchestration to Choreography through Contract Automata", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 67-85", "doi": "10.4204/EPTCS.166.8", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relations between a contract automata and an interaction model.\nIn the former model, distributed services are abstracted away as automata -\noblivious of their partners - that coordinate with each other through an\norchestrator. The interaction model relies on channel-based asynchronous\ncommunication and choreography to coordinate distributed services.\n  We define a notion of strong agreement on the contract model, exhibit a\nnatural mapping from the contract model to the interaction model, and give\nconditions to ensure that strong agreement corresponds to well-formed\nchoreography.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 00:41:39 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Basile", "Davide", "", "Dipartimento di Informatica, Universita' di Pisa,\n  Italy"], ["Degano", "Pierpaolo", "", "Dipartimento di Informatica, Universita' di Pisa,\n  Italy"], ["Ferrari", "Gian-Luigi", "", "Dipartimento di Informatica, Universita' di Pisa,\n  Italy"], ["Tuosto", "Emilio", "", "Computer Science Department, University of Leicester"]]}, {"id": "1410.7551", "submitter": "Sasha Rubin", "authors": "Benjamin Aminof, Aniello Murano, Sasha Rubin", "title": "Satisfiability and Model Checking of CTL* with Graded Path Modalities", "comments": "13 pages + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graded path modalities count the number of paths satisfying a property, and\ngeneralize the existential (E) and universal (A) path modalities of CTL*. The\nresulting logic is called GCTL*. We settle the complexity of satisfiability of\nGCTL*, i.e., 2ExpTime-Complete, and the complexity of the model checking\nproblem for GCTL*, i.e., PSpace-Complete. The lower bounds already hold for\nCTL*, and so, using the automata-theoretic approach we supply the upper bounds.\nThe significance of this work is two-fold: GCTL* is more expressive than CTL*\nat no extra cost in computational complexity, and GCTL* has all the advantages\nover GCTL (CTL with graded path modalities) that CTL* has over CTL, e.g., the\nability to express fairness.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 08:38:46 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Aminof", "Benjamin", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""]]}, {"id": "1410.7704", "submitter": "Tatjana Petrov", "authors": "Mirco Giacobbe, Calin C. Guet, Ashutosh Gupta, Thomas A. Henzinger,\n  Tiago Paixao, and Tatjana Petrov", "title": "Model Checking Gene Regulatory Networks", "comments": "19 pages, 20 references, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behaviour of gene regulatory networks (GRNs) is typically analysed using\nsimulation-based statistical testing-like methods. In this paper, we\ndemonstrate that we can replace this approach by a formal verification-like\nmethod that gives higher assurance and scalability. We focus on Wagner weighted\nGRN model with varying weights, which is used in evolutionary biology. In the\nmodel, weight parameters represent the gene interaction strength that may\nchange due to genetic mutations. For a property of interest, we synthesise the\nconstraints over the parameter space that represent the set of GRNs satisfying\nthe property. We experimentally show that our parameter synthesis procedure\ncomputes the mutational robustness of GRNs -an important problem of interest in\nevolutionary biology- more efficiently than the classical simulation method. We\nspecify the property in linear temporal logics. We employ symbolic bounded\nmodel checking and SMT solving to compute the space of GRNs that satisfy the\nproperty, which amounts to synthesizing a set of linear constraints on the\nweights.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 17:19:13 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 17:25:12 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Giacobbe", "Mirco", ""], ["Guet", "Calin C.", ""], ["Gupta", "Ashutosh", ""], ["Henzinger", "Thomas A.", ""], ["Paixao", "Tiago", ""], ["Petrov", "Tatjana", ""]]}, {"id": "1410.7850", "submitter": "EPTCS", "authors": "Christoph Benzm\\\"uller, Bruno Woltzenlogel Paleo", "title": "Proceedings Eleventh Workshop on User Interfaces for Theorem Provers", "comments": null, "journal-ref": "EPTCS 167, 2014", "doi": "10.4204/EPTCS.167", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The UITP workshop series brings together researchers interested in designing,\ndeveloping and evaluating user interfaces for automated reasoning tools, such\nas interactive proof assistants, automated theorem provers, model finders,\ntools for formal methods, and tools for visualising and manipulating logical\nformulas and proofs. The eleventh edition of UITP took place in Vienna,\nAustria, and was part of the Vienna Summer of Logic, the largest ever joint\nconference in the area of Logic. This proceedings contains the eight\ncontributed papers that were accepted for presentation at the workshop as well\nas the two invited papers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 01:06:19 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1410.7930", "submitter": "Klaus Keimel", "authors": "Klaus Keimel", "title": "On the equivalence of state transformer semantics and predicate\n  transformer semantics", "comments": null, "journal-ref": "Proceedings of the Workshop Informatics and Information\n  Technologies in Education: Theory, Practice, Didactics, Novosibirsk, vol. 1\n  (2012), 78--104", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  G. Plotkin and the author have worked out the equivalence between state\ntransformer semantics and predicate transformer semantics in a domain\ntheoretical setting for programs combining nondeterminism and probability.\nWorks of C. Morgan and co-authors, Keimel, Rosenbusch and Streicher, already go\nin the same direction using only discrete state spaces. It is the aim of this\npaper to exhibit a general framework in which one can hope that state\ntransformer semantics and predicate transformer semantics are equivalent. We\nuse a notion of entropicity borrowed from universal algebra and a relaxed\nsetting adapted to the domain theoretical situation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 10:56:58 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Keimel", "Klaus", ""]]}, {"id": "1410.8060", "submitter": "Paolo Zuliani", "authors": "Fedor Shmarov, Paolo Zuliani", "title": "ProbReach: Verified Probabilistic Delta-Reachability for Stochastic\n  Hybrid Systems", "comments": "HSCC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ProbReach, a tool for verifying probabilistic reachability for\nstochastic hybrid systems, i.e., computing the probability that the system\nreaches an unsafe region of the state space. In particular, ProbReach will\ncompute an arbitrarily small interval which is guaranteed to contain the\nrequired probability. Standard (non-probabilistic) reachability is undecidable\neven for linear hybrid systems. In ProbReach we adopt the weaker notion of\ndelta-reachability, in which the unsafe region is overapproximated by a\nuser-defined parameter (delta). This choice leads to false alarms, but also\nmakes the reachability problem decidable for virtually any hybrid system. In\nProbReach we have implemented a probabilistic version of delta-reachability\nthat is suited for hybrid systems whose stochastic behaviour is given in terms\nof random initial conditions. In this paper we introduce the capabilities of\nProbReach, give an overview of the parallel implementation, and present results\nfor several benchmarks involving highly non-linear hybrid systems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 17:09:06 GMT"}, {"version": "v2", "created": "Fri, 31 Oct 2014 21:28:30 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2015 11:29:15 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Shmarov", "Fedor", ""], ["Zuliani", "Paolo", ""]]}, {"id": "1410.8111", "submitter": "Zoltan Esik", "authors": "Zoltan Esik", "title": "Equational properties of stratified least fixed points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel fixed point operation has been introduced over certain\nnon-monotonic functions between stratified complete lattices and used to give\nsemantics to logic programs with negation and boolean context-free grammars. We\nprove that this new operation satisfies `the standard' identities of fixed\npoint operations as described by the axioms of iteration theories. We also\nstudy this new fixed point operation in connection with lambda-abstraction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 19:31:52 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 18:21:19 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2015 17:01:13 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2015 14:54:31 GMT"}, {"version": "v5", "created": "Thu, 10 Dec 2015 18:54:09 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Esik", "Zoltan", ""]]}, {"id": "1410.8215", "submitter": "EPTCS", "authors": "Bernhard Beckert (Karlsruhe Institute of Technology (KIT)), Sarah\n  Grebing (Karlsruhe Institute of Technology (KIT)), Florian B\\\"ohl (Karlsruhe\n  Institute of Technology (KIT))", "title": "How to Put Usability into Focus: Using Focus Groups to Evaluate the\n  Usability of Interactive Theorem Provers", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 4-13", "doi": "10.4204/EPTCS.167.3", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:02 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Beckert", "Bernhard", "", "Karlsruhe Institute of Technology"], ["Grebing", "Sarah", "", "Karlsruhe Institute of Technology"], ["B\u00f6hl", "Florian", "", "Karlsruhe\n  Institute of Technology"]]}, {"id": "1410.8216", "submitter": "EPTCS", "authors": "Andrew Butterfield (Trinity College Dublin)", "title": "UTP2: Higher-Order Equational Reasoning by Pointing", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 14-22", "doi": "10.4204/EPTCS.167.4", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a prototype theorem prover, UTP2, developed to match the style of\nhand-written proof work in the Unifying Theories of Programming semantical\nframework. This is based on alphabetised predicates in a 2nd-order logic, with\na strong emphasis on equational reasoning. We present here an overview of the\nuser-interface of this prover, which was developed from the outset using a\npoint-and-click approach. We contrast this with the command-line paradigm that\ncontinues to dominate the mainstream theorem provers, and raises the question:\ncan we have the best of both worlds?\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:15 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Butterfield", "Andrew", "", "Trinity College Dublin"]]}, {"id": "1410.8217", "submitter": "EPTCS", "authors": "Gudmund Grov (Heriot-Watt University), Aleks Kissinger (University of\n  Oxford), Yuhui Lin (Heriot-Watt University)", "title": "Tinker, tailor, solver, proof", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 23-34", "doi": "10.4204/EPTCS.167.5", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Tinker, a tool for designing and evaluating proof strategies\nbased on proof-strategy graphs, a formalism previously introduced by the\nauthors. We represent proof strategies as open-graphs, which are directed\ngraphs with additional input/output edges. Tactics appear as nodes in a graph,\nand can be `piped' together by adding edges between them. Goals are added to\nthe input edges of such a graph, and flow through the graph as the strategy is\nevaluated. Properties of the edges ensure that only the right `type' of goals\nare accepted. In this paper, we detail the Tinker tool and show how it can be\nintegrated with two different theorem provers: Isabelle and ProofPower.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:33 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Grov", "Gudmund", "", "Heriot-Watt University"], ["Kissinger", "Aleks", "", "University of\n  Oxford"], ["Lin", "Yuhui", "", "Heriot-Watt University"]]}, {"id": "1410.8218", "submitter": "EPTCS", "authors": "Tomer Libal (Microsoft Research - Inria Joint Center, Ecole\n  Polytechnique), Martin Riener (Institute of Computer Languages, Vienna\n  University of Technology), Mikheil Rukhaia (Institute of Applied Mathematics,\n  Tbilisi State University)", "title": "Advanced Proof Viewing in ProofTool", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 35-47", "doi": "10.4204/EPTCS.167.6", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequent calculus is widely used for formalizing proofs. However, due to the\nproliferation of data, understanding the proofs of even simple mathematical\narguments soon becomes impossible. Graphical user interfaces help in this\nmatter, but since they normally utilize Gentzen's original notation, some of\nthe problems persist. In this paper, we introduce a number of criteria for\nproof visualization which we have found out to be crucial for analyzing proofs.\nWe then evaluate recent developments in tree visualization with regard to these\ncriteria and propose the Sunburst Tree layout as a complement to the\ntraditional tree structure. This layout constructs inferences as concentric\ncircle arcs around the root inference, allowing the user to focus on the\nproof's structural content. Finally, we describe its integration into ProofTool\nand explain how it interacts with the Gentzen layout.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:47 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Libal", "Tomer", "", "Microsoft Research - Inria Joint Center, Ecole\n  Polytechnique"], ["Riener", "Martin", "", "Institute of Computer Languages, Vienna\n  University of Technology"], ["Rukhaia", "Mikheil", "", "Institute of Applied Mathematics,\n  Tbilisi State University"]]}, {"id": "1410.8219", "submitter": "EPTCS", "authors": "Florian Rabe (Jacobs University Bremen)", "title": "A Logic-Independent IDE", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 48-60", "doi": "10.4204/EPTCS.167.7", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The author's MMT system provides a framework for defining and implementing\nlogical systems. By combining MMT with the jEdit text editor, we obtain a\nlogic-independent IDE. The IDE functionality includes advanced features such as\ncontext-sensitive auto-completion, search, and change management.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:58 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Rabe", "Florian", "", "Jacobs University Bremen"]]}, {"id": "1410.8220", "submitter": "EPTCS", "authors": "Christian Sternagel (University of Innsbruck, Austria), Ren\\'e\n  Thiemann (University of Innsbruck, Austria)", "title": "The Certification Problem Format", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 61-72", "doi": "10.4204/EPTCS.167.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of CPF, the certification problem format, and explain\nsome design decisions. Whereas CPF was originally invented to combine three\ndifferent formats for termination proofs into a single one, in the meanwhile\nproofs for several other properties of term rewrite systems are also\nexpressible: like confluence, complexity, and completion. As a consequence, the\nformat is already supported by several tools and certifiers. Its acceptance is\nalso demonstrated in international competitions: the certified tracks of both\nthe termination and the confluence competition utilized CPF as exchange format\nbetween automated tools and trusted certifiers.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:08:09 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Sternagel", "Christian", "", "University of Innsbruck, Austria"], ["Thiemann", "Ren\u00e9", "", "University of Innsbruck, Austria"]]}, {"id": "1410.8221", "submitter": "EPTCS", "authors": "Carst Tankink (Inria Saclay - \\^Ile-de-France)", "title": "PIDE for Asynchronous Interaction with Coq", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 73-83", "doi": "10.4204/EPTCS.167.9", "report-no": null, "categories": "cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the initial progress towards integrating the Coq proof\nassistant with the PIDE architecture initially developed for Isabelle. The\narchitecture is aimed at asynchronous, parallel interaction with proof\nassistants, and is tied in heavily with a plugin that allows the jEdit editor\nto work with Isabelle.\n  We have made some generalizations to the PIDE architecture to accommodate for\nmore provers than just Isabelle, and adapted Coq to understand the core\nprotocol: this delivered a working system in about two man-months.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:08:18 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Tankink", "Carst", "", "Inria Saclay - \u00cele-de-France"]]}, {"id": "1410.8222", "submitter": "EPTCS", "authors": "Makarius Wenzel (Univ. Paris-Sud, Laboratoire LRI, UMR8623)", "title": "System description: Isabelle/jEdit in 2014", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 84-94", "doi": "10.4204/EPTCS.167.10", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an updated system description for Isabelle/jEdit, according to the\nofficial release Isabelle2014 (August 2014). The following new PIDE concepts\nare explained: asynchronous print functions and document overlays, syntactic\nand semantic completion, editor navigation, management of auxiliary files\nwithin the document-model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:08:32 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Wenzel", "Makarius", "", "Univ. Paris-Sud, Laboratoire LRI, UMR8623"]]}, {"id": "1410.8314", "submitter": "Andrea Turrini", "authors": "Andrea Turrini (State Key Laboratory of Computer Science, Institute of\n  Software, Chinese Academy of Sciences, Beijing, China), Holger Hermanns\n  (Saarland University -- Computer Science, Saarbruecken, Germany)", "title": "Cost Preserving Bisimulations for Probabilistic Automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  18, 2014) lmcs:1050", "doi": "10.2168/LMCS-10(4:11)2014", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic automata constitute a versatile and elegant model for\nconcurrent probabilistic systems. They are equipped with a compositional theory\nsupporting abstraction, enabled by weak probabilistic bisimulation serving as\nthe reference notion for summarising the effect of abstraction. This paper\nconsiders probabilistic automata augmented with costs. It extends the notions\nof weak transitions in probabilistic automata in such a way that the costs\nincurred along a weak transition are captured. This gives rise to\ncost-preserving and cost-bounding variations of weak probabilistic\nbisimilarity, for which we establish compositionality properties with respect\nto parallel composition. Furthermore, polynomial-time decision algorithms are\nproposed, that can be effectively used to compute reward-bounding abstractions\nof Markov decision processes in a compositional manner.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 10:26:58 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2014 00:36:25 GMT"}, {"version": "v3", "created": "Mon, 16 Feb 2015 08:54:52 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Turrini", "Andrea", "", "State Key Laboratory of Computer Science, Institute of\n  Software, Chinese Academy of Sciences, Beijing, China"], ["Hermanns", "Holger", "", "Saarland University -- Computer Science, Saarbruecken, Germany"]]}, {"id": "1410.8470", "submitter": "Gilles Dowek", "authors": "Gilles Dowek, Ying Jiang", "title": "Cut-elimination and the decidability of reachability in alternating\n  pushdown systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new proof of the decidability of reachability in alternating\npushdown systems, showing that it is a simple consequence of a cut-elimination\ntheorem for some natural-deduction style inference systems. Then, we show how\nthis result can be used to extend an alternating pushdown system into a\ncomplete system where for every configuration $A$, either $A$ or $\\neg A$ is\nprovable.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 17:57:24 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Dowek", "Gilles", ""], ["Jiang", "Ying", ""]]}, {"id": "1410.8692", "submitter": "Inge Bethke", "authors": "Jan A. Bergstra and Inge Bethke", "title": "Note on paraconsistency and reasoning about fractions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": "report TCS1413, October 2014", "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a paraconsistent logic to reason about fractions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2014 10:21:30 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2015 10:47:32 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Bergstra", "Jan A.", ""], ["Bethke", "Inge", ""]]}, {"id": "1410.8852", "submitter": "Jonathan Kochems", "authors": "Jonathan Kochems and C.-H. Luke Ong", "title": "Decidable Models of Recursive Asynchronous Concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronously communicating pushdown systems (ACPS) that satisfy the\nempty-stack constraint (a pushdown process may receive only when its stack is\nempty) are a popular decidable model for recursive programs with asynchronous\natomic procedure calls. We study a relaxation of the empty-stack constraint for\nACPS that permits concurrency and communication actions at any stack height,\ncalled the shaped stack constraint, thus enabling a larger class of concurrent\nprograms to be modelled. We establish a close connection between ACPS with\nshaped stacks and a novel extension of Petri nets: Nets with Nested Coloured\nTokens (NNCTs). Tokens in NNCTs are of two types: simple and complex. Complex\ntokens carry an arbitrary number of coloured tokens. The rules of NNCT can\nsynchronise complex and simple tokens, inject coloured tokens into a complex\ntoken, and eject all tokens of a specified set of colours to predefined places.\nWe show that the coverability problem for NNCTs is Tower-complete. To our\nknowledge, NNCT is the first extension of Petri nets, in the class of nets with\nan infinite set of token types, that has primitive recursive coverability. This\nresult implies Tower-completeness of coverability for ACPS with shaped stacks.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2014 19:01:39 GMT"}, {"version": "v2", "created": "Sun, 18 Jan 2015 22:08:13 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Kochems", "Jonathan", ""], ["Ong", "C. -H. Luke", ""]]}]