[{"id": "2002.00009", "submitter": "Thomas Seiller", "authors": "Thomas Seiller (LIPN, CNRS)", "title": "Probabilistic Complexity Classes through Semantics", "comments": "arXiv admin note: text overlap with arXiv:1609.07895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, the author has shown how Interaction Graphs models for\nlinear logic can be used to obtain implicit characterisations of\nnon-deterministic complexity classes. In this paper, we show how this semantic\napproach to Implicit Complexity Theory (ICC) can be used to characterise\ndeterministic and probabilistic models of computation. In doing so, we obtain\ncorrespondences between group actions and both deterministic and probabilistic\nhierarchies of complexity classes. As a particular case, we provide the first\nimplicit characterisations of the classes PLogspace (un-bounded error\nprobabilistic logarithmic space) and PPtime (unbounded error probabilistic\npolynomial time)\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:34:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Seiller", "Thomas", "", "LIPN, CNRS"]]}, {"id": "2002.00188", "submitter": "Ulrich Berger", "authors": "Ulrich Berger, Hideki Tsuiki", "title": "Intuitionistic Fixed Point Logic", "comments": "65 pages", "journal-ref": "Annals of Pure and Applied Logic, Volume 172, Issue 3, March 2021,\n  102903", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the system IFP of intuitionistic fixed point logic, an extension of\nintuitionistic first-order logic by strictly positive inductive and coinductive\ndefinitions. We define a realizability interpretation of IFP and use it to\nextract computational content from proofs about abstract structures specified\nby arbitrary classically true disjunction free formulas. The interpretation is\nshown to be sound with respect to a domain-theoretic denotational semantics and\na corresponding lazy operational semantics of a functional language for\nextracted programs. We also show how extracted programs can be translated into\nHaskell. As an application we extract a program converting the signed digit\nrepresentation of real numbers to infinite Gray-code from a proof of inclusion\nof the corresponding coinductive predicates.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 10:52:03 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 19:39:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Berger", "Ulrich", ""], ["Tsuiki", "Hideki", ""]]}, {"id": "2002.00423", "submitter": "Ibrahim Abdelaziz", "authors": "Ibrahim Abdelaziz, Veronika Thost, Maxwell Crouse, Achille Fokoue", "title": "An Experimental Study of Formula Embeddings for Automated Theorem\n  Proving in First-Order Logic", "comments": "7 pages, preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated theorem proving in first-order logic is an active research area\nwhich is successfully supported by machine learning. While there have been\nvarious proposals for encoding logical formulas into numerical vectors -- from\nsimple strings to more involved graph-based embeddings -- little is known about\nhow these different encodings compare. In this paper, we study and\nexperimentally compare pattern-based embeddings that are applied in current\nsystems with popular graph-based encodings, most of which have not been\nconsidered in the theorem proving context before. Our experiments show that the\nadvantages of simpler encoding schemes in terms of runtime are outdone by more\ncomplex graph-based embeddings, which yield more efficient search strategies\nand simpler proofs. To support this, we present a detailed analysis across\nseveral dimensions of theorem prover performance beyond just proof completion\nrate, thus providing empirical evidence to help guide future research on\nneural-guided theorem proving towards the most promising directions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 16:07:15 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 16:41:53 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Abdelaziz", "Ibrahim", ""], ["Thost", "Veronika", ""], ["Crouse", "Maxwell", ""], ["Fokoue", "Achille", ""]]}, {"id": "2002.00620", "submitter": "Kazuhiko Sakaguchi", "authors": "Kazuhiko Sakaguchi", "title": "Validating Mathematical Structures", "comments": "Preprint of the paper accepted in proceedings of IJCAR 2020, LNCS,\n  Springer, including appendix", "journal-ref": "IJCAR 2020, LNCS, Springer, vol. 12167, pp. 138--157", "doi": "10.1007/978-3-030-51054-1_8", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing of notations and theories across an inheritance hierarchy of\nmathematical structures, e.g., groups and rings, is important for productivity\nwhen formalizing mathematics in proof assistants. The packed classes\nmethodology is a generic design pattern to define and combine mathematical\nstructures in a dependent type theory with records. When combined with\nmechanisms for implicit coercions and unification hints, packed classes enable\nautomated structure inference and subtyping in hierarchies, e.g., that a ring\ncan be used in place of a group. However, large hierarchies based on packed\nclasses are challenging to implement and maintain. We identify two hierarchy\ninvariants that ensure modularity of reasoning and predictability of inference\nwith packed classes, and propose algorithms to check these invariants. We\nimplement our algorithms as tools for the Coq proof assistant, and show that\nthey significantly improve the development process of Mathematical Components,\na library for formalized mathematics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:31:24 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 13:42:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sakaguchi", "Kazuhiko", ""]]}, {"id": "2002.00666", "submitter": "Keehang Kwon", "authors": "Keehang Kwon and Daeseong Kang", "title": "Agent-Based Proof Design via Lemma Flow Diagram", "comments": "three figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss an agent-based approach to proof design and implementation, which\nwe call {\\it Lemma Flow Diagram} (LFD). This approach is based on the multicut\nrule with $shared$ cuts. This approach is modular and easy to use, read and\nautomate. Thus, we consider LFD an appealing alternative to `flow proof' which\nis popular in mathematical education. Some examples are provided.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:03:05 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kwon", "Keehang", ""], ["Kang", "Daeseong", ""]]}, {"id": "2002.00720", "submitter": "Valentin D. Richard", "authors": "Valentin D. Richard", "title": "Introduction of Quantification in Frame Semantics", "comments": "Master report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Structures (FSs) are a widespread tool used for decompositional\nframeworks of Attribute-Value associations. Even though they thrive in simple\nsystems, they lack a way of representing higher-order entities and relations.\nThis is however needed in Frame Semantics, where semantic dependencies should\nbe able to connect groups of individuals and their properties, especially to\nmodel quantification. To answer this issue, this master report introduces\nwrappings as a way to envelop a sub-FS and treat it as a node. Following the\nwork of [Kallmeyer, Osswald 2013], we extend its syntax, semantics and some\nproperties (translation to FOL, subsumption, unification). We can then expand\nthe proposed pipeline. Lexical minimal model sets are generated from formulas.\nThey unify by FS value equations obtained by LTAG parsing to an underspecified\nsentence representation. The syntactic approach of quantifiers allows us to use\nexisting methods to produce any possible reading. Finally, we give a\ntranscription to type-logical formulas to interact with the context in the view\nof dynamic semantics. Supported by ideas of Frame Types, this system provides a\nworkable and tractable tool for higher-order relations with FS.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:52:29 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Richard", "Valentin D.", ""]]}, {"id": "2002.00725", "submitter": "Valentin D. Richard", "authors": "Valentin D. Richard", "title": "Traduction des Grammaires Cat\\'egorielles de Lambek dans les Grammaires\n  Cat\\'egorielles Abstraites", "comments": "Bachelor internship report, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lambek Grammars (LG) are a computational modelling of natural language, based\non non-commutative compositional types. It has been widely studied, especially\nfor languages where the syntax plays a major role (like English). The goal of\nthis internship report is to demonstrate that every Lambek Grammar can be, not\nentirely but efficiently, expressed in Abstract Categorial Grammars (ACG). The\nlatter is a novel modelling based on higher-order signature homomorphisms\n(using $\\lambda$-calculus), aiming at uniting the currently used models. The\nmain idea is to transform the type rewriting system of LGs into that of\nContext-Free Grammars (CFG) by erasing introduction and elimination rules and\ngenerating enough axioms so that the cut rule suffices. This iterative approach\npreserves the derivations and enables us to stop the possible infinite\ngenerative process at any step. Although the underlying algorithm was not fully\nimplemented, this proof provides another argument in favour of the relevance of\nACGs in Natural Language Processing.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:23:03 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Richard", "Valentin D.", ""]]}, {"id": "2002.00731", "submitter": "Matej Trojak", "authors": "Matej Troj\\'ak, David \\v{S}afr\\'anek, Lubo\\v{s} Brim", "title": "Executable Biochemical Space for Specification and Analysis of\n  Biochemical Systems", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0238838", "report-no": null, "categories": "q-bio.MN cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the second generation of a rule-based language called Biochemical\nSpace Language (BCSL) that combines the advantages of different approaches and\nthus makes an effort to overcome several problems with existing solutions. The\nkey aspect of the language is the level of abstraction it uses, which allows\nscalable and compact hierarchical specification of biochemical entities. This\nabstraction enables unique analysis techniques to reason about properties of\nmodels written in the language on the semantic and syntactic level.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:02:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Troj\u00e1k", "Matej", ""], ["\u0160afr\u00e1nek", "David", ""], ["Brim", "Lubo\u0161", ""]]}, {"id": "2002.01091", "submitter": "Mario Alvarez-Picallo", "authors": "Mario Alvarez-Picallo, Jean-Simon Pacaud Lemay", "title": "Cartesian Difference Categories: Extended Report", "comments": "This version corrects the Cartesian difference structure of the\n  Kleisli category, compared to the one found in the conference paper version.\n  The proposed difference combinator in the conference was based on a result\n  from another paper. Unfortunately, we have found that the result in said\n  other paper is incorrect, and therefore so was the proposed difference\n  combinator in the conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cartesian differential categories are categories equipped with a differential\ncombinator which axiomatizes the directional derivative. Important models of\nCartesian differential categories include classical differential calculus of\nsmooth functions and categorical models of the differential lambda-calculus.\nHowever, Cartesian differential categories cannot account for other interesting\nnotions of differentiation such as the calculus of finite differences or the\nBoolean differential calculus. On the other hand, change action models have\nbeen shown to capture these examples as well as more \"exotic\" examples of\ndifferentiation. However, change action models are very general and do not\nshare the nice properties of a Cartesian differential category. In this paper,\nwe introduce Cartesian difference categories as a bridge between Cartesian\ndifferential categories and change action models. We show that every Cartesian\ndifferential category is a Cartesian difference category, and how certain\nwell-behaved change action models are Cartesian difference categories. In\nparticular, Cartesian difference categories model both the differential\ncalculus of smooth functions and the calculus of finite differences.\nFurthermore, every Cartesian difference category comes equipped with a tangent\nbundle monad whose Kleisli category is again a Cartesian difference category.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:30:05 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 12:44:00 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Alvarez-Picallo", "Mario", ""], ["Lemay", "Jean-Simon Pacaud", ""]]}, {"id": "2002.01202", "submitter": "Christoph Matheja", "authors": "Jens Pagel, Christoph Matheja, Florian Zuleger", "title": "A Decision Procedure for Guarded Separation Logic: Complete Entailment\n  Checking for Separation Logic with Inductive Definitions", "comments": "Substantial revision of v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a doubly-exponential decision procedure for the satisfiability\nproblem of guarded separation logic -- a novel fragment of separation logic\nfeaturing user-supplied inductive predicates, Boolean connectives, and\nseparating connectives, including restricted (guarded) versions of negation,\nmagic wand, and septraction. Moreover, we show that dropping the guards for any\nof the above connectives leads to an undecidable fragment. We further apply our\ndecision procedure to reason about entailments in the popular symbolic heap\nfragment of separation logic. In particular, we obtain a doubly-exponential\ndecision procedure for entailments between (quantifier-free) symbolic heaps\nwith inductive predicate definitions of bounded treewidth (SLIDbtw) - one of\nthe most expressive decidable fragments of separation logic. Together with the\nrecently shown 2ExpTime-hardness for entailments in said fragment, we conclude\nthat the entailment problem for SLIDbtw is 2ExpTime-complete - thereby closing\na previously open complexity gap.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 10:02:57 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 10:20:23 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 13:45:36 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Pagel", "Jens", ""], ["Matheja", "Christoph", ""], ["Zuleger", "Florian", ""]]}, {"id": "2002.01287", "submitter": "Federico Olimpieri", "authors": "Federico Olimpieri", "title": "Intersection Type Distributors", "comments": "Accepted paper at LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a family of distributors-induced bicategorical models of\nlambda-calculus, proving that they can be syntactically presented via\nintersection type systems. We first introduce a class of 2-monads whose\nalgebras are monoidal categories modelling resource management. We lift these\nmonads to distributors and define a parametric Kleisli bicategory, giving a\nsufficient condition for its cartesian closure. In this framework we define a\nproof-relevant semantics: the interpretation of a term associates to it the set\nof its typing derivations in appropriate systems. We prove that our model\ncharacterize solvability, adapting reducibility techniques to our setting. We\nconclude by describing two examples of our construction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:00:53 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:08:46 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 12:57:20 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 13:41:24 GMT"}, {"version": "v5", "created": "Wed, 5 May 2021 11:00:03 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Olimpieri", "Federico", ""]]}, {"id": "2002.01766", "submitter": "Eugenia Oshurko", "authors": "Russ Harmer and Eugenia Oshurko", "title": "Knowledge representation and update in hierarchies of graphs", "comments": "25 pages, 4 figures, submitted to the Journal of Logical and\n  Algebraic Methods in Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mathematical theory is presented for the representation of knowledge in the\nform of a directed acyclic hierarchy of objects in a category where all paths\nbetween any given pair of objects are required to be equal. The conditions\nunder which knowledge update, in the form of the sesqui-pushout rewriting of an\nobject in a hierarchy, can be propagated to the rest of the hierarchy, in order\nto maintain all required path equalities, are analysed: some rewrites must be\npropagated forwards, in the direction of the arrows, while others must be\npropagated backwards, against the direction of the arrows, and, depending on\nthe precise form of the hierarchy, certain composability conditions may also be\nnecessary. The implementation of this theory, in the ReGraph Python library for\n(simple) directed graphs with attributes on nodes and edges, is then discussed\nin the context of two significant use cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:01:55 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Harmer", "Russ", ""], ["Oshurko", "Eugenia", ""]]}, {"id": "2002.01865", "submitter": "Michael Mislove", "authors": "Xiaodong Jia and Michael Mislove", "title": "Completing Simple Valuations in K-categories", "comments": "34 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that Keimel and Lawson's K-completion Kc of the simple valuation\nmonad Vs defines a monad Kc o Vs on each K-category A. We also characterize the\nEilenberg-Moore algebras of Kc o Vs as the weakly locally convex K-cones, and\nits algebra morphisms as the continuous linear maps. In addition, we explicitly\ndescribe the distributive law of Vs over Kc, which allows us to show that the\nK-completion of any locally convex (respectively, weakly locally convex,\nlocally linear) topological cone is a locally convex (respectively, weakly\nlocally convex, locally linear) K-cone. We also give an example - the Cantor\ntree with a top - that shows the dcpo-completion of the simple valuations is\nnot the D-completion of the simple valuations in general, where D is the\ncategory of monotone convergence spaces and continuous maps.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:56:49 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 22:06:42 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Jia", "Xiaodong", ""], ["Mislove", "Michael", ""]]}, {"id": "2002.02228", "submitter": "Sen Zheng", "authors": "Sen Zheng, Renate A. Schmidt", "title": "Querying Guarded Fragments via Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering Boolean conjunctive queries over the guarded fragment is decidable,\nhowever, as yet no practical decision procedure exists. Meanwhile, ordered\nresolution, as a practically oriented algorithm, is widely used in state-of-art\nmodern theorem provers. In this paper, we devise a resolution decision\nprocedure, which not only proves decidability of querying of the guarded\nfragment, but is implementable in any `off-the-shelf' resolution theorem prover\nwith modest effort. Further, we extend the procedure to querying the loosely\nguarded fragment.\n  The difficulty in querying a knowledge base of (loosely) guarded clauses is\nthat query clauses are not guarded. We show however there are ways to\nreformulate query clauses into (loosely) guarded clauses either directly via\nthe separation and splitting rules, or via performing inferences using our\ntop-variable inference system combining with a form of dynamic renaming.\nTherefore, the problem of querying the (loosely) guarded fragment can be\nreduced to deciding the (loosely) guarded fragment and possibly irreducible\nquery clauses, i.e., a clause that cannot derive any new conclusion. Meanwhile,\nour procedure yields a goal-oriented query rewriting algorithm: Before\nintroducing datasets, one can produce a saturated clausal set $\\mathcal{S}$\nusing given BCQs and (loosely) guarded theories. Clauses in $\\mathcal{S}$ can\nbe easily transformed first-order queries, therefore query answering over the\n(loosely) guarded fragment is reduced to evaluating a union of first-order\nqueries over datasets. As far as we know, this is the first practical decision\nprocedure for answering and rewriting Boolean conjunctive queries over the\nguarded fragment and the loosely guarded fragment.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:45:18 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 19:25:59 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Zheng", "Sen", ""], ["Schmidt", "Renate A.", ""]]}, {"id": "2002.02321", "submitter": "Simon Doherty", "authors": "James Cranch and Simon Doherty and Georg Struth", "title": "Convolution and Concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how concurrent quantales and concurrent Kleene algebras arise as\nconvolution algebras $Q^X$ of functions from structures $X$ with two ternary\nrelations that satisfy relational interchange laws into concurrent quantales or\nKleene algebras $Q$. The elements of $Q$ can be understood as weights; the case\n$Q=\\bool$ corresponds to a powerset lifting. We develop a correspondence theory\nbetween relational properties in $X$ and algebraic properties in $Q$ and $Q^X$\nin the sense of modal and substructural logics, and boolean algebras with\noperators. As examples, we construct the concurrent quantales and Kleene\nalgebras of $Q$-weighted words, digraphs, posets, isomorphism classes of finite\ndigraphs and pomsets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:59:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cranch", "James", ""], ["Doherty", "Simon", ""], ["Struth", "Georg", ""]]}, {"id": "2002.02512", "submitter": "Herman Geuvers", "authors": "Herman Geuvers and Bart Jacobs", "title": "Relating Apartness and Bisimulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A bisimulation for a coalgebra of a functor on the category of sets can be\ndescribed via a coalgebra in the category of relations, of a lifted functor. A\nfinal coalgebra then gives rise to the coinduction principle, which states that\ntwo bisimilar elements are equal. For polynomial functors, this leads to\nwell-known descriptions. In the present paper we look at the dual notion of\n\"apartness\". Intuitively, two elements are apart if there is a positive way to\ndistinguish them. Phrased differently: two elements are apart if and only if\nthey are not bisimilar. Since apartness is an inductive notion, described by a\nleast fixed point, we can give a proof system, to derive that two elements are\napart. This proof system has derivation rules and two elements are apart if and\nonly if there is a finite derivation (using the rules) of this fact.\n  We study apartness versus bisimulation in two separate ways. First, for weak\nforms of bisimulation on labelled transition systems, where silent (tau) steps\nare included, we define an apartness notion that corresponds to weak\nbisimulation and another apartness that corresponds to branching bisimulation.\nThe rules for apartness can be used to show that two states of a labelled\ntransition system are not branching bismilar. To support the apartness view on\nlabelled transition systems, we cast a number of well-known properties of\nbranching bisimulation in terms of branching apartness and prove them. Next, we\nalso study the more general categorical situation and show that indeed,\napartness is the dual of bisimilarity in a precise categorical sense: apartness\nis an initial algebra and gives rise to an induction principle. In this\nanalogy, we include the powerset functor, which gives a semantics to\nnon-deterministic choice in process-theory.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:58:48 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 16:23:47 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 08:02:45 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2021 16:46:53 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 12:40:07 GMT"}, {"version": "v6", "created": "Thu, 29 Jul 2021 14:33:09 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Geuvers", "Herman", ""], ["Jacobs", "Bart", ""]]}, {"id": "2002.02536", "submitter": "Brandon Bohrer", "authors": "Brandon Bohrer, Andr\\'e Platzer", "title": "Constructive Hybrid Games", "comments": "60 pages, preprint, under review", "journal-ref": null, "doi": "10.1007/978-3-030-51074-9_26", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid games are models which combine discrete, continuous, and adversarial\ndynamics. Game logic enables proving (classical) existence of winning\nstrategies. We introduce constructive differential game logic (CdGL) for hybrid\ngames, where proofs that a player can win the game correspond to computable\nwinning strategies. This is the logical foundation for synthesis of correct\ncontrol and monitoring code for safety-critical cyber-physical systems. Our\ncontributions include novel static and dynamic semantics as well as soundness\nand consistency.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 22:19:13 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Bohrer", "Brandon", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2002.02576", "submitter": "Brandon Bohrer", "authors": "Brandon Bohrer and Andr\\'e Platzer", "title": "Refining Constructive Hybrid Games", "comments": "40 pages. Extended preprint", "journal-ref": null, "doi": "10.4230/LIPIcs.FSCD.2020.14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the constructive differential game logic (CdGL) of hybrid games\nwith a refinement connective that relates two hybrid games. We use this\nconnective to prove a folk theorem relating hybrid games to hybrid systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:06:28 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 01:50:37 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 21:15:48 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Bohrer", "Brandon", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2002.02710", "submitter": "Pedro Antonino", "authors": "Pedro Antonino and A. W. Roscoe", "title": "Formalising and verifying smart contracts with Solidifier: a bounded\n  model checker for Solidity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploitation of smart-contract vulnerabilities can have catastrophic\nconsequences such as the loss of millions of pounds worth of crypto assets.\nFormal verification can be a useful tool in identifying vulnerabilities and\nproving that they have been fixed. In this paper, we present a formalisation of\nSolidity and the Ethereum blockchain using the Solid language and its\nblockchain; a Solid program is obtained by explicating/desugaring a Solidity\nprogram. We make some abstractions that over-approximate the way in which\nSolidity/Ethereum behave. Based on this formalisation, we create Solidifier: a\nbounded model checker for Solidity. It translates Solid into Boogie, an\nintermediate verification language, that is later verified using Corral, a\nbounded model checker for Boogie. Unlike much of the work in this area, we do\nnot try to find specific behavioural/code patterns that might lead to\nvulnerabilities. Instead, we provide a tool to find errors/bad states, i.e.\nprogram states that do not conform with the intent of the developer. Such a bad\nstate, be it a vulnerability or not, might be reached through the execution of\nspecific known code patterns or through behaviours that have not been\nanticipated.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:54:57 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Antonino", "Pedro", ""], ["Roscoe", "A. W.", ""]]}, {"id": "2002.02899", "submitter": "Tim Boykett", "authors": "Tim Boykett", "title": "Maximality of reversible gate sets", "comments": "Submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.DM cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to better understand the structure of closed collections of\nreversible gates, we investigate the lattice of closed sets and the maximal\nmembers of this lattice. In this note, we find the maximal closed sets over a\nfinite alphabet. We find that for odd sized alphabets, there are a finite\nnumber of maximal closed sets, while for the even case we have a countable\ninfinity, almost all of which are related to an alternating permutations. We\nthen extend to other forms of closure for reversible gates, ancilla and borrow\nclosure. Here we find some structural results, including some examples of\nmaximal closed sets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:05:18 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Boykett", "Tim", ""]]}, {"id": "2002.02904", "submitter": "Robert Dickerson", "authors": "Robert Dickerson, Qianchuan Ye, Benjamin Delaware", "title": "RHLE: Modular Deductive Verification of Relational $\\forall\\exists$\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational program logics are used to prove that a desired relationship holds\nbetween the execution of multiple programs. Existing relational program logics\nhave focused on verifying that all runs of a collection of programs do not fall\noutside a desired set of behaviors. Several important relational properties,\nincluding refinement and noninterference, do not fit into this category, as\nthey require the existence of specific desirable executions. This paper\npresents RHLE, a logic for verifying a class of relational properties which we\nterm $\\forall\\exists$ properties. $\\forall\\exists$ properties assert that for\nall executions of a collection of programs, there exist executions of another\nset of programs exhibiting some intended behavior. Importantly, RHLE can reason\nmodularly about programs which make library calls, ensuring that\n$\\forall\\exists$ properties are preserved when the programs are linked with any\nvalid implementation of the library. To achieve this, we develop a novel form\nof function specification that requires the existence of certain behaviors in\nvalid implementations. We have built a tool based on RHLE which we use to\nverify a diverse set of relational properties drawn from the literature,\nincluding refinement and generalized noninterference.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:03:53 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 22:17:54 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 02:50:11 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 23:17:10 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dickerson", "Robert", ""], ["Ye", "Qianchuan", ""], ["Delaware", "Benjamin", ""]]}, {"id": "2002.02914", "submitter": "Graham Campbell", "authors": "Graham Campbell and Jack Romo and Detlef Plump", "title": "Improving the GP 2 Compiler", "comments": "Technical Report, Department of Computer Science, University of York,\n  42 pages, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  GP 2 is an experimental programming language based on graph transformation\nrules which aims to facilitate program analysis and verification. Writing\nefficient programs in such a language is hard because graph matching is\nexpensive, however GP 2 addresses this problem by providing rooted rules which,\nunder mild conditions, can be matched in constant time using the GP 2 to C\ncompiler. In this report, we document various improvements made to the\ncompiler; most notably the introduction of node lists to improve iteration\nperformance for destructive programs, meaning that binary DAG recognition by\nreduction need only take linear time where the previous implementation required\nquadratic time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:29:54 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 12:44:37 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Campbell", "Graham", ""], ["Romo", "Jack", ""], ["Plump", "Detlef", ""]]}, {"id": "2002.02929", "submitter": "Sven Linker", "authors": "Sven Linker", "title": "Intuitionistic Euler-Venn Diagrams (extended)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an intuitionistic interpretation of Euler-Venn diagrams with\nrespect to Heyting algebras. In contrast to classical Euler-Venn diagrams, we\ntreat shaded and missing zones differently, to have diagrammatic\nrepresentations of conjunction, disjunction and intuitionistic implication. We\npresent a cut-free sequent calculus for this language, and prove it to be sound\nand complete. Furthermore, we show that the rules of cut, weakening and\ncontraction are admissible.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:05:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Linker", "Sven", ""]]}, {"id": "2002.03117", "submitter": "Artur Niewiadomski", "authors": "Magdalena Kacprzak, Artur Niewiadomski, Wojciech Penczek", "title": "SAT-Based ATL Satisfiability Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesis of models and strategies is a very important problem in software\nengineering. The main element here is checking the satisfiability of formulae\nexpressing the specification of a system to be implemented. This paper puts\nforward a novel method for deciding the satisfiability of formulae of\nAlternating-time Temporal Logic (ATL). The method presented expands on one for\nCTL exploit ing SAT Modulo Monotonic Theories solvers. Similarly to the CTL\ncase, our approach appears to be very efficient. The experimental results show\nthat we can quickly test the satisfiability of large ATL formulae that have\nbeen out of reach of the existing approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 08:48:51 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kacprzak", "Magdalena", ""], ["Niewiadomski", "Artur", ""], ["Penczek", "Wojciech", ""]]}, {"id": "2002.03145", "submitter": "Yuri Gurevich", "authors": "Yuri Gurevich", "title": "Means-fit effectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, the notion of effective algorithm is closely related to the\nChurch-Turing thesis. But effectivity imposes no restriction on computation\ntime or any other resource; in that sense, it is incompatible with engineering\nor physics. We propose a natural generalization of it, means-fitting\neffectivity, which is effectivity relative to the (physical or abstract)\nunderlying machinery of the algorithm. This machinery varies from one class of\nalgorithms to another. Think for example of ruler-and-compass algorithms,\narithmetical algorithms, and Blum-Shub-Smale algorithms. We believe that\nmeans-fitting effectivity is meaningful and useful independently of the\nChurch-Turing thesis. Means-fitting effectivity is definable, at least in the\ntheory of abstract state machines (ASMs). The definition elucidates original\neffectivity as well. Familiarity with the ASM theory is not assumed. We tried\nto make the paper self-contained.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:28:24 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 17:27:10 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Gurevich", "Yuri", ""]]}, {"id": "2002.03664", "submitter": "Olivier Serre", "authors": "Rapha\\\"el Berthon, Nathana\\\"el Fijalkow, Emmanuel Filiot, Shibashis\n  Guha, Bastien Maubert, Aniello Murano, Laureline Pinault, Sophie Pinchinat,\n  Sasha Rubin, Olivier Serre", "title": "Alternating Tree Automata with Qualitative Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study alternating automata with qualitative semantics over infinite binary\ntrees: alternation means that two opposing players construct a decoration of\nthe input tree called a run, and the qualitative semantics says that a run of\nthe automaton is accepting if almost all branches of the run are accepting. In\nthis paper we prove a positive and a negative result for the emptiness problem\nof alternating automata with qualitative semantics.\n  The positive result is the decidability of the emptiness problem for the case\nof B\\\"uchi acceptance condition. An interesting aspect of our approach is that\nwe do not extend the classical solution for solving the emptiness problem of\nalternating automata, which first constructs an equivalent non-deterministic\nautomaton. Instead, we directly construct an emptiness game making use of\nimperfect information.\n  The negative result is the undecidability of the emptiness problem for the\ncase of co-B\\\"uchi acceptance condition. This result has two direct\nconsequences: the undecidability of monadic second-order logic extended with\nthe qualitative path-measure quantifier, and the undecidability of the\nemptiness problem for alternating tree automata with non-zero semantics, a\nrecently introduced probabilistic model of alternating tree automata.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:31:08 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 16:17:42 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Fijalkow", "Nathana\u00ebl", ""], ["Filiot", "Emmanuel", ""], ["Guha", "Shibashis", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Pinault", "Laureline", ""], ["Pinchinat", "Sophie", ""], ["Rubin", "Sasha", ""], ["Serre", "Olivier", ""]]}, {"id": "2002.03668", "submitter": "Rajarshi Roy", "authors": "Rajarshi Roy, Dana Fisman and Daniel Neider", "title": "Learning Interpretable Models in the Property Specification Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning human-interpretable descriptions of a\ncomplex system from a finite set of positive and negative examples of its\nbehavior. In contrast to most of the recent work in this area, which focuses on\ndescriptions expressed in Linear Temporal Logic (LTL), we develop a learning\nalgorithm for formulas in the IEEE standard temporal logic PSL (Property\nSpecification Language). Our work is motivated by the fact that many natural\nproperties, such as an event happening at every n-th point in time, cannot be\nexpressed in LTL, whereas it is easy to express such properties in PSL.\nMoreover, formulas in PSL can be more succinct and easier to interpret (due to\nthe use of regular expressions in PSL formulas) than formulas in LTL.\n  Our learning algorithm builds on top of an existing algorithm for learning\nLTL formulas. Roughly speaking, our algorithm reduces the learning task to a\nconstraint satisfaction problem in propositional logic and then uses a SAT\nsolver to search for a solution in an incremental fashion. We have implemented\nour algorithm and performed a comparative study between the proposed method and\nthe existing LTL learning algorithm. Our results illustrate the effectiveness\nof the proposed approach to provide succinct human-interpretable descriptions\nfrom examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:42:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Roy", "Rajarshi", ""], ["Fisman", "Dana", ""], ["Neider", "Daniel", ""]]}, {"id": "2002.03725", "submitter": "Anatole Dahan", "authors": "Anatole Dahan and Anuj Dawar", "title": "Relativization of Gurevich's Conjectures", "comments": "accepted for publication in a volume of papers dedicated to Yuri\n  Gurevich's 80th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gurevich (1988) conjectured that there is no logic for $\\textsf{P}$ or for\n$\\textsf{NP}\\cap \\textsf{coNP}$. For the latter complexity class, he also\nshowed that the existence of a logic would imply that $\\textsf{NP} \\cap\n\\textsf{coNP}$ has a complete problem under polynomial time reductions. We show\nthat there is an oracle with respect to which $\\textsf P$ does have a logic and\n$\\textsf P \\ne\\textsf{NP}$. We also show that a logic for $\\textsf{NP} \\cap\n\\textsf{coNP}$ follows from the existence of a complete problem and a further\nassumption about canonical labelling. For intersection classes $\\Sigma^p_n \\cap\n\\Pi^p_n$ higher in the polynomial hierarchy, the existence of a logic is\nequivalent to the existence of complete problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:28:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dahan", "Anatole", ""], ["Dawar", "Anuj", ""]]}, {"id": "2002.03762", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro and Gilles Dowek", "title": "Extensional proofs in a propositional logic modulo isomorphisms", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System I is a proof language for a fragment of propositional logic where\nisomorphic propositions, such as $A\\wedge B$ and $B\\wedge A$, or\n$A\\Rightarrow(B\\wedge C)$ and $(A\\Rightarrow B)\\wedge(A\\Rightarrow C)$ are made\nequal. System I enjoys the strong normalisation property. This is sufficient to\nprove the existence of empty types, but not to prove the introduction property\n(every closed term in normal form is an introduction). Moreover, a severe\nrestriction had to be made on the types of the variables in order to obtain the\nexistence of empty types. We show here that adding $\\eta$-expansion rules to\nSystem I permits to drop this restriction, and yields a strongly normalising\ncalculus with enjoying the full introduction property.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:10:41 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:05:33 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 14:23:19 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 20:13:31 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Dowek", "Gilles", ""]]}, {"id": "2002.04005", "submitter": "Martin Ziegler", "authors": "Donghyun Lim and Martin Ziegler", "title": "Quantitative Coding and Complexity Theory of Compact Metric Spaces", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-51466-2_18", "report-no": null, "categories": "math.LO cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specifying a computational problem requires fixing encodings for input and\noutput: encoding graphs as adjacency matrices, characters as integers, integers\nas bit strings, and vice versa. For such discrete data, the actual encoding is\nusually straightforward and/or complexity-theoretically inessential (up to\npolynomial time, say); but concerning continuous data, already real numbers\nnaturally suggest various encodings with very different computational\nproperties. With respect to qualitative computability, Kreitz and Weihrauch\n(1985) had identified ADMISSIBILITY as crucial property for 'reasonable'\nencodings over the Cantor space of infinite binary sequences, so-called\nrepresentations [doi:10.1007/11780342_48]: For (precisely) these does the\nsometimes so-called MAIN THEOREM apply, characterizing continuity of functions\nin terms of continuous realizers.\n  We rephrase qualitative admissibility as continuity of both the\nrepresentation and its multivalued inverse, adopting from\n[doi:10.4115/jla.2013.5.7] a notion of sequential continuity for\nmultifunctions. This suggests its quantitative refinement as criterion for\nrepresentations suitable for complexity investigations. Higher-type complexity\nis captured by replacing Cantor's as ground space with Baire or any other\n(compact) ULTRAmetric space: a quantitative counterpart to equilogical spaces\nin computability [doi:10.1016/j.tcs.2003.11.012].\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:23:21 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 16:03:16 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 23:08:35 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lim", "Donghyun", ""], ["Ziegler", "Martin", ""]]}, {"id": "2002.04011", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Antonio Bucciarelli, Delia Kesner, Alejandro R\\'ios, Andr\\'es Viso", "title": "The Bang Calculus Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Call-by-Push-Value (CBPV) is a programming paradigm subsuming both\nCall-by-Name (CBN) and Call-by-Value (CBV) semantics. The paradigm was recently\nmodelled by means of the Bang Calculus, a term language connecting CBPV and\nLinear Logic.\n  This paper presents a revisited version of the Bang Calculus, called $\\lambda\n!$, enjoying some important properties missing in the original system. Indeed,\nthe new calculus integrates commutative conversions to unblock value redexes\nwhile being confluent at the same time. A second contribution is related to\nnon-idempotent types. We provide a quantitative type system for our $\\lambda\n!$-calculus, and we show that the length of the (weak) reduction of a typed\nterm to its normal form \\emph{plus} the size of this normal form is bounded by\nthe size of its type derivation. We also explore the properties of this type\nsystem with respect to CBN/CBV translations. We keep the original CBN\ntranslation from $\\lambda$-calculus to the Bang Calculus, which preserves\nnormal forms and is sound and complete with respect to the (quantitative) type\nsystem for CBN. However, in the case of CBV, we reformulate both the\ntranslation and the type system to restore two main properties: preservation of\nnormal forms and completeness. Last but not least, the quantitative system is\nrefined to a \\emph{tight} one, which transforms the previous upper bound on the\nlength of reduction to normal form plus its size into two independent\n\\emph{exact} measures for them.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:38:00 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 13:02:32 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bucciarelli", "Antonio", ""], ["Kesner", "Delia", ""], ["R\u00edos", "Alejandro", ""], ["Viso", "Andr\u00e9s", ""]]}, {"id": "2002.04282", "submitter": "Alexis B\\`es", "authors": "Alexis B\\`es and Christian Choffrut", "title": "Theories of real addition with and without a predicate for integers", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 26,\n  2021) lmcs:7512", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that it is decidable whether or not a relation on the reals definable\nin the structure $\\langle \\mathbb{R}, +,<, \\mathbb{Z} \\rangle$ can be defined\nin the structure $\\langle \\mathbb{R}, +,<, 1 \\rangle$. This result is achieved\nby obtaining a topological characterization of $\\langle \\mathbb{R}, +,<, 1\n\\rangle$-definable relations in the family of $\\langle \\mathbb{R}, +,<,\n\\mathbb{Z} \\rangle$-definable relations and then by following Muchnik's\napproach of showing that the characterization of the relation $X$ can be\nexpressed in the logic of $\\langle \\mathbb{R}, +,<,1, X \\rangle$.\n  The above characterization allows us to prove that there is no intermediate\nstructure between $\\langle \\mathbb{R}, +,<, \\mathbb{Z} \\rangle$ and $\\langle\n\\mathbb{R}, +,<, 1 \\rangle$. We also show that a $\\langle \\mathbb{R}, +,<,\n\\mathbb{Z} \\rangle$-definable relation is $\\langle \\mathbb{R}, +,<, 1\n\\rangle$-definable if and only if its intersection with every $\\langle\n\\mathbb{R}, +,<, 1 \\rangle$-definable line is $\\langle \\mathbb{R}, +,<, 1\n\\rangle$-definable. This gives a noneffective but simple characterization of\n$\\langle \\mathbb{R}, +,<, 1 \\rangle$-definable relations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:57:14 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 09:03:14 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 20:06:16 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 12:43:43 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["B\u00e8s", "Alexis", ""], ["Choffrut", "Christian", ""]]}, {"id": "2002.04460", "submitter": "Piotr Wieczorek", "authors": "Jakub Michaliszyn and Jan Otop and Piotr Wieczorek", "title": "Modular Path Queries with Arithmetic", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.04419", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to querying graph databases. Our approach balances\ncompeting goals of expressive power, language clarity and computational\ncomplexity. A distinctive feature of our approach is the ability to express\nproperties of minimal (e.g. shortest) and maximal (e.g. most valuable) paths\nsatisfying given criteria. To express complex properties in a modular way, we\nintroduce labelling-generating ontologies. The resulting formalism is\ncomputationally attractive -- queries can be answered in non-deterministic\nlogarithmic space in the size of the database.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:14:49 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 17:12:46 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 16:58:59 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 17:41:20 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Michaliszyn", "Jakub", ""], ["Otop", "Jan", ""], ["Wieczorek", "Piotr", ""]]}, {"id": "2002.04590", "submitter": "Oleg Verbitsky", "authors": "Frank Fuhlbr\\\"uck, Johannes K\\\"obler, Oleg Verbitsky", "title": "Local WL Invariance and Hidden Shades of Regularity", "comments": "12 pages, 2 figures, 1 table. Section 5 of the preceding version is\n  moved to arxiv:2005.08887", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-dimensional Weisfeiler-Leman algorithm is a powerful tool in graph\nisomorphism testing. For an input graph $G$, the algorithm determines a\ncanonical coloring of $s$-tuples of vertices of $G$ for each $s$ between 1 and\n$k$. We say that a numerical parameter of $s$-tuples is $k$-WL-invariant if it\nis determined by the tuple color. As an application of Dvo\\v{r}\\'ak's result on\n$k$-WL-invariance of homomorphism counts, we spot some non-obvious regularity\nproperties of strongly regular graphs and related graph families. For example,\nif $G$ is a strongly regular graph, then the number of paths of length 6\nbetween vertices $x$ and $y$ in $G$ depends only on whether or not $x$ and $y$\nare adjacent (and the length 6 is here optimal). Or, the number of cycles of\nlength 7 passing through a vertex $x$ in $G$ is the same for every $x$ (where\nthe length 7 is also optimal).\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:32:02 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 16:36:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Fuhlbr\u00fcck", "Frank", ""], ["K\u00f6bler", "Johannes", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "2002.04607", "submitter": "Klaas Pruiksma", "authors": "Klaas Pruiksma and Frank Pfenning", "title": "Back to Futures", "comments": "31 pages, 3 figures. Submitted to ESOP 2021. This replaces a previous\n  version with similar content, but has been heavily rewritten to reflect\n  increased understanding of the contents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common approaches to concurrent programming begin with languages whose\nsemantics are naturally sequential and add new constructs that provide limited\naccess to concurrency, as exemplified by futures. This approach has been quite\nsuccessful, but often does not provide a satisfactory theoretical backing for\nthe concurrency constructs, and it can be difficult to give a good semantics\nthat allows a programmer to use more than one of these constructs at a time.\n  We take a different approach, starting with a concurrent language based on a\nCurry-Howard interpretation of adjoint logic, to which we add three atomic\nprimitives that allow us to encode sequential composition and various forms of\nsynchronization. The resulting language is highly expressive, allowing us to\nencode futures, fork/join parallelism, and monadic concurrency in the same\nframework. Notably, since our language is based on adjoint logic, we are able\nto give a formal account of linear futures, which have been used in complexity\nanalysis by Blelloch and Reid-Miller. The uniformity of this approach means\nthat we can similarly work with many of the other concurrency primitives in a\nlinear fashion, and that we can mix several of these forms of concurrency in\nthe same program to serve different purposes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:57:32 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 19:56:45 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Pruiksma", "Klaas", ""], ["Pfenning", "Frank", ""]]}, {"id": "2002.04841", "submitter": "Harro Wimmel", "authors": "Uli Schlachter and Harro Wimmel", "title": "Optimal Label Splitting for Embedding an LTS into an arbitrary Petri Net\n  Reachability Graph is NP-complete", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given labelled transition system (LTS), synthesis is the task to find\nan unlabelled Petri net with an isomorphic reachability graph. Even when just\ndemanding an embedding into a reachability graph instead of an isomorphism, a\nsolution is not guaranteed. In such a case, label splitting is an option, i.e.\nrelabelling edges of the LTS such that differently labelled edges remain\ndifferent. With an appropriate label splitting, we can always obtain a solution\nfor the synthesis or embedding problem. Using the label splitting, we can\nconstruct a labelled Petri net with the intended bahaviour (e.g. embedding the\ngiven LTS in its reachability graph). As the labelled Petri net can have a\nlarge number of transitions, an optimisation may be desired, limiting the\nnumber of labels produced by the label splitting. We show that such a\nlimitation will turn the problem from being solvable in polynomial time into an\nNP-complete problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:28:32 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Schlachter", "Uli", ""], ["Wimmel", "Harro", ""]]}, {"id": "2002.04855", "submitter": "Eugenio Orlandelli", "authors": "Eugenio Orlandelli", "title": "Labelled calculi for quantified modal logics with definite descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce labelled sequent calculi for quantified modal logics with\ndefinite descriptions. We prove that these calculi have the good structural\nproperties of G3-style calculi. In particular, all rules are height-preserving\ninvertible, weakening and contraction are height-preserving admissible and cut\nis admissible. Finally, we show that each calculus gives a proof-theoretic\ncharacterization of validity in the corresponding class of models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:11:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Orlandelli", "Eugenio", ""]]}, {"id": "2002.05064", "submitter": "Denis Ponomaryov", "authors": "Andrei Mantsivoda and Denis Ponomaryov", "title": "On Termination of Transactions over Semantic Document Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the framework of Document Modeling, which lays the formal basis\nfor representing the document lifecycle in Business Process Management systems.\nWe formulate document models in the scope of the logic-based Semantic Modeling\nlanguage and study the question whether transactions given by a document model\nterminate on any input. We show that in general this problem is undecidable and\nformulate sufficient conditions, which guarantee decidability and polynomial\nboundedness of effects of transactions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:08:49 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 13:03:05 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 13:46:08 GMT"}, {"version": "v4", "created": "Tue, 17 Mar 2020 06:23:12 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Mantsivoda", "Andrei", ""], ["Ponomaryov", "Denis", ""]]}, {"id": "2002.05075", "submitter": "Daniel Hausmann", "authors": "Daniel Hausmann and Lutz Schr\\\"oder", "title": "NP Reasoning in the Monotone $\\mu$-Calculus", "comments": "Longer version of IJCAR 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability checking for monotone modal logic is known to be (only)\nNP-complete. We show that this remains true when the logic is extended with\naconjunctive and alternation-free fixpoint operators as well as the universal\nmodality; the resulting logic -- the aconjunctive alternation-free monotone\n$\\mu$-calculus with the universal modality -- contains both concurrent\npropositional dynamic logic (CPDL) and the alternation-free fragment of game\nlogic as fragments. We obtain our result from a characterization of\nsatisfiability by means of B\\\"uchi games with polynomially many Eloise nodes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:28:59 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 02:04:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hausmann", "Daniel", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "2002.05256", "submitter": "Mario Alvarez-Picallo", "authors": "Mario Alvarez-Picallo", "title": "Change actions: from incremental computation to discrete derivatives", "comments": "PhD thesis, Oxford, Preliminary version, 224 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this thesis is threefold: first, to provide a general semantic\nsetting for reasoning about incremental computation. Second, to establish and\nclarify the connection between derivatives in the incremental sense and\nderivatives in the analytic sense, that is to say, to provide a common\ndefinition of derivative of which the previous two are particular instances.\nThird, to give a theoretically sound calculus for this general setting. To this\nend we define and explore the notions of change actions and differential maps\nbetween change actions and show how these notions relate to incremental\ncomputation through the concrete example of the semi-naive evaluation of\nDatalog queries. We also introduce the notion of a change action model as a\nsetting for higher-order differentiation, and exhibit some interesting\nexamples. Finally, we show how Cartesian difference categories, a family of\nparticularly well-behaved change action models, generalise Cartesian\ndifferential categories and give rise to a calculus in the spirit of Ehrhard\nand Regnier's differential lambda-calculus.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:58:24 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:19:56 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Alvarez-Picallo", "Mario", ""]]}, {"id": "2002.05406", "submitter": "Josef Urban", "authors": "Jan Jakub\\r{u}v, Karel Chvalovsk\\'y, Miroslav Ol\\v{s}\\'ak, Bartosz\n  Piotrowski, Martin Suda, Josef Urban", "title": "ENIGMA Anonymous: Symbol-Independent Inference Guiding Machine (system\n  description)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an implementation of gradient boosting and neural guidance of\nsaturation-style automated theorem provers that does not depend on consistent\nsymbol names across problems. For the gradient-boosting guidance, we manually\ncreate abstracted features by considering arity-based encodings of formulas.\nFor the neural guidance, we use symbol-independent graph neural networks (GNNs)\nand their embedding of the terms and clauses. The two methods are efficiently\nimplemented in the E prover and its ENIGMA learning-guided framework.\n  To provide competitive real-time performance of the GNNs, we have developed a\nnew context-based approach to evaluation of generated clauses in E. Clauses are\nevaluated jointly in larger batches and with respect to a large number of\nalready selected clauses (context) by the GNN that estimates their collectively\nmost useful subset in several rounds of message passing. This means that\napproximative inference rounds done by the GNN are efficiently interleaved with\nprecise symbolic inference rounds done inside E. The methods are evaluated on\nthe MPTP large-theory benchmark and shown to achieve comparable real-time\nperformance to state-of-the-art symbol-based methods. The methods also show\nhigh complementarity, solving a large number of hard Mizar problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:44:38 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:59:26 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Chvalovsk\u00fd", "Karel", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Piotrowski", "Bartosz", ""], ["Suda", "Martin", ""], ["Urban", "Josef", ""]]}, {"id": "2002.05649", "submitter": "Gabriele Vanoni", "authors": "Beniamino Accattoli and Ugo Dal Lago and Gabriele Vanoni", "title": "The Abstract Machinery of Interaction (Long Version)", "comments": "Accepted at PPDP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the Interaction Abstract Machine (IAM), a machine based\non Girard's Geometry of Interaction, introduced by Mackie and Danos & Regnier.\nIt is an unusual machine, not relying on environments, presented on linear\nlogic proof nets, and whose soundness proof is convoluted and passes through\nvarious other formalisms. Here we provide a new direct proof of its\ncorrectness, based on a variant of Sands's improvements, a natural notion of\nbisimulation. Moreover, our proof is carried out on a new presentation of the\nIAM, defined as a machine acting directly on $\\lambda$-terms, rather than on\nlinear logic proof nets.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:32:39 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 10:53:23 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Lago", "Ugo Dal", ""], ["Vanoni", "Gabriele", ""]]}, {"id": "2002.05958", "submitter": "Marianna Girlando", "authors": "Marianna Girlando and Sara Negri and Nicola Olivetti", "title": "Uniform labelled calculi for preferential conditional logics based on\n  neighbourhood semantics", "comments": "Submitted for publication. Will be revised after referees report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preferential conditional logic PCL, introduced by Burgess, and its\nextensions are studied. First, a natural semantics based on neighbourhood\nmodels, which generalise Lewis' sphere models for counterfactual logics, is\nproposed. Soundness and completeness of PCL and its extensions with respect to\nthis class of models are proved directly. Labelled sequent calculi for all\nlogics of the family are then introduced. The calculi are modular and have\nstandard proof-theoretical properties, the most important of which is\nadmissibility of cut, that entails a syntactic proof of completeness of the\ncalculi. By adopting a general strategy, root-first proof search terminates,\nthereby providing a decision procedure for PCL and its extensions. Finally, the\nsemantic completeness of the calculi is established: from a finite branch in a\nfailed proof attempt it is possible to extract a finite countermodel of the\nroot sequent. The latter result gives a constructive proof of the finite model\nproperty of all the logics considered.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 10:36:41 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Girlando", "Marianna", ""], ["Negri", "Sara", ""], ["Olivetti", "Nicola", ""]]}, {"id": "2002.06000", "submitter": "Borja Gonzalez Leon", "authors": "Borja G. Le\\'on and Francesco Belardinelli", "title": "Extended Markov Games to Learn Multiple Tasks in Multi-Agent\n  Reinforcement Learning", "comments": "Long version of the correspondent ECAI 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Formal Methods with Reinforcement Learning (RL) has\nrecently attracted interest as a way for single-agent RL to learn multiple-task\nspecifications. In this paper we extend this convergence to multi-agent\nsettings and formally define Extended Markov Games as a general mathematical\nmodel that allows multiple RL agents to concurrently learn various\nnon-Markovian specifications. To introduce this new model we provide formal\ndefinitions and proofs as well as empirical tests of RL algorithms running on\nthis framework. Specifically, we use our model to train two different\nlogic-based multi-agent RL algorithms to solve diverse settings of\nnon-Markovian co-safe LTL specifications.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:37:41 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Le\u00f3n", "Borja G.", ""], ["Belardinelli", "Francesco", ""]]}, {"id": "2002.06047", "submitter": "Luca Ciccone", "authors": "Luca Ciccone", "title": "Flexible Coinduction in Agda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theorem provers are tools that help users to write machine readable proofs.\nSome of this tools are also interactive. The need of such softwares is\nincreasing since they provide proofs that are more certified than the hand\nwritten ones. Agda is based on type theory and on the propositions-as-types\ncorrespondence and has a Haskell-like syntax. This means that a proof of a\nstatement is turned into a function. Inference systems are a way of defining\ninductive and coinductive predicates and induction and coinduction principles\nare provided to help proving their correctness with respect to a given\nspecification in terms of soundness and completeness. Generalized inference\nsystems deal with predicates whose inductive and coinductive interpretations do\nnot provide the expected set of judgments. In this case inference systems are\nenriched by corules that are rules that can be applied at infinite depth in a\nproof tree. Induction and coinduction principles cannot be used in case of\ngeneralized inference systems and the bounded coinduction one has been\nproposed. We first present how Agda supports inductive and coinductive types\nhighlighting the fact that data structures and predicates are defined using the\nsame constructs. Then we move to the main topic of this thesis, which is\ninvestigating how generalized inference systems can be implemented and how\ntheir correctness can be proved.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:20:00 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 13:15:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ciccone", "Luca", ""]]}, {"id": "2002.06072", "submitter": "Bartosz Bednarczyk", "authors": "Franz Baader, Bartosz Bednarczyk and Sebastian Rudolph", "title": "Satisfiability and Query Answering in Description Logics with Global and\n  Local Cardinality Constraints", "comments": "Technical report for the paper of the same title accepted to ECAI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and investigate the expressive description logic (DL) ALCSCC++,\nin which the global and local cardinality constraints introduced in previous\npapers can be mixed. On the one hand, we prove that this does not increase the\ncomplexity of satisfiability checking and other standard inference problems. On\nthe other hand, the satisfiability problem becomes undecidable if inverse roles\nare added to the languages. In addition, even without inverse roles,\nconjunctive query entailment in this DL turns out to be undecidable. We prove\nthat decidability of querying can be regained if global and local constraints\nare not mixed and the global constraints are appropriately restricted. The\nlatter result is based on a locally-acyclic model construction, and it reduces\nquery entailment to ABox consistency in the restricted setting, i.e., to ABox\nconsistency w.r.t. restricted cardinality constraints in ALCSCC, for which we\ncan show an ExpTime upper bound.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:28:15 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Baader", "Franz", ""], ["Bednarczyk", "Bartosz", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2002.06100", "submitter": "Emile Van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Analyzing Differentiable Fuzzy Logic Operators", "comments": "45 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a push to integrate symbolic AI and deep\nlearning, as it is argued that the strengths and weaknesses of these approaches\nare complementary. One such trend in the literature are weakly supervised\nlearning techniques that use operators from fuzzy logics. They employ prior\nbackground knowledge described in logic to benefit the training of a neural\nnetwork from unlabeled and noisy data. By interpreting logical symbols using\nneural networks, this background knowledge can be added to regular loss\nfunctions used in deep learning to integrate reasoning and learning. In this\npaper, we analyze how a large collection of logical operators from the fuzzy\nlogic literature behave in a differentiable setting. We find large differences\nbetween the formal properties of these operators that are of crucial importance\nin a differentiable learning setting. We show that many of these operators,\nincluding some of the best known, are highly unsuitable for use in a\ndifferentiable learning setting. A further finding concerns the treatment of\nimplication in these fuzzy logics, with a strong imbalance between gradients\ndriven by the antecedent and the consequent of the implication. Finally, we\nempirically show that it is possible to use Differentiable Fuzzy Logics for\nsemi-supervised learning. However, to achieve the most significant performance\nimprovement over a supervised baseline, we have to resort to non-standard\ncombinations of logical operators which perform well in learning, but which no\nlonger satisfy the usual logical laws. We end with a discussion on extensions\nto large-scale problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:11:36 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "2002.06451", "submitter": "Gregory Wilsenach", "authors": "Anuj Dawar and Gregory Wilsenach", "title": "Symmetric Arithmetic Circuits", "comments": "24 pages. A preliminary version of this work was presented at the\n  International Colloquium on Automata, Languages and Programming (ICALP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce symmetric arithmetic circuits, i.e. arithmetic circuits with a\nnatural symmetry restriction. In the context of circuits computing polynomials\ndefined on a matrix of variables, such as the determinant or the permanent, the\nrestriction amounts to requiring that the shape of the circuit is invariant\nunder simultaneous row and column permutations of the matrix. We establish\nunconditional exponential lower bounds on the size of any symmetric circuit for\ncomputing the permanent. In contrast, we show that there are polynomial-size\nsymmetric circuits for computing the determinant over fields of characteristic\nzero.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 21:13:00 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 21:15:27 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Dawar", "Anuj", ""], ["Wilsenach", "Gregory", ""]]}, {"id": "2002.06465", "submitter": "Ezio Bartocci", "authors": "Ezio Bartocci, Thomas Ferr\\`ere, Thomas A. Henzinger, Dejan Nickovic\n  and Ana Oliveira da Costa", "title": "Information-Flow Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contract-based design is a promising methodology for taming the complexity of\ndeveloping sophisticated systems. A formal contract distinguishes between\nassumptions, which are constraints that the designer of a component puts on the\nenvironments in which the component can be used safely, and guarantees, which\nare promises that the designer asks from the team that implements the\ncomponent. A theory of formal contracts can be formalized as an interface\ntheory, which supports the composition and refinement of both assumptions and\nguarantees. Although there is a rich landscape of contract-based design methods\nthat address functional and extra-functional properties, we present the first\ninterface theory that is designed for ensuring system-wide security properties,\nthus paving the way for a science of safety and security co-engineering. Our\nframework provides a refinement relation and a composition operation that\nsupport both incremental design and independent implementability. We develop\nour theory for both stateless and stateful interfaces. We illustrate the\napplicability of our framework with an example inspired from the automotive\ndomain. Finally, we provide three plausible trace semantics to stateful\ninformation-flow interfaces and we show that only two correspond to temporal\nlogics for specifying hyperproperties, while the third defines a new class of\nhyperproperties that lies between the other two classes.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:49:34 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 04:19:25 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 20:53:25 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Bartocci", "Ezio", ""], ["Ferr\u00e8re", "Thomas", ""], ["Henzinger", "Thomas A.", ""], ["Nickovic", "Dejan", ""], ["da Costa", "Ana Oliveira", ""]]}, {"id": "2002.06727", "submitter": "Krist\\'of B\\'erczi", "authors": "Krist\\'of B\\'erczi, Endre Boros, Ond\\v{r}ej \\v{C}epek, Khaled\n  Elbassioni, Petr Ku\\v{c}era, Kazuhisa Makino", "title": "Generating clause sequences of a CNF formula", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a CNF formula $\\Phi$ with clauses $C_1,\\ldots,C_m$ and variables\n$V=\\{x_1,\\ldots,x_n\\}$, a truth assignment $a:V\\rightarrow\\{0,1\\}$ of $\\Phi$\nleads to a clause sequence $\\sigma_\\Phi(a)=(C_1(a),\\ldots,C_m(a))\\in\\{0,1\\}^m$\nwhere $C_i(a) = 1$ if clause $C_i$ evaluates to $1$ under assignment $a$,\notherwise $C_i(a) = 0$. The set of all possible clause sequences carries a lot\nof information on the formula, e.g. SAT, MAX-SAT and MIN-SAT can be encoded in\nterms of finding a clause sequence with extremal properties.\n  We consider a problem posed at Dagstuhl Seminar 19211 \"Enumeration in Data\nManagement\" (2019) about the generation of all possible clause sequences of a\ngiven CNF with bounded dimension. We prove that the problem can be solved in\nincremental polynomial time. We further give an algorithm with polynomial delay\nfor the class of tractable CNF formulas. We also consider the generation of\nmaximal and minimal clause sequences, and show that generating maximal clause\nsequences is NP-hard, while minimal clause sequences can be generated with\npolynomial delay.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:35:02 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["B\u00e9rczi", "Krist\u00f3f", ""], ["Boros", "Endre", ""], ["\u010cepek", "Ond\u0159ej", ""], ["Elbassioni", "Khaled", ""], ["Ku\u010dera", "Petr", ""], ["Makino", "Kazuhisa", ""]]}, {"id": "2002.06737", "submitter": "Zhe Chen", "authors": "Zhe Chen, Yunyun Chen, Robert M. Hierons and Yifan Wu", "title": "Four-valued monitorability of $\\omega$-regular languages", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime Verification (RV) is a lightweight formal technique in which program\nor system execution is monitored and analyzed, to check whether certain\nproperties are satisfied or violated after a finite number of steps. The use of\nRV has led to interest in deciding whether a property is monitorable: whether\nit is always possible for the satisfaction or violation of the property to be\ndetermined after a finite future continuation. However, classical two-valued\nmonitorability suffers from two inherent limitations. First, a property can\nonly be evaluated as monitorable or non-monitorable; no information is\navailable regarding whether only one verdict (satisfaction or violation) can be\ndetected. Second, monitorability is defined at the language-level and does not\ntell us whether satisfaction or violation can be detected starting from the\ncurrent monitor state during system execution.\n  To address these limitations, this paper proposes a new notion of four-valued\nmonitorability for $\\omega$-languages and applies it at the state-level.\nFour-valued monitorability is more informative than two-valued monitorability\nas a property can be evaluated as a four-valued result, denoting that only\nsatisfaction, only violation, or both are active for a monitorable property. We\ncan also compute state-level weak monitorability, i.e., whether satisfaction or\nviolation can be detected starting from a given state in a monitor, which\nenables state-level optimizations of monitoring algorithms. Based on a new\nsix-valued semantics, we propose procedures for computing four-valued\nmonitorability of $\\omega$-regular languages, both at the language-level and at\nthe state-level. We have developed a new tool that implements the proposed\nprocedure for computing monitorability of LTL formulas.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 01:54:27 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 03:44:09 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Chen", "Zhe", ""], ["Chen", "Yunyun", ""], ["Hierons", "Robert M.", ""], ["Wu", "Yifan", ""]]}, {"id": "2002.06784", "submitter": "Satoshi Kura", "authors": "Satoshi Kura", "title": "Graded Algebraic Theories", "comments": "Long version of FoSSaCS'20 camera ready paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide graded extensions of algebraic theories and Lawvere theories that\ncorrespond to graded monads. We prove that graded algebraic theories, graded\nLawvere theories, and finitary graded monads are equivalent via equivalence of\ncategories, which extends the equivalence for monads. We also give sums and\ntensor products of graded algebraic theories to combine computational effects\nas an example of importing techniques based on algebraic theories to graded\nmonads.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:01:06 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 06:40:16 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Kura", "Satoshi", ""]]}, {"id": "2002.06911", "submitter": "Philipp Wanko", "authors": "Pedro Cabalar and Jorge Fandinno and Torsten Schaub and Philipp Wanko", "title": "An ASP semantics for Constraints involving Conditional Aggregates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate upon the formal foundations of hybrid Answer Set Programming\n(ASP) and extend its underlying logical framework with aggregate functions over\nconstraint values and variables. This is achieved by introducing the construct\nof conditional expressions, which allow for considering two alternatives while\nevaluating constraints. Which alternative is considered is\ninterpretation-dependent and chosen according to an associated condition. We\nput some emphasis on logic programs with linear constraints and show how common\nASP aggregates can be regarded as particular cases of so-called conditional\nlinear constraints. Finally, we introduce a polynomial-size, modular and\nfaithful translation from our framework into regular (condition-free)\nConstraint ASP, outlining an implementation of conditional aggregates on top of\nexisting hybrid ASP solvers.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:25:01 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 15:37:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Schaub", "Torsten", ""], ["Wanko", "Philipp", ""]]}, {"id": "2002.06916", "submitter": "Fran\\c{c}ois Laferri\\`ere", "authors": "Pedro Cabalar (University of Corunna, Spain), Mart\\'in Di\\'eguez\n  (University of Pau, France), Torsten Schaub (1), Fran\\c{c}ois Laferri\\`ere\n  (1) ((1) University of Potsdam, Germany)", "title": "Implementing Dynamic Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an implementation of an extension of Answer Set Programming\n(ASP) with language constructs from dynamic (and temporal) logic that provides\nan expressive computational framework for modeling dynamic applications.\nStarting from logical foundations, provided by dynamic and temporal equilibrium\nlogics over finite linear traces, we develop a translation of dynamic formulas\ninto temporal logic programs. This provides us with a normal form result\nestablishing the strong equivalence of formulas in different logics. Our\ntranslation relies on the introduction of auxiliary atoms to guarantee\npolynomial space complexity and to provide an embedding that is doomed to be\nimpossible over the same language. Finally, the reduction of dynamic formulas\nto temporal logic programs allows us to extend ASP with both approaches in a\nuniform way and to implement both extensions via temporal ASP solvers such as\ntelingo\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:34:14 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:33:34 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Cabalar", "Pedro", "", "University of Corunna, Spain"], ["Di\u00e9guez", "Mart\u00edn", "", "University of Pau, France"], ["Schaub", "Torsten", "", "University of Potsdam, Germany"], ["Laferri\u00e8re", "Fran\u00e7ois", "", "University of Potsdam, Germany"]]}, {"id": "2002.07019", "submitter": "Mingzhe Wang", "authors": "Mingzhe Wang, Jia Deng", "title": "Learning to Prove Theorems by Learning to Generate Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of automated theorem proving, a key AI task. Deep\nlearning has shown promise for training theorem provers, but there are limited\nhuman-written theorems and proofs available for supervised learning. To address\nthis limitation, we propose to learn a neural generator that automatically\nsynthesizes theorems and proofs for the purpose of training a theorem prover.\nExperiments on real-world tasks demonstrate that synthetic data from our\napproach improves the theorem prover and advances the state of the art of\nautomated theorem proving in Metamath. Code is available at\nhttps://github.com/princeton-vl/MetaGen.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:06:02 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 04:33:04 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Mingzhe", ""], ["Deng", "Jia", ""]]}, {"id": "2002.07020", "submitter": "Vikraman Choudhury", "authors": "Chao-Hong Chen, Vikraman Choudhury, Jacques Carette, Amr Sabry", "title": "Fractional Types: Expressive and Safe Space Management for Ancilla Bits", "comments": "For the agda formalization, see\n  https://github.com/DreamLinuxer/FracAncilla", "journal-ref": null, "doi": "10.1007/978-3-030-52482-1_10", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reversible computing, the management of space is subject to two broad\nclasses of constraints. First, as with general-purpose computation, every\nallocation must be paired with a matching de-allocation. Second, space can only\nbe safely de-allocated if its contents are restored to their initial value from\nallocation time. Generally speaking, the state of the art provides limited\npartial solutions that address the first constraint by imposing a stack\ndiscipline and by leaving the second constraint to programmers' assertions. We\npropose a novel approach based on the idea of fractional types. As a simple\nintuitive example, allocation of a new boolean value initialized to\n$\\texttt{false}$ also creates a value $1/{\\texttt{false}}$ that can be thought\nof as a garbage collection (GC) process specialized to reclaim, and only\nreclaim, storage containing the value $\\texttt{false}$. This GC process is a\nfirst-class entity that can be manipulated, decomposed into smaller processes\nand combined with other GC processes. We formalize this idea in the context of\na reversible language founded on type isomorphisms, prove its fundamental\ncorrectness properties, and illustrate its expressiveness using a wide variety\nof examples. The development is backed by a fully-formalized Agda\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:06:23 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chen", "Chao-Hong", ""], ["Choudhury", "Vikraman", ""], ["Carette", "Jacques", ""], ["Sabry", "Amr", ""]]}, {"id": "2002.07025", "submitter": "Abhishek Kulkarni", "authors": "Jie Fu, Abhishek N. Kulkarni, Huan Luo, Nandi O. Leslie and Charles A.\n  Kamhoua", "title": "Secure-by-synthesis network with active deception and temporal logic\n  specifications", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the synthesis of strategies in network systems\nwith active cyber deception. Active deception in a network employs decoy\nsystems and other defenses to conduct defensive planning against the intrusion\nof malicious attackers who have been confirmed by sensing systems. In this\nsetting, the defender's objective is to ensure the satisfaction of security\nproperties specified in temporal logic formulas. We formulate the problem of\ndeceptive planning with decoy systems and other defenses as a two-player games\nwith asymmetrical information and Boolean payoffs in temporal logic. We use\nlevel-2 hypergame with temporal logic objectives to capture the\nincomplete/incorrect knowledge of the attacker about the network system as a\npayoff misperception. The true payoff function is private information of the\ndefender. Then, we extend the solution concepts of $omega$-regular games to\nanalyze the attacker's rational strategy given her incomplete information. By\ngeneralizing the solution of level-2 hypergame in the normal form to extensive\nform, we extend the solutions of games with safe temporal logic objectives to\ndecide whether the defender can ensure security properties to be satisfied with\nprobability one, given any possible strategy that is perceived to be rational\nby the attacker. Further, we use the solution of games with co-safe\n(reachability) temporal logic objectives to determine whether the defender can\nengage the attacker, by directing the attacker to a high-fidelity honeypot. The\neffectiveness of the proposed synthesis methods is illustrated with synthetic\nnetwork systems with honeypots.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:09:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Fu", "Jie", ""], ["Kulkarni", "Abhishek N.", ""], ["Luo", "Huan", ""], ["Leslie", "Nandi O.", ""], ["Kamhoua", "Charles A.", ""]]}, {"id": "2002.07054", "submitter": "Michael Pinsker", "authors": "Pierre Gillibert, Julius Jonu\\v{s}as, Michael Kompatscher, Antoine\n  Mottet, Michael Pinsker", "title": "When symmetries are not enough: a hierarchy of hard Constraint\n  Satisfaction Problems", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We produce a class of $\\omega$-categorical structures with finite signature\nby applying a model-theoretic construction -- a refinement of the\nHrushosvki-encoding -- to $\\omega$-categorical structures in a possibly\ninfinite signature. We show that the encoded structures retain desirable\nalgebraic properties of the original structures, but that the constraint\nsatisfaction problems (CSPs) associated with these structures can be badly\nbehaved in terms of computational complexity. This method allows us to\nsystematically generate $\\omega$-categorical templates whose CSPs are complete\nfor a variety of complexity classes of arbitrarily high complexity, and\n$\\omega$-categorical templates that show that membership in any given\ncomplexity class cannot be expressed by a set of identities on the\npolymorphisms. It moreover enables us to prove that recent results about the\nrelevance of topology on polymorphism clones of $\\omega$-categorical structures\nalso apply for CSP templates, i.e., structures in a finite language. Finally,\nwe obtain a concrete algebraic criterion which could constitute a description\nof the delineation between tractability and NP-hardness in the dichotomy\nconjecture for first-order reducts of finitely bounded homogeneous structures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:49:00 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 19:54:03 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gillibert", "Pierre", ""], ["Jonu\u0161as", "Julius", ""], ["Kompatscher", "Michael", ""], ["Mottet", "Antoine", ""], ["Pinsker", "Michael", ""]]}, {"id": "2002.07115", "submitter": "Sophie Fortz", "authors": "Sophie Fortz, Fred Mesnard, Etienne Payet, Gilles Perrouin, Wim\n  Vanhoof and German Vidal", "title": "An SMT-Based Concolic Testing Tool for Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concolic testing mixes symbolic and concrete execution to generate test cases\ncovering paths effectively. Its benefits have been demonstrated for more than\n15 years to test imperative programs. Other programming paradigms, like logic\nprogramming, have received less attention. In this paper, we present a\nconcolic-based test generation method for logic programs. Our approach exploits\nSMT-solving for constraint resolution. We then describe the implementation of a\nconcolic testing tool for Prolog and validate it on some selected benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:25:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Fortz", "Sophie", ""], ["Mesnard", "Fred", ""], ["Payet", "Etienne", ""], ["Perrouin", "Gilles", ""], ["Vanhoof", "Wim", ""], ["Vidal", "German", ""]]}, {"id": "2002.07218", "submitter": "Ugo Dal Lago", "authors": "Boaz Barak, Rapha\\\"elle Crubill\\'e, Ugo Dal Lago", "title": "On Higher-Order Cryptography (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type-two constructions abound in cryptography: adversaries for encryption and\nauthentication schemes, if active, are modeled as algorithms having access to\noracles, i.e. as second-order algorithms. But how about making cryptographic\nschemes themselves higher-order? This paper gives an answer to this question,\nby first describing why higher-order cryptography is interesting as an object\nof study, then showing how the concept of probabilistic polynomial time\nalgorithm can be generalized so as to encompass algorithms of order strictly\nhigher than two, and finally proving some positive and negative results about\nthe existence of higher-order cryptographic primitives, namely authentication\nschemes and pseudorandom functions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:25:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Barak", "Boaz", ""], ["Crubill\u00e9", "Rapha\u00eblle", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "2002.07309", "submitter": "Ross Horne", "authors": "Ross Horne and Sjouke Mauw", "title": "Discovering ePassport Vulnerabilities using Bisimilarity", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (June 2,\n  2021) lmcs:7537", "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We uncover privacy vulnerabilities in the ICAO 9303 standard implemented by\nePassports worldwide. These vulnerabilities, confirmed by ICAO, enable an\nePassport holder who recently passed through a checkpoint to be reidentified\nwithout opening their ePassport. This paper explains how bisimilarity was used\nto discover these vulnerabilities, which exploit the BAC protocol - the\noriginal ICAO 9303 standard ePassport authentication protocol - and remains\nvalid for the PACE protocol, which improves on the security of BAC in the\nlatest ICAO 9303 standards. In order to tackle such bisimilarity problems, we\ndevelop here a chain of methods for the applied $\\pi$-calculus including a\nsymbolic under-approximation of bisimilarity, called open bisimilarity, and a\nmodal logic, called classical FM, for describing and certifying attacks.\nEvidence is provided to argue for a new scheme for specifying such\nunlinkability problems that more accurately reflects the capabilities of an\nattacker.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:26:19 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 18:24:05 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 18:31:43 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 10:10:34 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 14:29:57 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Horne", "Ross", ""], ["Mauw", "Sjouke", ""]]}, {"id": "2002.07545", "submitter": "EPTCS", "authors": "B\\'eatrice B\\'erard (Sorbonne Universit\\'e, CNRS, LIP6, Paris,\n  France), Benedikt Bollig (CNRS & LSV, ENS Paris-Saclay, Universit\\'e\n  Paris-Saclay, France), Patricia Bouyer (CNRS & LSV, ENS Paris-Saclay,\n  Universit\\'e Paris-Saclay, France), Matthias F\\\"ugger (CNRS & LSV, ENS\n  Paris-Saclay, Universit\\'e Paris-Saclay, Inria, France), Nathalie Sznajder\n  (Sorbonne Universit\\'e, CNRS, LIP6, Paris, France)", "title": "Synthesis in Presence of Dynamic Links", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 33-49", "doi": "10.4204/EPTCS.326.3", "report-no": null, "categories": "cs.FL cs.DC cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of distributed synthesis is to automatically generate a\ndistributed algorithm, given a target communication network and a specification\nof the algorithm's correct behavior.\n  Previous work has focused on static networks with an a priori fixed message\nsize. This approach has two shortcomings: Recent work in distributed computing\nis shifting towards dynamically changing communication networks rather than\nstatic ones, and an important class of distributed algorithms are so-called\nfull-information protocols, where nodes piggy-pack previously received messages\nonto current messages.\n  In this work, we consider the synthesis problem for a system of two nodes\ncommunicating in rounds over a dynamic link whose message size is not bounded.\nGiven a network model, i.e., a set of link directions, in each round of the\nexecution, the adversary choses a link from the network model, restricted only\nby the specification, and delivers messages according to the current link's\ndirections. Motivated by communication buses with direct acknowledge\nmechanisms, we further assume that nodes are aware of which messages have been\ndelivered.\n  We show that the synthesis problem is decidable for a network model if and\nonly if it does not contain the empty link that dismisses both nodes' messages.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:21:24 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 01:24:22 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["B\u00e9rard", "B\u00e9atrice", "", "Sorbonne Universit\u00e9, CNRS, LIP6, Paris,\n  France"], ["Bollig", "Benedikt", "", "CNRS & LSV, ENS Paris-Saclay, Universit\u00e9\n  Paris-Saclay, France"], ["Bouyer", "Patricia", "", "CNRS & LSV, ENS Paris-Saclay,\n  Universit\u00e9 Paris-Saclay, France"], ["F\u00fcgger", "Matthias", "", "CNRS & LSV, ENS\n  Paris-Saclay, Universit\u00e9 Paris-Saclay, Inria, France"], ["Sznajder", "Nathalie", "", "Sorbonne Universit\u00e9, CNRS, LIP6, Paris, France"]]}, {"id": "2002.07574", "submitter": "Alan Logan", "authors": "Laura Ciobanu, Alan D. Logan", "title": "The Post Correspondence Problem and equalisers for certain free group\n  and monoid morphisms", "comments": "16 pages, final version incorporating referees comments", "journal-ref": "47th International Colloquium on Automata, Languages, and\n  Programming (ICALP 2020), volume 168, pp. 120:1-120:16", "doi": "10.4230/LIPIcs.ICALP.2020.120", "report-no": null, "categories": "math.GR cs.DM cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A marked free monoid morphism is a morphism for which the image of each\ngenerator starts with a different letter, and immersions are the analogous maps\nin free groups. We show that the (simultaneous) PCP is decidable for immersions\nof free groups, and provide an algorithm to compute bases for the sets, called\nequalisers, on which the immersions take the same values. We also answer a\nquestion of Stallings about the rank of the equaliser.\n  Analogous results are proven for marked morphisms of free monoids.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 14:17:21 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 15:22:18 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Ciobanu", "Laura", ""], ["Logan", "Alan D.", ""]]}, {"id": "2002.07654", "submitter": "Sean Tull", "authors": "Sean Tull and Johannes Kleiner", "title": "Integrated Information in Process Theories", "comments": "18 pages, 4 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how the key notions of Tononi et al.'s Integrated Information\nTheory (IIT) can be studied within the simple graphical language of process\ntheories, i.e. symmetric monoidal categories. This allows IIT to be generalised\nto a broad range of physical theories, including as a special case the Quantum\nIIT of Zanardi, Tomka and Venuti.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:44:00 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Tull", "Sean", ""], ["Kleiner", "Johannes", ""]]}, {"id": "2002.07672", "submitter": "Christoph Welzel", "authors": "Marius Bozga, Javier Esparza, Radu Iosif, Joseph Sifakis, Christoph\n  Welzel", "title": "Structural Invariants for the Verification of Systems with Parameterized\n  Architectures", "comments": "preprint; to be published in the proceedings of TACAS20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider parameterized concurrent systems consisting of a finite but\nunknown number of components, obtained by replicating a given set of finite\nstate automata. Components communicate by executing atomic interactions whose\nparticipants update their states simultaneously. We introduce an interaction\nlogic to specify both the type of interactions (e.g.\\ rendez-vous, broadcast)\nand the topology of the system (e.g.\\ pipeline, ring). The logic can be easily\nembedded in monadic second order logic of finitely many successors, and is\ntherefore decidable.\n  Proving safety properties of such a parameterized system, like deadlock\nfreedom or mutual exclusion, requires to infer an inductive invariant that\ncontains all reachable states of all system instances, and no unsafe state. We\npresent a method to automatically synthesize inductive invariants directly from\nthe formula describing the interactions, without costly fixed point iterations.\nWe experimentally prove that this invariant is strong enough to verify safety\nproperties of a large number of systems including textbook examples (dining\nphilosophers, synchronization schemes), classical mutual exclusion algorithms,\ncache-coherence protocols and self-stabilization algorithms, for an arbitrary\nnumber of components.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:00:30 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bozga", "Marius", ""], ["Esparza", "Javier", ""], ["Iosif", "Radu", ""], ["Sifakis", "Joseph", ""], ["Welzel", "Christoph", ""]]}, {"id": "2002.07944", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Beniamino Accattoli and Alejandro D\\'iaz-Caro", "title": "Functional Pearl: The Distributive $\\lambda$-Calculus", "comments": "17 pages. Accepted at FLOPS 2020", "journal-ref": "LNCS 12073:13-32, 2020", "doi": "10.1007/978-3-030-59025-3_3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple extension of the $\\lambda$-calculus with pairs---called\nthe distributive $\\lambda$-calculus---obtained by adding a computational\ninterpretation of the valid distributivity isomorphism $A \\Rightarrow (B\\wedge\nC)\\ \\ \\equiv\\ \\ (A\\Rightarrow B) \\wedge (A\\Rightarrow C)$ of simple types. We\nstudy the calculus both as an untyped and as a simply typed setting. Key\nfeatures of the untyped calculus are confluence, the absence of clashes of\nconstructs, that is, evaluation never gets stuck, and a leftmost-outermost\nnormalization theorem, obtained with straightforward proofs. With respect to\nsimple types, we show that the new rules satisfy subject reduction if types are\nconsidered up to the distributivity isomorphism. The main result is strong\nnormalization for simple types up to distributivity. The proof is a smooth\nvariation over the one for the $\\lambda$-calculus with pairs and simple types.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:58:44 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 12:17:05 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Accattoli", "Beniamino", ""], ["D\u00edaz-Caro", "Alejandro", ""]]}, {"id": "2002.08150", "submitter": "Niels Van der weide", "authors": "Niccol\\`o Veltri and Niels van der Weide", "title": "Constructing Higher Inductive Types as Groupoid Quotients", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 22,\n  2021) lmcs:7391", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study finitary 1-truncated higher inductive types (HITs) in\nhomotopy type theory. We start by showing that all these types can be\nconstructed from the groupoid quotient. We define an internal notion of\nsignatures for HITs, and for each signature, we construct a bicategory of\nalgebras in 1-types and in groupoids. We continue by proving initial algebra\nsemantics for our signatures. After that, we show that the groupoid quotient\ninduces a biadjunction between the bicategories of algebras in 1-types and in\ngroupoids. Then we construct a biinitial object in the bicategory of algebras\nin groupoids, which gives the desired algebra. From all this, we conclude that\nall finitary 1-truncated HITs can be constructed from the groupoid quotient.\n  We present several examples of HITs which are definable using our notion of\nsignature. In particular, we show that each signature gives rise to a HIT\ncorresponding to the freely generated algebraic structure over it. We also\nstart the development of universal algebra in 1-types. We show that the\nbicategory of algebras has PIE limits, i.e. products, inserters and equifiers,\nand we prove a version of the first isomorphism theorem for 1-types. Finally,\nwe give an alternative characterization of the foundamental groups of some\nHITs, exploiting our construction of HITs via the groupoid quotient. All the\nresults are formalized over the UniMath library of univalent mathematics in\nCoq.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:04:32 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:12:10 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 15:30:17 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 15:16:49 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 06:38:07 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Veltri", "Niccol\u00f2", ""], ["van der Weide", "Niels", ""]]}, {"id": "2002.08175", "submitter": "Gabriel Ciobanu", "authors": "Bogdan Aman and Gabriel Ciobanu", "title": "Imprecise Probability for Multiparty Session Types in Process Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce imprecise probability for session types. More\nexactly, we use a probabilistic process calculus in which both nondeterministic\nexternal choice and probabilistic internal choice are considered. We propose\nthe probabilistic multiparty session types able to codify the structure of the\ncommunications by using some imprecise probabilities given in terms of lower\nand upper probabilities. We prove that this new probabilistic typing system is\nsound, as well as several other results dealing with both classical and\nprobabilistic properties. The approach is illustrated by a simple example\ninspired by survey polls.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:33:58 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Aman", "Bogdan", ""], ["Ciobanu", "Gabriel", ""]]}, {"id": "2002.08181", "submitter": "Twan Basten", "authors": "Martijn Hendriks, Marc Geilen, Kees Goossens, Rob de Jong, Twan Basten", "title": "Interface Modeling for Quality and Resource Management", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 26,\n  2021) lmcs:7513", "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop an interface-modeling framework for quality and resource\nmanagement that captures configurable working points of hardware and software\ncomponents in terms of functionality, resource usage and provision, and quality\nindicators such as performance and energy consumption. We base these aspects on\npartially-ordered sets to capture quality levels, budget sizes, and functional\ncompatibility. This makes the framework widely applicable and domain\nindependent (although we aim for embedded and cyber-physical systems). The\nframework paves the way for dynamic (re-)configuration and multi-objective\noptimization of component-based systems for quality- and resource-management\npurposes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:42:21 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 22:05:06 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 14:30:22 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 12:49:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hendriks", "Martijn", ""], ["Geilen", "Marc", ""], ["Goossens", "Kees", ""], ["de Jong", "Rob", ""], ["Basten", "Twan", ""]]}, {"id": "2002.08203", "submitter": "L\\'eo Exibard", "authors": "L\\'eo Exibard, Emmanuel Filiot, Pierre-Alain Reynier", "title": "On Computability of Data Word Functions Defined by Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the problem of synthesizing computable\nfunctions of infinite words over an infinite alphabet (data omega-words). The\nnotion of computability is defined through Turing machines with infinite inputs\nwhich can produce the corresponding infinite outputs in the limit. We use\nnon-deterministic transducers equipped with registers, an extension of register\nautomata with outputs, to specify functions. Such transducers may not define\nfunctions but more generally relations of data omega-words, and we show that it\nis PSpace-complete to test whether a given transducer defines a function. Then,\ngiven a function defined by some register transducer, we show that it is\ndecidable (and again, PSpace-complete) whether such function is computable. As\nfor the known finite alphabet case, we show that computability and continuity\ncoincide for functions defined by register transducers, and show how to decide\ncontinuity. We also define a subclass for which those problems are solvable in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:17:24 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Exibard", "L\u00e9o", ""], ["Filiot", "Emmanuel", ""], ["Reynier", "Pierre-Alain", ""]]}, {"id": "2002.08241", "submitter": "Pui Yiu Carol Mak", "authors": "Carol Mak, Luke Ong", "title": "A Differential-form Pullback Programming Language for Higher-order\n  Reverse-mode Automatic Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Building on the observation that reverse-mode automatic differentiation (AD)\n-- a generalisation of backpropagation -- can naturally be expressed as\npullbacks of differential 1-forms, we design a simple higher-order programming\nlanguage with a first-class differential operator, and present a reduction\nstrategy which exactly simulates reverse-mode AD. We justify our reduction\nstrategy by interpreting our language in any differential $\\lambda$-category\nthat satisfies the Hahn-Banach Separation Theorem, and show that the reduction\nstrategy precisely captures reverse-mode AD in a truly higher-order setting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:38:03 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mak", "Carol", ""], ["Ong", "Luke", ""]]}, {"id": "2002.08392", "submitter": "Giulio Guerrieri", "authors": "Ugo Dal Lago (1) and Giulio Guerrieri (2) and Willem Heijltjes (2)\n  ((1) Dipartimento di Informatica - Scienza e Ingegneria, Universit\\`a di\n  Bologna, Bologna, Italy and (2) Department of Computer Science University of\n  Bath, Bath, UK)", "title": "Decomposing Probabilistic Lambda-calculi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notion of probabilistic lambda-calculus usually comes with a prescribed\nreduction strategy, typically call-by-name or call-by-value, as the calculus is\nnon-confluent and these strategies yield different results. This is a break\nwith one of the main advantages of lambda-calculus: confluence, which means\nresults are independent from the choice of strategy. We present a probabilistic\nlambda-calculus where the probabilistic operator is decomposed into two\nsyntactic constructs: a generator, which represents a probabilistic event; and\na consumer, which acts on the term depending on a given event. The resulting\ncalculus, the Probabilistic Event Lambda-Calculus, is confluent, and interprets\nthe call-by-name and call-by-value strategies through different interpretations\nof the probabilistic operator into our generator and consumer constructs. We\npresent two notions of reduction, one via fine-grained local rewrite steps, and\none by generation and consumption of probabilistic events. Simple types for the\ncalculus are essentially standard, and they convey strong normalization. We\ndemonstrate how we can encode call-by-name and call-by-value probabilistic\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:09:49 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Guerrieri", "Giulio", ""], ["Heijltjes", "Willem", ""]]}, {"id": "2002.08523", "submitter": "Brandon Bohrer", "authors": "Brandon Bohrer, Andr\\'e Platzer", "title": "Constructive Game Logic", "comments": "74 pages, extended preprint for ESOP", "journal-ref": null, "doi": "10.1007/978-3-030-44914-8_4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game Logic is an excellent setting to study proofs-about-programs via the\ninterpretation of those proofs as programs, because constructive proofs for\ngames correspond to effective winning strategies to follow in response to the\nopponent's actions. We thus develop Constructive Game Logic which extends\nParikh's Game Logic (GL) with constructivity and with first-order programs a la\nPratt's first-order dynamic logic (DL). Our major contributions include:\n  1) a novel realizability semantics capturing the adversarial dynamics of\ngames, 2) a natural deduction calculus and operational semantics describing the\ncomputational meaning of strategies via proof-terms, and 3) theoretical results\nincluding soundness of the proof calculus w.r.t. realizability semantics,\nprogress and preservation of the operational semantics of proofs, and Existence\nProperties on support of the extraction of computational artifacts from game\nproofs.\n  Together, these results provide the most general account of a Curry-Howard\ninterpretation for any program logic to date, and the first at all for Game\nLogic.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:44:24 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 12:44:05 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bohrer", "Brandon", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2002.08646", "submitter": "Christian Herrera", "authors": "Christian Herrera", "title": "From Stateless to Stateful Priorities: Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the notion of stateful priorities for imposing precise\nrestrictions on system actions, in order to meet safety constraints. By using\nstateful priorities we are able to exclusively restrict erroneous system\nbehavior as specified by the constraint, whereas safe system behavior remains\nunrestricted. Given a system modeled as a network of discrete automata and an\nerror constraint, we present algorithms which use those inputs to synthesize\nstateful priorities. We present as well a network transformation which uses\nsynthesized priorities for blocking all system actions leading to the input\nerror. Our experiments with three real-world examples demonstrate the\napplicability of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:03:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Herrera", "Christian", ""]]}, {"id": "2002.08863", "submitter": "Hans van Ditmarsch", "authors": "Hans van Ditmarsch, Eric Goubault, Jeremy Ledent, Sergio Rajsbaum", "title": "Knowledge and simplicial complexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplicial complexes are a versatile and convenient paradigm on which to\nbuild all the tools and techniques of the logic of knowledge, on the assumption\nthat initial epistemic models can be described in a distributed fashion. Thus,\nwe can define: knowledge, belief, bisimulation, the group notions of mutual,\ndistributed and common knowledge, and also dynamics in the shape of simplicial\naction models. We give a survey on how to interpret all such notions on\nsimplicial complexes, building upon the foundations laid in prior work by\nGoubault and others.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:03:19 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["van Ditmarsch", "Hans", ""], ["Goubault", "Eric", ""], ["Ledent", "Jeremy", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "2002.08874", "submitter": "Robin Piedeleu", "authors": "Filippo Bonchi, Robin Piedeleu, Pawel Sobocinski, Fabio Zanasi", "title": "Contextual Equivalence for Signal Flow Graphs", "comments": "Accepted for publication in the proceedings of the 23rd International\n  Conference on Foundations of Software Science and Computation Structures\n  (FoSSaCS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the signal flow calculus---a compositional account of the classical\nsignal flow graph model of computation---to encompass affine behaviour, and\nfurnish it with a novel operational semantics. The increased expressive power\nallows us to define a canonical notion of contextual equivalence, which we show\nto coincide with denotational equality. Finally, we characterise the realisable\nfragment of the calculus: those terms that express the computations of (affine)\nsignal flow graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:20:14 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Bonchi", "Filippo", ""], ["Piedeleu", "Robin", ""], ["Sobocinski", "Pawel", ""], ["Zanasi", "Fabio", ""]]}, {"id": "2002.08955", "submitter": "Vasudha Varadarajan", "authors": "Radu Grosu, Anna Lukina, Scott A. Smolka, Ashish Tiwari, Vasudha\n  Varadarajan and Xingfang Wang", "title": "V-Formation via Model Predictive Control", "comments": "arXiv admin note: text overlap with arXiv:1612.07059,\n  arXiv:1805.07929, arXiv:1702.00290", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present recent results that demonstrate the power of viewing the problem\nof V-formation in a flock of birds as one of Model Predictive Control (MPC).\nThe V-formation-MPC marriage can be understood in terms of the problem of\nsynthesizing an optimal plan for a continuous-space and continuous-time Markov\ndecision process (MDP), where the goal is to reach a target state that\nminimizes a given cost function. First, we consider ARES, an approximation\nalgorithm for generating optimal plans (action sequences) that take an initial\nstate of an MDP to a state whose cost is below a specified (convergence)\nthreshold. ARES uses Particle Swarm Optimization, with adaptive sizing for both\nthe receding horizon and the particle swarm. Inspired by Importance Splitting,\nthe length of the horizon and the number of particles are chosen such that at\nleast one particle reaches a next-level state. ARES can alternatively be viewed\nas a model-predictive control (MPC) algorithm that utilizes an adaptive\nreceding horizon, aka Adaptive MPC (AMPC). We next present Distributed AMPC\n(DAMPC), a distributed version of AMPC that works with local neighborhoods. We\nintroduce adaptive neighborhood resizing, whereby the neighborhood size is\ndetermined by the cost-based Lyapunov function evaluated over a global system\nstate. Our experiments show that DAMPC can perform almost as well as\ncentralized AMPC, while using only local information and a form of distributed\nconsensus in each time step. Finally, inspired by security attacks on\ncyber-physical systems, we introduce controller-attacker games (CAG), where two\nplayers, a controller and an attacker, have antagonistic objectives. We\nformulate a special case of CAG called V-formation games, where the attacker's\ngoal is to prevent the controller from attaining V-formation. We demonstrate\nhow adaptation in the design of the controller helps in overcoming certain\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:00:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Grosu", "Radu", ""], ["Lukina", "Anna", ""], ["Smolka", "Scott A.", ""], ["Tiwari", "Ashish", ""], ["Varadarajan", "Vasudha", ""], ["Wang", "Xingfang", ""]]}, {"id": "2002.09033", "submitter": "Wen Chean Teh", "authors": "Wen Chean Teh and Adrian Atanasiu", "title": "Simulation Of Reaction Systems By The Strictly Minimal Ones", "comments": "11 pages, submitted for a special issue consideration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reaction systems, introduced by Ehrenfeucht and Rozenberg, are elementary\ncomputational models based on biochemical reactions transpiring within the\nliving cells. Numerous studies focus on mathematical aspects of minimal\nreaction systems due to their simplicity and rich generative power. In 2014\nManzoni, Pocas, and Porreca showed that every reaction system can be simulated\nby some minimal reaction system over an extended background set. Motivated by\ntheir work, we introduce the concepts of strictly minimal and hybrid reaction\nsystems. Using our new concepts, the result of Manzoni et al. is revisited and\nstrengthened. We also show that extension of the background set by polynomially\nbounded many elements is not sufficient to guarantee the aforementioned\nsimulation. Finally, an analogous result for strong simulation is obtained.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 07:26:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Teh", "Wen Chean", ""], ["Atanasiu", "Adrian", ""]]}, {"id": "2002.09282", "submitter": "Joshua Chen", "authors": "Joshua Chen", "title": "Homotopy Type Theory in Isabelle", "comments": "Thoroughly revised version; accepted for publication at the 12th\n  International Conference on Interactive Theorem Proving (ITP 2021). 8 pages,\n  1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces Isabelle/HoTT, the first development of homotopy type\ntheory in the Isabelle proof assistant. Building on earlier work by Paulson, I\nuse Isabelle's existing logical framework infrastructure to implement essential\nautomation, such as type checking and term elaboration, that is usually handled\non the source code level of dependently typed systems. I also integrate the\npropositions-as-types paradigm with the declarative Isar proof language,\nproviding an alternative to the tactic-based proofs of Coq and the proof terms\nof Agda. The infrastructure developed is then used to formalize foundational\nresults from the Homotopy Type Theory book.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:47:18 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 14:51:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chen", "Joshua", ""]]}, {"id": "2002.09387", "submitter": "Alexandre Cl\\'ement", "authors": "Alexandre Cl\\'ement and Simon Perdrix", "title": "PBS-Calculus: A Graphical Language for Coherent Control of Quantum\n  Computations", "comments": "55 pages. This is the full version of a paper published at MFCS'20", "journal-ref": null, "doi": "10.4230/LIPIcs.MFCS.2020.24", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the PBS-calculus to represent and reason on quantum computations\ninvolving coherent control of quantum operations. Coherent control, and in\nparticular indefinite causal order, is known to enable multiple computational\nand communication advantages over classically ordered models like quantum\ncircuits. The PBS-calculus is inspired by quantum optics, in particular the\npolarising beam splitter (PBS for short). We formalise the syntax and the\nsemantics of the PBS-diagrams, and we equip the language with an equational\ntheory, which is proved to be sound and complete: two diagrams are representing\nthe same quantum evolution if and only if one can be transformed into the other\nusing the rules of the PBS-calculus. Moreover, we show that the equational\ntheory is minimal. Finally, we consider applications like the implementation of\ncontrolled permutations and the unrolling of loops.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:15:58 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 18:16:43 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Cl\u00e9ment", "Alexandre", ""], ["Perdrix", "Simon", ""]]}, {"id": "2002.09393", "submitter": "Georg Zetzsche", "authors": "Miko{\\l}aj Boja\\'nczyk, Edon Kelmendi, Rafa{\\l} Stefa\\'nski, and Georg\n  Zetzsche", "title": "Extensions of $\\omega$-Regular Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider extensions of monadic second order logic over $\\omega$-words,\nwhich are obtained by adding one language that is not $\\omega$-regular. We show\nthat if the added language $L$ has a neutral letter, then the resulting logic\nis necessarily undecidable. A corollary is that the $\\omega$-regular languages\nare the only decidable Boolean-closed full trio over $\\omega$-words.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:22:24 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Kelmendi", "Edon", ""], ["Stefa\u0144ski", "Rafa\u0142", ""], ["Zetzsche", "Georg", ""]]}, {"id": "2002.09682", "submitter": "Tobias Kapp\\'e", "authors": "Tobias Kapp\\'e and Paul Brunet and Alexandra Silva and Jana Wagemaker\n  and Fabio Zanasi", "title": "Concurrent Kleene Algebra with Observations: from Hypotheses to\n  Completeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concurrent Kleene Algebra (CKA) extends basic Kleene algebra with a parallel\ncomposition operator, which enables reasoning about concurrent programs.\nHowever, CKA fundamentally misses tests, which are needed to model standard\nprogramming constructs such as conditionals and $\\mathsf{while}$-loops. It\nturns out that integrating tests in CKA is subtle, due to their interaction\nwith parallelism. In this paper we provide a solution in the form of Concurrent\nKleene Algebra with Observations (CKAO). Our main contribution is a\ncompleteness theorem for CKAO. Our result resorts on a more general study of\nCKA \"with hypotheses\", of which CKAO turns out to be an instance: this analysis\nis of independent interest, as it can be applied to extensions of CKA other\nthan CKAO.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:51:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kapp\u00e9", "Tobias", ""], ["Brunet", "Paul", ""], ["Silva", "Alexandra", ""], ["Wagemaker", "Jana", ""], ["Zanasi", "Fabio", ""]]}, {"id": "2002.09784", "submitter": "Alessandro Gianola", "authors": "Silvio Ghilardi and Alessandro Gianola and Deepak Kapur", "title": "Uniform Interpolants in EUF: Algorithms using DAG-representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of a uniform interpolant for a quantifier-free formula from a\ngiven formula with a list of symbols, while well-known in the logic literature,\nhas been unknown to the formal methods and automated reasoning community. This\nconcept is precisely defined. Two algorithms for computing quantifier-free\nuniform interpolants of the theory of equality over uninterpreted symbols (EUF)\nendowed with a list of symbols to be eliminated are proposed. The first\nalgorithm is non-deterministic and generates a uniform interpolant expressed as\na disjunction of conjunctions of literals, whereas the second algorithm gives a\ncompact representation of a uniform interpolant as a conjunction of Horn\nclauses. Both algorithms exploit efficient dedicated DAG representations of\nterms. Correctness and completeness proofs are supplied, using arguments\ncombining rewrite techniques with model theory.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:54:22 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 02:27:25 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ghilardi", "Silvio", ""], ["Gianola", "Alessandro", ""], ["Kapur", "Deepak", ""]]}, {"id": "2002.09827", "submitter": "Ron van der Meyden", "authors": "Ron van der Meyden", "title": "A Formal Treatment of Contract Signature", "comments": "28 pages. This is a significantly revised and retitled version of an\n  earlier paper \"Signature in Counterparts, a Formal Treatment\". Revisions\n  include changes to the semantics, addition of a treatment of offer and\n  acceptance, added proof material and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops a logical understanding of processes for signature of\nlegal contracts, motivated by applications to legal recognition of smart\ncontracts on blockchain platforms. A number of axioms and rules of inference\nare developed that can be used to justify a \"meeting of the minds\" precondition\nfor contract formation from the fact that certain content has been signed. In\naddition to an \"offer and acceptance\" process, the paper considers \"signature\nin counterparts\", a legal process that permits a contract between two or more\nparties to be brought into force by having the parties independently (possibly,\nremotely) sign different copies of the contract, rather than placing their\nsignatures on a common copy at a physical meeting. It is argued that a\nsatisfactory account of signature in counterparts benefits from a logic with\nsyntactic self-reference. The axioms used are supported by a formal semantics,\nand a number of further properties of the logic are investigated. In\nparticular, it is shown that the logic implies that when a contract has been\nsigned, the parties do not just agree, but are in mutual agreement (a\ncommon-knowledge-like notion) about the terms of the contract.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 04:39:56 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 08:48:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["van der Meyden", "Ron", ""]]}, {"id": "2002.09941", "submitter": "Soumyajit Paul", "authors": "Hugo Gimbert, Soumyajit Paul and B. Srivathsan", "title": "A Bridge between Polynomial Optimization and Games with Imperfect Recall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide several positive and negative complexity results for solving games\nwith imperfect recall. Using a one-to-one correspondence between these games on\none side and multivariate polynomials on the other side, we show that solving\ngames with imperfect recall is as hard as solving certain problems of the first\norder theory of reals. We establish square root sum hardness even for the\nspecific class of A-loss games. On the positive side, we find restrictions on\ngames and strategies motivated by Bridge bidding that give polynomial-time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:06:46 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 09:35:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Gimbert", "Hugo", ""], ["Paul", "Soumyajit", ""], ["Srivathsan", "B.", ""]]}, {"id": "2002.09942", "submitter": "Olivier Serre", "authors": "Arnaud Carayol and Olivier Serre", "title": "How Good Is a Strategy in a Game With Nature?", "comments": null, "journal-ref": "ACM Transactions on Computational Logic, Vol. 21, No 3, Article\n  21, pp. 1-39, February 2020", "doi": "10.1145/3377137", "report-no": null, "categories": "cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider games with two antagonistic players --- \\'Elo\\\"ise (modelling a\nprogram) and Ab\\'elard (modelling a byzantine environment) --- and a third,\nunpredictable and uncontrollable player, that we call Nature. Motivated by the\nfact that the usual probabilistic semantics very quickly leads to\nundecidability when considering either infinite game graphs or\nimperfect-information, we propose two alternative semantics that leads to\ndecidability where the probabilistic one fails: one based on counting and one\nbased on topology.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:18:16 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Carayol", "Arnaud", ""], ["Serre", "Olivier", ""]]}, {"id": "2002.10212", "submitter": "Arve Gengelbach", "authors": "Johannes {\\AA}man Pohjola, Arve Gengelbach", "title": "A Mechanised Semantics for HOL with Ad-hoc Overloading", "comments": "19 pages, accepted at LPAR 2020", "journal-ref": null, "doi": "10.29007/413d", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isabelle/HOL augments classical higher-order logic with ad-hoc overloading of\nconstant definitions---that is, one constant may have several definitions for\nnon-overlapping types. In this paper, we present a mechanised proof that HOL\nwith ad-hoc overloading is consistent. All our results have been formalised in\nthe HOL4 theorem prover.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:57:42 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 07:14:50 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Pohjola", "Johannes \u00c5man", ""], ["Gengelbach", "Arve", ""]]}, {"id": "2002.10259", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Complex Markov Logic Networks: Expressivity and Liftability", "comments": "Fixed typos in Lemma 1 and Section 7. Paper accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study expressivity of Markov logic networks (MLNs). We introduce complex\nMLNs, which use complex-valued weights, and we show that, unlike standard MLNs\nwith real-valued weights, complex MLNs are fully expressive. We then observe\nthat discrete Fourier transform can be computed using weighted first order\nmodel counting (WFOMC) with complex weights and use this observation to design\nan algorithm for computing relational marginal polytopes which needs\nsubstantially less calls to a WFOMC oracle than a recent algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:50:59 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 13:04:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2002.10712", "submitter": "Takayuki Kihara", "authors": "Takayuki Kihara", "title": "Degrees of incomputability, realizability and constructive reverse\n  mathematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a way of assigning a realizability notion to each degree of\nincomputability. In our setting, we make use of Weihrauch degrees (degrees of\nincomputability/discontinuity of partial multi-valued functions) to obtain\nLifschitz-like relative realizability predicates. In this note, we present\nsample examples on how to lift some separation results on Weihrauch degrees to\nthose over intuitionistic Zermelo-Fraenkel set theory ${\\bf IZF}$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:55:08 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Kihara", "Takayuki", ""]]}, {"id": "2002.10803", "submitter": "Luigi Liquori", "authors": "Luigi Liquori and Claude Stolze", "title": "A Type Checker for a Logical Framework with Union and Intersection Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the syntax, semantics, and typing rules of Bull, a prototype\ntheorem prover based on the Delta-Framework, i.e. a fully-typed lambda-calculus\ndecorated with union and intersection types, as described in previous papers by\nthe authors. Bull also implements a subtyping algorithm for the Type Theory Xi\nof Barbanera-Dezani-de'Liguoro. Bull has a command-line interface where the\nuser can declare axioms, terms, and perform computations and some basic\nterminal-style features like error pretty-printing, subexpressions\nhighlighting, and file loading. Moreover, it can typecheck a proof or normalize\nit. These terms can be incomplete, therefore the typechecking algorithm uses\nunification to try to construct the missing subterms. Bull uses the syntax of\nBerardi's Pure Type Systems to improve the compactness and the modularity of\nthe kernel. Abstract and concrete syntax are mostly aligned and similar to the\nconcrete syntax of Coq. Bull uses a higher-order unification algorithm for\nterms, while typechecking and partial type inference are done by a\nbidirectional refinement algorithm, similar to the one found in Matita and\nBeluga. The refinement can be split into two parts: the essence refinement and\nthe typing refinement. Binders are implemented using commonly-used de Bruijn\nindices. We have defined a concrete language syntax that will allow the user to\nwrite Delta-terms. We have defined the reduction rules and an evaluator. We\nhave implemented from scratch a refiner which does partial typechecking and\ntype reconstruction. We have experimented Bull with classical examples of the\nintersection and union literature, such as the ones formalized by Pfenning with\nhis Refinement Types in LF. We hope that this research vein could be useful to\nexperiment, in a proof theoretical setting, forms of polymorphism alternatives\nto Girard's parametric one.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:46:26 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Liquori", "Luigi", ""], ["Stolze", "Claude", ""]]}, {"id": "2002.10814", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Failure Trace Semantics for a Process Algebra with Time-outs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 23,\n  2021) lmcs:7398", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper extends a standard process algebra with a time-out operator,\nthereby increasing its absolute expressiveness, while remaining within the\nrealm of untimed process algebra, in the sense that the progress of time is not\nquantified. Trace and failures equivalence fail to be congruences for this\noperator; their congruence closure is characterised as failure trace\nequivalence.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:03:58 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:25:11 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 07:47:15 GMT"}, {"version": "v4", "created": "Sat, 17 Apr 2021 06:33:47 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 06:33:02 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "2002.10888", "submitter": "Thomas Seiller", "authors": "Luc Pellissier (LACL), Thomas Seiller (CNRS, LIPN)", "title": "Lower bounds for algebraic machines, semantically", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.06787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new semantic method for proving lower bounds in\ncomputational complexity. We use it to prove that maxflow, a PTIME complete\nproblem, is not computable in polylogarithmic time on parallel random access\nmachines (PRAMs) working with integers, showing that NCZ \\neq PTIME, where NCZ\nis the complexity class defined by such machines, and PTIME is the standard\nclass of polynomial time computable problems (on, say, a Turing machine). On\ntop of showing this new separation result, we show our method captures previous\nlower bounds results from the literature: Steele and Yao's lower bounds for\nalgebraic decision trees, Ben-Or's lower bounds for algebraic computation\ntrees, Cucker's proof that NC is not equal to PTIME on the reals, and\nMulmuley's lower bounds for \"PRAMs without bit operations\".\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:48:00 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 08:21:20 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Pellissier", "Luc", "", "LACL"], ["Seiller", "Thomas", "", "CNRS, LIPN"]]}, {"id": "2002.10892", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "Facets of the PIE Environment for Proving, Interpolating and Eliminating\n  on the Basis of First-Order Logic", "comments": "To appear in DECLARE 2019 Revised Selected Papers. arXiv admin note:\n  substantial text overlap with arXiv:1908.11137", "journal-ref": null, "doi": "10.1007/978-3-030-46714-2_11", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PIE is a Prolog-embedded environment for automated reasoning on the basis of\nfirst-order logic. Its main focus is on formulas, as constituents of complex\nformalizations that are structured through formula macros, and as outputs of\nreasoning tasks such as second-order quantifier elimination and Craig\ninterpolation. It supports a workflow based on documents that intersperse macro\ndefinitions, invocations of reasoners, and LaTeX-formatted natural language\ntext. Starting from various examples, the paper discusses features and\napplication possibilities of PIE along with current limitations and issues for\nfuture research.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:09:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "2002.10973", "submitter": "Paulina Paraponiari", "authors": "Vagia Karyoti and Paulina Paraponiari", "title": "Weighted PCL over product valuation monoids", "comments": "22 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1704.04969", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a weighted propositional configuration logic over a product\nvaluation monoid. Our logic is intended to serve as a specification language\nfor software architectures with quantitative features such as the average of\nall interactions' costs of the architecture and the maximum cost among all\ncosts occurring most frequently within a specific number of components in an\narchitecture. We provide formulas of our logic which describe well-known\narchitectures equipped with quantitative characteristics. Moreover, we prove an\nefficient construction of a full normal form which leads to decidability of\nequivalence of formulas in this logic.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:36:18 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 18:06:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Karyoti", "Vagia", ""], ["Paraponiari", "Paulina", ""]]}, {"id": "2002.11459", "submitter": "Christina Mika-Michalski", "authors": "Barbara K\\\"onig, Christina Mika-Michalski, Lutz Schr\\\"oder", "title": "Explaining Non-Bisimilarity in a Coalgebraic Approach: Games and\n  Distinguishing Formulas", "comments": "Long version of CMCS 2020 paper", "journal-ref": null, "doi": "10.1007/978-3-030-57201-3_8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioural equivalences can be characterized via bisimulation, modal logics,\nand spoiler-duplicator games. In this paper we work in the general setting of\ncoalgebra and focus on generic algorithms for computing the winning strategies\nof both players in a bisimulation game. The winning strategy of the spoiler (if\nit exists) is then transformed into a modal formula that distinguishes the\ngiven non-bisimilar states. The modalities required for the formula are also\nsynthesized on-the-fly, and we present a recipe for re-coding the formula with\ndifferent modalities, given by a separating set of predicate liftings. Both the\ngame and the generation of the distinguishing formulas have been implemented in\na tool called T-BEG.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:25:25 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 07:23:56 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 08:33:33 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["K\u00f6nig", "Barbara", ""], ["Mika-Michalski", "Christina", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "2002.11510", "submitter": "Amar Isli", "authors": "Amar Isli", "title": "Buchi automata augmented with spatial constraints: simulating an\n  alternating with a nondeterministic and deciding the emptiness problem for\n  the latter", "comments": "See footnote 1 on the first page of the paper. arXiv admin note:\n  substantial text overlap with arXiv:cs/0307040", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to thoroughly investigate Buchi automata augmented\nwith spatial constraints. The input trees of such an automaton are infinite\nk-ary Sigma-trees, with the nodes standing for time points, and Sigma\nincluding, additionally to its uses in classical k-ary Sigma-trees, the\ndescription of the snapshot of an n-object spatial scene of interest. The\nconstraints, from an RCC8-like spatial Relation Algebra (RA) x, are used to\nimpose spatial constraints on objects of the spatial scene, eventually at\ndifferent nodes of the input trees. We show that a Buchi alternating automaton\naugmented with spatial constraints can be simulated with a classical Buchi\nnondeterministic automaton of the same type, augmented with spatial\nconstraints. We then provide a nondeterministic doubly depth-first polynomial\nspace algorithm for the emptiness problem of the latter automaton. Our main\nmotivation came from another work, also submitted to this conference, which\ndefines a spatio-temporalisation of the well-known family ALC(D) of description\nlogics with a concrete domain: together, the two works provide an effective\nsolution to the satisfiability problem of a concept of the\nspatio-temporalisation with respect to a weakly cyclic TBox.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 16:25:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Isli", "Amar", ""]]}, {"id": "2002.11519", "submitter": "Alberto Gandolfi", "authors": "Alberto Gandolfi", "title": "Decidability of Sample Complexity of PAC Learning in finite setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we observe that the sample complexity of PAC machine\nlearning of various concepts, including learning the maximum (EMX), can be\nexactly determined when the support of the probability measures considered as\nmodels satisfies an a-priori bound. This result contrasts with the recently\ndiscovered undecidability of EMX within ZFC for finitely supported\nprobabilities (with no a priori bound). Unfortunately, the decision procedure\nis at present, at least doubly exponential in the number of points times the\nuniform bound on the support size.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:27:36 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Gandolfi", "Alberto", ""]]}, {"id": "2002.11776", "submitter": "Tom Hanika", "authors": "Tom Hanika and Johannes Hirth", "title": "Knowledge Cores in Large Formal Contexts", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge computation tasks are often infeasible for large data sets. This is\nin particular true when deriving knowledge bases in formal concept analysis\n(FCA). Hence, it is essential to come up with techniques to cope with this\nproblem. Many successful methods are based on random processes to reduce the\nsize of the investigated data set. This, however, makes them hardly\ninterpretable with respect to the discovered knowledge. Other approaches\nrestrict themselves to highly supported subsets and omit rare and interesting\npatterns. An essentially different approach is used in network science, called\n$k$-cores. These are able to reflect rare patterns if they are well connected\nin the data set. In this work, we study $k$-cores in the realm of FCA by\nexploiting the natural correspondence to bi-partite graphs. This structurally\nmotivated approach leads to a comprehensible extraction of knowledge cores from\nlarge formal contexts data sets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 20:15:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Hanika", "Tom", ""], ["Hirth", "Johannes", ""]]}, {"id": "2002.11895", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra, Portugal), Walther Neuper (Graz\n  University of Technology, Austria), Jo\\~ao Marcos (UFRN, Brazil)", "title": "Proceedings 8th International Workshop on Theorem Proving Components for\n  Educational Software", "comments": null, "journal-ref": "EPTCS 313, 2020", "doi": "10.4204/EPTCS.313", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This EPTCS volume contains the proceedings of the ThEdu'19 workshop, promoted\non August 25, 2019, as a satellite event of CADE-27, in Natal, Brazil.\nRepresenting the eighth installment of the ThEdu series, ThEdu'19 was a vibrant\nworkshop, with an invited talk by Sarah Winkler, four contributions, and the\nfirst edition of a Geometry Automated Provers Competition. After the workshop\nan open call for papers was issued and attracted seven submissions, six of\nwhich have been accepted by the reviewers, and collected in the present\npost-proceedings volume.\n  The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favoring software support for this transition by\nexploiting the power of theorem-proving technologies.\n  The volume editors hope that this collection of papers will further promote\nthe development of theorem-proving-based software, and that it will collaborate\non improving mutual understanding between computer mathematicians and\nstakeholders in education.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:10:08 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra, Portugal"], ["Neuper", "Walther", "", "Graz\n  University of Technology, Austria"], ["Marcos", "Jo\u00e3o", "", "UFRN, Brazil"]]}, {"id": "2002.11942", "submitter": "Mirai Ikebuchi", "authors": "Mirai Ikebuchi", "title": "A Lower Bound of the Number of Rewrite Rules Obtained by Homological\n  Methods", "comments": "25 pages, submitted to Logical Methods in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.AC math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well-known that some equational theories such as groups or boolean\nalgebras can be defined by fewer equational axioms than the original axioms.\nHowever, it is not easy to determine if a given set of axioms is the smallest\nor not. Malbos and Mimram investigated a general method to find a lower bound\nof the cardinality of the set of equational axioms (or rewrite rules) that is\nequivalent to a given equational theory (or term rewriting systems), using\nhomological algebra. Their method is an analog of Squier's homology theory on\nstring rewriting systems. In this paper, we develop the homology theory for\nterm rewriting systems more and provide a better lower bound under a stronger\nnotion of equivalence than their equivalence. The author also implemented a\nprogram to compute the lower bounds, and experimented with 64 complete TRSs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:51:19 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 00:49:50 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ikebuchi", "Mirai", ""]]}, {"id": "2002.12156", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Cautious Reinforcement Learning with Logical Constraints", "comments": "Accepted to AAMAS 2020. arXiv admin note: text overlap with\n  arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the concept of an adaptive safe padding that forces\nReinforcement Learning (RL) to synthesise optimal control policies while\nensuring safety during the learning process. Policies are synthesised to\nsatisfy a goal, expressed as a temporal logic formula, with maximal\nprobability. Enforcing the RL agent to stay safe during learning might limit\nthe exploration, however we show that the proposed architecture is able to\nautomatically handle the trade-off between efficient progress in exploration\n(towards goal satisfaction) and ensuring safety. Theoretical guarantees are\navailable on the optimality of the synthesised policies and on the convergence\nof the learning algorithm. Experimental results are provided to showcase the\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:01:08 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:26:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "2002.12267", "submitter": "Rui Eduardo Brasileiro Paiva", "authors": "Rui Paiva, Benjam\\'in Bedregal, Regivan Santiago", "title": "Residuated implications derived from quasi-overlap functions on lattices", "comments": "27 pages, paper submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the concept of residuated implications derived\nfrom quasi-overlap functions on lattices and prove some related properties. In\naddition, we formalized the residuation principle for the case of quasi-overlap\nfunctions on lattices and their respective induced implications, as well as\nrevealing that the class of quasi-overlap functions that fulfill the\nresiduation principle is the same class of continuous functions according to\ntopology of Scott. Also, Scott's continuity and the notion of densely ordered\nposets are used to generalize a classification theorem for residuated\nquasi-overlap functions. Finally, the concept of automorphisms are extended to\nthe context of quasi-overlap functions over lattices, taking these lattices\ninto account as topological spaces, with a view to obtaining quasi-overlap\nfunctions conjugated by the action of automorphisms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:12:28 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Paiva", "Rui", ""], ["Bedregal", "Benjam\u00edn", ""], ["Santiago", "Regivan", ""]]}, {"id": "2002.12551", "submitter": "EPTCS", "authors": "Ludovic Font (\\'Ecole Polytechnique de Montr\\'eal), S\\'ebastien Cyr\n  (Universit\\'e de Montr\\'eal), Philippe R. Richard (Universit\\'e de\n  Montr\\'eal), Michel Gagnon (\\'Ecole Polytechnique de Montr\\'eal)", "title": "Automating the Generation of High School Geometry Proofs using Prolog in\n  an Educational Context", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 1-16", "doi": "10.4204/EPTCS.313.1", "report-no": null, "categories": "cs.AI cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working on intelligent tutor systems designed for mathematics education\nand its specificities, an interesting objective is to provide relevant help to\nthe students by anticipating their next steps. This can only be done by\nknowing, beforehand, the possible ways to solve a problem. Hence the need for\nan automated theorem prover that provide proofs as they would be written by a\nstudent. To achieve this objective, logic programming is a natural tool due to\nthe similarity of its reasoning with a mathematical proof by inference. In this\npaper, we present the core ideas we used to implement such a prover, from its\nencoding in Prolog to the generation of the complete set of proofs. However,\nwhen dealing with educational aspects, there are many challenges to overcome.\nWe also present the main issues we encountered, as well as the chosen\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:23:16 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Font", "Ludovic", "", "\u00c9cole Polytechnique de Montr\u00e9al"], ["Cyr", "S\u00e9bastien", "", "Universit\u00e9 de Montr\u00e9al"], ["Richard", "Philippe R.", "", "Universit\u00e9 de\n  Montr\u00e9al"], ["Gagnon", "Michel", "", "\u00c9cole Polytechnique de Montr\u00e9al"]]}, {"id": "2002.12552", "submitter": "EPTCS", "authors": "Josje Lodder (Open University of the Netherlands), Bastiaan Heeren\n  (Open University of the Netherlands), Johan Jeuring (Universiteit Utrecht,\n  The Netherlands)", "title": "Providing Hints, Next Steps and Feedback in a Tutoring System for\n  Structural Induction", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 17-34", "doi": "10.4204/EPTCS.313.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural induction is a proof technique that is widely used to prove\nstatements about discrete structures. Students find it hard to construct\ninductive proofs, and when learning to construct such proofs, receiving\nfeedback is important. In this paper we discuss the design of a tutoring\nsystem, LogInd, that helps students with constructing stepwise inductive proofs\nby providing hints, next steps and feedback. As far as we know, this is the\nfirst tutoring system for structural induction with this functionality. We\nexplain how we use a strategy to construct proofs for a restricted class of\nproblems. This strategy can also be used to complete partial student solutions,\nand hence to provide hints or next steps. We use constraints to provide\nfeedback. A pilot evaluation with a small group of students shows that LogInd\nindeed can give hints and next steps in almost all cases.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:23:28 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lodder", "Josje", "", "Open University of the Netherlands"], ["Heeren", "Bastiaan", "", "Open University of the Netherlands"], ["Jeuring", "Johan", "", "Universiteit Utrecht,\n  The Netherlands"]]}, {"id": "2002.12553", "submitter": "EPTCS", "authors": "David M. Cerna (Research Institute For Symbolic Computation), Rafael\n  P.D. Kiesel (Knowlege Based Systems, Technical University of Vienna),\n  Alexandra Dzhiganskaya (University of Applied Arts Vienna)", "title": "A Mobile Application for Self-Guided Study of Formal Reasoning", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 35-53", "doi": "10.4204/EPTCS.313.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce AXolotl, a self-study aid designed to guide\nstudents through the basics of formal reasoning and term manipulation. Unlike\nmost of the existing study aids for formal reasoning, AXolotl is an\nAndroid-based application with a simple touch-based interface. Part of the\ndesign goal was to minimize the possibility of user errors which distract from\nthe learning process. Such as typos or inconsistent application of the provided\nrules. The system includes a zoomable proof viewer which displays the progress\nmade so far and allows for storage of the completed proofs as a JPEG or LaTeX\nfile. The software is available on the google play store and comes with a small\nlibrary of problems. Additional problems may be opened in AXolotl using a\nsimple input language. Currently, AXolotl supports problems that can be solved\nusing rules which transform a single expression into a set of expressions. This\ncovers educational scenarios found in our first-semester introduction to logic\ncourse and helps bridge the gap between propositional and first-order\nreasoning. Future developments will include rewrite rules which take a set of\nexpressions and return a set of expressions, as well as a quantified\nfirst-order extension.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:23:43 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Cerna", "David M.", "", "Research Institute For Symbolic Computation"], ["Kiesel", "Rafael P. D.", "", "Knowlege Based Systems, Technical University of Vienna"], ["Dzhiganskaya", "Alexandra", "", "University of Applied Arts Vienna"]]}, {"id": "2002.12554", "submitter": "EPTCS", "authors": "Sarah Winkler (Universit\\`a di Verona, Italy), Aart Middeldorp\n  (University of Innsbruck, Austria)", "title": "Tools in Term Rewriting for Education", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 54-72", "doi": "10.4204/EPTCS.313.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Term rewriting is a Turing complete model of computation. When taught to\nstudents of computer science, key properties of computation as well as\ntechniques to analyze programs on an abstract level are conveyed. This paper\ngives a swift introduction to term rewriting and presents several automatic\ntools to analyze term rewrite systems which were developed by the Computational\nLogic Group at the University of Innsbruck. These include the termination tool\nTTT2, the confluence prover CSI, the completion tools mkbTT and KBCV, the\ncomplexity tool TcT, the strategy tool AutoStrat, as well as FORT, an\nimplementation of the decision procedure for the first-order theory for a\ndecidable class of rewrite systems. Besides its applications in research, this\nsoftware pool has also proved invaluable for teaching, e.g., in multiple\neditions of the International Summer School on Rewriting.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:24:00 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Winkler", "Sarah", "", "Universit\u00e0 di Verona, Italy"], ["Middeldorp", "Aart", "", "University of Innsbruck, Austria"]]}, {"id": "2002.12555", "submitter": "EPTCS", "authors": "Asta Halkj{\\ae}r From (Technical University of Denmark), Alexander\n  Birch Jensen (Technical University of Denmark), Anders Schlichtkrull\n  (Technical University of Denmark), J{\\o}rgen Villadsen (Technical University\n  of Denmark)", "title": "Teaching a Formalized Logical Calculus", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 73-92", "doi": "10.4204/EPTCS.313.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical first-order logic is in many ways central to work in mathematics,\nlinguistics, computer science and artificial intelligence, so it is worthwhile\nto define it in full detail. We present soundness and completeness proofs of a\nsequent calculus for first-order logic, formalized in the interactive proof\nassistant Isabelle/HOL. Our formalization is based on work by Stefan Berghofer,\nwhich we have since updated to use Isabelle's declarative proof style Isar\n(Archive of Formal Proofs, Entry FOL-Fitting, August 2007 / July 2018). We\nrepresent variables with de Bruijn indices; this makes substitution under\nquantifiers less intuitive for a human reader. However, the nature of natural\nnumbers yields an elegant solution when compared to implementations of\nsubstitution using variables represented by strings. The sequent calculus\nconsidered has the special property of an always empty antecedent and a list of\nformulas in the succedent. We obtain the proofs of soundness and completeness\nfor the sequent calculus as a derived result of the inverse duality of its\ntableau counterpart. We strive to not only present the results of the proofs of\nsoundness and completeness, but also to provide a deep dive into a\nprogramming-like approach to the formalization of first-order logic syntax,\nsemantics and the sequent calculus. We use the formalization in a bachelor\ncourse on logic for computer science and discuss our experiences.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:24:18 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["From", "Asta Halkj\u00e6r", "", "Technical University of Denmark"], ["Jensen", "Alexander Birch", "", "Technical University of Denmark"], ["Schlichtkrull", "Anders", "", "Technical University of Denmark"], ["Villadsen", "J\u00f8rgen", "", "Technical University\n  of Denmark"]]}]