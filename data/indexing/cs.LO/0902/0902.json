[{"id": "0902.0043", "submitter": "Christoph Benzmueller", "authors": "Christoph Benzmueller, Chad E. Brown, Michael Kohlhase", "title": "Cut-Simulation and Impredicativity", "comments": "21 pages", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 1 (March 3,\n  2009) lmcs:1144", "doi": "10.2168/LMCS-5(1:6)2009", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate cut-elimination and cut-simulation in impredicative\n(higher-order) logics. We illustrate that adding simple axioms such as Leibniz\nequations to a calculus for an impredicative logic -- in our case a sequent\ncalculus for classical type theory -- is like adding cut. The phenomenon\nequally applies to prominent axioms like Boolean- and functional\nextensionality, induction, choice, and description. This calls for the\ndevelopment of calculi where these principles are built-in instead of being\ntreated axiomatically.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2009 03:24:08 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2009 23:37:34 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Benzmueller", "Christoph", ""], ["Brown", "Chad E.", ""], ["Kohlhase", "Michael", ""]]}, {"id": "0902.0101", "submitter": "Michael Ummels", "authors": "Michael Ummels and Dominik Wojtczak", "title": "The Complexity of Nash Equilibria in Simple Stochastic Multiplayer Games", "comments": "23 pages; revised version", "journal-ref": null, "doi": "10.1007/978-3-642-02930-1_25", "report-no": "EDI-INF-RR-1323", "categories": "cs.GT cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the computational complexity of finding Nash equilibria in simple\nstochastic multiplayer games. We show that restricting the search space to\nequilibria whose payoffs fall into a certain interval may lead to\nundecidability. In particular, we prove that the following problem is\nundecidable: Given a game G, does there exist a pure-strategy Nash equilibrium\nof G where player 0 wins with probability 1. Moreover, this problem remains\nundecidable if it is restricted to strategies with (unbounded) finite memory.\nHowever, if mixed strategies are allowed, decidability remains an open problem.\nOne way to obtain a provably decidable variant of the problem is restricting\nthe strategies to be positional or stationary. For the complexity of these two\nproblems, we obtain a common lower bound of NP and upper bounds of NP and\nPSPACE respectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2009 16:09:28 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2009 19:54:43 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2009 20:12:06 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Ummels", "Michael", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "0902.1042", "submitter": "Wadie Guizani", "authors": "Mikolaj Bojanczyk", "title": "Weak Mso with the Unbounding Quantifier", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 159-170", "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of languages of infinite words is introduced, called the\nmax-regular languages, extending the class of $\\omega$-regular languages. The\nclass has two equivalent descriptions: in terms of automata (a type of\ndeterministic counter automaton), and in terms of logic (weak monadic\nsecond-order logic with a bounding quantifier). Effective translations between\nthe logic and automata are given.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 09:53:15 GMT"}], "update_date": "2009-03-09", "authors_parsed": [["Bojanczyk", "Mikolaj", ""]]}, {"id": "0902.1179", "submitter": "Goetz Schwandtner", "authors": "Martin Grohe, Goetz Schwandtner", "title": "The Complexity of Datalog on Linear Orders", "comments": "21 pages", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 1 (February\n  27, 2009) lmcs:811", "doi": "10.2168/LMCS-5(1:4)2009", "report-no": null, "categories": "cs.LO cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the program complexity of datalog on both finite and infinite linear\norders. Our main result states that on all linear orders with at least two\nelements, the nonemptiness problem for datalog is EXPTIME-complete. While\ncontainment of the nonemptiness problem in EXPTIME is known for finite linear\norders and actually for arbitrary finite structures, it is not obvious for\ninfinite linear orders. It sharply contrasts the situation on other infinite\nstructures; for example, the datalog nonemptiness problem on an infinite\nsuccessor structure is undecidable. We extend our upper bound results to\ninfinite linear orders with constants.\n  As an application, we show that the datalog nonemptiness problem on Allen's\ninterval algebra is EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2009 17:56:09 GMT"}, {"version": "v2", "created": "Fri, 27 Feb 2009 22:32:04 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Grohe", "Martin", ""], ["Schwandtner", "Goetz", ""]]}, {"id": "0902.1256", "submitter": "Wadie Guizani", "authors": "Andrei A. Bulatov, Victor Dalmau, Martin Grohe, Daniel Marx", "title": "Enumerating Homomorphisms", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 231-242", "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The homomorphism problem for relational structures is an abstract way of\nformulating constraint satisfaction problems (CSP) and various problems in\ndatabase theory. The decision version of the homomorphism problem received a\nlot of attention in literature; in particular, the way the graph-theoretical\nstructure of the variables and constraints influences the complexity of the\nproblem is intensively studied. Here we study the problem of enumerating all\nthe solutions with polynomial delay from a similar point of view. It turns out\nthat the enumeration problem behaves very differently from the decision\nversion. We give evidence that it is unlikely that a characterization result\nsimilar to the decision version can be obtained. Nevertheless, we show\nnontrivial cases where enumeration can be done with polynomial delay.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2009 17:57:24 GMT"}], "update_date": "2009-02-10", "authors_parsed": [["Bulatov", "Andrei A.", ""], ["Dalmau", "Victor", ""], ["Grohe", "Martin", ""], ["Marx", "Daniel", ""]]}, {"id": "0902.1587", "submitter": "Publications Loria", "authors": "Alain Finkel (LSV), Jean Goubault-Larrecq (LSV)", "title": "Forward analysis for WSTS, Part I: Completions", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science - STACS 2009 (2009) 433-444", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well-structured transition systems provide the right foundation to compute a\nfinite basis of the set of predecessors of the upward closure of a state. The\ndual problem, to compute a finite representation of the set of successors of\nthe downward closure of a state, is harder: Until now, the theoretical\nframework for manipulating downward-closed sets was missing. We answer this\nproblem, using insights from domain theory (dcpos and ideal completions), from\ntopology (sobrifications), and shed new light on the notion of adequate domains\nof limits.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 06:42:24 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Finkel", "Alain", "", "LSV"], ["Goubault-Larrecq", "Jean", "", "LSV"]]}, {"id": "0902.1790", "submitter": "David Ellerman", "authors": "David Ellerman", "title": "Counting Distinctions: On the Conceptual Foundations of Shannon's\n  Information Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LO math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical logic has shown that modern logic is essentially the logic of\nsubsets (or \"subobjects\"). Partitions are dual to subsets so there is a dual\nlogic of partitions where a \"distinction\" [an ordered pair of distinct elements\n(u,u') from the universe U ] is dual to an \"element\". An element being in a\nsubset is analogous to a partition p on U making a distinction, i.e., if u and\nu' were in different blocks of p. Subset logic leads to finite probability\ntheory by taking the (Laplacian) probability as the normalized size of each\nsubset-event of a finite universe. The analogous step in the logic of\npartitions is to assign to a partition the number of distinctions made by a\npartition normalized by the total number of ordered pairs |UxU| from the finite\nuniverse. That yields a notion of \"logical entropy\" for partitions and a\n\"logical information theory.\" The logical theory directly counts the\n(normalized) number of distinctions in a partition while Shannon's theory gives\nthe average number of binary partitions needed to make those same distinctions.\nThus the logical theory is seen as providing a conceptual underpinning for\nShannon's theory based on the logical notion of \"distinctions.\" (forthcoming in\nSynthese)\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2009 01:34:21 GMT"}], "update_date": "2009-02-12", "authors_parsed": [["Ellerman", "David", ""]]}, {"id": "0902.2072", "submitter": "Publications Loria", "authors": "Lutz Schr\\\"oder, Dirk Pattinson", "title": "Strong Completeness of Coalgebraic Modal Logics", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science - STACS 2009 (2009) 433-444", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical models are of central importance in modal logic, in particular as\nthey witness strong completeness and hence compactness. While the canonical\nmodel construction is well understood for Kripke semantics, non-normal modal\nlogics often present subtle difficulties - up to the point that canonical\nmodels may fail to exist, as is the case e.g. in most probabilistic logics.\nHere, we present a generic canonical model construction in the semantic\nframework of coalgebraic modal logic, which pinpoints coherence conditions\nbetween syntax and semantics of modal logics that guarantee strong\ncompleteness. We apply this method to reconstruct canonical model theorems that\nare either known or folklore, and moreover instantiate our method to obtain new\nstrong completeness results. In particular, we prove strong completeness of\ngraded modal logic with finite multiplicities, and of the modal logic of exact\nprobabilities.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 16:03:10 GMT"}], "update_date": "2009-02-13", "authors_parsed": [["Schr\u00f6der", "Lutz", ""], ["Pattinson", "Dirk", ""]]}, {"id": "0902.2073", "submitter": "Olha Shkaravska", "authors": "Olha Shkaravska, Marko van Eekelen and Ron van Kesteren", "title": "Polynomial Size Analysis of First-Order Shapely Functions", "comments": "35 pages, 1 figure", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 2 (May 25,\n  2009) lmcs:1148", "doi": "10.2168/LMCS-5(2:10)2009", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a size-aware type system for first-order shapely function\ndefinitions. Here, a function definition is called shapely when the size of the\nresult is determined exactly by a polynomial in the sizes of the arguments.\nExamples of shapely function definitions may be implementations of matrix\nmultiplication and the Cartesian product of two lists. The type system is\nproved to be sound w.r.t. the operational semantics of the language. The type\nchecking problem is shown to be undecidable in general. We define a natural\nsyntactic restriction such that the type checking becomes decidable, even\nthough size polynomials are not necessarily linear or monotonic. Furthermore,\nwe have shown that the type-inference problem is at least semi-decidable (under\nthis restriction). We have implemented a procedure that combines run-time\ntesting and type-checking to automatically obtain size dependencies. It\nterminates on total typable function definitions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 10:16:29 GMT"}, {"version": "v2", "created": "Mon, 25 May 2009 12:01:00 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Shkaravska", "Olha", ""], ["van Eekelen", "Marko", ""], ["van Kesteren", "Ron", ""]]}, {"id": "0902.2104", "submitter": "Dmitry Shkatov", "authors": "Valentin Goranko, Dmitry Shkatov", "title": "Tableau-based decision procedure for full coalitional multiagent\n  temporal-epistemic logic of linear time", "comments": "Proceedings of 8th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 09)", "journal-ref": "8th International Joint Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2009), Budapest, Hungary, May 10-15, 2009, Volume\n  2. IFAAMAS 2009, ISBN 978-0-9817381-7-8", "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a tableau-based decision procedure for the full coalitional\nmultiagent temporal-epistemic logic of linear time CMATEL(CD+LT). It extends\nLTL with operators of common and distributed knowledge for all coalitions of\nagents. The tableau procedure runs in exponential time, matching the lower\nbound obtained by Halpern and Vardi for a fragment of our logic, thus providing\na complexity-optimal decision procedure for CMATEL(CD+LT).\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 13:33:52 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 14:15:42 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Goranko", "Valentin", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "0902.2108", "submitter": "Olivier Serre", "authors": "Vincent Gripon (LIAFA), Olivier Serre (LIAFA)", "title": "Qualitative Concurrent Stochastic Games with Imperfect Information", "comments": "Automata, Languages and Programming, 36th International Colloquium,\n  ICALP 2009, Rhodes: Greece (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a model of games that combines concurrency, imperfect information\nand stochastic aspects. Those are finite states games in which, at each round,\nthe two players choose, simultaneously and independently, an action. Then a\nsuccessor state is chosen accordingly to some fixed probability distribution\ndepending on the previous state and on the pair of actions chosen by the\nplayers. Imperfect information is modeled as follows: both players have an\nequivalence relation over states and, instead of observing the exact state,\nthey only know to which equivalence class it belongs. Therefore, if two partial\nplays are indistinguishable by some player, he should behave the same in both\nof them. We consider reachability (does the play eventually visit a final\nstate?) and B\\\"uchi objective (does the play visit infinitely often a final\nstate?). Our main contribution is to prove that the following problem is\ncomplete for 2-ExpTime: decide whether the first player has a strategy that\nensures her to almost-surely win against any possible strategy of her oponent.\nWe also characterise those strategies needed by the first player to\nalmost-surely win.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 13:39:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2009 09:55:51 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2011 11:45:27 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Gripon", "Vincent", "", "LIAFA"], ["Serre", "Olivier", "", "LIAFA"]]}, {"id": "0902.2125", "submitter": "Dmitry Shkatov", "authors": "Valentin Goranko, Dmitry Shkatov", "title": "Tableau-based procedure for deciding satisfiability in the full\n  coalitional multiagent epistemic logic", "comments": "Appeared in S. Artemov, A. Nerode (editors). Logical Foundations of\n  Computer Science 2009. Lecture Notes in Computer Science. Vol. 5407.\n  Springer, 2009. pp. 197--213", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multiagent epistemic logic CMAELCD with operators for common and\ndistributed knowledge for all coalitions of agents. We introduce Hintikka\nstructures for this logic and prove that satisfiability in such structures is\nequivalent to satisfiability in standard models. Using this result, we design\nan incremental tableau based decision procedure for testing satisfiability in\nCMAELCD.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 14:48:24 GMT"}], "update_date": "2009-02-13", "authors_parsed": [["Goranko", "Valentin", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "0902.2137", "submitter": "Xavier Leroy", "authors": "Xavier Leroy (INRIA Rocquencourt)", "title": "A formally verified compiler back-end", "comments": null, "journal-ref": "Journal of Automated Reasoning 43, 4 (2009) 363-446", "doi": "10.1007/s10817-009-9155-4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the development and formal verification (proof of\nsemantic preservation) of a compiler back-end from Cminor (a simple imperative\nintermediate language) to PowerPC assembly code, using the Coq proof assistant\nboth for programming the compiler and for proving its correctness. Such a\nverified compiler is useful in the context of formal methods applied to the\ncertification of critical software: the verification of the compiler guarantees\nthat the safety properties proved on the source code hold for the executable\ncompiled code as well.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 15:48:28 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2009 13:07:04 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2009 09:14:31 GMT"}], "update_date": "2009-11-14", "authors_parsed": [["Leroy", "Xavier", "", "INRIA Rocquencourt"]]}, {"id": "0902.2969", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Ptarithmetic", "comments": "Substantially better versions are on their way. Hence the present\n  article probably will not be published", "journal-ref": "The Baltic International Yearbook on Cognition, Logic and\n  Communication 8 (2013), Article 5, pp. 1-186", "doi": "10.4148/1944-3676.1074", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present article introduces ptarithmetic (short for \"polynomial time\narithmetic\") -- a formal number theory similar to the well known Peano\narithmetic, but based on the recently born computability logic (see\nhttp://www.cis.upenn.edu/~giorgi/cl.html) instead of classical logic. The\nformulas of ptarithmetic represent interactive computational problems rather\nthan just true/false statements, and their \"truth\" is understood as existence\nof a polynomial time solution. The system of ptarithmetic elaborated in this\narticle is shown to be sound and complete. Sound in the sense that every\ntheorem T of the system represents an interactive number-theoretic\ncomputational problem with a polynomial time solution and, furthermore, such a\nsolution can be effectively extracted from a proof of T. And complete in the\nsense that every interactive number-theoretic problem with a polynomial time\nsolution is represented by some theorem T of the system.\n  The paper is self-contained, and can be read without any previous familiarity\nwith computability logic.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2009 19:14:09 GMT"}, {"version": "v2", "created": "Wed, 18 Feb 2009 12:48:43 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2010 10:17:31 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "0902.2975", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth, Ruediger Lunde", "title": "Writing Positive/Negative-Conditional Equations Conveniently", "comments": "ii + 21 pages", "journal-ref": null, "doi": null, "report-no": "SEKI Working-Paper SWP-94-04", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convenient notation for positive/negative-conditional equations.\nThe idea is to merge rules specifying the same function by using case-, if-,\nmatch-, and let-expressions. Based on the presented macro-rule-construct,\npositive/negative-conditional equational specifications can be written on a\nhigher level. A rewrite system translates the macro-rule-constructs into\npositive/negative-conditional equations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2009 19:13:32 GMT"}], "update_date": "2009-02-18", "authors_parsed": [["Wirth", "Claus-Peter", ""], ["Lunde", "Ruediger", ""]]}, {"id": "0902.3294", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "Progress in Computer-Assisted Inductive Theorem Proving by\n  Human-Orientedness and Descente Infinie?", "comments": "ii + 35 pages", "journal-ref": "Logic Journal of the IGPL, 2012, Volume 20, Pp. 1046-1063", "doi": "10.1093/jigpal/jzr048", "report-no": "SEKI Working-Paper SR-2006-01", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short position paper we briefly review the development history of\nautomated inductive theorem proving and computer-assisted mathematical\ninduction. We think that the current low expectations on progress in this field\nresult from a faulty narrow-scope historical projection. Our main motivation is\nto explain--on an abstract but hopefully sufficiently descriptive level--why we\nbelieve that future progress in the field is to result from human-orientedness\nand descente infinie.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2009 22:37:31 GMT"}, {"version": "v2", "created": "Tue, 11 May 2010 18:16:50 GMT"}, {"version": "v3", "created": "Wed, 1 Sep 2010 14:06:16 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3532", "submitter": "Vadim Tropashko", "authors": "Vadim Tropashko", "title": "Relational Lattice Foundation for Algebraic Logic", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Lattice is a succinct mathematical model for Relational Algebra.\nIt reduces the set of six classic relational algebra operators to two: natural\njoin and inner union. In this paper we push relational lattice theory in two\ndirections. First, we uncover a pair of complementary lattice operators, and\norganize the model into a bilattice of four operations and four distinguished\nconstants. We take a notice a peculiar way bilattice symmetry is broken. Then,\nwe give axiomatic introduction of unary negation operation and prove several\nlaws, including double negation and De Morgan. Next we reduce the model back to\ntwo basic binary operations and twelve axioms, and exhibit a convincing\nargument that the resulting system is complete in model-theoretic sense. The\nfinal parts of the paper casts relational lattice perspective onto database\ndependency theory and into cylindric algebras.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 08:01:54 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2009 23:34:29 GMT"}], "update_date": "2009-03-24", "authors_parsed": [["Tropashko", "Vadim", ""]]}, {"id": "0902.3614", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "Syntactic Confluence Criteria for Positive/Negative-Conditional Term\n  Rewriting Systems", "comments": "ii + 187 pages", "journal-ref": "J. Symbolic Computation, 2009, 44:60--98", "doi": null, "report-no": "SEKI Report SR-95-09", "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study the combination of the following already known ideas for showing\nconfluence of unconditional or conditional term rewriting systems into\npractically more useful confluence criteria for conditional systems: Our\nsyntactical separation into constructor and non-constructor symbols, Huet's\nintroduction and Toyama's generalization of parallel closedness for\nnon-noetherian unconditional systems, the use of shallow confluence for proving\nconfluence of noetherian and non-noetherian conditional systems, the idea that\ncertain kinds of limited confluence can be assumed for checking the\nfulfilledness or infeasibility of the conditions of conditional critical pairs,\nand the idea that (when termination is given) only prime superpositions have to\nbe considered and certain normalization restrictions can be applied for the\nsubstitutions fulfilling the conditions of conditional critical pairs. Besides\ncombining and improving already known methods, we present the following new\nideas and results: We strengthen the criterion for overlay joinable noetherian\nsystems, and, by using the expressiveness of our syntactical separation into\nconstructor and non-constructor symbols, we are able to present criteria for\nlevel confluence that are not criteria for shallow confluence actually and also\nable to weaken the severe requirement of normality (stiffened with\nleft-linearity) in the criteria for shallow confluence of noetherian and\nnon-noetherian conditional systems to the easily satisfied requirement of\nquasi-normality. Finally, the whole paper may also give a practically useful\noverview of the syntactical means for showing confluence of conditional term\nrewriting systems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 16:26:52 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3616", "submitter": "Stephan Kreutzer", "authors": "Stephan Kreutzer", "title": "Algorithmic Meta-Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic meta-theorems are general algorithmic results applying to a whole\nrange of problems, rather than just to a single problem alone. They often have\na \"logical\" and a \"structural\" component, that is they are results of the form:\nevery computational problem that can be formalised in a given logic L can be\nsolved efficiently on every class C of structures satisfying certain\nconditions. This paper gives a survey of algorithmic meta-theorems obtained in\nrecent years and the methods used to prove them. As many meta-theorems use\nresults from graph minor theory, we give a brief introduction to the theory\ndeveloped by Robertson and Seymour for their proof of the graph minor theorem\nand state the main algorithmic consequences of this theory as far as they are\nneeded in the theory of algorithmic meta-theorems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 16:45:04 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Kreutzer", "Stephan", ""]]}, {"id": "0902.3623", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "A Self-Contained and Easily Accessible Discussion of the Method of\n  Descente Infinie and Fermat's Only Explicitly Known Proof by Descente Infinie", "comments": "ii + 36 pages, French abstract (R\\'esum\\'e) included in paper", "journal-ref": null, "doi": null, "report-no": "SEKI Working-Paper SWP-2006-02, Second edition", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the only proof of Pierre Fermat by descente infinie that is known\nto exist today. As the text of its Latin original requires active mathematical\ninterpretation, it is more a proof sketch than a proper mathematical proof. We\ndiscuss descente infinie from the mathematical, logical, historical,\nlinguistic, and refined logic-historical points of view. We provide the\nrequired preliminaries from number theory and develop a self-contained proof in\na modern form, which nevertheless is intended to follow Fermat's ideas closely.\nWe then annotate an English translation of Fermat's original proof with terms\nfrom the modern proof. Including all important facts, we present a concise and\nself-contained discussion of Fermat's proof sketch, which is easily accessible\nto laymen in number theory as well as to laymen in the history of mathematics,\nand which provides new clarification of the Method of Descente Infinie to the\nexperts in these fields. Last but not least, this paper fills a gap regarding\nthe easy accessibility of the subject.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 17:16:52 GMT"}, {"version": "v2", "created": "Sun, 28 Nov 2010 22:23:01 GMT"}, {"version": "v3", "created": "Wed, 8 Dec 2010 15:39:54 GMT"}, {"version": "v4", "created": "Tue, 14 Dec 2010 08:32:44 GMT"}], "update_date": "2010-12-15", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3635", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "lim+, delta+, and Non-Permutability of beta-Steps", "comments": "ii + 36 pages", "journal-ref": "Journal of Symbolic Computation, 2012, Volume 47, Pp. 1109-1135", "doi": "10.1016/j.jsc.2011.12.035", "report-no": "SEKI Report SR-2005-01", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a human-oriented formal example proof of the (lim+) theorem, i.e. that\nthe sum of limits is the limit of the sum, which is of value for reference on\nits own, we exhibit a non-permutability of beta-steps and delta+-steps\n(according to Smullyan's classification), which is not visible with\nnon-liberalized delta-rules and not serious with further liberalized\ndelta-rules, such as the delta++-rule. Besides a careful presentation of the\nsearch for a proof of (lim+) with several pedagogical intentions, the main\nsubject is to explain why the order of beta-steps plays such a practically\nimportant role in some calculi.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 18:07:28 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3648", "submitter": "Claus-Peter Wirth", "authors": "Volker Mattick, Claus-Peter Wirth", "title": "An Algebraic Dexter-Based Hypertext Reference Model", "comments": "ii + 48 pages", "journal-ref": null, "doi": null, "report-no": "Research Report 719/1999 (green/grey series), Fachbereich\n  Informatik, University of Dortmund", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first formal algebraic specification of a hypertext reference\nmodel. It is based on the well-known Dexter Hypertext Reference Model and\nincludes modifications with respect to the development of hypertext since the\nWWW came up. Our hypertext model was developed as a product model with the aim\nto automatically support the design process and is extended to a model of\nhypertext-systems in order to be able to describe the state transitions in this\nprocess. While the specification should be easy to read for non-experts in\nalgebraic specification, it guarantees a unique understanding and enables a\nclose connection to logic-based development and verification.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 19:57:30 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Mattick", "Volker", ""], ["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3722", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - Imag)", "title": "A minimalistic look at widening operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of formalizing the familiar notion of widening in\nabstract interpretation in higher-order logic. It turns out that many axioms of\nwidening (e.g. widening sequences are ascending) are not useful for proving\ncorrectness. After keeping only useful axioms, we give an equivalent\ncharacterization of widening as a lazily constructed well-founded tree. In type\nsystems supporting dependent products and sums, this tree can be made to\nreflect the condition of correct termination of the widening sequence.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2009 07:13:28 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2009 19:09:15 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2009 17:45:04 GMT"}], "update_date": "2009-11-23", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - Imag"]]}, {"id": "0902.3730", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "Full First-Order Sequent and Tableau Calculi With Preservation of\n  Solutions and the Liberalized delta-Rule but Without Skolemization", "comments": "ii + 40 pages", "journal-ref": "Caferra, R. and Salzer, G., eds., Automated Deduction in Classical\n  and Non-Classical Logics (FTP'98), LNAI 1761, pp. 283-298, Springer, 2000", "doi": null, "report-no": "Research Report 698/1998 (green/grey series), Fachbereich\n  Informatik, University of Dortmund", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a combination of raising, explicit variable dependency\nrepresentation, the liberalized delta-rule, and preservation of solutions for\nfirst-order deductive theorem proving. Our main motivation is to provide the\nfoundation for our work on inductive theorem proving, where the preservation of\nsolutions is indispensable.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2009 09:45:20 GMT"}], "update_date": "2009-02-24", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3749", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "Hilbert's epsilon as an Operator of Indefinite Committed Choice", "comments": "ii + 73 pages. arXiv admin note: substantial text overlap with\n  arXiv:1104.2444", "journal-ref": "Journal of Applied Logic 6 (2008), pp. 287-317", "doi": "10.1016/j.jal.2007.07.009", "report-no": "SEKI Report SR-2006-02", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paul Bernays and David Hilbert carefully avoided overspecification of\nHilbert's epsilon-operator and axiomatized only what was relevant for their\nproof-theoretic investigations. Semantically, this left the epsilon-operator\nunderspecified. In the meanwhile, there have been several suggestions for\nsemantics of the epsilon as a choice operator. After reviewing the literature\non semantics of Hilbert's epsilon operator, we propose a new semantics with the\nfollowing features: We avoid overspecification (such as right-uniqueness), but\nadmit indefinite choice, committed choice, and classical logics. Moreover, our\nsemantics for the epsilon supports proof search optimally and is natural in the\nsense that it does not only mirror some cases of referential interpretation of\nindefinite articles in natural language, but may also contribute to philosophy\nof language. Finally, we ask the question whether our epsilon within our\nfree-variable framework can serve as a paradigm useful in the specification and\ncomputation of semantics of discourses in natural language.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2009 17:04:16 GMT"}, {"version": "v2", "created": "Sun, 23 May 2010 16:23:47 GMT"}, {"version": "v3", "created": "Mon, 16 Jan 2012 21:10:14 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "0902.3858", "submitter": "Eric Jaeger", "authors": "Eric Jaeger (DCSSI/SDS/Lti, Lip6), Catherine Dubois (CEDRIC)", "title": "Why Would You Trust B?", "comments": "15 pages", "journal-ref": "Logic for Programming, Artificial Intelligence, and Reasoning,\n  Yerevan : Arm\\'enie (2007)", "doi": "10.1007/978-3-540-75560-9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of formal methods provides confidence in the correctness of\ndevelopments. Yet one may argue about the actual level of confidence obtained\nwhen the method itself -- or its implementation -- is not formally checked. We\naddress this question for the B, a widely used formal method that allows for\nthe derivation of correct programs from specifications. Through a deep\nembedding of the B logic in Coq, we check the B theory but also implement B\ntools. Both aspects are illustrated by the description of a proved prover for\nthe B logic.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2009 07:58:03 GMT"}], "update_date": "2009-02-24", "authors_parsed": [["Jaeger", "Eric", "", "DCSSI/SDS/Lti, Lip6"], ["Dubois", "Catherine", "", "CEDRIC"]]}, {"id": "0902.3861", "submitter": "Eric Jaeger", "authors": "Eric Jaeger (LIP6, Dcssi/SDS/Lti), Th\\'er\\`ese Hardin (LIP6)", "title": "A Few Remarks About Formal Development of Secure Systems", "comments": "10 pages", "journal-ref": "High Assurance Systems Engineering Symposium, Nanjing : Chine\n  (2008)", "doi": "10.1109/HASE.2008.49", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal methods provide remarkable tools allowing for high levels of\nconfidence in the correctness of developments. Their use is therefore\nencouraged, when not required, for the development of systems in which safety\nor security is mandatory. But effectively specifying a secure system or\nderiving a secure implementation can be tricky. We propose a review of some\nclassical `gotchas' and other possible sources of concerns with the objective\nto improve the confidence in formal developments, or at least to better assess\nthe actual confidence level.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2009 08:19:11 GMT"}], "update_date": "2009-02-24", "authors_parsed": [["Jaeger", "Eric", "", "LIP6, Dcssi/SDS/Lti"], ["Hardin", "Th\u00e9r\u00e8se", "", "LIP6"]]}, {"id": "0902.3865", "submitter": "Eric Jaeger", "authors": "Eric Jaeger (LIP6, Dcssi/SDS/Lti), Th\\'er\\`ese Hardin (LIP6)", "title": "Yet Another Deep Embedding of B:Extending de Bruijn Notations", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Bicoq3, a deep embedding of the B system in Coq, focusing on the\ntechnical aspects of the development. The main subjects discussed are related\nto the representation of sets and maps, the use of induction principles, and\nthe introduction of a new de Bruijn notation providing solutions to various\nproblems related to the mechanisation of languages and logics.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2009 08:53:36 GMT"}], "update_date": "2009-02-24", "authors_parsed": [["Jaeger", "Eric", "", "LIP6, Dcssi/SDS/Lti"], ["Hardin", "Th\u00e9r\u00e8se", "", "LIP6"]]}, {"id": "0902.3958", "submitter": "Laurent Doyen", "authors": "Laurent Doyen and Jean-Francois Raskin", "title": "Antichains for the Automata-Based Approach to Model-Checking", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 1 (March 2,\n  2009) lmcs:1027", "doi": "10.2168/LMCS-5(1:5)2009", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate antichain algorithms to solve the universality and\nlanguage inclusion problems for nondeterministic Buechi automata, and the\nemptiness problem for alternating Buechi automata. To obtain those algorithms,\nwe establish the existence of simulation pre-orders that can be exploited to\nefficiently evaluate fixed points on the automata defined during the\ncomplementation step (that we keep implicit in our approach). We evaluate the\nperformance of the algorithm to check the universality of Buechi automata using\nthe random automaton model recently proposed by Tabakov and Vardi. We show that\non the difficult instances of this probabilistic model, our algorithm\noutperforms the standard ones by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2009 17:17:11 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2009 18:54:55 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Doyen", "Laurent", ""], ["Raskin", "Jean-Francois", ""]]}, {"id": "0902.4348", "submitter": "Sandor Vagvolgyi", "authors": "Sandor Vagvolgyi", "title": "On ground word problem of term equation systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give semi-decision procedures for the ground word problem of variable\npreserving term equation systems and term equation systems. They are natural\nimprovements of two well known trivial semi-decision procedures. We show the\ncorrectness of our procedures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2009 11:35:02 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2012 06:22:14 GMT"}], "update_date": "2012-09-10", "authors_parsed": [["Vagvolgyi", "Sandor", ""]]}, {"id": "0902.4682", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth, Joerg Siekmann, Christoph Benzmueller, Serge\n  Autexier", "title": "Lectures on Jacques Herbrand as a Logician", "comments": "ii + 82 pages", "journal-ref": null, "doi": null, "report-no": "SEKI Report SR-2009-01", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give some lectures on the work on formal logic of Jacques Herbrand, and\nsketch his life and his influence on automated theorem proving. The intended\naudience ranges from students interested in logic over historians to logicians.\nBesides the well-known correction of Herbrand's False Lemma by Goedel and\nDreben, we also present the hardly known unpublished correction of Heijenoort\nand its consequences on Herbrand's Modus Ponens Elimination. Besides Herbrand's\nFundamental Theorem and its relation to the Loewenheim-Skolem-Theorem, we\ncarefully investigate Herbrand's notion of intuitionism in connection with his\nnotion of falsehood in an infinite domain. We sketch Herbrand's two proofs of\nthe consistency of arithmetic and his notion of a recursive function, and last\nbut not least, present the correct original text of his unification algorithm\nwith a new translation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2009 19:59:17 GMT"}, {"version": "v2", "created": "Fri, 27 Feb 2009 18:29:54 GMT"}, {"version": "v3", "created": "Tue, 12 May 2009 19:09:43 GMT"}, {"version": "v4", "created": "Thu, 30 Jun 2011 18:43:12 GMT"}, {"version": "v5", "created": "Tue, 27 May 2014 08:58:06 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Wirth", "Claus-Peter", ""], ["Siekmann", "Joerg", ""], ["Benzmueller", "Christoph", ""], ["Autexier", "Serge", ""]]}, {"id": "0902.4723", "submitter": "Joerg Endrullis", "authors": "Joerg Endrullis, Herman Geuvers, Hans Zantema", "title": "Degrees of Undecidability in Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undecidability of various properties of first order term rewriting systems is\nwell-known. An undecidable property can be classified by the complexity of the\nformula defining it. This gives rise to a hierarchy of distinct levels of\nundecidability, starting from the arithmetical hierarchy classifying properties\nusing first order arithmetical formulas and continuing into the analytic\nhierarchy, where also quantification over function variables is allowed.\n  In this paper we consider properties of first order term rewriting systems\nand classify them in this hierarchy. Weak and strong normalization for single\nterms turn out to be Sigma-0-1-complete, while their uniform versions as well\nas dependency pair problems with minimality flag are Pi-0-2-complete. We find\nthat confluence is Pi-0-2-complete both for single terms and uniform.\nUnexpectedly weak confluence for ground terms turns out to be harder than weak\nconfluence for open terms. The former property is Pi-0-2-complete while the\nlatter is Sigma-0-1-complete (and thereby recursively enumerable).\n  The most surprising result is on dependency pair problems without minimality\nflag: we prove this to be Pi-1-1-complete, which means that this property\nexceeds the arithmetical hierarchy and is essentially analytic.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2009 22:59:29 GMT"}], "update_date": "2009-03-02", "authors_parsed": [["Endrullis", "Joerg", ""], ["Geuvers", "Herman", ""], ["Zantema", "Hans", ""]]}]