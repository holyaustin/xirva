[{"id": "1610.00026", "submitter": "Robin Adams", "authors": "Robin Adams, Marc Bezem, Thierry Coquand", "title": "A Normalizing Computation Rule for Propositional Extensionality in\n  Higher-Order Minimal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The univalence axiom expresses the principle of extensionality for dependent\ntype theory. However, if we simply add the univalence axiom to type theory,\nthen we lose the property of canonicity - that every closed term computes to a\ncanonical form. A computation becomes `stuck' when it reaches the point that it\nneeds to evaluate a proof term that is an application of the univalence axiom.\nSo we wish to find a way to compute with the univalence axiom. While this\nproblem has been solved with the formulation of cubical type theory, where the\ncomputations are expressed using a nominal extension of lambda-calculus, it may\nbe interesting to explore alternative solutions, which do not require such an\nextension.\n  As a first step, we present here a system of propositional higher-order\nminimal logic (PHOML). There are three kinds of typing judgement in PHOML.\nThere are terms which inhabit types, which are the simple types over $\\Omega$.\nThere are proofs which inhabit propositions, which are the terms of type\n$\\Omega$. The canonical propositions are those constructed from $\\bot$ by\nimplication $\\supset$. Thirdly, there are paths which inhabit equations $M =_A\nN$, where $M$ and $N$ are terms of type $A$. There are two ways to prove an\nequality: reflexivity, and propositional extensionality - logically equivalent\npropositions are equal. This system allows for some definitional equalities\nthat are not present in cubical type theory, namely that transport along the\ntrivial path is identity.\n  We present a call-by-name reduction relation for this system, and prove that\nthe system satisfies canonicity: every closed typable term head-reduces to a\ncanonical form. This work has been formalised in Agda.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 20:40:04 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 12:49:12 GMT"}, {"version": "v3", "created": "Mon, 13 Mar 2017 12:12:25 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Adams", "Robin", ""], ["Bezem", "Marc", ""], ["Coquand", "Thierry", ""]]}, {"id": "1610.00253", "submitter": "J\\\"urgen Koslowski", "authors": "Alberto Lluch Lafuente, Michele Loreti, Ugo Montanari", "title": "Asynchronous Distributed Execution Of Fixpoint-Based Computational\n  Fields", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 22,\n  2017) lmcs:3212", "doi": "10.23638/LMCS-13(1:13)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination is essential for dynamic distributed systems whose components\nexhibit interactive and autonomous behaviors. Spatially distributed, locally\ninteracting, propagating computational fields are particularly appealing for\nallowing components to join and leave with little or no overhead. Computational\nfields are a key ingredient of aggregate programming, a promising software\nengineering methodology particularly relevant for the Internet of Things. In\nour approach, space topology is represented by a fixed graph-shaped field,\nnamely a network with attributes on both nodes and arcs, where arcs represent\ninteraction capabilities between nodes. We propose a SMuC calculus where\nmu-calculus- like modal formulas represent how the values stored in neighbor\nnodes should be combined to update the present node. Fixpoint operations can be\nunderstood globally as recursive definitions, or locally as asynchronous\nconverging propagation processes. We present a distributed implementation of\nour calculus. The translation is first done mapping SMuC programs into normal\nform, purely iterative programs and then into distributed programs. Some key\nresults are presented that show convergence of fixpoint computations under fair\nasynchrony and under reinitialization of nodes. The first result allows nodes\nto proceed at different speeds, while the second one provides robustness\nagainst certain kinds of failure. We illustrate our approach with a case study\nbased on a disaster recovery scenario, implemented in a prototype simulator\nthat we use to evaluate the performance of a recovery strategy.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 09:48:50 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 10:39:38 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Lafuente", "Alberto Lluch", ""], ["Loreti", "Michele", ""], ["Montanari", "Ugo", ""]]}, {"id": "1610.00328", "submitter": "J\\\"urgen Koslowski", "authors": "Tzu-chun Chen and Mariangiola Dezani-Ciancaglini and Alceste Scalas\n  and Nobuko Yoshida", "title": "On the Preciseness of Subtyping in Session Types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (June 30,\n  2017) lmcs:3752", "doi": "10.23638/LMCS-13(2:12)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtyping in concurrency has been extensively studied since early 1990s as\none of the most interesting issues in type theory. The correctness of subtyping\nrelations has been usually provided as the soundness for type safety. The\nconverse direction, the completeness, has been largely ignored in spite of its\nusefulness to define the largest subtyping relation ensuring type safety. This\npaper formalises preciseness (i.e. both soundness and completeness) of\nsubtyping for mobile processes and studies it for the synchronous and the\nasynchronous session calculi. We first prove that the well-known session\nsubtyping, the branching-selection subtyping, is sound and complete for the\nsynchronous calculus. Next we show that in the asynchronous calculus, this\nsubtyping is incomplete for type-safety: that is, there exist session types T\nand S such that\n  T can safely be considered as a subtype of S, but T < S is not derivable by\nthe subtyping. We then propose an asynchronous subtyping system which is sound\nand complete for the asynchronous calculus. The method gives a general guidance\nto design rigorous channel-based subtypings respecting desired safety\nproperties. Both the synchronous and the asynchronous calculus are first\nconsidered with lin ear channels only, and then they are extended with session\ninitialisations and c ommunications of expressions (including shared channels).\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 18:17:38 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 13:49:22 GMT"}, {"version": "v3", "created": "Thu, 29 Jun 2017 11:59:39 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chen", "Tzu-chun", ""], ["Dezani-Ciancaglini", "Mariangiola", ""], ["Scalas", "Alceste", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1610.00450", "submitter": "Arnaud Carayol", "authors": "Luca Aceto, Arnaud Carayol, Zolt\\'an \\'Esik, Anna Ing\\'olfsd\\'ottir", "title": "Algebraic Synchronization Trees and Processes", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algebraic synchronization trees, i.e., initial solutions of\nalgebraic recursion schemes over the continuous categorical algebra of\nsynchronization trees. In particular, we investigate the relative expressive\npower of algebraic recursion schemes over two signatures, which are based on\nthose for Basic CCS and Basic Process Algebra, as a means for defining\nsynchronization trees up to isomorphism as well as modulo bisimilarity and\nlanguage equivalence. The expressiveness of algebraic recursion schemes is also\ncompared to that of the low levels in Caucal's pushdown hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 09:00:35 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Aceto", "Luca", ""], ["Carayol", "Arnaud", ""], ["\u00c9sik", "Zolt\u00e1n", ""], ["Ing\u00f3lfsd\u00f3ttir", "Anna", ""]]}, {"id": "1610.01004", "submitter": "Brijesh Dongol", "authors": "Alasdair Armstrong, Brijesh Dongol, Simon Doherty", "title": "Reducing Opacity to Linearizability: A Sound and Complete Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional memory is a mechanism that manages thread synchronisation on\nbehalf of a programmer so that blocks of code execute with an illusion of\natomicity. The main safety criterion for transactional memory is opacity, which\ndefines conditions for serialising concurrent transactions.\n  Proving opacity is complicated because it allows concurrent transactions to\nobserve distinct memory states, while TM implementations are typically based on\none single shared store. This paper presents a sound and complete method, based\non coarse-grained abstraction, for reducing proofs of opacity to the relatively\nsimpler correctness condition: linearizability. We use our methods to verify\nTML and NORec from the literature and show our techniques extend to relaxed\nmemory models by showing that both are opaque under TSO without requiring\nadditional fences. Our methods also elucidate TM designs at higher level of\nabstraction; as an application, we develop a variation of NORec with fast-path\nreads transactions. All our proofs have been mechanised, either in the Isabelle\ntheorem prover or the PAT model checker.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 14:07:52 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Armstrong", "Alasdair", ""], ["Dongol", "Brijesh", ""], ["Doherty", "Simon", ""]]}, {"id": "1610.01134", "submitter": "Ulrik Buchholtz", "authors": "Ulrik Buchholtz and Egbert Rijke", "title": "The Cayley-Dickson Construction in Homotopy Type Theory", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define in the setting of homotopy type theory an H-space structure on\n$\\mathbb S^3$. Hence we obtain a description of the quaternionic Hopf fibration\n$\\mathbb S^3\\hookrightarrow\\mathbb S^7\\twoheadrightarrow\\mathbb S^4$, using\nonly homotopy invariant tools.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 19:28:42 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Buchholtz", "Ulrik", ""], ["Rijke", "Egbert", ""]]}, {"id": "1610.01185", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra and Daniel Rubery", "title": "Recursion-Theoretic Ranking and Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For which sets A does there exist a mapping, computed by a total or partial\nrecursive function, such that the mapping, when its domain is restricted to A,\nis a 1-to-1, onto mapping to $\\Sigma^*$? And for which sets A does there exist\nsuch a mapping that respects the lexicographical ordering within A? Both cases\nare types of perfect, minimal hash functions. The complexity-theoretic versions\nof these notions are known as compression functions and ranking functions. The\npresent paper defines and studies the recursion-theoretic versions of\ncompression and ranking functions, and in particular studies the question of\nwhich sets have, or lack, such functions. Thus, this is a case where, in\ncontrast to the usual direction of notion transferal, notions from complexity\ntheory are inspiring notions, and an investigation, in computability theory.\n  We show that the rankable and compressible sets broadly populate the\n1-truth-table degrees, and we prove that every nonempty coRE cylinder is\nrecursively compressible.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 20:18:40 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 04:48:14 GMT"}, {"version": "v3", "created": "Fri, 20 Oct 2017 14:38:45 GMT"}, {"version": "v4", "created": "Fri, 24 Nov 2017 17:05:31 GMT"}, {"version": "v5", "created": "Wed, 29 Nov 2017 03:48:13 GMT"}, {"version": "v6", "created": "Mon, 4 Dec 2017 03:35:47 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Rubery", "Daniel", ""]]}, {"id": "1610.01188", "submitter": "Andreas Pavlogiannis", "authors": "Marek Chalupa and Krishnendu Chatterjee and Andreas Pavlogiannis and\n  Nishant Sinha and Kapil Vaidya", "title": "Data-centric Dynamic Partial Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new dynamic partial-order reduction method for stateless model\nchecking of concurrent programs. A common approach for exploring program\nbehaviors relies on enumerating the traces of the program, without storing the\nvisited states (aka stateless exploration). As the number of distinct traces\ngrows exponentially, dynamic partial-order reduction (DPOR) techniques have\nbeen successfully used to partition the space of traces into equivalence\nclasses (Mazurkiewicz partitioning), with the goal of exploring only few\nrepresentative traces from each class.\n  We introduce a new equivalence on traces under sequential consistency\nsemantics, which we call the observation equivalence. Two traces are\nobservationally equivalent if every read event observes the same write event in\nboth traces. While the traditional Mazurkiewicz equivalence is control-centric,\nour new definition is data-centric. We show that our observation equivalence is\ncoarser than the Mazurkiewicz equivalence, and in many cases even exponentially\ncoarser. We devise a DPOR exploration of the trace space, called data-centric\nDPOR, based on the observation equivalence. For acyclic architectures, our\nalgorithm is guaranteed to explore exactly one representative trace from each\nobservation class, while spending polynomial time per class. Hence, our\nalgorithm is optimal wrt the observation equivalence, and in several cases\nexplores exponentially fewer traces than any enumerative method based on the\nMazurkiewicz equivalence. For cyclic architectures, we consider an equivalence\nbetween traces which is finer than the observation equivalence; but coarser\nthan the Mazurkiewicz equivalence, and in some cases is exponentially coarser.\nOur data-centric DPOR algorithm remains optimal under this trace equivalence.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 20:29:15 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 22:13:53 GMT"}, {"version": "v3", "created": "Mon, 2 Jan 2017 11:28:08 GMT"}, {"version": "v4", "created": "Sun, 22 Oct 2017 12:11:58 GMT"}, {"version": "v5", "created": "Wed, 17 Oct 2018 13:12:44 GMT"}, {"version": "v6", "created": "Fri, 25 Jan 2019 08:32:46 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Chalupa", "Marek", ""], ["Chatterjee", "Krishnendu", ""], ["Pavlogiannis", "Andreas", ""], ["Sinha", "Nishant", ""], ["Vaidya", "Kapil", ""]]}, {"id": "1610.01213", "submitter": "Gabriel Scherer", "authors": "Gabriel Scherer", "title": "Deciding equivalence with sums and the empty type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The logical technique of focusing can be applied to the $\\lambda$-calculus;\nin a simple type system with atomic types and negative type formers (functions,\nproducts, the unit type), its normal forms coincide with $\\beta\\eta$-normal\nforms. Introducing a saturation phase gives a notion of quasi-normal forms in\npresence of positive types (sum types and the empty type). This rich structure\nlet us prove the decidability of $\\beta\\eta$-equivalence in presence of the\nempty type, the fact that it coincides with contextual equivalence, and a\nfinite model property.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 21:37:45 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 02:04:34 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2016 15:58:09 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Scherer", "Gabriel", ""]]}, {"id": "1610.01331", "submitter": "Quang Loc Le", "authors": "Quang Loc Le", "title": "A Decision Procedure for String Logic with Equations, Regular Membership\n  and Length Constraints", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the satisfiability problem for string logic with\nequations, regular membership and Presburger constraints over length functions.\nThe difficulty comes from multiple occurrences of string variables making\nstate-of-the-art algorithms non-terminating. Our main contribution is to show\nthat the satisfiability problem in a fragment where no string variable occurs\nmore than twice in an equation is decidable. In particular, we propose a\nsemi-decision procedure for arbitrary string formulae with word equations,\nregular membership and length functions. The essence of our procedure is an\nalgorithm to enumerate an equivalent set of solvable disjuncts for the formula.\nWe further show that the algorithm always terminates for the aforementioned\ndecidable fragment. Finally, we provide a complexity analysis of our decision\nprocedure to prove that it runs, in the worst case, in factorial time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 09:37:51 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2016 14:40:09 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Le", "Quang Loc", ""]]}, {"id": "1610.01412", "submitter": "Kees Middelburg", "authors": "C. A. Middelburg", "title": "A short introduction to process theory", "comments": "130 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These lecture notes concern the basics of the theory of process behaviour.\nFirst the concept of a (labelled) transition system receives ample treatment\nand then the following issues concerning process behaviour are elaborated in\nthe setting of transition systems: (i) concurrency and interaction, (ii)\nabstraction, (iii) sequential composition, alternative composition, and\niteration, (iv) expressions that represent process behaviours, and (v)\nstructural operational semantics and equational laws for such expressions. To\nquicken an intuitive understanding, direct connections with programs and\nautomata are established wherever appropriate. For the interested reader,\ndirect connections with Petri nets are also established. In each chapter,\nexcept the last one, it shows that what has been dealt with so far still has\ncertain limitations. Each time, the next chapter is devoted to reducing the\nlimitations concerned.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 15:35:43 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Middelburg", "C. A.", ""]]}, {"id": "1610.01470", "submitter": "Patrick Totzke", "authors": "Piotr Hofman, J\\'er\\^ome Leroux, Patrick Totzke", "title": "Linear Combinations of Unordered Data Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data vectors generalise finite multisets: they are finitely supported\nfunctions into a commutative monoid. We study the question if a given data\nvector can be expressed as a finite sum of others, only assuming that 1) the\ndomain is countable and 2) the given set of base vectors is finite up to\npermutations of the domain.\n  Based on a succinct representation of the involved permutations as integer\nlinear constraints, we derive that positive instances can be witnessed in a\nbounded subset of the domain.\n  For data vectors over a group we moreover study when a data vector is\nreversible, that is, if its inverse is expressible using only nonnegative\ncoefficients. We show that if all base vectors are reversible then the\nexpressibility problem reduces to checking membership in finitely generated\nsubgroups. Moreover, checking reversibility also reduces to such membership\ntests.\n  These questions naturally appear in the analysis of counter machines extended\nwith unordered data: namely, for data vectors over $(\\mathbb{Z}^d,+)$\nexpressibility directly corresponds to checking state equations for Coloured\nPetri nets where tokens can only be tested for equality. We derive that in this\ncase, expressibility is in NP, and in P for reversible instances. These upper\nbounds are tight: they match the lower bounds for standard integer vectors\n(over singleton domains).\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 15:05:48 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Hofman", "Piotr", ""], ["Leroux", "J\u00e9r\u00f4me", ""], ["Totzke", "Patrick", ""]]}, {"id": "1610.01669", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "Game Semantics for Martin-L\\\"of Type Theory", "comments": "This paper has been withdrawn by the author due to a crucial error on\n  linear implication between games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new game semantics for Martin-L\\\"of type theory (MLTT), our aim\nis to give a mathematical and intensional explanation of MLTT. Specifically, we\npropose a category with families of a novel variant of games, which induces a\nsurjective and injective (when Id-types are excluded) interpretation of the\nintensional variant of MLTT equipped with unit-, empty-, N-, dependent product,\ndependent sum and Id-types as well as the cumulative hierarchy of universes for\nthe first time in the literature (as far as we are aware), though the\nsurjectivity is accomplished merely by an inductive definition of a certain\nclass of games and strategies. Our games generalize the existing notion of\ngames, and achieve an interpretation of dependent types and the hierarchy of\nuniverses in an intuitive yet mathematically precise manner, our strategies can\nbe seen as algorithms underlying programs (or proofs) in MLTT. A more\nfine-grained interpretation of Id-types is left as future work.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 21:56:27 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2016 11:40:59 GMT"}, {"version": "v3", "created": "Thu, 9 Feb 2017 18:56:12 GMT"}, {"version": "v4", "created": "Thu, 23 Feb 2017 14:16:01 GMT"}, {"version": "v5", "created": "Thu, 4 May 2017 16:26:04 GMT"}, {"version": "v6", "created": "Mon, 8 May 2017 13:28:30 GMT"}, {"version": "v7", "created": "Thu, 17 Jun 2021 12:24:10 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1610.02101", "submitter": "Tomer Kotek", "authors": "Shachar Itzhaky, Tomer Kotek, Noam Rinetzky, Mooly Sagiv, Orr Tamir,\n  Helmut Veith, Florian Zuleger", "title": "On the automated verification of web applications with embedded SQL", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of web applications is based on a relational database together\nwith a program, typically a script, that enables the user to interact with the\ndatabase through embedded SQL queries and commands. In this paper, we introduce\na method for formal automated verification of such systems which connects\ndatabase theory to mainstream program analysis. We identify a fragment of SQL\nwhich captures the behavior of the queries in our case studies, is\nalgorithmically decidable, and facilitates the construction of weakest\npreconditions. Thus, we can integrate the analysis of SQL queries into a\nprogram analysis tool chain. To this end, we implement a new decision procedure\nfor the SQL fragment that we introduce. We demonstrate practical applicability\nof our results with three case studies, a web administrator, a simple firewall,\nand a conference management system.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 23:51:29 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Itzhaky", "Shachar", ""], ["Kotek", "Tomer", ""], ["Rinetzky", "Noam", ""], ["Sagiv", "Mooly", ""], ["Tamir", "Orr", ""], ["Veith", "Helmut", ""], ["Zuleger", "Florian", ""]]}, {"id": "1610.02247", "submitter": "Lucius Meredith", "authors": "Mike Stay, Lucius Gregory Meredith", "title": "Logic as a distributive law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an algorithm for deriving a spatial-behavioral type system from a\nformal presentation of a computational calculus. Given a 2-monad Calc:\nCatv$\\to$ Cat for the free calculus on a category of terms and rewrites and a\n2-monad BoolAlg for the free Boolean algebra on a category, we get a 2-monad\nForm = BoolAlg + Calc for the free category of formulae and proofs. We also get\nthe 2-monad BoolAlg $\\circ$ Calc for subsets of terms. The interpretation of\nformulae is a natural transformation $\\interp{-}$: Form $\\Rightarrow$ BoolAlg\n$\\circ$ Calc defined by the units and multiplications of the monads and a\ndistributive law transformation $\\delta$: Calc $\\circ$ BoolAlg $\\Rightarrow$\nBoolAlg $\\circ$ Calc. This interpretation is consistent both with the\nCurry-Howard isomorphism and with realizability. We give an implementation of\nthe \"possibly\" modal operator parametrized by a two-hole term context and show\nthat, surprisingly, the arrow type constructor in the $\\lambda$-calculus is a\nspecific case. We also exhibit nontrivial formulae encoding confinement and\nliveness properties for a reflective higher-order variant of the\n$\\pi$-calculus.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 12:26:03 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 13:57:58 GMT"}, {"version": "v3", "created": "Sun, 16 Oct 2016 14:23:45 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Stay", "Mike", ""], ["Meredith", "Lucius Gregory", ""]]}, {"id": "1610.02260", "submitter": "Dieter Spreen", "authors": "Dieter Spreen", "title": "Generalised Information Systems Capture L-Domains", "comments": "Typo removed", "journal-ref": null, "doi": "10.1016/j.tcs.2020.12.044", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalisation of Scott's information systems \\cite{sco82} is presented\nthat captures exactly all L-domains. The global consistency predicate in\nScott's definition is relativised in such a way that there is a consistency\npredicate for each atomic proposition (token) saying which finite sets of such\nstatements express information that is consistent with the given statement.\n  It is shown that the states of such generalised information systems form an\nL-domain, and that each L-domain can be generated in this way, up to\nisomorphism. Moreover, the equivalence of the category of generalised\ninformation systems with the category of L-domains is derived. In addition, it\nwill be seen that from every generalised information system capturing an\nalgebraic bounded-complete domain a corresponding Scott information system can\nbe obtained in an easy and natural way, and vice versa; similarly for Hoofman's\ncontinuous information systems \\cite{ho93} and the continuous bounded-complete\ndomains captured by them; for Chen and Jung's disjunctive propositional logic\n\\cite{cj06} and algebraic L-domains (as well as for Wang and Li's \\cite{wll20}\nfinitary version and Lawson-compact algebraic L-domains); and for Wang and Li's\nconjunctive sequent calculi \\cite{wlbc20} and proper continuous\nbounded-complete domains. The proofs always contain syntactic translations\nbetween the logical calculi involved.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 12:54:48 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 13:01:59 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 10:55:10 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 11:51:16 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Spreen", "Dieter", ""]]}, {"id": "1610.02327", "submitter": "Roly Perera", "authors": "Roly Perera, Deepak Garg, James Cheney", "title": "Causally consistent dynamic slicing", "comments": "in Proceedings of 27th International Conference on Concurrency Theory\n  (CONCUR 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a lattice-theoretic account of dynamic slicing for {\\pi}-calculus,\nbuilding on prior work in the sequential setting. For any run of a concurrent\nprogram, we exhibit a Galois connection relating forward slices of the start\nconfiguration to backward slices of the end configuration. We prove that, up to\nlattice isomorphism, the same Galois connection arises for any causally\nequivalent execution, allowing an efficient concurrent implementation of\nslicing via a standard interleaving semantics. Our approach has been formalised\nin the dependently-typed language Agda.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 15:35:30 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Perera", "Roly", ""], ["Garg", "Deepak", ""], ["Cheney", "James", ""]]}, {"id": "1610.02364", "submitter": "J\\\"urgen Koslowski", "authors": "Ximeng Li, Xi Wu, Alberto Lluch Lafuente, Flemming Nielson, Hanne Riis\n  Nielson", "title": "A Coordination Language for Databases", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 17,\n  2017) lmcs:3205", "doi": "10.23638/LMCS-13(1:10)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coordination language for the modeling of distributed database\napplications. The language, baptized Klaim-DB, borrows the concepts of\nlocalities and nets of the coordination language Klaim but re-incarnates the\ntuple spaces of Klaim as databases. It provides high-level abstractions and\nprimitives for the access and manipulation of structured data, with integrity\nand atomicity considerations. We present the formal semantics of Klaim-DB and\ndevelop a type system that avoids potential runtime errors such as certain\nevaluation errors and mismatches of data format in tables, which are monitored\nin the semantics. The use of the language is illustrated in a scenario where\nthe sales from different branches of a chain of department stores are\naggregated from their local databases. Raising the abstraction level and\nencapsulating integrity checks in the language primitives have benefited the\nmodeling task considerably.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 18:21:20 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 07:47:12 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 09:05:13 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Ximeng", ""], ["Wu", "Xi", ""], ["Lafuente", "Alberto Lluch", ""], ["Nielson", "Flemming", ""], ["Nielson", "Hanne Riis", ""]]}, {"id": "1610.02500", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Probabilistic Process Algebra to Unifying Quantum and Classical\n  Computing in Closed Systems", "comments": "64 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have unified quantum and classical computing in open quantum systems\ncalled qACP which is a quantum generalization of process algebra ACP. But, an\naxiomatization for quantum and classical processes with an assumption of closed\nquantum systems is still missing. For closed quantum systems, unitary operator,\nquantum measurement and quantum entanglement are three basic components for\nquantum computing. This leads to probability unavoidable. Along the solution of\nqACP to unify quantum and classical computing in open quantum systems, we unify\nquantum and classical computing with an assumption of closed systems under the\nframework of ACP-like probabilistic process algebra. This unification make it\ncan be used widely in verification for quantum and classical computing mixed\nsystems, such as most quantum communication protocols.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 08:48:09 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1610.02634", "submitter": "Mani A", "authors": "A. Mani", "title": "On Deductive Systems of AC Semantics for Rough Sets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Antichain based semantics for general rough sets were introduced recently by\nthe present author. In her paper two different semantics, one for general rough\nsets and another for general approximation spaces over quasi-equivalence\nrelations, were developed. These semantics are improved and studied further\nfrom a lateral algebraic logic perspective in this research. The main results\nconcern the structure of the algebras and deductive systems in the context.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 06:42:20 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1610.02675", "submitter": "J\\\"urgen Koslowski", "authors": "Aleksy Schubert and Pawe{\\l} Urzyczyn and Konrad Zdanowski", "title": "On the Mints Hierarchy in First-Order Intuitionistic Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2623", "doi": "10.2168/LMCS-12(4:11)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We stratify intuitionistic first-order logic over $(\\forall,\\to)$ into\nfragments determined by the alternation of positive and negative occurrences of\nquantifiers (Mints hierarchy).\n  We study the decidability and complexity of these fragments. We prove that\neven the $\\Delta_2$ level is undecidable and that $\\Sigma_1$ is\nExpspace-complete. We also prove that the arity-bounded fragment of $\\Sigma_1$\nis complete for co-Nexptime.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 13:36:13 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 17:28:45 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2016 20:59:07 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Schubert", "Aleksy", ""], ["Urzyczyn", "Pawe\u0142", ""], ["Zdanowski", "Konrad", ""]]}, {"id": "1610.03052", "submitter": "Lihao Liang", "authors": "Lihao Liang, Paul E. McKenney, Daniel Kroening, Tom Melham", "title": "Verification of the Tree-Based Hierarchical Read-Copy Update in the\n  Linux Kernel", "comments": "This is a long version of a conference paper published in the 2018\n  Design, Automation and Test in Europe Conference (DATE)", "journal-ref": "Design, Automation and Test in Europe Conference (2018): 61-66", "doi": "10.23919/DATE.2018.8341980", "report-no": null, "categories": "cs.LO cs.DC cs.OS cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Read-Copy Update (RCU) is a scalable, high-performance Linux-kernel\nsynchronization mechanism that runs low-overhead readers concurrently with\nupdaters. Production-quality RCU implementations for multi-core systems are\ndecidedly non-trivial. Giving the ubiquity of Linux, a rare \"million-year\" bug\ncan occur several times per day across the installed base. Stringent validation\nof RCU's complex behaviors is thus critically important. Exhaustive testing is\ninfeasible due to the exponential number of possible executions, which suggests\nuse of formal verification.\n  Previous verification efforts on RCU either focus on simple implementations\nor use modeling languages, the latter requiring error-prone manual translation\nthat must be repeated frequently due to regular changes in the Linux kernel's\nRCU implementation. In this paper, we first describe the implementation of Tree\nRCU in the Linux kernel. We then discuss how to construct a model directly from\nTree RCU's source code in C, and use the CBMC model checker to verify its\nsafety and liveness properties. To our best knowledge, this is the first\nverification of a significant part of RCU's source code, and is an important\nstep towards integration of formal verification into the Linux kernel's\nregression test suite.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 19:59:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 17:15:33 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 17:40:49 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Liang", "Lihao", ""], ["McKenney", "Paul E.", ""], ["Kroening", "Daniel", ""], ["Melham", "Tom", ""]]}, {"id": "1610.03346", "submitter": "J\\\"urgen Koslowski", "authors": "Nicolai Kraus, Mart\\'in Escard\\'o, Thierry Coquand, Thorsten\n  Altenkirch", "title": "Notions of Anonymous Existence in Martin-L\\\"of Type Theory", "comments": "36 pages, to appear in the special issue of TLCA'13 (LMCS)", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 24,\n  2017) lmcs:3217", "doi": "10.23638/LMCS-13(1:15)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the groupoid model of Hofmann and Streicher proves, identity proofs in\nintensional Martin-L\\\"of type theory cannot generally be shown to be unique.\nInspired by a theorem by Hedberg, we give some simple characterizations of\ntypes that do have unique identity proofs. A key ingredient in these\nconstructions are weakly constant endofunctions on identity types. We study\nsuch endofunctions on arbitrary types and show that they always factor through\na propositional type, the truncated or squashed domain. Such a factorization is\nimpossible for weakly constant functions in general (a result by Shulman), but\nwe present several non-trivial cases in which it can be done. Based on these\nresults, we define a new notion of anonymous existence in type theory and\ncompare different forms of existence carefully. In addition, we show possibly\nsurprising consequences of the judgmental computation rule of the truncation,\nin particular in the context of homotopy type theory. All the results have been\nformalized and verified in the dependently typed programming language Agda.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 14:06:24 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 12:48:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kraus", "Nicolai", ""], ["Escard\u00f3", "Mart\u00edn", ""], ["Coquand", "Thierry", ""], ["Altenkirch", "Thorsten", ""]]}, {"id": "1610.03532", "submitter": "Xue-Ping Wang", "authors": "Peng He, Xue-ping Wang", "title": "On the uniqueness of $L$-fuzzy sets in the representation of families of\n  sets", "comments": "8pages", "journal-ref": "Fuzzy Sets and Systems, 2018, Vol.333: 28-35", "doi": "10.1016/j.fss.2017.05.023", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the uniqueness of $L$-fuzzy sets in the representation\nof a given family of subsets of nonempty set. It first shows a formula of the\nnumber of $L$-fuzzy sets whose collection of cuts coincides with a given family\nof subsets of a nonempty set, and then provides a necessary and sufficient\ncondition under which such $L$-fuzzy sets are unique.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 11:49:00 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 00:53:40 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 10:22:06 GMT"}, {"version": "v4", "created": "Thu, 3 Jan 2019 09:40:14 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["He", "Peng", ""], ["Wang", "Xue-ping", ""]]}, {"id": "1610.03592", "submitter": "Shay Moran", "authors": "Ofir David and Shay Moran and Amir Yehudayoff", "title": "On statistical learning via the lens of compression", "comments": "Appeared in NIPS '16 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work continues the study of the relationship between sample compression\nschemes and statistical learning, which has been mostly investigated within the\nframework of binary classification. The central theme of this work is\nestablishing equivalences between learnability and compressibility, and\nutilizing these equivalences in the study of statistical learning theory.\n  We begin with the setting of multiclass categorization (zero/one loss). We\nprove that in this case learnability is equivalent to compression of\nlogarithmic sample size, and that uniform convergence implies compression of\nconstant size.\n  We then consider Vapnik's general learning setting: we show that in order to\nextend the compressibility-learnability equivalence to this case, it is\nnecessary to consider an approximate variant of compression.\n  Finally, we provide some applications of the compressibility-learnability\nequivalences:\n  (i) Agnostic-case learnability and realizable-case learnability are\nequivalent in multiclass categorization problems (in terms of sample\ncomplexity).\n  (ii) This equivalence between agnostic-case learnability and realizable-case\nlearnability does not hold for general learning problems: There exists a\nlearning problem whose loss function takes just three values, under which\nagnostic-case and realizable-case learnability are not equivalent.\n  (iii) Uniform convergence implies compression of constant size in multiclass\ncategorization problems. Part of the argument includes an analysis of the\nuniform convergence rate in terms of the graph dimension, in which we improve\nupon previous bounds.\n  (iv) A dichotomy for sample compression in multiclass categorization\nproblems: If a non-trivial compression exists then a compression of logarithmic\nsize exists.\n  (v) A compactness theorem for multiclass categorization problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 03:46:00 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 18:30:27 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["David", "Ofir", ""], ["Moran", "Shay", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1610.03935", "submitter": "Ron van der Meyden", "authors": "Ron van der Meyden", "title": "Optimizing Epistemic Model Checking using Conditional Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional independence reasoning has been shown to be helpful in the\ncontext of Bayesian nets to optimize probabilistic inference, and related\ntechniques have been applied to speed up a number of logical reasoning tasks in\nboolean logic by eliminating irrelevant parts of the formulas. This paper shows\nthat conditional independence reasoning can also be applied to optimize\nepistemic model checking, in which one verifies that a model for a number of\nagents operating with imperfect information satisfies a formula expressed in a\nmodal multi-agent logic of knowledge. An optimization technique is developed\nthat precedes the use of a model checking algorithm with an analysis that\napplies conditional independence reasoning to reduce the size of the model. The\noptimization has been implemented in the epistemic model checker MCK. The paper\nreports experimental results demonstrating that it can yield multiple orders of\nmagnitude performance improvements.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 04:14:09 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["van der Meyden", "Ron", ""]]}, {"id": "1610.04388", "submitter": "Martin Zimmermann", "authors": "Bernd Finkbeiner and Martin Zimmermann", "title": "The First-Order Logic of Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the logical foundations of hyperproperties. Hyperproperties\ngeneralize trace properties, which are sets of traces, to sets of sets of\ntraces. The most prominent application of hyperproperties is information flow\nsecurity: information flow policies characterize the secrecy and integrity of a\nsystem by comparing two or more execution traces, for example by comparing the\nobservations made by an external observer on execution traces that result from\ndifferent values of a secret variable. In this paper, we establish the first\nconnection between temporal logics for hyperproperties and first-order logic.\nKamp's seminal theorem (in the formulation due to Gabbay et al.) states that\nlinear-time temporal logic (LTL) is expressively equivalent to first-order\nlogic over the natural numbers with order. We introduce first-order logic over\nsets of traces and prove that HyperLTL, the extension of LTL to\nhyperproperties, is strictly subsumed by this logic. We furthermore exhibit a\nfragment that is expressively equivalent to HyperLTL, thereby establishing\nKamp's theorem for hyperproperties.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 10:07:47 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 13:44:21 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1610.04591", "submitter": "Peter LeFanu Lumsdaine", "authors": "Andrej Bauer, Jason Gross, Peter LeFanu Lumsdaine, Mike Shulman,\n  Matthieu Sozeau, and Bas Spitters", "title": "The HoTT Library: A formalization of homotopy type theory in Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the development of the HoTT library, a formalization of homotopy\ntype theory in the Coq proof assistant. It formalizes most of basic homotopy\ntype theory, including univalence, higher inductive types, and significant\namounts of synthetic homotopy theory, as well as category theory and\nmodalities. The library has been used as a basis for several independent\ndevelopments. We discuss the decisions that led to the design of the library,\nand we comment on the interaction of homotopy type theory with recently\nintroduced features of Coq, such as universe polymorphism and private inductive\ntypes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 19:23:50 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 16:31:04 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Bauer", "Andrej", ""], ["Gross", "Jason", ""], ["Lumsdaine", "Peter LeFanu", ""], ["Shulman", "Mike", ""], ["Sozeau", "Matthieu", ""], ["Spitters", "Bas", ""]]}, {"id": "1610.04592", "submitter": "Xaver Newberry", "authors": "X.Y. Newberry", "title": "The Recursion Theorem from a Different Angle", "comments": "This paper has been superseded by \"Getting around the Halting\n  Problem\" https://arxiv.org/abs/1706.03392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about computability. I claim the likely existence of a program\nDoesHalt(Program, Input) such that DoesHalt( HaltsOnItself, AntiSelf ) halts\nwith resounding 'NO'. HaltsOnItself( Program ) is simply DoesHalt( Program,\nProgram ). AntiSelf() is a self-referential self-contradictory program that\nloops when HaltsOnItself() returns 'YES' and halts when HaltsOnItself() returns\n'NO'.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:46:51 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 19:57:09 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Newberry", "X. Y.", ""]]}, {"id": "1610.04641", "submitter": "Niki Vazou", "authors": "Niki Vazou and Ranjit Jhala", "title": "Refinement Reflection (or, how to turn your favorite language into a\n  proof assistant using SMT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refinement Reflection turns your favorite programming language into a proof\nassistant by reflecting the code implementing a user-defined function into the\nfunction's (output) refinement type. As a consequence, at uses of the function,\nthe function definition is unfolded into the refinement logic in a precise,\npredictable and most importantly, programmer controllable way. In the logic, we\nencode functions and lambdas using uninterpreted symbols preserving SMT-based\ndecidable verification. In the language, we provide a library of combinators\nthat lets programmers compose proofs from basic refinements and function\ndefinitions. We have implemented our approach in the Liquid Haskell system,\nthereby converting Haskell into an interactive proof assistant, that we used to\nverify a variety of properties ranging from arithmetic properties of higher\norder, recursive functions to the Monoid, Applicative, Functor and Monad type\nclass laws for a variety of instances.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 21:04:26 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Vazou", "Niki", ""], ["Jhala", "Ranjit", ""]]}, {"id": "1610.04707", "submitter": "Radu Iosif", "authors": "Andrew Reynolds and Radu Iosif and Cristina Serban", "title": "Reasoning in the Bernays-Schoenfinkel-Ramsey Fragment of Separation\n  Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation Logic (SL) is a well-known assertion language used in Hoare-style\nmodular proof systems for programs with dynamically allocated data structures.\nIn this paper we investigate the fragment of first-order SL restricted to the\nBernays-Schoenfinkel-Ramsey quantifier prefix $\\exists^*\\forall^*$, where the\nquantified variables range over the set of memory locations. When this set is\nuninterpreted (has no associated theory) the fragment is PSPACE-complete, which\nmatches the complexity of the quantifier-free fragment. However, SL becomes\nundecidable when the quantifier prefix belongs to $\\exists^*\\forall^*\\exists^*$\ninstead, or when the memory locations are interpreted as integers with linear\narithmetic constraints, thus setting a sharp boundary for decidability within\nSL. We have implemented a decision procedure for the decidable fragment of\n$\\exists^*\\forall^*$SL as a specialized solver inside a DPLL($T$) architecture,\nwithin the CVC4 SMT solver. The evaluation of our implementation was carried\nout using two sets of verification conditions, produced by (i) unfolding\ninductive predicates, and (ii) a weakest precondition-based verification\ncondition generator. Experimental data shows that automated quantifier\ninstantiation has little overhead, compared to manual model-based\ninstantiation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 09:42:36 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 10:06:03 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Reynolds", "Andrew", ""], ["Iosif", "Radu", ""], ["Serban", "Cristina", ""]]}, {"id": "1610.04761", "submitter": "Lucas Carvalho Cordeiro", "authors": "Alessandro Abate, Iury Bessa, Dario Cattaruzza, Lucas Cordeiro,\n  Cristina David, Pascal Kesseli and Daniel Kroening", "title": "Sound and Automated Synthesis of Digital Stabilizing Controllers for\n  Continuous Plants", "comments": "10 pages", "journal-ref": "20th ACM International Conference on Hybrid Systems: Computation\n  and Control (HSCC 2017)", "doi": "10.1145/3049797.3049802", "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern control is implemented with digital microcontrollers, embedded within\na dynamical plant that represents physical components. We present a new\nalgorithm based on counter-example guided inductive synthesis that automates\nthe design of digital controllers that are correct by construction. The\nsynthesis result is sound with respect to the complete range of approximations,\nincluding time discretization, quantization effects, and finite-precision\narithmetic and its rounding errors. We have implemented our new algorithm in a\ntool called DSSynth, and are able to automatically generate stable controllers\nfor a set of intricate plant models taken from the literature within minutes.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 16:34:47 GMT"}, {"version": "v2", "created": "Sat, 22 Oct 2016 13:19:31 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 15:13:02 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Abate", "Alessandro", ""], ["Bessa", "Iury", ""], ["Cattaruzza", "Dario", ""], ["Cordeiro", "Lucas", ""], ["David", "Cristina", ""], ["Kesseli", "Pascal", ""], ["Kroening", "Daniel", ""]]}, {"id": "1610.05064", "submitter": "Yanjun Li", "authors": "Yanjun Li and Yanjing Wang", "title": "Achieving while maintaining: A logic of knowing how with intermediate\n  constraints", "comments": "appear in Proceedings of ICLA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a ternary knowing how operator to express that the\nagent knows how to achieve $\\phi$ given $\\psi$ while maintaining $\\chi$\nin-between. It generalizes the logic of goal-directed knowing how proposed by\nYanjing Wang 2015 'A logic of knowing how'. We give a sound and complete\naxiomatization of this logic.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 12:01:03 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Li", "Yanjun", ""], ["Wang", "Yanjing", ""]]}, {"id": "1610.05072", "submitter": "Ga\\\"etan Gilbert", "authors": "Ga\\\"etan Gilbert", "title": "Formalising Real Numbers in Homotopy Type Theory", "comments": "Submitted to CPP 2017", "journal-ref": null, "doi": "10.1145/3018610.3018614", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cauchy reals can be defined as a quotient of Cauchy sequences of rationals.\nThe limit of a Cauchy sequence of Cauchy reals is defined through lifting it to\na sequence of Cauchy sequences of rationals. This lifting requires the axiom of\ncountable choice or excluded middle, neither of which is available in homotopy\ntype theory. To address this, the Univalent Foundations Program uses a higher\ninductive-inductive type to define the Cauchy reals as the free Cauchy complete\nmetric space generated by the rationals. We generalize this construction to\ndefine the free Cauchy complete metric space generated by an arbitrary metric\nspace. This forms a monad in the category of metric spaces with Lipschitz\nfunctions. When applied to the rationals it defines the Cauchy reals. Finally,\nwe can use Altenkirch and Danielson (2016)'s partiality monad to define a\nsemi-decision procedure comparing a real number and a rational number.\n  The entire construction has been formalized in the Coq proof assistant. It is\navailable at https://github.com/SkySkimmer/HoTTClasses/tree/CPP2017 .\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 12:25:48 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 11:41:53 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Gilbert", "Ga\u00ebtan", ""]]}, {"id": "1610.05156", "submitter": "J\\\"urgen Koslowski", "authors": "Thomas Genet, Yann Salmon", "title": "Reachability Analysis of Innermost Rewriting", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 22,\n  2017) lmcs:3211", "doi": "10.23638/LMCS-13(1:12)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring a grammar describing the output of a\nfunctional program given a grammar describing its input. Solutions to this\nproblem are helpful for detecting bugs or proving safety properties of\nfunctional programs, and several rewriting tools exist for solving this\nproblem. However, known grammar inference techniques are not able to take\nevaluation strategies of the program into account. This yields very imprecise\nresults when the evaluation strategy matters. In this work, we adapt the Tree\nAutomata Completion algorithm to approximate accurately the set of terms\nreachable by rewriting under the innermost strategy. We formally prove that the\nproposed technique is sound and precise w.r.t. innermost rewriting. We show\nthat those results can be extended to the leftmost and rightmost innermost\ncase. The algorithms for the general innermost case have been implemented in\nthe Timbuk reachability tool. Experiments show that it noticeably improves the\naccuracy of static analysis for functional programs using the call-by-value\nevaluation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 15:07:31 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 10:30:09 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Genet", "Thomas", ""], ["Salmon", "Yann", ""]]}, {"id": "1610.05270", "submitter": "Bas Spitters", "authors": "Bas Spitters", "title": "Cubical sets and the topological topos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coquand's cubical set model for homotopy type theory provides the basis for a\ncomputational interpretation of the univalence axiom and some higher inductive\ntypes, as implemented in the cubical proof assistant. This paper contributes to\nthe understanding of this model. We make three contributions:\n  1. Johnstone's topological topos was created to present the geometric\nrealization of simplicial sets as a geometric morphism between toposes.\nJohnstone shows that simplicial sets classify strict linear orders with\ndisjoint endpoints and that (classically) the unit interval is such an order.\nHere we show that it can also be a target for cubical realization by showing\nthat Coquand's cubical sets classify the geometric theory of flat distributive\nlattices. As a side result, we obtain a simplicial realization of a cubical\nset.\n  2. Using the internal `interval' in the topos of cubical sets, we construct a\nMoore path model of identity types.\n  3. We construct a premodel structure internally in the cubical type theory\nand hence on the fibrant objects in cubical sets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 19:11:16 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Spitters", "Bas", ""]]}, {"id": "1610.05551", "submitter": "Giso Dal", "authors": "Giso H. Dal and Peter J.F. Lucas", "title": "Weighted Positive Binary Decision Diagrams for Exact Probabilistic\n  Inference", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on weighted model counting has been very successfully applied to\nthe problem of probabilistic inference in Bayesian networks. The probability\ndistribution is encoded into a Boolean normal form and compiled to a target\nlanguage, in order to represent local structure expressed among conditional\nprobabilities more efficiently. We show that further improvements are possible,\nby exploiting the knowledge that is lost during the encoding phase and\nincorporating it into a compiler inspired by Satisfiability Modulo Theories.\nConstraints among variables are used as a background theory, which allows us to\noptimize the Shannon decomposition. We propose a new language, called Weighted\nPositive Binary Decision Diagrams, that reduces the cost of probabilistic\ninference by using this decomposition variant to induce an arithmetic circuit\nof reduced size.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 11:58:28 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Dal", "Giso H.", ""], ["Lucas", "Peter J. F.", ""]]}, {"id": "1610.05593", "submitter": "Yuhui Lin", "authors": "Yuhui Lin, Gudmund Grov and Rob Arthan", "title": "Understanding and maintaining tactics graphically OR how we are learning\n  that a diagram can be worth more than 10K LoC", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of a functional language to implement proof strategies as proof\ntactics in interactive theorem provers, often provides short, concise and\nelegant implementations. Whilst being elegant, the use of higher order features\nand combinator languages often results in a very procedural view of a strategy,\nwhich may deviate significantly from the high-level ideas behind it. This can\nmake a tactic hard to understand and hence difficult to to debug and maintain\nfor experts and non-experts alike: one often has to tear apart complex\ncombinations of lower level tactics manually in order to analyse a failure in\nthe overall strategy. In an industrial technology transfer project, we have\nbeen working on porting a very large and complex proof tactic into PSGraph, a\ngraphical language for representing proof strategies, supported by the Tinker\ntool. The goal of this work is to improve understandability and maintainability\nof tactics. Motivated by some initial successes with this, we here extend\nPSGraph with additional features for development and debugging. Through the\nre-implementation and refactoring of several existing tactics, we demonstrates\nthe advantages of PSGraph compared with a typical linear (term-based) tactic\nlanguage with respect to debugging, readability and maintenance. In order to\nact as guidance for others, we give a fairly detailed comparison of the user\nexperience with the two approaches. The paper is supported by a web page\nproviding further details about the implementation as well as interactive\nillustrations of the examples.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 10:17:01 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 11:04:30 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Lin", "Yuhui", ""], ["Grov", "Gudmund", ""], ["Arthan", "Rob", ""]]}, {"id": "1610.05867", "submitter": "Andreas Katis", "authors": "Andreas Katis, Grigory Fedyukovich, Andrew Gacek, John Backes, Arie\n  Gurfinkel, Michael W. Whalen", "title": "Synthesis from Assume-Guarantee Contracts using Skolemized Proofs of\n  Realizability", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The realizability problem in requirements engineering is to determine the\nexistence of an implementation that meets the given formal requirements. A step\nforward after realizability is proven, is to construct such an implementation\nautomatically, and thus solve the problem of program synthesis. In this paper,\nwe propose a novel approach to pro- gram synthesis guided by k-inductive proofs\nof realizability of assume- guarantee contracts constructed from safety\nproperties. The proof of re- alizability is performed over a set of\nforall-exists formulas, and synthesis is per- formed by extracting Skolem\nfunctions witnessing the existential quan- tification. These Skolem functions\ncan then be combined into an imple- mentation. Our approach is implemented in\nthe JSyn tool which con- structs Skolem functions from a contract written in a\nvariant of the Lus- tre programming language and then compiles the Skolem\nfunctions into a C language implementation. For a variety of benchmark models\nthat already contained hand-written implementations, we are able to identify\nthe usability and effectiveness of the synthesized counterparts, assuming a\ncomponent-based verification framework.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 05:17:59 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 18:26:11 GMT"}, {"version": "v3", "created": "Thu, 15 Jun 2017 16:26:10 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Katis", "Andreas", ""], ["Fedyukovich", "Grigory", ""], ["Gacek", "Andrew", ""], ["Backes", "John", ""], ["Gurfinkel", "Arie", ""], ["Whalen", "Michael W.", ""]]}, {"id": "1610.06162", "submitter": "J\\\"urgen Koslowski", "authors": "Daniel Gebler, Kim G. Larsen, Simone Tini", "title": "Compositional bisimulation metric reasoning with Probabilistic Process\n  Calculi", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2627", "doi": "10.2168/LMCS-12(4:12)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study which standard operators of probabilistic process calculi allow for\ncompositional reasoning with respect to bisimulation metric semantics. We argue\nthat uniform continuity (generalizing the earlier proposed property of\nnon-expansiveness) captures the essential nature of compositional reasoning and\nallows now also to reason compositionally about recursive processes. We\ncharacterize the distance between probabilistic processes composed by standard\nprocess algebra operators. Combining these results, we demonstrate how\ncompositional reasoning about systems specified by continuous process algebra\noperators allows for metric assume-guarantee like performance validation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 19:42:32 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 16:12:02 GMT"}, {"version": "v3", "created": "Fri, 30 Dec 2016 16:57:40 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Gebler", "Daniel", ""], ["Larsen", "Kim G.", ""], ["Tini", "Simone", ""]]}, {"id": "1610.06229", "submitter": "Marijn Heule", "authors": "Marijn J. H. Heule", "title": "The DRAT format and DRAT-trim checker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the DRAT format for clausal proofs and the DRAT-trim\nproof checker.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 21:29:08 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Heule", "Marijn J. H.", ""]]}, {"id": "1610.06317", "submitter": "Zhenqi Huang", "authors": "Chuchu Fan and Zhenqi Huang and Sayan Mitra", "title": "Approximate Partial Order Reduction", "comments": "23 pages, 5 figures. Accepted at 22nd International Symposium on\n  Formal Methods (FM 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new partial order reduction method for reachability analysis of\nnondeterministic labeled transition systems over metric spaces. Nondeterminism\narises from both the choice of the initial state and the choice of actions, and\nthe number of executions to be explored grows exponentially with their length.\nWe introduce a notion of $\\varepsilon$-independence relation over actions that\nrelate approximately commutative actions; $\\varepsilon$-equivalent action\nsequences are obtained by swapping $\\varepsilon$-independent consecutive action\npairs. Our reachability algorithm generalizes individual executions to cover\nsets of executions that start from different, but $\\delta$-close initial\nstates, and follow different, but $\\varepsilon$-independent, action sequences.\nThe constructed over-approximations can be made arbitrarily precise by reducing\nthe $\\delta,\\varepsilon$ parameters. Exploiting both the continuity of actions\nand their approximate independence, the algorithm can yield an exponential\nreduction in the number of executions explored. We illustrate this with\nexperiments on consensus, platooning, and distributed control examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 07:53:48 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 04:26:29 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 20:45:45 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Fan", "Chuchu", ""], ["Huang", "Zhenqi", ""], ["Mitra", "Sayan", ""]]}, {"id": "1610.06362", "submitter": "Christoph Rauch", "authors": "Paula Severi and Luca Padovani and Emilio Tuosto and Mariangiola\n  Dezani-Ciancaglini", "title": "On Sessions and Infinite Data", "comments": "39 pages 6 files including .bbl", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (June 20,\n  2017) lmcs:3725", "doi": "10.23638/LMCS-13(2:9)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a novel calculus that combines a call-by-name functional core with\nsession-based communication primitives. We develop a typing discipline that\nguarantees both normalisation of expressions and progress of processes and that\nuncovers an unexpected interplay between evaluation and communication.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 11:21:11 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 10:13:19 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 16:50:27 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Severi", "Paula", ""], ["Padovani", "Luca", ""], ["Tuosto", "Emilio", ""], ["Dezani-Ciancaglini", "Mariangiola", ""]]}, {"id": "1610.06393", "submitter": "Luigi Santocanale", "authors": "Luigi Santocanale (LIF)", "title": "$\\mu$-Bicomplete Categories and Parity Games", "comments": "Unfortunately, it appears that LaBRI has not kept a copy of this\n  document. An email sent to director of this institution enquiring where are\n  kept the reports before 2005 has not received an answer. A shortened version\n  of this report has been published as RAIRO-Theor. Inf. Appl., Volume 36,\n  Number 2, April/June 2002, Fixed Points in Computer Science (FICS'01) Page(s)\n  195 - 22. DOI http://dx.doi.org/10.1051/ita:2002010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an arbitrary category, we consider the least class of functors con-\ntaining the projections and closed under finite products, finite coproducts,\nparameterized initial algebras and parameterized final coalgebras, i.e. the\nclass of functors that are definable by $\\mu$-terms. We call the category\n$\\mu$-bicomplete if every $\\mu$-term defines a functor. We provide concrete ex-\namples of such categories and explicitly characterize this class of functors\nfor the category of sets and functions. This goal is achieved through par- ity\ngames: we associate to each game an algebraic expression and turn the game into\na term of a categorical theory. We show that $\\mu$-terms and parity games are\nequivalent, meaning that they define the same property of being\n$\\mu$-bicomplete. Finally, the interpretation of a parity game in the category\nof sets is shown to be the set of deterministic winning strategies for a chosen\nplayer.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 13:14:52 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Santocanale", "Luigi", "", "LIF"]]}, {"id": "1610.06399", "submitter": "Pierre Vial", "authors": "Pierre Vial", "title": "Representing permutations without permutations, or the expressive power\n  of sequence types", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works by Asada, Ong and Tsukada have championed a rigid description of\nresources. Whereas in non-rigid paradigms (e.g., standard Taylor expansion or\nnon-idempotent intersection types), bags of resources are multisets and\ninvariant under permutation, in the rigid ones, permutations must be processed\nexplicitly and can be allowed or disallowed. Rigidity enables a fine-grained\ncontrol of reduction paths and their effects on e.g., typing derivations. We\npreviously introduced a very constrained coinductive type system (system S) in\nwhich permutation is completely disallowed. One may wonder in what extent the\nabsence of permutations causes a loss of expressivity w.r.t. reduction paths,\ncompared to a usual multiset framework or a rigid one allowing permutations. We\nanswer this question in the most general case i.e. coinductive type grammars\nwithout validity conditions. Our main contribution is to prove that not only\nevery non-idempotent derivation can be represented by a rigid, permutation-free\nderivation, but also that any dynamic behavior may be captured in this way. In\nother words, we prove that system S has full expressive power over\nmultiset/permutation-inclusive intersection.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 13:25:55 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 10:40:11 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Vial", "Pierre", ""]]}, {"id": "1610.06409", "submitter": "Pierre Vial", "authors": "Pierre Vial", "title": "Infinitary Intersection Types as Sequences: a New Answer to Klop's\n  Question", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a type-theoretical characterization of weakly-normalizing terms in\nan infinitary lambda-calculus. We adapt for this purpose the standard\nquantitative (with non-idempotent intersections) type assignment system of the\nlambda-calculus to our infinite calculus. Our work provides a new answer to\nKlop's HHN-problem, namely, finding out if there is a type system\ncharacterizing the hereditary head-normalizing (HHN) lambda-terms. Tatsuta\nshowed that HHN could not be characterized by a finite type system. We prove\nthat an infinitary type system endowed with a validity condition called\napproximability can achieve it.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 13:40:58 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Vial", "Pierre", ""]]}, {"id": "1610.06552", "submitter": "Fei Yang", "authors": "Bas Luttik and Fei Yang", "title": "Reactive Turing Machines with Infinite Alphabets", "comments": "Submitted to ICALP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of Reactive Turing machine (RTM) was proposed as an orthogonal\nextension of Turing machines with interaction. RTMs are used to define the\nnotion of executable transition system in the same way as Turing machines are\nused to define the notion of computable function on natural numbers. RTMs\ninherited finiteness of all sets involved from Turing machines, and as a\nconsequence, in a single step, an RTM can only communicate elements from a\nfinite set of data. Some process calculi, such as the pi-calculus, essentially\ndepend on an infinite alphabet of actions, and hence it immediately follows\nthat transition systems specified in these calculi are not executable. On\ncloser inspection, however, the pi-calculus does not appear to use the infinite\ndata in a non-computable manner.\n  In this paper, we investigate several ways to relax the finiteness\nrequirement. We start by considering a variant of RTMs in which all sets are\nallowed to be countable, and we get a notion of infinitary RTM. Infinitary RTMs\nare extremely expressive such that we can hardly use them as a expressiveness\ncriterion. Then, we refine the model by adding extra restrictions. As a result,\nwe define a notion of RTM with atoms. It is a more restricted variant of RTMs\nin which the sets of actions and data symbols are still allowed to be infinite.\nWe propose a notion of of nominal executability based on RTMs with atoms, and\nshow that every effective transition system with atoms is nominally executable.\nIt will follow that processes definable in the pi-calculus are nominally\nexecutable. In contrast, in the process specification language mCRL2 it is\npossible to specify processes that are not nominally executable. Thus, nominal\nexecutability provides a new expressiveness criterion for process calculi.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 19:38:54 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 16:52:37 GMT"}, {"version": "v3", "created": "Mon, 20 Feb 2017 10:32:50 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Luttik", "Bas", ""], ["Yang", "Fei", ""]]}, {"id": "1610.06715", "submitter": "Jonathan Behaegel", "authors": "Jonathan Behaegel, Jean-Paul Comet and Maxime Folschette", "title": "A Hybrid Hoare Logic for Gene Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main difficulty when modelling gene networks is the identification of the\nparameters that govern their dynamics. It is particularly difficult for models\nin which time is continuous: parameters have real values which cannot be\nenumerated. The widespread idea is to infer new constraints that reduce the\nrange of possible values. Here we present a new work based on a particular\nclass of Hybrid automata (inspired by Thomas discrete models) where discrete\nparameters are replaced by signed celerities. We propose a new approach\ninvolving Hoare logic and weakest precondition calculus (a la Dijkstra) that\ngenerates constraints on the parameter values. Indeed, once proper\nspecifications are extracted from biological traces with duration information\n(found in the literature or biological experiments), they play a role similar\nto imperative programs in the classical Hoare logic. We illustrate our hybrid\nHoare logic on a small model controlling the lacI repressor of the lactose\noperon.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 09:30:12 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Behaegel", "Jonathan", ""], ["Comet", "Jean-Paul", ""], ["Folschette", "Maxime", ""]]}, {"id": "1610.06984", "submitter": "Joao Marques-Silva", "authors": "Lu\\'is Cruz-Filipe and Joao Marques-Silva and Peter Schneider-Kamp", "title": "Efficient Certified Resolution Proof Checking", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-54577-5_7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel propositional proof tracing format that eliminates complex\nprocessing, thus enabling efficient (formal) proof checking. The benefits of\nthis format are demonstrated by implementing a proof checker in C, which\noutperforms a state-of-the-art checker by two orders of magnitude. We then\nformalize the theory underlying propositional proof checking in Coq, and\nextract a correct-by-construction proof checker for our format from the\nformalization. An empirical evaluation using 280 unsatisfiable instances from\nthe 2015 and 2016 SAT competitions shows that this certified checker usually\nperforms comparably to a state-of-the-art non-certified proof checker. Using\nthis format, we formally verify the recent 200 TB proof of the Boolean\nPythagorean Triples conjecture.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 01:43:43 GMT"}, {"version": "v2", "created": "Sat, 29 Oct 2016 16:23:56 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Marques-Silva", "Joao", ""], ["Schneider-Kamp", "Peter", ""]]}, {"id": "1610.06996", "submitter": "Bohua Zhan", "authors": "Bohua Zhan", "title": "Efficient verification of imperative programs using auto2", "comments": "17 pages, accepted for TACAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto2 is a recently introduced prover for the proof assistant Isabelle. It is\ndesigned to be both highly customizable from within Isabelle, and also have a\npowerful proof search mechanism. In this paper, we apply auto2 to the\nverification of imperative programs. We describe the setup of auto2 for both\nstages of the proof process: verification of a functional version of the\nprogram, and refining to the imperative version using separation logic. As\nexamples, we verify several data structures, including red-black trees,\ninterval trees, priority queues, and union-find. We also verify several\nalgorithms making use of these data structures. These examples show that our\nframework is able to verify complex algorithms efficiently and in a modular\nmanner.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 04:18:54 GMT"}, {"version": "v2", "created": "Sun, 22 Oct 2017 09:58:18 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 13:00:23 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhan", "Bohua", ""]]}, {"id": "1610.07041", "submitter": "Christoph Matheja", "authors": "Christina Jansen, Jens Katelaan, Christoph Matheja, Thomas Noll,\n  Florian Zuleger", "title": "Unified Reasoning about Robustness Properties of Symbolic-Heap\n  Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce heap automata, a formalism for automatic reasoning about\nrobustness properties of the symbolic heap fragment of separation logic with\nuser-defined inductive predicates. Robustness properties, such as\nsatisfiability, reachability, and acyclicity, are important for a wide range of\nreasoning tasks in automated program analysis and verification based on\nseparation logic. Previously, such properties have appeared in many places in\nthe separation logic literature, but have not been studied in a systematic\nmanner. In this paper, we develop an algorithmic framework based on heap\nautomata that allows us to derive asymptotically optimal decision procedures\nfor a wide range of robustness properties in a uniform way. We implemented a\nprotoype of our framework and obtained promising results for all of the\naforementioned robustness properties. Further, we demonstrate the applicability\nof heap automata beyond robustness properties. We apply our algorithmic\nframework to the model checking and the entailment problem for symbolic-heap\nseparation logic.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 12:14:13 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Jansen", "Christina", ""], ["Katelaan", "Jens", ""], ["Matheja", "Christoph", ""], ["Noll", "Thomas", ""], ["Zuleger", "Florian", ""]]}, {"id": "1610.07066", "submitter": "Lucas Carvalho Cordeiro", "authors": "Lennon Chaves, Iury Bessa, Lucas Cordeiro and Daniel Kroening", "title": "DSValidator: An Automated Counterexample Reproducibility Tool for\n  Digital Systems (Tool Demonstration)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated counterexample reproducibility tool based on MATLAB is\npresented, called DSValidator, with the goal of reproducing counterexamples\nthat refute specific properties related to digital systems. We exploit\ncounterexamples generated by the Digital System Verifier (DSVerifier), which is\na model checking tool based on satisfiability modulo theories for digital\nsystems. DSValidator reproduces the execution of a digital system, relating its\ninput with the counterexample, in order to establish trust in a verification\nresult. We show that DSValidator can validate a set of intricate\ncounterexamples for digital controllers used in a real quadrotor attitude\nsystem within seconds and also expose incorrect verification results in\nDSVerifier. The resulting toolbox leverages the potential of combining\ndifferent verification tools for validating digital systems via an exchangeable\ncounterexample format.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 15:32:07 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 13:34:04 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Chaves", "Lennon", ""], ["Bessa", "Iury", ""], ["Cordeiro", "Lucas", ""], ["Kroening", "Daniel", ""]]}, {"id": "1610.07080", "submitter": "Raphael Khoury", "authors": "Yannick Lebrun, Rapha\\\"el Khoury, Sylvain Hall\\'e", "title": "An Alternating Automaton for First-Order Linear Temporal Logic--Tech\n  Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give automata-based representation of LTL-FO$^+$ properties.\nLTL-FO$^+$ is an extension of LTL that includes first-order quantification over\nbounded variable, thus greatly increasing the expressivity of the language. An\nautomata representation of this formalism allows greater ease in writing and\nunderstanding properties, as well as in performing manipulations, such as\nnegation or emptiness checking. The automata representation of an LTL-FO$^+$\nformula has finite size regardless of the domain of quantified variables, and\nthe number of states that is linear in the size of the property.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 17:32:41 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Lebrun", "Yannick", ""], ["Khoury", "Rapha\u00ebl", ""], ["Hall\u00e9", "Sylvain", ""]]}, {"id": "1610.07145", "submitter": "J\\\"urgen Koslowski", "authors": "Nicola Botta, Patrik Jansson, Cezar Ionescu, David R. Christiansen,\n  Edwin Brady", "title": "Sequential decision problems, dependent types and generic solutions", "comments": "23 pages, 2 figures", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 17,\n  2017) lmcs:3202", "doi": "10.23638/LMCS-13(1:7)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computer-checked generic implementation for solving\nfinite-horizon sequential decision problems. This is a wide class of problems,\nincluding inter-temporal optimizations, knapsack, optimal bracketing,\nscheduling, etc. The implementation can handle time-step dependent control and\nstate spaces, and monadic representations of uncertainty (such as stochastic,\nnon-deterministic, fuzzy, or combinations thereof). This level of genericity is\nachievable in a programming language with dependent types (we have used both\nIdris and Agda). Dependent types are also the means that allow us to obtain a\nformalization and computer-checked proof of the central component of our\nimplementation: Bellman's principle of optimality and the associated backwards\ninduction algorithm. The formalization clarifies certain aspects of backwards\ninduction and, by making explicit notions such as viability and reachability,\ncan serve as a starting point for a theory of controllability of monadic\ndynamical systems, commonly encountered in, e.g., climate impact research.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 10:53:18 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 09:40:34 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 09:01:55 GMT"}, {"version": "v4", "created": "Tue, 21 Mar 2017 14:47:59 GMT"}, {"version": "v5", "created": "Wed, 22 Mar 2017 14:04:56 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Botta", "Nicola", ""], ["Jansson", "Patrik", ""], ["Ionescu", "Cezar", ""], ["Christiansen", "David R.", ""], ["Brady", "Edwin", ""]]}, {"id": "1610.07390", "submitter": "Roberto Bagnara", "authors": "Roberto Bagnara, Michele Chiari, Roberta Gori, Abramo Bagnara", "title": "A Practical Approach to Interval Refinement for math.h/cmath Functions", "comments": "98 pages, 2 figures, 11 tables, 11 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of C++ programs has seen considerable progress in several areas,\nbut not for programs that use these languages' mathematical libraries. The\nreason is that all libraries in widespread use come with no guarantees about\nthe computed results. This would seem to prevent any attempt at formal\nverification of programs that use them: without a specification for the\nfunctions, no conclusion can be drawn statically about the behavior of the\nprogram. We propose an alternative to surrender. We introduce a pragmatic\napproach that leverages the fact that most math.h/cmath functions are almost\npiecewise monotonic: as we discovered through exhaustive testing, they may have\nglitches, often of very small size and in small numbers. We develop interval\nrefinement techniques for such functions based on a modified dichotomic search,\nthat enable verification via symbolic execution based model checking, abstract\ninterpretation, and test data generation. Our refinement algorithms are the\nfirst in the literature to be able to handle non-correctly rounded function\nimplementations, enabling verification in the presence of the most common\nimplementations. We experimentally evaluate our approach on real-world code,\nshowing its ability to detect or rule out anomalous behaviors.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 12:39:29 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 15:22:17 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 14:25:00 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Bagnara", "Roberto", ""], ["Chiari", "Michele", ""], ["Gori", "Roberta", ""], ["Bagnara", "Abramo", ""]]}, {"id": "1610.07535", "submitter": "Thomas Kern", "authors": "Thomas Kern", "title": "Generating the Functions with Regular Graphs under Composition", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While automata theory often concerns itself with regular predicates,\nrelations corresponding to acceptance by a finite state automaton, in this\narticle we study the regular functions, such relations which are also functions\nin the set-theoretic sense. Here we present a small (but necessarily infinite)\ncollection of (multi-ary) functions which generate the regular functions under\ncomposition. To this end, this paper presents an interpretation of the powerset\ndeterminization construction in terms of compositions of input-to-run maps.\nFurthermore, known results using the Krohn-Rhodes theorem to further decompose\nour generating set are spelled out in detail, alongside some coding tricks for\ndealing with variable length words. This will include two clear proofs of the\nKrohn-Rhodes Theorem in modern notation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 18:43:07 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Kern", "Thomas", ""]]}, {"id": "1610.07700", "submitter": "EPTCS", "authors": "Razieh Behjati (Simula Research Laboratory), Ahmed Elmokashfi (Simula\n  Research Laboratory)", "title": "Proceedings of the First International Workshop on Formal Methods for\n  and on the Cloud", "comments": null, "journal-ref": "EPTCS 228, 2016", "doi": "10.4204/EPTCS.228", "report-no": null, "categories": "cs.DC cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud solutions are increasingly used for a plethora of purposes, including\nsolving memory-intensive and computation-intensive problems. Ensuring the\nreliability, availability, scalability, and security of cloud solutions, as\nnetworked distributed systems with properties such as dynamic reallocation of\nresources, is a challenging problem that requires rigorous modeling, analysis,\nand verification tools. Such tools can be devised using the techniques provided\nby the formal methods community. On the other hand, many formal analysis and\nverification tools are memory-intensive and computation-intensive solutions,\nwhich can benefit from the cloud technology.\n  The goal of the iFMCloud workshop is to identify and better understand\nchallenges of using formal and semi-formal methods for modeling and\nverification of Cloud-based systems and computer and communication networks, as\nwell as challenges and opportunities in providing formal analysis and\nverification as services on the Cloud. We aim to reach these goals by bringing\ntogether researchers and practitioners from these, and other related fields.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 01:18:53 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Behjati", "Razieh", "", "Simula Research Laboratory"], ["Elmokashfi", "Ahmed", "", "Simula\n  Research Laboratory"]]}, {"id": "1610.07858", "submitter": "Mickael Randour", "authors": "Patricia Bouyer, Piotr Hofman, Nicolas Markey, Mickael Randour, Martin\n  Zimmermann", "title": "Bounding Average-energy Games", "comments": "Full version of FoSSaCS 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider average-energy games, where the goal is to minimize the long-run\naverage of the accumulated energy. While several results have been obtained on\nthese games recently, decidability of average-energy games with a lower-bound\nconstraint on the energy level (but no upper bound) remained open; in\nparticular, so far there was no known upper bound on the memory that is\nrequired for winning strategies.\n  By reducing average-energy games with lower-bounded energy to infinite-state\nmean-payoff games and analyzing the density of low-energy configurations, we\nshow an almost tight doubly-exponential upper bound on the necessary memory,\nand that the winner of average-energy games with lower-bounded energy can be\ndetermined in doubly-exponential time. We also prove EXPSPACE-hardness of this\nproblem.\n  Finally, we consider multi-dimensional extensions of all types of\naverage-energy games: without bounds, with only a lower bound, and with both a\nlower and an upper bound on the energy. We show that the fully-bounded version\nis the only case to remain decidable in multiple dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 13:22:10 GMT"}, {"version": "v2", "created": "Wed, 11 Jan 2017 13:37:45 GMT"}, {"version": "v3", "created": "Fri, 13 Jan 2017 16:13:08 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Bouyer", "Patricia", ""], ["Hofman", "Piotr", ""], ["Markey", "Nicolas", ""], ["Randour", "Mickael", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1610.07884", "submitter": "Maria Spichkova", "authors": "Maria Spichkova", "title": "Spatio-temporal features of FocusST", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report we summarise the spatio-temporal features and\npresent the core operators of FocusST specification framework. We present the\ngeneral idea of these operators, using a Steam Boiler System example to\nillustrate how the specification framework can be applied.\n  FocusST was inspired by Focus, a framework for formal specification and\ndevelopment of interactive systems. In contrast to Focus, FocusST is devoted to\nspecify and to analyse spatial (S) and timing (T) aspects of the systems, which\nis also reflected in the name of the framework: the extension ST highlights the\nspatio-temporal nature of the specifications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 14:10:55 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Spichkova", "Maria", ""]]}, {"id": "1610.08027", "submitter": "H{\\aa}kon Gylterud", "authors": "H{\\aa}kon Robbestad Gylterud", "title": "Multisets in Type Theory", "comments": null, "journal-ref": null, "doi": "10.1017/S0305004119000045", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A multiset consists of elements, but the notion of a multiset is\ndistinguished from that of a set by carrying information of how many times each\nelement occurs in a given multiset. In this work we will investigate the notion\nof iterative multisets, where multisets are iteratively built up from other\nmultisets, in the context Martin-L\\\"of Type Theory, in the presence of\nVoevodsky's Univalence Axiom.\n  Aczel 1978 introduced a model of constructive set theory in type theory,\nusing a W-type quantifying over a universe, and an inductively defined\nequivalence relation on it. Our investigation takes this W-type and instead\nconsiders the identity type on it, which can be computed from the Univalence\nAxiom. Our thesis is that this gives a model of multisets. In order to\ndemonstrate this, we adapt axioms of constructive set theory to multisets, and\nshow that they hold for our model.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 19:24:41 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Gylterud", "H\u00e5kon Robbestad", ""]]}, {"id": "1610.08116", "submitter": "Mirko Viroli", "authors": "Mirko Viroli, Giorgio Audrito, Ferruccio Damiani, Danilo Pianini,\n  Jacob Beal", "title": "A Higher-order Calculus of Computational Fields", "comments": "39 pages, 12 figures", "journal-ref": "ACM Transactions on Computational Logic (TOCL), 20(1), Article 5,\n  January 2019", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of large-scale distributed systems, particularly when deployed\nin physical space, calls for new mechanisms to address composability and\nreusability of collective adaptive behaviour. Computational fields have been\nproposed as an effective abstraction to fill the gap between the macro-level of\nsuch systems (specifying a system's collective behaviour) and the micro-level\n(individual devices' actions of computation and interaction to implement that\ncollective specification), thereby providing a basis to better facilitate the\nengineering of collective APIs and complex systems at higher levels of\nabstraction. This paper proposes a full formal foundation for field\ncomputations, in terms of a core (higher-order) calculus of computational\nfields containing a few key syntactic constructs, and equipped with typing,\ndenotational and operational semantics. Critically, this allows formal\nestablishment of a link between the micro- and macro-levels of collective\nadaptive systems, by a result of full abstraction and adequacy for the\n(aggregate) denotational semantics with respect to the (per-device) operational\nsemantics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 23:18:39 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Viroli", "Mirko", ""], ["Audrito", "Giorgio", ""], ["Damiani", "Ferruccio", ""], ["Pianini", "Danilo", ""], ["Beal", "Jacob", ""]]}, {"id": "1610.08167", "submitter": "EPTCS", "authors": "Vladimir Klebanov (KIT), Alexander Weigl (KIT), J\\\"org Weisbarth", "title": "Sound Probabilistic #SAT with Projection", "comments": "In Proceedings QAPL'16, arXiv:1610.07696", "journal-ref": "EPTCS 227, 2016, pp. 15-29", "doi": "10.4204/EPTCS.227.2", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved method for a sound probabilistic estimation of the\nmodel count of a boolean formula under projection. The problem solved can be\nused to encode a variety of quantitative program analyses, such as concerning\nsecurity of resource consumption. We implement the technique and discuss its\napplication to quantifying information flow in programs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 05:00:04 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Klebanov", "Vladimir", "", "KIT"], ["Weigl", "Alexander", "", "KIT"], ["Weisbarth", "J\u00f6rg", ""]]}, {"id": "1610.08169", "submitter": "EPTCS", "authors": "Valentina Castiglioni (University of Insubria), Daniel Gebler (VU\n  University Amsterdam), Simone Tini (University of Insubria)", "title": "Logical Characterization of Bisimulation Metrics", "comments": "In Proceedings QAPL'16, arXiv:1610.07696", "journal-ref": "EPTCS 227, 2016, pp. 44-62", "doi": "10.4204/EPTCS.227.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bisimulation metrics provide a robust and accurate approach to study the\nbehavior of nondeterministic probabilistic processes. In this paper, we propose\na logical characterization of bisimulation metrics based on a simple\nprobabilistic variant of the Hennessy-Milner logic. Our approach is based on\nthe novel notions of mimicking formulae and distance between formulae. The\nformer are a weak version of the well known characteristic formulae and allow\nus to characterize also (ready) probabilistic simulation and probabilistic\nbisimilarity. The latter is a 1-bounded pseudometric on formulae that mirrors\nthe Hausdorff and Kantorovich lifting the defining bisimilarity pseudometric.\nWe show that the distance between two processes equals the distance between\ntheir own mimicking formulae.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 05:00:25 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Castiglioni", "Valentina", "", "University of Insubria"], ["Gebler", "Daniel", "", "VU\n  University Amsterdam"], ["Tini", "Simone", "", "University of Insubria"]]}, {"id": "1610.08171", "submitter": "EPTCS", "authors": "Ludovica Luisa Vissat, Jane Hillston, Glenn Marion, Matthew J. Smith", "title": "MELA: Modelling in Ecology with Location Attributes", "comments": "In Proceedings QAPL'16, arXiv:1610.07696", "journal-ref": "EPTCS 227, 2016, pp. 82-97", "doi": "10.4204/EPTCS.227.6", "report-no": null, "categories": "cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ecology studies the interactions between individuals, species and the\nenvironment. The ability to predict the dynamics of ecological systems would\nsupport the design and monitoring of control strategies and would help to\naddress pressing global environmental issues. It is also important to plan for\nefficient use of natural resources and maintenance of critical ecosystem\nservices. The mathematical modelling of ecological systems often includes\nnontrivial specifications of processes that influence the birth, death,\ndevelopment and movement of individuals in the environment, that take into\naccount both biotic and abiotic interactions. To assist in the specification of\nsuch models, we introduce MELA, a process algebra for Modelling in Ecology with\nLocation Attributes. Process algebras allow the modeller to describe concurrent\nsystems in a high-level language. A key feature of concurrent systems is that\nthey are composed of agents that can progress simultaneously but also interact\n- a good match to ecological systems. MELA aims to provide ecologists with a\nstraightforward yet flexible tool for modelling ecological systems, with\nparticular emphasis on the description of space and the environment. Here we\npresent four example MELA models, illustrating the different spatial\narrangements which can be accommodated and demonstrating the use of MELA in\nepidemiological and predator-prey scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 05:00:42 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Vissat", "Ludovica Luisa", ""], ["Hillston", "Jane", ""], ["Marion", "Glenn", ""], ["Smith", "Matthew J.", ""]]}, {"id": "1610.08200", "submitter": "EPTCS", "authors": "Pavel Zaichenkov (University of Hertfordshire), Olga Tveretina\n  (University of Hertfordshire), Alex Shafarenko (University of Hertfordshire)", "title": "Configuring Cloud-Service Interfaces Using Flow Inheritance", "comments": "In Proceedings iFMCloud 2016, arXiv:1610.07700", "journal-ref": "EPTCS 228, 2016, pp. 27-34", "doi": "10.4204/EPTCS.228.4", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technologies for composition of loosely-coupled web services in a modular and\nflexible way are in high demand today. On the one hand, the services must be\nflexible enough to be reused in a variety of contexts. On the other hand, they\nmust be specific enough so that their composition may be provably consistent.\nThe existing technologies (WS-CDL, WSCI and session types) require a\nbehavioural contract associated with each service, which is impossible to\nderive automatically. Furthermore, neither technology supports flow\ninheritance: a mechanism that automatically and transparently propagates data\nthrough service pipelines. This paper presents a novel mechanism for automatic\ninterface configuration of such services. Instead of checking consistency of\nthe behavioural contracts, our approach focuses solely on that of data formats\nin the presence of subtyping, polymorphism and flow inheritance. The paper\npresents a toolchain that automatically derives service interfaces from the\ncode and performs interface configuration taking non-local constraints into\naccount. Although the configuration mechanism is global, the services are\ncompiled separately. As a result, the mechanism does not raise source security\nissues despite global service availability in adaptable form.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:52:13 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Zaichenkov", "Pavel", "", "University of Hertfordshire"], ["Tveretina", "Olga", "", "University of Hertfordshire"], ["Shafarenko", "Alex", "", "University of Hertfordshire"]]}, {"id": "1610.08201", "submitter": "EPTCS", "authors": "Nuno Oliveira (HASLab INESC TEX), Luis Soares Barbosa (HASLab INESC\n  TEC)", "title": "An Enhanced Model for Stochastic Coordination", "comments": "In Proceedings iFMCloud 2016, arXiv:1610.07700", "journal-ref": "EPTCS 228, 2016, pp. 35-45", "doi": "10.4204/EPTCS.228.5", "report-no": null, "categories": "cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications developed over the cloud coordinate several, often anonymous,\ncomputational resources, distributed over different execution nodes, within\nflexible architectures. Coordination models able to represent quantitative data\nprovide a powerful basis for their analysis and validation. This paper extends\nIMCreo, a semantic model for Stochastic reo based on interactive Markov chains,\nto enhance its scalability, by regarding each channel and node, as well as\ninterface components, as independent stochastic processes that may (or may not)\nsynchronise with the rest of the coordination circuit.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:52:22 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Oliveira", "Nuno", "", "HASLab INESC TEX"], ["Barbosa", "Luis Soares", "", "HASLab INESC\n  TEC"]]}, {"id": "1610.08241", "submitter": "Thorsten Wissmann", "authors": "Hans-E. Porst", "title": "Hopf and Lie algebras in semi-additive Varieties", "comments": "13 pages", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2,\n  Coalgebraic methods (May 8, 2017) lmcs:3315", "doi": "10.23638/LMCS-13(2:3)2017", "report-no": null, "categories": "math.RA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Hopf monoids in entropic semi-additive varieties with an emphasis on\nadjunctions related to the enveloping monoid functor and the primitive element\nfunctor. These investigations are based on the concept of the abelian core of a\nsemi-additive variety variety and its monoidal structure in case the variety is\nentropic.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 09:14:52 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 13:19:10 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 14:54:02 GMT"}, {"version": "v4", "created": "Thu, 4 May 2017 16:46:37 GMT"}, {"version": "v5", "created": "Fri, 5 May 2017 11:59:39 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Porst", "Hans-E.", ""]]}, {"id": "1610.08261", "submitter": "Shiv Kumar Kaushik Dr.", "authors": "Poonam Mantry and S.K.Kaushik", "title": "Computable g- Frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of g-frames for Hilbert spaces was introduced and studied by\nWenchang Sun [16] as a generalization of the notion of frames. In this paper,\nwe define computable g-frames in computable Hilbert spaces and obtain\ncomputable versions of some of their characterizations and related results.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 10:02:02 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Mantry", "Poonam", ""], ["Kaushik", "S. K.", ""]]}, {"id": "1610.08419", "submitter": "Christoph Rauch", "authors": "Chiara Bodei, Pierpaolo Degano, Gian-Luigi Ferrari and Letterio\n  Galletta", "title": "Tracing where IoT data are collected and aggregated", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (July 19,\n  2017) lmcs:3799", "doi": "10.23638/LMCS-13(3:5)2017", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) offers the infrastructure of the information\nsociety. It hosts smart objects that automatically collect and exchange data of\nvarious kinds, directly gathered from sensors or generated by aggregations.\nSuitable coordination primitives and analysis mechanisms are in order to design\nand reason about IoT systems, and to intercept the implied technological\nshifts. We address these issues from a foundational point of view. To study\nthem, we define IoT-LySa, a process calculus endowed with a static analysis\nthat tracks the provenance and the manipulation of IoT data, and how they flow\nin the system. The results of the analysis can be used by a designer to check\nthe behaviour of smart objects, in particular to verify non-functional\nproperties, among which security.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 16:55:14 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 09:17:23 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 07:58:19 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Bodei", "Chiara", ""], ["Degano", "Pierpaolo", ""], ["Ferrari", "Gian-Luigi", ""], ["Galletta", "Letterio", ""]]}, {"id": "1610.08685", "submitter": "Ale\\v{s} Bizjak", "authors": "Karine Altisen, Pierre Corbineau, and Stephane Devismes", "title": "A Framework for Certified Self-Stabilization", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (November\n  28, 2017) lmcs:4098", "doi": "10.23638/LMCS-13(4:14)2017", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a general framework to build certified proofs of distributed\nself-stabilizing algorithms with the proof assistant Coq. We first define in\nCoq the locally shared memory model with composite atomicity, the most commonly\nused model in the self-stabilizing area. We then validate our framework by\ncertifying a non trivial part of an existing silent self-stabilizing algorithm\nwhich builds a $k$-clustering of the network. We also certify a quantitative\nproperty related to the output of this algorithm. Precisely, we show that the\ncomputed $k$-clustering contains at most $\\lfloor \\frac{n-1}{k+1} \\rfloor + 1$\nclusterheads, where $n$ is the number of nodes in the network. To obtain these\nresults, we also developed a library which contains general tools related to\npotential functions and cardinality of sets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 10:02:25 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 09:26:21 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 09:33:12 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Altisen", "Karine", ""], ["Corbineau", "Pierre", ""], ["Devismes", "Stephane", ""]]}, {"id": "1610.08713", "submitter": "Sebastian Junges", "authors": "Christian Dehnert, Sebastian Junges, Joost-Pieter Katoen, Matthias\n  Volk", "title": "The Probabilistic Model Checker Storm (Extended Abstract)", "comments": "Extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new probabilistic model checker Storm. Using state-of-the-art\nlibraries, we aim for both high performance and versatility. This extended\nabstract gives a brief overview of the features of Storm.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 11:14:53 GMT"}], "update_date": "2016-10-30", "authors_parsed": [["Dehnert", "Christian", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Volk", "Matthias", ""]]}, {"id": "1610.08772", "submitter": "J\\\"urgen Koslowski", "authors": "Anupam Das and Lutz Stra{\\ss}burger", "title": "On linear rewriting systems for Boolean logic and some applications to\n  proof theory", "comments": "27 pages, 3 figures, special issue of RTA 2015", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2621", "doi": "10.2168/LMCS-12(4:9)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear rules have played an increasing role in structural proof theory in\nrecent years. It has been observed that the set of all sound linear inference\nrules in Boolean logic is already coNP-complete, i.e. that every Boolean\ntautology can be written as a (left- and right-)linear rewrite rule. In this\npaper we study properties of systems consisting only of linear inferences. Our\nmain result is that the length of any 'nontrivial' derivation in such a system\nis bound by a polynomial. As a consequence there is no polynomial-time\ndecidable sound and complete system of linear inferences, unless coNP=NP. We\ndraw tools and concepts from term rewriting, Boolean function theory and graph\ntheory in order to access some required intermediate results. At the same time\nwe make several connections between these areas that, to our knowledge, have\nnot yet been presented and constitute a rich theoretical framework for\nreasoning about linear TRSs for Boolean logic.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 13:35:54 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 20:10:09 GMT"}, {"version": "v3", "created": "Fri, 23 Dec 2016 12:16:46 GMT"}, {"version": "v4", "created": "Tue, 27 Dec 2016 20:55:19 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Das", "Anupam", ""], ["Stra\u00dfburger", "Lutz", ""]]}, {"id": "1610.08843", "submitter": "Julien Lange", "authors": "Julien Lange and Nicholas Ng and Bernardo Toninho and Nobuko Yoshida", "title": "Fencing off Go: Liveness and Safety for Channel-based Programming\n  (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Go is a production-level statically typed programming language whose design\nfeatures explicit message-passing primitives and lightweight threads, enabling\n(and encouraging) programmers to develop concurrent systems where components\ninteract through communication more so than by lock-based shared memory\nconcurrency. Go can only detect global deadlocks at runtime, but provides no\ncompile-time protection against all too common communication mismatches or\npartial deadlocks. This work develops a static verification framework for\nliveness and safety in Go programs, able to detect communication errors and\npartial deadlocks in a general class of realistic concurrent programs,\nincluding those with dynamic channel creation, unbounded thread creation and\nrecursion. Our approach infers from a Go program a faithful representation of\nits communication patterns as a behavioural type. By checking a syntactic\nrestriction on channel usage, dubbed fencing, we ensure that programs are made\nup of finitely many different communication patterns that may be repeated\ninfinitely many times. This restriction allows us to implement procedures to\ncheck for liveness and safety in types which in turn approximates liveness and\nsafety in Go programs. We have implemented a type inference and liveness and\nsafety checks in a tool-chain and tested it against publicly available Go\nprograms.\n  Note: This is a revised extended version of a paper that appeared in POPL\n2017, see page 13 for details.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 15:40:45 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2017 18:06:37 GMT"}, {"version": "v3", "created": "Tue, 28 Feb 2017 13:55:03 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Lange", "Julien", ""], ["Ng", "Nicholas", ""], ["Toninho", "Bernardo", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1610.08845", "submitter": "Stefano Berardi", "authors": "Stefano Berardi", "title": "A Sound, Complete and Effective Second Order Game Semantics", "comments": "30 pages, unpublished draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a game semantics for second order classical arithmetic PA2 (with\nquantifiers over predicates on integers and full comprehension axiom). Our\nsemantics is effective: moves are described by a finite amount of information\nand whenever there is some winning strategy for the player defending the truth\nof the formula, then there is some primitive recursive winning strategy. Then\nwe show that our game semantics is sound and complete for the truth assignment\nfor formulas of PA2. In our game model, the value of a predicate variable is\nsome family of \"generic\" games. This value is \"unknown\" during the play, but at\nthe end of the play it is used by a \"judge of the play\" to decide who is the\nwinner.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 15:43:56 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Berardi", "Stefano", ""]]}, {"id": "1610.08910", "submitter": "Tong Zhang", "authors": "Tong Zhang", "title": "Perfect Memory Context Trees in time series modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stochastic Context Tree (SCOT) is a useful tool for studying infinite\nrandom sequences generated by an m-Markov Chain (m-MC). It captures the\nphenomenon that the probability distribution of the next state sometimes\ndepends on less than m of the preceding states. This allows compressing the\ninformation needed to describe an m-MC. The SCOT construction has been earlier\nused under various names: VLMC, VOMC, PST, CTW. In this paper we study the\npossibility of reducing the m-MC to a 1-MC on the leaves of the SCOT. Such\ncontext trees are called perfect-memory. We give various combinatorial\ncharacterizations of perfect-memory context trees and an efficient algorithm to\nfind the minimal perfect-memory extension of a SCOT.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 19:29:17 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Zhang", "Tong", ""]]}, {"id": "1610.09089", "submitter": "Thomas Zeume", "authors": "Thomas Zeume", "title": "The Dynamic Descriptive Complexity of k-Clique", "comments": "An extended abstract of this work appeared in the proceedings of the\n  conference Mathematical Foundations of Computer Science 2014 (MFCS 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the dynamic descriptive complexity of the k-clique query is\nstudied. It is shown that when edges may only be inserted then k-clique can be\nmaintained by a quantifier-free update program of arity k-1, but it cannot be\nmaintained by a quantifier-free update program of arity k-2 (even in the\npresence of unary auxiliary functions). This establishes an arity hierarchy for\ngraph queries for quantifier-free update programs under insertions. The proof\nof the lower bound uses upper and lower bounds for Ramsey numbers.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 06:25:27 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Zeume", "Thomas", ""]]}, {"id": "1610.09161", "submitter": "Ohad Kammar", "authors": "Yannick Forster, Ohad Kammar, Sam Lindley, Matija Pretnar", "title": "On the Expressive Power of User-Defined Effects: Effect Handlers,\n  Monadic Reflection, Delimited Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the expressive power of three programming abstractions for\nuser-defined computational effects: Bauer and Pretnar's effect handlers,\nFilinski's monadic reflection, and delimited control without\nanswer-type-modification. This comparison allows a precise discussion about the\nrelative expressiveness of each programming abstraction. It also demonstrates\nthe sensitivity of the relative expressiveness of user-defined effects to\nseemingly orthogonal language features. We present three calculi, one per\nabstraction, extending Levy's call-by-push-value. For each calculus, we present\nsyntax, operational semantics, a natural type-and-effect system, and, for\neffect handlers and monadic reflection, a set-theoretic denotational semantics.\nWe establish their basic meta-theoretic properties: safety, termination, and,\nwhere applicable, soundness and adequacy. Using Felleisen's notion of a macro\ntranslation, we show that these abstractions can macro-express each other, and\nshow which translations preserve typeability. We use the adequate finitary\nset-theoretic denotational semantics for the monadic calculus to show that\neffect handlers cannot be macro-expressed while preserving typeability either\nby monadic reflection or by delimited control. We supplement our development\nwith a mechanised Abella formalisation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 10:36:42 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 15:12:00 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Forster", "Yannick", ""], ["Kammar", "Ohad", ""], ["Lindley", "Sam", ""], ["Pretnar", "Matija", ""]]}, {"id": "1610.09209", "submitter": "Ale\\v{s} Bizjak", "authors": "Eike Neumann, Martin Pape and Thomas Streicher", "title": "Computability in Basic Quantum Mechanics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (June 19,\n  2018) lmcs:4598", "doi": "10.23638/LMCS-14(2:14)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The basic notions of quantum mechanics are formulated in terms of separable\ninfinite dimensional Hilbert space $\\mathcal{H}$. In terms of the Hilbert\nlattice $\\mathcal{L}$ of closed linear subspaces of $\\mathcal{H}$ the notions\nof state and observable can be formulated as kinds of measures as in [21]. The\naim of this paper is to show that there is a good notion of computability for\nthese data structures in the sense of Weihrauch's Type Two Effectivity (TTE)\n[26].\n  Instead of explicitly exhibiting admissible representations for the data\ntypes under consideration we show that they do live within the category\n$\\mathbf{QCB}_0$ which is equivalent to the category $\\mathbf{AdmRep}$ of\nadmissible representations and continuously realizable maps between them. For\nthis purpose in case of observables we have to replace measures by valuations\nwhich allows us to prove an effective version of von Neumann's Spectral\nTheorem.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 11:42:50 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 12:18:18 GMT"}, {"version": "v3", "created": "Mon, 27 Mar 2017 09:08:02 GMT"}, {"version": "v4", "created": "Tue, 9 Jan 2018 13:30:41 GMT"}, {"version": "v5", "created": "Fri, 2 Mar 2018 13:43:04 GMT"}, {"version": "v6", "created": "Thu, 22 Mar 2018 11:19:38 GMT"}, {"version": "v7", "created": "Fri, 18 May 2018 14:47:40 GMT"}, {"version": "v8", "created": "Mon, 18 Jun 2018 13:39:53 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Neumann", "Eike", ""], ["Pape", "Martin", ""], ["Streicher", "Thomas", ""]]}, {"id": "1610.09235", "submitter": "Eric Hehner", "authors": "Eric Hehner", "title": "A Tale of Two Turing Machines", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two Turing Machines may be able to answer questions about each other that\nthey cannot answer about themselves.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 17:54:21 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Hehner", "Eric", ""]]}, {"id": "1610.09254", "submitter": "Nicolai Kraus", "authors": "Thorsten Altenkirch, Nils Anders Danielsson, Nicolai Kraus", "title": "Partiality, Revisited: The Partiality Monad as a Quotient\n  Inductive-Inductive Type", "comments": "v1: 16 pages. v2: 17 pages, llncs style. Minor changes. The final\n  publication is available at Springer via\n  http://dx.doi.org/10.1007/978-3-662-54458-7_31", "journal-ref": "FOSSACS 2017, LNCS 10203, pp. 534-549, 2017", "doi": "10.1007/978-3-662-54458-7_31", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capretta's delay monad can be used to model partial computations, but it has\nthe \"wrong\" notion of built-in equality, strong bisimilarity. An alternative is\nto quotient the delay monad by the \"right\" notion of equality, weak\nbisimilarity. However, recent work by Chapman et al. suggests that it is\nimpossible to define a monad structure on the resulting construction in common\nforms of type theory without assuming (instances of) the axiom of countable\nchoice. Using an idea from homotopy type theory - a higher inductive-inductive\ntype - we construct a partiality monad without relying on countable choice. We\nprove that, in the presence of countable choice, our partiality monad is\nequivalent to the delay monad quotiented by weak bisimilarity. Furthermore we\noutline several applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 15:04:42 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 15:37:59 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Altenkirch", "Thorsten", ""], ["Danielsson", "Nils Anders", ""], ["Kraus", "Nicolai", ""]]}, {"id": "1610.09305", "submitter": "Xue-Ping Wang", "authors": "Peng He, Xue-ping Wang", "title": "Conditions that the quotient of $L$-fuzzy up-sets forms a complete\n  lattice", "comments": "13", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with conditions under which the quotient of $L$-fuzzy\nup-sets forms a complete lattice by using terminologies of closure operators.\nIt first gives a condition that a family of some subsets of a nonempty set can\nbe represented by $L$-fuzzy up-sets, which is then used to formulate a\nnecessary and sufficient condition under which the quotient of $L$-fuzzy\nup-sets forms a complete lattice. This paper finally shows that the quotient of\na kind of $L$-fuzzy up-sets is isomorphic to an interval generated by an\n$L$-fuzzy up-set.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 01:00:39 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["He", "Peng", ""], ["Wang", "Xue-ping", ""]]}, {"id": "1610.09607", "submitter": "Omar Al-Bataineh I.", "authors": "Omar Al-Bataineh and Xie Xiaofei and Mark Reynolds", "title": "Termination of Monotone Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient approach to prove termination of monotone programs\nwith integer variables, an expressive class of loops that is often encountered\nin computer programs. Our approach is based on a lightweight static analysis\nmethod and takes advantage of simple %nice properties of monotone functions.\nOur preliminary implementation %beats shows that our tool has an advantage over\nexisting tools and can prove termination for a high percentage of loops for a\nclass of benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 05:42:29 GMT"}, {"version": "v2", "created": "Sat, 4 Feb 2017 11:43:42 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Al-Bataineh", "Omar", ""], ["Xiaofei", "Xie", ""], ["Reynolds", "Mark", ""]]}, {"id": "1610.09629", "submitter": "Beno\\^it Valiron", "authors": "Ugo Dal Lago, Claudia Faggian, Benoit Valiron, Akira Yoshimizu", "title": "The Geometry of Parallelism. Classical, Probabilistic, and Quantum\n  Effects", "comments": "21 pages, extended version of the conference paper ; July 2017:\n  removed a spurious and unused lemma", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Geometry of Interaction model for higher-order quantum\ncomputation, and prove its adequacy for a full quantum programming language in\nwhich entanglement, duplication, and recursion are all available. Our model\ncomes with a multi-token machine, a proof net system, and a PCF-style language.\nThe approach we develop is not specific to quantum computation, and our model\nis an instance of a new framework whose main feature is the ability to model\ncommutative effects in a parallel setting. Being based on a multi-token machine\nequipped with a memory, it has a concrete nature which makes it well suited for\nbuilding low-level operational descriptions of higher-order languages.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 10:54:43 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 12:10:01 GMT"}, {"version": "v3", "created": "Sat, 15 Jul 2017 14:32:53 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Faggian", "Claudia", ""], ["Valiron", "Benoit", ""], ["Yoshimizu", "Akira", ""]]}, {"id": "1610.09795", "submitter": "Omar Al-Bataineh", "authors": "Omar Al-Bataineh, Mark Reynolds, and Tim French", "title": "Finding Minimum and Maximum Termination Time of Timed Automata Models\n  with Cyclic Behaviour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel algorithm for computing best and worst case\nexecution times (BCET/WCET) of timed automata models with cyclic behaviour. The\nalgorithms can work on any arbitrary diagonal-free TA and can handle more cases\nthan previously existing algorithms for BCET/WCET computations, as it can\nhandle cycles in TA and decide whether they lead to an infinite WCET. We show\nsoundness of the proposed algorithm and study its complexity. To our knowledge,\nthis is the first model checking algorithm that addresses comprehensively the\nBCET/WCET problem of systems with cyclic behaviour. Behrmann et al. provide an\nalgorithm for computing the minimum cost/time of reaching a goal state in\npriced timed automata (PTA). The algorithm has been implemented in the\nwell-known model checking tool UPPAAL to compute the minimum time for\ntermination of an automaton. However, we show that in certain circumstances,\nwhen infinite cycles exist, the algorithm implemented in UPPAAL may not\nterminate, and we provide examples which UPPAAL fails to verify.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 06:09:16 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Al-Bataineh", "Omar", ""], ["Reynolds", "Mark", ""], ["French", "Tim", ""]]}, {"id": "1610.09847", "submitter": "Jouni J\\\"arvinen", "authors": "Jouni J\\\"arvinen and S\\'andor Radeleczki", "title": "Representing regular pseudocomplemented Kleene algebras by\n  tolerance-based rough sets", "comments": "Title modified from the first version. Repaired one proof. Changes in\n  terminology", "journal-ref": "Journal of the Australian Mathematical Society 105, 57-78 (2018)", "doi": "10.1017/S1446788717000283", "report-no": null, "categories": "math.CO cs.FL cs.LO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any regular pseudocomplemented Kleene algebra defined on an\nalgebraic lattice is isomorphic to a rough set Kleene algebra determined by a\ntolerance induced by an irredundant covering.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 10:12:51 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 16:37:27 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["J\u00e4rvinen", "Jouni", ""], ["Radeleczki", "S\u00e1ndor", ""]]}]