[{"id": "1611.00401", "submitter": "Ale\\v{s} Bizjak", "authors": "David De Frutos Escrig, Jeroen J.A. Keiren and Tim A.C. Willemse", "title": "Games for Bisimulations and Abstraction", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (November\n  28, 2017) lmcs:4099", "doi": "10.23638/LMCS-13(4:15)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak bisimulations are typically used in process algebras where silent steps\nare used to abstract from internal behaviours. They facilitate relating\nimplementations to specifications. When an implementation fails to conform to\nits specification, pinpointing the root cause can be challenging. In this paper\nwe provide a generic characterisation of branching-, delayed-, $\\eta$- and\nweak-bisimulation as a game between Spoiler and Duplicator, offering an\noperational understanding of the relations. We show how such games can be used\nto assist in diagnosing non-conformance between implementation and\nspecification. Moreover, we show how these games can be extended to distinguish\ndivergences.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 21:26:56 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 19:33:28 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 15:45:57 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Escrig", "David De Frutos", ""], ["Keiren", "Jeroen J. A.", ""], ["Willemse", "Tim A. C.", ""]]}, {"id": "1611.00455", "submitter": "Thorsten Wissmann", "authors": "Yusuke Kawamoto, Konstantinos Chatzikokolakis, and Catuscia\n  Palamidessi", "title": "On the Compositionality of Quantitative Information Flow", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (August\n  15, 2017) lmcs:3860", "doi": "10.23638/LMCS-13(3:11)2017", "report-no": null, "categories": "cs.LO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information flow is the branch of security that studies the leakage of\ninformation due to correlation between secrets and observables. Since in\ngeneral such correlation cannot be avoided completely, it is important to\nquantify the leakage. The most followed approaches to defining appropriate\nmeasures are those based on information theory. In particular, one of the most\nsuccessful approaches is the recently proposed $g$-leakage framework, which\nencompasses most of the information-theoretic ones. A problem with $g$-leakage,\nhowever, is that it is defined in terms of a minimization problem, which, in\nthe case of large systems, can be computationally rather heavy. In this paper\nwe study the case in which the channel associated to the system can be\ndecomposed into simpler channels, which typically happens when the observables\nconsist of multiple components. Our main contribution is the derivation of\nbounds on the (multiplicative version of) $g$-leakage of the whole system in\nterms of the $g$-leakages of its components. We also consider the particular\ncases of min-entropy leakage and of parallel channels, generalizing and\nsystematizing results from the literature. We demonstrate the effectiveness of\nour method and evaluate the precision of our bounds using examples.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:56:01 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 01:51:05 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 00:56:10 GMT"}, {"version": "v4", "created": "Mon, 14 Aug 2017 09:59:18 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Kawamoto", "Yusuke", ""], ["Chatzikokolakis", "Konstantinos", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "1611.00574", "submitter": "Fuyuan Zhang", "authors": "Fuyuan Zhang, Yongwang Zhao, David Sanan, Yang Liu, Alwen Tiu,\n  Shang-Wei Lin, Jun Sun", "title": "Compositional Reasoning for Shared-variable Concurrent Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable and automatic formal verification for concurrent systems is always\ndemanding. In this paper, we propose a verification framework to support\nautomated compositional reasoning for concurrent programs with shared\nvariables. Our framework models concurrent programs as succinct automata and\nsupports the verification of multiple important properties. Safety verification\nand simulations of succinct automata are parallel compositional, and safety\nproperties of succinct automata are preserved under refinements. We generate\nsuccinct automata from infinite state concurrent programs in an automated\nmanner. Furthermore, we propose the first automated approach to checking\nrely-guarantee based simulations between infinite state concurrent programs. We\nhave prototyped our algorithms and applied our tool to the verification of\nmultiple refinements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 12:56:15 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 13:51:38 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhang", "Fuyuan", ""], ["Zhao", "Yongwang", ""], ["Sanan", "David", ""], ["Liu", "Yang", ""], ["Tiu", "Alwen", ""], ["Lin", "Shang-Wei", ""], ["Sun", "Jun", ""]]}, {"id": "1611.00580", "submitter": "Jad Hamza", "authors": "Ahmed Bouajjani, Constantin Enea, Rachid Guerraoui, Jad Hamza", "title": "On Verifying Causal Consistency", "comments": "extended version of POPL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal consistency is one of the most adopted consistency criteria for\ndistributed implementations of data structures. It ensures that operations are\nexecuted at all sites according to their causal precedence. We address the\nissue of verifying automatically whether the executions of an implementation of\na data structure are causally consistent. We consider two problems: (1)\nchecking whether one single execution is causally consistent, which is relevant\nfor developing testing and bug finding algorithms, and (2) verifying whether\nall the executions of an implementation are causally consistent.\n  We show that the first problem is NP-complete. This holds even for the\nread-write memory abstraction, which is a building block of many modern\ndistributed systems. Indeed, such systems often store data in key-value stores,\nwhich are instances of the read-write memory abstraction. Moreover, we prove\nthat, surprisingly, the second problem is undecidable, and again this holds\neven for the read-write memory abstraction. However, we show that for the\nread-write memory abstraction, these negative results can be circumvented if\nthe implementations are data independent, i.e., their behaviors do not depend\non the data values that are written or read at each moment, which is a\nrealistic assumption.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 13:01:50 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 11:50:13 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Bouajjani", "Ahmed", ""], ["Enea", "Constantin", ""], ["Guerraoui", "Rachid", ""], ["Hamza", "Jad", ""]]}, {"id": "1611.01296", "submitter": "Lo\\\"ic Paulev\\'e", "authors": "Thomas Chatain and Lo\\\"ic Paulev\\'e", "title": "Goal-Driven Unfolding of Petri Nets", "comments": "research report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfoldings provide an efficient way to avoid the state-space explosion due to\ninterleavings of concurrent transitions when exploring the runs of a Petri net.\nThe theory of adequate orders allows one to define finite prefixes of\nunfoldings which contain all the reachable markings. In this paper we are\ninterested in reachability of a single given marking, called the goal. We\npropose an algorithm for computing a finite prefix of the unfolding of a 1-safe\nPetri net that preserves all minimal configurations reaching this goal. Our\nalgorithm combines the unfolding technique with on-the-fly model reduction by\nstatic analysis aiming at avoiding the exploration of branches which are not\nneeded for reaching the goal. We present some experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 09:41:33 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Chatain", "Thomas", ""], ["Paulev\u00e9", "Lo\u00efc", ""]]}, {"id": "1611.01328", "submitter": "Thorsten Wissmann", "authors": "Olaf Beyersdorff, Leroy Chew, Meena Mahajan, Anil Shukla", "title": "Feasible Interpolation for QBF Resolution Calculi", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (June 8,\n  2017) lmcs:3702", "doi": "10.23638/LMCS-13(2:7)2017", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sharp contrast to classical proof complexity we are currently short of\nlower bound techniques for QBF proof systems. In this paper we establish the\nfeasible interpolation technique for all resolution-based QBF systems, whether\nmodelling CDCL or expansion-based solving. This both provides the first general\nlower bound method for QBF proof systems as well as largely extends the scope\nof classical feasible interpolation. We apply our technique to obtain new\nexponential lower bounds to all resolution-based QBF systems for a new class of\nQBF formulas based on the clique problem. Finally, we show how feasible\ninterpolation relates to the recently established lower bound method based on\nstrategy extraction.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 11:13:17 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 11:11:14 GMT"}, {"version": "v3", "created": "Wed, 7 Jun 2017 16:13:36 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Beyersdorff", "Olaf", ""], ["Chew", "Leroy", ""], ["Mahajan", "Meena", ""], ["Shukla", "Anil", ""]]}, {"id": "1611.01337", "submitter": "Iulia Dragomir", "authors": "Viorel Preoteasa and Iulia Dragomir and Stavros Tripakis", "title": "Mechanically Proving Determinacy of Hierarchical Block Diagram\n  Translations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical block diagrams (HBDs) are at the heart of embedded system design\ntools, including Simulink. Numerous translations exist from HBDs into languages\nwith formal semantics, amenable to formal verification. However, none of these\ntranslations has been proven correct, to our knowledge. We present in this\npaper the first mechanically proven HBD translation algorithm. The algorithm\ntranslates HBDs into an algebra of terms with three basic composition\noperations (serial, parallel, and feedback). In order to capture various\ntranslation strategies resulting in different terms achieving different\ntradeoffs, the algorithm is nondeterministic. Despite this, we prove its\nsemantic determinacy: for every input HBD, all possible terms that can be\ngenerated by the algorithm are semantically equivalent. We apply this result to\nshow how three Simulink translation strategies introduced previously can be\nformalized as determinizations of the algorithm, and derive that these\nstrategies yield semantically equivalent results (a question left open in\nprevious work). All results are formalized and proved in the Isabelle\ntheorem-prover.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 11:39:46 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 08:48:56 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Preoteasa", "Viorel", ""], ["Dragomir", "Iulia", ""], ["Tripakis", "Stavros", ""]]}, {"id": "1611.01429", "submitter": "Steffen Lewitzka", "authors": "Steffen Lewitzka", "title": "Epistemic extensions of combined classical and intuitionistic\n  propositional logic", "comments": "23 pages", "journal-ref": null, "doi": "10.1093/jigpal/jzx004", "report-no": "TR-PGCOMP-004/2016. Computer Science Graduate Program. Federal\n  University of Bahia", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic $L$ was introduced by Lewitzka [7] as a modal system that combines\nintuitionistic and classical logic: $L$ is a conservative extension of CPC and\nit contains a copy of IPC via the embedding $\\varphi\\mapsto\\square\\varphi$. In\nthis article, we consider $L3$, i.e. $L$ augmented with S3 modal axioms, define\nbasic epistemic extensions and prove completeness w.r.t. algebraic semantics.\nThe resulting logics combine classical knowledge and belief with intuitionistic\ntruth. Some epistemic laws of Intuitionistic Epistemic Logic studied by Artemov\nand Protopopescu [1] are reflected by classical modal principles. In\nparticular, the implications \"intuitionistic truth $\\Rightarrow$ knowledge\n$\\Rightarrow$ classical truth\" are represented by the theorems\n$\\square\\varphi\\rightarrow K\\varphi$ and $K\\varphi\\rightarrow\\varphi$ of our\nlogic $EL3$, where we are dealing with classical instead of intuitionistic\nknowledge. Finally, we show that a modification of our semantics yields\nalgebraic models for the systems of Intuitionistic Epistemic Logic introduced\nin [1].\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 15:49:17 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 17:12:35 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lewitzka", "Steffen", ""]]}, {"id": "1611.01553", "submitter": "Vedad Hadzic", "authors": "Roderick Bloem, Nicolas Braud-Santoni and Vedad Hadzic", "title": "QBF Solving by Counterexample-guided Expansion", "comments": "This is a **very** old version of the paper arXiv:1807.08964 and\n  should be taken down. I did not know you could just replace papers, and did\n  not know whether I could change authors and similar, so that is why I made a\n  different submission. Please take it down", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce a novel generalization of Counterexample-Guided Inductive\nSynthesis (CEGIS) and instantiate it to yield a novel, competitive algorithm\nfor solving Quantified Boolean Formulas (QBF). Current QBF solvers based on\ncounterexample-guided expansion use a recursive approach which scales poorly\nwith the number of quantifier alternations. Our generalization of CEGIS removes\nthe need for this recursive approach, and we instantiate it to yield a simple\nand efficient algorithm for QBF solving. Lastly, this research is supported by\na competitive, though straightforward, implementation of the algorithm, making\nit possible to study the practical impact of our algorithm design decisions,\nalong with various optimizations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 22:08:40 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 15:26:12 GMT"}, {"version": "v3", "created": "Fri, 25 Nov 2016 17:48:36 GMT"}, {"version": "v4", "created": "Fri, 27 Jul 2018 10:16:43 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Bloem", "Roderick", ""], ["Braud-Santoni", "Nicolas", ""], ["Hadzic", "Vedad", ""]]}, {"id": "1611.01648", "submitter": "Hugo Luiz Mariano", "authors": "Darllan Concei\\c{c}\\~ao Pinto and Hugo Luiz Mariano", "title": "Remarks on Propositional Logics and the categorial relationship between\n  Institutions and {\\Pi}-Institutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore some applications of the notions of Institution and\n{\\Pi}-Institution in the setting of propositional logics and establish a\nprecise categorial relation between these notions, i.e., we provide a pair of\nfunctors that establishes an adjunction between the categories Inst and\n{\\Pi}-Inst.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 13:25:23 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Pinto", "Darllan Concei\u00e7\u00e3o", ""], ["Mariano", "Hugo Luiz", ""]]}, {"id": "1611.01696", "submitter": "Jackson Abascal", "authors": "Jackson Abascal, Lane A. Hemaspaandra, Shir Maimon, and Daniel Rubery", "title": "Closure and Nonclosure Properties of the Compressible and Rankable Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rankable and compressible sets have been studied for more than a quarter\nof a century, ever since Allender [1] and Goldberg and Sipser [6] introduced\nthe formal study of polynomial-time ranking. Yet even after all that time,\nwhether the rankable and compressible sets are closed under the most important\nboolean and other operations remains essentially unexplored. The present paper\nstudies these questions for both polynomial-time and recursion-theoretic\ncompression and ranking, and for almost every case arrives at a Closed, a\nNot-Closed, or a Closed-Iff-Well-Known-Complexity-Classes-Collapse result for\nthe given operation. Even though compression and ranking classes are capturing\nsomething quite natural about the structure of sets, it turns out that they are\nquite fragile with respect to closure properties, and many fail to possess even\nthe most basic of closure properties. For example, we show that with respect to\nthe join (aka disjoint union) operation: the P-rankable sets are not closed,\nwhether the semistrongly P-rankable sets are closed is closely linked to\nwhether P = UP $\\cap$ coUP, and the strongly P-rankable sets are closed.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 20:31:58 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 14:50:46 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 03:44:04 GMT"}, {"version": "v4", "created": "Wed, 23 May 2018 21:37:30 GMT"}, {"version": "v5", "created": "Tue, 24 Jul 2018 20:56:20 GMT"}, {"version": "v6", "created": "Wed, 31 Oct 2018 00:28:13 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Abascal", "Jackson", ""], ["Hemaspaandra", "Lane A.", ""], ["Maimon", "Shir", ""], ["Rubery", "Daniel", ""]]}, {"id": "1611.02108", "submitter": "Anders M\\\"ortberg", "authors": "Cyril Cohen, Thierry Coquand, Simon Huber, and Anders M\\\"ortberg", "title": "Cubical Type Theory: a constructive interpretation of the univalence\n  axiom", "comments": "To be published in the post-proceedings of the 21st International\n  Conference on Types for Proofs and Programs, TYPES 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a type theory in which it is possible to directly\nmanipulate $n$-dimensional cubes (points, lines, squares, cubes, etc.) based on\nan interpretation of dependent type theory in a cubical set model. This enables\nnew ways to reason about identity types, for instance, function extensionality\nis directly provable in the system. Further, Voevodsky's univalence axiom is\nprovable in this system. We also explain an extension with some higher\ninductive types like the circle and propositional truncation. Finally we\nprovide semantics for this cubical type theory in a constructive meta-theory.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:25:28 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Cohen", "Cyril", ""], ["Coquand", "Thierry", ""], ["Huber", "Simon", ""], ["M\u00f6rtberg", "Anders", ""]]}, {"id": "1611.02112", "submitter": "Emanuel Kieronski", "authors": "Bartosz Bednarczyk, Witold Charatonik and Emanuel Kiero\\'nski", "title": "Extending Two-Variable Logic on Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite satisfiability problem for the two-variable fragment of\nfirst-order logic interpreted over trees was recently shown to be\nExpSpace-complete. We consider two extensions of this logic. We show that\nadding either additional binary symbols or counting quantifiers to the logic\ndoes not affect the complexity of the finite satisfiability problem. However,\ncombining the two extensions and adding both binary symbols and counting\nquantifiers leads to an explosion of this complexity.\n  We also compare the expressive power of the two-variable fragment over trees\nwith its extension with counting quantifiers. It turns out that the two logics\nare equally expressive, although counting quantifiers do add expressive power\nin the restricted case of unordered trees.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:30:35 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 12:37:20 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Charatonik", "Witold", ""], ["Kiero\u0144ski", "Emanuel", ""]]}, {"id": "1611.02528", "submitter": "Tayssir Touili Touili", "authors": "Fu Song and Tayssir Touili", "title": "LTL Model-Checking for Dynamic Pushdown Networks Communicating via Locks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dynamic Pushdown Network (DPN) is a set of pushdown systems (PDSs) where\neach process can dynamically create new instances of PDSs. DPNs are a natural\nmodel of multi-threaded programs with (possibly recursive) procedure calls and\nthread creation. Extending DPNs with locks allows processes to synchronize with\neach other. Thus, DPNs with locks are a well adapted formalism to model\nmulti-threaded programs that synchronize via locks. Therefore, it is important\nto have model-checking algorithms for DPNs with locks. We consider in this work\nmodel-checking for DPNs with locks against single-indexed LTL properties of the\nform V fi s.t. fi is a LTL formula interpreted over the PDS i. We consider the\nmodel-checking problems w.r.t. simple valuations (i.e, whether a configuration\nsatisfies an atomic proposition depends only on its control location and held\nlocks) and w.r.t. regular valuations (i.e., the set of the configurations\nsatisfying an atomic proposition is a regular set of configurations). We show\nthat these model-checking problems are decidable.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 11:29:46 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Song", "Fu", ""], ["Touili", "Tayssir", ""]]}, {"id": "1611.02867", "submitter": "William DeMeo", "authors": "Clifford Bergman and William DeMeo", "title": "Universal Algebraic Methods for Constraint Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After substantial progress over the last 15 years, the \"algebraic\nCSP-dichotomy conjecture\" reduces to the following: every local constraint\nsatisfaction problem (CSP) associated with a finite idempotent algebra is\ntractable if and only if the algebra has a Taylor term operation. Despite the\ntremendous achievements in this area (including recently announce proofs of the\ngeneral conjecture), there remain examples of small algebras with just a single\nbinary operation whose CSP resists direct classification as either tractable or\nNP-complete using known methods. In this paper we present some new methods for\napproaching such problems, with particular focus on those techniques that help\nus attack the class of finite algebras known as \"commutative idempotent binars\"\n(CIBs). We demonstrate the utility of these methods by using them to prove that\nevery CIB of cardinality at most 4 yields a tractable CSP.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 09:49:27 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 07:35:01 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 11:00:35 GMT"}, {"version": "v4", "created": "Fri, 10 Mar 2017 03:20:01 GMT"}, {"version": "v5", "created": "Mon, 16 Dec 2019 12:29:16 GMT"}, {"version": "v6", "created": "Wed, 10 Jun 2020 16:33:01 GMT"}, {"version": "v7", "created": "Thu, 11 Jun 2020 10:02:18 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Bergman", "Clifford", ""], ["DeMeo", "William", ""]]}, {"id": "1611.02908", "submitter": "Simon Robillard", "authors": "Laura Kovacs, Simon Robillard and Andrei Voronkov", "title": "Coming to Terms with Quantified Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of finite term algebras provides a natural framework to describe\nthe semantics of functional languages. The ability to efficiently reason about\nterm algebras is essential to automate program analysis and verification for\nfunctional or imperative programs over algebraic data types such as lists and\ntrees. However, as the theory of finite term algebras is not finitely\naxiomatizable, reasoning about quantified properties over term algebras is\nchallenging.\n  In this paper we address full first-order reasoning about properties of\nprograms manipulating term algebras, and describe two approaches for doing so\nby using first-order theorem proving. Our first method is a conservative\nextension of the theory of term algebras using a finite number of statements,\nwhile our second method relies on extending the superposition calculus of\nfirst-order theorem provers with additional inference rules.\n  We implemented our work in the first-order theorem prover Vampire and\nevaluated it on a large number of algebraic data type benchmarks, as well as\ngame theory constraints. Our experimental results show that our methods are\nable to find proofs for many hard problems previously unsolved by\nstate-of-the-art methods. We also show that Vampire implementing our methods\noutperforms existing SMT solvers able to deal with algebraic data types.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 12:55:38 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Kovacs", "Laura", ""], ["Robillard", "Simon", ""], ["Voronkov", "Andrei", ""]]}, {"id": "1611.03267", "submitter": "Emanuel Kieronski", "authors": "Emanuel Kieronski, Lidia Tendera", "title": "Finite Satisfiability of the Two-Variable Guarded Fragment with\n  Transitive Guards and Related Variants", "comments": "Accepted for ACM TOCL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider extensions of the two-variable guarded fragment, GF2, where\ndistinguished binary predicates that occur only in guards are required to be\ninterpreted in a special way (as transitive relations, equivalence relations,\npre-orders or partial orders). We prove that the only fragment that retains the\nfinite (exponential) model property is GF2 with equivalence guards without\nequality. For remaining fragments we show that the size of a minimal finite\nmodel is at most doubly exponential. To obtain the result we invent a strategy\nof building finite models that are formed from a number of multidimensional\ngrids placed over a cylindrical surface. The construction yields a\n2NExpTime-upper bound on the complexity of the finite satisfiability problem\nfor these fragments. We improve the bounds and obtain optimal ones for all the\nfragments considered, in particular NExpTime for GF2 with equivalence guards,\nand 2ExpTime for GF2 with transitive guards. To obtain our results we\nessentially use some results from integer programming.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 11:38:49 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 08:44:51 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 13:42:30 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Kieronski", "Emanuel", ""], ["Tendera", "Lidia", ""]]}, {"id": "1611.03322", "submitter": "Hongyang Qu", "authors": "Hongyang Qu, Sandor M. Veres", "title": "Verification of Logical Consistency in Robotic Reasoning", "comments": null, "journal-ref": "Robotics and Autonomous Systems, Vol. 83(2016), 44-56", "doi": "10.1016/j.robot.2016.06.005", "report-no": null, "categories": "cs.RO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most autonomous robotic agents use logic inference to keep themselves to safe\nand permitted behaviour. Given a set of rules, it is important that the robot\nis able to establish the consistency between its rules, its perception-based\nbeliefs, its planned actions and their consequences. This paper investigates\nhow a robotic agent can use model checking to examine the consistency of its\nrules, beliefs and actions. A rule set is modelled by a Boolean evolution\nsystem with synchronous semantics, which can be translated into a labelled\ntransition system (LTS). It is proven that stability and consistency can be\nformulated as computation tree logic (CTL) and linear temporal logic (LTL)\nproperties. Two new algorithms are presented to perform realtime consistency\nand stability checks respectively. Their implementation provides us a\ncomputational tool, which can form the basis of efficient consistency checks\non-board robots.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 14:51:07 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Qu", "Hongyang", ""], ["Veres", "Sandor M.", ""]]}, {"id": "1611.03424", "submitter": "Marino Miculan", "authors": "Alessio Mansutti and Marino Miculan", "title": "Deciding Hedged Bisimilarity", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spi-calculus is a formal model for the design and analysis of\ncryptographic protocols: many security properties, such as authentication and\nstrong confidentiality, can be reduced to the verification of behavioural\nequivalences between spi processes. In this paper we provide an algorithm for\ndeciding hedged bisimilarity on finite processes, which is equivalent to barbed\nequivalence (and coarser than framed bisimilarity). This algorithm works with\nany term equivalence satisfying a simple set of conditions, thus encompassing\nmany different encryption schemata.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:50:09 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Mansutti", "Alessio", ""], ["Miculan", "Marino", ""]]}, {"id": "1611.03429", "submitter": "Barak Pearlmutter", "authors": "Robert Kelly and Barak A. Pearlmutter and Jeffrey Mark Siskind", "title": "Evolving the Incremental {\\lambda} Calculus into a Model of Forward\n  Automatic Differentiation (AD)", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal transformations somehow resembling the usual derivative are\nsurprisingly common in computer science, with two notable examples being\nderivatives of regular expressions and derivatives of types. A newcomer to this\nlist is the incremental $\\lambda$-calculus, or ILC, a \"theory of changes\" that\ndeploys a formal apparatus allowing the automatic generation of efficient\nupdate functions which perform incremental computation. The ILC is not only\ndefined, but given a formal machine-understandable definition---accompanied by\nmechanically verifiable proofs of various properties, including in particular\ncorrectness of various sorts. Here, we show how the ILC can be mutated into\npropagating tangents, thus serving as a model of Forward Accumulation Mode\nAutomatic Differentiation. This mutation is done in several steps. These steps\ncan also be applied to the proofs, resulting in machine-checked proofs of the\ncorrectness of this model of forward AD.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 18:06:43 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Kelly", "Robert", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1611.03524", "submitter": "Bastien Maubert", "authors": "Rapha\\\"el Berthon, Bastien Maubert, Aniello Murano", "title": "Quantified CTL with imperfect information", "comments": "New version: added EU logo to comply with Marie Curie fellowships\n  requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantified CTL (QCTL) is a well-studied temporal logic that extends CTL with\nquantification over atomic propositions. It has recently come to the fore as a\npowerful intermediary framework to study logics for strategic reasoning. We\nextend it to include imperfect information by parameterising quantifiers with\nan observation that defines how well they observe the model, thus constraining\ntheir behaviour. We consider two different semantics, one related to the notion\nof no memory, the other to perfect recall. We study the expressiveness of our\nlogic, and show that it coincides with MSO for the first semantics and with MSO\nwith equal level for the second one. We establish that the model-checking\nproblem is Pspace-complete for the first semantics. While it is undecidable for\nthe second one, we identify a syntactic fragment, defined by a notion of\nhierarchical formula, which we prove to be decidable thanks to an\nautomata-theoretic approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 21:44:53 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 10:49:49 GMT"}, {"version": "v3", "created": "Wed, 20 Jun 2018 10:43:13 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 13:55:43 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""]]}, {"id": "1611.03628", "submitter": "Maja Hanne Kirkeby", "authors": "Henning Christiansen and Maja H. Kirkeby", "title": "On Proving Confluence Modulo Equivalence for Constraint Handling Rules", "comments": null, "journal-ref": null, "doi": "10.1007/s00165-016-0396-9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous results on proving confluence for Constraint Handling Rules are\nextended in two ways in order to allow a larger and more realistic class of CHR\nprograms to be considered confluent. Firstly, we introduce the relaxed notion\nof confluence modulo equivalence into the context of CHR: while confluence for\na terminating program means that all alternative derivations for a query lead\nto the exact same final state, confluence modulo equivalence only requires the\nfinal states to be equivalent with respect to an equivalence relation tailored\nfor the given program. Secondly, we allow non-logical built-in predicates such\nas var/1 and incomplete ones such as is/2, that are ignored in previous work on\nconfluence.\n  To this end, a new operational semantics for CHR is developed which includes\nsuch predicates. In addition, this semantics differs from earlier approaches by\nits simplicity without loss of generality, and it may also be recommended for\nfuture studies of CHR.\n  For the purely logical subset of CHR, proofs can be expressed in first-order\nlogic, that we show is not sufficient in the present case. We have introduced a\nformal meta-language that allows reasoning about abstract states and\nderivations with meta-level restrictions that reflect the non-logical and\nincomplete predicates. This language represents subproofs as diagrams, which\nfacilitates a systematic enumeration of proof cases, pointing forward to a\nmechanical support for such proofs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 09:11:58 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Christiansen", "Henning", ""], ["Kirkeby", "Maja H.", ""]]}, {"id": "1611.03656", "submitter": "Ale\\v{s} Bizjak", "authors": "Rolf Hennicker, Michel Bidoit", "title": "Compatibility Properties of Synchronously and Asynchronously\n  Communicating Components", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  9, 2018) lmcs:4191", "doi": "10.23638/LMCS-14(1:1)2018", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study interacting components and their compatibility with respect to\nsynchronous and asynchronous composition. The behavior of components is\nformalized by I/O-transition systems. Synchronous composition is based on\nsimultaneous execution of shared output and input actions of two components\nwhile asynchronous composition uses unbounded FIFO-buffers for message\ntransfer. In both contexts we study compatibility notions based on the idea\nthat any output issued by one component should be accepted as an input by the\nother. We distinguish between strong and weak versions of compatibility, the\nlatter allowing the execution of internal actions before a message is accepted.\nWe consider open systems and study conditions under which (strong/weak)\nsynchronous compatibility is sufficient and necessary to get (strong/weak)\nasynchronous compatibility. We show that these conditions characterize\nhalf-duplex systems. Then we focus on the verification of weak asynchronous\ncompatibility for possibly non half-duplex systems and provide a decidable\ncriterion that ensures weak asynchronous compatibility. We investigate\nconditions under which this criterion is complete, i.e. if it is not satisfied\nthen the asynchronous system is not weakly asynchronously compatible. Finally,\nwe discuss deadlock-freeness and investigate relationships between\ndeadlock-freeness in the synchronous and in the asynchronous case.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 10:59:59 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 16:31:01 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 17:28:39 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hennicker", "Rolf", ""], ["Bidoit", "Michel", ""]]}, {"id": "1611.03714", "submitter": "Matteo Manighetti", "authors": "Matteo Manighetti", "title": "Computational Interpretations of Markov's principle", "comments": null, "journal-ref": null, "doi": null, "report-no": "AC13687273", "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov's principle is a statement that originated in the Russian school of\nConstructive Mathematics and stated originally that \"if it is impossible that\nan algorithm does not terminate, then it will terminate\". This principle has\nbeen adapted to many different contexts, and in particular we are interested in\nits most common version for arithmetic, which can be stated as \"given a total\nrecursive function f , if it is impossible that there is no n for which f(n) =\n0, then there exists an n such that f(n) = 0\". This is in general not accepted\nin constructivism, where stating an existential statement requires one to be\nable to show at request a witness for the statement: here there is no clear way\nto choose such an n. We introduce more in detail the context of constructive\nmathematics from different points of view, and we show how they are related to\nMarkov's principle. In particular, several realizability semantics are\npresented, which provide interpretations of logical systems by means of\ndifferent computational concepts (mainly, recursive functions and lambda\ncalculi). This field of research gave origin to the well known paradigm often\ncalled Curry-Howrd isomorphism, or also propositions as types, that states a\ncorrespondence between proofs in logic and programs in computer science. Thanks\nto this the field of proof theory, that is the metamathematical investigations\nof proofs as mathematical objects, became of interest for computer science and\nin particular for the study of programming languages. By using modern research\non the Curry-Howard isomorphism, we will obtain a more refined interpretation\nof Markov's principle. We will then use this results to investigate the logical\nproperties of systems related to the principle, and introduce a proof\ntransformation technique to interpret constructively some non-constructive\nproofs of arithmetic.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 14:23:19 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 13:23:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Manighetti", "Matteo", ""]]}, {"id": "1611.04181", "submitter": "Giuseppe Greco", "authors": "Giuseppe Greco and Alessandra Palmigiano", "title": "Linear Logic Properly Displayed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce proper display calculi for intuitionistic, bi-intuitionistic and\nclassical linear logics with exponentials, which are sound, complete,\nconservative, and enjoy cut-elimination and subformula property. Based on the\nsame design, we introduce a variant of Lambek calculus with exponentials, aimed\nat capturing the controlled application of exchange and associativity.\nProperness (i.e. closure under uniform substitution of all parametric parts in\nrules) is the main interest and added value of the present proposal, and allows\nfor the smoothest proof of cut-elimination. Our proposal builds on an algebraic\nand order-theoretic analysis of linear logic, and applies the guidelines of the\nmulti-type methodology in the design of display calculi.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 20:25:00 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Greco", "Giuseppe", ""], ["Palmigiano", "Alessandra", ""]]}, {"id": "1611.04444", "submitter": "F\\'elix Bou", "authors": "F\\'elix Bou, Francesc Esteva, Llu\\'is Godo and Ricardo Oscar Rodriguez", "title": "Possibilistic semantics for a modal KD45 extension of G\\\"odel fuzzy\n  logic", "comments": "12 pages", "journal-ref": null, "doi": "10.1007/978-3-319-40581-0_11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a simplified semantics for the logic KD45(G), i.e.\nthe many-valued G\\\"odel counterpart of the classical modal logic KD45. More\nprecisely, we characterize KD45(G) as the set of valid formulae of the class of\npossibilistic G\\\"odel Kripke Frames $\\langle W,\\pi \\rangle$, where $W$ is a\nnon-empty set of worlds and $\\pi: W \\longrightarrow [0, 1]$ is a normalized\npossibility distribution on $W$.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 16:23:53 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Bou", "F\u00e9lix", ""], ["Esteva", "Francesc", ""], ["Godo", "Llu\u00eds", ""], ["Rodriguez", "Ricardo Oscar", ""]]}, {"id": "1611.04838", "submitter": "Jingchao Chen", "authors": "Jingchao Chen", "title": "Fast Verifying Proofs of Propositional Unsatisfiability via Window\n  Shifting", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness and correctness of SAT solvers are receiving more and more\nattention. In recent SAT competitions, a proof of unsatisfiability emitted by\nSAT solvers must be checked. So far, no proof checker has been efficient for\nevery case. In the SAT competition 2016, some proofs were not verified within\n20000 seconds. For this reason, we decided to develop a more efficient proof\nchecker called TreeRat. This new checker uses a window shifting technique to\nimprove the level of efficiency at which it verifies proofs of\nunsatisfiability. At the same time, we suggest that tree-search-based SAT\nsolvers should use an equivalent relation encoding to emit proofs of\nsubproblems. In our experiments, TreeRat was able to verify almost all proofs\nwithin 20000 seconds. On this point, TreeRat is shown to be superior to\ngratgen, which is an improved version of DRAT-trim. Also, in most cases,\nTreeRat is faster than gratgen. Like DRAT-trim, TreeRat can output also trace\ndependency graphs. Its output format is LRAT. The correctness of TreeRat can be\nensured by checking its LRAT output.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 14:07:54 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 02:22:33 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 13:18:44 GMT"}, {"version": "v4", "created": "Sun, 24 Jun 2018 12:50:58 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Chen", "Jingchao", ""]]}, {"id": "1611.04946", "submitter": "Jianwen Li", "authors": "Jianwen Li and Shufang Zhu and Yueling Zhang and Geguang Pu and Moshe\n  Vardi", "title": "Safety Model Checking with Complementary Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification techniques such as model checking, are becoming popular\nin hardware design. SAT-based model checking techniques such as IC3/PDR, have\ngained a significant success in hardware industry. In this paper, we present a\nnew framework for SAT-based safety model checking, named Complementary\nApproximate Reachability (CAR). CAR is based on standard reachability analysis,\nbut instead of maintaining a single sequence of reachable- state sets, CAR\nmaintains two sequences of over- and under- approximate reachable-state sets,\nchecking safety and unsafety at the same time. To construct the two sequences,\nCAR uses standard Boolean-reasoning algorithms, based on satisfiability\nsolving, one to find a satisfying cube of a satisfiable Boolean formula, and\none to provide a minimal unsatisfiable core of an unsatisfiable Boolean\nformula. We applied CAR to 548 hardware model-checking instances, and compared\nits performance with IC3/PDR. Our results show that CAR is able to solve 42\ninstances that cannot be solved by IC3/PDR. When evaluated against a portfolio\nthat includes IC3/PDR and other approaches, CAR is able to solve 21 instances\nthat the other approaches cannot solve. We conclude that CAR should be\nconsidered as a valuable member of any algorithmic portfolio for safety model\nchecking.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 17:22:59 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 16:53:25 GMT"}, {"version": "v3", "created": "Thu, 21 Dec 2017 03:48:10 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Li", "Jianwen", ""], ["Zhu", "Shufang", ""], ["Zhang", "Yueling", ""], ["Pu", "Geguang", ""], ["Vardi", "Moshe", ""]]}, {"id": "1611.04969", "submitter": "Philip Gasteiger", "authors": "Philip Gasteiger, Carmine Dodaro, Benjamin Musitsch, Kristian Reale,\n  Francesco Ricca, Konstantin Schekotihin", "title": "An integrated Graphical User Interface for Debugging Answer Set Programs", "comments": "Paper presented at the 1st Workshop on Trends and Applications of\n  Answer Set Programming (TAASP 2016), Klagenfurt, Austria, 26 September 2016,\n  15 pages, LaTeX, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is an expressive knowledge representation and\nreasoning framework. Due to its rather simple syntax paired with\nhigh-performance solvers, ASP is interesting for industrial applications.\nHowever, to err is human and thus debugging is an important activity during the\ndevelopment process. Therefore, tools for debugging non-ground answer set\nprograms are needed. In this paper, we present a new graphical debugging\ninterface for non-ground answer set programs. The tool is based on the\nrecently-introduced DWASP approach for debugging and it simplifies the\ninteraction with the debugger. Furthermore, the debugging interface is\nintegrated in ASPIDE, a rich IDE for answer set programs. With our extension\nASPIDE turns into a full-fledged IDE by offering debugging support.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 18:11:43 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Gasteiger", "Philip", ""], ["Dodaro", "Carmine", ""], ["Musitsch", "Benjamin", ""], ["Reale", "Kristian", ""], ["Ricca", "Francesco", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "1611.05101", "submitter": "Cunxi Yu", "authors": "Cunxi Yu and Maciej Ciesielski", "title": "Efficient Parallel Verification of Galois Field Multipliers", "comments": "6 pages, 22nd Asia and South Pacific Design Automation Conference\n  (ASP-DAC 2017), Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Galois field (GF) arithmetic is used to implement critical arithmetic\ncomponents in communication and security-related hardware, and verification of\nsuch components is of prime importance. Current techniques for formally\nverifying such components are based on computer algebra methods that proved\nsuccessful in verification of integer arithmetic circuits. However, these\nmethods are sequential in nature and do not offer any parallelism. This paper\npresents an algebraic functional verification technique of gate-level GF (2m )\nmultipliers, in which verification is performed in bit-parallel fashion. The\nmethod is based on extracting a unique polynomial in Galois field of each\noutput bit independently. We demonstrate that this method is able to verify an\nn-bit GF multiplier in n threads. Experiments performed on pre- and\npost-synthesized Mastrovito and Montgomery multipliers show high efficiency up\nto 571 bits.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 00:03:28 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:50:19 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Yu", "Cunxi", ""], ["Ciesielski", "Maciej", ""]]}, {"id": "1611.05176", "submitter": "Silvia Steila", "authors": "Emanuele Frittaion and Silvia Steila and Keita Yokoyama", "title": "The strength of the SCT criterion", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertake the study of size-change analysis in the context of Reverse\nMathematics. In particular, we prove that the SCT criterion is equivalent to\n$\\Sigma^0_2$-induction over RCA$_0$.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 07:50:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Frittaion", "Emanuele", ""], ["Steila", "Silvia", ""], ["Yokoyama", "Keita", ""]]}, {"id": "1611.05183", "submitter": "J\\\"urgen Koslowski", "authors": "Bartek Klin, Jurriaan Rot", "title": "Coalgebraic trace semantics via forgetful logics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2622", "doi": "10.2168/LMCS-12(4:10)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use modal logic as a framework for coalgebraic trace semantics, and show\nthe flexibility of the approach with concrete examples such as the language\nsemantics of weighted, alternating and tree automata, and the trace semantics\nof generative probabilistic systems. We provide a sufficient condition under\nwhich a logical semantics coincides with the trace semantics obtained via a\ngiven determinization construction. Finally, we consider a condition that\nguarantees the existence of a canonical determinization procedure that is\ncorrect with respect to a given logical semantics. That procedure is closely\nrelated to Brzozowski's minimization algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 08:28:37 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 12:58:47 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2016 20:57:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Klin", "Bartek", ""], ["Rot", "Jurriaan", ""]]}, {"id": "1611.05640", "submitter": "J\\\"org P\\\"uhrer", "authors": "Stefan Ellmauthaler, J\\\"org P\\\"uhrer", "title": "Stream Packing for Asynchronous Multi-Context Systems using ASP", "comments": "Workshop on Trends and Applications of Answer Set Programming (TAASP\n  2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a processing unit relies on data from external streams, we may face the\nproblem that the stream data needs to be rearranged in a way that allows the\nunit to perform its task(s). On arrival of new data, we must decide whether\nthere is sufficient information available to start processing or whether to\nwait for more data. Furthermore, we need to ensure that the data meets the\ninput specification of the processing step. In the case of multiple input\nstreams it is also necessary to coordinate which data from which incoming\nstream should form the input of the next process instantiation. In this work,\nwe propose a declarative approach as an interface between multiple streams and\na processing unit. The idea is to specify via answer-set programming how to\narrange incoming data in packages that are suitable as input for subsequent\nprocessing. Our approach is intended for use in asynchronous multi-context\nsystems (aMCSs), a recently proposed framework for loose coupling of knowledge\nrepresentation formalisms that allows for online reasoning in a dynamic\nenvironment. Contexts in aMCSs process data streams from external sources and\nother contexts.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 11:39:58 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ellmauthaler", "Stefan", ""], ["P\u00fchrer", "J\u00f6rg", ""]]}, {"id": "1611.05672", "submitter": "Thorsten Wissmann", "authors": "Andrej Dudenhefner, Moritz Martens, Jakob Rehof", "title": "The Algebraic Intersection Type Unification Problem", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (August\n  15, 2017) lmcs:3858", "doi": "10.23638/LMCS-13(3:9)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algebraic intersection type unification problem is an important component\nin proof search related to several natural decision problems in intersection\ntype systems. It is unknown and remains open whether the algebraic intersection\ntype unification problem is decidable. We give the first nontrivial lower bound\nfor the problem by showing (our main result) that it is exponential time hard.\nFurthermore, we show that this holds even under rank 1 solutions (substitutions\nwhose codomains are restricted to contain rank 1 types). In addition, we\nprovide a fixed-parameter intractability result for intersection type matching\n(one-sided unification), which is known to be NP-complete.\n  We place the algebraic intersection type unification problem in the context\nof unification theory. The equational theory of intersection types can be\npresented as an algebraic theory with an ACI (associative, commutative, and\nidempotent) operator (intersection type) combined with distributivity\nproperties with respect to a second operator (function type). Although the\nproblem is algebraically natural and interesting, it appears to occupy a\nhitherto unstudied place in the theory of unification, and our investigation of\nthe problem suggests that new methods are required to understand the problem.\nThus, for the lower bound proof, we were not able to reduce from known results\nin ACI-unification theory and use game-theoretic methods for two-player tiling\ngames.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 13:13:18 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 08:50:51 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 11:31:52 GMT"}, {"version": "v4", "created": "Tue, 20 Jun 2017 21:24:17 GMT"}, {"version": "v5", "created": "Mon, 14 Aug 2017 09:32:51 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Dudenhefner", "Andrej", ""], ["Martens", "Moritz", ""], ["Rehof", "Jakob", ""]]}, {"id": "1611.05990", "submitter": "Cezary Kaliszyk", "authors": "Michael F\\\"arber, Cezary Kaliszyk, Josef Urban", "title": "Monte Carlo Tableau Proof Search", "comments": null, "journal-ref": "Proceedings of the 26th International Conference on Automated\n  Deduction, CADE 2017", "doi": "10.1007/978-3-319-63046-5_34", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Monte Carlo Tree Search to guide proof search in tableau calculi.\nThis includes proposing a number of proof-state evaluation heuristics, some of\nwhich are learnt from previous proofs. We present an implementation based on\nthe leanCoP prover. The system is trained and evaluated on a large suite of\nrelated problems coming from the Mizar proof assistant, showing that it is\ncapable to find new and different proofs.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 06:30:09 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 00:34:50 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1611.06389", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "The Explicit Definition of Quantifiers via Hilbert's epsilon is\n  Confluent and Terminating", "comments": "ii+20pp", "journal-ref": "IfCoLog Journal of Logics and their Applications, Vol. 4, number\n  2, March 2017, pp. 527--547", "doi": null, "report-no": "SEKI Report SR-2015-02", "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the elimination of quantifiers in first-order formulas via\nHilbert's epsilon-operator (or -binder), following Bernays' explicit\ndefinitions of the existential and the universal quantifier symbol by means of\nepsilon-terms. This elimination has its first explicit occurrence in the proof\nof the first epsilon-theorem in Hilbert-Bernays in 1939. We think that there is\na lacuna in this proof w.r.t. this elimination, related to the erroneous\nassumption that explicit definitions always terminate. Surprisingly, to the\nbest of our knowledge, nobody ever proved confluence or termination for this\nelimination procedure. Even myths on non-confluence and the openness of the\ntermination problem are circulating. We show confluence and termination of this\nelimination procedure by means of a direct, straightforward, and easily\nverifiable proof, based on a new theorem on how to obtain termination from weak\nnormalization.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 15:57:08 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "1611.06413", "submitter": "Orkunt Sabuncu", "authors": "Orkunt Sabuncu, Torsten Schaub, Christian Schulz-Hanke", "title": "Formalizing Multi-Agent Systems Using Action Descriptions in Single\n  Agent Perspective", "comments": "Workshop on Trends and Applications of Answer Set Programming,\n  TAASP'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based representations of multi-agent systems have been extensively\nstudied. In this work, we focus on the action language BC to formalize global\nviews of MAS domains. Methodologically, we start representing the behaviour of\neach agent by an action description from a single agent perspective. Then, it\ngoes through two stages that guide the modeler in composing the global view by\nfirst designating multi-agent aspects of the domain via potential conflicts and\nlater resolving these conflicts according to the expected behaviour of the\noverall system. Considering that representing single agent descriptions is\nrelatively simpler than representing multi-agent description directly, the\nformalization developed here is valuable from a knowledge representation\nperspective.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 18:57:05 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Sabuncu", "Orkunt", ""], ["Schaub", "Torsten", ""], ["Schulz-Hanke", "Christian", ""]]}, {"id": "1611.06631", "submitter": "Chitta Baral", "authors": "Vladik Kreinovich and Chitta Baral", "title": "On Selecting a Conjunction Operation in Probabilistic Soft Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Soft Logic has been proposed and used in several applications\nas an efficient way to deal with inconsistency, uncertainty and relational\nrepresentation. In several applications, this approach has led to an adequate\ndescription of the corresponding human reasoning. In this paper, we provide a\ntheoretical explanation for one of the semi-heuristic choices made in this\napproach: namely, we explain the choice of the corresponding conjunction\noperations. Our explanation leads to a more general family of operations which\nmay be used in future applications of probabilistic soft logic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 01:50:56 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Kreinovich", "Vladik", ""], ["Baral", "Chitta", ""]]}, {"id": "1611.07178", "submitter": "EPTCS", "authors": "Ruzica Piskac, Rayna Dimitrova", "title": "Proceedings Fifth Workshop on Synthesis", "comments": null, "journal-ref": "EPTCS 229, 2016", "doi": "10.4204/EPTCS.229", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SYNT workshop aims to bring together researchers interested in the broad\narea of synthesis of computing systems. The goal is to foster the development\nof frontier techniques in automating the development of computing system.\nContributions of interest include algorithms, complexity and decidability\nanalysis, as well as reproducible heuristics, implemented tools, and\nexperimental evaluation. Application domains include software, hardware,\nembedded, and cyberphysical systems. Computation models include functional,\nreactive, hybrid and timed systems. Identifying, formalizing, and evaluating\nsynthesis in particular application domains is encouraged.\n  The fifth iteration of the workshop took place in Toronto, Canada. It was\nco-located with the 28th International Conference on Computer Aided\nVerification. The workshop included twelve contributed talks and two invited\ntalks. In addition, it featured a special session about the Syntax-Guided\nSynthesis Competition (SyGuS) and the SyntComp Synthesis competition.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 07:41:53 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Piskac", "Ruzica", ""], ["Dimitrova", "Rayna", ""]]}, {"id": "1611.07255", "submitter": "J\\\"urgen Koslowski", "authors": "Giulio Guerrieri, Luca Paolini, Simona Ronchi Della Rocca", "title": "Standardization and Conservativity of a Refined Call-by-Value\n  lambda-Calculus", "comments": "27 pages", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (December\n  22, 2017) lmcs:4162", "doi": "10.23638/LMCS-13(4:29)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of Plotkin's call-by-value lambda-calculus via two\ncommutation rules (sigma-reductions). These commutation rules are sufficient to\nremove harmful call-by-value normal forms from the calculus, so that it enjoys\nelegant characterizations of many semantic properties. We prove that this\nextended calculus is a conservative refinement of Plotkin's one. In particular,\nthe notions of solvability and potential valuability for this calculus coincide\nwith those for Plotkin's call-by-value lambda-calculus. The proof rests on a\nstandardization theorem proved by generalizing Takahashi's approach of parallel\nreductions to our set of reduction rules. The standardization is weak (i.e.\nredexes are not fully sequentialized) because of overlapping interferences\nbetween reductions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 11:32:10 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 12:08:24 GMT"}, {"version": "v3", "created": "Thu, 21 Dec 2017 13:21:47 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Guerrieri", "Giulio", ""], ["Paolini", "Luca", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "1611.07372", "submitter": "Ale\\v{s} Bizjak", "authors": "Parosh Aziz Abdulla, Mohamed Faouzi Atig, Stefanos Kaxiras, Carl\n  Leonardsson, Alberto Ros and Yunyun Zhu", "title": "Mending Fences with Self-Invalidation and Self-Downgrade", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  16, 2018) lmcs:4211", "doi": "10.23638/LMCS-14(1:6)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cache coherence protocols based on self-invalidation and self-downgrade have\nrecently seen increased popularity due to their simplicity, potential\nperformance efficiency, and low energy consumption. However, such protocols\nresult in memory instruction reordering, thus causing extra program behaviors\nthat are often not intended by the programmers. We propose a novel formal model\nthat captures the semantics of programs running under such protocols, and\nfeatures a set of fences that interact with the coherence layer. Using the\nmodel, we design an algorithm to analyze the reachability and check whether a\nprogram satisfies a given safety property with the current set of fences. We\ndescribe a method for insertion of optimal sets of fences that ensure\ncorrectness of the program under such protocols. The method relies on a\ncounter-example guided fence insertion procedure. One feature of our method is\nthat it can handle a variety of fences (with different costs). This diversity\nmakes optimization more difficult since one has to optimize the total cost of\nthe inserted fences, rather than just their number. To demonstrate the strength\nof our approach, we have implemented a prototype and run it on a wide range of\nexamples and benchmarks. We have also, using simulation, evaluated the\nperformance of the resulting fenced programs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 15:43:23 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 16:15:18 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 10:33:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Kaxiras", "Stefanos", ""], ["Leonardsson", "Carl", ""], ["Ros", "Alberto", ""], ["Zhu", "Yunyun", ""]]}, {"id": "1611.07621", "submitter": "EPTCS", "authors": "Werner Damm, Bernd Finkbeiner, Astrid Rakow", "title": "What You Really Need To Know About Your Neighbor", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 21-34", "doi": "10.4204/EPTCS.229.4", "report-no": null, "categories": "cs.LO cs.GT cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in system design is to decide how much of the design\nof one component must be known in order to successfully design another\ncomponent of the system. We study this question in the setting of reactive\nsynthesis, where one constructs a system implementation from a specification\ngiven in temporal logic. In previous work, we have shown that the system can be\nconstructed compositionally, one component at a time, if the specification\nadmits a \"dominant\" (as explained in Introduction) strategy for each component.\nIn this paper, we generalize the approach to settings where dominant strategies\nonly exist under certain assumptions about the future behavior of the other\ncomponents. We present an incremental synthesis method based on the automatic\nconstruction of such assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:16:18 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Damm", "Werner", ""], ["Finkbeiner", "Bernd", ""], ["Rakow", "Astrid", ""]]}, {"id": "1611.07622", "submitter": "EPTCS", "authors": "Shahar Maoz (Tel Aviv University), Or Pistiner (Tel Aviv University),\n  Jan Oliver Ringert (Tel Aviv University)", "title": "Symbolic BDD and ADD Algorithms for Energy Games", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 35-54", "doi": "10.4204/EPTCS.229.5", "report-no": null, "categories": "cs.LO cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy games, which model quantitative consumption of a limited resource,\ne.g., time or energy, play a central role in quantitative models for reactive\nsystems. Reactive synthesis constructs a controller which satisfies a given\nspecification, if one exists. For energy games a synthesized controller ensures\nto satisfy not only the safety constraints of the specification but also the\nquantitative constraints expressed in the energy game. A symbolic algorithm for\nenergy games, recently presented by Chatterjee et al., is symbolic in its\nrepresentation of quantitative values but concrete in the representation of\ngame states and transitions. In this paper we present an algorithm that is\nsymbolic both in the quantitative values and in the underlying game\nrepresentation. We have implemented our algorithm using two different symbolic\nrepresentations for reactive games, Binary Decision Diagrams (BDD) and\nAlgebraic Decision Diagrams (ADD). We investigate the commonalities and\ndifferences of the two implementations and compare their running times on\nspecifications of energy games.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:16:27 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Maoz", "Shahar", "", "Tel Aviv University"], ["Pistiner", "Or", "", "Tel Aviv University"], ["Ringert", "Jan Oliver", "", "Tel Aviv University"]]}, {"id": "1611.07625", "submitter": "EPTCS", "authors": "Manos Koukoutos (EPFL), Etienne Kneuss (EPFL), Viktor Kuncak (EPFL)", "title": "An Update on Deductive Synthesis and Repair in the Leon Tool", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 100-111", "doi": "10.4204/EPTCS.229.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report our progress in scaling deductive synthesis and repair of recursive\nfunctional Scala programs in the Leon tool. We describe new techniques,\nincluding a more precise mechanism for encoding the space of meaningful\ncandidate programs. Our techniques increase the scope of synthesis by expanding\nthe space of programs we can synthesize and by reducing the synthesis time in\nmany cases. As a new example, we present a run-length encoding function for a\nlist of values, which Leon can now automatically synthesize from specification\nconsisting of the decoding function and the local minimality property of the\nencoded value.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:16:55 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Koukoutos", "Manos", "", "EPFL"], ["Kneuss", "Etienne", "", "EPFL"], ["Kuncak", "Viktor", "", "EPFL"]]}, {"id": "1611.07626", "submitter": "EPTCS", "authors": "Swen Jacobs (Saarland University), Roderick Bloem (Graz University of\n  Technology)", "title": "The Reactive Synthesis Competition: SYNTCOMP 2016 and Beyond", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 133-148", "doi": "10.4204/EPTCS.229.11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the design of the third reactive synthesis competition (SYNTCOMP\n2016), including a major extension of the competition to specifications in full\nlinear temporal logic. We give a brief overview of the synthesis problem as\nconsidered in SYNTCOMP, and present the rules of the competition in 2016, as\nwell as the ideas behind our design choices. Furthermore, we evaluate the\nrecent changes to the competition based on the experiences with SYNTCOMP 2016.\nFinally, we give an outlook on further changes and extensions of the\ncompetition that are planned for the future.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:17:11 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Jacobs", "Swen", "", "Saarland University"], ["Bloem", "Roderick", "", "Graz University of\n  Technology"]]}, {"id": "1611.07627", "submitter": "EPTCS", "authors": "Rajeev Alur (University of Pennsylvania), Dana Fisman (Ben-Gurion\n  University), Rishabh Singh (Microsoft Research, Redmond), Armando\n  Solar-Lezama (Massachusetts Institute of Technology)", "title": "SyGuS-Comp 2016: Results and Analysis", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178. arXiv admin note: text\n  overlap with arXiv:1602.01170", "journal-ref": "EPTCS 229, 2016, pp. 178-202", "doi": "10.4204/EPTCS.229.13", "report-no": null, "categories": "cs.SE cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an\nimplementation f that meets both a semantic constraint given by a logical\nformula $\\varphi$ in a background theory T, and a syntactic constraint given by\na grammar G, which specifies the allowed set of candidate implementations. Such\na synthesis problem can be formally defined in SyGuS-IF, a language that is\nbuilt on top of SMT-LIB.\n  The Syntax-Guided Synthesis Competition (SyGuS-Comp) is an effort to\nfacilitate, bring together and accelerate research and development of efficient\nsolvers for SyGuS by providing a platform for evaluating different synthesis\ntechniques on a comprehensive set of benchmarks. In this year's competition we\nadded a new track devoted to programming by examples. This track consisted of\ntwo categories, one using the theory of bit-vectors and one using the theory of\nstrings. This paper presents and analyses the results of SyGuS-Comp'16.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:17:40 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Alur", "Rajeev", "", "University of Pennsylvania"], ["Fisman", "Dana", "", "Ben-Gurion\n  University"], ["Singh", "Rishabh", "", "Microsoft Research, Redmond"], ["Solar-Lezama", "Armando", "", "Massachusetts Institute of Technology"]]}, {"id": "1611.07716", "submitter": "J\\\"urgen Koslowski", "authors": "Frederik Harwath and Nicole Schweikardt", "title": "On the locality of arb-invariant first-order formulas with modulo\n  counting quantifiers", "comments": "This is the full version of the conference contribution \"On the\n  locality of arb-invariant first-order logic with modulo counting\n  quantifiers\", CSL 2013", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2620", "doi": "10.2168/LMCS-12(4:8)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Gaifman locality and Hanf locality of an extension of first-order\nlogic with modulo p counting quantifiers (FO+MOD_p, for short) with arbitrary\nnumerical predicates. We require that the validity of formulas is independent\nof the particular interpretation of the numerical predicates and refer to such\nformulas as arb-invariant formulas. This paper gives a detailed picture of\nlocality and non-locality properties of arb-invariant FO+MOD_p. For example, on\nthe class of all finite structures, for any p >= 2, arb-invariant FO+MOD_p is\nneither Hanf nor Gaifman local with respect to a sublinear locality radius.\nHowever, in case that p is an odd prime power, it is weakly Gaifman local with\na polylogarithmic locality radius. And when restricting attention to the class\nof string structures, for odd prime powers p, arb-invariant FO+MOD_p is both\nHanf and Gaifman local with a polylogarithmic locality radius. Our negative\nresults build on examples of order-invariant FO+MOD_p formulas presented in\nNiemist\\\"o's PhD thesis. Our positive results make use of the close connection\nbetween FO+MOD_p and Boolean circuits built from NOT-gates and AND-, OR-, and\nMOD_p- gates of arbitrary fan-in.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 10:08:01 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 09:54:45 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2016 20:53:06 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Harwath", "Frederik", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "1611.07726", "submitter": "Steven De Oliveira", "authors": "Steven de Oliveira, Saddek Bensalem and Virgile Prevosto", "title": "Polynomial invariants by linear algebra", "comments": "15 pages + 6 appendix", "journal-ref": "Automated Technology for Verification and Analysis 2016 Volume\n  9938 of the series Lecture Notes in Computer Science pp 479-494", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a new technique for generating polynomial\ninvariants, divided in two independent parts : a procedure that reduces\npolynomial assignments composed loops analysis to linear loops under certain\nhypotheses and a procedure for generating inductive invariants for linear\nloops. Both of these techniques have a polynomial complexity for a bounded\nnumber of variables and we guarantee the completeness of the technique for a\nbounded degree which we successfully implemented for C programs verification.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 10:25:54 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["de Oliveira", "Steven", ""], ["Bensalem", "Saddek", ""], ["Prevosto", "Virgile", ""]]}, {"id": "1611.07753", "submitter": "Steven De Oliveira", "authors": "Steven de Oliveira, Saddek Bensalem and Virgile Prevosto", "title": "Synthesizing invariants by solving solvable loops", "comments": "15 pages + 3 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When proving invariance properties of a program, we face two problems. The\nfirst problem is related to the necessity of proving tautologies of considered\nassertion language, whereas the second manifests in the need of finding\nsufficiently strong invariants. This paper focuses on the second problem and\ndescribes a new method for the automatic generation of loop invariants that\nhandles polynomial and non deterministic assignments. This technique is based\non the eigenvector generation for a given linear transformation and on the\npolynomial optimization problem, which we implemented in the open-source tool\nPilat.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 11:53:52 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["de Oliveira", "Steven", ""], ["Bensalem", "Saddek", ""], ["Prevosto", "Virgile", ""]]}, {"id": "1611.07803", "submitter": "Davide Giacomo Cavezza", "authors": "Davide G. Cavezza and Dalal Alrajeh", "title": "Interpolation-Based GR(1) Assumptions Refinement", "comments": "Extension of the paper in TACAS 2017 proceedings with the same title;\n  more comprehensive description; new experimental setting; additional case\n  studies; additional evidence to support the original claim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of assumptions refinement in the context of\nunrealizable specifications for reactive systems. We propose a new\ncounterstrategy-guided synthesis approach for GR(1) specifications based on\nCraig's interpolants. Our interpolation-based method identifies causes for\nunrealizability and computes assumptions that directly target unrealizable\ncores, without the need for user input. Thereby, we discuss how this property\nreduces the maximum number of steps needed to converge to realizability\ncompared with other techniques. We describe properties of interpolants that\nyield helpful GR(1) assumptions and prove the soundness of the results.\nFinally, we demonstrate that our approach yields weaker assumptions than\nbaseline techniques, and finds solutions in case studies that are unsolvable\nvia existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 14:12:15 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 18:06:53 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 17:41:39 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Cavezza", "Davide G.", ""], ["Alrajeh", "Dalal", ""]]}, {"id": "1611.07812", "submitter": "Vincent Botbol", "authors": "Vincent Botbol, Emmanuel Chailloux, Tristan Le Gall", "title": "Static Analysis of Communicating Processes using Symbolic Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general model allowing static analysis based on abstract\ninterpretation for systems of communicating processes. Our technique, inspired\nby Regular Model Checking, represents set of program states as lattice automata\nand programs semantics as symbolic transducers. This model can express dynamic\ncreation/destruction of processes and communications. Using the abstract\ninterpretation framework, we are able to provide a sound over-approximation of\nthe reachability set of the system thus allowing us to prove safety properties.\nWe implemented this method in a prototype that targets the MPI library for C\nprograms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 14:25:58 GMT"}, {"version": "v2", "created": "Sun, 27 Nov 2016 20:43:01 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Botbol", "Vincent", ""], ["Chailloux", "Emmanuel", ""], ["Gall", "Tristan Le", ""]]}, {"id": "1611.08208", "submitter": "Michael Lettmann", "authors": "Alexander Leitsch, Michael Peter Lettmann", "title": "The problem of Pi_2-cut-introduction", "comments": "52 pages", "journal-ref": null, "doi": "10.1016/j.tcs.2017.10.003", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithmic method of proof compression based on the\nintroduction of Pi_2-cuts into a cut-free LK-proof. The current approach is\nbased on an inversion of Gentzen s cut-elimination method and extends former\nmethods for introducing Pi_1-cuts. The Herbrand instances of a cut-free proof\npi of a sequent S are described by a grammar G which encodes substitutions\ndefined in the elimination of quantified cuts. We present an algorithm which,\ngiven a grammar G, constructs a Pi_2-cut formula A and a proof phi of S with\none cut on A. It is shown that, by this algorithm, we can achieve an\nexponential proof compression.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 15:05:39 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 10:29:47 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Leitsch", "Alexander", ""], ["Lettmann", "Michael Peter", ""]]}, {"id": "1611.08541", "submitter": "J\\\"urgen Koslowski", "authors": "Fabio Mogavero, Aniello Murano, Giuseppe Perelli, and Moshe Y. Vardi", "title": "Reasoning about Strategies: on the Satisfiability Problem", "comments": "arXiv admin note: text overlap with arXiv:1112.6275, arXiv:1202.1309", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 17,\n  2017) lmcs:3204", "doi": "10.23638/LMCS-13(1:9)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategy Logic (SL, for short) has been introduced by Mogavero, Murano, and\nVardi as a useful formalism for reasoning explicitly about strategies, as\nfirst-order objects, in multi-agent concurrent games. This logic turns out to\nbe very powerful, subsuming all major previously studied modal logics for\nstrategic reasoning, including ATL, ATL*, and the like. Unfortunately, due to\nits high expressiveness, SL has a non-elementarily decidable model-checking\nproblem and the satisfiability question is undecidable, specifically Sigma_1^1.\n  In order to obtain a decidable sublogic, we introduce and study here One-Goal\nStrategy Logic (SL[1G], for short). This is a syntactic fragment of SL,\nstrictly subsuming ATL*, which encompasses formulas in prenex normal form\nhaving a single temporal goal at a time, for every strategy quantification of\nagents. We prove that, unlike SL, SL[1G] has the bounded tree-model property\nand its satisfiability problem is decidable in 2ExpTime, thus not harder than\nthe one for ATL*.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 18:12:11 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 16:45:15 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 08:45:33 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Mogavero", "Fabio", ""], ["Murano", "Aniello", ""], ["Perelli", "Giuseppe", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1611.08554", "submitter": "Fabian Reiter", "authors": "Fabian Reiter", "title": "Asynchronous Distributed Automata: A Characterization of the Modal\n  Mu-Fragment", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2017.100", "report-no": null, "categories": "cs.FL cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish the equivalence between a class of asynchronous distributed\nautomata and a small fragment of least fixpoint logic, when restricted to\nfinite directed graphs. More specifically, the logic we consider is (a variant\nof) the fragment of the modal $\\mu$-calculus that allows least fixpoints but\nforbids greatest fixpoints. The corresponding automaton model uses a network of\nidentical finite-state machines that communicate in an asynchronous manner and\nwhose state diagram must be acyclic except for self-loops. Exploiting the\nconnection with logic, we also prove that the expressive power of those\nmachines is independent of whether or not messages can be lost.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 19:02:23 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 17:40:00 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Reiter", "Fabian", ""]]}, {"id": "1611.08677", "submitter": "Guillermo P\\'erez", "authors": "Romain Brenguier, Guillermo A. P\\'erez, Jean-Fran\\c{c}ois Raskin, Ocan\n  Sankur", "title": "Admissibility in Quantitative Graph Games", "comments": "This is the full version of an article that will be published in\n  FSTTCS'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Admissibility has been studied for games of infinite duration with Boolean\nobjectives. We extend here this study to games of infinite duration with\nquantitative objectives. First, we show that, un- der the assumption that\noptimal worst-case and cooperative strategies exist, admissible strategies are\nguaranteed to exist. Second, we give a characterization of admissible\nstrategies using the no- tion of adversarial and cooperative values of a\nhistory, and we characterize the set of outcomes that are compatible with\nadmissible strategies. Finally, we show how these characterizations can be used\nto design algorithms to decide relevant verification and synthesis problems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 08:20:11 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Brenguier", "Romain", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""]]}, {"id": "1611.08733", "submitter": "Jan Jakubuv", "authors": "Jan Jakubuv, Josef Urban", "title": "BliStrTune: Hierarchical Invention of Theorem Proving Strategies", "comments": "Submitted to Certified Programs and Proofs (CPP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inventing targeted proof search strategies for specific problem sets is a\ndifficult task. State-of-the-art automated theorem provers (ATPs) such as E\nallow a large number of user-specified proof search strategies described in a\nrich domain specific language. Several machine learning methods that invent\nstrategies automatically for ATPs were proposed previously. One of them is the\nBlind Strategymaker (BliStr), a system for automated invention of ATP\nstrategies.\n  In this paper we introduce BliStrTune -- a hierarchical extension of BliStr.\nBliStrTune allows exploring much larger space of E strategies by interleaving\nsearch for high-level parameters with their fine-tuning. We use BliStrTune to\ninvent new strategies based also on new clause weight functions targeted at\nproblems from large ITP libraries. We show that the new strategies\nsignificantly improve E's performance in solving problems from the Mizar\nMathematical Library.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 18:48:43 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Jakubuv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1611.08738", "submitter": "Thorsten Wissmann", "authors": "Georgios Kourtis, Ian Pratt-Hartmann", "title": "Adding Path-Functional Dependencies to the Guarded Two-Variable Fragment\n  with Counting", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (October\n  30, 2017) lmcs:4028", "doi": "10.23638/LMCS-13(4:4)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The satisfiability and finite satisfiability problems for the two-variable\nguarded fragment of first-order logic with counting quantifiers, a database,\nand path-functional dependencies are both ExpTime-complete.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 20:15:47 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 13:26:56 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 08:53:22 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Kourtis", "Georgios", ""], ["Pratt-Hartmann", "Ian", ""]]}, {"id": "1611.08800", "submitter": "Ale\\v{s} Bizjak", "authors": "Davide Bresolin, Emilio Mu\\~noz-Velasco, Guido Sciavicco", "title": "On Sub-Propositional Fragments of Modal Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (June 22,\n  2018) lmcs:4632", "doi": "10.23638/LMCS-14(2:16)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the well-known modal logics $\\mathbf{K}$,\n$\\mathbf{T}$, $\\mathbf{K4}$, and $\\mathbf{S4}$, and we study some of their\nsub-propositional fragments, namely the classical Horn fragment, the Krom\nfragment, the so-called core fragment, defined as the intersection of the Horn\nand the Krom fragments, plus their sub-fragments obtained by limiting the use\nof boxes and diamonds in clauses. We focus, first, on the relative expressive\npower of such languages: we introduce a suitable measure of expressive power,\nand we obtain a complex hierarchy that encompasses all fragments of the\nconsidered logics. Then, after observing the low expressive power, in\nparticular, of the Horn fragments without diamonds, we study the computational\ncomplexity of their satisfiability problem, proving that, in general, it\nbecomes polynomial.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 07:41:06 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 15:24:40 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 14:06:22 GMT"}, {"version": "v4", "created": "Thu, 21 Jun 2018 16:03:13 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Bresolin", "Davide", ""], ["Mu\u00f1oz-Velasco", "Emilio", ""], ["Sciavicco", "Guido", ""]]}, {"id": "1611.08888", "submitter": "Hanwen Wu", "authors": "Hongwei Xi, Hanwen Wu", "title": "Propositions in Linear Multirole Logic as Multiparty Session Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify multirole logic as a new form of logic and formalize linear\nmultirole logic (LMRL) as a natural generalization of classical linear logic\n(CLL). Among various meta-properties established for LMRL, we obtain one named\nmulti-cut elimination stating that every cut between three (or more) sequents\n(as a generalization of a cut between two sequents) can be eliminated, thus\nextending the celebrated result of cut-elimination by Gentzen. We also present\na variant of $\\pi$-calculus for multiparty sessions that demonstrates a tight\ncorrespondence between process communication in this variant and multi-cut\nelimination in LMRL, thus extending some recent results by Caires and Pfenning\n(2010) and Wadler (2012), among others, along a similar line of work.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 19:06:42 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Xi", "Hongwei", ""], ["Wu", "Hanwen", ""]]}, {"id": "1611.08992", "submitter": "David Naumann", "authors": "Anindya Banerjee, David A. Naumann, Mohammad Nikouei", "title": "Relational Logic with Framing and Hypotheses: Technical Report", "comments": "Technical report to accompany a paper to appear in FSTTCS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational properties arise in many settings: relating two versions of a\nprogram that use different data representations, noninterference properties for\nsecurity, etc. The main ingredient of relational verification, relating aligned\npairs of intermediate steps, has been used in numerous guises, but existing\nrelational program logics are narrow in scope. This paper introduces a logic\nbased on novel syntax that weaves together product programs to express\nalignment of control flow points at which relational formulas are asserted.\nCorrectness judgments feature hypotheses with relational specifications,\ndischarged by a rule for the linking of procedure implementations. The logic\nsupports reasoning about program-pairs containing both similar and dissimilar\ncontrol and data structures. Reasoning about dynamically allocated objects is\nsupported by a frame rule based on frame conditions amenable to SMT provers. We\nprove soundness and sketch how the logic can be used for data abstraction, loop\noptimizations, and secure information flow.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 05:57:30 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Banerjee", "Anindya", ""], ["Naumann", "David A.", ""], ["Nikouei", "Mohammad", ""]]}, {"id": "1611.09014", "submitter": "Renate Schmidt", "authors": "Peter Baumgartner and Renate A. Schmidt", "title": "Blocking and Other Enhancements for Bottom-Up Model Generation Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model generation is a problem complementary to theorem proving and is\nimportant for fault analysis and debugging of formal specifications of security\nprotocols, programs and terminological definitions. This paper discusses\nseveral ways of enhancing the paradigm of bottom-up model generation. The two\nmain contributions are new, generalized blocking techniques and a new\nrange-restriction transformation. The blocking techniques are based on simple\ntransformations of the input set together with standard equality reasoning and\nredundancy elimination techniques. These provide general methods for finding\nsmall, finite models. The range-restriction transformation refines existing\ntransformations to range-restricted clauses by carefully limiting the creation\nof domain terms. All possible combinations of the introduced techniques and\nclassical range-restriction were tested on the clausal problems of the TPTP\nVersion 6.0.0 with an implementation based on the SPASS theorem prover using a\nhyperresolution-like refinement. Unrestricted domain blocking gave best results\nfor satisfiable problems showing it is a powerful technique indispensable for\nbottom-up model generation methods. Both in combination with the new\nrange-restricting transformation, and the classical range-restricting\ntransformation, good results have been obtained. Limiting the creation of terms\nduring the inference process by using the new range restricting transformation\nhas paid off, especially when using it together with a shifting transformation.\nThe experimental results also show that classical range restriction with\nunrestricted blocking provides a useful complementary method. Overall, the\nresults showed bottom-up model generation methods were good for disproving\ntheorems and generating models for satisfiable problems, but less efficient\nthan SPASS in auto mode for unsatisfiable problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 07:54:50 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 22:30:09 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Baumgartner", "Peter", ""], ["Schmidt", "Renate A.", ""]]}, {"id": "1611.09035", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Algebraic Laws for True Concurrency", "comments": "110 pages, 3 figures, 48 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find the algebraic laws for true concurrency. Eventually, we establish a\nwhole axiomatization for true concurrency called APTC (Algebra for Parallelism\nin True Concurrency). The theory APTC has four modules: BATC (Basic Algebra for\nTrue Concurrency), APTC (Algebra for Parallelism in True Concurrency),\nrecursion and abstraction. And also, we show the applications and extensions of\nAPTC.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 09:37:05 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 08:01:14 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 08:51:40 GMT"}, {"version": "v4", "created": "Sat, 4 May 2019 08:56:23 GMT"}, {"version": "v5", "created": "Tue, 3 Sep 2019 04:31:06 GMT"}, {"version": "v6", "created": "Sun, 15 Sep 2019 09:46:32 GMT"}, {"version": "v7", "created": "Thu, 26 Sep 2019 05:39:45 GMT"}, {"version": "v8", "created": "Mon, 10 Feb 2020 11:25:58 GMT"}, {"version": "v9", "created": "Sat, 15 Feb 2020 17:46:14 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1611.09067", "submitter": "J\\\"urgen Koslowski", "authors": "Mila Dalla Preda, Maurizio Gabbrielli, Saverio Giallorenzo, Ivan\n  Lanese, Jacopo Mauro", "title": "Dynamic Choreographies: Theory And Implementation", "comments": "arXiv admin note: text overlap with arXiv:1407.0970", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (April 10,\n  2017) lmcs:3263", "doi": "10.23638/LMCS-13(2:1)2017", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming distributed applications free from communication deadlocks and\nrace conditions is complex. Preserving these properties when applications are\nupdated at runtime is even harder. We present a choreographic approach for\nprogramming updatable, distributed applications. We define a choreography\nlanguage, called Dynamic Interaction-Oriented Choreography (AIOC), that allows\nthe programmer to specify, from a global viewpoint, which parts of the\napplication can be updated. At runtime, these parts may be replaced by new AIOC\nfragments from outside the application. AIOC programs are compiled, generating\ncode for each participant in a process-level language called Dynamic\nProcess-Oriented Choreographies (APOC). We prove that APOC distributed\napplications generated from AIOC specifications are deadlock free and race free\nand that these properties hold also after any runtime update. We instantiate\nthe theoretical model above into a programming framework called Adaptable\nInteraction-Oriented Choreographies in Jolie (AIOCJ) that comprises an\nintegrated development environment, a compiler from an extension of AIOCs to\ndistributed Jolie programs, and a runtime environment to support their\nexecution.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 11:04:47 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 15:31:49 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 11:37:43 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Preda", "Mila Dalla", ""], ["Gabbrielli", "Maurizio", ""], ["Giallorenzo", "Saverio", ""], ["Lanese", "Ivan", ""], ["Mauro", "Jacopo", ""]]}, {"id": "1611.09263", "submitter": "Bas Spitters", "authors": "Lars Birkedal, Ale\\v{s} Bizjak, Ranald Clouston, Hans Bugge Grathwohl,\n  Bas Spitters, Andrea Vezzosi", "title": "Guarded Cubical Type Theory", "comments": "Final version; Special Issue on Homotopy Type Theory and Univalent\n  Foundations, Journal of Automated Reasoning, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper improves the treatment of equality in guarded dependent type\ntheory (GDTT), by combining it with cubical type theory (CTT). GDTT is an\nextensional type theory with guarded recursive types, which are useful for\nbuilding models of program logics, and for programming and reasoning with\ncoinductive types. We wish to implement GDTT with decidable type checking,\nwhile still supporting non-trivial equality proofs that reason about the\nextensions of guarded recursive constructions. CTT is a variation of\nMartin-L\\\"of type theory in which the identity type is replaced by abstract\npaths between terms. CTT provides a computational interpretation of functional\nextensionality, enjoys canonicity for the natural numbers type, and is\nconjectured to support decidable type-checking. Our new type theory, guarded\ncubical type theory (GCTT), provides a computational interpretation of\nextensionality for guarded recursive types. This further expands the\nfoundations of CTT as a basis for formalisation in mathematics and computer\nscience. We present examples to demonstrate the expressivity of our type\ntheory, all of which have been checked using a prototype type-checker\nimplementation. We show that CTT can be given semantics in presheaves on the\nproduct of the cube category and a small category with an initial object. We\nthen show that the category of presheaves on the product of the cube category\nand omega provides semantics for GCTT.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 18:01:48 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 14:18:20 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Birkedal", "Lars", ""], ["Bizjak", "Ale\u0161", ""], ["Clouston", "Ranald", ""], ["Grathwohl", "Hans Bugge", ""], ["Spitters", "Bas", ""], ["Vezzosi", "Andrea", ""]]}, {"id": "1611.09318", "submitter": "Alfons Laarman", "authors": "Henning G\\\"unther and Alfons Laarman and Ana Sokolova and Georg\n  Weissenbacher", "title": "Dynamic Reductions for Model Checking Concurrent Software", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic model checking of parallel programs stands and falls with effective\nmethods of dealing with the explosion of interleavings. We propose a dynamic\nreduction technique to avoid unnecessary interleavings. By extending Lipton's\noriginal work with a notion of bisimilarity, we accommodate dynamic\ntransactions, and thereby reduce dependence on the accuracy of static analysis,\nwhich is a severe bottleneck in other reduction techniques.\n  The combination of symbolic model checking and dynamic reduction techniques\nhas proven to be challenging in the past. Our generic reduction theorem\nnonetheless enables us to derive an efficient symbolic encoding, which we\nimplemented for IC3 and BMC. The experiments demonstrate the power of dynamic\nreduction on several case studies and a large set of SVCOMP benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:11:49 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["G\u00fcnther", "Henning", ""], ["Laarman", "Alfons", ""], ["Sokolova", "Ana", ""], ["Weissenbacher", "Georg", ""]]}, {"id": "1611.09473", "submitter": "EPTCS", "authors": "Prabhakar Ragde (University of Waterloo)", "title": "Proust: A Nano Proof Assistant", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 63-75", "doi": "10.4204/EPTCS.230.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proust is a small Racket program offering rudimentary interactive assistance\nin the development of verified proofs for propositional and predicate logic. It\nis constructed in stages, some of which are done by students before using it to\ncomplete proof exercises, and in parallel with the study of its theoretical\nunderpinnings, including elements of Martin-Lof type theory. The goal is\ntwofold: to demystify some of the machinery behind full-featured proof\nassistants such as Coq and Agda, and to better integrate the study of formal\nlogic with other core elements of an undergraduate computer science curriculum.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:40:04 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Ragde", "Prabhakar", "", "University of Waterloo"]]}, {"id": "1611.09590", "submitter": "Virendra Sule", "authors": "Virendra Sule", "title": "Implicant based parallel all solution solver for Boolean satisfiability", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a parallel computational solver for computing all\nsatifying assignments of a Boolean system of equations defined by Boolean\nfunctions of several variables. While there are we known solvers for\nsatisfiability of Boolean formulas in CNF form, these are designed primarily\nfor deciding satisfiability of the formula and do not address the problem of\nfinding all satisfying solutions. Moreover development of parallel solvers for\nsatisfiability problems is still an unfinished problem of Computer Science. The\nsolver proposed in this paper is aimed at representing all solutions of Boolean\nformulas even without the CNF form with a parallel algorithm. Algorithm\nproposed is applied to Boolean functions in algebraic normal form (ANF). The\nalgorithm is based on the idea to represent the satisfying assignments in terms\nof a complete set of implicants of the Boolean functions appearing as factors\nof a Boolean formula. The algorithm is effective mainly in the case when the\nfactors of the formula are sparse (i.e. have a small fraction of the total\nnumber of variables). This allows small computation of a complete set of\nimplicants of individual factors one at a time and reduce the formula at each\nstep. An algorithm is also proposed for finding a complete set of orthogonal\nimplicants of functions in ANF. An advantages of this algorithm is that all\nsolutions can be represented compactly in terms of implicants. Finally due to\nsmall and distributed computation at every step as well as computation in terms\nof independent threads, the solver proposed in this paper is expected to be\nuseful for developing heuristics for a well scalable parallel solver for large\nsize problems of Boolean satisfiability over large number of processors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 12:27:10 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 12:42:10 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 13:27:22 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Sule", "Virendra", ""]]}, {"id": "1611.09633", "submitter": "Christoph Rauch", "authors": "Dmitriy Traytel", "title": "Formal Languages, Formally and Coinductively", "comments": "Extended version of homonymous FSCD 2016 paper", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  19, 2017) lmcs:3943", "doi": "10.23638/LMCS-13(3:28)2017", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, formal languages are defined as sets of words. More recently,\nthe alternative coalgebraic or coinductive representation as infinite tries,\ni.e., prefix trees branching over the alphabet, has been used to obtain compact\nand elegant proofs of classic results in language theory. In this article, we\nstudy this representation in the Isabelle proof assistant. We define regular\noperations on infinite tries and prove the axioms of Kleene algebra for those\noperations. Thereby, we exercise corecursion and coinduction and confirm the\ncoinductive view being profitable in formalizations, as it improves over the\nset-of-words view with respect to proof automation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 13:56:39 GMT"}, {"version": "v2", "created": "Sat, 13 May 2017 22:58:31 GMT"}, {"version": "v3", "created": "Mon, 18 Sep 2017 12:53:01 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Traytel", "Dmitriy", ""]]}, {"id": "1611.10146", "submitter": "Ashutosh Gupta", "authors": "Supratik Chakraborty, Ashutosh Gupta, Rahul Jain", "title": "Matching Multiplications in Bit-Vector Formulas", "comments": "Accepted in VMCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bit-vector formulas arising from hardware verification problems often contain\nword-level arithmetic operations. Empirical evidence shows that\nstate-of-the-art SMT solvers are not very efficient at reasoning about\nbit-vector formulas with multiplication. This is particularly true when\nmultiplication operators are decomposed and represented in alternative ways in\nthe formula.We present a pre-processing heuristic that identifies certain types\nof decomposed multipliers, and adds special assertions to the input formula\nencoding the equivalence of sub-terms to word-level multiplication. The\npre-processed formulas are then solved using an SMT solver. Our experiments\nwith three SMT solvers show that our heuristic allows several formulas to be\nsolved quickly, while the same formulas time out without the pre-processing\nstep.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 13:45:30 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 04:56:44 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Chakraborty", "Supratik", ""], ["Gupta", "Ashutosh", ""], ["Jain", "Rahul", ""]]}, {"id": "1611.10212", "submitter": "Antonis Achilleos", "authors": "Luca Aceto, Antonis Achilleos, Adrian Francalanza, Anna\n  Ing\\'olfsd\\'ottir and S{\\ae}var \\\"Orn Kjartansson", "title": "Determinizing Monitors for HML with Recursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the determinization of monitors for HML with recursion. We\ndemonstrate that every monitor is equivalent to a deterministic one, which is\nat most doubly exponential in size with respect to the original monitor. When\nmonitors are described as CCS-like processes, this doubly exponential bound is\noptimal. When (deterministic) monitors are described as finite automata (as\ntheir LTS), then they can be exponentially more succinct than their CCS process\nform.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 15:21:01 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Aceto", "Luca", ""], ["Achilleos", "Antonis", ""], ["Francalanza", "Adrian", ""], ["Ing\u00f3lfsd\u00f3ttir", "Anna", ""], ["Kjartansson", "S\u00e6var \u00d6rn", ""]]}, {"id": "1611.10334", "submitter": "Christoph Rauch", "authors": "Cynthia Kop and Jakob Grue Simonsen", "title": "Complexity Hierarchies and Higher-order Cons-free Term Rewriting", "comments": "extended version of a paper submitted to FSCD 2016. arXiv admin note:\n  substantial text overlap with arXiv:1604.08936", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (August 7,\n  2017) lmcs:3847", "doi": "10.23638/LMCS-13(3:8)2017", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructor rewriting systems are said to be cons-free if, roughly,\nconstructor terms in the right-hand sides of rules are subterms of the\nleft-hand sides; the computational intuition is that rules cannot build new\ndata structures. In programming language research, cons-free languages have\nbeen used to characterize hierarchies of computational complexity classes; in\nterm rewriting, cons-free first-order TRSs have been used to characterize the\nclass PTIME.\n  We investigate cons-free higher-order term rewriting systems, the complexity\nclasses they characterize, and how these depend on the type order of the\nsystems. We prove that, for every K $\\geq$ 1, left-linear cons-free systems\nwith type order K characterize E$^K$TIME if unrestricted evaluation is used\n(i.e., the system does not have a fixed reduction strategy).\n  The main difference with prior work in implicit complexity is that (i) our\nresults hold for non-orthogonal term rewriting systems with no assumptions on\nreduction strategy, (ii) we consequently obtain much larger classes for each\ntype order (E$^K$TIME versus EXP$^{K-1}$TIME), and (iii) results for cons-free\nterm rewriting systems have previously only been obtained for K = 1, and with\nadditional syntactic restrictions besides cons-freeness and left-linearity.\n  Our results are among the first implicit characterizations of the hierarchy E\n= E$^1$TIME $\\subsetneq$ E$^2$TIME $\\subsetneq$ ... Our work confirms prior\nresults that having full non-determinism (via overlapping rules) does not\ndirectly allow for characterization of non-deterministic complexity classes\nlike NE. We also show that non-determinism makes the classes characterized\nhighly sensitive to minor syntactic changes like admitting product types or\nnon-left-linear rules.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 20:02:40 GMT"}, {"version": "v2", "created": "Sat, 6 May 2017 11:43:13 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 14:06:34 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Kop", "Cynthia", ""], ["Simonsen", "Jakob Grue", ""]]}]