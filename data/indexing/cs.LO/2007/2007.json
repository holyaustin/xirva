[{"id": "2007.00102", "submitter": "Sebastian Junges", "authors": "Alexander Bork, Sebastian Junges, Joost-Pieter Katoen, Tim Quatmann", "title": "Verification of indefinite-horizon POMDPs", "comments": "Technical report for ATVA 2020 paper with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification problem in MDPs asks whether, for any policy resolving the\nnondeterminism, the probability that something bad happens is bounded by some\ngiven threshold. This verification problem is often overly pessimistic, as the\npolicies it considers may depend on the complete system state. This paper\nconsiders the verification problem for partially observable MDPs, in which the\npolicies make their decisions based on (the history of) the observations\nemitted by the system. We present an abstraction-refinement framework extending\nprevious instantiations of the Lovejoy-approach. Our experiments show that this\nframework significantly improves the scalability of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:01:52 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Bork", "Alexander", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Quatmann", "Tim", ""]]}, {"id": "2007.00111", "submitter": "Wojciech Czerwi\\'nski", "authors": "Wojciech Czerwi\\'nski, Georg Zetzsche", "title": "An Approach to Regular Separability in Vector Addition Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of regular separability of languages of vector addition\nsystems with states (VASS). It asks whether for two given VASS languages K and\nL, there exists a regular language R that includes K and is disjoint from L.\nWhile decidability of the problem in full generality remains an open question,\nthere are several subclasses for which decidability has been shown: It is\ndecidable for (i) one-dimensional VASS, (ii) VASS coverability languages, (iii)\nlanguages of integer VASS, and (iv) commutative VASS languages. We propose a\ngeneral approach to deciding regular separability. We use it to decide regular\nseparability of an arbitrary VASS language from any language in the classes\n(i), (ii), and (iii). This generalizes all previous results, including (iv).\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:17:47 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Czerwi\u0144ski", "Wojciech", ""], ["Zetzsche", "Georg", ""]]}, {"id": "2007.00125", "submitter": "David A. Plaisted", "authors": "David A. Plaisted", "title": "Situation Calculus by Term Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A version of the situation calculus in which situations are represented as\nfirst-order terms is presented. Fluents can be computed from the term\nstructure, and actions on the situations correspond to rewrite rules on the\nterms. Actions that only depend on or influence a subset of the fluents can be\ndescribed as rewrite rules that operate on subterms of the terms in some cases.\nIf actions are bidirectional then efficient completion methods can be used to\nsolve planning problems. This representation for situations and actions is most\nsimilar to the fluent calculus of Thielscher \\cite{Thielscher98}, except that\nthis representation is more flexible and more use is made of the subterm\nstructure. Some examples are given, and a few general methods for constructing\nsuch sets of rewrite rules are presented. This paper was submitted to FSCD 2020\non December 23, 2019.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:47:47 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Plaisted", "David A.", ""]]}, {"id": "2007.00167", "submitter": "Luis Scoccola", "authors": "Thorsten Altenkirch and Luis Scoccola", "title": "The Integers as a Higher Inductive Type", "comments": "11 pages", "journal-ref": "Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in\n  Computer Science (pp. 67-73), 2020", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of defining the integers in Homotopy Type Theory\n(HoTT). We can define the type of integers as signed natural numbers (i.e.,\nusing a coproduct), but its induction principle is very inconvenient to work\nwith, since it leads to an explosion of cases. An alternative is to use\nset-quotients, but here we need to use set-truncation to avoid non-trivial\nhigher equalities. This results in a recursion principle that only allows us to\ndefine function into sets (types satisfying UIP). In this paper we consider\nhigher inductive types using either a small universe or bi-invertible maps.\nThese types represent integers without explicit set-truncation that are\nequivalent to the usual coproduct representation. This is an interesting\nexample since it shows how some coherence problems can be handled in HoTT. We\ndiscuss some open questions triggered by this work. The proofs have been\nformally verified using cubical Agda.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 00:58:06 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Altenkirch", "Thorsten", ""], ["Scoccola", "Luis", ""]]}, {"id": "2007.00304", "submitter": "Valeriu Motroi", "authors": "Valeriu Motroi and Stefan Ciobaca", "title": "A Typo in the Paterson-Wegman-de Champeaux algorithm", "comments": "Unification Algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the Paterson-Wegman-de Champeaux linear-time unification\nalgorithm. We show that there is a small mistake in the de Champeaux\npresentation of the algorithm and we provide a fix.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 07:56:35 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Motroi", "Valeriu", ""], ["Ciobaca", "Stefan", ""]]}, {"id": "2007.00502", "submitter": "Radu Iosif", "authors": "Mnacho Echenim, Radu Iosif, Nicolas Peltier", "title": "Decidable Entailments in Separation Logic with Inductive Definitions:\n  Beyond Established Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a class of Separation Logic formulae, whose entailment problem:\ngiven formulae $\\phi, \\psi_1, \\ldots, \\psi_n$, is every model of $\\phi$ a model\nof some $\\psi_i$? is 2EXPTIME-complete. The formulae in this class are\nexistentially quantified separating conjunctions involving predicate atoms,\ninterpreted by the least sets of store-heap structures that satisfy a set of\ninductive rules, which is also part of the input to the entailment problem.\nPrevious work consider established sets of rules, meaning that every\nexistentially quantified variable in a rule must eventually be bound to an\nallocated location, i.e. from the domain of the heap. In particular, this\nguarantees that each structure has treewidth bounded by the size of the largest\nrule in the set. In contrast, here we show that establishment, although\nsufficient for decidability (alongside two other natural conditions), is not\nnecessary, by providing a condition, called equational restrictedness, which\napplies syntactically to (dis-)equalities. The entailment problem is more\ngeneral in this case, because equationally restricted rules define richer\nclasses of structures, of unbounded treewidth. In this paper we show that (1)\nevery established set of rules can be converted into an equationally restricted\none and (2) the entailment problem is 2EXPTIME-complete in the latter case,\nthus matching the complexity of entailments for established sets of rules.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 14:02:49 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 11:57:39 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 12:52:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Echenim", "Mnacho", ""], ["Iosif", "Radu", ""], ["Peltier", "Nicolas", ""]]}, {"id": "2007.00505", "submitter": "Muhammad Syifa'ul Mufid", "authors": "Alessandro Abate, Alessandro Cimatti, Andrea Micheli, Muhammad\n  Syifa'ul Mufid", "title": "Computation of the Transient in Max-Plus Linear Systems via SMT-Solving", "comments": "The paper consists of 22 pages (including references and Appendix).\n  It is accepted in FORMATS 2020 First revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new approach, grounded in Satisfiability Modulo\nTheories (SMT), to study the transient of a Max-Plus Linear (MPL) system, that\nis the number of steps leading to its periodic regime. Differently from\nstate-of-the-art techniques, our approach allows the analysis of periodic\nbehaviors for subsets of initial states, as well as the characterization of\nsets of initial states exhibiting the same specific periodic behavior and\ntransient. Our experiments show that the proposed technique dramatically\noutperforms state-of-the-art methods based on max-plus algebra computations for\nsystems of large dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 14:06:40 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 18:54:46 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Abate", "Alessandro", ""], ["Cimatti", "Alessandro", ""], ["Micheli", "Andrea", ""], ["Mufid", "Muhammad Syifa'ul", ""]]}, {"id": "2007.00571", "submitter": "Erman Acar", "authors": "Erman Acar and Rafael Pe\\~naloza", "title": "Reasoning with Contextual Knowledge and Influence Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence diagrams (IDs) are well-known formalisms extending Bayesian\nnetworks to model decision situations under uncertainty. Although they are\nconvenient as a decision theoretic tool, their knowledge representation ability\nis limited in capturing other crucial notions such as logical consistency. We\ncomplement IDs with the light-weight description logic (DL) EL to overcome such\nlimitations. We consider a setup where DL axioms hold in some contexts, yet the\nactual context is uncertain. The framework benefits from the convenience of\nusing DL as a domain knowledge representation language and the modelling\nstrength of IDs to deal with decisions over contexts in the presence of\ncontextual uncertainty. We define related reasoning problems and study their\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 15:57:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Acar", "Erman", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "2007.00624", "submitter": "Philip Saville", "authors": "Philip Saville", "title": "Cartesian closed bicategories: type theory and coherence", "comments": "PhD thesis, supervised by Marcelo Fiore. This version optimised for\n  on-screen viewing (smaller margins, smaller page size, larger font). A\n  version for print is available at\n  http://homepages.inf.ed.ac.uk/psaville/thesis-for-print.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis I lift the Curry--Howard--Lambek correspondence between the\nsimply-typed lambda calculus and cartesian closed categories to the\nbicategorical setting, then use the resulting type theory to prove a coherence\nresult for cartesian closed bicategories. Cartesian closed\nbicategories---2-categories `up to isomorphism' equipped with similarly weak\nproducts and exponentials---arise in logic, categorical algebra, and game\nsemantics. I show that there is at most one 2-cell between any parallel pair of\n1-cells in the free cartesian closed bicategory on a set and hence---in terms\nof the difficulty of calculating---bring the data of cartesian closed\nbicategories down to the familiar level of cartesian closed categories.\n  In fact, I prove this result in two ways. The first argument is closely\nrelated to Power's coherence theorem for bicategories with flexible bilimits.\nFor the second, which is the central preoccupation of this thesis, the proof\nstrategy has two parts: the construction of a type theory, and the proof that\nit satisfies a form of normalisation I call \"local coherence\". I synthesise the\ntype theory from algebraic principles using a novel generalisation of the\n(multisorted) abstract clones of universal algebra, called \"biclones\". Using a\nbicategorical treatment of M. Fiore's categorical analysis of\nnormalisation-by-evaluation, I then prove a normalisation result which entails\nthe coherence theorem for cartesian closed bicategories. In contrast to\nprevious coherence results for bicategories, the argument does not rely on the\ntheory of rewriting or strictify using the Yoneda embedding. Along the way I\nprove bicategorical generalisations of a series of well-established\ncategory-theoretic results, present a notion of glueing of bicategories, and\nbicategorify the folklore result providing sufficient conditions for a glueing\ncategory to be cartesian closed.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 17:17:52 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Saville", "Philip", ""]]}, {"id": "2007.00637", "submitter": "Florian Funke", "authors": "Simon Jantsch, Florian Funke, Christel Baier", "title": "Minimal witnesses for probabilistic timed automata", "comments": "33 pages; conference version accepted for publication at ATVA'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Witnessing subsystems have proven to be a useful concept in the analysis of\nprobabilistic systems, for example as diagnostic information on why a given\nproperty holds or as input to refinement algorithms. This paper introduces\nwitnessing subsystems for reachability problems in probabilistic timed automata\n(PTA). Using a new operation on difference bounds matrices, it is shown how\nFarkas certificates of finite-state bisimulation quotients of a PTA can be\ntranslated into witnessing subsystems. We present algorithms for the\ncomputation of minimal witnessing subsystems under three notions of minimality,\nwhich capture the timed behavior from different perspectives, and discuss their\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 17:38:28 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Jantsch", "Simon", ""], ["Funke", "Florian", ""], ["Baier", "Christel", ""]]}, {"id": "2007.00732", "submitter": "Max Rapp", "authors": "Max Rapp and Axel Adrian and Michael Kohlhase", "title": "Context Graphs for Legal Reasoning and Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a new, structured, logic-based framework for legal reasoning and\nargumentation: Instead of using a single, unstructured meaning space, theory\ngraphs organize knowledge and inference into collections of modular meaning\nspaces organized by inheritance and interpretation. Context graphs extend\ntheory graphs by attack relations and interpret theories as knowledge contexts\nof agents in argumentation. We introduce the context graph paradigm by modeling\nthe well-studied case Popov v. Hayashi, concentrating on the role of analogical\nreasoning in context graphs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:10:38 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Rapp", "Max", ""], ["Adrian", "Axel", ""], ["Kohlhase", "Michael", ""]]}, {"id": "2007.00757", "submitter": "Renate Schmidt", "authors": "Patrick Koopmann, Warren Del-Pinto, Sophie Tourret and Renate A.\n  Schmidt", "title": "Signature-Based Abduction for Expressive Description Logics -- Technical\n  Report", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signature-based abduction aims at building hypotheses over a specified set of\nnames, the signature, that explain an observation relative to some background\nknowledge. This type of abduction is useful for tasks such as diagnosis, where\nthe vocabulary used for observed symptoms differs from the vocabulary expected\nto explain those symptoms. We present the first complete method solving\nsignature-based abduction for observations expressed in the expressive\ndescription logic ALC, which can include TBox and ABox axioms, thereby solving\nthe knowledge base abduction problem. The method is guaranteed to compute a\nfinite and complete set of hypotheses, and is evaluated on a set of realistic\nknowledge bases.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:06:24 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:32:36 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Koopmann", "Patrick", ""], ["Del-Pinto", "Warren", ""], ["Tourret", "Sophie", ""], ["Schmidt", "Renate A.", ""]]}, {"id": "2007.01019", "submitter": "Christoph Benzm\\\"uller", "authors": "David Fuenmayor and Christoph Benzm\\\"uller", "title": "Higher-order Logic as Lingua Franca -- Integrating Argumentative\n  Discourse and Deep Logical Analysis", "comments": "35 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach towards the deep, pluralistic logical analysis of\nargumentative discourse that benefits from the application of state-of-the-art\nautomated reasoning technology for classical higher-order logic. Thanks to its\nexpressivity this logic can adopt the status of a uniform \\textit{lingua\nfranca} allowing the encoding of both formalized arguments (their deep logical\nstructure) and dialectical interactions (their attack and support relations).\nWe illustrate this by analyzing an excerpt from an argumentative debate on\nclimate engineering.\n  Another, novel contribution concerns the definition of abstract,\nlanguage-theoretical foundations for the characterization and assessment of\nshallow semantical embeddings (SSEs) of non-classical logics in classical\nhigher-order logic, which constitute a pillar stone of our approach.\n  The novel perspective we draw enables more concise and more elegant\ncharacterizations of semantical embeddings of logics and logic combinations,\nwhich is demonstrated with several examples.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:07:53 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fuenmayor", "David", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2007.01033", "submitter": "Paul Wild", "authors": "Paul Wild and Lutz Schr\\\"oder", "title": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax\n  Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems involving quantitative data, such as probabilistic, fuzzy, or\nmetric systems, behavioural distances provide a more fine-grained comparison of\nstates than two-valued notions of behavioural equivalence or behaviour\ninclusion. Like in the two-valued case, the wide variation found in system\ntypes creates a need for generic methods that apply to many system types at\nonce. Approaches of this kind are emerging within the paradigm of universal\ncoalgebra, based either on lifting pseudometrics along set functors or on\nlifting general real-valued (fuzzy) relations along functors by means of fuzzy\nlax extensions. An immediate benefit of the latter is that they allow bounding\nbehavioural distance by means of fuzzy (bi-)simulations that need not\nthemselves be hemi- or pseudometrics; this is analogous to classical\nsimulations and bisimulations, which need not be preorders or equivalence\nrelations, respectively. The known generic pseudometric liftings, specifically\nthe generic Kantorovich and Wasserstein liftings, both can be extended to yield\nfuzzy lax extensions, using the fact that both are effectively given by a\nchoice of quantitative modalities. Our central result then shows that in fact\nall fuzzy lax extensions are Kantorovich extensions for a suitable set of\nquantitative modalities, the so-called Moss modalities. For nonexpansive fuzzy\nlax extensions, this allows for the extraction of quantitative modal logics\nthat characterize behavioural distance, i.e. satisfy a quantitative version of\nthe Hennessy-Milner theorem; equivalently, we obtain expressiveness of a\nquantitative version of Moss' coalgebraic logic. All our results explicitly\nhold also for asymmetric distances (hemimetrics), i.e. notions of quantitative\nsimulation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:40:03 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 11:20:34 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wild", "Paul", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "2007.01223", "submitter": "Nathan Fulton", "authors": "Nathan Hunt, Nathan Fulton, Sara Magliacane, Nghia Hoang, Subhro Das,\n  Armando Solar-Lezama", "title": "Verifiably Safe Exploration for End-to-End Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep reinforcement learning in safety-critical settings requires\ndeveloping algorithms that obey hard constraints during exploration. This paper\ncontributes a first approach toward enforcing formal safety constraints on\nend-to-end policies with visual inputs. Our approach draws on recent advances\nin object detection and automated reasoning for hybrid dynamical systems. The\napproach is evaluated on a novel benchmark that emphasizes the challenge of\nsafely exploring in the presence of hard constraints. Our benchmark draws from\nseveral proposed problem sets for safe learning and includes problems that\nemphasize challenges such as reward signals that are not aligned with safety\nconstraints. On each of these benchmark problems, our algorithm completely\navoids unsafe behavior while remaining competitive at optimizing for as much\nreward as is safe. We also prove that our method of enforcing the safety\nconstraints preserves all safe policies from the original environment.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 16:12:20 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Hunt", "Nathan", ""], ["Fulton", "Nathan", ""], ["Magliacane", "Sara", ""], ["Hoang", "Nghia", ""], ["Das", "Subhro", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "2007.01233", "submitter": "Bartosz Bednarczyk", "authors": "Bartosz Bednarczyk, Jakub Michaliszyn", "title": "\"Most of\" leads to undecidability: Failure of adding frequencies to LTL", "comments": "Full version of FOSSACS 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Temporal Logic (LTL) interpreted on finite traces is a robust\nspecification framework popular in formal verification. However, despite the\nhigh interest in the logic in recent years, the topic of their quantitative\nextensions is not yet fully explored. The main goal of this work is to study\nthe effect of adding weak forms of percentage constraints (e.g. that most of\nthe positions in the past satisfy a given condition, or that sigma is the\nmost-frequent letter occurring in the past) to fragments of LTL. Such\nextensions could potentially be used for the verification of influence networks\nor statistical reasoning. Unfortunately, as we prove in the paper, it turns out\nthat percentage extensions of even tiny fragments of LTL have undecidable\nsatisfiability and model-checking problems. Our undecidability proofs not only\nsharpen most of the undecidability results on logics with arithmetics\ninterpreted on words known from the literature, but also are fairly simple. We\nalso show that the undecidability can be avoided by restricting the allowed\nusage of the negation, and briefly discuss how the undecidability results\ntransfer to first-order logic on words.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 16:31:01 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 14:46:34 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 10:36:21 GMT"}, {"version": "v4", "created": "Sun, 3 Jan 2021 13:51:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Michaliszyn", "Jakub", ""]]}, {"id": "2007.01266", "submitter": "Sven Linker", "authors": "Sven Linker and Fabio Papacchini and Michele Sevegnani", "title": "Analysing Spatial Properties on Neighbourhood Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a bisimulation relation for neighbourhood spaces, a generalisation\nof topological spaces. We show that this notion, path preserving bisimulation,\npreserves formulas of the spatial logic SLCS. We then use this preservation\nresult to show that SLCS cannot express standard topological properties such as\nseparation and connectedness. Furthermore, we compare the bisimulation relation\nwith standard modal bisimulation and modal bisimulation with converse on graphs\nand prove it coincides with the latter.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 17:18:58 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Linker", "Sven", ""], ["Papacchini", "Fabio", ""], ["Sevegnani", "Michele", ""]]}, {"id": "2007.01374", "submitter": "Makai Mann", "authors": "Makai Mann, Amalee Wilson, Cesare Tinelli, Clark Barrett", "title": "Smt-Switch: a solver-agnostic C++ API for SMT Solving", "comments": "This version adds a reference to metaSMT. 11 pages, 1 figure, to be\n  included in SMT Workshop 2020: http://smt-workshop.cs.uiowa.edu/2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This extended abstract describes work in progress on Smt-Switch, an\nopen-source, solver-agnostic API for SMT solving. Smt-Switch provides an\nabstract interface, which can be implemented by different SMT solvers.\nSmt-Switch provides simple, uniform, and high-performance access to SMT solving\nfor applications in areas such as automated reasoning, planning, and formal\nverification. The interface allows the user to create, traverse, and manipulate\nterms, as well as to dynamically dispatch queries to different underlying SMT\nsolvers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 20:29:47 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 16:52:04 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mann", "Makai", ""], ["Wilson", "Amalee", ""], ["Tinelli", "Cesare", ""], ["Barrett", "Clark", ""]]}, {"id": "2007.01597", "submitter": "Frank Wolter", "authors": "Jean Christoph Jung and Frank Wolter", "title": "Living without Beth and Craig: Definitions and Interpolants in the\n  Guarded and Two-Variable Fragments", "comments": "This is an updated version that also investigates the two-variable\n  fragment of FO. The paper will appear in the proceedings of LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In logics with the Craig interpolation property (CIP) the existence of an\ninterpolant for an implication follows from the validity of the implication. In\nlogics with the projective Beth definability property (PBDP), the existence of\nan explicit definition of a relation follows from the validity of a formula\nexpressing its implicit definability. The two-variable fragment, FO2, and the\nguarded fragment, GF, of first-order logic both fail to have the CIP and the\nPBDP. We show that nevertheless in both fragments the existence of interpolants\nand explicit definitions is decidable. In GF, both problems are\n3ExpTime-complete in general, and 2ExpTime-complete if the arity of relation\nsymbols is bounded by a constant c not smaller than 3. In FO2, we prove a\ncoN2ExpTime upper bound and a 2ExpTime lower bound for both problems. Thus,\nboth for GF and FO2 existence of interpolants and explicit definitions are\ndecidable but harder than validity (in case of FO2 under standard complexity\nassumptions).\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 10:30:24 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 09:33:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Wolter", "Frank", ""]]}, {"id": "2007.01610", "submitter": "Jean Christoph Jung", "authors": "Jean Christoph Jung, Carsten Lutz, Hadrien Pulcini, Frank Wolter", "title": "Logical Separability of Incomplete Data under Ontologies", "comments": "Full Version of KR'20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a logical formula that separates positive and negative examples given\nin the form of labeled data items is fundamental in applications such as\nconcept learning, reverse engineering of database queries, and generating\nreferring expressions. In this paper, we investigate the existence of a\nseparating formula for incomplete data in the presence of an ontology. Both for\nthe ontology language and the separation language, we concentrate on\nfirst-order logic and three important fragments thereof: the description logic\n$\\mathcal{ALCI}$, the guarded fragment, and the two-variable fragment. We\nconsider several forms of separability that differ in the treatment of negative\nexamples and in whether or not they admit the use of additional helper symbols\nto achieve separation. We characterize separability in a model-theoretic way,\ncompare the separating power of the different languages, and determine the\ncomputational complexity of separability as a decision problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 11:00:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Lutz", "Carsten", ""], ["Pulcini", "Hadrien", ""], ["Wolter", "Frank", ""]]}, {"id": "2007.01637", "submitter": "L\\'eo Henry", "authors": "L\\'eo Henry, Nicolas Markey, Thierry J\\'eron", "title": "Active learning of timed automata with unobservable resets", "comments": "Long version of the FORMATS2020 paper of same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning of timed languages is concerned with the inference of timed\nautomata from observed timed words. The agent can query for the membership of\nwords in the target language, or propose a candidate model and verify its\nequivalence to the target. The major difficulty of this framework is the\ninference of clock resets, central to the dynamics of timed automata, but not\ndirectly observable. Interesting first steps have already been made by\nrestricting to the subclass of event-recording automata, where clock resets are\ntied to observations. In order to advance towards learning of general timed\nautomata, we generalize this method to a new class, called reset-free\nevent-recording automata, where some transitions may reset no clocks. This\noffers the same challenges as generic timed automata while keeping the simpler\nframework of event-recording automata for the sake of readability. Central to\nour contribution is the notion of invalidity, and the algorithm and data\nstructures to deal with it, allowing on-the-fly detection and pruning of reset\nhypotheses that contradict observations, a key to any efficient active-learning\nprocedure for generic timed automata.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 12:13:42 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 07:30:20 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Henry", "L\u00e9o", ""], ["Markey", "Nicolas", ""], ["J\u00e9ron", "Thierry", ""]]}, {"id": "2007.01709", "submitter": "Natalia Moanga", "authors": "Ioana Leu\\c{s}tean, Natalia Moang\\u{a}, Traian Florin\n  \\c{S}erb\\u{a}nu\\c{t}\\u{a}", "title": "Many-Sorted Hybrid Modal Languages", "comments": "arXiv admin note: text overlap with arXiv:1905.05036,\n  arXiv:1907.05029", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue our investigation into hybrid polyadic multi-sorted logic with a\nfocus on expresivity related to the operational and axiomatic semantics of\nrogramming languages, and relations with first-order logic. We identify a\nfragment of the full logic, for which we prove sound and complete deduction and\nwe show that it is powerful enough to represent both the programs and their\nsemantics in an uniform way. Although weaker than other hybrid systems\npreviously developed, this system is expected to have better computational\nproperties. Finally, we provide a standard translation from full hybrid\nmany-sorted logic to first-order logic.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 13:54:35 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Leu\u015ftean", "Ioana", ""], ["Moang\u0103", "Natalia", ""], ["\u015eerb\u0103nu\u0163\u0103", "Traian Florin", ""]]}, {"id": "2007.01733", "submitter": "Gianluca Curzi", "authors": "Gianluca Curzi and Luca Roversi", "title": "Probabilistic Soft Type Assignment", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model randomized complexity classes in the style of Implicit Computational\nComplexity. We introduce PSTA, a probabilistic version of STA, the\ntype-theoretical counterpart of Soft Linear Logic. PSTA is a type assignment\nfor an extension of Simpson's Linear Lambda Calculus and its surface reduction,\nwhere Linear additives express random choice. Linear additives are weaker than\nthe usual ones; they allow for duplications harmlessly affecting the\ncomputational cost of normalization. PSTA is sound and complete w.r.t.\nprobabilistic polynomial time functions and characterizes the probabilistic\ncomplexity classes PP and BPP, the latter slightly less implicitly than PP.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 14:54:45 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Curzi", "Gianluca", ""], ["Roversi", "Luca", ""]]}, {"id": "2007.01773", "submitter": "Anne-Kathrin Schmuck", "authors": "Rupak Majumdar and Anne-Kathrin Schmuck", "title": "Supervisory Controller Synthesis for Non-terminating Processes is an\n  Obliging Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to solve the supervisory control problem over\nnon-terminating processes modeled as $\\omega$-regular automata. A solution to\nthis problem was obtained by Thistle in 1995 which uses complex manipulations\nof automata. We show a new solution to the problem through a reduction to\nobliging games, which, in turn, can be reduced to $\\omega$-regular reactive\nsynthesis. Therefore, our reduction results in a symbolic algorithm based on\nmanipulating sets of states using tools from reactive synthesis. This\nestablishes a new connection between the research areas of (I) supervisory\ncontrol theory in the field of control engineering and (II) reactive synthesis\nin the field of computer science.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 15:49:22 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 08:05:55 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Majumdar", "Rupak", ""], ["Schmuck", "Anne-Kathrin", ""]]}, {"id": "2007.01779", "submitter": "Stanislav Zivny", "authors": "Caterina Viola and Stanislav Zivny", "title": "The combined basic LP and affine IP relaxation for promise VCSPs on\n  infinite domains", "comments": "Full version of an MFCS'20 paper", "journal-ref": "ACM Transactions on Algorithms 17(3) Article No. 21 (2021)", "doi": "10.1145/3458041", "report-no": null, "categories": "cs.CC cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex relaxations have been instrumental in solvability of constraint\nsatisfaction problems (CSPs), as well as in the three different generalisations\nof CSPs: valued CSPs, infinite-domain CSPs, and most recently promise CSPs. In\nthis work, we extend an existing tractability result to the three\ngeneralisations of CSPs combined: We give a sufficient condition for the\ncombined basic linear programming and affine integer programming relaxation for\nexact solvability of promise valued CSPs over infinite-domains. This extends a\nresult of Brakensiek and Guruswami [SODA'20] for promise (non-valued) CSPs (on\nfinite domains).\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:06:43 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 15:12:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Viola", "Caterina", ""], ["Zivny", "Stanislav", ""]]}, {"id": "2007.02261", "submitter": "Maksym Bortin", "authors": "Maksym Bortin", "title": "A Framework for Modelling, Verification and Transformation of Concurrent\n  Imperative Programs", "comments": "57 pages, to be submitted to Discrete Mathematics & Theoretical\n  Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper gives a detailed presentation of a framework, embedded into the\nsimply typed higher-order logic and aimed at sound and structured reasoning\nabout models of imperative programs with interleaved computations. As a case\nstudy, a model of the Peterson's mutual exclusion algorithm will be scrutinised\nin the course of the paper illustrating applicability of the framework.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 08:11:37 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 09:53:19 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 15:15:48 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Bortin", "Maksym", ""]]}, {"id": "2007.02484", "submitter": "Florian Richter", "authors": "Florian Richter", "title": "Logic, Language, and Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difference between object-language and metalanguage is crucial for\nlogical analysis, but has yet not been examined for the field of computer\nscience. In this paper the difference is examined with regard to inferential\nrelations. It is argued that inferential relations in a metalanguage (like a\ncalculus for propositional logic) cannot represent conceptual relations of\nnatural language. Inferential relations govern our concept use and\nunderstanding. Several approaches in the field of Natural Language\nUnderstanding (NLU) and Natural Language Inference (NLI) take this insight in\naccount, but do not consider, how an inference can be assessed as a good\ninference. I present a logical analysis that can assesss the normative\ndimension of inferences, which is a crucial part of logical understanding and\ngoes beyond formal understanding of metalanguages.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 00:52:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Richter", "Florian", ""]]}, {"id": "2007.02487", "submitter": "Florian Richter", "authors": "Florian Richter", "title": "Inferences and Modal Vocabulary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deduction is the one of the major forms of inferences and commonly used in\nformal logic. This kind of inference has the feature of monotonicity, which can\nbe problematic. There are different types of inferences that are not monotonic,\ne.g. abductive inferences. The debate between advocates and critics of\nabduction as a useful instrument can be reconstructed along the issue, how an\nabductive inference warrants to pick out one hypothesis as the best one. But\nhow can the goodness of an inference be assessed? Material inferences express\ngood inferences based on the principle of material incompatibility. Material\ninferences are based on modal vocabulary, which enriches the logical\nexpressivity of the inferential relations. This leads also to certain limits in\nthe application of labeling in machine learning. I propose a modal\ninterpretation of implications to express conceptual relations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 01:04:06 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Richter", "Florian", ""]]}, {"id": "2007.02559", "submitter": "Jesse Han", "authors": "Jesse Michael Han", "title": "Enhancing SAT solvers with glue variable predictions", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern SAT solvers routinely operate at scales that make it impractical to\nquery a neural network for every branching decision. NeuroCore, proposed by\nSelsam and Bjorner, offered a proof-of-concept that neural networks can still\naccelerate SAT solvers by only periodically refocusing a score-based branching\nheuristic. However, that work suffered from several limitations: their modified\nsolvers require GPU acceleration, further ablations showed that they were no\nbetter than a random baseline on the SATCOMP 2018 benchmark, and their training\ntarget of unsat cores required an expensive data pipeline which only labels\nrelatively easy unsatisfiable problems. We address all these limitations, using\na simpler network architecture allowing CPU inference for even large industrial\nproblems with millions of clauses, and training instead to predict {\\em glue\nvariables}---a target for which it is easier to generate labelled data, and\nwhich can also be formulated as a reinforcement learning task. We demonstrate\nthe effectiveness of our approach by modifying the state-of-the-art SAT solver\nCaDiCaL, improving its performance on SATCOMP 2018 and SATRACE 2019 with\nsupervised learning and its performance on a dataset of SHA-1 preimage attacks\nwith reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 07:16:49 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Han", "Jesse Michael", ""]]}, {"id": "2007.02579", "submitter": "Siang-Yun Lee", "authors": "Siang-Yun Lee, Heinz Riener, Alan Mishchenko, Robert K. Brayton,\n  Giovanni De Micheli", "title": "Simulation-Guided Boolean Resubstitution", "comments": "8 pages, originally accepted at Int'l Workshop on Logic & Synthesis\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new logic optimization paradigm based on circuit\nsimulation, which reduces the need for Boolean computations such as SAT-solving\nor constructing BDDs. The paper develops a Boolean resubstitution framework to\ndemonstrate the effectiveness of the proposed approach. Methods to generate\nhighly expressive simulation patterns are developed, and the generated patterns\nare used in resubstitution for efficient filtering of potential resubstitution\ncandidates to reduce the need for SAT validation. Experimental results show\nthat improvements in circuit size reduction were achieved by up to 74%,\ncompared to a state-of-the-art resubstitution algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 08:11:33 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Lee", "Siang-Yun", ""], ["Riener", "Heinz", ""], ["Mishchenko", "Alan", ""], ["Brayton", "Robert K.", ""], ["De Micheli", "Giovanni", ""]]}, {"id": "2007.02669", "submitter": "Jean Christoph Jung", "authors": "Jean Christoph Jung, Carsten Lutz, Hadrien Pulcini, Frank Wolter", "title": "Separating Positive and Negative Data Examples by Concepts and Formulas:\n  The Case of Restricted Signatures", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the separation of positive and negative data examples in terms of\ndescription logic (DL) concepts and formulas of decidable FO fragments, in the\npresence of an ontology. In contrast to previous work, we add a signature that\nspecifies a subset of the symbols from the data and ontology that can be used\nfor separation. We consider weak and strong versions of the resulting problem\nthat differ in how the negative examples are treated. Our main results are that\n(a projective form of) the weak version is decidable in $\\mathcal{ALCI}$ while\nit is undecidable in the guarded fragment GF, the guarded negation fragment\nGNF, and the DL $\\mathcal{ALCFIO}$, and that strong separability is decidable\nin $\\mathcal{ALCI}$, GF, and GNF. We also provide (mostly tight) complexity\nbounds.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:58:02 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Lutz", "Carsten", ""], ["Pulcini", "Hadrien", ""], ["Wolter", "Frank", ""]]}, {"id": "2007.02736", "submitter": "Frank Wolter", "authors": "Alessandro Artale and Jean Christoph Jung and Andrea Mazzullo and Ana\n  Ozaki and Frank Wolter", "title": "Living Without Beth and Craig: Definitions and Interpolants in\n  Description Logics with Nominals and Role Inclusions", "comments": "We have added results on description logics with role inclusions and\n  an ExpTime-completeness result for the explicit definability of concept\n  names. The title has been modified by adding role inclusions. This paper has\n  been accepted for AAAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Craig interpolation property (CIP) states that an interpolant for an\nimplication exists iff it is valid. The projective Beth definability property\n(PBDP) states that an explicit definition exists iff a formula stating implicit\ndefinability is valid. Thus, the CIP and PBDP transform potentially hard\nexistence problems into deduction problems in the underlying logic. Description\nLogics with nominals and/or role inclusions do not enjoy the CIP nor PBDP, but\ninterpolants and explicit definitions have many potential applications in\nontology engineering and ontology-based data management. In this article we\nshow the following: even without Craig and Beth, the existence of interpolants\nand explicit definitions is decidable in description logics with nominals\nand/or role inclusions such as ALCO, ALCH and ALCHIO. However, living without\nCraig and Beth makes this problem harder than deduction: we prove that the\nexistence problems become 2ExpTime-complete, thus one exponential harder than\nvalidity. The existence of explicit definitions is 2ExpTime-hard even if one\nasks for a definition of a nominal using any symbol distinct from that nominal,\nbut it becomes ExpTime-complete if one asks for a definition of a concept name\nusing any symbol distinct from that concept name.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:16:12 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 08:52:24 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 11:48:02 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Artale", "Alessandro", ""], ["Jung", "Jean Christoph", ""], ["Mazzullo", "Andrea", ""], ["Ozaki", "Ana", ""], ["Wolter", "Frank", ""]]}, {"id": "2007.02823", "submitter": "Evan Piermont", "authors": "Joseph Y. Halpern and Evan Piermont", "title": "Dynamic Awareness", "comments": "To appear in the 17th International Conference on Principles of\n  Knowledge Representation and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how to model the beliefs of an agent who becomes more aware.\nWe use the framework of Halpern and Rego (2013) by adding probability, and\ndefine a notion of a model transition that describes constraints on how, if an\nagent becomes aware of a new formula $\\phi$ in state $s$ of a model $M$, she\ntransitions to state $s^*$ in a model $M^*$. We then discuss how such a model\ncan be applied to information disclosure.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:28:22 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Piermont", "Evan", ""]]}, {"id": "2007.02900", "submitter": "Martin E. Bidlingmaier", "authors": "Martin E. Bidlingmaier", "title": "An interpretation of dependent type theory in a model category of\n  locally cartesian closed categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally cartesian closed (lcc) categories are natural categorical models of\nextensional dependent type theory. This paper introduces the \"gros\" semantics\nin the category of lcc categories: Instead of constructing an interpretation in\na given individual lcc category, we show that also the category of all lcc\ncategories can be endowed with the structure of a model of dependent type\ntheory. The original interpretation in an individual lcc category can then be\nrecovered by slicing. As in the original interpretation, we face the issue of\ncoherence: Categorical structure is usually preserved by functors only up to\nisomorphism, whereas syntactic substitution commutes strictly with all type\ntheoretic structure. Our solution involves a suitable presentation of the\nhigher category of lcc categories as model category. To that end, we construct\na model category of lcc sketches, from which we obtain by the formalism of\nalgebraically (co)fibrant objects model categories of strict lcc categories and\nthen algebraically cofibrant strict lcc categories. The latter is our model of\ndependent type theory.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:24:27 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 15:17:36 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Bidlingmaier", "Martin E.", ""]]}, {"id": "2007.02911", "submitter": "Joel Ouaknine", "authors": "Toghrul Karimov, Jo\\\"el Ouaknine, James Worrell", "title": "On LTL Model Checking for Low-Dimensional Discrete Linear Dynamical\n  Systems", "comments": "Long version of MFCS 2020 paper (19 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a discrete dynamical system given by a square matrix $M \\in\n\\mathbb{Q}^{d \\times d}$ and a starting point $s \\in \\mathbb{Q}^d$. The orbit\nof such a system is the infinite trajectory $\\langle s, Ms, M^2s,\n\\ldots\\rangle$. Given a collection $T_1, T_2, \\ldots, T_m \\subseteq\n\\mathbb{R}^d$ of semialgebraic sets, we can associate with each $T_i$ an atomic\nproposition $P_i$ which evaluates to true at time $n$ if, and only if, $M^ns\n\\in T_i$. This gives rise to the LTL Model-Checking Problem for discrete linear\ndynamical systems: given such a system $(M,s)$ and an LTL formula over such\natomic propositions, determine whether the orbit satisfies the formula. The\nmain contribution of the present paper is to show that the LTL Model-Checking\nProblem for discrete linear dynamical systems is decidable in dimension 3 or\nless.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:42:12 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 14:29:04 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Karimov", "Toghrul", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "2007.02924", "submitter": "Albert Qiaochu Jiang", "authors": "Yuhuai Wu, Albert Qiaochu Jiang, Jimmy Ba, Roger Grosse", "title": "INT: An Inequality Benchmark for Evaluating Generalization in Theorem\n  Proving", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning-assisted theorem proving, one of the most critical challenges is\nto generalize to theorems unlike those seen at training time. In this paper, we\nintroduce INT, an INequality Theorem proving benchmark, specifically designed\nto test agents' generalization ability. INT is based on a procedure for\ngenerating theorems and proofs; this procedure's knobs allow us to measure 6\ndifferent types of generalization, each reflecting a distinct challenge\ncharacteristic to automated theorem proving. In addition, unlike prior\nbenchmarks for learning-assisted theorem proving, INT provides a lightweight\nand user-friendly theorem proving environment with fast simulations, conducive\nto performing learning-based and search-based research. We introduce\nlearning-based baselines and evaluate them across 6 dimensions of\ngeneralization with the benchmark. We then evaluate the same agents augmented\nwith Monte Carlo Tree Search (MCTS) at test time, and show that MCTS can help\nto prove new theorems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:55:33 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 16:21:59 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wu", "Yuhuai", ""], ["Jiang", "Albert Qiaochu", ""], ["Ba", "Jimmy", ""], ["Grosse", "Roger", ""]]}, {"id": "2007.03204", "submitter": "Pashootan Vaezipoor", "authors": "Pashootan Vaezipoor, Gil Lederman, Yuhuai Wu, Chris J. Maddison, Roger\n  Grosse, Edward Lee, Sanjit A. Seshia, Fahiem Bacchus", "title": "Learning Branching Heuristics for Propositional Model Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional model counting or #SAT is the problem of computing the number\nof satisfying assignments of a Boolean formula and many discrete probabilistic\ninference problems can be translated into a model counting problem to be solved\nby #SAT solvers. Generic ``exact'' #SAT solvers, however, are often not\nscalable to industrial-level instances. In this paper, we present Neuro#, an\napproach for learning branching heuristics for exact #SAT solvers via evolution\nstrategies (ES) to reduce the number of branching steps the solver takes to\nsolve an instance. We experimentally show that our approach not only reduces\nthe step count on similarly distributed held-out instances but it also\ngeneralizes to much larger instances from the same problem family. The gap\nbetween the learned and the vanilla solver on larger instances is sometimes so\nwide that the learned solver can even overcome the run time overhead of\nquerying the model and beat the vanilla in wall-clock time by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 05:20:29 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Vaezipoor", "Pashootan", ""], ["Lederman", "Gil", ""], ["Wu", "Yuhuai", ""], ["Maddison", "Chris J.", ""], ["Grosse", "Roger", ""], ["Lee", "Edward", ""], ["Seshia", "Sanjit A.", ""], ["Bacchus", "Fahiem", ""]]}, {"id": "2007.03251", "submitter": "Andrea Peruffo", "authors": "Andrea Peruffo, Daniele Ahmed, Alessandro Abate", "title": "Automated and Formal Synthesis of Neural Barrier Certificates for\n  Dynamical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automated, formal, counterexample-based approach to\nsynthesise Barrier Certificates (BC) for the safety verification of continuous\nand hybrid dynamical models. The approach is underpinned by an inductive\nframework: this is structured as a sequential loop between a learner, which\nmanipulates a candidate BC structured as a neural network, and a sound\nverifier, which either certifies the candidate's validity or generates\ncounter-examples to further guide the learner. We compare the approach against\nstate-of-the-art techniques, over polynomial and non-polynomial dynamical\nmodels: the outcomes show that we can synthesise sound BCs up to two orders of\nmagnitude faster, with in particular a stark speedup on the verification engine\n(up to five orders less), whilst needing a far smaller data set (up to three\norders less) for the learning part. Beyond improvements over the state of the\nart, we further challenge the new approach on a hybrid dynamical model and on\nlarger-dimensional models, and showcase the numerical robustness of our\nalgorithms and codebase.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 07:39:42 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:27:10 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Peruffo", "Andrea", ""], ["Ahmed", "Daniele", ""], ["Abate", "Alessandro", ""]]}, {"id": "2007.03365", "submitter": "Gethin Norman", "authors": "Marta Kwiatkowska, Gethin Norman, David Parker, Gabriel Santos", "title": "Multi-player Equilibria Verification for Concurrent Stochastic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent stochastic games (CSGs) are an ideal formalism for modelling\nprobabilistic systems that feature multiple players or components with distinct\nobjectives making concurrent, rational decisions. Examples include\ncommunication or security protocols and multi-robot navigation. Verification\nmethods for CSGs exist but are limited to scenarios where agents or players are\ngrouped into two coalitions, with those in the same coalition sharing an\nidentical objective. In this paper, we propose multi-coalitional verification\ntechniques for CSGs. We use subgame-perfect social welfare (or social cost)\noptimal Nash equilibria, which are strategies where there is no incentive for\nany coalition to unilaterally change its strategy in any game state, and where\nthe total combined objectives are maximised (or minimised). We present an\nextension of the temporal logic rPATL (probabilistic alternating-time temporal\nlogic with rewards) to specify equilibria-based properties for any number of\ndistinct coalitions, and a corresponding model checking algorithm for a variant\nof stopping games. We implement our techniques in the PRISM-games tool and\napply them to several case studies, including a secret sharing protocol and a\npublic good game.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:56:33 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 12:22:00 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Kwiatkowska", "Marta", ""], ["Norman", "Gethin", ""], ["Parker", "David", ""], ["Santos", "Gabriel", ""]]}, {"id": "2007.03540", "submitter": "Frits Vaandrager", "authors": "Frits Vaandrager and Abhisek Midya", "title": "A Myhill-Nerode Theorem for Register Automata and Symbolic Trace\n  Languages", "comments": "This is the full version of a paper that appeared in the proceedings\n  of ICTAC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new symbolic trace semantics for register automata (extended\nfinite state machines) which records both the sequence of input symbols that\noccur during a run as well as the constraints on input parameters that are\nimposed by this run. Our main result is a generalization of the classical\nMyhill-Nerode theorem to this symbolic setting. Our generalization requires the\nuse of three relations to capture the additional structure of register\nautomata. Location equivalence $\\equiv_l$ captures that symbolic traces end in\nthe same location, transition equivalence $\\equiv_t$ captures that they share\nthe same final transition, and a partial equivalence relation $\\equiv_r$\ncaptures that symbolic values $v$ and $v'$ are stored in the same register\nafter symbolic traces $w$ and $w'$, respectively. A symbolic language is\ndefined to be regular if relations $\\equiv_l$, $\\equiv_t$ and $\\equiv_r$ exist\nthat satisfy certain conditions, in particular, they all have finite index. We\nshow that the symbolic language associated to a register automaton is regular,\nand we construct, for each regular symbolic language, a register automaton that\naccepts this language. Our result provides a foundation for grey-box learning\nalgorithms in settings where the constraints on data parameters can be\nextracted from code using e.g. tools for symbolic/concolic execution or\ntainting. We believe that moving to a grey-box setting is essential to overcome\nthe scalability problems of state-of-the-art black-box learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:13:35 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 09:03:12 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Vaandrager", "Frits", ""], ["Midya", "Abhisek", ""]]}, {"id": "2007.03564", "submitter": "Titouan Carette", "authors": "Titouan Carette and Simon Perdrix", "title": "Colored props for large scale graphical reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prop formalism allows representation of processes withstring diagrams and\nhas been successfully applied in various areas such as quantum computing,\nelectric circuits and control flow graphs. However, these graphical approaches\nsuffer from scalability problems when it comes to writing large diagrams. A\nproposal to tackle this issue has been investigated for ZX-calculus using\ncolored props. This paper extends the approach to any prop, making it a general\ntool for graphical languages manipulation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:40:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Carette", "Titouan", ""], ["Perdrix", "Simon", ""]]}, {"id": "2007.03648", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Francisco Noriega and Alejandro D\\'iaz-Caro", "title": "The Vectorial Lambda Calculus Revisited", "comments": "Long version with detailed proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Vectorial Lambda Calculus, a typed version of Lineal.\nVectorial (as well as Lineal) has been originally designed for quantum\ncomputing, as an extension to System F where linear combinations of lambda\nterms are also terms and linear combinations of types are also types. In its\nfirst presentation, Vectorial only provides a weakened version of the Subject\nReduction property. We prove that our revised Vectorial Lambda Calculus\nsupports the standard version of said property, answering a long standing\nissue. In addition we also introduce the concept of weight of types and terms,\nand prove a relation between the weight of terms and of its types.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:37:51 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:21:29 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 00:35:41 GMT"}, {"version": "v4", "created": "Fri, 14 May 2021 12:59:48 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Noriega", "Francisco", ""], ["D\u00edaz-Caro", "Alejandro", ""]]}, {"id": "2007.03867", "submitter": "Jonni Virtema", "authors": "Miika Hannula, Juha Kontinen, Martin L\\\"uck and Jonni Virtema", "title": "On the Complexity of Horn and Krom Fragments of Second-Order Boolean\n  Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order Boolean logic is a generalization of QBF, whose constant\nalternation fragments are known to be complete for the levels of the\nexponential time hierarchy. We consider two types of restriction of this logic:\n1) restrictions to term constructions, 2) restrictions to the form of the\nBoolean matrix. Of the first sort, we consider two kinds of restrictions:\nfirstly, disallowing nested use of proper function variables, and secondly\nstipulating that each function variable must appear with a fixed sequence of\narguments. Of the second sort, we consider Horn, Krom, and core fragments of\nthe Boolean matrix. We classify the complexity of logics obtained by combining\nthese two types of restrictions. We show that, in most cases, logics with k\nalternating blocks of function quantifiers are complete for the kth or (k-1)th\nlevel of the exponential time hierarchy. Furthermore, we establish\nNL-completeness for the Krom and core fragments, when k=1 and both restrictions\nof the first sort are in effect.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 02:50:43 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hannula", "Miika", ""], ["Kontinen", "Juha", ""], ["L\u00fcck", "Martin", ""], ["Virtema", "Jonni", ""]]}, {"id": "2007.04150", "submitter": "Simon Wimmer", "authors": "Simon Wimmer, Fr\\'ed\\'eric Herbreteau, Jaco van de Pol", "title": "Certifying Emptiness of Timed B\\\"uchi Automata", "comments": "A shorter version appears in the proceedings of FORMATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checkers for timed automata are widely used to verify safety-critical,\nreal-time systems. State-of-the-art tools achieve scalability by intricate\nabstractions. We aim at further increasing the trust in their verification\nresults, in particular for checking liveness properties. To this end, we\ndevelop an approach for extracting certificates for the emptiness of timed\nB\\\"uchi automata from model checking runs. These certificates can be\ndouble-checked by a certifier that we formally verify in Isabelle/HOL. We study\nliveness certificates in an abstract setting and show that our approach is\nsound and complete. To also demonstrate its feasibility, we extract\ncertificates for several models checked by TChecker and Imitator, and validate\nthem with our verified certifier.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 14:28:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wimmer", "Simon", ""], ["Herbreteau", "Fr\u00e9d\u00e9ric", ""], ["van de Pol", "Jaco", ""]]}, {"id": "2007.04212", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Honghua Dong, Roger Grosse, Jimmy Ba", "title": "The Scattering Compositional Learner: Discovering Objects, Attributes,\n  Relationships in Analogical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on an analogical reasoning task that contains rich\ncompositional structures, Raven's Progressive Matrices (RPM). To discover\ncompositional structures of the data, we propose the Scattering Compositional\nLearner (SCL), an architecture that composes neural networks in a sequence. Our\nSCL achieves state-of-the-art performance on two RPM datasets, with a 48.7%\nrelative improvement on Balanced-RAVEN and 26.4% on PGM over the previous\nstate-of-the-art. We additionally show that our model discovers compositional\nrepresentations of objects' attributes (e.g., shape color, size), and their\nrelationships (e.g., progression, union). We also find that the compositional\nrepresentation makes the SCL significantly more robust to test-time domain\nshifts and greatly improves zero-shot generalization to previously unseen\nanalogies.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:53:06 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wu", "Yuhuai", ""], ["Dong", "Honghua", ""], ["Grosse", "Roger", ""], ["Ba", "Jimmy", ""]]}, {"id": "2007.04213", "submitter": "Marino Miculan", "authors": "Davide Castelnovo, Marino Miculan", "title": "Closure hyperdoctrines, with paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Pre)closure spaces are a generalization of topological spaces covering also\nthe notion of neighbourhood in discrete structures, widely used to model and\nreason about spatial aspects of distributed systems.\n  In this paper we introduce an abstract theoretical framework for the\nsystematic investigation of the logical aspects of closure spaces. To this end,\nwe introduce the notion of closure (hyper)doctrines, i.e. doctrines endowed\nwith inflationary operators (and subject to suitable conditions). The\ngenerality and effectiveness of this concept is witnessed by many examples\narising naturally from topological spaces, fuzzy sets, algebraic structures,\ncoalgebras, and covering at once also known cases such as Kripke frames and\nprobabilistic frames (i.e., Markov chains). Then, we show how spatial logical\nconstructs concerning surroundedness and reachability can be interpreted by\nendowing hyperdoctrines with a general notion of paths. By leveraging general\ncategorical constructions, we provide axiomatisations and sound and complete\nsemantics for various fragments of logics for closure operators.\n  Therefore, closure hyperdoctrines are useful both for refining and improving\nthe theory of existing spatial logics, but especially for the definition of new\nspatial logics for new applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:53:28 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 16:15:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Castelnovo", "Davide", ""], ["Miculan", "Marino", ""]]}, {"id": "2007.04510", "submitter": "Muhammad Syifa'ul Mufid", "authors": "Muhammad Syifa'ul Mufid, Dieky Adzkiya, Alessandro Abate", "title": "Symbolic Reachability Analysis of High Dimensional Max-Plus Linear\n  Systems", "comments": "7 pages, accepted in International Workshop on Discrete Event Systems\n  (WODES) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work discusses the reachability analysis (RA) of Max-Plus Linear (MPL)\nsystems, a class of continuous-space, discrete-event models defined over the\nmax-plus algebra. Given the initial and target sets, we develop algorithms to\nverify whether there exist trajectories of the MPL system that, starting from\nthe initial set, eventually reach the target set. We show that RA can be solved\nsymbolically by encoding the MPL system, as well as initial and target sets\ninto difference logic, and then checking the satisfaction of the resulting\nlogical formula via an off-the-shelf satisfiability modulo theories (SMT)\nsolver. The performance and scalability of the developed SMT-based algorithms\nare shown to clearly outperform state-of-the-art RA algorithms for MPL systems,\nnewly allowing to investigate RA of high-dimensional MPL systems: the\nverification of models with more than 100 continuous variables shows the\napplicability of these techniques to MPL systems of industrial relevance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 02:19:18 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Mufid", "Muhammad Syifa'ul", ""], ["Adzkiya", "Dieky", ""], ["Abate", "Alessandro", ""]]}, {"id": "2007.04620", "submitter": "Markus Hecher", "authors": "Markus Hecher, Jorge Fandinno", "title": "Treewidth-Aware Complexity in ASP: Not all Positive Cycles are Equally\n  Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-know that deciding consistency for normal answer set programs\n(ASP) is NP-complete, thus, as hard as the satisfaction problem for classical\npropositional logic (SAT). The best algorithms to solve these problems take\nexponential time in the worst case. The exponential time hypothesis (ETH)\nimplies that this result is tight for SAT, that is, SAT cannot be solved in\nsubexponential time. This immediately establishes that the result is also tight\nfor the consistency problem for ASP. However, accounting for the treewidth of\nthe problem, the consistency problem for ASP is slightly harder than SAT: while\nSAT can be solved by an algorithm that runs in exponential time in the\ntreewidth k, it was recently shown that ASP requires exponential time in k\n\\cdot log(k). This extra cost is due checking that there are no self-supported\ntrue atoms due to positive cycles in the program. In this paper, we refine the\nabove result and show that the consistency problem for ASP can be solved in\nexponential time in k \\cdot log({\\lambda}) where {\\lambda} is the minimum\nbetween the treewidth and the size of the largest strongly-connected component\nin the positive dependency graph of the program. We provide a dynamic\nprogramming algorithm that solves the problem and a treewidth-aware reduction\nfrom ASP to SAT that adhere to the above limit.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 08:09:41 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Hecher", "Markus", ""], ["Fandinno", "Jorge", ""]]}, {"id": "2007.04621", "submitter": "Yuichi Nishiwaki", "authors": "Yuichi Nishiwaki, Toshiya Asai", "title": "Logic of computational semi-effects and categorical gluing for\n  equivariant functors", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit Moggi's celebrated calculus of computational\neffects from the perspective of logic of monoidal action (actegory). Our\ndevelopment takes the following steps. Firstly, we perform proof-theoretic\nreconstruction of Moggi's computational metalanguage and obtain a type theory\nwith a modal type $\\rhd$ as a refinement. Through the proposition-as-type\nparadigm, its logic can be seen as a decomposition of lax logic via Benton's\nadjoint calculus. This calculus models as a programming language a weaker\nversion of effects, which we call \\emph{semi-effects}. Secondly, we give its\nsemantics using actegories and equivariant functors. Compared to previous\nstudies of effects and actegories, our approach is more general in that models\nare directly given by equivariant functors, which include Freyd categories\n(hence strong monads) as a special case. Thirdly, we show that categorical\ngluing along equivariant functors is possible and derive logical predicates for\n$\\rhd$-modality. We also show that this gluing, under a natural assumption,\ngives rise to logical predicates that coincide with those derived by\nKatsumata's categorical $\\top\\top$-lifting for Moggi's metalanguage.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 08:13:07 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Nishiwaki", "Yuichi", ""], ["Asai", "Toshiya", ""]]}, {"id": "2007.04840", "submitter": "Gianluca Amato", "authors": "Gianluca Amato, Marco Maggesi, Maurizio Parton, Cosimo Perini Brogi", "title": "Universal Algebra in UniMath", "comments": "Accepted at the HoTT/UF 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an ongoing effort to implement Universal Algebra in the UniMath\nsystem. Our aim is to develop a general framework for formalizing and studying\nUniversal Algebra in a proof assistant. By constituting a formal system for\nisolating the invariants of the theory we are interested in -- that is, general\nalgebraic structures modulo isomorphism -- Univalent Mathematics seems to\nprovide a suitable environment to carry on our endeavour.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:41:29 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Amato", "Gianluca", ""], ["Maggesi", "Marco", ""], ["Parton", "Maurizio", ""], ["Brogi", "Cosimo Perini", ""]]}, {"id": "2007.04916", "submitter": "Salom\\'on Wollenstein-Betech", "authors": "Salom\\'on Wollenstein-Betech, Christian Muise, Christos G. Cassandras,\n  Ioannis Ch. Paschalidis, Yasaman Khazaeni", "title": "Explainability of Intelligent Transportation Systems using Knowledge\n  Compilation: a Traffic Light Controller Case", "comments": "Proc. IEEE Int. Conf. on Intelligent Transportation Systems, Rhodes,\n  Greece, 2020. (In Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage of automated controllers which make decisions on an environment are\nwidespread and are often based on black-box models. We use Knowledge\nCompilation theory to bring explainability to the controller's decision given\nthe state of the system. For this, we use simulated historical state-action\ndata as input and build a compact and structured representation which relates\nstates with actions. We implement this method in a Traffic Light Control\nscenario where the controller selects the light cycle by observing the presence\n(or absence) of vehicles in different regions of the incoming roads.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 16:27:47 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wollenstein-Betech", "Salom\u00f3n", ""], ["Muise", "Christian", ""], ["Cassandras", "Christos G.", ""], ["Paschalidis", "Ioannis Ch.", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2007.04982", "submitter": "Alexandros Arvanitakis", "authors": "Alexandros Arvanitakis", "title": "Recursion and evolution: Part II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the question of whether it is possible for a diagonalizing system,\nto learn to use environmental reward and punishment as an information, in order\nto appropriately adapt. More specifically, we study the possiblity of such a\nsystem, to learn to use diagonalization on the basis of a rewarding function.\nRelevant phenomena regarding memory are also investigated.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:27:56 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Arvanitakis", "Alexandros", ""]]}, {"id": "2007.05065", "submitter": "Patrick Totzke", "authors": "Stefan Kiefer, Richard Mayr, Mahsa Shirmohammadi, Patrick Totzke", "title": "Strategy Complexity of Parity Objectives in Countable MDPs", "comments": "This is the full version of a paper presented at CONCUR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study countably infinite MDPs with parity objectives. Unlike in finite\nMDPs, optimal strategies need not exist, and may require infinite memory if\nthey do. We provide a complete picture of the exact strategy complexity of\n$\\varepsilon$-optimal strategies (and optimal strategies, where they exist) for\nall subclasses of parity objectives in the Mostowski hierarchy. Either\nMD-strategies, Markov strategies, or 1-bit Markov strategies are necessary and\nsufficient, depending on the number of colors, the branching degree of the MDP,\nand whether one considers $\\varepsilon$-optimal or optimal strategies. In\nparticular, 1-bit Markov strategies are necessary and sufficient for\n$\\varepsilon$-optimal (resp. optimal) strategies for general parity objectives.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:41:25 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Kiefer", "Stefan", ""], ["Mayr", "Richard", ""], ["Shirmohammadi", "Mahsa", ""], ["Totzke", "Patrick", ""]]}, {"id": "2007.05269", "submitter": "Philippe Schnoebelen", "authors": "Philippe Schnoebelen", "title": "On flat lossy channel machines", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that reachability, repeated reachability, nontermination and\nunboundedness are NP-complete for Lossy Channel Machines that are flat, i.e.,\nwith no nested cycles in the control graph. The upper complexity bound relies\non a fine analysis of iterations of lossy channel actions and uses compressed\nword techniques for efficiently reasoning with paths of exponential lengths.\nThe lower bounds already apply to acyclic or single-path machines.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:27:55 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Schnoebelen", "Philippe", ""]]}, {"id": "2007.05459", "submitter": "Abhisekh Sankaran", "authors": "Anuj Dawar and Abhisekh Sankaran", "title": "Extension Preservation in the Finite and Prefix Classes of First Order\n  Logic", "comments": "15 pages, to appear in the proceedings of CSL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the classic {\\L}o\\'s-Tarski preservation theorem fails\nin the finite: there are first-order definable classes of finite structures\nclosed under extensions which are not definable (in the finite) in the\nexistential fragment of first-order logic. We strengthen this by constructing\nfor every $n$, first-order definable classes of finite structures closed under\nextensions which are not definable with $n$ quantifier alternations. The\nclasses we construct are definable in the extension of Datalog with negation\nand indeed in the existential fragment of transitive-closure logic. This\nanswers negatively an open question posed by Rosen and Weinstein.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 16:00:00 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 17:08:45 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Dawar", "Anuj", ""], ["Sankaran", "Abhisekh", ""]]}, {"id": "2007.05619", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Weighted First-Order Model Counting in the Two-Variable Fragment With\n  Counting Quantifiers", "comments": "This version: Fixed typos in the statement of Proposition 4 (missing\n  dependency on bit-complexity of w and \\overline{w} in the statement of the\n  proposition) and in Eq. 19 (missing negation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known due to the work of Van den Broeck et al [KR, 2014] that weighted\nfirst-order model counting (WFOMC) in the two-variable fragment of first-order\nlogic can be solved in time polynomial in the number of domain elements. In\nthis paper we extend this result to the two-variable fragment with counting\nquantifiers.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 21:38:42 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:32:52 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 08:56:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2007.05789", "submitter": "Arnaud Sangnier", "authors": "Florian Horn and Arnaud Sangnier", "title": "Deciding the existence of cut-off in parameterized rendez-vous networks", "comments": "Version with proofs of paper accepted at CONCUR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study networks of processes which all execute the same finite-state\nprotocol and communicate thanks to a rendez-vous mechanism. Given a protocol,\nwe are interested in checking whether there exists a number, called a cut-off,\nsuch that in any networks with a bigger number of participants, there is an\nexecution where all the entities end in some final states. We provide\ndecidability and complexity results of this problem under various assumptions,\nsuch as absence/presence of a leader or symmetric/asymmetric rendez-vous.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 14:55:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Horn", "Florian", ""], ["Sangnier", "Arnaud", ""]]}, {"id": "2007.05793", "submitter": "Mahmoud Elfar", "authors": "Mahmoud Elfar, Yu Wang, Miroslav Pajic", "title": "Context-Aware Temporal Logic for Probabilistic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the context-aware probabilistic temporal logic\n(CAPTL) that provides an intuitive way to formalize system requirements by a\nset of PCTL objectives with a context-based priority structure. We formally\npresent the syntax and semantics of CAPTL and propose a synthesis algorithm for\nCAPTL requirements. We also implement the algorithm based on the PRISM-games\nmodel checker. Finally, we demonstrate the usage of CAPTL on two case studies:\na robotic task planning problem, and synthesizing error-resilient scheduler for\nmicro-electrode-dot-array digital microfluidic biochips.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 15:09:32 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Elfar", "Mahmoud", ""], ["Wang", "Yu", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2007.05874", "submitter": "Mohammad Reza Besharati", "authors": "Mohammad Reza Besharati, Mohammad Izadi", "title": "KARB Solution: Compliance to Quality by Rule Based Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instead of proofs or logical evaluations, compliance assessment could be done\nby benchmarking. Benchmarks, in their nature, are applied. So a set of\nbenchmarks could shape an applied solution for compliance assessment. In this\npaper, we introduce the KARB solution: Keeping away compliance Anomalies by\nRule-based Benchmarking. By rule-based benchmarking, we mean evaluation of\nunder-compliance-system by its symbolic specification and by using a set of\nsymbolic rules (on behalf of semantic logic of evaluation). In order to\ndemonstrate and investigate the manner of KARB solution, we conducted a case\nstudy. The IR-QUMA study (Iranian Survey on Quality in Messenger Apps) is\ndefined to evaluate the quality of some messenger apps. the results of\nevaluations suggest that the Hybrid Method of DD-KARB (with combination of\nsemantics-awareness and data-drivenness) is more effective than solo-methods\nand could compute a somehow good estimation for messenger-apps user quality\nscores. So DD-KARB could be considered as a method for quality benchmarking in\nthis technical context.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 23:50:49 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 21:36:03 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 14:12:17 GMT"}, {"version": "v4", "created": "Sun, 31 Jan 2021 07:53:23 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Besharati", "Mohammad Reza", ""], ["Izadi", "Mohammad", ""]]}, {"id": "2007.06248", "submitter": "Balasubramanian A.R", "authors": "A. R. Balasubramanian, Javier Esparza and Marijana Lazic", "title": "Complexity of Verification and Synthesis of Threshold Automata", "comments": "Accepted at ATVA20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threshold automata are a formalism for modeling and analyzing fault-tolerant\ndistributed algorithms, recently introduced by Konnov, Veith, and Widder,\ndescribing protocols executed by a fixed but arbitrary number of processes. We\nconduct the first systematic study of the complexity of verification and\nsynthesis problems for threshold automata. We prove that the coverability,\nreachability, safety, and liveness problems are NP-complete, and that the\nbounded synthesis problem is $\\Sigma_p^2$ complete. A key to our results is a\nnovel characterization of the reachability relation of a threshold automaton as\nan existential Presburger formula. The characterization also leads to novel\nverification and synthesis algorithms. We report on an implementation, and\nprovide experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 08:53:18 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Balasubramanian", "A. R.", ""], ["Esparza", "Javier", ""], ["Lazic", "Marijana", ""]]}, {"id": "2007.06286", "submitter": "Gustav Sourek", "authors": "Gustav Sourek, Filip Zelezny, Ondrej Kuzelka", "title": "Beyond Graph Neural Networks with Lifted Relational Neural Networks", "comments": "Submitted to MLJ's Special Track on Learning and Reasoning (May 15th\n  2020 cut-off) http://lr2020.iit.demokritos.gr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a declarative differentiable programming framework based on\nthe language of Lifted Relational Neural Networks, where small parameterized\nlogic programs are used to encode relational learning scenarios. When presented\nwith relational data, such as various forms of graphs, the program interpreter\ndynamically unfolds differentiable computational graphs to be used for the\nprogram parameter optimization by standard means. Following from the used\ndeclarative Datalog abstraction, this results into compact and elegant learning\nprograms, in contrast with the existing procedural approaches operating\ndirectly on the computational graph level. We illustrate how this idea can be\nused for an efficient encoding of a diverse range of existing advanced neural\narchitectures, with a particular focus on Graph Neural Networks (GNNs).\nAdditionally, we show how the contemporary GNN models can be easily extended\ntowards higher relational expressiveness. In the experiments, we demonstrate\ncorrectness and computation efficiency through comparison against specialized\nGNN deep learning frameworks, while shedding some light on the learning\nperformance of existing GNN models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:10:58 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sourek", "Gustav", ""], ["Zelezny", "Filip", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2007.06327", "submitter": "Lutz Klinkenberg", "authors": "Lutz Klinkenberg, Kevin Batz, Benjamin Lucien Kaminski, Joost-Pieter\n  Katoen, Joshua Moerman, Tobias Winkler", "title": "Generating Functions for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the usage of generating functions (GFs) encoding\nmeasures over the program variables for reasoning about discrete probabilistic\nprograms. To that end, we define a denotational GF-transformer semantics for\nprobabilistic while-programs, and show that it instantiates Kozen's seminal\ndistribution transformer semantics. We then study the effective usage of GFs\nfor program analysis. We show that finitely expressible GFs enable checking\nsuper-invariants by means of computer algebra tools, and that they can be used\nto determine termination probabilities. The paper concludes by characterizing a\nclass of -- possibly infinite-state -- programs whose semantics is a rational\nGF encoding a discrete phase-type distribution.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 11:47:01 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Klinkenberg", "Lutz", ""], ["Batz", "Kevin", ""], ["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Moerman", "Joshua", ""], ["Winkler", "Tobias", ""]]}, {"id": "2007.06421", "submitter": "David Naumann", "authors": "David A. Naumann", "title": "Thirty-seven years of relational Hoare logic: remarks on its principles\n  and history", "comments": "A version appears in proceedings of ISOLA 2020. Version2: fix typos,\n  minor clarifications, add a citation. Version3: copy edits, add citations on\n  completeness. Version 4: minor corrections. Version 5: restore missing\n  precond in loop rule", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Hoare logics extend the applicability of modular, deductive\nverification to encompass important 2-run properties including dependency\nrequirements such as confidentiality and program relations such as equivalence\nor similarity between program versions. A considerable number of recent works\nintroduce different relational Hoare logics without yet converging on a core\nset of proof rules. This paper looks backwards to little known early work. This\nbrings to light some principles that clarify and organize the rules as well as\nsuggesting a new rule and a new notion of completeness.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 14:53:22 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 22:25:19 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 16:07:12 GMT"}, {"version": "v4", "created": "Fri, 29 Jan 2021 02:19:59 GMT"}, {"version": "v5", "created": "Thu, 3 Jun 2021 14:48:32 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Naumann", "David A.", ""]]}, {"id": "2007.06913", "submitter": "Zhilin Wu", "authors": "Taolue Chen, Matthew Hague, Jinlong He, Denghang Hu, Anthony Widjaja\n  Lin, Philipp Rummer, Zhilin Wu", "title": "A Decision Procedure for Path Feasibility of String Manipulating\n  Programs with Integer Data Type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strings are widely used in programs, especially in web applications. Integer\ndata type occurs naturally in string-manipulating programs, and is frequently\nused to refer to lengths of, or positions in, strings. Analysis and testing of\nstring-manipulating programs can be formulated as the path feasibility problem:\ngiven a symbolic execution path, does there exist an assignment to the inputs\nthat yields a concrete execution that realizes this path? Such a problem can\nnaturally be reformulated as a string constraint solving problem. Although\nstate-of-the-art string constraint solvers usually provide support for both\nstring and integer data types, they mainly resort to heuristics without\ncompleteness guarantees. In this paper, we propose a decision procedure for a\nclass of string-manipulating programs which includes not only a wide range of\nstring operations such as concatenation, replaceAll, reverse, and finite\ntransducers, but also those involving the integer data-type such as length,\nindexof, and substring. To the best of our knowledge, this represents one of\nthe most expressive string constraint languages that is currently known to be\ndecidable. Our decision procedure is based on a variant of cost register\nautomata. We implement the decision procedure, giving rise to a new solver\nOSTRICH+. We evaluate the performance of OSTRICH+ on a wide range of existing\nand new benchmarks. The experimental results show that OSTRICH+ is the first\nstring decision procedure capable of tackling finite transducers and integer\nconstraints, whilst its overall performance is comparable with the\nstate-of-the-art string constraint solvers.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:50:19 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Chen", "Taolue", ""], ["Hague", "Matthew", ""], ["He", "Jinlong", ""], ["Hu", "Denghang", ""], ["Lin", "Anthony Widjaja", ""], ["Rummer", "Philipp", ""], ["Wu", "Zhilin", ""]]}, {"id": "2007.06941", "submitter": "Noemi Passing", "authors": "Bernd Finkbeiner and Noemi Passing", "title": "Dependency-based Compositional Synthesis (Full Version)", "comments": "Full version of the corresponding ATVA 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many recent advances, reactive synthesis is still not really a\npractical technique. The grand challenge is to scale from small transition\nsystems, where synthesis performs well, to complex multi-component designs.\nCompositional methods, such as the construction of dominant strategies for\nindividual components, reduce the complexity significantly, but are usually not\napplicable without extensively rewriting the specification. In this paper, we\npresent a refinement of compositional synthesis that does not require such an\nintervention. Our algorithm decomposes the system into a sequence of\ncomponents, such that every component has a strategy that is dominant, i.e.,\nperforms at least as good as any possible alternative, provided that the\npreceding components follow their (already synthesized) strategies. The\ndecomposition of the system is based on a dependency analysis, for which we\nprovide semantic and syntactic techniques. We establish the soundness and\ncompleteness of the approach and report on encouraging experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 09:55:35 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 12:47:54 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Passing", "Noemi", ""]]}, {"id": "2007.07188", "submitter": "Carlo Nicolai", "authors": "Martin Fischer, Carlo Nicolai, Pablo Dopico Fernandez", "title": "Nonclassical truth with classical strength. A proof-theoretic analysis\n  of compositional truth over HYPE", "comments": "Fixed a gap in the proof of the lower bound for KFL^*", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions concerning the proof-theoretic strength of classical versus\nnon-classical theories of truth have received some attention recently. A\nparticularly convenient case study concerns classical and nonclassical\naxiomatizations of fixed-point semantics. It is known that nonclassical\naxiomatizations in four- or three-valued logics are substantially weaker than\ntheir classical counterparts. In this paper we consider the addition of a\nsuitable conditional to First-Degree Entailment -- a logic recently studied by\nHannes Leitgeb under the label `HYPE'. We show in particular that, by\nformulating the theory PKF over HYPE one obtains a theory that is sound with\nrespect to fixed-point models, while being proof-theoretically on a par with\nits classical counterpart KF. Moreover, we establish that also its schematic\nextension -- in the sense of Feferman -- is as strong as the schematic\nextension of KF, thus matching the strength of predicative analysis.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:06:53 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 13:33:41 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 15:44:42 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Fischer", "Martin", ""], ["Nicolai", "Carlo", ""], ["Fernandez", "Pablo Dopico", ""]]}, {"id": "2007.07235", "submitter": "Manuel Gieseking", "authors": "Bernd Finkbeiner, Manuel Gieseking, Jesko Hecking-Harbusch,\n  Ernst-R\\\"udiger Olderog", "title": "Model Checking Branching Properties on Petri Nets with Transits (Full\n  Version)", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To model check concurrent systems, it is convenient to distinguish between\nthe data flow and the control. Correctness is specified on the level of data\nflow whereas the system is configured on the level of control. Petri nets with\ntransits and Flow-LTL are a corresponding formalism. In Flow-LTL, both the\ncorrectness of the data flow and assumptions on fairness and maximality for the\ncontrol are expressed in linear time. So far, branching behavior cannot be\nspecified for Petri nets with transits. In this paper, we introduce Flow-CTL*\nto express the intended branching behavior of the data flow while maintaining\nLTL for fairness and maximality assumptions on the control. We encode physical\naccess control with policy updates as Petri nets with transits and give\nstandard requirements in Flow-CTL*. For model checking, we reduce the model\nchecking problem of Petri nets with transits against Flow-CTL* via automata\nconstructions to the model checking problem of Petri nets against LTL. Thereby,\nphysical access control with policy updates under fairness assumptions for an\nunbounded number of people can be verified.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:51:35 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Gieseking", "Manuel", ""], ["Hecking-Harbusch", "Jesko", ""], ["Olderog", "Ernst-R\u00fcdiger", ""]]}, {"id": "2007.07421", "submitter": "Toru Takisaka", "authors": "Kittiphon Phalakarn, Toru Takisaka, Thomas Haas, Ichiro Hasuo", "title": "Widest Paths and Global Propagation in Bounded Value Iteration for\n  Stochastic Games", "comments": "v2: an URL to the implementation is added", "journal-ref": "32nd International Conference on Computer-Aided Verification. CAV\n  2020. Lecture Notes in Computer Science, vol 12225. Springer", "doi": "10.1007/978-3-030-53291-8_19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving stochastic games with the reachability objective is a fundamental\nproblem, especially in quantitative verification and synthesis. For this\npurpose, bounded value iteration (BVI) attracts attention as an efficient\niterative method. However, BVI's performance is often impeded by costly end\ncomponent (EC) computation that is needed to ensure convergence. Our\ncontribution is a novel BVI algorithm that conducts, in addition to local\npropagation by the Bellman update that is typical of BVI, global propagation of\nupper bounds that is not hindered by ECs. To conduct global propagation in a\ncomputationally tractable manner, we construct a weighted graph and solve the\nwidest path problem in it. Our experiments show the algorithm's performance\nadvantage over the previous BVI algorithms that rely on EC computation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 00:58:20 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 04:17:47 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Phalakarn", "Kittiphon", ""], ["Takisaka", "Toru", ""], ["Haas", "Thomas", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "2007.07571", "submitter": "Joelle Despeyroux", "authors": "Elisabetta de Maria, Joelle Despeyroux (CRISAM), Amy Felty (uOttawa),\n  Pietro Li\\`o, Carlos Olarte (UFRN), Abdorrahim Bahrami (uOttawa)", "title": "Computational Logic for Biomedicine and Neurosciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate here the use of computational logic for systems biology, as a\n\\emph{unified and safe} framework well suited for both modeling the dynamic\nbehaviour of biological systems, expressing properties of them, and verifying\nthese properties. The potential candidate logics should have a traditional\nproof theoretic pedigree (including either induction, or a sequent calculus\npresentation enjoying cut-elimination and focusing), and should come with\ncertified proof tools. Beyond providing a reliable framework, this allows the\ncorrect encodings of our biological systems. % For systems biology in general\nand biomedicine in particular, we have so far, for the modeling part, three\ncandidate logics: all based on linear logic. The studied properties and their\nproofs are formalized in a very expressive (non linear) inductive logic: the\nCalculus of Inductive Constructions (CIC). The examples we have considered so\nfar are relatively simple ones; however, all coming with formal semi-automatic\nproofs in the Coq system, which implements CIC. In neuroscience, we are\ndirectly using CIC and Coq, to model neurons and some simple neuronal circuits\nand prove some of their dynamic properties. % In biomedicine, the study of\nmulti omic pathway interactions, together with clinical and electronic health\nrecord data should help in drug discovery and disease diagnosis. Future work\nincludes using more automatic provers. This should enable us to specify and\nstudy more realistic examples, and in the long term to provide a system for\ndisease diagnosis and therapy prognosis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 09:37:09 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:58:49 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["de Maria", "Elisabetta", "", "CRISAM"], ["Despeyroux", "Joelle", "", "CRISAM"], ["Felty", "Amy", "", "uOttawa"], ["Li\u00f2", "Pietro", "", "UFRN"], ["Olarte", "Carlos", "", "UFRN"], ["Bahrami", "Abdorrahim", "", "uOttawa"]]}, {"id": "2007.07573", "submitter": "Giovanni Casini", "authors": "Giovanni Casini, Umberto Straccia", "title": "Defeasible RDFS via Rational Closure", "comments": "47 pages. Preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of non-monotonic logics, the notion of Rational Closure (RC) is\nacknowledged as a prominent approach. In recent years, RC has gained even more\npopularity in the context of Description Logics (DLs), the logic underpinning\nthe semantic web standard ontology language OWL 2, whose main ingredients are\nclasses and roles. In this work, we show how to integrate RC within the triple\nlanguage RDFS, which together with OWL2 are the two major standard semantic web\nontology languages. To do so, we start from $\\rho df$, which is the logic\nbehind RDFS, and then extend it to $\\rho df_\\bot$, allowing to state that two\nentities are incompatible. Eventually, we propose defeasible $\\rho df_\\bot$ via\na typical RC construction. The main features of our approach are: (i) unlike\nmost other approaches that add an extra non-monotone rule layer on top of\nmonotone RDFS, defeasible $\\rho df_\\bot$ remains syntactically a triple\nlanguage and is a simple extension of $\\rho df_\\bot$ by introducing some new\npredicate symbols with specific semantics. In particular, any RDFS\nreasoner/store may handle them as ordinary terms if it does not want to take\naccount for the extra semantics of the new predicate symbols; (ii) the\ndefeasible $\\rho df_\\bot$ entailment decision procedure is build on top of the\n$\\rho df_\\bot$ entailment decision procedure, which in turn is an extension of\nthe one for $\\rho df$ via some additional inference rules favouring an\npotential implementation; and (iii) defeasible $\\rho df_\\bot$ entailment can be\ndecided in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 09:45:50 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Casini", "Giovanni", ""], ["Straccia", "Umberto", ""]]}, {"id": "2007.07593", "submitter": "Jurriaan Rot", "authors": "Jana Wagemaker and Paul Brunet and Simon Docherty and Tobias Kapp\\'e\n  and Jurriaan Rot and Alexandra Silva", "title": "Partially Observable Concurrent Kleene Algebra", "comments": "Accepted for publication at CONCUR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce partially observable concurrent Kleene algebra (POCKA), an\nalgebraic framework to reason about concurrent programs with control\nstructures, such as conditionals and loops. POCKA enables reasoning about\nprograms that can access variables and values, which we illustrate through\nconcrete examples. We prove that POCKA is a sound and complete axiomatisation\nof a model of partial observations, and show the semantics passes an important\ncheck for sequential consistency.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 10:16:36 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 16:27:27 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Wagemaker", "Jana", ""], ["Brunet", "Paul", ""], ["Docherty", "Simon", ""], ["Kapp\u00e9", "Tobias", ""], ["Rot", "Jurriaan", ""], ["Silva", "Alexandra", ""]]}, {"id": "2007.07694", "submitter": "David Purser", "authors": "Dmitry Chistikov, Stefan Kiefer, Andrzej S. Murawski and David Purser", "title": "The Big-O Problem", "comments": "Extended version of the CONCUR 2020 paper \"The Big-O Problem for\n  Labelled Markov Chains and Weighted Automata\":\n  https://doi.org/10.4230/LIPIcs.CONCUR.2020.41", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two weighted automata, we consider the problem of whether one is big-O\nof the other, i.e., if the weight of every finite word in the first is not\ngreater than some constant multiple of the weight in the second.\n  We show that the problem is undecidable, even for the instantiation of\nweighted automata as labelled Markov chains. Moreover, even when it is known\nthat one weighted automaton is big-O of another, the problem of finding or\napproximating the associated constant is also undecidable.\n  Our positive results show that the big-O problem is polynomial-time solvable\nfor unambiguous automata, coNP-complete for unlabelled weighted automata (i.e.,\nwhen the alphabet is a single character) and decidable, subject to Schanuel's\nconjecture, when the language is bounded (i.e., a subset of $w_1^*\\dots w_m^*$\nfor some finite words $w_1,\\dots,w_m$) or when the automaton has finite\nambiguity.\n  On labelled Markov chains, the problem can be restated as a ratio total\nvariation distance, which, instead of finding the maximum difference between\nthe probabilities of any two events, finds the maximum ratio between the\nprobabilities of any two events. The problem is related to\n$\\epsilon$-differential privacy, for which the optimal constant of the big-O\nnotation is exactly $\\exp(\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:08:48 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 14:10:11 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Chistikov", "Dmitry", ""], ["Kiefer", "Stefan", ""], ["Murawski", "Andrzej S.", ""], ["Purser", "David", ""]]}, {"id": "2007.07769", "submitter": "Tiago Veras Sr.", "authors": "Tiago M. L. Veras and Arthur F. Ramos and Ruy J. G. B. de Queiroz and\n  Thiago D. O. Silva and Anjolina G. de Oliveira", "title": "Computational Paths -- A Weak Groupoid", "comments": "37 pages. arXiv admin note: substantial text overlap with\n  arXiv:1906.09105", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a labelled deduction system based on the concept of computational\npaths (sequences of rewrites) as equalities between two terms of the same type.\nWe also define a term rewriting system that is used to make computations\nbetween these computational paths, establishing equalities between equalities.\nWe use a labelled deduction system based on the concept of computational paths\n(sequences of rewrites) as our tool, to perform in algebraic topology an\napproach of computational paths. This makes it possible to build the\nfundamental groupoid of a type $X$ connected by paths. Then, we will establish\nthe morphism between these groupoid structures, getting the concept of\nisomorphisms between types and to constitute the category of computational\npaths, which will be called $\\mathcal{C}_{paths}$. Finally, we will conclude\nthat the weak category $\\mathcal{C}_{paths}$ determines a weak groupid.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 22:30:54 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Veras", "Tiago M. L.", ""], ["Ramos", "Arthur F.", ""], ["de Queiroz", "Ruy J. G. B.", ""], ["Silva", "Thiago D. O.", ""], ["de Oliveira", "Anjolina G.", ""]]}, {"id": "2007.07857", "submitter": "Sebastian Siebertz", "authors": "Jaroslav Nesetril, Patrice Ossona de Mendez, Michal Pilipczuk, Roman\n  Rabinovich, Sebastian Siebertz", "title": "Rankwidth meets stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two notions of being well-structured for classes of graphs that are\ninspired by classic model theory. A class of graphs $C$ is monadically stable\nif it is impossible to define arbitrarily long linear orders in vertex-colored\ngraphs from $C$ using a fixed first-order formula. Similarly, monadic\ndependence corresponds to the impossibility of defining all graphs in this way.\nExamples of monadically stable graph classes are nowhere dense classes, which\nprovide a robust theory of sparsity. Examples of monadically dependent classes\nare classes of bounded rankwidth (or equivalently, bounded cliquewidth), which\ncan be seen as a dense analog of classes of bounded treewidth. Thus, monadic\nstability and monadic dependence extend classical structural notions for graphs\nby viewing them in a wider, model-theoretical context. We explore this emerging\ntheory by proving the following:\n  - A class of graphs $C$ is a first-order transduction of a class with bounded\ntreewidth if and only if $C$ has bounded rankwidth and a stable edge relation\n(i.e. graphs from $C$ exclude some half-graph as a semi-induced subgraph).\n  - If a class of graphs $C$ is monadically dependent and not monadically\nstable, then $C$ has in fact an unstable edge relation.\n  As a consequence, we show that classes with bounded rankwidth excluding some\nhalf-graph as a semi-induced subgraph are linearly $\\chi$-bounded. Our proofs\nare effective and lead to polynomial time algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:21:58 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Nesetril", "Jaroslav", ""], ["de Mendez", "Patrice Ossona", ""], ["Pilipczuk", "Michal", ""], ["Rabinovich", "Roman", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "2007.07879", "submitter": "Aliaume Lopez", "authors": "Aliaume Lopez", "title": "Preservation Theorems Through the Lens of Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a family of topological spaces that captures the\nexistence of preservation theorems. The structure of those spaces allows us to\nstudy the relativisation of preservation theorems under suitable definitions of\nsurjective morphisms, subclasses, sums, products, topological closures, and\nprojective limits. Throughout the paper, we also integrate already known\nresults into this new framework and show how it captures th essence of their\nproofs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:54:33 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Lopez", "Aliaume", ""]]}, {"id": "2007.08017", "submitter": "Jesse Michel", "authors": "Benjamin Sherman, Jesse Michel, Michael Carbin", "title": "$\\lambda_S$: Computable Semantics for Differentiable Programming with\n  Higher-Order Functions and Datatypes", "comments": "31 pages, 10 figures", "journal-ref": null, "doi": "10.1145/3434284", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is moving towards increasingly sophisticated optimization\nobjectives that employ higher-order functions, such as integration, continuous\noptimization, and root-finding. Since differentiable programming frameworks\nsuch as PyTorch and TensorFlow do not have first-class representations of these\nfunctions, developers must reason about the semantics of such objectives and\nmanually translate them to differentiable code.\n  We present a differentiable programming language, $\\lambda_S$, that is the\nfirst to deliver a semantics for higher-order functions, higher-order\nderivatives, and Lipschitz but nondifferentiable functions. Together, these\nfeatures enable $\\lambda_S$ to expose differentiable, higher-order functions\nfor integration, optimization, and root-finding as first-class functions with\nautomatically computed derivatives. $\\lambda_S$'s semantics is computable,\nmeaning that values can be computed to arbitrary precision, and we implement\n$\\lambda_S$ as an embedded language in Haskell.\n  We use $\\lambda_S$ to construct novel differentiable libraries for\nrepresenting probability distributions, implicit surfaces, and generalized\nparametric surfaces -- all as instances of higher-order datatypes -- and\npresent case studies that rely on computing the derivatives of these\nhigher-order functions and datatypes. In addition to modeling existing\ndifferentiable algorithms, such as a differentiable ray tracer for implicit\nsurfaces, without requiring any user-level differentiation code, we demonstrate\nnew differentiable algorithms, such as the Hausdorff distance of generalized\nparametric surfaces.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 22:11:48 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 17:23:29 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Sherman", "Benjamin", ""], ["Michel", "Jesse", ""], ["Carbin", "Michael", ""]]}, {"id": "2007.08094", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "Game semantics of Martin-L\\\"of type theory, part III: its consistency\n  with Church's thesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove consistency of intensional Martin-L\\\"of type theory (MLTT) with\nformal Church's thesis (CT), which was open for at least fifteen years. The\ndifficulty in proving the consistency is that a standard method of\nrealizability \\`{a} la Kleene does not work for the consistency, though it\nvalidates CT, as it does not model MLTT; specifically, the realizability does\nnot validate MLTT's congruence rule on pi-types (known as the $\\xi$-rule). We\novercome this point and prove the consistency by novel realizability \\`{a} la\ngame semantics, which is based on the author's previous work.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 04:07:59 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 16:49:45 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "2007.08152", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek, Vincent Gramoli and Pierre Tholoniat", "title": "Feasibility of Cross-Chain Payment with Success Guarantees", "comments": "This is a summary of the work reported in arXiv:1912.04513", "journal-ref": "Proc. 32nd ACM Symposium on Parallelism in Algorithms and\n  Architectures, SPAA'20, July 2020, pp. 579-581", "doi": "10.1145/3350755.3400264", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of cross-chain payment whereby customers of different\nescrows---implemented by a bank or a blockchain smart contract---successfully\ntransfer digital assets without trusting each other. Prior to this work,\ncross-chain payment problems did not require this success, or any form of\nprogress. We demonstrate that it is possible to solve this problem when\nassuming synchrony, in the sense that each message is guaranteed to arrive\nwithin a known amount of time, but impossible to solve without assuming\nsynchrony. Yet, we solve a weaker variant of this problem, where success is\nconditional on the patience of the participants, without assuming synchrony,\nand in the presence of Byzantine failures. We also discuss the relation with\nthe recently defined cross-chain deals.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 07:22:20 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["van Glabbeek", "Rob", ""], ["Gramoli", "Vincent", ""], ["Tholoniat", "Pierre", ""]]}, {"id": "2007.08187", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert, Daniele Varacca (LACL)", "title": "Processes, Systems \\& Tests: Defining Contextual Equivalences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper, we would like to offer and defend a new template to\nstudy equivalences between programs -- in the particular framework of process\nalgebras for concurrent computation.We believe that our layered model of\ndevelopment will clarify the distinction that is too often left implicit\nbetween the tasks and duties of the programmer and of the tester. It will also\nenlighten pre-existing issues that have been running across process algebras as\ndiverse as the calculus of communicating systems, the \\(\\pi\\)-calculus -- also\nin its distributed version -- or mobile ambients.Our distinction starts by\nsubdividing the notion of process itself in three conceptually separated\nentities, that we call \\emph{Processes}, \\emph{Systems} and \\emph{Tests}.While\nthe role of what can be observed and the subtleties in the definitions of\ncongruences have been intensively studied, the fact that \\emph{not every\nprocess can be tested}, and that \\emph{the tester should have access to a\ndifferent set of tools than the programmer} is curiously left out, or at least\nnot often formally discussed.We argue that this blind spot comes from the\nunder-specification of contexts -- environments in which comparisons takes\nplace -- that play multiple distinct roles but supposedly always \\enquote{stay\nthe same}.We illustrate our statement with a simple Java example, the\n\\enquote{usual} concurrent languages, but also back it up with\n\\(\\lambda\\)-calculus and existing implementations of concurrent languages as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 08:54:46 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 12:57:02 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 14:16:28 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LACL"], ["Varacca", "Daniele", "", "LACL"]]}, {"id": "2007.08255", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere and Chris Hankin", "title": "MaxSAT Evaluation 2020 -- Benchmark: Identifying Maximum Probability\n  Minimal Cut Sets in Fault Trees", "comments": "5 pages, 1 figure. To appear in Proceedings of the MaxSAT Evaluation\n  2020 (MSE'20). https://maxsat-evaluations.github.io/2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM cs.LO cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a MaxSAT benchmark focused on the identification of\nMaximum Probability Minimal Cut Sets (MPMCSs) in fault trees. We address the\nMPMCS problem by transforming the input fault tree into a weighted logical\nformula that is then used to build and solve a Weighted Partial MaxSAT problem.\nThe benchmark includes 80 cases with fault trees of different size and\ncomposition as well as the optimal cost and solution for each case.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 11:05:24 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""]]}, {"id": "2007.08307", "submitter": "Jamie Vicary", "authors": "Eric Finster, David Reutter and Jamie Vicary", "title": "A Type Theory for Strictly Unital $\\infty$-Categories", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a type theory for strictly unital $\\infty$-categories, in which a\nterm computes to its strictly unital normal form. Using this as a toy model, we\nargue that it illustrates important unresolved questions in the foundations of\ntype theory, which we explore. Furthermore, our type theory leads to a new\ndefinition of strictly unital $\\infty$-category, which we claim is stronger\nthan any previously described in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 12:54:43 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Finster", "Eric", ""], ["Reutter", "David", ""], ["Vicary", "Jamie", ""]]}, {"id": "2007.08351", "submitter": "Nils Jansen", "authors": "Leonore Winterer, Ralf Wimmer, Nils Jansen, Bernd Becker", "title": "Strengthening Deterministic Policies for POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synthesis problem for partially observable Markov decision processes\n(POMDPs) is to compute a policy that satisfies a given specification. Such\npolicies have to take the full execution history of a POMDP into account,\nrendering the problem undecidable in general. A common approach is to use a\nlimited amount of memory and randomize over potential choices. Yet, this\nproblem is still NP-hard and often computationally intractable in practice. A\nrestricted problem is to use neither history nor randomization, yielding\npolicies that are called stationary and deterministic. Previous approaches to\ncompute such policies employ mixed-integer linear programming (MILP). We\nprovide a novel MILP encoding that supports sophisticated specifications in the\nform of temporal logic constraints. It is able to handle an arbitrary number of\nsuch specifications. Yet, randomization and memory are often mandatory to\nachieve satisfactory policies. First, we extend our encoding to deliver a\nrestricted class of randomized policies. Second, based on the results of the\noriginal MILP, we employ a preprocessing of the POMDP to encompass memory-based\ndecisions. The advantages of our approach over state-of-the-art POMDP solvers\nlie (1) in the flexibility to strengthen simple deterministic policies without\nlosing computational tractability and (2) in the ability to enforce the\nprovable satisfaction of arbitrarily many specifications. The latter point\nallows taking trade-offs between performance and safety aspects of typical\nPOMDP examples into account. We show the effectiveness of our method on a broad\nrange of benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:22:55 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Winterer", "Leonore", ""], ["Wimmer", "Ralf", ""], ["Jansen", "Nils", ""], ["Becker", "Bernd", ""]]}, {"id": "2007.08387", "submitter": "Richard Combes", "authors": "Richard Combes and Mikael Touati", "title": "Solving Random Parity Games in Polynomial Time", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of solving random parity games. We prove that parity\ngames exibit a phase transition threshold above $d_P$, so that when the degree\nof the graph that defines the game has a degree $d > d_P$ then there exists a\npolynomial time algorithm that solves the game with high probability when the\nnumber of nodes goes to infinity. We further propose the SWCP (Self-Winning\nCycles Propagation) algorithm and show that, when the degree is large enough,\nSWCP solves the game with high probability. Furthermore, the complexity of SWCP\nis polynomial $O\\Big(|{\\cal V}|^2 + |{\\cal V}||{\\cal E}|\\Big)$. The design of\nSWCP is based on the threshold for the appearance of particular types of cycles\nin the players' respective subgraphs. We further show that non-sparse games can\nbe solved in time $O(|{\\cal V}|)$ with high probability, and emit a conjecture\nconcerning the hardness of the $d=2$ case.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 15:05:51 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Combes", "Richard", ""], ["Touati", "Mikael", ""]]}, {"id": "2007.08598", "submitter": "Bartosz Bednarczyk", "authors": "Bartosz Bednarczyk, St\\'ephane Demri, Raul Fervari, Alessio Mansutti", "title": "Modal Logics with Composition on Finite Forests: Expressivity and\n  Complexity (Extra Material)", "comments": "Extra material for our LICS 2020 paper published under the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the expressivity and computational complexity of two modal\nlogics on finite forests equipped with operators to reason on submodels. The\nlogic ML(|) extends the basic modal logic ML with the composition operator |\nfrom static ambient logic, whereas ML(*) contains the separating conjunction *\nfrom separation logic. Though both operators are second-order in nature, we\nshow that ML(|) is as expressive as the graded modal logic GML (on finite\ntrees) whereas ML(*) lies strictly between ML and GML. Moreover, we establish\nthat the satisfiability problem for ML(*) is Tower-complete, whereas for ML(|)\nis (only) AExpPol-complete. As a by-product, we solve several open problems\nrelated to sister logics, such as static ambient logic, modal separation logic,\nand second-order modal logic on finite trees.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 19:56:42 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Demri", "St\u00e9phane", ""], ["Fervari", "Raul", ""], ["Mansutti", "Alessio", ""]]}, {"id": "2007.08636", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM), Dominique Lecomte (IMJ-PRG)", "title": "Descriptive Set Theory and $\\omega$-Powers of Finitary Languages", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.08174", "journal-ref": "Adrian Rezus. Contemporary Logic and Computing, 1, College\n  Publications, pp.518-541, 2020, Landscapes in Logic", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\omega$-power of a finitary language L over a finite alphabet $\\Sigma$\nis the language of infinite words over $\\Sigma$ defined by L $\\infty$ := {w 0 w\n1. .. $\\in$ $\\Sigma$ $\\omega$ | $\\forall$i $\\in$ $\\omega$ w i $\\in$ L}. The\n$\\omega$-powers appear very naturally in Theoretical Computer Science in the\ncharacterization of several classes of languages of infinite words accepted by\nvarious kinds of automata, like B{\\\"u}chi automata or B{\\\"u}chi pushdown\nautomata. We survey some recent results about the links relating Descriptive\nSet Theory and $\\omega$-powers.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 10:20:58 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Finkel", "Olivier", "", "ELM"], ["Lecomte", "Dominique", "", "IMJ-PRG"]]}, {"id": "2007.08638", "submitter": "Michael Wolman", "authors": "Marcin Sabok, Sam Staton, Dario Stein, Michael Wolman", "title": "Probabilistic Programming Semantics for Name Generation", "comments": "29 pages, 1 figure; to be published in POPL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make a formal analogy between random sampling and fresh name generation.\nWe show that quasi-Borel spaces, a model for probabilistic programming, can\nsoundly interpret Stark's $\\nu$-calculus, a calculus for name generation.\nMoreover, we prove that this semantics is fully abstract up to first-order\ntypes. This is surprising for an 'off-the-shelf' model, and requires a novel\nanalysis of probability distributions on function spaces. Our tools are diverse\nand include descriptive set theory and normal forms for the $\\nu$-calculus.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 21:06:07 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 14:07:59 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2020 20:11:24 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Sabok", "Marcin", ""], ["Staton", "Sam", ""], ["Stein", "Dario", ""], ["Wolman", "Michael", ""]]}, {"id": "2007.08926", "submitter": "Gordon Plotkin", "authors": "Martin Abadi and Gordon Plotkin", "title": "Smart Choices and the Selection Monad", "comments": "Improved resulss and presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing systems in terms of choices and their resulting costs and rewards\noffers the promise of freeing algorithm designers and programmers from\nspecifying how those choices should be made; in implementations, the choices\ncan be realized by optimization techniques and,increasingly, by\nmachine-learning methods. We study this approach from a programming-language\nperspective. We define two small languages that support decision-making\nabstractions: one with choices and rewards, and the other additionally with\nprobabilities. We give both operational and denotational semantics.\n  In the case of the second language we consider three denotational semantics,\nwith varying degrees of correlation between possible program values and\nexpected rewards. The operational semantics combine the usual semantics of\nstandard constructs with optimization over spaces of possible execution\nstrategies. The denotational semantics, which are compositional rely on the\nselection monad, to handle choice, augmented with an auxiliary monad to handle\nother effects, such as rewards or probability.\n  We establish adequacy theorems that the two semantics coincide in all cases.\nWe also prove full abstraction at base types, with varying notions of\nobservation in the probabilistic case corresponding to the various degrees of\ncorrelation. We present axioms for choice combined with rewards and\nprobability, establishing completeness at base types for the case of rewards\nwithout probability.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 12:13:16 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 18:53:23 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 18:33:28 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 11:48:28 GMT"}, {"version": "v5", "created": "Mon, 28 Jun 2021 02:11:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Abadi", "Martin", ""], ["Plotkin", "Gordon", ""]]}, {"id": "2007.09096", "submitter": "Gr\\'egoire Sutre", "authors": "J\\'er\\^ome Leroux and Gr\\'egoire Sutre", "title": "Reachability in Two-Dimensional Vector Addition Systems with States: One\n  Test is for Free", "comments": "Full version of the paper with the same title and authors in the\n  proceedings of CONCUR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector addition system with states is an ubiquitous model of computation with\nextensive applications in computer science. The reachability problem for vector\naddition systems is central since many other problems reduce to that question.\nThe problem is decidable and it was recently proved that the dimension of the\nvector addition system is an important parameter of the complexity. In fixed\ndimensions larger than two, the complexity is not known (with huge complexity\ngaps). In dimension two, the reachability problem was shown to be\nPSPACE-complete by Blondin et al. in 2015. We consider an extension of this\nmodel, called 2-TVASS, where the first counter can be tested for zero. This\nmodel naturally extends the classical model of one counter automata (OCA). We\nshow that reachability is still solvable in polynomial space for 2-TVASS. As in\nthe work Blondin et al., our approach relies on the existence of small\nreachability certificates obtained by concatenating polynomially many cycles.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 16:22:31 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Leroux", "J\u00e9r\u00f4me", ""], ["Sutre", "Gr\u00e9goire", ""]]}, {"id": "2007.09099", "submitter": "Andrei Bulatov", "authors": "Andrei A. Bulatov", "title": "A dichotomy theorem for nonuniform CSPs simplified", "comments": "This is an updated and improved version of the proof of the CSP\n  dichotomy from CoRR abs/1703.03021, 2017. arXiv admin note: text overlap with\n  arXiv:1703.03021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a non-uniform Constraint Satisfaction problem CSP(G), where G is a set of\nrelations on a finite set A, the goal is to find an assignment of values to\nvariables subject to constraints imposed on specified sets of variables using\nthe relations from G. The Dichotomy Conjecture for the non-uniform CSP states\nthat for every constraint language G the problem CSP(G) is either solvable in\npolynomial time or is NP-complete. It was proposed by Feder and Vardi in their\nseminal 1993 paper. In this paper we confirm the Dichotomy Conjecture.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 00:43:28 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Bulatov", "Andrei A.", ""]]}, {"id": "2007.09189", "submitter": "Mikhail Raskin", "authors": "Michael Raskin, Chana Weil-Kennedy", "title": "Efficient Restrictions of Immediate Observation Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper we introduced immediate observation Petri nets, a\nsubclass of Petri nets with application domains in distributed protocols\n(population protocols) and theoretical chemistry (chemical reaction networks).\nIO nets enjoy many useful properties, but like the general case of conservative\nPetri nets they have a PSPACE-complete reachability problem. In this paper we\nexplore two restrictions of the reachability problem for IO nets which lower\nthe complexity of the problem drastically. The complexity is NP-complete for\nthe first restriction with applications in distributed protocols, and it is\npolynomial for the second restriction with applications in chemical settings.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 18:54:34 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 14:00:19 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 16:24:44 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Raskin", "Michael", ""], ["Weil-Kennedy", "Chana", ""]]}, {"id": "2007.09399", "submitter": "Ruggero Lanotte Dr", "authors": "Ruggero Lanotte and Massimo Merro and Andrei Munteanu", "title": "A process calculus approach to correctness enforcement of PLCs (full\n  version)", "comments": "21-st Italian Conference on Theoretical Computer Science (ICTCS\n  2020). CEUR Workshop Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a simple process calculus, based on Hennessy and Regan's Timed\nProcess Language, for specifying networks of communicating programmable logic\ncontrollers (PLCs) enriched with monitors enforcing specifications compliance.\nWe define a synthesis algorithm that given an uncorrupted PLC returns a monitor\nthat enforces the correctness of the PLC, even when injected with malware that\nmay forge/drop actuator commands and inter-controller communications. Then, we\nstrengthen the capabilities of our monitors by allowing the insertion of\nactions to mitigate malware activities. This gives us deadlock-freedom\nmonitoring: malware may not drag monitored controllers into deadlock states.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 10:40:18 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 15:46:46 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Lanotte", "Ruggero", ""], ["Merro", "Massimo", ""], ["Munteanu", "Andrei", ""]]}, {"id": "2007.09909", "submitter": "Fran\\c{c}ois Bry", "authors": "Fran\\c{c}ois Bry", "title": "Coinduction Plain and Simple", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Coinduction refers to both a technique for the definition of infinite\nstreams, so-called codata, and a technique for proving the equality of\ncoinductively specified codata. This article first reviews coinduction in\ndeclarative programming. Second, it reviews and slightly extends the formalism\ncommonly used for specifying codata. Third, it generalizes the coinduction\nproof principle, which has been originally specified for the equality predicate\nonly, to other predicates. This generalization makes the coinduction proof\nprinciple more intuitive and stresses its closeness with structural induction.\nThe article finally suggests in its conclusion extensions of functional and\nlogic programming with limited and decidable forms of the generalized\ncoinduction proof principle.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 06:52:54 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 08:23:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bry", "Fran\u00e7ois", ""]]}, {"id": "2007.10057", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Retracing some paths in categorical semantics: From\n  process-propositions-as-types to categorified reals and computers", "comments": "63 pages, 40 figures; cut two words from the title, tried to improve\n  (without lengthening) Sec.8; rewrote a proof in the Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logical parallelism of propositional connectives and type constructors\nextends beyond the static realm of predicates, to the dynamic realm of\nprocesses. Understanding the logical parallelism of process propositions and\ndynamic types was one of the central problems of the semantics of computation,\nalbeit not always clear or explicit. It sprung into clarity through the early\nwork of Samson Abramsky, where the central ideas of denotational semantics and\nprocess calculus were brought together and analyzed by categorical tools, e.g.\nin the structure of interaction categories. While some logical structures borne\nof dynamics of computation immediately started to emerge, others had to wait,\nbe it because the underlying logical principles (mainly those arising from\ncoinduction) were not yet sufficiently well-understood, or simply because the\nresearch community was more interested in other semantical tasks. Looking back,\nit seems that the process logic uncovered by those early semantical efforts\nmight still be starting to emerge and that the vast field of results that have\nbeen obtained in the meantime might be a valley on a tip of an iceberg.\n  In the present paper, I try to provide a logical overview of the gamut of\ninteraction categories and to distinguish those that model computation from\nthose that capture processes in general. The main coinductive constructions\nturn out to be of this latter kind, as illustrated towards the end of the paper\nby a compact category of all real numbers as processes, computable and\nuncomputable, with polarized bisimulations as morphisms. The addition of the\nreals arises as the biproduct, real vector spaces are the enriched\nbicompletions, and linear algebra arises from the enriched kan extensions. At\nthe final step, I sketch a structure that characterizes the computable fragment\nof categorical semantics.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 12:52:26 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 00:11:58 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 05:02:40 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "2007.10090", "submitter": "Amirhoshang Hoseinpour Dehkordi", "authors": "Amirhoshang Hoseinpour Dehkordi, Majid Alizadeh, Ebrahim\n  Ardeshir-Larijani, Ali Movaghar", "title": "MASKS: A Multi-Classifier's verification approach", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers are one of the most widely applied approaches in Artificial\nIntelligence (AI). However, the employment of classifiers in critical\napplications would render any errors in these systems more consequential;\nparticularly due to the lack of formal verification methods in these systems.\nThis study aims to develop a verification method that eliminates errors through\nthe integration of multiple classifiers. In order to do this, primarily, we\nhave defined a special property for the classifiers which extracts the\nknowledge of these classifiers. Secondly, we have designed a multi-agent\nsystem, comprised of multiple classifiers, in order to check the satisfaction\nof the aforementioned special property. Also, in order to help examine the\nreasoning concerning the aggregation of the distributed knowledge, itself\ngained through the combined effort of separate classifiers and acquired\nexternal information sources, a dynamic epistemic logic-based method has been\nproposed. Our proposed model is capable of verifying itself given specific\ninputs if the cumulative knowledge of the entire system proves their\ncorrectness, which results in self-awareness of this system. Finally, we\napplied this model to the MNIST dataset, and it successfully reduced the error\nrate to approximately one-tenth of the individual classifiers. In conclusion,\nwe have formulated and developed a Multi-Agent Systems' Knowledge-Sharing\nalgorithm (MASKS) and verified its utility compared to individual classifiers\nusing the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 10:47:40 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 11:48:44 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dehkordi", "Amirhoshang Hoseinpour", ""], ["Alizadeh", "Majid", ""], ["Ardeshir-Larijani", "Ebrahim", ""], ["Movaghar", "Ali", ""]]}, {"id": "2007.10215", "submitter": "Tobias Reinhard", "authors": "Tobias Reinhard, Amin Timany, Bart Jacobs", "title": "A Separation Logic to Verify Termination of Busy-Waiting for Abrupt\n  Program Exit: Technical Report", "comments": "22 pages, 14 figures, Technical report (replacement: corrected\n  citation in conclusion)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs for multiprocessor machines commonly perform busy-waiting for\nsynchronisation. In this paper, we make a first step towards proving\ntermination of such programs. We approximate (i) arbitrary waitable events by\nabrupt program termination and (ii) busy-waiting for events by busy-waiting to\nbe abruptly terminated.\n  We propose a separation logic for modularly verifying termination (under fair\nscheduling) of programs where some threads eventually abruptly terminate the\nprogram, and other threads busy-wait for this to happen.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 15:57:25 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 12:55:06 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Reinhard", "Tobias", ""], ["Timany", "Amin", ""], ["Jacobs", "Bart", ""]]}, {"id": "2007.10288", "submitter": "Marius Buliga", "authors": "Marius Buliga", "title": "Graph rewrites, from graphic lambda calculus, to chemlambda, to directed\n  interaction combinators", "comments": "arXiv admin note: text overlap with arXiv:2003.14332", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here I report about the modifications of and relations between graphic lambda\ncalculus, various formalisms which appeared under the name chemlambda and a\nversion of directed interaction combinators. This is part of the study and\nexperiments with the artificial chemistry chemlambda and the relations with\nlambda calculus or interaction combinators, as described in arXiv:2003.14332\nand available from the entry page at https://chemlambda.github.io/index.html\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 19:31:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Buliga", "Marius", ""]]}, {"id": "2007.10400", "submitter": "Kuldeep S. Meel", "authors": "Rahul Gupta, Subhajit Roy, Kuldeep S. Meel", "title": "Phase Transition Behavior in Knowledge Compilation", "comments": "This is full version of the conference paper published at\n  International Conference on Principles and Practice of Constraint Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of phase transition behaviour in SAT has led to deeper\nunderstanding and algorithmic improvements of modern SAT solvers. Motivated by\nthese prior studies of phase transitions in SAT, we seek to study the behaviour\nof size and compile-time behaviour for random k-CNF formulas in the context of\nknowledge compilation.\n  We perform a rigorous empirical study and analysis of the size and runtime\nbehavior for different knowledge compilation forms (and their corresponding\ncompilation algorithms): d-DNNFs, SDDs and OBDDs across multiple tools and\ncompilation algorithms. We employ instances generated from the random k-CNF\nmodel with varying generation parameters to empirically reason about the\nexpected and median behavior of size and compilation-time for these languages.\nOur work is similar in spirit to the early work in CSP community on phase\ntransition behavior in SAT/CSP. In a similar spirit, we identify the\ninteresting behavior with respect to different parameters: clause density and\nsolution density, a novel control parameter that we identify for the study of\nphase transition behavior in the context of knowledge compilation. Furthermore,\nwe summarize our empirical study in terms of two concrete conjectures; a\nrigorous study of these conjectures will possibly require new theoretical\ntools.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 18:36:27 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Gupta", "Rahul", ""], ["Roy", "Subhajit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2007.10519", "submitter": "Elizabeth Polgreen", "authors": "Elizabeth Polgreen and Sanjit A. Seshia", "title": "SynRG: Syntax Guided Synthesis of Expressions with Alternating\n  Quantifiers", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Program synthesis is the task of automatically generating expressions that\nsatisfy a given specification. Program synthesis techniques have been used to\nautomate the generation of loop invariants in code, synthesize function\nsummaries, and to assist programmers via program sketching. Syntax-guided\nsynthesis has been a successful paradigm in this area, however, one area where\nthe state-of-the-art solvers fall-down is reasoning about potentially unbounded\ndata structures such as arrays where both specifications and solutions may\nrequire quantifiers and quantifier alternations. We present SynRG, a synthesis\nalgorithm based on restricting the synthesis problem to generate candidate\nsolutions with quantification over a finite domain, and then generalizing these\ncandidate solutions to the unrestricted domain of the original specification.\nWe report experiments on invariant synthesis benchmarks and on program\nsketching benchmarks taken from the Java StringUtils class and show that our\ntechnique can synthesize expressions out of reach of all existing solvers.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 22:39:17 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 05:10:04 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Polgreen", "Elizabeth", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2007.10539", "submitter": "Franck Cassez", "authors": "Franck Cassez, Peter Gj{\\o}l Jensen, Kim Guldstrand Larsen", "title": "Verification and Parameter Synthesis for Real-Time Programs using\n  Refinement of Trace Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the safety verification and synthesis problems for real-time\nsystems. We introduce real-time programs that are made of instructions that can\nperform assignments to discrete and real-valued variables. They are general\nenough to capture interesting classes of timed systems such as timed automata,\nstopwatch automata, time(d) Petri nets and hybrid automata.\n  We propose a semi-algorithm using refinement of trace abstractions to solve\nboth the reachability verification problem and the parameter synthesis problem\nfor real-time programs.\n  All of the algorithms proposed have been implemented and we have conducted a\nseries of experiments, comparing the performance of our new approach to\nstate-of-the-art tools in classical reachability, robustness analysis and\nparameter synthesis for timed systems. We show that our new method provides\nsolutions to problems which are unsolvable by the current state-of-the-art\ntools.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 00:33:21 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Cassez", "Franck", ""], ["Jensen", "Peter Gj\u00f8l", ""], ["Larsen", "Kim Guldstrand", ""]]}, {"id": "2007.10553", "submitter": "Dan Plyukhin", "authors": "Dan Plyukhin and Gul Agha", "title": "Scalable Termination Detection for Distributed Actor Systems", "comments": "23 pages, 7 figures. To appear in the proceedings of CONCUR 2020.\n  Version 2: Fixed TeX error that omitted predicates in the third line of the\n  Send rule: Actor $A$ must have active refobs $x$ and $y_1 \\dots y_n$", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2020.44", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic garbage collection (GC) prevents certain kinds of bugs and reduces\nprogramming overhead. GC techniques for sequential programs are based on\nreachability analysis. However, testing reachability from a root set is\ninadequate for determining whether an actor is garbage because an unreachable\nactor may send a message to a reachable actor. Instead, it is sufficient to\ncheck termination (sometimes also called quiescence): an actor is terminated if\nit is not currently processing a message and cannot receive a message in the\nfuture. Moreover, many actor frameworks provide all actors with access to file\nI/O or external storage; without inspecting an actor's internal code, it is\nnecessary to check that the actor has terminated to ensure that it may be\ngarbage collected in these frameworks. Previous algorithms to detect actor\ngarbage require coordination mechanisms such as causal message delivery or\nnonlocal monitoring of actors for mutation. Such coordination mechanisms\nadversely affect concurrency and are therefore expensive in distributed\nsystems. We present a low-overhead reference listing technique (called DRL) for\ntermination detection in actor systems. DRL is based on asynchronous local\nsnapshots and message-passing between actors. This enables a decentralized\nimplementation and transient network partition tolerance. The paper provides a\nformal description of DRL, shows that all actors identified as garbage have\nindeed terminated (safety), and that all terminated actors--under certain\nreasonable assumptions--will eventually be identified (liveness).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 01:45:46 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 17:14:00 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Plyukhin", "Dan", ""], ["Agha", "Gul", ""]]}, {"id": "2007.10688", "submitter": "Caterina Urban", "authors": "Caterina Urban", "title": "What Programs Want: Automatic Inference of Input Data Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, as machine-learned software quickly permeates our society, we are\nbecoming increasingly vulnerable to programming errors in the data\npre-processing or training software, as well as errors in the data itself. In\nthis paper, we propose a static shape analysis framework for input data of\ndata-processing programs. Our analysis automatically infers necessary\nconditions on the structure and values of the data read by a data-processing\nprogram. Our framework builds on a family of underlying abstract domains,\nextended to indirectly reason about the input data rather than simply reasoning\nabout the program variables. The choice of these abstract domain is a parameter\nof the analysis. We describe various instances built from existing abstract\ndomains. The proposed approach is implemented in an open-source static analyzer\nfor Python programs. We demonstrate its potential on a number of representative\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 09:56:55 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Urban", "Caterina", ""]]}, {"id": "2007.10770", "submitter": "Ludovic Henrio", "authors": "Rab\\'ea Ameur-Boulifa, Ludovic Henrio, Eric Madelaine", "title": "Compositional equivalences based on Open pNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article defines bisimulation relations for the comparison of systems\nspecified as pNets. We first define a strong bisimulation for open pNets. In\npractice, as happens in process algebras, strong bisimulation is too strong,\nand we need to define some coarser relations, taking into account invisible or\ninternal moves. We then define an equivalence relation similar to the classical\n\\emph{weak bisimulation}, and study its properties. Among these properties we\nare interested in compositionality: If two systems are proven equivalent they\nwill be undistinguishable by their context, and they will also be\nundistinguishable when their holes are filled with equivalent systems. The\narticle is illustrated with a transport protocol running example; it shows the\ncharacteristics of our formalism and our bisimulation relations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 13:09:22 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 13:57:19 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ameur-Boulifa", "Rab\u00e9a", ""], ["Henrio", "Ludovic", ""], ["Madelaine", "Eric", ""]]}, {"id": "2007.10805", "submitter": "Suneel Sarswat", "authors": "Suneel Sarswat and Abhishek Kr Singh", "title": "Formally Verified Trades in Financial Markets", "comments": "Aceepted in ICFEM 2020. arXiv admin note: substantial text overlap\n  with arXiv:1907.07885", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.GT q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formal framework for analyzing trades in financial markets.\nThese days, all big exchanges use computer algorithms to match buy and sell\nrequests and these algorithms must abide by certain regulatory guidelines. For\nexample, market regulators enforce that a matching produced by exchanges should\nbe fair, uniform and individual rational. To verify these properties of trades,\nwe first formally define these notions in a theorem prover and then develop\nmany important results about matching demand and supply. Finally, we use this\nframework to verify properties of two important classes of double sided auction\nmechanisms. All the definitions and results presented in this paper are\ncompletely formalized in the Coq proof assistant without adding any additional\naxioms to it.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 10:03:22 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Sarswat", "Suneel", ""], ["Singh", "Abhishek Kr", ""]]}, {"id": "2007.10842", "submitter": "Stefan Ciobaca", "authors": "Cezar-Constantin Andrici, \\c{S}tefan Ciob\\^ac\\u{a}", "title": "Who Verifies the Verifiers? A Computer-Checked Implementation of the\n  DPLL Algorithm in Dafny", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1909.01743", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We build a SAT solver implementing the DPLL algorithm in the\nverification-enabled programming language Dafny. The resulting solver is fully\nverified (soundness, completeness and termination are computer checked). We\nbenchmark our Dafny solver and we show that it is just as efficient as an\nequivalent DPLL solver implemented in C# and roughly two times less efficient\nthan an equivalent solver written in C++. We conclude that auto-active\nverification is a promising approach to increasing trust in SAT solvers, as it\ncombines a good trade-off between execution speed and degree of trustworthiness\nof the final product.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 19:07:44 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Andrici", "Cezar-Constantin", ""], ["Ciob\u00e2c\u0103", "\u015etefan", ""]]}, {"id": "2007.10865", "submitter": "Andrea Peruffo", "authors": "Daniele Ahmed, Andrea Peruffo, Alessandro Abate", "title": "Automated and Sound Synthesis of Lyapunov Functions with SMT Solvers", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-45190-5_6", "report-no": null, "categories": "eess.SY cs.LG cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we employ SMT solvers to soundly synthesise Lyapunov functions\nthat assert the stability of a given dynamical model. The search for a Lyapunov\nfunction is framed as the satisfiability of a second-order logical formula,\nasking whether there exists a function satisfying a desired specification\n(stability) for all possible initial conditions of the model. We synthesise\nLyapunov functions for linear, non-linear (polynomial), and for parametric\nmodels. For non-linear models, the algorithm also determines a region of\nvalidity for the Lyapunov function. We exploit an inductive framework to\nsynthesise Lyapunov functions, starting from parametric templates. The\ninductive framework comprises two elements: a learner proposes a Lyapunov\nfunction, and a verifier checks its validity - its lack is expressed via a\ncounterexample (a point over the state space), for further use by the learner.\nWhilst the verifier uses the SMT solver Z3, thus ensuring the overall soundness\nof the procedure, we examine two alternatives for the learner: a numerical\napproach based on the optimisation tool Gurobi, and a sound approach based\nagain on Z3. The overall technique is evaluated over a broad set of benchmarks,\nwhich shows that this methodology not only scales to 10-dimensional models\nwithin reasonable computational time, but also offers a novel soundness proof\nfor the generated Lyapunov functions and their domains of validity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:45:23 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ahmed", "Daniele", ""], ["Peruffo", "Andrea", ""], ["Abate", "Alessandro", ""]]}, {"id": "2007.10907", "submitter": "Wojciech Czerwi\\'nski", "authors": "Wojciech Czerwi\\'nski, Diego Figueira and Piotr Hofman", "title": "Universality Problem for Unambiguous VASS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study languages of unambiguous VASS, that is, Vector Addition Systems with\nStates, whose transitions read letters from a finite alphabet, and whose\nacceptance condition is defined by a set of final states (i.e., the\ncoverability language). We show that the problem of universality for\nunambiguous VASS is ExpSpace-complete, in sheer contrast to\nAckermann-completeness for arbitrary VASS, even in dimension 1. When the\ndimension d is fixed, the universality problem is PSpace-complete if d is at\nleast 2, and coNP-hard for 1-dimensional VASSes (also known as One Counter\nNets).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 15:54:19 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Czerwi\u0144ski", "Wojciech", ""], ["Figueira", "Diego", ""], ["Hofman", "Piotr", ""]]}, {"id": "2007.11235", "submitter": "Tetsuya Sato", "authors": "Marco Gaboardi, Shin-ya Katsumata, Dominic Orchard and Tetsuya Sato", "title": "Graded Hoare Logic and its Categorical Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deductive verification techniques based on program logics (i.e., the family\nof Floyd-Hoare logics) are a powerful approach for program reasoning. Recently,\nthere has been a trend of increasing the expressive power of such logics by\naugmenting their rules with additional information to reason about program\nside-effects. For example, general program logics have been augmented with cost\nanalyses, logics for probabilistic computations have been augmented with\nestimate measures, and logics for differential privacy with\nindistinguishability bounds. In this work, we unify these various approaches\nvia the paradigm of grading, adapted from the world of functional calculi and\nsemantics. We propose Graded Hoare Logic (GHL), a parameterisable framework for\naugmenting program logics with a preordered monoidal analysis. We develop a\nsemantic framework for modelling GHL such that grading, logical assertions\n(pre- and post-conditions) and the underlying effectful semantics of an\nimperative language can be integrated together. Central to our framework is the\nnotion of a graded category which we extend here, introducing graded Freyd\ncategories which provide a semantics that can interpret many examples of\naugmented program logics from the literature. We leverage coherent fibrations\nto model the base assertion language, and thus the overall setting is also\nfibrational.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 07:14:31 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 16:53:28 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Gaboardi", "Marco", ""], ["Katsumata", "Shin-ya", ""], ["Orchard", "Dominic", ""], ["Sato", "Tetsuya", ""]]}, {"id": "2007.11345", "submitter": "Jakub Gajarsk\\'y", "authors": "Jakub Gajarsk\\'y, Maximilian Gorsky, Stephan Kreutzer", "title": "Differential games, locality and model checking for FO logic of graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce differential games for FO logic of graphs, a variant of\nEhrenfeucht-Fra\\\"{i}ss\\'e games in which the game is played on only one graph\nand the moves of both players restricted. We prove that, in a certain sense,\nthese games are strong enough to capture essential information about graphs\nfrom graph classes which are interpretable in nowhere dense graph classes.\nThis, together with the newly introduced notion of differential locality and\nthe fact that the restriction of possible moves by the players makes it easy to\ndecide the winner of the game in some cases, leads to a new approach to the FO\nmodel checking problem on interpretations of nowhere dense graph classes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 11:14:49 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Gajarsk\u00fd", "Jakub", ""], ["Gorsky", "Maximilian", ""], ["Kreutzer", "Stephan", ""]]}, {"id": "2007.11398", "submitter": "Peter Chini", "authors": "Peter Chini, Prakash Saivasan", "title": "A Framework for Consistency Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that provides deterministic consistency algorithms for\ngiven memory models. Such an algorithm checks whether the executions of a\nshared-memory concurrent program are consistent under the axioms defined by a\nmodel. For memory models like SC and TSO, checking consistency is NP-complete.\nOur framework shows, that despite the hardness, fast deterministic consistency\nalgorithms can be obtained by employing tools from fine-grained complexity. The\nframework is based on a universal consistency problem which can be instantiated\nby different memory models. We construct an algorithm for the problem running\nin time O*(2^k), where k is the number of write accesses in the execution that\nis checked for consistency. Each instance of the framework then admits an\nO*(2^k)-time consistency algorithm. By applying the framework, we obtain\ncorresponding consistency algorithms for SC, TSO, PSO, and RMO. Moreover, we\nshow that the obtained algorithms for SC, TSO, and PSO are optimal in the\nfine-grained sense: there is no consistency algorithm for these running in time\n2^o(k) unless the exponential time hypothesis fails.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 08:18:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Chini", "Peter", ""], ["Saivasan", "Prakash", ""]]}, {"id": "2007.11737", "submitter": "EPTCS", "authors": "Mehrnoosh Askarpour (Mcmaster University), Matteo Rossi (Politecnico\n  di Milano), Omer Tiryakiler (Politecnico di Milano)", "title": "Co-Simulation of Human-Robot Collaboration: from Temporal Logic to 3D\n  Simulation", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 1-8", "doi": "10.4204/EPTCS.319.1", "report-no": null, "categories": "cs.RO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-Robot Collaboration (HRC) is rapidly replacing the traditional\napplication of robotics in the manufacturing industry. Robots and human\noperators no longer have to perform their tasks in segregated areas and are\ncapable of working in close vicinity and performing hybrid tasks -- performed\npartially by humans and by robots.\n  We have presented a methodology in an earlier work [16] to promote and\nfacilitate formally modeling HRC systems, which are notoriously\nsafety-critical. Relying on temporal logic modeling capabilities and automated\nmodel checking tools, we built a framework to formally model HRC systems and\nverify the physical safety of human operator against ISO 10218-2 [10] standard.\nIn order to make our proposed formal verification framework more appealing to\nsafety engineers, whom are usually not very fond of formal modeling and\nverification techniques, we decided to couple our model checking approach with\na 3D simulator that demonstrates the potential hazardous situations to the\nsafety engineers in a more transparent way. This paper reports our\nco-simulation approach, using Morse simulator [4] and Zot model checker [14].\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:30:31 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Askarpour", "Mehrnoosh", "", "Mcmaster University"], ["Rossi", "Matteo", "", "Politecnico\n  di Milano"], ["Tiryakiler", "Omer", "", "Politecnico di Milano"]]}, {"id": "2007.11743", "submitter": "EPTCS", "authors": "Peter Stringer (University of Liverpool), Rafael C. Cardoso\n  (University of Liverpool), Xiaowei Huang (University of Liverpool), Louise A.\n  Dennis (University of Liverpool)", "title": "Adaptable and Verifiable BDI Reasoning", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 117-125", "doi": "10.4204/EPTCS.319.9", "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term autonomy requires autonomous systems to adapt as their capabilities\nno longer perform as expected. To achieve this, a system must first be capable\nof detecting such changes. In this position paper, we describe a system\narchitecture for BDI autonomous agents capable of adapting to changes in a\ndynamic environment and outline the required research. Specifically, we\ndescribe an agent-maintained self-model with accompanying theories of durative\nactions and learning new action descriptions in BDI systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:32:53 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Stringer", "Peter", "", "University of Liverpool"], ["Cardoso", "Rafael C.", "", "University of Liverpool"], ["Huang", "Xiaowei", "", "University of Liverpool"], ["Dennis", "Louise A.", "", "University of Liverpool"]]}, {"id": "2007.11832", "submitter": "Catia Trubiani", "authors": "Omar Inverso, Hern\\'an Melgratti, Luca Padovani, Catia Trubiani,\n  Emilio Tuosto", "title": "Probabilistic Analysis of Binary Sessions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a probabilistic variant of binary session types that relate to a\nclass of Finite-State Markov Chains. The probability annotations in session\ntypes enable the reasoning on the probability that a session terminates\nsuccessfully, for some user-definable notion of successful termination. We\ndevelop a type system for a simple session calculus featuring probabilistic\nchoices and show that the success probability of well-typed processes agrees\nwith that of the sessions they use. To this aim, the type system needs to track\nthe propagation of probabilistic choices across different sessions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 07:36:42 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Inverso", "Omar", ""], ["Melgratti", "Hern\u00e1n", ""], ["Padovani", "Luca", ""], ["Trubiani", "Catia", ""], ["Tuosto", "Emilio", ""]]}, {"id": "2007.11875", "submitter": "Simone Martini", "authors": "Simone Martini, Andrea Masini, Margherita Zorzi", "title": "From 2-sequents and Linear Nested Sequents to Natural Deduction for\n  Normal Modal Logics", "comments": null, "journal-ref": null, "doi": "10.1145/3461661", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend to natural deduction the approach of Linear Nested Sequents and of\n2-sequents. Formulas are decorated with a spatial coordinate, which allows a\nformulation of formal systems in the original spirit of natural deduction --\nonly one introduction and one elimination rule per connective, no additional\n(structural) rule, no explicit reference to the accessibility relation of the\nintended Kripke models. We give systems for the normal modal logics from K to\nS4. For the intuitionistic versions of the systems, we define proof reduction,\nand prove proof normalization, thus obtaining a syntactical proof of\nconsistency. For logics K and K4 we use existence predicates (following Scott)\nfor formulating sound deduction rules.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 09:27:08 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 20:53:15 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Martini", "Simone", ""], ["Masini", "Andrea", ""], ["Zorzi", "Margherita", ""]]}, {"id": "2007.11922", "submitter": "Shaull Almagor", "authors": "Shaull Almagor", "title": "Process Symmetry in Probabilistic Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking is the process of deciding whether a system satisfies a given\nspecification. Often, when the setting comprises multiple processes, the\nspecifications are over sets of input and output signals that correspond to\nindividual processes. Then, many of the properties one wishes to specify are\nsymmetric with respect to the processes identities. In this work, we consider\nthe problem of deciding whether the given system exhibits symmetry with respect\nto the processes' identities. When the system is symmetric, this gives insight\ninto the behaviour of the system, as well as allows the designer to use only\nrepresentative specifications, instead of iterating over all possible process\nidentities.\n  Specifically, we consider probabilistic systems, and we propose several\nvariants of symmetry. We start with precise symmetry, in which, given a\npermutation $\\pi$, the system maintains the exact distribution of permuted\noutputs, given a permuted inputs. We proceed to study approximate versions of\nsymmetry, including symmetry induced by small $L_\\infty$ norm, variants of\nParikh-image based symmetry, and qualitative symmetry. For each type of\nsymmetry, we consider the problem of deciding whether a given system exhibits\nthis type of symmetry.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 10:53:24 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Almagor", "Shaull", ""]]}, {"id": "2007.12006", "submitter": "Takao Inoue", "authors": "Takao Inou\\'e", "title": "A sound interpretation of Le\\'sniewski's epsilon in modal logic KTB", "comments": "8 pages. arXiv admin note: substantial text overlap with\n  arXiv:2006.15421", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we shall show that the following translation $I^M$ from the\npropositional fragment $\\bf L_1$ of Le\\'{s}niewski's ontology to modal logic\n$\\bf KTB$ is sound: for any formula $\\phi$ and $\\psi$ of $\\bf L_1$, it is\ndefined as\n  (M1) $I^M(\\phi \\vee \\psi)$ = $I^M(\\phi) \\vee I^M(\\psi),$\n  (M2) $I^M(\\neg \\phi)$ = $\\neg I^M(\\phi),$\n  (M3) $I^M(\\epsilon ab)$ = $\\Diamond p_a \\supset p_a . \\wedge . \\Box p_a\n\\supset \\Box p_b . \\wedge . \\Diamond p_b \\supset p_a,$\n  where $p_a$ and $p_b$ are propositional variables corresponding to the name\nvariables $a$ and $b$, respectively. We shall give some comments including some\nopen problems and my conjectures.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 11:03:19 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Inou\u00e9", "Takao", ""]]}, {"id": "2007.12105", "submitter": "S{\\o}ren Eller Thomsen", "authors": "S{\\o}ren Eller Thomsen and Bas Spitters", "title": "Formalizing Nakamoto-Style Proof of Stake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-tolerant distributed systems move the trust in a single party to a\nmajority of parties participating in the protocol. This makes blockchain based\ncrypto-currencies possible: they allow parties to agree on a total order of\ntransactions without a trusted third party. To trust a distributed system, the\nsecurity of the protocol and the correctness of the implementation must be\nindisputable.\n  We present the first machine checked proof that guarantees both safety and\nliveness for a consensus algorithm. We verify a Proof of Stake (PoS)\nNakamoto-style blockchain (NSB) protocol, using the foundational proof\nassistant Coq.\n  In particular, we consider a PoS NSB in a synchronous network with a static\nset of corrupted parties. We define execution semantics for this setting and\nprove chain growth, chain quality, and common prefix which together imply both\nsafety and liveness.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 16:12:53 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 10:37:43 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thomsen", "S\u00f8ren Eller", ""], ["Spitters", "Bas", ""]]}, {"id": "2007.12247", "submitter": "Antonina Nepeivoda", "authors": "Antonina Nepeivoda", "title": "On Solving Word Equations via Program Transformation", "comments": "Another version of this work will be uploaded on arXiv by eptcs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an experiment of solving word equations via specialization\nof a configuration WE(R,E), where the program WE can be considered as an\ninterpreter testing whether a composition of substitutions R produces a\nsolution of a word equation E. Several variants of such interpreters, when\nspecialized using a basic unfold/fold strategy, are able to decide solvability\nfor a number of sets of the word equations with the overlapping variables.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 20:39:29 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 20:04:16 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 10:41:02 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nepeivoda", "Antonina", ""]]}, {"id": "2007.12372", "submitter": "Ronny Tredup", "authors": "Ronny Tredup and Evgeny Erofeev", "title": "On the Parameterized Complexity of Synthesizing Boolean Petri Nets With\n  Restricted Dependency (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of $\\tau$-synthesis consists in deciding whether a given directed\nlabeled graph $A$ is isomorphic to the reachability graph of a Boolean Petri\nnet $N$ of type $\\tau$. In case of a positive decision, $N$ should be\nconstructed. For many Boolean types of nets, the problem is NP-complete. This\npaper deals with a special variant of $\\tau$-synthesis that imposes\nrestrictions for the target net $N$: we investigate \\emph{dependency\n$d$-restricted $\\tau$-synthesis (DR$\\tau$S)} where each place of $N$ can\ninfluence and be influenced by at most $d$ transitions. For a type $\\tau$, if\n$\\tau$-synthesis is NP-complete then DR$\\tau$S is also NP-complete. In this\npaper, we show that DR$\\tau$S parameterized by $d$ is in XP. Furthermore, we\nprove that it is $W[2]$-hard, for many Boolean types that allow unconditional\ninteractions $set$ and $reset$.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 06:37:16 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Tredup", "Ronny", ""], ["Erofeev", "Evgeny", ""]]}, {"id": "2007.12404", "submitter": "Murdoch Gabbay", "authors": "Murdoch J. Gabbay", "title": "What is an EUTxO blockchain?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We condense the theory of blockchains down to a simple and compact set of\nfour type equations (Idealised EUTxO), and to an algebraic characterisation\n(abstract chunk systems), and exhibit an adjoint pair of functors between them.\nThis gives a novel account of the essential mathematical structures underlying\nblockchain technology, such as Bitcoin.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 08:20:16 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Gabbay", "Murdoch J.", ""]]}, {"id": "2007.12412", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Yan Kim, Damian Kurpiewski, Peter Y. A. Ryan", "title": "Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The design and implementation of an e-voting system is a challenging task.\nFormal analysis can be of great help here. In particular, it can lead to a\nbetter understanding of how the voting system works, and what requirements on\nthe system are relevant. In this paper, we propose that the state-of-art model\nchecker Uppaal provides a good environment for modelling and preliminary\nverification of voting protocols. To illustrate this, we present an Uppaal\nmodel of Pr\\^et \\`a Voter, together with some natural extensions. We also show\nhow to verify a variant of receipt-freeness, despite the severe limitations of\nthe property specification language in the model checker.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:05:06 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 11:28:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Kim", "Yan", ""], ["Kurpiewski", "Damian", ""], ["Ryan", "Peter Y. A.", ""]]}, {"id": "2007.12424", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Damian Kurpiewski, Vadim Malvone", "title": "Natural Strategic Abilities in Voting Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Security properties are often focused on the technological side of the\nsystem. One implicitly assumes that the users will behave in the right way to\npreserve the property at hand. In real life, this cannot be taken for granted.\nIn particular, security mechanisms that are difficult and costly to use are\noften ignored by the users, and do not really defend the system against\npossible attacks.\n  Here, we propose a graded notion of security based on the complexity of the\nuser's strategic behavior. More precisely, we suggest that the level to which a\nsecurity property $\\varphi$ is satisfied can be defined in terms of (a) the\ncomplexity of the strategy that the voter needs to execute to make $\\varphi$\ntrue, and (b) the resources that the user must employ on the way. The simpler\nand cheaper to obtain $\\varphi$, the higher the degree of security.\n  We demonstrate how the idea works in a case study based on an electronic\nvoting scenario. To this end, we model the vVote implementation of the \\Pret\nvoting protocol for coercion-resistant and voter-verifiable elections. Then, we\nidentify \"natural\" strategies for the voter to obtain receipt-freeness, and\nmeasure the voter's effort that they require. We also look at how hard it is\nfor the coercer to compromise the election through a randomization attack.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:28:07 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 11:17:29 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Kurpiewski", "Damian", ""], ["Malvone", "Vadim", ""]]}, {"id": "2007.12474", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka and Takayuki Ito", "title": "Abstract Interpretation in Formal Argumentation: with a Galois\n  Connection for Abstract Dialectical Frameworks and May-Must Argumentation\n  (First Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labelling-based formal argumentation relies on labelling functions that\ntypically assign one of 3 labels to indicate either acceptance, rejection, or\nelse undecided-to-be-either, to each argument. While a classical\nlabelling-based approach applies globally uniform conditions as to how an\nargument is to be labelled, they can be determined more locally per argument.\nAbstract dialectical frameworks (ADF) is a well-known argumentation formalism\nthat belongs to this category, offering a greater labelling flexibility. As the\nsize of an argumentation increases in the numbers of arguments and\nargument-to-argument relations, however, it becomes increasingly more costly to\ncheck whether a labelling function satisfies those local conditions or even\nwhether the conditions are as per the intention of those who had specified\nthem. Some compromise is thus required for reasoning about a larger\nargumentation. In this context, there is a more recently proposed formalism of\nmay-must argumentation (MMA) that enforces still local but more abstract\nlabelling conditions. We identify how they link to each other in this work. We\nprove that there is a Galois connection between them, in which ADF is a\nconcretisation of MMA and MMA is an abstraction of ADF. We explore the\nconsequence of abstract interpretation at play in formal argumentation,\ndemonstrating a sound reasoning about the judgement of\nacceptability/rejectability in ADF from within MMA. As far as we are aware,\nthere is seldom any work that incorporates abstract interpretation into formal\nargumentation in the literature, and, in the stated context, this work is the\nfirst to demonstrate its use and relevance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 04:26:15 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Ito", "Takayuki", ""]]}, {"id": "2007.12501", "submitter": "Bhaskar Ramasubramanian", "authors": "Bhaskar Ramasubramanian, Luyao Niu, Andrew Clark, Linda Bushnell,\n  Radha Poovendran", "title": "Secure Control in Partially Observable Environments to Satisfy LTL\n  Specifications", "comments": "Provisionally accepted to the IEEE Transactions on Automatic Control.\n  arXiv admin note: text overlap with arXiv:1903.06873", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.GT cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the synthesis of control policies for an agent that has to\nsatisfy a temporal logic specification in a partially observable environment,\nin the presence of an adversary. The interaction of the agent (defender) with\nthe adversary is modeled as a partially observable stochastic game. The goal is\nto generate a defender policy to maximize satisfaction of a given temporal\nlogic specification under any adversary policy. The search for policies is\nlimited to the space of finite state controllers, which leads to a tractable\napproach to determine policies. We relate the satisfaction of the specification\nto reaching (a subset of) recurrent states of a Markov chain. We present an\nalgorithm to determine a set of defender and adversary finite state controllers\nof fixed sizes that will satisfy the temporal logic specification, and prove\nthat it is sound. We then propose a value-iteration algorithm to maximize the\nprobability of satisfying the temporal logic specification under finite state\ncontrollers of fixed sizes. Lastly, we extend this setting to the scenario\nwhere the size of the finite state controller of the defender can be increased\nto improve the satisfaction probability. We illustrate our approach with an\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 23:52:59 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 00:10:34 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ramasubramanian", "Bhaskar", ""], ["Niu", "Luyao", ""], ["Clark", "Andrew", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "2007.12987", "submitter": "Gian Pietro Farina", "authors": "Gian Pietro Farina, Stephen Chong, Marco Gaboardi", "title": "Coupled Relational Symbolic Execution for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a de facto standard in data privacy with applications\nin the private and public sectors. Most of the techniques that achieve\ndifferential privacy are based on a judicious use of randomness. However,\nreasoning about randomized programs is difficult and error prone. For this\nreason, several techniques have been recently proposed to support designer in\nproving programs differentially private or in finding violations to it. In this\nwork we propose a technique based on symbolic execution for reasoning about\ndifferential privacy. Symbolic execution is a classic technique used for\ntesting, counterexample generation and to prove absence of bugs. Here we use\nsymbolic execution to support these tasks specifically for differential\nprivacy. To achieve this goal, we leverage two ideas that have been already\nproven useful in formal reasoning about differential privacy: relational\nreasoning and probabilistic coupling. Our technique integrates these two ideas\nand shows how such a combination can be used to both verify and find violations\nto differential privacy.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 18:08:07 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Farina", "Gian Pietro", ""], ["Chong", "Stephen", ""], ["Gaboardi", "Marco", ""]]}, {"id": "2007.13053", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller", "title": "Recursive Rules with Aggregation: A Simple Unified Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex reasoning problems are most clearly and easily specified using\nlogical rules, especially recursive rules with aggregation such as counts and\nsums for practical applications. Unfortunately, the meaning of such rules has\nbeen a significant challenge, leading to many different conflicting semantics.\n  This paper describes a unified semantics for recursive rules with\naggregation, extending the unified founded semantics and constraint semantics\nfor recursive rules with negation. The key idea is to support simple expression\nof the different assumptions underlying different semantics, and orthogonally\ninterpret aggregation operations straightforwardly using their simple usual\nmeaning.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 04:42:44 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "2007.13272", "submitter": "Bhaskar Ramasubramanian", "authors": "Bhaskar Ramasubramanian, Luyao Niu, Andrew Clark, Linda Bushnell,\n  Radha Poovendran", "title": "Privacy-Preserving Resilience of Cyber-Physical Systems to Adversaries", "comments": "Accepted to the IEEE Conference on Decision and Control (CDC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cyber-physical system (CPS) is expected to be resilient to more than one\ntype of adversary. In this paper, we consider a CPS that has to satisfy a\nlinear temporal logic (LTL) objective in the presence of two kinds of\nadversaries. The first adversary has the ability to tamper with inputs to the\nCPS to influence satisfaction of the LTL objective. The interaction of the CPS\nwith this adversary is modeled as a stochastic game. We synthesize a controller\nfor the CPS to maximize the probability of satisfying the LTL objective under\nany policy of this adversary. The second adversary is an eavesdropper who can\nobserve labeled trajectories of the CPS generated from the previous step. It\ncould then use this information to launch other kinds of attacks. A labeled\ntrajectory is a sequence of labels, where a label is associated to a state and\nis linked to the satisfaction of the LTL objective at that state. We use\ndifferential privacy to quantify the indistinguishability between states that\nare related to each other when the eavesdropper sees a labeled trajectory. Two\ntrajectories of equal length will be differentially private if they are\ndifferentially private at each state along the respective trajectories. We use\na skewed Kantorovich metric to compute distances between probability\ndistributions over states resulting from actions chosen according to policies\nfrom related states in order to quantify differential privacy. Moreover, we do\nthis in a manner that does not affect the satisfaction probability of the LTL\nobjective. We validate our approach on a simulation of a UAV that has to\nsatisfy an LTL objective in an adversarial environment.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 02:12:21 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ramasubramanian", "Bhaskar", ""], ["Niu", "Luyao", ""], ["Clark", "Andrew", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "2007.13529", "submitter": "Simon Foster", "authors": "Simon Foster, Kangfeng Ye, Ana Cavalcanti, Jim Woodcock", "title": "Automated Verification of Reactive and Concurrent Programs by\n  Calculation", "comments": "39 pages, accepted for publication in Journal of Logic and Algebraic\n  Methods in Programming (JLAMP), submitted 30/04/2019", "journal-ref": null, "doi": "10.1016/j.jlamp.2021.100681", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive programs combine traditional sequential programming constructs with\nprimitives to allow communication with other concurrent agents. They are\nubiquitous in modern applications, ranging from components systems and web\nservices, to cyber-physical systems and autonomous robots. In this paper, we\npresent an algebraic verification strategy for concurrent reactive programs,\nwith a large or infinite state space. We define novel operators to characterise\ninteractions and state updates, and an associated equational theory. With this\nwe can calculate a reactive program's denotational semantics, and thereby\nfacilitate automated proof. Of note is our reasoning support for iterative\nprograms with reactive invariants, based on Kleene algebra, and for parallel\ncomposition. We illustrate our strategy by verifying a reactive buffer. Our\nlaws and strategy are mechanised in Isabelle/UTP, our implementation of Hoare\nand He's Unifying Theories of Programming (UTP) framework, to provide soundness\nguarantees and practical verification support.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 13:07:08 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 14:18:09 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Foster", "Simon", ""], ["Ye", "Kangfeng", ""], ["Cavalcanti", "Ana", ""], ["Woodcock", "Jim", ""]]}, {"id": "2007.13685", "submitter": "Yepeng Ding", "authors": "Yepeng Ding, Hiroyuki Sato", "title": "Extending Concurrent Separation Logic to Enhance Modular Formalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, numerous services based on large-scale distributed systems have\nbeen developed to boost the convenience of human life. On the other side, it\nbecomes a significant challenge to ensure the correctness and properties of\nthese systems due to the complex and nested architecture. Although concurrent\nseparation logic (CSL) has partially tackled the problem by specifying systems\nand verifying the correctness of them, it faces modularity issues. In this\npaper, we propose an extended concurrent separation logic (ECSL) to address the\nmodularity issues of CSL with the support of the temporal extension,\ncommunication extension, environment extension, and nest extension. ECSL is\ncapable of formalizing systems at different abstraction levels from memory\nmanagement to architecture and protocol design with great modularity.\nFurthermore, we stick to unitarity and compatibility principles while\ndeveloping ECSL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 16:56:32 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ding", "Yepeng", ""], ["Sato", "Hiroyuki", ""]]}, {"id": "2007.14155", "submitter": "Dominique Unruh", "authors": "Dominique Unruh", "title": "Local Variables and Quantum Relational Hoare Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We add local variables to quantum relational Hoare logic (Unruh, POPL 2019).\nWe derive reasoning rules for supporting local variables (including an improved\n\"adversary rule\"). We extended the qrhl-tool for computer-aided verification of\nqRHL to support local variables and our new reasoning rules.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 12:20:56 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Unruh", "Dominique", ""]]}, {"id": "2007.14259", "submitter": "Amir Kafshdar Goharshady", "authors": "Ali Asadi and Krishnendu Chatterjee and Hongfei Fu and Amir Kafshdar\n  Goharshady and Mohammad Mahdavi", "title": "Inductive Reachability Witnesses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the fundamental problem of reachability analysis\nover imperative programs with real variables. The reachability property\nrequires that a program can reach certain target states during its execution.\nPrevious works that tackle reachability analysis are either unable to handle\nprograms consisting of general loops (e.g. symbolic execution), or lack\ncompleteness guarantees (e.g. abstract interpretation), or are not automated\n(e.g. incorrectness logic/reverse Hoare logic). In contrast, we propose a novel\napproach for reachability analysis that can handle general programs, is\n(semi-)complete, and can be entirely automated for a wide family of programs.\nOur approach extends techniques from both invariant generation and\nranking-function synthesis to reachability analysis through the notion of\n(Universal) Inductive Reachability Witnesses (IRWs/UIRWs). While traditional\ninvariant generation uses over-approximations of reachable states, we consider\nthe natural dual problem of under-approximating the set of program states that\ncan reach a target state. We then apply an argument similar to ranking\nfunctions to ensure that all states in our under-approximation can indeed reach\nthe target set in finitely many steps.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 14:18:37 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Asadi", "Ali", ""], ["Chatterjee", "Krishnendu", ""], ["Fu", "Hongfei", ""], ["Goharshady", "Amir Kafshdar", ""], ["Mahdavi", "Mohammad", ""]]}, {"id": "2007.14801", "submitter": "Oleg Kudinov", "authors": "M.V. Korovina and O.V. Kudinov", "title": "On the computability of ordered fields", "comments": "18 pages, proofs corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop general techniques for classes of computable real\nnumbers generated by subsets of total computable (recursive functions) with\nspecial restrictions on basic operations in order to investigate the following\nproblems: whether a generated class is a real closed field and whether there\nexists a computable presentation of a generated class. We prove a series of\ntheorems that lead to the result that there are no computable presentations\nneither for polynomial time computable no even for $E_n$-computable real\nnumbers, where $E_n$ is a level in Grzegorczyk hierarchy, $n \\geq 2$. We also\npropose a criterion of computable presentability of an archimedean ordered\nfield.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 12:45:48 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 16:02:21 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 13:57:12 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Korovina", "M. V.", ""], ["Kudinov", "O. V.", ""]]}, {"id": "2007.14960", "submitter": "Alireza Partovi", "authors": "Alireza Partovi, Taeho Jung, Lin Hai", "title": "Opacity of Discrete Event Systems with Active Intruder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opacity is a security property formalizing the information leakage of a\nsystem to an external observer, namely intruder. The conventional opacity that\nhas been studied in the Discrete Event System (DES) literature usually assumes\npassive intruders, who only observe the behavior of the system. However, in\nmany cybersecurity concerns, such as web service, active intruders, who are\ncapable of influencing the system's behavior beyond passive observations, need\nto be considered and defended against. We are therefore motivated to extend the\nopacity notions to handle active intruders. For this, we model the system as a\nnon-deterministic finite-state transducer. It is assumed that the intruder has\na full knowledge of the system structure and is capable of interacting with the\nsystem by injecting different inputs and observing its responses. In this\nsetup, we first introduce reactive current-state opacity (RCSO) notion\ncharacterizing a property that the system does not leak its secret state\nregardless of how the intruder manipulates the system behavior. We furthermore\nextend this notion to language-based and initial-state reactive opacity\nnotions, and study the relationship among them. It turns out that all the\nproposed reactive opacity notions are equivalent to RCSO. We therefore focus on\nRCSO and study its verification problem. It is shown that the RCSO can be\nverified by constructing an observer automaton.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 20:27:26 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Partovi", "Alireza", ""], ["Jung", "Taeho", ""], ["Hai", "Lin", ""]]}, {"id": "2007.15082", "submitter": "Daniel O. Martinez-Rivillas", "authors": "Daniel O. Mart\\'inez-Rivillas and Ruy J.G.B. de Queiroz", "title": "Towards a Homotopy Domain Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An appropriate framework is put forward for the construction of\n$\\lambda$-models with $\\infty$-groupoid structure, which we call\n\\textit{homotopic $\\lambda$-models} through the use of an $\\infty$-category\nwith cartesian closure and enough points. With this, we establish the start of\na project of generalization of Domain Theory and $\\lambda$-calculus, in the\nsense that the concept of proof (path) of equality of $\\lambda$-terms is raised\nto \\textit{higher proof} (homotopy).\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 19:59:22 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 12:27:45 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 20:53:38 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 17:15:34 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 10:50:02 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Mart\u00ednez-Rivillas", "Daniel O.", ""], ["de Queiroz", "Ruy J. G. B.", ""]]}, {"id": "2007.15140", "submitter": "Alexey Ignatiev", "authors": "Jinqiang Yu, Alexey Ignatiev, Peter J. Stuckey, Pierre Le Bodic", "title": "Computing Optimal Decision Sets with SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to help make decisions, there is a\ndemand for these decisions to be explainable. Arguably, the most explainable\nmachine learning models use decision rules. This paper focuses on decision\nsets, a type of model with unordered rules, which explains each prediction with\na single rule. In order to be easy for humans to understand, these rules must\nbe concise. Earlier work on generating optimal decision sets first minimizes\nthe number of rules, and then minimizes the number of literals, but the\nresulting rules can often be very large. Here we consider a better measure,\nnamely the total size of the decision set in terms of literals. So we are not\ndriven to a small set of rules which require a large number of literals. We\nprovide the first approach to determine minimum-size decision sets that achieve\nminimum empirical risk and then investigate sparse alternatives where we trade\naccuracy for size. By finding optimal solutions we show we can build decision\nset classifiers that are almost as accurate as the best heuristic methods, but\nfar more concise, and hence more explainable.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:35:22 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Yu", "Jinqiang", ""], ["Ignatiev", "Alexey", ""], ["Stuckey", "Peter J.", ""], ["Bodic", "Pierre Le", ""]]}, {"id": "2007.15246", "submitter": "Carroll Morgan", "authors": "Annabelle McIver, Carroll Morgan", "title": "Correctness by construction for probabilistic programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"correct by construction\" paradigm is an important component of modern\nFormal Methods, and here we use the probabilistic Guarded-Command Language\n$\\mathit{pGCL}$ to illustrate its application to $\\mathit{probabilistic}$\nprogramming. $\\mathit{pGCL}$ extends Dijkstra's guarded-command language\n$\\mathit{GCL}$ with probabilistic choice, and is equipped with a\ncorrectness-preserving refinement relation $(\\sqsubseteq)$ that enables\ncompact, abstract specifications of probabilistic properties to be transformed\ngradually to concrete, executable code by applying mathematical insights in a\nsystematic and layered way. Characteristically for \"correctness by\nconstruction\", as far as possible the reasoning in each refinement-step layer\ndoes not depend on earlier layers, and does not affect later ones. We\ndemonstrate the technique by deriving a fair-coin implementation of any given\ndiscrete probability distribution. In the special case of simulating a fair\ndie, our correct-by-construction algorithm turns out to be \"within spitting\ndistance\" of Knuth and Yao's optimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 05:54:09 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["McIver", "Annabelle", ""], ["Morgan", "Carroll", ""]]}, {"id": "2007.15415", "submitter": "Luca Reggio", "authors": "Mai Gehrke, Tomas Jakl, Luca Reggio", "title": "A Cook's tour of duality in logic: from quantifiers, through Vietoris,\n  to measures", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and highlight certain landmark results in Samson Abramsky's work\nwhich we believe are fundamental to current developments and future trends. In\nparticular, we focus on the use of (i) topological duality methods to solve\nproblems in logic and computer science; (ii) category theory and, more\nparticularly, free (and co-free) constructions; (iii) these tools to unify the\n`power' and `structure' strands in computer science.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 12:22:10 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Gehrke", "Mai", ""], ["Jakl", "Tomas", ""], ["Reggio", "Luca", ""]]}, {"id": "2007.15458", "submitter": "Bastien Maubert", "authors": "Bastien Maubert, Aniello Murano, Olivier Serre", "title": "Reasoning about strategies on collapsible pushdown arenas with imperfect\n  information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategy Logic with imperfect information (SLiR) is a very expressive logic\ndesigned to express complex properties of strategic abilities in distributed\nsystems. Previous work on SLiR focused on finite systems, and showed that the\nmodel-checking problem is decidable when information on the control states of\nthe system is hierarchical among the players or components of the system,\nmeaning that the players or components can be totally ordered according to\ntheir respective knowledge of the state. We show that moving from finite to\ninfinite systems generated by collapsible (higher-order) pushdown systems\npreserves decidability, under the natural restriction that the stack content is\nvisible. The proof follows the same lines as in the case of finite systems, but\nrequires to use (collapsible) alternating pushdown tree automata. Such automata\nare undecidable, but semi-alternating pushdown tree automata were introduced\nand proved decidable, to study a strategic problem on pushdown systems with two\nplayers. In order to tackle multiple players with hierarchical information, we\nrefine further these automata: we define direction-guided (collapsible)\npushdown tree automata, and show that they are stable under projection,\nnondeterminisation and narrowing. For the latter operation, used to deal with\nimperfect information, stability holds under some assumption that is satisfied\nwhen used for systems with visible stack. We then use these automata to prove\nour main result.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 13:51:24 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Serre", "Olivier", ""]]}, {"id": "2007.15478", "submitter": "Anthony Widjaja Lin", "authors": "Anthony W. Lin and Rupak Majumdar", "title": "Quadratic Word Equations with Length Constraints, Counter Systems, and\n  Presburger Arithmetic with Divisibility", "comments": "19 pages, 3 figures, journal submission of ATVA'18 paper\n  [arXiv:1805.06701]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word equations are a crucial element in the theoretical foundation of\nconstraint solving over strings. A word equation relates two words over string\nvariables and constants. Its solution amounts to a function mapping variables\nto constant strings that equate the left and right hand sides of the equation.\nWhile the problem of solving word equations is decidable, the decidability of\nthe problem of solving a word equation with a length constraint (i.e., a\nconstraint relating the lengths of words in the word equation) has remained a\nlong-standing open problem. We focus on the subclass of quadratic word\nequations, i.e., in which each variable occurs at most twice. We first show\nthat the length abstractions of solutions to quadratic word equations are in\ngeneral not Presburger-definable. We then describe a class of counter systems\nwith Presburger transition relations which capture the length abstraction of a\nquadratic word equation with regular constraints. We provide an encoding of the\neffect of a simple loop of the counter systems in the existential theory of\nPresburger Arithmetic with divisibility (PAD). Since PAD is decidable (NP-hard\nand is in NEXP), we obtain a decision procedure for quadratic words equations\nwith length constraints for which the associated counter system is flat (i.e.,\nall nodes belong to at most one cycle). In particular, we show a decidability\nresult (in fact, also an NP algorithm with a PAD oracle) for a recently\nproposed NP-complete fragment of word equations called regular-oriented word\nequations, when augmented with length constraints. We extend this decidability\nresult (in fact, with a complexity upper bound of PSPACE with a PAD oracle) in\nthe presence of regular constraints.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 14:18:25 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 22:42:24 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 13:30:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lin", "Anthony W.", ""], ["Majumdar", "Rupak", ""]]}, {"id": "2007.15617", "submitter": "Tobias Reinhard", "authors": "Tobias Reinhard", "title": "A Core Calculus for Static Latency Tracking with Placement Types", "comments": "3 pages, 0 figures, accepted at Student Research Competition @ POPL\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient geo-distributed applications is challenging as\nprogrammers can easily introduce computations that entail high latency\ncommunication. We propose a language design which makes latency explicit and\nextracts type-level bounds for a computation's runtime latency. We present our\ninitial steps with a core calculus that enables extracting provably correct\nlatency bounds and outline future work.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 17:31:31 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Reinhard", "Tobias", ""]]}, {"id": "2007.15697", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Logic of fusion", "comments": "17 pages, 6 diagrams; Andre Scedrov FestSchrift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The starting point of this work is the observation that the Curry-Howard\nisomorphism, relating types and propositions, programs and proofs, composition\nand cut, extends to the correspondence of program fusion and cut elimination.\nThis simple idea suggests logical interpretations of some of the basic methods\nof generic and transformational programming. In the present paper, we provide a\nlogical analysis of the general form of build fusion, also known as\ndeforestation, over the inductive and the coinductive datatypes, regular or\nnested. The analysis is based on a novel logical interpretation of\nparametricity in terms of the paranatural transformations, introduced in the\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 19:18:23 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "2007.16077", "submitter": "Thomas Seiller", "authors": "Boris Eng (LIPN), Thomas Seiller (CNRS, LIPN)", "title": "Stellar Resolution: Multiplicatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new asynchronous model of computation named Stellar Resolution\nbased on first-order unification. This model of computation is obtained as a\nformalisation of Girard's transcendental syntax programme, sketched in a series\nof three articles. As such, it is the first step towards a proper formal\ntreatment of Girard's proposal to tackle first-order logic in a\nproofs-as-program approach. After establishing formal definitions and basic\nproperties of stellar resolution, we explain how it generalises traditional\nmodels of computation, such as logic programming and combinatorial models such\nas Wang tilings. We then explain how it can represent multiplicative\nproof-structures, their cut-elimination and the correctness criterion of Danos\nand Regnier. Further use of realisability techniques lead to dynamic semantics\nfor Multiplicative Linear Logic, following previous Geometry of Interaction\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 13:47:14 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Eng", "Boris", "", "LIPN"], ["Seiller", "Thomas", "", "CNRS, LIPN"]]}, {"id": "2007.16161", "submitter": "Ralph Matthes", "authors": "Jos\\'e Esp\\'irito Santo and Ralph Matthes and Lu\\'is Pinto", "title": "Coinductive proof search for polarized logic with applications to full\n  intuitionistic propositional logic", "comments": "22 pages incl. appendices; we now stress the dependence of the\n  results on specific proof systems (seen in the abstract, hence the change of\n  title). LJT now comes at the end of the main text. Thm 8 (was Thm 14)\n  evolved, and we abandon modifications in the vector of declarations in two\n  clauses for finitary representation. There is new material on type finiteness\n  in LJP (developed in the appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The approach to proof search dubbed \"coinductive proof search\", and\npreviously developed by the authors for implicational intuitionistic logic, is\nin this paper extended to LJP, a focused sequent-calculus presentation of\npolarized intuitionistic logic, including an array of positive and negative\nconnectives. As before, this includes developing a coinductive description of\nthe search space generated by a sequent, an equivalent inductive syntax\ndescribing the same space, and decision procedures for inhabitation problems in\nthe form of predicates defined by recursion on the inductive syntax. We prove\nthe decidability of existence of focused inhabitants, and of finiteness of the\nnumber of focused inhabitants for polarized intuitionistic logic, by means of\nsuch recursive procedures. Moreover, the polarized logic can be used as a\nplatform from which proof search for other logics is understood. We illustrate\nthe technique with LJT, a focused sequent calculus for full intuitionistic\npropositional logic (including disjunction). For that, we have to work out the\n\"negative translation\" of LJT into LJP (that sees all intuitionistic types as\nnegative types), and verify that the translation gives a faithful\nrepresentation of proof search in LJT as proof search in the polarized logic.\nWe therefore inherit decidability of both problems studied for LJP and thus get\nnew proofs of these results for LJT.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:30:54 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 18:35:52 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Santo", "Jos\u00e9 Esp\u00edrito", ""], ["Matthes", "Ralph", ""], ["Pinto", "Lu\u00eds", ""]]}, {"id": "2007.16171", "submitter": "Germ\\'an Vidal", "authors": "Germ\\'an Vidal", "title": "Reversible Debugging in Logic Programming", "comments": "15 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible debugging is becoming increasingly popular for locating the source\nof errors. This technique proposes a more natural approach to debugging, where\none can explore a computation from the observable misbehaviour backwards to the\nsource of the error. In this work, we propose a reversible debugging scheme for\nlogic programs. For this purpose, we define an appropriate instrumented\nsemantics (a so-called Landauer embedding) that makes SLD resolution\nreversible. An implementation of a reversible debugger for Prolog, rever, has\nbeen developed and is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:47:05 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Vidal", "Germ\u00e1n", ""]]}]