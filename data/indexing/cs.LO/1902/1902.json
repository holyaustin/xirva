[{"id": "1902.00133", "submitter": "Benjam\\'in Bedregal Prof.", "authors": "Rui Paiva, Eduardo Palmeira, Regivan Santiago, Benjamin Bedregal", "title": "Lattice-valued Overlap and Quasi-Overlap Functions", "comments": "35 pages, paper submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlap functions were introduced as class of bivariate aggregation functions\non [0, 1] to be applied in image processing. This paper has as main objective\nto present appropriates definitions of overlap functions considering the scope\nof lattices and introduced a more general definition, called of quasi-overlaps,\nwhich arise of abolishes the continuity condition. In addition, are\ninvestigated the main properties of (quasi-)overlaps on bounded lattices,\nnamely, convex sum, migrativity, homogeneity, idempotency and cancellation law.\nMoreover, we make a characterization of Archimedian overlaps.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 23:44:02 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Paiva", "Rui", ""], ["Palmeira", "Eduardo", ""], ["Santiago", "Regivan", ""], ["Bedregal", "Benjamin", ""]]}, {"id": "1902.00196", "submitter": "L\\^e Th\\`anh D\\~ung Nguy\\^en", "authors": "L\\^e Th\\`anh D\\~ung Nguy\\^en", "title": "Around finite second-order coherence spaces", "comments": "The v1 of this is being split into multiple smaller papers. A\n  forthcoming paper with Pistone, Seiller and Tortora de Falco will cover the\n  syntactic aspects not included in the present v3. Changes from v2: add\n  hypercoherences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications of denotational semantics, such as higher-order model\nchecking or the complexity of normalization, rely on finite semantics for\nmonomorphic type systems. We exhibit such a finite semantics for a polymorphic\npurely linear language: more precisely, we show that in Girard's semantics of\nsecond-order linear logic using coherence spaces and normal functors, the\ndenotations of multiplicative-additive formulas are finite.\n  This model is also effective, in the sense that the denotations of formulas\nand proofs are computable, as we show. We also establish analogous results for\na second-order extension of Ehrhard's hypercoherences; while finiteness holds\nfor the same reason as in coherence spaces, effectivity presents additional\ndifficulties.\n  Finally, we discuss the applications our our work to implicit computational\ncomplexity in linear (or affine) logic. In view of these applications, we study\ncardinality and complexity bounds in our finite semantics.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 06:18:14 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:55:10 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 05:13:20 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Nguy\u00ean", "L\u00ea Th\u00e0nh D\u0169ng", ""]]}, {"id": "1902.00246", "submitter": "Fabian M\\\"uller", "authors": "Anselm Haak, Juha Kontinen, Fabian M\\\"uller, Heribert Vollmer, Fan\n  Yang", "title": "Counting of Teams in First-Order Team Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study descriptive complexity of counting complexity classes in the range\nfrom #P to #$\\cdot$NP. A corollary of Fagin's characterization of NP by\nexistential second-order logic is that #P can be logically described as the\nclass of functions counting satisfying assignments to free relation variables\nin first-order formulae. In this paper we extend this study to classes beyond\n#P and extensions of first-order logic with team semantics. These team-based\nlogics are closely related to existential second-order logic and its fragments,\nhence our results also shed light on the complexity of counting for extensions\nof FO in Tarski's semantics. Our results show that the class #$\\cdot$NP can be\nlogically characterized by independence logic and existential second-order\nlogic, whereas dependence logic and inclusion logic give rise to subclasses of\n#$\\cdot$NP and #P , respectively. Our main technical result shows that the\nproblem of counting satisfying assignments for monotone Boolean\n$\\Sigma_1$-formulae is #$\\cdot$NP-complete as well as complete for the function\nclass generated by dependence logic.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:34:22 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 05:53:14 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 06:19:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Haak", "Anselm", ""], ["Kontinen", "Juha", ""], ["M\u00fcller", "Fabian", ""], ["Vollmer", "Heribert", ""], ["Yang", "Fan", ""]]}, {"id": "1902.00297", "submitter": "Andras Kovacs", "authors": "Ambrus Kaposi, Andr\\'as Kov\\'acs", "title": "Signatures and Induction Principles for Higher Inductive-Inductive Types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  13, 2020) lmcs:6100", "doi": "10.23638/LMCS-16(1:10)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Higher inductive-inductive types (HIITs) generalize inductive types of\ndependent type theories in two ways. On the one hand they allow the\nsimultaneous definition of multiple sorts that can be indexed over each other.\nOn the other hand they support equality constructors, thus generalizing higher\ninductive types of homotopy type theory. Examples that make use of both\nfeatures are the Cauchy real numbers and the well-typed syntax of type theory\nwhere conversion rules are given as equality constructors. In this paper we\npropose a general definition of HIITs using a small type theory, named the\ntheory of signatures. A context in this theory encodes a HIIT by listing the\nconstructors. We also compute notions of induction and recursion for HIITs, by\nusing variants of syntactic logical relation translations. Building full\ncategorical semantics and constructing initial algebras is left for future\nwork. The theory of HIIT signatures was formalised in Agda together with the\nsyntactic translations. We also provide a Haskell implementation, which takes\nsignatures as input and outputs translation results as valid Agda code.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 12:14:28 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 08:40:28 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 16:35:20 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 16:16:36 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 17:28:26 GMT"}, {"version": "v6", "created": "Mon, 10 Feb 2020 12:45:27 GMT"}, {"version": "v7", "created": "Wed, 12 Feb 2020 13:24:33 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kaposi", "Ambrus", ""], ["Kov\u00e1cs", "Andr\u00e1s", ""]]}, {"id": "1902.00325", "submitter": "Dominique Unruh", "authors": "Dominique Unruh", "title": "Quantum Hoare Logic with Ghost Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum Hoare logic allows us to reason about quantum programs. We present an\nextension of quantum Hoare logic that introduces \"ghost variables\" to extend\nthe expressive power of pre-/postconditions. Ghost variables are variables that\ndo not actually occur in the program and are allowed to have arbitrary quantum\nstates (in a sense, they are existentially quantified), and be entangled with\nprogram variables. Ghost variables allow us to express properties such as the\ndistribution of a program variable or the fact that a variable has classical\ncontent. And as a case study, we show how quantum Hoare logic with ghost\nvariables can be used to prove the security of the quantum one-time pad.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 13:47:09 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Unruh", "Dominique", ""]]}, {"id": "1902.00343", "submitter": "Sean Tull", "authors": "Sean Tull", "title": "Categorical Operational Physics", "comments": "DPhil Thesis, University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many insights into the quantum world can be found by studying it from amongst\nmore general operational theories of physics. In this thesis, we develop an\napproach to the study of such theories purely in terms of the behaviour of\ntheir processes, as described mathematically through the language of category\ntheory. This extends a framework for quantum processes known as categorical\nquantum mechanics (CQM) due to Abramsky and Coecke.\n  We first consider categorical frameworks for operational theories. We\nintroduce a notion of such theory, based on those of Chiribella, D'Ariano and\nPerinotti (CDP), but more general than the probabilistic ones typically\nconsidered. We establish a correspondence between these and what we call\n\"operational categories\", using features introduced by Jacobs et al. in\neffectus theory, an area of categorical logic to which we provide an\noperational interpretation. We then see how to pass to a broader category of\n\"super-causal\" processes, allowing for the powerful diagrammatic features of\nCQM.\n  Next we study operational theories themselves. We survey numerous principles\nthat a theory may satisfy, treating them in a basic diagrammatic setting, and\nrelating notions from probabilistic theories, CQM and effectus theory. We\nprovide a new description of superpositions in the category of pure quantum\nprocesses, using this to give an abstract construction of the category of\nHilbert spaces and linear maps.\n  Finally, we reconstruct finite-dimensional quantum theory itself. More\nbroadly, we give a recipe for recovering a class of generalised quantum\ntheories, before instantiating it with operational principles inspired by an\nearlier reconstruction due to CDP. This reconstruction is fully categorical,\nnot requiring the usual technical assumptions of probabilistic theories.\nSpecialising to such theories recovers both standard quantum theory and that\nover real Hilbert spaces.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:15:38 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Tull", "Sean", ""]]}, {"id": "1902.00435", "submitter": "Antonis Achilleos", "authors": "Luca Aceto, Antonis Achilleos, Adrian Francalanza, Anna\n  Ing\\'olfsd\\'ottir, Karoliina Lehtinen", "title": "Adventures in Monitorability: From Branching to Linear Time and Back\n  Again", "comments": "Published in POPL 2019. 54 pages, including the appendix", "journal-ref": "Proc. ACM Program. Lang. 3, POPL, Article 52 (January 2019), 29\n  pages", "doi": "10.1145/3290365", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a comprehensive theory of runtime monitorability for\nHennessy-Milner logic with recursion, a very expressive variant of the modal\n$\\mu$-calculus. It investigates the monitorability of that logic with a\nlinear-time semantics and then compares the obtained results with ones that\nwere previously presented in the literature for a branching-time setting. Our\nwork establishes an expressiveness hierarchy of monitorable fragments of\nHennessy-Milner logic with recursion in a linear-time setting and exactly\nidentifies what kinds of guarantees can be given using runtime monitors for\neach fragment in the hierarchy. Each fragment is shown to be complete, in the\nsense that it can express all properties that can be monitored under the\ncorresponding guarantees. The study is carried out using a principled approach\nto monitoring that connects the semantics of the logic and the operational\nsemantics of monitors. The proposed framework supports the automatic,\ncompositional synthesis of correct monitors from monitorable properties.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 16:16:20 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Aceto", "Luca", ""], ["Achilleos", "Antonis", ""], ["Francalanza", "Adrian", ""], ["Ing\u00f3lfsd\u00f3ttir", "Anna", ""], ["Lehtinen", "Karoliina", ""]]}, {"id": "1902.00818", "submitter": "John Hester", "authors": "John Hester", "title": "Automated ZFC Theorem Proving with E", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce an approach for automated reasoning in first order set theories\nthat are not finitely axiomatizable, such as $ZFC$, and describe its\nimplementation alongside the automated theorem proving software E. I then\ncompare the results of proof search in the class based set theory $NBG$ with\nthose of $ZFC$.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 00:02:00 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Hester", "John", ""]]}, {"id": "1902.01164", "submitter": "Mario Benevides", "authors": "Mario Roberto Folhadela Benevides and Isaque Macalam Saab Lima", "title": "Dynamic Epistemic Logic with Communication Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a Dynamic Epistemic Logic with Communication Actions that\ncan be performed concurrently. Unlike Concurrent Epistemic Action Logic\nintroduced by Ditmarsch, Hoek and Kooi, where the concurrency mechanism is the\nso called true concurrency, here we use an approach based on process calculus,\nlike CCS and CSP, and Action Models Logic. Our approach makes possible the\nproof of soundness, completeness and decidability, different from the others\napproaches. We present an axiomatization and show that the proof of soundness,\ncompleteness and decidability can be done using a reduction method.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 13:20:20 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Benevides", "Mario Roberto Folhadela", ""], ["Lima", "Isaque Macalam Saab", ""]]}, {"id": "1902.01353", "submitter": "Dimitrios Kouzapas", "authors": "Dimitrios Kouzapas and Ramunas Forsberg Gutkovas and A. Laura Voinea\n  and Simon J. Gay", "title": "A Session Type System for Asynchronous Unreliable Broadcast\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types are formal specifications of communication protocols, allowing\nprotocol implementations to be verified by typechecking. Up to now, session\ntype disciplines have assumed that the communication medium is reliable, with\nno loss of messages. However, unreliable broadcast communication is common in a\nwide class of distributed systems such as ad-hoc and wireless sensor networks.\nOften such systems have structured communication patterns that should be\namenable to analysis by means of session types, but the necessary theory has\nnot previously been developed. We introduce the Unreliable Broadcast Session\nCalculus, a process calculus with unreliable broadcast communication, and equip\nit with a session type system that we show is sound. We capture two common\noperations, broadcast and gather, inhabiting dual session types. Message loss\nmay lead to non-synchronised session endpoints. To further account for\nunreliability we provide with an autonomous recovery mechanism that does not\nrequire acknowledgements from session participants. Our type system ensures\nsoundness, safety, and progress between the synchronised endpoints within a\nsession. We demonstrate the expressiveness of our framework by implementing\nPaxos, the textbook protocol for reaching consensus in an unreliable,\nasynchronous network.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:17:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Kouzapas", "Dimitrios", ""], ["Gutkovas", "Ramunas Forsberg", ""], ["Voinea", "A. Laura", ""], ["Gay", "Simon J.", ""]]}, {"id": "1902.01494", "submitter": "Eshan Singh", "authors": "Eshan Singh, Keerthikumara Devarajegowda, Sebastian Simon, Ralf\n  Schnieder, Karthik Ganesan, Mohammad R. Fadiheh, Dominik Stoffel, Wolfgang\n  Kunz, Clark Barrett, Wolfgang Ecker and Subhasish Mitra", "title": "Symbolic QED Pre-silicon Verification for Automotive Microcontroller\n  Cores: Industrial Case Study", "comments": null, "journal-ref": null, "doi": "10.23919/DATE.2019.8715271", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an industrial case study that demonstrates the practicality and\neffectiveness of Symbolic Quick Error Detection (Symbolic QED) in detecting\nlogic design flaws (logic bugs) during pre-silicon verification. Our study\nfocuses on several microcontroller core designs (~1,800 flip-flops, ~70,000\nlogic gates) that have been extensively verified using an industrial\nverification flow and used for various commercial automotive products. The\nresults of our study are as follows: 1. Symbolic QED detected all logic bugs in\nthe designs that were detected by the industrial verification flow (which\nincludes various flavors of simulation-based verification and formal\nverification). 2. Symbolic QED detected additional logic bugs that were not\nrecorded as detected by the industrial verification flow. (These additional\nbugs were also perhaps detected by the industrial verification flow.) 3.\nSymbolic QED enables significant design productivity improvements: (a) 8X\nimproved (i.e., reduced) verification effort for a new design (8 person-weeks\nfor Symbolic QED vs. 17 person-months using the industrial verification flow).\n(b) 60X improved verification effort for subsequent designs (2 person-days for\nSymbolic QED vs. 4-7 person-months using the industrial verification flow). (c)\nQuick bug detection (runtime of 20 seconds or less), together with short\ncounterexamples (10 or fewer instructions) for quick debug, using Symbolic QED.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 23:16:53 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Singh", "Eshan", ""], ["Devarajegowda", "Keerthikumara", ""], ["Simon", "Sebastian", ""], ["Schnieder", "Ralf", ""], ["Ganesan", "Karthik", ""], ["Fadiheh", "Mohammad R.", ""], ["Stoffel", "Dominik", ""], ["Kunz", "Wolfgang", ""], ["Barrett", "Clark", ""], ["Ecker", "Wolfgang", ""], ["Mitra", "Subhasish", ""]]}, {"id": "1902.01510", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez, Ian Mackie", "title": "Proceedings Tenth International Workshop on Computing with Terms and\n  Graphs", "comments": null, "journal-ref": "EPTCS 288, 2019", "doi": "10.4204/EPTCS.288", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of the papers presented at TERMGRAPH 2018,\nthe tenth edition of the international workshop on computing with terms and\ngraphs. Graphs, and graph transformation systems, are used in many areas within\nComputer Science: to represent data structures and algorithms, to define\ncomputation models, as a general modelling tool to study complex systems, etc.\nResearch in this area addresses a range of theoretical and practical issues,\nincluding the modelling of first- and higher-order term rewriting by (acyclic\nor cyclic) graph rewriting, graphical frameworks such as interaction nets and\nsharing graphs (optimal reduction), rewrite calculi for the analysis of\nfunctional programs, graph reduction implementations of programming languages,\ngraphical calculi modelling concurrent and mobile computations, object-oriented\nsystems, graphs as a model of biological or chemical systems, and automated\nreasoning and symbolic computation systems working on shared structures.\nPrevious editions of TERMGRAPH took place in Barcelona (2002), Rome (2004),\nVienna (2006), Braga (2007), York (2009), Saarbrucken (2011), Rome (2013),\nVienna (2014) and Eindhoven (2016). TERMGRAPH 2018 is affiliated with FSCD,\nwhich is part of FLOC.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 01:17:47 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Fern\u00e1ndez", "Maribel", ""], ["Mackie", "Ian", ""]]}, {"id": "1902.02010", "submitter": "EPTCS", "authors": "Clemens Grabmayer (Gran Sasso Science Institute)", "title": "Modeling Terms by Graphs with Structure Constraints (Two Illustrations)", "comments": "In Proceedings TERMGRAPH 2018, arXiv:1902.01510", "journal-ref": "EPTCS 288, 2019, pp. 1-13", "doi": "10.4204/EPTCS.288.1", "report-no": null, "categories": "cs.LO cs.DM cs.FL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the talk at the workshop my aim was to demonstrate the usefulness of graph\ntechniques for tackling problems that have been studied predominantly as\nproblems on the term level: increasing sharing in functional programs, and\naddressing questions about Milner's process semantics for regular expressions.\nFor both situations an approach that is based on modeling terms by graphs with\nstructure constraints has turned out to be fruitful. In this extended abstract\nI describe the underlying problems, give references, provide examples, indicate\nthe chosen approaches, and compare the initial situations as well as the\nresults that have been obtained, and some results that are being developed at\npresent.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 03:22:34 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Grabmayer", "Clemens", "", "Gran Sasso Science Institute"]]}, {"id": "1902.02011", "submitter": "EPTCS", "authors": "Wolfram Kahl (McMaster University), Yuhang Zhao (McMaster University)", "title": "Semantics-Preserving DPO-Based Term Graph Rewriting", "comments": "In Proceedings TERMGRAPH 2018, arXiv:1902.01510", "journal-ref": "EPTCS 288, 2019, pp. 26-37", "doi": "10.4204/EPTCS.288.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Term graph rewriting is important as \"conceptual implementation\" of the\nexecution of functional programs, and of data-flow optimisations in compilers.\nOne way to define term graph transformation rule application is via the\nwell-established and intuitively accessible double-pushout (DPO) approach; we\npresent a new result proving semantics preservation for such DPO-based term\ngraph rewriting.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 03:23:16 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Kahl", "Wolfram", "", "McMaster University"], ["Zhao", "Yuhang", "", "McMaster University"]]}, {"id": "1902.02012", "submitter": "EPTCS", "authors": "Mitsuhiro Okada (Keio University), Yuta Takahashi (Nagoya University)", "title": "On Quasi Ordinal Diagram Systems", "comments": "In Proceedings TERMGRAPH 2018, arXiv:1902.01510", "journal-ref": "EPTCS 288, 2019, pp. 38-49", "doi": "10.4204/EPTCS.288.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purposes of this note are the following two; we first generalize\nOkada-Takeuti's well quasi ordinal diagram theory, utilizing the recent result\nof Dershowitz-Tzameret's version of tree embedding theorem with gap conditions.\nSecond, we discuss possible use of such strong ordinal notation systems for the\npurpose of a typical traditional termination proof method for term rewriting\nsystems, especially for second-order (pattern-matching-based) rewriting systems\nincluding a rewrite-theoretic version of Buchholz's hydra game.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 03:23:34 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Okada", "Mitsuhiro", "", "Keio University"], ["Takahashi", "Yuta", "", "Nagoya University"]]}, {"id": "1902.02333", "submitter": "Kamellia Reshadi", "authors": "Kamellia Reshadi", "title": "Unary Patterns of Size Four with Morphic Permutations", "comments": "Accepted in the Student Research Forum (SRF) of SOFSEM 2019\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the avoidability of unary patterns of size of four with\nmorphic permutations. More precisely, we show that, for the positive integers\n$i,j,k$, the sizes of the alphabets over which a pattern $x \\pi ^ {i} (x)\n\\pi^{j}(x) \\pi^{k}(x)$ is avoidable are an interval of the integers (where $x$\nis a word variable and $\\pi$ is a function variable with values in the set of\nall morphic permutations of the respective alphabets). We also show how to\ncompute a good approximation of this interval. This continues the work of\n[Manea et al., 2015], where a complete characterisation of the avoidability of\ncubic patterns with permutations was given.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 15:05:29 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Reshadi", "Kamellia", ""]]}, {"id": "1902.02601", "submitter": "Tomasz Brengos", "authors": "Tomasz Brengos", "title": "A coalgebraic take on regular and $\\omega$-regular behaviours", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general coalgebraic setting in which we define finite and\ninfinite behaviour with B\\\"uchi acceptance condition for systems whose type is\na monad. The first part of the paper is devoted to presenting a construction of\na monad suitable for modelling (in)finite behaviour. The second part of the\npaper focuses on presenting the concepts of a (coalgebraic) automaton and its\n($\\omega$-) behaviour. We end the paper with coalgebraic Kleene-type theorems\nfor ($\\omega$-) regular input. The framework is instantiated on\nnon-deterministic (B\\\"uchi) automata, tree automata and probabilistic automata.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 13:03:51 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 17:54:00 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 12:03:56 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Brengos", "Tomasz", ""]]}, {"id": "1902.03013", "submitter": "\\'Etienne Andr\\'e", "authors": "\\'Etienne Andr\\'e, Vincent Bloemen, Laure Petrucci and Jaco van de Pol", "title": "Minimal-Time Synthesis for Parametric Timed Automata", "comments": "Author version of the paper of the same name published in the\n  proceedings of the 25th International Conference on Tools and Algorithms for\n  the Construction and Analysis of Systems (TACAS 2019)", "journal-ref": "TACAS'19, Springer LNCS 11428, pages 211-228, April 2019", "doi": "10.1007/978-3-030-17465-1_12", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parametric timed automata (PTA) extend timed automata by allowing parameters\nin clock constraints. Such a formalism is for instance useful when reasoning\nabout unknown delays in a timed system. Using existing techniques, a user can\nsynthesize the parameter constraints that allow the system to reach a specified\ngoal location, regardless of how much time has passed for the internal clocks.\n  We focus on synthesizing parameters such that not only the goal location is\nreached, but we also address the following questions: what is the minimal time\nto reach the goal location? and for which parameter values can we achieve this?\nWe analyse the problem and present an algorithm that solves it. We also discuss\nand provide solutions for minimizing a specific parameter value to still reach\nthe goal.\n  We empirically study the performance of these algorithms on a benchmark set\nfor PTAs and show that minimal-time reachability synthesis is more efficient to\ncompute than the standard synthesis algorithm for reachability.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 10:40:01 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", ""], ["Bloemen", "Vincent", ""], ["Petrucci", "Laure", ""], ["van de Pol", "Jaco", ""]]}, {"id": "1902.03025", "submitter": "Chana Weil-Kennedy", "authors": "Javier Esparza, Mikhail Raskin, Chana Weil-Kennedy", "title": "Parameterized Analysis of Immediate Observation Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce immediate observation Petri nets, a class of interest in the\nstudy of population protocols (a model of distributed computation), and\nenzymatic chemical networks. In these areas, relevant analysis questions\ntranslate into parameterized Petri net problems: whether an infinite set of\nPetri nets with the same underlying net, but different initial markings,\nsatisfy a given property. We study the parameterized reachability,\ncoverability, and liveness problems for immediate observation Petri nets. We\nshow that all three problems are in PSPACE for infinite sets of initial\nmarkings defined by counting constraints, a class sufficiently rich for the\nintended application. This is remarkable, since the problems are already\nPSPACE-hard when the set of markings is a singleton, i.e., in the\nnon-parameterized case. We use these results to prove that the correctness\nproblem for immediate observation population protocols is PSPACE-complete,\nanswering a question left open in a previous paper.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 11:30:41 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 12:46:55 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Esparza", "Javier", ""], ["Raskin", "Mikhail", ""], ["Weil-Kennedy", "Chana", ""]]}, {"id": "1902.03074", "submitter": "Alexandre Madeira", "authors": "Rolf Hennicker, Alexandre Madeira and Alexander Knapp", "title": "A Hybrid Dynamic Logic for Event/Data-based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\mathcal{E}^{\\downarrow}$-logic as a formal foundation for the\nspecification and development of event-based systems with local data states.\nThe logic is intended to cover a broad range of abstraction levels from\nabstract requirements specifications up to constructive specifications. Our\nlogic uses diamond and box modalities over structured actions adopted from\ndynamic logic. Atomic actions are pairs $e /\\psi$ where $e$ is an event and\n$\\psi$ a state transition predicate capturing the allowed reactions to the\nevent. To write concrete specifications of recursive process structures we\nintegrate (control) state variables and binders of hybrid logic. The semantic\ninterpretation relies on event/data transition systems; specification\nrefinement is defined by model class inclusion. For the presentation of\nconstructive specifications we propose operational event/data specifications\nallowing for familiar, diagrammatic representations by state transition graphs.\nWe show that $\\mathcal{E}^{\\downarrow}$-logic is powerful enough to\ncharacterise the semantics of an operational specification by a single\n$\\mathcal{E}^{\\downarrow}$-sentence. Thus the whole development process can\nrely on $\\mathcal{E}^{\\downarrow}$-logic and its semantics as a common basis.\nThis includes also a variety of implementation constructors to support, among\nothers, event refinement and parallel composition.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 13:34:21 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Hennicker", "Rolf", ""], ["Madeira", "Alexandre", ""], ["Knapp", "Alexander", ""]]}, {"id": "1902.03178", "submitter": "Aleks Kissinger", "authors": "Ross Duncan and Aleks Kissinger and Simon Perdrix and John van de\n  Wetering", "title": "Graph-theoretic Simplification of Quantum Circuits with the ZX-calculus", "comments": "18 pages + appendices with examples, proofs, and pseudocode", "journal-ref": "Quantum 4, 279 (2020)", "doi": "10.22331/q-2020-06-04-279", "report-no": null, "categories": "quant-ph cs.LO math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a completely new approach to quantum circuit optimisation, based\non the ZX-calculus. We first interpret quantum circuits as ZX-diagrams, which\nprovide a flexible, lower-level language for describing quantum computations\ngraphically. Then, using the rules of the ZX-calculus, we give a simplification\nstrategy for ZX-diagrams based on the two graph transformations of local\ncomplementation and pivoting and show that the resulting reduced diagram can be\ntransformed back into a quantum circuit. While little is known about extracting\ncircuits from arbitrary ZX-diagrams, we show that the underlying graph of our\nsimplified ZX-diagram always has a graph-theoretic property called generalised\nflow, which in turn yields a deterministic circuit extraction procedure. For\nClifford circuits, this extraction procedure yields a new normal form that is\nboth asymptotically optimal in size and gives a new, smaller upper bound on\ngate depth for nearest-neighbour architectures. For Clifford+T and more general\ncircuits, our technique enables us to to `see around' gates that obstruct the\nClifford structure and produce smaller circuits than naive\n'cut-and-resynthesise' methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:37:51 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:06:48 GMT"}, {"version": "v3", "created": "Mon, 29 Apr 2019 15:42:09 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 08:05:29 GMT"}, {"version": "v5", "created": "Mon, 30 Mar 2020 16:06:03 GMT"}, {"version": "v6", "created": "Tue, 26 May 2020 16:13:42 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Duncan", "Ross", ""], ["Kissinger", "Aleks", ""], ["Perdrix", "Simon", ""], ["van de Wetering", "John", ""]]}, {"id": "1902.03218", "submitter": "Ji Guan", "authors": "Ji Guan, Yuan Feng, Andrea Turrini and Mingsheng Ying", "title": "Model Checking Applied to Quantum Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking has been successfully applied to verification of computer\nhardware and software, communication systems and even biological systems. In\nthis paper, we further push the boundary of its applications and show that it\ncan be adapted for applications in quantum physics. More explicitly, we show\nhow quantum statistical and many-body systems can be modeled as quantum Markov\nchains, and some of their properties that interest physicists can be specified\nin linear-time temporal logics. Then we present an efficient algorithm to check\nthese properties. A few case studies are given to demonstrate the use of our\nalgorithm to actual quantum physical problems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 18:28:26 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Guan", "Ji", ""], ["Feng", "Yuan", ""], ["Turrini", "Andrea", ""], ["Ying", "Mingsheng", ""]]}, {"id": "1902.03273", "submitter": "Nicolas Troquard", "authors": "Ana Ozaki and Nicolas Troquard", "title": "Learning Ontologies with Epistemic Reasoning: The EL Case", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning description logic ontologies from\nentailments via queries, using epistemic reasoning. We introduce a new learning\nmodel consisting of epistemic membership and example queries and show that\npolynomial learnability in this model coincides with polynomial learnability in\nAngluin's exact learning model with membership and equivalence queries. We then\ninstantiate our learning framework to EL and show some complexity results for\nan epistemic extension of EL where epistemic operators can be applied over the\naxioms. Finally, we transfer known results for EL ontologies and its fragments\nto our learning model based on epistemic reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 20:06:36 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ozaki", "Ana", ""], ["Troquard", "Nicolas", ""]]}, {"id": "1902.03399", "submitter": "Mohsen Mansouri", "authors": "Mohsen Mansouri, Farzad Didehvar", "title": "Approximation of subsets of natural numbers by c.e. sets", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximation of natural numbers subsets has always been one of the\nfundamental issues in computability theory. Computable approximation,\n$\\Delta_2$-approximation, as well as introducing the generically computable\nsets have been some efforts for this purpose. In this paper, a type of\napproximation for natural numbers subsets by computably enumerable sets will be\nexamined. For an infinite and non-c.e set, $W_i$ will be an $A$.maximal\n(maximal inside $A$) if $W_i \\subseteq A$, is infinite and $\\forall j (W_i\n\\subseteq W_j \\subseteq A) \\to \\Delta (W_i, W_j )< \\infty$, where $\\Delta$ is\nthe symmetric difference of the two sets. In this study, the natural numbers\nsubsets will be examined from the maximal subset contents point of view, and we\nwill categorize them on this basis. We will study c.regular sets that are\nnon-c.e. and include a maximal set inside themselves, and c.irregular sets that\nare non-c.e. and non-immune sets which do not include maximal sets. Finally, we\nstudy the graph of relationship between c.e. subsets of c.irregular sets.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 10:11:23 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Mansouri", "Mohsen", ""], ["Didehvar", "Farzad", ""]]}, {"id": "1902.03431", "submitter": "Manuel Kauers", "authors": "Manuel Kauers, Martina Seidl, Doron Zeilberger", "title": "On the maximal minimal cube lengths in distinct DNF tautologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a recent article by Anthony Zaleski and Doron Zeilberger, we\ninvestigate the question of determining the largest k for which there exists\nboolean formulas in disjunctive normal form (DNF) with n variables, none of\nwhose conjunctions are `parallel', and such that all of them have at least k\nliterals. Using a SAT solver, we answer some of the questions they left open.\nWe also determine the corresponding numbers for DNFs obeying certain\nsymmetries.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 15:03:37 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kauers", "Manuel", ""], ["Seidl", "Martina", ""], ["Zeilberger", "Doron", ""]]}, {"id": "1902.03770", "submitter": "Philippe Balbiani", "authors": "Philippe Balbiani, \\c{C}i\\u{g}dem Gencer", "title": "About the unification type of simple symmetric modal logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unification problem in a normal modal logic is to determine, given a\nformula F, whether there exists a substitution s such that s(F) is in that\nlogic. In that case, s is a unifier of F. We shall say that a set of unifiers\nof a unifiable formula F is complete if for all unifiers s of F, there exists a\nunifier t of F in that set such that t is more general than s. When a unifiable\nformula has no minimal complete set of unifiers, the formula is nullary. In\nthis paper, we prove that KB, KDB and KTB possess nullary formulas.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 08:23:28 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Balbiani", "Philippe", ""], ["Gencer", "\u00c7i\u011fdem", ""]]}, {"id": "1902.03882", "submitter": "Francesco Antonio Genco", "authors": "Federico Aschieri, Agata Ciabattoni, and Francesco A. Genco", "title": "A typed parallel {\\lambda}-calculus via 1-depth intermediate proofs", "comments": "LPAR23", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Curry-Howard correspondence for a large class of intermediate\nlogics characterized by intuitionistic proofs with non-nested applications of\nrules for classical disjunctive tautologies (1-depth intermediate proofs). The\nresulting calculus, we call it $\\lambda_{\\parallel}$, is a strongly normalizing\nparallel extension of the simply typed $\\lambda$-calculus. Although simple, the\n$\\lambda_{\\parallel}$ reduction rules can model arbitrary process network\ntopologies, and encode interesting parallel programs ranging from numeric\ncomputation to algorithms on graphs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 14:05:07 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 18:53:13 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 09:20:21 GMT"}, {"version": "v4", "created": "Mon, 25 Feb 2019 14:25:11 GMT"}, {"version": "v5", "created": "Wed, 8 Apr 2020 11:41:20 GMT"}, {"version": "v6", "created": "Tue, 21 Apr 2020 15:32:18 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Aschieri", "Federico", ""], ["Ciabattoni", "Agata", ""], ["Genco", "Francesco A.", ""]]}, {"id": "1902.04111", "submitter": "Yu Wang", "authors": "Yu Wang, Siddhartha Nalluri, Borzoo Bonakdarpour, Miroslav Pajic", "title": "Statistical Model Checking for Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties have shown to be a powerful tool for expressing and reasoning\nabout information-flow security policies. In this paper, we investigate the\nproblem of statistical model checking (SMC) for hyperproperties. Unlike\nexhaustive model checking, SMC works based on drawing samples from the system\nat hand and evaluate the specification with statistical confidence. The main\nbenefit of applying SMC over exhaustive techniques is its efficiency and\nscalability. To reason about probabilistic hyperproperties, we first propose\nthe temporal logic HyperPCLT* that extends PCTL* and HyperPCTL. We show that\nHyperPCLT* can express important probabilistic information-flow security\npolicies that cannot be expressed with HyperPCTL. Then, we introduce SMC\nalgorithms for verifying HyperPCLT* formulas on discrete-time Markov chains,\nbased on sequential probability ratio tests (SPRT) with a new notion of\nmulti-dimensional indifference region. Our SMC algorithms can handle both\nnon-nested and nested probability operators for any desired significance level.\nTo show the effectiveness of our technique, we evaluate our SMC algorithms on\nfour case studies focused on information security: timing side-channel\nvulnerability in encryption, probabilistic anonymity in dining cryptographers,\nprobabilistic noninterference of parallel programs, and the performance of a\nrandomized cache replacement policy that acts as a countermeasure against cache\nflush attacks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:40:15 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 16:26:28 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 13:59:31 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 05:35:04 GMT"}, {"version": "v5", "created": "Tue, 4 Aug 2020 18:04:03 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wang", "Yu", ""], ["Nalluri", "Siddhartha", ""], ["Bonakdarpour", "Borzoo", ""], ["Pajic", "Miroslav", ""]]}, {"id": "1902.04373", "submitter": "Amir Kafshdar Goharshady", "authors": "Krishnendu Chatterjee and Hongfei Fu and Amir Kafshdar Goharshady and\n  Ehsan Kafshdar Goharshady", "title": "Polynomial Invariant Generation for Non-deterministic Recursive Programs", "comments": "A conference version of this article appears in PLDI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical problem of invariant generation for programs with\npolynomial assignments and focus on synthesizing invariants that are a\nconjunction of strict polynomial inequalities. We present a sound and\nsemi-complete method based on positivstellensaetze, i.e. theorems in\nsemi-algebraic geometry that characterize positive polynomials over a\nsemi-algebraic set. To the best of our knowledge, this is the first invariant\ngeneration method to provide completeness guarantees for invariants consisting\nof polynomial inequalities. Moreover, on the theoretical side, the worst-case\ncomplexity of our approach is subexponential, whereas the worst-case complexity\nof the previously-known complete method (Colon et al, CAV 2003), which could\nonly handle linear invariants, is exponential. On the practical side, we reduce\nthe invariant generation problem to quadratic programming (QCLP), which is a\nclassical optimization problem with many industrial solvers. Finally, we\ndemonstrate the applicability of our approach by providing experimental results\non several academic benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 13:17:25 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 16:55:34 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 14:18:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Fu", "Hongfei", ""], ["Goharshady", "Amir Kafshdar", ""], ["Goharshady", "Ehsan Kafshdar", ""]]}, {"id": "1902.04538", "submitter": "Jakob Piribauer", "authors": "Jakob Piribauer and Christel Baier", "title": "Partial and Conditional Expectations in Markov Decision Processes with\n  Integer Weights", "comments": "This is the extended version of a paper published at FoSSaCS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses two variants of the stochastic shortest path problem\n('optimize the accumulated weight until reaching a goal state') in Markov\ndecision processes (MDPs) with integer weights. The first variant optimizes\npartial expected accumulated weights, where paths not leading to a goal state\nare assigned weight 0, while the second variant considers conditional expected\naccumulated weights, where the probability mass is redistributed to paths\nreaching the goal. Both variants constitute useful approaches to the analysis\nof systems without guarantees on the occurrence of an event of interest\n(reaching a goal state), but have only been studied in structures with\nnon-negative weights. Our main results are as follows. There are\npolynomial-time algorithms to check the finiteness of the supremum of the\npartial or conditional expectations in MDPs with arbitrary integer weights. If\nfinite, then optimal weight-based deterministic schedulers exist. In contrast\nto the setting of non-negative weights, optimal schedulers can need infinite\nmemory and their value can be irrational. However, the optimal value can be\napproximated up to an absolute error of $\\epsilon$ in time exponential in the\nsize of the MDP and polynomial in $\\log(1/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:33:29 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 08:35:49 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Piribauer", "Jakob", ""], ["Baier", "Christel", ""]]}, {"id": "1902.04572", "submitter": "Ruggero Lanotte Dr", "authors": "Ruggero Lanotte and Massimo Merro and Andrei Munteanu and Luca\n  Vigan\\`o", "title": "A Formal Approach to Physics-Based Attacks in Cyber-Physical Systems\n  (Extended Version)", "comments": "This document extends the paper \"A Formal Approach to Physics-Based\n  Attacks in Cyber-Physical Systems\" that will appear in ACM Transactions on\n  Privacy and Security by providing proofs that are worked out in full details.\n  arXiv admin note: text overlap with arXiv:1611.01377", "journal-ref": "ACM Trans. Priv. Secur. 23(1): 3:1-3:41 (2020)", "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply formal methods to lay and streamline theoretical foundations to\nreason about Cyber-Physical Systems (CPSs) and physics-based attacks, i.e.,\nattacks targeting physical devices. We focus on a formal treatment of both\nintegrity and denial of service attacks to sensors and actuators of CPSs, and\non the timing aspects of these attacks. Our contributions are fourfold. (1)~We\ndefine a hybrid process calculus to model both CPSs and physics-based attacks.\n(2)~We formalise a threat model that specifies MITM attacks that can manipulate\nsensor readings or control commands in order to drive a CPS into an undesired\nstate, and we provide the means to assess attack tolerance/vulnerability with\nrespect to a given attack. (3)~We formalise how to estimate the impact of a\nsuccessful attack on a CPS and investigate possible quantifications of the\nsuccess chances of an attack. (4)~We illustrate our definitions and results by\nformalising a non-trivial running example in Uppaal SMC, the statistical\nextension of the Uppaal model checker; we use Uppaal SMC as an automatic tool\nfor carrying out a static security analysis of our running example in isolation\nand when exposed to three different physics-based attacks with different\nimpacts.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 14:41:59 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:23:37 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 09:00:47 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Lanotte", "Ruggero", ""], ["Merro", "Massimo", ""], ["Munteanu", "Andrei", ""], ["Vigan\u00f2", "Luca", ""]]}, {"id": "1902.04618", "submitter": "Mahmoud Elfar", "authors": "Mahmoud Elfar, Yu Wang, Miroslav Pajic", "title": "Security-Aware Synthesis Using Delayed-Action Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic multiplayer games (SMGs) have gained attention in the field of\nstrategy synthesis for multi-agent reactive systems. However, standard SMGs are\nlimited to modeling systems where all agents have full knowledge of the state\nof the game. In this paper, we introduce delayed-action games (DAGs) formalism\nthat simulates hidden-information games (HIGs) as SMGs, where hidden\ninformation is captured by delaying a player's actions. The elimination of\nprivate variables enables the usage of SMG off-the-shelf model checkers to\nimplement HIGs. Furthermore, we demonstrate how a DAG can be decomposed into\nsubgames that can be independently explored, utilizing parallel computation to\nreduce the model checking time, while alleviating the state space explosion\nproblem that SMGs are notorious for. In addition, we propose a DAG-based\nframework for strategy synthesis and analysis. Finally, we demonstrate\napplicability of the DAG-based synthesis framework on a case study of a\nhuman-on-the-loop unmanned-aerial vehicle system under stealthy attacks, where\nthe proposed framework is used to formally model, analyze and synthesize\nsecurity-aware strategies for the system.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 20:19:58 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 03:03:48 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Elfar", "Mahmoud", ""], ["Wang", "Yu", ""], ["Pajic", "Miroslav", ""]]}, {"id": "1902.04645", "submitter": "Cristina Matache", "authors": "Cristina Matache", "title": "Program Equivalence for Algebraic Effects via Modalities", "comments": "Master Thesis, University of Oxford (September 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation is concerned with the study of program equivalence and\nalgebraic effects as they arise in the theory of programming languages.\nAlgebraic effects represent impure behaviour in a functional programming\nlanguage, such as input and output, exceptions, nondeterminism etc. all treated\nin a generic way. Program equivalence aims to identify which programs can be\nconsidered equal in some sense. This question has been studied for a long time\nbut has only recently been extended to languages with algebraic effects, which\nare a newer development. Much work remains to be done in order to understand\nprogram equivalence in the presence of algebraic effects. In particular, there\nis no characterisation of contextual equivalence using a logic. We define a\nlogic whose formulas express properties of higher-order programs with algebraic\neffects. We then investigate three notions of program equivalence for algebraic\neffects: logical equivalence induced by the aforementioned logic, applicative\nbisimilarity and contextual equivalence. For the programming language used in\nthis dissertation, we prove that they all coincide. Therefore, the main novel\ncontribution of the dissertation is defining the first logic for algebraic\neffects whose induced program equivalence coincides with contextual\nequivalence.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 21:35:51 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Matache", "Cristina", ""]]}, {"id": "1902.04740", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek, Sivakanth Gopi and Venkatesan Guruswami", "title": "CSPs with Global Modular Constraints: Algorithms and Hardness via\n  Polynomial Representations", "comments": "52 pages; to appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of Boolean constraint satisfaction problems (CSPs)\nwhen the assignment must have Hamming weight in some congruence class modulo M,\nfor various choices of the modulus M. Due to the known classification of\ntractable Boolean CSPs, this mainly reduces to the study of three cases: 2-SAT,\nHORN-SAT, and LIN-2 (linear equations mod 2). We classify the moduli M for\nwhich these respective problems are polynomial time solvable, and when they are\nnot (assuming the ETH). Our study reveals that this modular constraint lends a\nsurprising richness to these classic, well-studied problems, with interesting\nbroader connections to complexity theory and coding theory. The HORN-SAT case\nis connected to the covering complexity of polynomials representing the NAND\nfunction mod M. The LIN-2 case is tied to the sparsity of polynomials\nrepresenting the OR function mod M, which in turn has connections to modular\nweight distribution properties of linear codes and locally decodable codes. In\nboth cases, the analysis of our algorithm as well as the hardness reduction\nrely on these polynomial representations, highlighting an interesting algebraic\ncommon ground between hard cases for our algorithms and the gadgets which show\nhardness. These new complexity measures of polynomial representations merit\nfurther study.\n  The inspiration for our study comes from a recent work by N\\\"agele, Sudakov,\nand Zenklusen on submodular minimization with a global congruence constraint.\nOur algorithm for HORN-SAT has strong similarities to their algorithm, and in\nparticular identical kind of set systems arise in both cases. Our connection to\npolynomial representations leads to a simpler analysis of such set systems, and\nalso sheds light on (but does not resolve) the complexity of submodular\nminimization with a congruency requirement modulo a composite M.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 04:49:40 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Gopi", "Sivakanth", ""], ["Guruswami", "Venkatesan", ""]]}, {"id": "1902.04809", "submitter": "Barbara K\\\"onig", "authors": "Andrea Corradini and Tobias Heindel and Barbara K\\\"onig and Dennis\n  Nolte and Arend Rensink", "title": "Rewriting Abstract Structures: Materialization Explained Categorically", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops an abstract (over-approximating) semantics for\ndouble-pushout rewriting of graphs and graph-like objects. The focus is on the\nso-called materialization of left-hand sides from abstract graphs, a central\nconcept in previous work. The first contribution is an accessible, general\nexplanation of how materializations arise from universal properties and\ncategorical constructions, in particular partial map classifiers, in a topos.\nSecond, we introduce an extension by enriching objects with annotations and\ngive a precise characterization of strongest post-conditions, which are\neffectively computable under certain assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:41:49 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Corradini", "Andrea", ""], ["Heindel", "Tobias", ""], ["K\u00f6nig", "Barbara", ""], ["Nolte", "Dennis", ""], ["Rensink", "Arend", ""]]}, {"id": "1902.04836", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (IRIF)", "title": "Differentials and distances in probabilistic coherence spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In probabilistic coherence spaces, a denotational model of probabilistic\nfunctional languages, mor-phisms are analytic and therefore smooth. We explore\ntwo related applications of the corresponding derivatives. First we show how\nderivatives allow to compute the expectation of execution time in the weak head\nreduction of probabilistic PCF (pPCF). Next we apply a general notion of\n\"local\" differential of morphisms to the proof of a Lipschitz property of these\nmorphisms allowing in turn to relate the observational distance on pPCF terms\nto a distance the model is naturally equipped with. This suggests that\nextending probabilistic programming languages with derivatives, in the spirit\nof the differential lambda-calculus, could be quite meaningful.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 10:12:36 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"]]}, {"id": "1902.05152", "submitter": "Antonis Achilleos", "authors": "Luca Aceto, Antonis Achilleos, Adrian Francalanza, Anna\n  Ing\\'olfsd\\'ottir, Karoliina Lehtinen", "title": "The Cost of Monitoring Alone", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the succinctness of two monitoring systems for properties of\ninfinite traces, namely parallel and regular monitors. Although a parallel\nmonitor can be turned into an equivalent regular monitor, the cost of this\ntransformation is a double-exponential blowup in the syntactic size of the\nmonitors, and a triple-exponential blowup when the goal is a deterministic\nmonitor. We show that these bounds are tight and that they also hold for\ntranslations between corresponding fragments of Hennessy-Milner logic with\nrecursion over infinite traces.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 22:22:32 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Aceto", "Luca", ""], ["Achilleos", "Antonis", ""], ["Francalanza", "Adrian", ""], ["Ing\u00f3lfsd\u00f3ttir", "Anna", ""], ["Lehtinen", "Karoliina", ""]]}, {"id": "1902.05172", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Computability logic: Giving Caesar what belongs to Caesar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present article is a brief informal survey of computability logic --- the\ngame-semantically conceived formal theory of computational resources and tasks.\nThis relatively young nonclassical logic is a conservative extension of\nclassical first order logic but is much more expressive than the latter,\nyielding a wide range of new potential application areas. In a reasonable (even\nif not strict) sense the same holds for intuitionistic and linear logics, which\nallows us to say that CoL reconciles and unifies the three traditions of\nlogical thought (and beyond) on the basis of its natural and \"universal\" game\nsemantics. A comprehensive online survey of the subject can be found at\nhttp://www.csc.villanova.edu/~japaridz/CL/ .\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 00:21:18 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1902.05193", "submitter": "Lionel Vaux Auclair", "authors": "Jules Chouquet, and Lionel Vaux Auclair", "title": "An application of parallel cut elimination in multiplicative linear\n  logic to the Taylor expansion of proof nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We examine some combinatorial properties of parallel cut elimination in\nmultiplicative linear logic (MLL) proof nets. We show that, provided we impose\na constraint on some paths, we can bound the size of all the nets satisfying\nthis constraint and reducing to a fixed resultant net. This result gives a\nsufficient condition for an infinite weighted sum of nets to reduce into\nanother sum of nets, while keeping coefficients finite. We moreover show that\nour constraints are stable under reduction.\n  Our approach is motivated by the quantitative semantics of linear logic: many\nmodels have been proposed, whose structure reflect the Taylor expansion of\nmultiplicative exponential linear logic (MELL) proof nets into infinite sums of\ndifferential nets. In order to simulate one cut elimination step in MELL, it is\nnecessary to reduce an arbitrary number of cuts in the differential nets of its\nTaylor expansion. It turns out our results apply to differential nets, because\ntheir cut elimination is essentially multiplicative. We moreover show that the\nset of differential nets that occur in the Taylor expansion of an MELL net\nautomatically satisfies our constraints.\n  Interestingly, our nets are untyped: we only rely on the sequentiality of\nlinear logic nets and the dynamics of cut elimination. The paths on which we\nimpose bounds are the switching paths involved in the Danos--Regnier criterion\nfor sequentiality. In order to accommodate multiplicative units and weakenings,\nour nets come equipped with jumps: each weakening node is connected to some\nother node. Our constraint can then be summed up as a bound on both the length\nof switching paths, and the number of weakenings that jump to a common node.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 02:52:28 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 23:44:38 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 21:45:44 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Chouquet", "Jules", ""], ["Auclair", "Lionel Vaux", ""]]}, {"id": "1902.05205", "submitter": "Luis Garcia", "authors": "Luis Garcia, Stefan Mitsch, Andre Platzer", "title": "HyPLC: Hybrid Programmable Logic Controller Program Translation for\n  Verification", "comments": "13 pages, 9 figures. ICCPS 2019", "journal-ref": null, "doi": "10.1145/3302509.3311036", "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable Logic Controllers (PLCs) provide a prominent choice of\nimplementation platform for safety-critical industrial control systems. Formal\nverification provides ways of establishing correctness guarantees, which can be\nquite important for such safety-critical applications. But since PLC code does\nnot include an analytic model of the system plant, their verification is\nlimited to discrete properties. In this paper, we, thus, start the other way\naround with hybrid programs that include continuous plant models in addition to\ndiscrete control algorithms. Even deep correctness properties of hybrid\nprograms can be formally verified in the theorem prover KeYmaera X that\nimplements differential dynamic logic, dL, for hybrid programs. After verifying\nthe hybrid program, we now present an approach for translating hybrid programs\ninto PLC code. The new tool, HyPLC, implements this translation of discrete\ncontrol code of verified hybrid program models to PLC controller code and, vice\nversa, the translation of existing PLC code into the discrete control actions\nfor a hybrid program given an additional input of the continuous dynamics of\nthe system to be verified. This approach allows for the generation of real\ncontroller code while preserving, by compilation, the correctness of a valid\nand verified hybrid program. PLCs are common cyber-physical interfaces for\nsafety-critical industrial control applications, and HyPLC serves as a\npragmatic tool for bridging formal verification of complex cyber-physical\nsystems at the algorithmic level of hybrid programs with the execution layer of\nconcrete PLC implementations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 03:48:04 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Garcia", "Luis", ""], ["Mitsch", "Stefan", ""], ["Platzer", "Andre", ""]]}, {"id": "1902.05465", "submitter": "Mario Alvarez-Picallo", "authors": "Mario Alvarez-Picallo, C.-H. Luke Ong", "title": "Change Actions: Models of Generalised Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cai et al. have recently proposed change structures as a semantic framework\nfor incremental computation. We generalise change structures to arbitrary\ncartesian categories and propose the notion of change action model as a\ncategorical model for (higher-order) generalised differentiation. Change action\nmodels naturally arise from many geometric and computational settings, such as\n(generalised) cartesian differential categories, group models of discrete\ncalculus, and Kleene algebra of regular expressions. We show how to build\ncanonical change action models on arbitrary cartesian categories, reminiscent\nof the F\\`aa di Bruno construction.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 16:00:23 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 20:01:18 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 10:53:04 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Alvarez-Picallo", "Mario", ""], ["Ong", "C. -H. Luke", ""]]}, {"id": "1902.05629", "submitter": "Anne-Kathrin Schmuck", "authors": "Rupak Majumdar, Nir Piterman, Anne-Kathrin Schmuck", "title": "Environmentally-friendly GR(1) Synthesis", "comments": "Full version of the TACAS'19 paper with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in reactive synthesis are stated using two formulas ---an\nenvironment assumption and a system guarantee--- and ask for an implementation\nthat satisfies the guarantee in environments that satisfy their assumption.\nReactive synthesis tools often produce strategies that formally satisfy such\nspecifications by actively preventing an environment assumption from holding.\nWhile formally correct, such strategies do not capture the intention of the\ndesigner. We introduce an additional requirement in reactive synthesis,\nnon-conflictingness, which asks that a system strategy should always allow the\nenvironment to fulfill its liveness requirements. We give an algorithm for\nsolving GR(1) synthesis that produces non-conflicting strategies. Our algorithm\nis given by a 4-nested fixed point in the $\\mu$-calculus, in contrast to the\nusual 3-nested fixed point for GR(1). Our algorithm ensures that, in every\nenvironment that satisfies its assumptions on its own, traces of the resulting\nimplementation satisfy both the assumptions and the guarantees. In addition,\nthe asymptotic complexity of our algorithm is the same as that of the usual\nGR(1) solution. We have implemented our algorithm and show how its performance\ncompares to the usual GR(1) synthesis algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 22:28:06 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Majumdar", "Rupak", ""], ["Piterman", "Nir", ""], ["Schmuck", "Anne-Kathrin", ""]]}, {"id": "1902.05720", "submitter": "Th\\'eo Grente", "authors": "\\'Etienne Grandjean and Th\\'eo Grente", "title": "Descriptive complexity for minimal time of cellular automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descriptive complexity may be useful to design programs in a natural\ndeclarative way. This is important for parallel computation models such as\ncellular automata, because designing parallel programs is considered difficult.\nOur paper establishes logical characterizations of the three classical\ncomplexity classes that model minimal time, called real-time, of\none-dimensional cellular automata according to their canonical variants. Our\nlogics are natural restrictions of the existential second-order Horn logic.\nThey correspond to the three ways of deciding a language on a square grid\ncircuit of side n according to the three canonical placements of an input word\nof length n on the grid. Our key tool is a normalization method that transforms\na formula into an equivalent formula that literally mimics a grid circuit.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 08:31:35 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:59:50 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Grandjean", "\u00c9tienne", ""], ["Grente", "Th\u00e9o", ""]]}, {"id": "1902.05727", "submitter": "Sebastian Junges", "authors": "Milan Ceska, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen", "title": "Shepherding Hordes of Markov Chains", "comments": "Full version of TACAS'19 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers large families of Markov chains (MCs) that are defined\nover a set of parameters with finite discrete domains. Such families occur in\nsoftware product lines, planning under partial observability, and sketching of\nprobabilistic programs. Simple questions, like `does at least one family member\nsatisfy a property?', are NP-hard. We tackle two problems: distinguish family\nmembers that satisfy a given quantitative property from those that do not, and\ndetermine a family member that satisfies the property optimally, i.e., with the\nhighest probability or reward. We show that combining two well-known\ntechniques, MDP model checking and abstraction refinement, mitigates the\ncomputational complexity. Experiments on a broad set of benchmarks show that in\nmany situations, our approach is able to handle families of millions of MCs,\nproviding superior scalability compared to existing solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 09:12:34 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 10:36:07 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Ceska", "Milan", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1902.05762", "submitter": "Jurriaan Rot", "authors": "Simone Barlocco, Clemens Kupke, Jurriaan Rot", "title": "Coalgebra Learning via Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automata learning is a popular technique for inferring minimal automata\nthrough membership and equivalence queries. In this paper, we generalise\nlearning to the theory of coalgebras. The approach relies on the use of logical\nformulas as tests, based on a dual adjunction between states and logical\ntheories. This allows us to learn, e.g., labelled transition systems, using\nHennessy-Milner logic. Our main contribution is an abstract learning algorithm,\ntogether with a proof of correctness and termination.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 10:52:59 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 10:05:39 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Barlocco", "Simone", ""], ["Kupke", "Clemens", ""], ["Rot", "Jurriaan", ""]]}, {"id": "1902.05905", "submitter": "Andreas Krebs", "authors": "Andreas Krebs, Kamal Lodaya, Paritosh K. Pandya, Howard Straubing", "title": "Two-variable logics with some betweenness relations: Expressiveness,\n  satisfiability and membership", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (September\n  8, 2020) lmcs:6765", "doi": "10.23638/LMCS-16(3:16)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study two extensions of FO2[<], first-order logic interpreted in finite\nwords, in which formulas are restricted to use only two variables. We adjoin to\nthis language two-variable atomic formulas that say, \"the letter $a$ appears\nbetween positions $x$ and $y$\" and \"the factor $u$ appears between positions\n$x$ and $y$\". These are, in a sense, the simplest properties that are not\nexpressible using only two variables.\n  We present several logics, both first-order and temporal, that have the same\nexpressive power, and find matching lower and upper bounds for the complexity\nof satisfiability for each of these formulations. We give effective conditions,\nin terms of the syntactic monoid of a regular language, for a property to be\nexpressible in these logics. This algebraic analysis allows us to prove, among\nother things, that our new logics have strictly less expressive power than full\nfirst-order logic FO[<]. Our proofs required the development of novel\ntechniques concerning factorizations of words.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 03:20:36 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 13:01:53 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 17:46:09 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Krebs", "Andreas", ""], ["Lodaya", "Kamal", ""], ["Pandya", "Paritosh K.", ""], ["Straubing", "Howard", ""]]}, {"id": "1902.05926", "submitter": "Arno Pauly", "authors": "Matthew de Brecht, Arno Pauly, Matthias Schr\\\"oder", "title": "Overt choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the notion of overt choice for countably-based spaces\nand for CoPolish spaces. Overt choice is the task of producing a point in a\nclosed set specified by what open sets intersect it. We show that the question\nof whether overt choice is continuous for a given space is related to\ntopological completeness notions such as the Choquet-property; and to whether\nvariants of Michael's selection theorem hold for that space. For spaces where\novert choice is discontinuous it is interesting to explore the resulting\nWeihrauch degrees, which in turn are related to whether or not the space is\nFrechet-Urysohn.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 09:29:49 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["de Brecht", "Matthew", ""], ["Pauly", "Arno", ""], ["Schr\u00f6der", "Matthias", ""]]}, {"id": "1902.05945", "submitter": "Giulio Guerrieri", "authors": "Beniamino Accattoli, Giulio Guerrieri, Maico Leberle", "title": "Types by Need (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cornerstone of the theory of lambda-calculus is that intersection types\ncharacterise termination properties. They are a flexible tool that can be\nadapted to various notions of termination, and that also induces adequate\ndenotational models.\n  Since the seminal work of de Carvalho in 2007, it is known that multi types\n(i.e. non-idempotent intersection types) refine intersection types with\nquantitative information and a strong connection to linear logic. Typically,\ntype derivations provide bounds for evaluation lengths, and minimal type\nderivations provide exact bounds.\n  De Carvalho studied call-by-name evaluation, and Kesner used his system to\nshow the termination equivalence of call-by-need and call-by-name. De\nCarvalho's system, however, cannot provide exact bounds on call-by-need\nevaluation lengths.\n  In this paper we develop a new multi type system for call-by-need. Our system\nproduces exact bounds and induces a denotational model of call-by-need,\nproviding the first tight quantitative semantics of call-by-need.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 18:57:33 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Guerrieri", "Giulio", ""], ["Leberle", "Maico", ""]]}, {"id": "1902.06097", "submitter": "Andreas Abel", "authors": "Andreas Abel and Christian Sattler", "title": "Normalization by Evaluation for Call-by-Push-Value and Polarized\n  Lambda-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that normalization by evaluation for simply-typed lambda-calculus\nwith weak coproducts can be carried out in a weak bi-cartesian closed category\nof presheaves equipped with a monad that allows us to perform case distinction\non neutral terms of sum type. The placement of the monad influences the normal\nforms we obtain: for instance, placing the monad on coproducts gives us\neta-long beta-pi normal forms where pi refers to permutation of case\ndistinctions out of elimination positions. We further observe that placing the\nmonad on every coproduct is rather wasteful, and an optimal placement of the\nmonad can be determined by considering polarized simple types inspired by\nfocalization. Polarization classifies types into positive and negative, and it\nis sufficient to place the monad at the embedding of positive types into\nnegative ones. We consider two calculi based on polarized types: pure\ncall-by-push-value (CBPV) and polarized lambda-calculus, the natural deduction\ncalculus corresponding to focalized sequent calculus. For these two calculi, we\npresent algorithms for normalization by evaluation. We further discuss\ndifferent implementations of the monad and their relation to existing\nnormalization proofs for lambda-calculus with sums. Our developments have been\npartially formalized in the Agda proof assistant.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 12:26:22 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Abel", "Andreas", ""], ["Sattler", "Christian", ""]]}, {"id": "1902.06178", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira, Renata Vieira", "title": "Iterated Belief Base Revision: A Dynamic Epistemic Logic Approach", "comments": "8 pages, AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AGM's belief revision is one of the main paradigms in the study of belief\nchange operations. In this context, belief bases (prioritised bases) have been\nlargely used to specify the agent's belief state - whether representing the\nagent's `explicit beliefs' or as a computational model for her belief state.\nWhile the connection of iterated AGM-like operations and their encoding in\ndynamic epistemic logics have been studied before, few works considered how\nwell-known postulates from iterated belief revision theory can be characterised\nby means of belief bases and their counterpart in a dynamic epistemic logic.\nThis work investigates how priority graphs, a syntactic representation of\npreference relations deeply connected to prioritised bases, can be used to\ncharacterise belief change operators, focusing on well-known postulates of\nIterated Belief Change. We provide syntactic representations of belief change\noperators in a dynamic context, as well as new negative results regarding the\npossibility of representing an iterated belief revision operation using\ntransformations on priority graphs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 00:14:26 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""], ["Vieira", "Renata", ""]]}, {"id": "1902.06572", "submitter": "Christian Sattler", "authors": "Thierry Coquand and Simon Huber and Christian Sattler", "title": "Canonicity and homotopy canonicity for cubical type theory", "comments": "33 pages, revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cubical type theory provides a constructive justification of homotopy type\ntheory. A crucial ingredient of cubical type theory is a path lifting operation\nwhich is explained computationally by induction on the type involving several\nnon-canonical choices. We present in this article two canonicity results, both\nproved by a sconing argument: a homotopy canonicity result, every natural\nnumber is path equal to a numeral, even if we take away the equations defining\nthe lifting operation on the type structure, and a canonicity result, which\nuses these equations in a crucial way. Both proofs are done internally in a\npresheaf model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 13:55:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 17:47:25 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 17:58:39 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Coquand", "Thierry", ""], ["Huber", "Simon", ""], ["Sattler", "Christian", ""]]}, {"id": "1902.06576", "submitter": "Guillermo P\\'erez", "authors": "Shaull Almagor, Nathann Cohen, Guillermo A. P\\'erez, Mahsa\n  Shirmohammadi, James Worrell", "title": "Coverability in 1-VASS with Disequality Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of reachability problems in weighted graphs with constraints\non the accumulated weight of paths. The problems we study can equivalently be\nformulated in the model of vector addition systems with states (VASS). We\nconsider a version of the vertex-to-vertex reachability problem in which the\naccumulated weight of a path is required always to be non-negative. This is\nequivalent to the so-called control-state reachability problem (also called the\ncoverability problem) for 1-dimensional VASS. We show that this problem lies in\nNC: the class of problems solvable in polylogarithmic parallel time. In our\nmain result we generalise the problem to allow disequality constraints on edges\n(i.e., we allow edges to be disabled if the accumulated weight is equal to a\nspecific value). We show that in this case the vertex-to-vertex reachability\nproblem is solvable in polynomial time even though a shortest path may have\nexponential length. In the language of VASS this means that control-state\nreachability is in polynomial time for 1-dimensional VASS with disequality\ntests.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 14:05:58 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:10:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Almagor", "Shaull", ""], ["Cohen", "Nathann", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "1902.06632", "submitter": "Tim Lyon", "authors": "Kees van Berkel and Tim Lyon", "title": "Appendix for: Cut-free Calculi and Relational Semantics for Temporal\n  STIT logics", "comments": "Appendix to paper \"Cut-free Calculi and Relational Semantics for\n  Temporal STIT logics\", accepted to the 16th Joint European Conference on\n  Logics in Artificial Intelligence (JELIA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an appendix to the paper \"Cut-free Calculi and Relational\nSemantics for Temporal STIT logics\" by Berkel and Lyon, 2019. It provides the\ncompleteness proof for the basic STIT logic Ldm (relative to irreflexive,\ntemporal Kripke STIT frames) as well as gives the derivation of the\nindependence of agents axiom for the logic Xstit.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 16:13:22 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["van Berkel", "Kees", ""], ["Lyon", "Tim", ""]]}, {"id": "1902.06648", "submitter": "Anuj Dawar", "authors": "Anuj Dawar, Erich Gr\\\"adel, Wied Pakusa", "title": "Approximations of Isomorphism and Logics with Linear-Algebraic Operators", "comments": "46 pages. Pre-submission version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invertible map equivalences are approximations of graph isomorphism that\nrefine the well-known Weisfeiler-Leman method. They are parametrised by a\nnumber k and a set Q of primes. The intuition is that two graphs G and H which\nare equivalent with respect to k-Q-IM-equivalence cannot be distinguished by a\nrefinement of k-tuples given by linear operators acting on vector spaces over\nfields of characteristic p, for any p in Q. These equivalences first appeared\nin the study of rank logic, but in fact they can be used to delimit the\nexpressive power of any extension of fixed-point logic with linear-algebraic\noperators. We define an infinitary logic with k variables and all\nlinear-algebraic operators over finite vector spaces of characteristic p in Q\nand show that the k-Q-IM-equivalence is the natural notion of elementary\nequivalence for this logic.\n  By means of a new and much deeper algebraic analysis of a generalized\nvariant, for any prime p, of the CFI-structures due to Cai, F\\\"urer, and\nImmerman, we prove that, as long as Q is not the set of all primes, there is no\nk such that k-Q-IM-equivalence is the same as isomorphism. It follows that\nthere are polynomial-time properties of graphs which are not definable in the\ninfinitary logic with all Q-linear-algebraic operators and finitely many\nvariables, which implies that no extension of fixed-point logic with\nlinear-algebraic operators can capture PTIME, unless it includes such operators\nfor all prime characteristics. Our analysis requires substantial algebraic\nmachinery, including a homogeneity property of CFI-structures and Maschke's\nTheorem, an important result from the representation theory of finite groups.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 17:01:23 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 15:10:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Dawar", "Anuj", ""], ["Gr\u00e4del", "Erich", ""], ["Pakusa", "Wied", ""]]}, {"id": "1902.06733", "submitter": "Carsten Fuhs", "authors": "Carsten Fuhs, Cynthia Kop", "title": "A static higher-order dependency pair framework", "comments": "Extended version of a paper which is to appear in the proceedings of\n  ESOP 2019 (28th European Symposium on Programming). arXiv admin note: text\n  overlap with arXiv:1805.09390", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the static dependency pair method for proving termination of\nhigher-order term rewriting and extend it in a number of ways:\n  (1) We introduce a new rewrite formalism designed for general applicability\nin termination proving of higher-order rewriting, Algebraic Functional Systems\nwith Meta-variables. (2) We provide a syntactically checkable soundness\ncriterion to make the method applicable to a large class of rewrite systems.\n(3) We propose a modular dependency pair framework for this higher-order\nsetting. (4) We introduce a fine-grained notion of formative and computable\nchains to render the framework more powerful. (5) We formulate several existing\nand new termination proving techniques in the form of processors within our\nframework.\n  The framework has been implemented in the (fully automatic) higher-order\ntermination tool WANDA.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 18:22:35 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 17:07:15 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Fuhs", "Carsten", ""], ["Kop", "Cynthia", ""]]}, {"id": "1902.07123", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Elementary-base cirquent calculus II: Choice quantifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cirquent calculus is a novel proof theory permitting component-sharing\nbetween logical expressions. Using it, the predecessor article \"Elementary-base\ncirquent calculus I: Parallel and choice connectives\" built the sound and\ncomplete axiomatization CL16 of a propositional fragment of computability logic\n(see http://www.csc.villanova.edu/~japaridz/CL/ ). The atoms of the language of\nCL16 represent elementary, i.e., moveless, games, and the logical vocabulary\nconsists of negation, parallel connectives and choice connectives. The present\npaper constructs the first-order version CL17 of CL16, also enjoying soundness\nand completeness. The language of CL17 augments that of CL18 by including\nchoice quantifiers. Unlike classical predicate calculus, CL17 turns out to be\ndecidable.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:30:07 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1902.07230", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer", "title": "Uniform Substitution At One Fell Swoop", "comments": "CADE 2019 Extending arXiv:1804.05880 with differential games\n  arXiv:1507.04943", "journal-ref": null, "doi": "10.1007/978-3-030-29436-6_25", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform substitution of function, predicate, program or game symbols is the\ncore operation in parsimonious provers for hybrid systems and hybrid games. By\npostponing soundness-critical admissibility checks, this paper introduces a\nuniform substitution mechanism that proceeds in a linear pass homomorphically\nalong the formula. Soundness is recovered using a simple variable condition at\nthe replacements performed by the substitution. The setting in this paper is\nthat of differential hybrid games, in which discrete, continuous, and\nadversarial dynamics interact in differential game logic dGL. This paper proves\nsoundness and completeness of one-pass uniform substitutions for dGL.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:01:03 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:41:35 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 19:45:51 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Platzer", "Andr\u00e9", ""]]}, {"id": "1902.07245", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Sabrina Ouazzani", "title": "Continuous Ordinary Differential Equations and Transfinite Computations", "comments": "The model is not sufficiently precisely detailed. Part of the article\n  needs clarification and rewriting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Continuous Ordinary Differential Equations (CODE) y'=f(y), where\nf is a continuous function. They are known to always have solutions for a given\ninitial condition y(0)=y0, these solutions being possibly non unique. We\nrestrict to our attention to a class of continuous functions, that we call\ngreedy: they always admit unique greedy solutions, i.e. going in greedy way in\nsome fixed direction.\n  We prove that they can be seen as models of computation over the ordinals and\nconversely in a very strong sense.\n  In particular, for such ODEs, to a greedy trajectory can be associated some\nordinal corresponding to some time of computation, and conversely models of\ncomputation over the ordinals can be associated to some CODE. In particular,\nanalyzing reachability for one or the other concept with respect to greedy\ntrajectories has the same hardness. This also brings new perspectives on\nanalysis in Mathematics, by providing ways to translate results for ITTMs to\nCODEs. This also extends some recent results about the relations between\nordinary differential equations and Turing machines, and more widely with\n(generalized) computability theory.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:29:32 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 12:19:10 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 10:30:16 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 15:03:03 GMT"}, {"version": "v5", "created": "Mon, 20 Jan 2020 18:22:52 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bournez", "Olivier", ""], ["Ouazzani", "Sabrina", ""]]}, {"id": "1902.07515", "submitter": "Fabian Kunze", "authors": "Yannick Forster, Fabian Kunze, Marc Roth", "title": "The Weak Call-By-Value {\\lambda}-Calculus is Reasonable for Both Time\n  and Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the weak call-by-value $\\lambda$-calculus as a model for\ncomputational complexity theory and establish the natural measures for time and\nspace -- the number of beta-reductions and the size of the largest term in a\ncomputation -- as reasonable measures with respect to the invariance thesis of\nSlot and van Emde Boas [STOC~84]. More precisely, we show that, using those\nmeasures, Turing machines and the weak call-by-value $\\lambda$-calculus can\nsimulate each other within a polynomial overhead in time and a constant factor\noverhead in space for all computations that terminate in (encodings) of 'true'\nor 'false'. We consider this result as a solution to the long-standing open\nproblem, explicitly posed by Accattoli [ENTCS~18], of whether the natural\nmeasures for time and space of the $\\lambda$-calculus are reasonable, at least\nin case of weak call-by-value evaluation.\n  Our proof relies on a hybrid of two simulation strategies of reductions in\nthe weak call-by-value $\\lambda$-calculus by Turing machines, both of which are\ninsufficient if taken alone. The first strategy is the most naive one in the\nsense that a reduction sequence is simulated precisely as given by the\nreduction rules; in particular, all substitutions are executed immediately.\nThis simulation runs within a constant overhead in space, but the overhead in\ntime might be exponential. The second strategy is heap-based and relies on\nstructure sharing, similar to existing compilers of eager functional languages.\nThis strategy only has a polynomial overhead in time, but the space consumption\nmight require an additional factor of $\\log n$, which is essentially due to the\nsize of the pointers required for this strategy. Our main contribution is the\nconstruction and verification of a space-aware interleaving of the two\nstrategies, which is shown to yield both a constant overhead in space and a\npolynomial overhead in time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 11:30:17 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Forster", "Yannick", ""], ["Kunze", "Fabian", ""], ["Roth", "Marc", ""]]}, {"id": "1902.07684", "submitter": "Renato Neves", "authors": "Sergey Goncharov and Renato Neves", "title": "An Adequate While-Language for Hybrid Computation", "comments": "Accepted at PPDP'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid computation combines discrete and continuous dynamics in the form of\nan entangled mixture inherently present both in various natural phenomena, and\nin applications ranging from control theory to microbiology. The emergent\nbehaviours bear signs of both computational and physical processes, and thus\npresent difficulties not only for analysis, but also for describing them\nadequately in a structural, well-founded way. Here, we introduce a language for\nhybrid computation, inspired by the fine-grain call-by-value paradigm, and\nequip it with a denotational and computationally adequate denotational\nsemantics. Our denotational semantics crucially relies on a hybrid monad\nsupporting an (Elgot) iteration operator, we developed elsewhere. As an\nintermediate step we introduce a more lightweight duration semantics furnished\nwith analogous results and drawing on a new duration monad that we introduce as\na lightweight counterpart to the hybrid monad.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 18:07:09 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 18:44:13 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Goncharov", "Sergey", ""], ["Neves", "Renato", ""]]}, {"id": "1902.07741", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Luis Fari\\~nas", "title": "Founded World Views with Autoepistemic Equilibrium Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defined by Gelfond in 1991 (G91), epistemic specifications (or programs) are\nan extension of logic programming under stable models semantics that\nintroducessubjective literals. A subjective literal al-lows checking whether\nsome regular literal is true in all (or in some of) the stable models of the\nprogram, being those models collected in a setcalledworld view. One epistemic\nprogram may yield several world views but, under the original G91 semantics,\nsome of them resulted from self-supported derivations. During the last eight\nyears, several alternative approaches have been proposed to get rid of these\nself-supported worldviews. Unfortunately, their success could only be measured\nby studying their behaviour on a set of common examples in the literature,\nsince no formal property of \"self-supportedness\" had been defined. To fill this\ngap, we extend in this paper the idea of unfounded set from standard logic\nprogramming to the epistemic case. We define when a world view is founded with\nrespect to some program and propose the foundedness property for any semantics\nwhose world views are always founded. Using counterexamples, we explain that\nthe previous approaches violate foundedness, and proceed to propose a new\nsemantics based on a combination of Moore's Autoepistemic Logic and Pearce's\nEquilibrium Logic. The main result proves that this new semantics precisely\ncaptures the set of founded G91 world views.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 19:20:44 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Fari\u00f1as", "Luis", ""]]}, {"id": "1902.08048", "submitter": "Paul Brunet", "authors": "Paul Brunet (UCL-CS)", "title": "A complete axiomatisation of reversible Kleene lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider algebras of languages over the signature of reversible Kleene\nlattices, that is the regular operations (empty and unit languages, union,\nconcatenation and Kleene star) together with intersection and mirror image. We\nprovide a complete set of axioms for the equational theory of these algebras.\nThis proof was developed in the proof assistant Coq.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:45:56 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Brunet", "Paul", "", "UCL-CS"]]}, {"id": "1902.08055", "submitter": "David Cerna", "authors": "David Cerna, Alexander Leitsch, and Anela Lolic", "title": "Schematic Refutations of Formula Schemata", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof schemata are infinite sequences of proofs which are defined\ninductively. In this paper we present a general framework for schemata of\nterms, formulas and unifiers and define a resolution calculus for schemata of\nquantifier-free formulas. The new calculus generalizes and improves former\napproaches to schematic deduction. As an application of the method we present a\nschematic refutation formalizing a proof of a weak form of the pigeon hole\nprinciple.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 14:01:12 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 11:53:32 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 15:25:02 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Cerna", "David", ""], ["Leitsch", "Alexander", ""], ["Lolic", "Anela", ""]]}, {"id": "1902.08149", "submitter": "Paul Gastin", "authors": "Manfred Droste and Paul Gastin", "title": "Aperiodic Weighted Automata and Weighted First-Order Logic", "comments": "An extended abstract of the paper appeared at MFCS'19", "journal-ref": null, "doi": "10.4230/LIPIcs.MFCS.2019.76", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By fundamental results of Sch\\\"utzenberger, McNaughton and Papert from the\n1970s, the classes of first-order definable and aperiodic languages coincide.\nHere, we extend this equivalence to a quantitative setting. For this, weighted\nautomata form a general and widely studied model. We define a suitable notion\nof a weighted first-order logic. Then we show that this weighted first-order\nlogic and aperiodic polynomially ambiguous weighted automata have the same\nexpressive power. Moreover, we obtain such equivalence results for suitable\nweighted sublogics and finitely ambiguous or unambiguous aperiodic weighted\nautomata. Our results hold for general weight structures, including all\nsemirings, average computations of costs, bounded lattices, and others.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 17:23:30 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 10:18:37 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:18:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Droste", "Manfred", ""], ["Gastin", "Paul", ""]]}, {"id": "1902.08345", "submitter": "Thorsten Wissmann", "authors": "Mauricio Ayala-Rinc\\'on, Maribel Fern\\'andez and Daniele\n  Nantes-Sobrinho", "title": "On Nominal Syntax and Permutation Fixed Points", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  17, 2020) lmcs:6106", "doi": "10.23638/LMCS-16(1:19)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new axiomatisation of the alpha-equivalence relation for nominal\nterms, based on a primitive notion of fixed-point constraint. We show that the\nstandard freshness relation between atoms and terms can be derived from the\nmore primitive notion of permutation fixed-point, and use this result to prove\nthe correctness of the new $\\alpha$-equivalence axiomatisation. This gives rise\nto a new notion of nominal unification, where solutions for unification\nproblems are pairs of a fixed-point context and a substitution. Although it may\nseem less natural than the standard notion of nominal unifier based on\nfreshness constraints, the notion of unifier based on fixed-point constraints\nbehaves better when equational theories are considered: for example, nominal\nunification remains finitary in the presence of commutativity, whereas it\nbecomes infinitary when unifiers are expressed using freshness contexts. We\nprovide a definition of $\\alpha$-equivalence modulo equational theories that\ntake into account A, C and AC theories. Based on this notion of equivalence, we\nshow that C-unification is finitary and we provide a sound and complete\nC-unification algorithm, as a first step towards the development of nominal\nunification modulo AC and other equational theories with permutative\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:48:02 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 02:32:47 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 14:38:23 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 08:25:52 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ayala-Rinc\u00f3n", "Mauricio", ""], ["Fern\u00e1ndez", "Maribel", ""], ["Nantes-Sobrinho", "Daniele", ""]]}, {"id": "1902.08414", "submitter": "Jurriaan Rot", "authors": "David Venhoek, Joshua Moerman, Jurriaan Rot", "title": "Fast Computations on Ordered Nominal Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to compute efficiently with nominal sets over the total order\nsymmetry, by developing a direct representation of such nominal sets and basic\nconstructions thereon. In contrast to previous approaches, we work directly at\nthe level of orbits, which allows for an accurate complexity analysis. The\napproach is implemented as the library ONS (Ordered Nominal Sets).\n  Our main motivation is nominal automata, which are models for recognising\nlanguages over infinite alphabets. We evaluate ONS in two applications:\nminimisation of automata and active automata learning. In both cases, ONS is\ncompetitive compared to existing implementations and outperforms them for\ncertain classes of inputs.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 09:35:53 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 15:59:22 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Venhoek", "David", ""], ["Moerman", "Joshua", ""], ["Rot", "Jurriaan", ""]]}, {"id": "1902.08419", "submitter": "EPTCS", "authors": "Andrei-Sebastian Buruian\\u{a} (Alexandru Ioan Cuza University and\n  Bitdefender), \\c{S}tefan Ciob\\^ac\\u{a} (Alexandru Ioan Cuza University)", "title": "Reducing Total Correctness to Partial Correctness by a Transformation of\n  the Language Semantics", "comments": "In Proceedings WPTE 2018, arXiv:1902.07818", "journal-ref": "EPTCS 289, 2019, pp. 1-16", "doi": "10.4204/EPTCS.289.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a language-parametric solution to the problem of total correctness,\nby automatically reducing it to the problem of partial correctness, under the\nassumption that an expression whose value decreases with each program step in a\nwell-founded order is provided. Our approach assumes that the programming\nlanguage semantics is given as a rewrite theory. We implement a prototype on\ntop of the RMT tool and we show that it works in practice on a number of\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:08:29 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Buruian\u0103", "Andrei-Sebastian", "", "Alexandru Ioan Cuza University and\n  Bitdefender"], ["Ciob\u00e2c\u0103", "\u015etefan", "", "Alexandru Ioan Cuza University"]]}, {"id": "1902.08420", "submitter": "EPTCS", "authors": "David Sabel (Goethe-University Frankfurt am Main)", "title": "Automating the Diagram Method to Prove Correctness of Program\n  Transformations", "comments": "In Proceedings WPTE 2018, arXiv:1902.07818", "journal-ref": "EPTCS 289, 2019, pp. 17-33", "doi": "10.4204/EPTCS.289.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the automation of a technique to prove the correctness of\nprogram transformations in higher-order program calculi which may permit\nrecursive let-bindings as they occur in functional programming languages. A\nprogram transformation is correct if it preserves the observational semantics\nof programs. In our LRSX Tool the so-called diagram method is automated by\ncombining unification, matching, and reasoning on alpha-renamings on the\nhigher-order meta-language, and automating induction proofs via an encoding\ninto termination problems of term rewrite systems. We explain the techniques,\nwe illustrate the usage of the tool, and we report on experiments.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:08:48 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Sabel", "David", "", "Goethe-University Frankfurt am Main"]]}, {"id": "1902.08421", "submitter": "EPTCS", "authors": "Yoshiaki Kanazawa (Nagoya University), Naoki Nishida (Nagoya\n  University)", "title": "On Transforming Functions Accessing Global Variables into Logically\n  Constrained Term Rewriting Systems", "comments": "In Proceedings WPTE 2018, arXiv:1902.07818", "journal-ref": "EPTCS 289, 2019, pp. 34-52", "doi": "10.4204/EPTCS.289.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show a new approach to transformations of an imperative\nprogram with function calls and global variables into a logically constrained\nterm rewriting system. The resulting system represents transitions of the whole\nexecution environment with a call stack. More precisely, we prepare a function\nsymbol for the whole environment, which stores values for global variables and\na call stack as its arguments. For a function call, we prepare rewrite rules to\npush the frame to the stack and to pop it after the execution. Any running\nframe is located at the top of the stack, and statements accessing global\nvariables are represented by rewrite rules for the environment symbol. We show\na precise transformation based on the approach and prove its correctness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:09:09 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Kanazawa", "Yoshiaki", "", "Nagoya University"], ["Nishida", "Naoki", "", "Nagoya\n  University"]]}, {"id": "1902.08423", "submitter": "EPTCS", "authors": "Naoki Nishida (Nagoya University), Yuya Maeda (Nagoya University)", "title": "On Transforming Narrowing Trees into Regular Tree Grammars Generating\n  Ranges of Substitutions", "comments": "In Proceedings WPTE 2018, arXiv:1902.07818", "journal-ref": "EPTCS 289, 2019, pp. 68-87", "doi": "10.4204/EPTCS.289.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The grammar representation of a narrowing tree for a syntactically\ndeterministic conditional term rewriting system and a pair of terms is a\nregular tree grammar that generates expressions for substitutions obtained by\nall possible innermost-narrowing derivations that start with the pair and end\nwith particular non-narrowable terms. In this paper, under a certain syntactic\ncondition, we show a transformation of the grammar representation of a\nnarrowing tree into another regular tree grammar that overapproximately\ngenerates the ranges of ground substitutions generated by the grammar\nrepresentation. In our previous work, such a transformation is restricted to\nthe ranges w.r.t. a given single variable, and thus, the usefulness is limited.\nWe extend the previous transformation by representing the range of a ground\nsubstitution as a tuple of terms, which is obtained by the coding for finite\ntrees. We show a precise definition of the transformation and prove that the\nlanguage of the transformed regular tree grammar is an overapproximation of the\nranges of ground substitutions generated by the grammar representation. We\nleave an experiment to evaluate the usefulness of the transformation as future\nwork.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:09:56 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Nishida", "Naoki", "", "Nagoya University"], ["Maeda", "Yuya", "", "Nagoya University"]]}, {"id": "1902.08765", "submitter": "Filip Mari\\'c", "authors": "Filip Mari\\'c, Bojan Vu\\v{c}kovi\\'c, Miodrag \\v{Z}ivkovi\\'c", "title": "Fully Automatic, Verified Classification of all Frankl-Complete (FC(6))\n  Set Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frankl's conjecture, formulated in 1979. and still open, states that in\nevery family of sets closed for unions there is an element contained in at\nleast half of the sets. A family Fc is called Frankl-complete (or FC-family) if\nin every union-closed family F containing Fc, one of the elements of union Fc\noccurs in at least half of the elements of F (so F satisfies the Frankl's\ncondition). FC-families play an important role in attacking the Frankl's\nconjecture, since they enable significant search space pruning. We extend\nprevious work by giving a total characterization of all FC-families over a\n6-element universe, by defining and enumerating all minimal FC and maximal\nnonFC-families. We use a fully automated, computer assisted approach, formally\nverified within the proof-assistant Isabelle/HOL.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 09:38:01 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mari\u0107", "Filip", ""], ["Vu\u010dkovi\u0107", "Bojan", ""], ["\u017divkovi\u0107", "Miodrag", ""]]}, {"id": "1902.08789", "submitter": "Weijun Zhu", "authors": "Weijun ZHU", "title": "Experimental Study on CTL model checking using Machine Learning", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing core methods, which are employed by the popular CTL model\nchecking tools, are facing the famous state explode problem. In our previous\nstudy, a method based on the Machine Learning (ML) algorithms was proposed to\naddress this problem. However, the accuracy is not satisfactory. First, we\nconduct a comprehensive experiment on Graph Lab to seek the optimal accuracy\nusing the five machine learning algorithms. Second, given the optimal accuracy,\nthe average time is seeked. The results show that the Logistic Regressive\n(LR)-based approach can simulate CTL model checking with the accuracy of 98.8%,\nand its average efficiency is 459 times higher than that of the existing\nmethod, as well as the Boosted Tree (BT)-based approach can simulate CTL model\nchecking with the accuracy of 98.7%, and its average efficiency is 639 times\nhigher than that of the existing method.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 14:04:50 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["ZHU", "Weijun", ""]]}, {"id": "1902.08847", "submitter": "Haroldas Giedra", "authors": "Haroldas Giedra, Romas Alonderis", "title": "Automated proof search system for logic of correlated knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated proof search system and decidability for logic of correlated\nknowledge is presented in this paper. The core of the proof system is the\nsequent calculus with the properties of soundness, completeness, admissibility\nof cut and structural rules, and invertibility of all rules. The proof search\nprocedure based on the sequent calculus performs automated terminating proof\nsearch and allows us to achieve decision result for logic of correlated\nknowledge.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 20:42:08 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Giedra", "Haroldas", ""], ["Alonderis", "Romas", ""]]}, {"id": "1902.08848", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling", "title": "Algebraic Type Theory and Universe Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly believed that algebraic notions of type theory support only\nuniverses \\`a la Tarski, and that universes \\`a la Russell must be removed by\nelaboration. We clarify the state of affairs, recalling the details of\nCartmell's discipline of _generalized algebraic theory_, showing how to\nformulate an algebraic version of Coquand's cumulative cwfs with universes \\`a\nla Russell. To demonstrate the power of algebraic techniques, we sketch a\npurely algebraic proof of canonicity for Martin-L\\\"of Type Theory with\nuniverses, dependent function types, and a base type with two constants.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 20:55:30 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Sterling", "Jonathan", ""]]}, {"id": "1902.09214", "submitter": "Karl Schlechta", "authors": "Karl Schlechta", "title": "Homogenousness and Specificity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We interpret homogenousness as a second order property and base it on the\nsame principle as nonmonotonic logic: there might be a small set of exceptions.\nWe use this idea to analyse fundamental questions about defeasible inheritance\nsystems.\n  In an appendix, we discuss the concept of the core of a (model) set.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 11:56:36 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 09:17:51 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 12:05:47 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Schlechta", "Karl", ""]]}, {"id": "1902.09539", "submitter": "Thomas Powell", "authors": "Thomas Powell", "title": "Dependent choice as a termination principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new formulation of the axiom of dependent choice that can be\nviewed as an abstract termination principle, which generalises the recursive\npath orderings used to establish termination of rewrite systems. We consider\nseveral variants of our termination principle, and relate them to general\ntermination theorems in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:14:05 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "1902.09693", "submitter": "Satoshi Matsuoka", "authors": "Satoshi Matsuoka", "title": "A New Linear Time Correctness Condition for Multiplicative Linear Logic", "comments": "Found an bug in the proof of the linear time claim in the second\n  version. Adapted the algorithm in order to guarantee the linear time\n  termination. Added an additional example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a new linear time correctness condition for proof nets\nof Multiplicative Linear Logic without units. Our approach is based on a\nrewriting system over trees. We have only three rewrite rules. Compared with\nprevious linear time correctness conditions, our system is surprisingly simple\nand intuitively appealing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:30:29 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 02:02:12 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 08:35:05 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 01:01:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Matsuoka", "Satoshi", ""]]}, {"id": "1902.09844", "submitter": "Laura Giordano", "authors": "Laura Giordano and Alberto Policriti", "title": "Adding the Power-Set to Description Logics", "comments": "30 pages", "journal-ref": "Theoretical Computer Science, November 2019", "doi": "10.1016/j.tcs.2019.10.049", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the relationships between Description Logics and Set Theory. The\nstudy is carried on using, on the set-theoretic side, a very rudimentary\naxiomatic set theory Omega, consisting of only four axioms characterizing\nbinary union, set difference, inclusion, and the power-set. An extension of\nALC, ALC^Omega, is then defined in which concepts are naturally interpreted as\nsets living in Omega-models. In ALC^Omega not only membership between concepts\nis allowed---even admitting circularity---but also the power-set construct is\nexploited to add metamodeling capabilities. We investigate translations of\nALC^Omega into standard description logics as well as a set-theoretic\ntranslation. A polynomial encoding of ALC^Omega in ALCIO proves the validity of\nthe finite model property as well as an ExpTime upper bound on the complexity\nof concept satisfiability. We develop a set-theoretic translation of ALC^Omega\nin the theory Omega, exploiting a technique originally proposed for translating\nnormal modal and polymodal logics into Omega. Finally, we show that the\nfragment LC^Omega of ALC^Omega, which does not admit roles and individual\nnames, is as expressive as ALC^Omega.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:23:43 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 10:57:35 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 11:41:10 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Giordano", "Laura", ""], ["Policriti", "Alberto", ""]]}, {"id": "1902.09866", "submitter": "Jianlin Li", "authors": "Jianlin Li, Pengfei Yang, Jiangchao Liu, Liqian Chen, Xiaowei Huang\n  and Lijun Zhang", "title": "Analyzing Deep Neural Networks with Symbolic Propagation: Towards Higher\n  Precision and Faster Verification", "comments": "SAS 2019: 26th Static Analysis Symposium, Porto, Portugal, October\n  8-11, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32304-2_15", "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been shown lack of robustness for the\nvulnerability of their classification to small perturbations on the inputs.\nThis has led to safety concerns of applying DNNs to safety-critical domains.\nSeveral verification approaches have been developed to automatically prove or\ndisprove safety properties of DNNs. However, these approaches suffer from\neither the scalability problem, i.e., only small DNNs can be handled, or the\nprecision problem, i.e., the obtained bounds are loose. This paper improves on\na recent proposal of analyzing DNNs through the classic abstract interpretation\ntechnique, by a novel symbolic propagation technique. More specifically, the\nvalues of neurons are represented symbolically and propagated forwardly from\nthe input layer to the output layer, on top of abstract domains. We show that\nour approach can achieve significantly higher precision and thus can prove more\nproperties than using only abstract domains. Moreover, we show that the bounds\nderived from our approach on the hidden neurons, when applied to a\nstate-of-the-art SMT based verification tool, can improve its performance. We\nimplement our approach into a software tool and validate it over a few DNNs\ntrained on benchmark datasets such as MNIST, etc.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:23:00 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 15:38:49 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Li", "Jianlin", ""], ["Yang", "Pengfei", ""], ["Liu", "Jiangchao", ""], ["Chen", "Liqian", ""], ["Huang", "Xiaowei", ""], ["Zhang", "Lijun", ""]]}, {"id": "1902.09880", "submitter": "Antoine Amarilli", "authors": "Maurice Laveaux, Jan Friso Groote and Tim A.C. Willemse", "title": "Correct and Efficient Antichain Algorithms for Refinement Checking", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  1, 2021) lmcs:7143", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of refinement plays an important role in software engineering. It\nis the basis of a stepwise development methodology in which the correctness of\na system can be established by proving, or computing, that a system refines its\nspecification. Wang et al. describe algorithms based on antichains for\nefficiently deciding trace refinement, stable failures refinement and\nfailures-divergences refinement. We identify several issues pertaining to the\nsoundness and performance in these algorithms and propose new, correct,\nantichain-based algorithms. Using a number of experiments we show that our\nalgorithms outperform the original ones in terms of running time and memory\nusage. Furthermore, we show that additional run time improvements can be\nobtained by applying divergence-preserving branching bisimulation minimisation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 12:12:06 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 15:42:48 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 19:09:32 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 16:22:45 GMT"}, {"version": "v5", "created": "Thu, 28 Jan 2021 22:37:53 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Laveaux", "Maurice", ""], ["Groote", "Jan Friso", ""], ["Willemse", "Tim A. C.", ""]]}, {"id": "1902.09900", "submitter": "Sophie Tourret", "authors": "Sophie Tourret, Andrew Cropper", "title": "SLD-Resolution Reduction of Second-Order Horn Fragments -- technical\n  report --", "comments": "technical report, extends a conference paper accepted at JELIA 2019\n  with detailed proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the derivation reduction problem for SLD-resolution, the\nundecidable problem of finding a finite subset of a set of clauses from which\nthe whole set can be derived using SLD-resolution. We study the reducibility of\nvarious fragments of second-order Horn logic with particular applications in\nInductive Logic Programming. We also discuss how these results extend to\nstandard resolution.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 12:54:45 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Tourret", "Sophie", ""], ["Cropper", "Andrew", ""]]}, {"id": "1902.09927", "submitter": "EPTCS", "authors": "Ivan Proki\\'c (Faculty of Technical Sciences, University of Novi Sad,\n  Serbia)", "title": "The Cpi-calculus: a Model for Confidential Name Passing", "comments": "In Proceedings ICE 2019, arXiv:1909.05242", "journal-ref": "EPTCS 304, 2019, pp. 115-136", "doi": "10.4204/EPTCS.304.8", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing confidential information in distributed systems is a necessity in\nmany applications, however, it opens the problem of controlling information\nsharing even among trusted parties. In this paper, we present a formal model in\nwhich dissemination of information is disabled at the level of the syntax in a\ndirect way. We introduce a subcalculus of the pi-calculus in which channels are\nconsidered as confidential information. The only difference with respect to the\npi-calculus is that channels once received cannot be forwarded later on. By\nmeans of examples, we give an initial idea of how some privacy notions already\nstudied in the past, such as group creation and name hiding, can be represented\nwithout any additional language constructs. We also present an encoding of the\n(sum-free) pi-calculus in our calculus.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 13:43:37 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 13:53:12 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 22:25:35 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Proki\u0107", "Ivan", "", "Faculty of Technical Sciences, University of Novi Sad,\n  Serbia"]]}, {"id": "1902.10278", "submitter": "Adilson Bonifacio", "authors": "Adilson Luiz Bonifacio and Arnaldo Vieira Moura", "title": "A conformance relation and complete test suites for I/O systems", "comments": "44 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model based testing is a well-established approach to verify implementations\nmodeled by I/O labeled transition systems (IOLTSs). One of the challenges\nstemming from model based testing is the conformance checking and the\ngeneration of test suites, specially when completeness is a required property.\nIn order to check whether an implementation under test is in compliance with\nits respective specification one resorts to some form of conformance relation\nthat guarantees the expected behavior of the implementations, given the\nbehavior of the specification. The ioco conformance relation is an example of\nsuch a relation, specially suited for asynchronous models. In this work we\nstudy a more general conformance relation, show how to generate finite and\ncomplete test suites, and discuss the complexity of the test generation\nmechanism under this more general conformance relation. We also show that ioco\nconformance is a special case of this new conformance relation, and we\ninvestigate the complexity of classical ioco-complete test suites. Further, we\nrelate our contributions to more recent works, accommodating the restrictions\nof their classes of fault models within our more general approach as special\ncases, and expose the complexity of generating any complete test suite that\nmust satisfy their restrictions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 17:12:53 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 22:45:07 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 17:31:31 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Bonifacio", "Adilson Luiz", ""], ["Moura", "Arnaldo Vieira", ""]]}, {"id": "1902.10396", "submitter": "Dominik Wagner", "authors": "C.-H. Luke Ong and Dominik Wagner", "title": "HoCHC: A Refutationally Complete and Semantically Invariant System of\n  Higher-order Logic Modulo Theories", "comments": null, "journal-ref": null, "doi": "10.1109/LICS.2019.8785784", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple resolution proof system for higher-order constrained Horn\nclauses (HoCHC) - a system of higher-order logic modulo theories - and prove\nits soundness and refutational completeness w.r.t. the standard semantics. As\ncorollaries, we obtain the compactness theorem and semi-decidability of HoCHC\nfor semi-decidable background theories, and we prove that HoCHC satisfies a\ncanonical model property. Moreover a variant of the well-known translation from\nhigher-order to 1st-order logic is shown to be sound and complete for HoCHC in\nstandard semantics. We illustrate how to transfer decidability results for\n(fragments of) 1st-order logic modulo theories to our higher-order setting,\nusing as example the Bernays-Schonfinkel-Ramsey fragment of HoCHC modulo a\nrestricted form of Linear Integer Arithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 08:58:33 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 17:32:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ong", "C. -H. Luke", ""], ["Wagner", "Dominik", ""]]}, {"id": "1902.10452", "submitter": "Amaury Pouly", "authors": "Rupak Majumdar, Jo\\\"el Ouaknine, Amaury Pouly, James Worrell", "title": "Algebraic Invariants for Linear Hybrid Automata", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2020.32", "report-no": null, "categories": "cs.LO math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit an algorithm to compute the strongest algebraic (or polynomial)\ninvariants that hold at each location of a given unguarded linear hybrid\nautomaton (i.e., a hybrid automaton having only unguarded transitions, all of\nwhose assignments are given by affine expressions, and all of whose continuous\ndynamics are given by linear differential equations). Our main tool is a\ncontrol-theoretic result of independent interest: given such a linear hybrid\nautomaton, we show how to discretise the continuous dynamics in such a way that\nthe resulting automaton has precisely the same algebraic invariants.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 10:57:16 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Majumdar", "Rupak", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Pouly", "Amaury", ""], ["Worrell", "James", ""]]}, {"id": "1902.10820", "submitter": "Nicolai Kraus", "authors": "Gun Pinyo and Nicolai Kraus", "title": "From Cubes to Twisted Cubes via Graph Morphisms in Type Theory", "comments": "v4: 18 pages, postproceedings of TYPES'2019", "journal-ref": null, "doi": "10.4230/LIPIcs.TYPES.2019.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cube categories are used to encode higher-dimensional categorical structures.\nThey have recently gained significant attention in the community of homotopy\ntype theory and univalent foundations, where types carry the structure of such\nhigher groupoids. Bezem, Coquand, and Huber have presented a constructive model\nof univalence using a specific cube category, which we call the BCH category.\n  The higher categories encoded with the BCH category have the property that\nall morphisms are invertible, mirroring the fact that equality is symmetric.\nThis might not always be desirable: the field of directed type theory considers\na notion of equality that is not necessarily invertible.\n  This motivates us to suggest a category of twisted cubes which avoids\nbuilt-in invertibility. Our strategy is to first develop several alternative\n(but equivalent) presentations of the BCH category using morphisms between\nsuitably defined graphs. Starting from there, a minor modification allows us to\ndefine our category of twisted cubes. We prove several first results about this\ncategory, and our work suggests that twisted cubes combine properties of cubes\nwith properties of globes and simplices (tetrahedra).\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 22:53:38 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 23:16:43 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 22:14:51 GMT"}, {"version": "v4", "created": "Sun, 19 Jul 2020 19:20:21 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pinyo", "Gun", ""], ["Kraus", "Nicolai", ""]]}, {"id": "1902.10971", "submitter": "Pierre Hyvernat", "authors": "Pierre Hyvernat", "title": "Representing Continuous Functions between Greatest Fixed Points of\n  Indexed Containers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a way to represent computable functions between coinductive types\nas particular transducers in type theory. This generalizes earlier work on\nfunctions between streams by P. Hancock to a much richer class of coinductive\ntypes. Those transducers can be defined in dependent type theory without any\nnotion of equality but require inductive-recursive definitions. Most of the\nproperties of these constructions only rely on a mild notion of equality\n(intensional equality) and can thus be formalized in the dependently typed\nlanguage Agda.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 09:35:06 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 08:44:15 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 06:27:10 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 14:04:17 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Hyvernat", "Pierre", ""]]}, {"id": "1902.11189", "submitter": "Fredrik Dahlqvist", "authors": "Fredrik Dahlqvist and Dexter Kozen", "title": "Semantics of higher-order probabilistic programs with conditioning", "comments": "17 pages, proofs in the Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a denotational semantics for higher-order probabilistic programs\nin terms of linear operators between Banach spaces. Our semantics is rooted in\nthe classical theory of Banach spaces and their tensor products, but bears\nsimilarities with the well-known Scott semantics of higher-order programs\nthrough the use ordered Banach spaces which allow definitions in terms of fixed\npoints. Being based on a monoidal rather than cartesian closed structure, our\nsemantics effectively treats randomness as a resource.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:17:33 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Kozen", "Dexter", ""]]}, {"id": "1902.11263", "submitter": "Pierre-Alain Reynier", "authors": "Pierre-Alain Reynier and Didier Villevalois", "title": "Sequentiality of String-to-Context Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transducers extend finite state automata with outputs, and describe\ntransformations from strings to strings. Sequential transducers, which have a\ndeterministic behaviour regarding their input, are of particular interest.\nHowever, unlike finite-state automata, not every transducer can be made\nsequential. The seminal work of Choffrut allows to characterise, amongst the\nfunctional one-way transducers, the ones that admit an equivalent sequential\ntransducer. In this work, we extend the results of Choffrut to the class of\ntransducers that produce their output string by adding simultaneously, at each\ntransition, a string on the left and a string on the right of the string\nproduced so far. We call them the string-to-context transducers. We obtain a\nmultiple characterisation of the functional string-to-context transducers\nadmitting an equivalent sequential one, based on a Lipschitz property of the\nfunction realised by the transducer, and on a pattern (a new twinning\nproperty). Last, we prove that given a string-to-context transducer,\ndetermining whether there exists an equivalent sequential one is in coNP.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:10:59 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Reynier", "Pierre-Alain", ""], ["Villevalois", "Didier", ""]]}]