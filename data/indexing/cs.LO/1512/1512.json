[{"id": "1512.00550", "submitter": "Shichao Liu", "authors": "Shichao Liu and Ying Jiang", "title": "Value-passing CCS for Trees: A Theory for Concurrent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the theory CCS for trees (CCTS) to value-passing\nCCTS (VCCTS), of which symbols have the capacity for receiving and sending data\nvalues, and a nonsequential semantics is proposed in an operational approach.\nIn this concurrent model, a weak barbed congruence and a localized early weak\nbisimilarity are defined, and the latter relation is proved to be sufficient to\njustify the former. As an illustration of potential applications of VCCTS, a\nsemantics based on VCCTS is given to a toy multi-threaded programming language\nfeaturing a core of C/C++ concurrency; and a formalization based on the\noperational semantics of VCCTS is proposed for some relaxed memory models, and\na DRF-guarantee property with respect to VCCTS is proved.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 02:54:52 GMT"}, {"version": "v2", "created": "Sun, 24 Apr 2016 06:44:43 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Liu", "Shichao", ""], ["Jiang", "Ying", ""]]}, {"id": "1512.01041", "submitter": "Pietro Codara", "authors": "Stefano Aguzzoli, Pietro Codara, Tommaso Flaminio, Brunella Gerla,\n  Diego Valota", "title": "Querying with {\\L}ukasiewicz logic", "comments": null, "journal-ref": "2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),\n  pp.1-8", "doi": "10.1109/FUZZ-IEEE.2015.7338061", "report-no": null, "categories": "cs.LO cs.AI cs.DB math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present, by way of case studies, a proof of concept, based\non a prototype working on a automotive data set, aimed at showing the potential\nusefulness of using formulas of {\\L}ukasiewicz propositional logic to query\ndatabases in a fuzzy way. Our approach distinguishes itself for its stress on\nthe purely linguistic, contraposed with numeric, formulations of queries. Our\nqueries are expressed in the pure language of logic, and when we use (integer)\nnumbers, these stand for shortenings of formulas on the syntactic level, and\nserve as linguistic hedges on the semantic one. Our case-study queries aim\nfirst at showing that each numeric-threshold fuzzy query is simulated by a\n{\\L}ukasiewicz formula. Then they focus on the expressing power of\n{\\L}ukasiewicz logic which easily allows for updating queries by clauses and\nfor modifying them through a potentially infinite variety of linguistic hedges\nimplemented with a uniform syntactic mechanism. Finally we shall hint how,\nalready at propositional level, {\\L}ukasiewicz natural semantics enjoys a\ndegree of reflection, allowing to write syntactically simple queries that\nsemantically work as meta-queries weighing the contribution of simpler ones.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 11:26:40 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Aguzzoli", "Stefano", ""], ["Codara", "Pietro", ""], ["Flaminio", "Tommaso", ""], ["Gerla", "Brunella", ""], ["Valota", "Diego", ""]]}, {"id": "1512.01416", "submitter": "Richard Bornat", "authors": "Richard Bornat (1), Jade Alglave (2 and 3) and Matthew Parkinson (3)\n  ((1) Middlesex University, London, (2) University College, London, (3)\n  Microsoft Research)", "title": "New Lace and Arsenic: adventures in weak memory with a program logic", "comments": "This paper reports the joint work of its authors. But the words in\n  the paper were written by Richard Bornat. Any opprobrium, bug reports,\n  complaints, and observations about sins of com- mission or omission should be\n  directed at him. R.Bornat@mdx.ac.uk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a program logic for weak memory (also known as relaxed memory).\nThe logic is based on Hoare logic within a thread, and rely/guarantee between\nthreads. It is presented via examples, giving proofs of many weak-memory litmus\ntests. It extends to coherence but not yet to synchronised assignment\n(compare-and-swap, load-logical/store-conditional). It deals with conditionals\nand loops but not yet arrays or heap.\n  The logic uses a version of Hoare logic within threads, and a version of\nrely/guarantee between threads, with five stability rules to handle various\nkinds of parallelism (external, internal, propagation-free and two kinds of\nin-flight parallelism). There are $\\mathbb{B}$ and $\\mathbb{U}$ modalities to\nregulate propagation, and temporal modalities $\\mathsf{since}$,\n$\\mathbb{S}\\mathsf{ofar}$ and $\\mathbb{O}\\mathsf{uat}$ to deal with global\ncoherence (SC per location).\n  The logic is presented by example. Proofs and unproofs of about thirty\nweak-memory examples, including many litmus tests in various guises, are dealt\nwith in detail. There is a proof of a version of the token ring.\n  In version 2: The correspondence with Herding Cats has been clarified. The\nstability rules have been simplified: in particular the sat and x= x tests have\nbeen eliminated from external stability checks. The embedding is simplified and\nhas a more transparent relation to the mechanisms of the logic. Definitions of\nU, Sofar and Ouat have been considerably altered. The description of modalities\nand the treatment of termination has been reworked. Many proofs are\nreconstructed. A comprehensive summary of the logic is an appendix.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 14:19:01 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 16:18:44 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Bornat", "Richard", "", "2 and 3"], ["Alglave", "Jade", "", "2 and 3"], ["Parkinson", "Matthew", ""]]}, {"id": "1512.01837", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling", "title": "Type Theory and its Meaning Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of intuitionistic type theory lies an intuitive semantics called\nthe \"meaning explanations\"; crucially, when meaning explanations are taken as\ndefinitive for type theory, the core notion is no longer \"proof\" but\n\"verification\". We'll explore how type theories of this sort arise naturally as\nenrichments of logical theories with further judgements, and contrast this with\nmodern proof-theoretic type theories which interpret the judgements and proofs\nof logics, not their propositions and verifications.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 21:29:30 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 23:46:26 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Sterling", "Jonathan", ""]]}, {"id": "1512.01952", "submitter": "Kamila Barylska", "authors": "Kamila Barylska and Edward Ochma\\'nski", "title": "Hierarchy of persistence with respect to the length of action's\n  disability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of persistence, based on the rule \"no action can disable another\none\" is one of the classical notions in concurrency theory. It is also one of\nthe issues discussed in the Petri net theory. We recall two ways of\ngeneralization of this notion: the first is \"no action can kill another one\"\n(called l/l-persistence) and the second \"no action can kill another enabled\none\" (called the delayed persistence, or shortly e/l-persistence). Afterwards\nwe introduce a more precise notion, called e/l-k-persistence, in which one\naction disables another one for no longer than a specified number k of single\nsequential steps. Then we consider an infinite hie\\-rarchy of such e/l-k\npersistencies. We prove that if an action is disabled, and not killed, by\nanother one, it can not be postponed indefinitely. Afterwards, we investigate\nthe set of markings in which two actions are enabled simultaneously, and also\nthe set of reachable markings with that feature. We show that the minimum of\nthe latter is finite and effectively computable. Finally we deal with decision\nproblems about e/l-k persistencies. We show that all the kinds of e/l-k\npersistencies are decidable with respect to steps, markings and nets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 09:29:07 GMT"}, {"version": "v2", "created": "Tue, 22 Mar 2016 14:31:26 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Barylska", "Kamila", ""], ["Ochma\u0144ski", "Edward", ""]]}, {"id": "1512.02078", "submitter": "Yanjing Wang", "authors": "Kai Li and Yanjing Wang", "title": "From rules to runs: A dynamic epistemic take on imperfect information\n  games", "comments": "draft of a paper accepted by Studies in Logic (published by Sun\n  Yat-Sen University)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature of game theory, the information sets of extensive form\ngames have different interpretations, which may lead to confusions and\nparadoxical cases. We argue that the problem lies in the mix-up of two\ninterpretations of the extensive form game structures: game rules or game runs\nwhich do not always coincide. In this paper, we try to separate and connect\nthese two views by proposing a dynamic epistemic framework in which we can\ncompute the runs step by step from the game rules plus the given assumptions of\nthe players. We propose a modal logic to describe players' knowledge and its\nchange during the plays, and provide a complete axiomatization. We also show\nthat, under certain conditions, the mix-up of the rules and the runs is not\nharmful due to the structural similarity of the two.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 15:01:18 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Li", "Kai", ""], ["Wang", "Yanjing", ""]]}, {"id": "1512.02215", "submitter": "EPTCS", "authors": "Alexei Lisitsa (The University of Liverpool), Andrei P. Nemytykh\n  (Program Systems Institute of Russian Academy of Sciences), Alberto\n  Pettorossi (University of Roma Tor Vergata)", "title": "Proceedings of the Third International Workshop on Verification and\n  Program Transformation", "comments": null, "journal-ref": "EPTCS 199, 2015", "doi": "10.4204/EPTCS.199", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers selected among those which were presented at\nthe 3rd International Workshop on Verification and Program Transformation (VPT\n2015) held in London, UK, on April 11th, 2015. Previous editions of the\nWorkshop were held at Saint-Petersburg (Russia) in 2013, and Vienna (Austria)\nin 2014.\n  Those papers show that methods and tools developed in the field of program\ntransformation such as partial evaluation and fold/unfold transformations, and\nsupercompilation, can be applied in the verification of software systems. They\nalso show how some program verification methods, such as model checking\ntechniques, abstract interpretation, SAT and SMT solving, and automated theorem\nproving, can be used to enhance program transformation techniques, thereby\nmaking these techniques more powerful and useful in practice.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 00:30:58 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Lisitsa", "Alexei", "", "The University of Liverpool"], ["Nemytykh", "Andrei P.", "", "Program Systems Institute of Russian Academy of Sciences"], ["Pettorossi", "Alberto", "", "University of Roma Tor Vergata"]]}, {"id": "1512.02791", "submitter": "Yves Bertot", "authors": "Sophie Bernard (MARELLE), Yves Bertot (MARELLE), Laurence Rideau\n  (MARELLE), Pierre-Yves Strub", "title": "Formal Proofs of Transcendence for e and $\\pi$ as an Application of\n  Multivariate and Symmetric Polynomials", "comments": "in Jeremy Avigad and Adam Chlipala. Certified Programs and Proofs,\n  Jan 2016, St Petersburg, Florida, United States. ACM Press, pp.12, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the formalisation in Coq of a proof that the numbers e and $\\pi$\nare transcendental. This proof lies at the interface of two domains of\nmathematics that are often considered separately: calculus (real and elementary\ncomplex analysis) and algebra. For the work on calculus, we rely on the\nCoquelicot library and for the work on algebra, we rely on the Mathematical\nComponents library. Moreover, some of the elements of our formalized proof\noriginate in the more ancient library for real numbers included in the Coq\ndistribution. The case of $\\pi$ relies extensively on properties of\nmultivariate polynomials and this experiment was also an occasion to put to\ntest a newly developed library for these multivariate polynomials.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 08:53:42 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Bernard", "Sophie", "", "MARELLE"], ["Bertot", "Yves", "", "MARELLE"], ["Rideau", "Laurence", "", "MARELLE"], ["Strub", "Pierre-Yves", ""]]}, {"id": "1512.02995", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "A token-passing net implementation of optimal reduction with embedded\n  read-back", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new interaction net implementation of optimal\nreduction for pure untyped lambda calculus. Unlike others, our implementation\nallows to reach normal form regardless of interaction net reduction strategy\nusing the approach of so-called token-passing nets. Another new feature is the\nread-back mechanism also implemented without leaving the formalism of\ninteraction nets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 19:01:32 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 05:15:14 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1512.03024", "submitter": "Arno Pauly", "authors": "Arno Pauly and Florian Steinberg", "title": "Comparing representations for function spaces in computable analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper compares different representations (in the sense of computable\nanalysis) of a number of function spaces that are of interest in analysis. In\nparticular subspace representations inherited from a larger function space are\ncompared to more natural representations for these spaces. The formal framework\nfor the comparisons is provided by Weihrauch reducibility.\n  The centrepiece of the paper considers several representations of the\nanalytic functions on the unit disk and their mutual translations. All\ntranslations that are not already computable are shown to be Weihrauch\nequivalent to closed choice on the natural numbers. Subsequently some similar\nconsiderations are carried out for representations of polynomials. In this case\nin addition to closed choice the Weihrauch degree LPO* shows up as the\ndifficulty of finding the degree or the zeros. As a final example, the smooth\nfunctions are contrasted with functions with bounded support and Schwartz\nfunctions. Here closed choice on the natural numbers and the lim degree appear.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 20:00:37 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 20:59:06 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Pauly", "Arno", ""], ["Steinberg", "Florian", ""]]}, {"id": "1512.03127", "submitter": "Marcel Jackson G", "authors": "Marcel Jackson", "title": "Flexible constraint satisfiability and a problem in semigroup theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine some flexible notions of constraint satisfaction, observing some\nrelationships between model theoretic notions of universal Horn class\nmembership and robust satisfiability. We show the \\texttt{NP}-completeness of\n$2$-robust monotone 1-in-3 3SAT in order to give very small examples of finite\nalgebras with \\texttt{NP}-hard variety membership problem. In particular we\ngive a $3$-element algebra with this property, and solve a widely stated\nproblem by showing that the $6$-element Brandt monoid has \\texttt{NP}-hard\nvariety membership problem. These are the smallest possible sizes for a general\nalgebra and a semigroup to exhibit \\texttt{NP}-hardness for the membership\nproblem of finite algebras in finitely generated varieties.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 02:31:37 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 09:41:53 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Jackson", "Marcel", ""]]}, {"id": "1512.03667", "submitter": "Jason Steinmetz Mr", "authors": "Jason W. Steinmetz", "title": "An Intuitively Complete Analysis of Godel's Incompleteness", "comments": "31 pages plus 2 appendices. In v2 multiple minor clarifications were\n  made, two errors were fixed, and PDF bookmarks were added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A detailed and rigorous analysis of G\\\"odel's proof of his first\nincompleteness theorem is presented. The purpose of this analysis is two-fold.\nThe first is to reveal what G\\\"odel actually proved to provide a clear and\nsolid foundation upon which to base future research. The second is to construct\na coherent explication of G\\\"odel's proof that is not only approachable by the\nnon-specialist, but also brings to light the core principles underlying\nG\\\"odel's proof.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 01:39:17 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 19:26:25 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Steinmetz", "Jason W.", ""]]}, {"id": "1512.03860", "submitter": "EPTCS", "authors": "Geoff Hamilton (School of Computing, Dublin City University)", "title": "Verifying Temporal Properties of Reactive Systems by Transformation", "comments": "In Proceedings VPT 2015, arXiv:1512.02215. This work was supported,\n  in part, by Science Foundation Ireland grant 10/CE/I1855 to Lero - the Irish\n  Software Engineering Research Centre (www.lero.ie), and by the School of\n  Computing, Dublin City University", "journal-ref": "EPTCS 199, 2015, pp. 33-49", "doi": "10.4204/EPTCS.199.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how program transformation techniques can be used for the\nverification of both safety and liveness properties of reactive systems. In\nparticular, we show how the program transformation technique distillation can\nbe used to transform reactive systems specified in a functional language into a\nsimplified form that can subsequently be analysed to verify temporal properties\nof the systems. Example systems which are intended to model mutual exclusion\nare analysed using these techniques with respect to both safety (mutual\nexclusion) and liveness (non-starvation), with the errors they contain being\ncorrectly identified.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 01:59:09 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Hamilton", "Geoff", "", "School of Computing, Dublin City University"]]}, {"id": "1512.03862", "submitter": "EPTCS", "authors": "Bishoksan Kafle (Roskilde University, Denmark), John P. Gallagher\n  (Roskilde University, Denmark and IMDEA Software Institute, Spain), Pierre\n  Ganty (IMDEA Software Institute, Spain)", "title": "Decomposition by tree dimension in Horn clause verification", "comments": "In Proceedings VPT 2015, arXiv:1512.02215", "journal-ref": "EPTCS 199, 2015, pp. 1-14", "doi": "10.4204/EPTCS.199.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the use of the concept of tree dimension in Horn\nclause analysis and verification. The dimension of a tree is a measure of its\nnon-linearity - for example a list of any length has dimension zero while a\ncomplete binary tree has dimension equal to its height. We apply this concept\nto trees corresponding to Horn clause derivations. A given set of Horn clauses\nP can be transformed into a new set of clauses P=<k, whose derivation trees are\nthe subset of P's derivation trees with dimension at most k. Similarly, a set\nof clauses P>k can be obtained from P whose derivation trees have dimension at\nleast k + 1. In order to prove some property of all derivations of P, we\nsystematically apply these transformations, for various values of k, to\ndecompose the proof into separate proofs for P=<k and P>k (which could be\nexecuted in parallel). We show some preliminary results indicating that\ndecomposition by tree dimension is a potentially useful proof technique. We\nalso investigate the use of existing automatic proof tools to prove some\ninteresting properties about dimension(s) of feasible derivation trees of a\ngiven program.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 02:02:27 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Kafle", "Bishoksan", "", "Roskilde University, Denmark"], ["Gallagher", "John P.", "", "Roskilde University, Denmark and IMDEA Software Institute, Spain"], ["Ganty", "Pierre", "", "IMDEA Software Institute, Spain"]]}, {"id": "1512.03868", "submitter": "Michael Bukatin", "authors": "Michael A. Bukatin", "title": "Mathematics of Domains", "comments": "135 pages, PhD Thesis, 2002, Department of Computer Science, Brandeis\n  University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two groups of naturally arising questions in the mathematical theory of\ndomains for denotational semantics are addressed. Domains are equipped with\nScott topology and represent data types. Scott continuous functions represent\ncomputable functions and form the most popular continuous model of\ncomputations.\n  Covariant Logic of Domains: Domains are represented as sets of theories, and\nScott continuous functions are represented as input-output inference engines.\nThe questions addressed are: A. What constitutes a subdomain? Do subdomains of\na given domain $A$ form a domain? B. Which retractions are finitary? C. What is\nthe essence of generalizations of information systems based on non-reflexive\nlogics? Are these generalizations restricted to continuous domains?\n  Analysis on Domains:\n  D. How to describe Scott topologies via generalized distance functions\nsatisfying the requirement of Scott continuity (\"abstract computability\")? The\nanswer is that the axiom $\\rho (x, x) = 0$ is incompatible with Scott\ncontinuity of distance functions. The resulting \\bf relaxed metrics are\nstudied.\n  E. Is it possible to obtain Scott continuous relaxed metrics via measures of\ndomain subsets representing positive and negative information about domain\nelements? The positive answer is obtained via the discovery of the novel class\nof co-continuous valuations on the systems of Scott open sets.\n  Some of these natural questions were studied earlier. However, in each case a\nnovel approach is presented, and the answers are supplied with much more\ncompelling and clear justifications, than were known before.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 03:36:23 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Bukatin", "Michael A.", ""]]}, {"id": "1512.03899", "submitter": "Mathew Joseph", "authors": "Mathew Joseph, Gabriel Kuper, Till Mossakowski, Luciano Serafini", "title": "Query Answering over Contextualized RDF/OWL Knowledge with\n  Forall-Existential Bridge Rules: Decidable Finite Extension Classes (Post\n  Print)", "comments": null, "journal-ref": "Semantic Web (IOS Press) Vol 7:1 Pages 25-61. 2016", "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of contextualized knowledge in the Semantic Web (SW) has\nled to the popularity of knowledge formats such as \\emph{quads} in the SW\ncommunity. A quad is an extension of an RDF triple with contextual information\nof the triple. In this paper, we study the problem of query answering over\nquads augmented with forall-existential bridge rules that enable\ninteroperability of reasoning between triples in various contexts. We call a\nset of quads together with such expressive bridge rules, a quad-system. Query\nanswering over quad-systems is undecidable, in general. We derive decidable\nclasses of quad-systems, for which query answering can be done using forward\nchaining. Sound, complete and terminating procedures, which are adaptations of\nthe well known chase algorithm, are provided for these classes for deciding\nquery entailment. Safe, msafe, and csafe class of quad-systems restrict the\nstructure of blank nodes generated during the chase computation process to be\ndirected acyclic graphs (DAGs) of bounded depth. RR and restricted RR classes\ndo not allow the generation of blank nodes during the chase computation\nprocess. Both data and combined complexity of query entailment has been\nestablished for the classes derived. We further show that quad-systems are\nequivalent to forall-existential rules whose predicates are restricted to\nternary arity, modulo polynomial time translations. We subsequently show that\nthe technique of safety, strictly subsumes in expressivity, some of the well\nknown and expressive techniques, such as joint acyclicity and model faithful\nacyclicity, used for decidability guarantees in the realm of forall-existential\nrules.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 09:56:38 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Joseph", "Mathew", ""], ["Kuper", "Gabriel", ""], ["Mossakowski", "Till", ""], ["Serafini", "Luciano", ""]]}, {"id": "1512.04013", "submitter": "Andrew Santosa", "authors": "Andrew E. Santosa", "title": "Comparing Weakest Precondition and Weakest Liberal Precondition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we investigate the relationships between the classical\nnotions of weakest precondition and weakest liberal precondition, and provide\nseveral results, namely that in general, weakest liberal precondition is\nneither stronger nor weaker than weakest precondition, however, given a\ndeterministic and terminating sequential while program and a postcondition,\nthey are equivalent. Hence, in such situation, it does not matter which\ndefinition is used.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 07:32:01 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Santosa", "Andrew E.", ""]]}, {"id": "1512.04021", "submitter": "Guido Governatori", "authors": "Guido Governatori, Francesco Olivieri, Simone Scannapieco, Antonino\n  Rotolo and Matteo Cristani", "title": "The Rationale behind the Concept of Goal", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 16 (2016) 296-324", "doi": "10.1017/S1471068416000053", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a fresh look at the concept of goal and advances that\nmotivational attitudes like desire, goal and intention are just facets of the\nbroader notion of (acceptable) outcome. We propose to encode the preferences of\nan agent as sequences of \"alternative acceptable outcomes\". We then study how\nthe agent's beliefs and norms can be used to filter the mental attitudes out of\nthe sequences of alternative acceptable outcomes. Finally, we formalise such\nintuitions in a novel Modal Defeasible Logic and we prove that the resulting\nformalisation is computationally feasible.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 09:19:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Governatori", "Guido", ""], ["Olivieri", "Francesco", ""], ["Scannapieco", "Simone", ""], ["Rotolo", "Antonino", ""], ["Cristani", "Matteo", ""]]}, {"id": "1512.04255", "submitter": "Guillermo P\\'erez", "authors": "Guillermo A. P\\'erez", "title": "The Fixed Initial Credit Problem for Partial-Observation Energy Games is\n  Ack-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study two-player games with asymmetric partial observation\nand an energy objective. Such games are played on a weighted automaton by Eve,\nchoosing actions, and Adam, choosing a transition labelled with the given\naction. Eve attempts to maintain the sum of the weights (of the transitions\ntaken) non-negative while Adam tries to do the opposite. Eve does not know the\nexact state of the game, she is only given an equivalence class of states which\ncontains it. In contrast, Adam has full observation. We show the fixed initial\ncredit problem for these games is Ack-complete.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 11:06:33 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2015 15:08:23 GMT"}, {"version": "v3", "created": "Sun, 27 Dec 2015 18:47:29 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2016 17:04:08 GMT"}, {"version": "v5", "created": "Sun, 14 Feb 2016 16:41:46 GMT"}, {"version": "v6", "created": "Wed, 16 Nov 2016 07:29:20 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["P\u00e9rez", "Guillermo A.", ""]]}, {"id": "1512.04639", "submitter": "Michael Bukatin", "authors": "Michael Bukatin and Steve Matthews", "title": "Linear Models of Computation and Program Learning", "comments": "13 pages; September 3, 2015 version; to appear in the Proceedings of\n  GCAI 2015, Tbilisi, Georgia, Oct.16-18, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two classes of computations which admit taking linear\ncombinations of execution runs: probabilistic sampling and generalized\nanimation. We argue that the task of program learning should be more tractable\nfor these architectures than for conventional deterministic programs. We look\nat the recent advances in the \"sampling the samplers\" paradigm in higher-order\nprobabilistic programming. We also discuss connections between partial\ninconsistency, non-monotonic inference, and vector semantics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 04:13:51 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Bukatin", "Michael", ""], ["Matthews", "Steve", ""]]}, {"id": "1512.04964", "submitter": "Max Kanovich", "authors": "Max Kanovich", "title": "Horn Linear Logic and Minsky Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we give a detailed proof for the crucial point in our Minsky machine\nsimulation - that any linear logic derivation for a specific Horn sequent can\nbe transformed into a Minsky computation leading from an initial configuration\nto the halting configuration.\n  Among other things, the presentation advantage of the 3-step program is that\nthe non-trivial tricky points are distributed between the independent parts\neach of which we justify following its own intrinsic methodology (to say\nnothing of the induction used in the opposite directions):\n  (1) From LL to HLL - we use purely proof-theoretic arguments.\n  (2) From HLL to Horn programs - we translate trees (HLL derivations) into\nanother trees (Horn programs)of the same shape, almost.\n  (3) From Horn programs to Minsky computations - we use purely computational\narguments.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 21:12:29 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Kanovich", "Max", ""]]}, {"id": "1512.05177", "submitter": "Alexander Weinert", "authors": "Alexander Weinert and Martin Zimmermann", "title": "Visibly Linear Dynamic Logic", "comments": "25 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Visibly Linear Dynamic Logic (VLDL), which extends Linear\nTemporal Logic (LTL) by temporal operators that are guarded by visibly pushdown\nlanguages over finite words. In VLDL one can, e.g., express that a function\nresets a variable to its original value after its execution, even in the\npresence of an unbounded number of intermediate recursive calls. We prove that\nVLDL describes exactly the $\\omega$-visibly pushdown languages. Thus it is\nstrictly more expressive than LTL and able to express recursive properties of\nprograms with unbounded call stacks.\n  The main technical contribution of this work is a translation of VLDL into\n$\\omega$-visibly pushdown automata of exponential size via one-way alternating\njumping automata. This translation yields exponential-time algorithms for\nsatisfiability, validity, and model checking. We also show that visibly\npushdown games with VLDL winning conditions are solvable in triply-exponential\ntime. We prove all these problems to be complete for their respective\ncomplexity classes.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 14:12:03 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 15:18:31 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Weinert", "Alexander", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1512.05313", "submitter": "Valentin Blot", "authors": "Valentin Blot (University of Bath)", "title": "Typed realizability for first-order classical analysis", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  31, 2015) lmcs:1623", "doi": "10.2168/LMCS-11(4:22)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a realizability framework for classical first-order logic in\nwhich realizers live in (a model of) typed {\\lambda}{\\mu}-calculus. This allows\na direct interpretation of classical proofs, avoiding the usual negative\ntranslation to intuitionistic logic. We prove that the usual terms of G\\\"odel's\nsystem T realize the axioms of Peano arithmetic, and that under some\nassumptions on the computational model, the bar recursion operator realizes the\naxiom of dependent choice. We also perform a proper analysis of relativization,\nwhich allows for less technical proofs of adequacy. Extraction of algorithms\nfrom proofs of {\\Pi}02 formulas relies on a novel implementation of Friedman's\ntrick exploiting the control possibilities of the language. This allows to have\nextracted programs with simpler types than in the case of negative translation\nfollowed by intuitionistic realizability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 20:18:20 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2015 22:07:15 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Blot", "Valentin", "", "University of Bath"]]}, {"id": "1512.05511", "submitter": "Nils Vortmeier", "authors": "Pablo Mu\\~noz and Nils Vortmeier and Thomas Zeume", "title": "Dynamic Graph Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph databases in many applications---semantic web, transport or biological\nnetworks among others---are not only large, but also frequently modified.\nEvaluating graph queries in this dynamic context is a challenging task, as\nthose queries often combine first-order and navigational features.\n  Motivated by recent results on maintaining dynamic reachability, we study the\ndynamic evaluation of traditional query languages for graphs in the descriptive\ncomplexity framework. Our focus is on maintaining regular path queries, and\nextensions thereof, by first-order formulas. In particular we are interested in\npath queries defined by non-regular languages and in extended conjunctive\nregular path queries (which allow to compare labels of paths based on word\nrelations). Further we study the closely related problems of maintaining\ndistances in graphs and reachability in product graphs.\n  In this preliminary study we obtain upper bounds for those problems in\nrestricted settings, such as undirected and acyclic graphs, or under insertions\nonly, and negative results regarding quantifier-free update formulas. In\naddition we point out interesting directions for further research.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 09:46:42 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Mu\u00f1oz", "Pablo", ""], ["Vortmeier", "Nils", ""], ["Zeume", "Thomas", ""]]}, {"id": "1512.05568", "submitter": "Mickael Randour", "authors": "Romain Brenguier, Lorenzo Clemente, Paul Hunter, Guillermo A. P\\'erez,\n  Mickael Randour, Jean-Fran\\c{c}ois Raskin, Ocan Sankur, Mathieu Sassolas", "title": "Non-Zero Sum Games for Reactive Synthesis", "comments": "LATA'16 invited paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this invited contribution, we summarize new solution concepts useful for\nthe synthesis of reactive systems that we have introduced in several recent\npublications. These solution concepts are developed in the context of non-zero\nsum games played on graphs. They are part of the contributions obtained in the\ninVEST project funded by the European Research Council.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 13:02:03 GMT"}], "update_date": "2016-08-06", "authors_parsed": [["Brenguier", "Romain", ""], ["Clemente", "Lorenzo", ""], ["Hunter", "Paul", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Randour", "Mickael", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""], ["Sassolas", "Mathieu", ""]]}, {"id": "1512.05667", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Proof complexity of intuitionistic implicational formulas", "comments": "47 pages, 1 figure; to appear in Annals of Pure and Applied Logic", "journal-ref": "Annals of Pure and Applied Logic 168 (2017), no. 1, pp. 150--190", "doi": "10.1016/j.apal.2016.09.003", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study implicational formulas in the context of proof complexity of\nintuitionistic propositional logic (IPC). On the one hand, we give an efficient\ntransformation of tautologies to implicational tautologies that preserves the\nlengths of intuitionistic extended Frege (EF) or substitution Frege (SF) proofs\nup to a polynomial. On the other hand, EF proofs in the implicational fragment\nof IPC polynomially simulate full intuitionistic logic for implicational\ntautologies. The results also apply to other fragments of other\nsuperintuitionistic logics under certain conditions.\n  In particular, the exponential lower bounds on the length of intuitionistic\nEF proofs by Hrube\\v{s} \\cite{hru:lbint}, generalized to exponential separation\nbetween EF and SF systems in superintuitionistic logics of unbounded branching\nby Je\\v{r}\\'abek \\cite{ej:sfef}, can be realized by implicational tautologies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 16:50:32 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 18:06:04 GMT"}, {"version": "v3", "created": "Sun, 18 Sep 2016 12:30:16 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1512.05813", "submitter": "Bart Jacobs", "authors": "Kenta Cho, Bart Jacobs, Bas Westerbaan, Abraham Westerbaan", "title": "An Introduction to Effectus Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectus theory is a new branch of categorical logic that aims to capture the\nessentials of quantum logic, with probabilistic and Boolean logic as special\ncases. Predicates in effectus theory are not subobjects having a Heyting\nalgebra structure, like in topos theory, but `characteristic' functions,\nforming effect algebras. Such effect algebras are algebraic models of\nquantitative logic, in which double negation holds. Effects in quantum theory\nand fuzzy predicates in probability theory form examples of effect algebras.\n  This text is an account of the basics of effectus theory. It includes the\nfundamental duality between states and effects, with the associated Born rule\nfor validity of an effect (predicate) in a particular state. A basic result\nsays that effectuses can be described equivalently in both `total' and\n`partial' form. So-called `commutative' and `Boolean' effectuses are\ndistinguished, for probabilistic and classical models. It is shown how these\nBoolean effectuses are essentially extensive categories. A large part of the\ntheory is devoted to the logical notions of comprehension and quotient, which\nare described abstractly as right adjoint to truth, and as left adjoint to\nfalisity, respectively. It is illustrated how comprehension and quotients are\nclosely related to measurement. The paper closes with a section on\n`non-commutative' effectus theory, where the appropriate formalisation is not\nentirely clear yet.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 22:17:36 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Cho", "Kenta", ""], ["Jacobs", "Bart", ""], ["Westerbaan", "Bas", ""], ["Westerbaan", "Abraham", ""]]}, {"id": "1512.05949", "submitter": "Tim Jungnickel", "authors": "Tim Jungnickel and Tobias Herb", "title": "TP1-valid Transformation Functions for Operations on ordered n-ary Trees", "comments": "Extension/Report for the work \"Simultaneous Editing of JSON Objects\n  via Operational Transformation\" in ACM SAC '16", "journal-ref": null, "doi": "10.1145/2851613.2852003", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative work on shared documents was revolutionized by web services\nlike Google Docs or Etherpad. Multiple users can work on the same document in a\ncomfortable and distributed way. For the synchronization of the changes a\nreplication system named Operational Transformation is used. Such a system\nconsists of a control algorithm and a transformation function. In essence, a\ntransformation function solves the conflicts that arise when multiple users\nchange the document at the same time. In this work we investigate on the\ncorrectness of such transformation functions. We introduce transformation\nfunctions n-ary trees that we designed especially for the purpose of\nsynchronization changes on JSON objects. We provide a detailed proof of the\nnecessary property: the Transformation Property 1.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 13:41:10 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Jungnickel", "Tim", ""], ["Herb", "Tobias", ""]]}, {"id": "1512.05980", "submitter": "Tom Hirschowitz", "authors": "Richard Garner, Tom Hirschowitz (LAMA)", "title": "Shapely monads and analytic functors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.AT math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give precise mathematical form to the idea of a structure\nwhose data and axioms are faithfully represented by a graphical calculus; some\nprominent examples are operads, polycategories, properads, and PROPs. Building\non the established presentation of such structures as algebras for monads on\npresheaf categories, we describe a characteristic property of the associated\nmonads---the shapeliness of the title---which says that \"any two operations of\nthe same shape agree\". An important part of this work is the study of analytic\nfunctors between presheaf categories, which are a common generalisation of\nJoyal's analytic endofunctors on sets and of the parametric right adjoint\nfunctors on presheaf categories introduced by Diers and studied by\nCarboni--Johnstone, Leinster and Weber. Our shapely monads will be found among\nthe analytic endofunctors, and may be characterised as the submonads of a\nuniversal analytic monad with \"exactly one operation of each shape\". In fact,\nshapeliness also gives a way to define the data and axioms of a structure\ndirectly from its graphical calculus, by generating a free shapely monad on the\nbasic operations of the calculus. In this paper we do this for some of the\nexamples listed above; in future work, we intend to do so for graphical calculi\nsuch as Milner's bigraphs, Lafont's interaction nets, or Girard's\nmultiplicative proof nets, thereby obtaining canonical notions of denotational\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 15:02:40 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 08:55:08 GMT"}, {"version": "v3", "created": "Tue, 10 Oct 2017 13:59:11 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Garner", "Richard", "", "LAMA"], ["Hirschowitz", "Tom", "", "LAMA"]]}, {"id": "1512.06233", "submitter": "Samson Abramsky", "authors": "Samson Abramsky", "title": "Process Realizability", "comments": "Appeared in Foundations of Secure Computation: Proceedings of the\n  1999 Marktoberdorf Summer School, F. L. Bauer and R. Steinbruggen, eds. (IOS\n  Press) 2000, 167-180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a notion of realizability for Classical Linear Logic based on a\nconcurrent process calculus.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 12:29:30 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Abramsky", "Samson", ""]]}, {"id": "1512.06282", "submitter": "M. H. van Emden", "authors": "Philip Kelly and M.H. van Emden", "title": "Contributions to the compositional semantics of first-order predicate\n  logic", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": "DCS-356-IR", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Henkin, Monk and Tarski gave a compositional semantics for first-order\npredicate logic. We extend this work by including function symbols in the\nlanguage and by giving the denotation of the atomic formula as a composition of\nthe denotations of its predicate symbol and of its tuple of arguments. In\naddition we give the denotation of a term as a composition of the denotations\nof its function symbol and of its tuple of arguments.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 19:59:52 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Kelly", "Philip", ""], ["van Emden", "M. H.", ""]]}, {"id": "1512.06632", "submitter": "Zeno Toffano", "authors": "Zeno Toffano", "title": "Eigenlogic in the spirit of George Boole", "comments": "24 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an operational and geometric approach to logic. It starts\nfrom the multilinear elective decomposition of binary logical functions in the\noriginal form introduced by George Boole. A justification on historical grounds\nis presented bridging Boole's theory and the use of his arithmetical logical\nfunctions with the axioms of Boolean algebra using sets and quantum logic. It\nis shown that this algebraic polynomial formulation can be naturally extended\nto operators in finite vector spaces. Logical operators will appear as\ncommuting projection operators and the truth values, which take the binary\nvalues {0,1}, are the respective eigenvalues. In this view the solution of a\nlogical proposition resulting from the operation on a combination of arguments\nwill appear as a selection where the outcome can only be one of the\neigenvalues. In this way propositional logic can be formalized in linear\nalgebra by using elective developments which correspond here to combinations of\ntensored elementary projection operators. The original and principal motivation\nof this work is for applications in the new field of quantum information,\ndifferences are outlined with more traditional quantum logic approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 14:09:27 GMT"}, {"version": "v10", "created": "Thu, 16 Feb 2017 16:44:20 GMT"}, {"version": "v11", "created": "Mon, 5 Feb 2018 09:18:26 GMT"}, {"version": "v12", "created": "Tue, 6 Feb 2018 08:10:29 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2015 10:38:12 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2015 15:25:38 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2015 12:05:42 GMT"}, {"version": "v5", "created": "Fri, 1 Jan 2016 12:35:38 GMT"}, {"version": "v6", "created": "Thu, 16 Jun 2016 19:43:25 GMT"}, {"version": "v7", "created": "Sat, 18 Jun 2016 09:42:33 GMT"}, {"version": "v8", "created": "Wed, 1 Feb 2017 10:42:26 GMT"}, {"version": "v9", "created": "Fri, 10 Feb 2017 13:26:19 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Toffano", "Zeno", ""]]}, {"id": "1512.06633", "submitter": "Kuldeep Meel", "authors": "Kuldeep S. Meel, Moshe Vardi, Supratik Chakraborty, Daniel J. Fremont,\n  Sanjit A. Seshia, Dror Fried, Alexander Ivrii and Sharad Malik", "title": "Constrained Sampling and Counting: Universal Hashing Meets SAT Solving", "comments": "Appears in proceedings of AAAI-16 Workshop on Beyond NP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained sampling and counting are two fundamental problems in artificial\nintelligence with a diverse range of applications, spanning probabilistic\nreasoning and planning to constrained-random verification. While the theory of\nthese problems was thoroughly investigated in the 1980s, prior work either did\nnot scale to industrial size instances or gave up correctness guarantees to\nachieve scalability. Recently, we proposed a novel approach that combines\nuniversal hashing and SAT solving and scales to formulas with hundreds of\nthousands of variables without giving up correctness guarantees. This paper\nprovides an overview of the key ingredients of the approach and discusses\nchallenges that need to be overcome to handle larger real-world instances.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 14:10:10 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Meel", "Kuldeep S.", ""], ["Vardi", "Moshe", ""], ["Chakraborty", "Supratik", ""], ["Fremont", "Daniel J.", ""], ["Seshia", "Sanjit A.", ""], ["Fried", "Dror", ""], ["Ivrii", "Alexander", ""], ["Malik", "Sharad", ""]]}, {"id": "1512.06751", "submitter": "Noam Zeilberger", "authors": "Noam Zeilberger", "title": "Linear lambda terms as invariants of rooted trivalent maps", "comments": "accepted author manuscript, posted six months after publication", "journal-ref": "Journal of Functional Programming, 26, e21, 20 pages, 2016", "doi": "10.1017/S095679681600023X", "report-no": null, "categories": "cs.LO math.CO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main aim of the article is to give a simple and conceptual account for\nthe correspondence (originally described by Bodini, Gardy, and Jacquot) between\n$\\alpha$-equivalence classes of closed linear lambda terms and isomorphism\nclasses of rooted trivalent maps on compact oriented surfaces without boundary,\nas an instance of a more general correspondence between linear lambda terms\nwith a context of free variables and rooted trivalent maps with a boundary of\nfree edges. We begin by recalling a familiar diagrammatic representation for\nlinear lambda terms, while at the same time explaining how such diagrams may be\nread formally as a notation for endomorphisms of a reflexive object in a\nsymmetric monoidal closed (bi)category. From there, the \"easy\" direction of the\ncorrespondence is a simple forgetful operation which erases annotations on the\ndiagram of a linear lambda term to produce a rooted trivalent map. The other\ndirection views linear lambda terms as complete invariants of their underlying\nrooted trivalent maps, reconstructing the missing information through a\nTutte-style topological recurrence on maps with free edges. As an application\nin combinatorics, we use this analysis to enumerate bridgeless rooted trivalent\nmaps as linear lambda terms containing no closed proper subterms, and conclude\nby giving a natural reformulation of the Four Color Theorem as a statement\nabout typing in lambda calculus.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 18:38:31 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2016 12:32:50 GMT"}, {"version": "v3", "created": "Thu, 4 May 2017 13:32:59 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Zeilberger", "Noam", ""]]}, {"id": "1512.06813", "submitter": "Tim Boykett", "authors": "Tim Boykett", "title": "Closed Systems of Invertible Maps", "comments": "Submitted to the Journal for Multiple Valued Logic and Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise clones, which are sets of functions $f:A^n \\rightarrow A$, to\nsets of mappings $f:A^n \\rightarrow A^m$. We formalise this and develop\nlanguage that we can use to speak about it. We then look at bijective mappings,\nwhich have connections to reversible computation, which is important for\nphysical (e.g. quantum computation) as well as engineering (e.g. heat\ndissipation) reasons. We generalise Toffoli's seminal work on reversible\ncomputation to arbitrary arity logics. In particular, we show that some\nrestrictions he found for reversible computation on alphabets of order 2 do not\napply for odd order alphabets. For $A$ odd, we can create all invertible\nmappings from the Toffoli 1- and 2-gates, demonstrating that we can realise all\nreversible mappings from four generators. We discuss various forms of closure,\ncorresponding to various systems of permitted manipulations. These correspond,\namongst other things, to discussions about ancilla bits in quantum computation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 20:35:02 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 20:49:50 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Boykett", "Tim", ""]]}, {"id": "1512.06941", "submitter": "EPTCS", "authors": "Mar\\'ia Alpuente (DSIC-UPV), Daniel Pardo (DSIC-UPV), Alicia\n  Villanueva (DSIC-UPV)", "title": "Automatic Inference of Specifications in the K Framework", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 1-17", "doi": "10.4204/EPTCS.200.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its many unquestionable benefits, formal specifications are not\nwidely used in industrial software development. In order to reduce the time and\neffort required to write formal specifications, in this paper we propose a\ntechnique for automatically discovering specifications from real code. The\nproposed methodology relies on the symbolic execution capabilities recently\nprovided by the K framework that we exploit to automatically infer formal\nspecifications from programs that are written in a non-trivial fragment of C,\ncalled KernelC. Roughly speaking, our symbolic analysis of KernelC programs\nexplains the execution of a (modifier) function by using other (observer)\nroutines in the program. We implemented our technique in the automated tool\nKindspec 2.0, which generates axioms that describe the precise input/output\nbehavior of C routines that handle pointer-based structures (i.e., result\nvalues and state change). We describe the implementation of our system and\ndiscuss the differences w.r.t. our previous work on inferring specifications\nfrom C code.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:11 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Alpuente", "Mar\u00eda", "", "DSIC-UPV"], ["Pardo", "Daniel", "", "DSIC-UPV"], ["Villanueva", "Alicia", "", "DSIC-UPV"]]}, {"id": "1512.06942", "submitter": "EPTCS", "authors": "Salvador Lucas (DSIC, Universitat Polit\\`ecnica de Val\\`encia, Spain)", "title": "Termination of canonical context-sensitive rewriting and productivity of\n  rewrite systems", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 18-31", "doi": "10.4204/EPTCS.200.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Termination of programs, i.e., the absence of infinite computations, ensures\nthe existence of normal forms for all initial expressions, thus providing an\nessential ingredient for the definition of a normalization semantics for\nfunctional programs. In lazy functional languages, though, infinite data\nstructures are often delivered as the outcome of computations. For instance,\nthe list of all prime numbers can be returned as a neverending stream of\nnumerical expressions or data structures. If such streams are allowed,\nrequiring termination is hopeless. In this setting, the notion of productivity\ncan be used to provide an account of computations with infinite data\nstructures, as it \"captures the idea of computability, of progress of\ninfinite-list programs\" (B.A. Sijtsma, On the Productivity of Recursive List\nDefinitions, ACM Transactions on Programming Languages and Systems\n11(4):633-649, 1989). However, in the realm of Term Rewriting Systems, which\ncan be seen as (first-order, untyped, unconditional) functional programs,\ntermination of Context-Sensitive Rewriting (CSR) has been showed equivalent to\nproductivity of rewrite systems through appropriate transformations. In this\nway, tools for proving termination of CSR can be used to prove productivity. In\nterm rewriting, CSR is the restriction of rewriting that arises when reductions\nare allowed on selected arguments of function symbols only. In this paper we\nshow that well-known results about the computational power of CSR are useful to\nbetter understand the existing connections between productivity of rewrite\nsystems and termination of CSR, and also to obtain more powerful techniques to\nprove productivity of rewrite systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:22 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Lucas", "Salvador", "", "DSIC, Universitat Polit\u00e8cnica de Val\u00e8ncia, Spain"]]}, {"id": "1512.06943", "submitter": "EPTCS", "authors": "Salvador Lucas (DSIC, Universitat Polit\\`ecnica de Val\\`encia, Spain)", "title": "Synthesis of models for order-sorted first-order theories using linear\n  algebra and constraint solving", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 32-47", "doi": "10.4204/EPTCS.200.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in termination analysis for declarative programs\nemphasize the use of appropriate models for the logical theory representing the\nprogram at stake as a generic approach to prove termination of declarative\nprograms. In this setting, Order-Sorted First-Order Logic provides a powerful\nframework to represent declarative programs. It also provides a target logic to\nobtain models for other logics via transformations. We investigate the\nautomatic generation of numerical models for order-sorted first-order logics\nand its use in program analysis, in particular in termination analysis of\ndeclarative programs. We use convex domains to give domains to the different\nsorts of an order-sorted signature; we interpret the ranked symbols of sorted\nsignatures by means of appropriately adapted convex matrix interpretations.\nSuch numerical interpretations permit the use of existing algorithms and tools\nfrom linear algebra and arithmetic constraint solving to synthesize the models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:34 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Lucas", "Salvador", "", "DSIC, Universitat Polit\u00e8cnica de Val\u00e8ncia, Spain"]]}, {"id": "1512.06944", "submitter": "EPTCS", "authors": "David Romero-Hern\\'andez (Universidad Complutense de Madrid, Spain),\n  David de Frutos-Escrig (Universidad Complutense de Madrid, Spain), Dario\n  Della Monica (Reykjavik University, Iceland)", "title": "Proving Continuity of Coinductive Global Bisimulation Distances: A Never\n  Ending Story", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 48-63", "doi": "10.4204/EPTCS.200.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a notion of global bisimulation distance between processes\nwhich goes somehow beyond the notions of bisimulation distance already existing\nin the literature, mainly based on bisimulation games. Our proposal is based on\nthe cost of transformations: how much we need to modify one of the compared\nprocesses to obtain the other. Our original definition only covered finite\nprocesses, but a coinductive approach allows us to extend it to cover infinite\nbut finitary trees. After having shown many interesting properties of our\ndistance, it was our intention to prove continuity with respect to projections,\nbut unfortunately the issue remains open. Nonetheless, we have obtained several\npartial results that are presented in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:44 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Romero-Hern\u00e1ndez", "David", "", "Universidad Complutense de Madrid, Spain"], ["de Frutos-Escrig", "David", "", "Universidad Complutense de Madrid, Spain"], ["Della Monica", "Dario", "", "Reykjavik University, Iceland"]]}, {"id": "1512.06945", "submitter": "EPTCS", "authors": "Fernando S\\'aenz-P\\'erez (Universidad Complutense de Madrid)", "title": "Restricted Predicates for Hypothetical Datalog", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 64-79", "doi": "10.4204/EPTCS.200.5", "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothetical Datalog is based on an intuitionistic semantics rather than on a\nclassical logic semantics, and embedded implications are allowed in rule\nbodies. While the usual implication (i.e., the neck of a Horn clause) stands\nfor inferring facts, an embedded implication plays the role of assuming its\npremise for deriving its consequence. A former work introduced both a formal\nframework and a goal-oriented tabled implementation, allowing negation in rule\nbodies. While in that work positive assumptions for both facts and rules can\noccur in the premise, negative assumptions are not allowed. In this work, we\ncover this subject by introducing a new concept: a restricted predicate, which\nallows negative assumptions by pruning the usual semantics of a predicate. This\nnew setting has been implemented in the deductive system DES.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:55 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["S\u00e1enz-P\u00e9rez", "Fernando", "", "Universidad Complutense de Madrid"]]}, {"id": "1512.06947", "submitter": "EPTCS", "authors": "Jos\\'e Proen\\c{c}a, Massimo Tivoli", "title": "Proceedings 14th International Workshop on Foundations of Coordination\n  Languages and Self-Adaptive Systems", "comments": null, "journal-ref": "EPTCS 201, 2015", "doi": "10.4204/EPTCS.201", "report-no": null, "categories": "cs.DC cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of FOCLASA 2015, the 14th International\nWorkshop on the Foundations of Coordination Languages and Self-Adaptive\nSystems. FOCLASA 2015 was held in Madrid, Spain, on September 5, 2015 as a\nsatellite event of CONCUR 2015, the 26th International Conference on\nConcurrency Theory.\n  Modern software systems are distributed, concurrent, mobile, and often\ninvolve composition of heterogeneous components and stand-alone services.\nService coordination and self-adaptation constitute the core characteristics of\ndistributed and service-oriented systems. Coordination languages and formal\napproaches to modelling and reasoning about self-adaptive behaviour help to\nsimplify the development of complex distributed service-based systems, enable\nfunctional correctness proofs, automated synthesis of correct-by-construction\nsystems, and improve reusability and maintainability of such systems. The goal\nof the FOCLASA workshop is to put together researchers and practitioners of the\naforementioned fields, to share and identify common problems, and to devise\ngeneral solutions in the context of coordination languages and self-adaptive\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:30:13 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Proen\u00e7a", "Jos\u00e9", ""], ["Tivoli", "Massimo", ""]]}, {"id": "1512.07098", "submitter": "Mario Bravetti", "authors": "Mario Bravetti", "title": "Reduction Semantics in Markovian Process Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic (Markovian) process algebra extend classical process algebra with\nprobabilistic exponentially distributed time durations denoted by rates (the\nparameter of the exponential distribution). Defining a semantics for such an\nalgebra, so to derive Continuous Time Markov Chains from system specifications,\nrequires dealing with transitions labeled by rates. With respect to standard\nprocess algebra semantics this poses a problem: we have to take into account\nthe multiplicity of several identical transitions (with the same rate). Several\ntechniques addressing this problem have been introduced in the literature, but\nthey can only be used for semantic definitions that do not exploit a structural\ncongruence relation on terms while inferring transitions. On the other hand,\nusing a structural congruence relation is a useful mechanism that is commonly\nadopted, for instance, in order to define semantics in reduction style for\nnon-basic process algebras such as the pi-calculus or richer ones. In this\npaper we show how to define semantics for Markovian process algebra when\nstructural congruence is used while inferring transitions and, as an\napplication example, we define the reduction semantics for a stochastic version\nof the pi-calculus. Moreover we show such semantics to be correct with respect\nto the standard one (defined in labeled operational semantics style).\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 14:17:35 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Bravetti", "Mario", ""]]}, {"id": "1512.07304", "submitter": "Rob van Glabbeek", "authors": "Timothy Bourke (INRIA), Robert J. van Glabbeek (NICTA) and Peter\n  H\\\"ofner (NICTA)", "title": "Mechanizing a Process Algebra for Network Protocols", "comments": "This paper is an extended version of arXiv:1407.3519. The\n  Isabelle/HOL source files, and a full proof document, are available in the\n  Archive of Formal Proofs, at http://afp.sourceforge.net/entries/AWN.shtml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the mechanization of a process algebra for Mobile Ad hoc\nNetworks and Wireless Mesh Networks, and the development of a compositional\nframework for proving invariant properties. Mechanizing the core process\nalgebra in Isabelle/HOL is relatively standard, but its layered structure\nnecessitates special treatment. The control states of reactive processes, such\nas nodes in a network, are modelled by terms of the process algebra. We propose\na technique based on these terms to streamline proofs of inductive invariance.\nThis is not sufficient, however, to state and prove invariants that relate\nstates across multiple processes (entire networks). To this end, we propose a\nnovel compositional technique for lifting global invariants stated at the level\nof individual nodes to networks of nodes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 23:54:48 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Bourke", "Timothy", "", "INRIA"], ["van Glabbeek", "Robert J.", "", "NICTA"], ["H\u00f6fner", "Peter", "", "NICTA"]]}, {"id": "1512.07312", "submitter": "Rob van Glabbeek", "authors": "Ansgar Fehnker, Rob van Glabbeek, Peter H\\\"ofner, Annabelle McIver,\n  Marius Portmann, Wee Lum Tan", "title": "Modelling and Analysis of AODV in UPPAAL", "comments": "in Proc. 1st International Workshop on Rigorous Protocol Engineering,\n  WRiPE 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes work in progress towards an automated formal and\nrigorous analysis of the Ad hoc On-Demand Distance Vector (AODV) routing\nprotocol, a popular protocol used in ad hoc wireless networks. We give a brief\noverview of a model of AODV implemented in the UPPAAL model checker, and\ndescribe experiments carried out to explore AODV's behaviour in two network\ntopologies. We were able to locate automatically and confirm some known\nproblematic and undesirable behaviours. We believe this use of model checking\nas a diagnostic tool complements other formal methods based protocol modelling\nand verification techniques, such as process algebras. Model checking is in\nparticular useful for the discovery of protocol limitations and in the\ndevelopment of improved variations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 00:24:41 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Fehnker", "Ansgar", ""], ["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["McIver", "Annabelle", ""], ["Portmann", "Marius", ""], ["Tan", "Wee Lum", ""]]}, {"id": "1512.07319", "submitter": "Rob van Glabbeek", "authors": "Ansgar Fehnker, Rob van Glabbeek, Peter H\\\"ofner, Annabelle McIver,\n  Marius Portmann, Wee Lum Tan", "title": "A Process Algebra for Wireless Mesh Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.7645", "journal-ref": "Proc. 21st European Symposium on Programming, ESOP'12, (Helmut\n  Seidl, ed.), LNCS 7211, Springer, 2012, pp. 295-315", "doi": "10.1007/978-3-642-28869-2_15", "report-no": null, "categories": "cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a process algebra for wireless mesh networks that combines novel\ntreatments of local broadcast, conditional unicast and data structures. In this\nframework, we model the Ad-hoc On-Demand Distance Vector (AODV) routing\nprotocol and (dis)prove crucial properties such as loop freedom and packet\ndelivery.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 01:08:55 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Fehnker", "Ansgar", ""], ["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["McIver", "Annabelle", ""], ["Portmann", "Marius", ""], ["Tan", "Wee Lum", ""]]}, {"id": "1512.07352", "submitter": "Rob van Glabbeek", "authors": "Ansgar Fehnker, Rob van Glabbeek, Peter H\\\"ofner, Annabelle McIver,\n  Marius Portmann, Wee Lum Tan", "title": "Automated Analysis of AODV using UPPAAL", "comments": "arXiv admin note: text overlap with arXiv:1512.07312", "journal-ref": "Proc. Tools and Algorithms for the Construction and Analysis of\n  Systems, TACAS'12 (C. Flanagan & B. K\\\"onig, eds.), LNCS 7214, Springer,\n  2012, pp. 173-187", "doi": "10.1007/978-3-642-28756-5_13", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an automated, formal and rigorous analysis of the Ad hoc\nOn-Demand Distance Vector (AODV) routing protocol, a popular protocol used in\nwireless mesh networks.\n  We give a brief overview of a model of AODV implemented in the UPPAAL model\nchecker. It is derived from a process-algebraic model which reflects precisely\nthe intention of AODV and accurately captures the protocol specification.\nFurthermore, we describe experiments carried out to explore AODV's behaviour in\nall network topologies up to 5 nodes. We were able to automatically locate\nproblematic and undesirable behaviours. This is in particular useful to\ndiscover protocol limitations and to develop improved variants. This use of\nmodel checking as a diagnostic tool complements other formal-methods-based\nprotocol modelling and verification techniques, such as process algebra.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 04:39:23 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Fehnker", "Ansgar", ""], ["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["McIver", "Annabelle", ""], ["Portmann", "Marius", ""], ["Tan", "Wee Lum", ""]]}, {"id": "1512.07680", "submitter": "EPTCS", "authors": "Mario Bravetti (University of Bologna, Italy / INRIA, France)", "title": "Towards Dynamic Updates in Service Composition", "comments": "In Proceedings FOCLASA 2015, arXiv:1512.06947. arXiv admin note:\n  substantial text overlap with arXiv:1411.3791", "journal-ref": "EPTCS 201, 2015, pp. 1-17", "doi": "10.4204/EPTCS.201.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey our results about verification of adaptable processes. We present\nadaptable processes as a way of overcoming the limitations that process calculi\nhave for describing patterns of dynamic process evolution. Such patterns rely\non direct ways of controlling the behavior and location of running processes,\nand so they are at the heart of the adaptation capabilities present in many\nmodern concurrent systems. Adaptable processes have named scopes and are\nsensible to actions of dynamic update at runtime; this allows to express\ndynamic and static topologies of adaptable processes as well as different\nevolvability patterns for concurrent processes. We introduce a core calculus of\nadaptable processes and consider verification problems for them: first based on\nspecific properties related to error occurrence, that we call bounded and\neventual adaptation, and then by considering a simple yet expressive temporal\nlogic over adaptable processes. We provide (un)decidability results of such\nverification problems over adaptable processes considering the spectrum of\ntopologies/evolvability patterns introduced. We then consider distributed\nadaptability, where a process can update part of a protocol by performing\ndynamic distributed updates over a set of protocol participants. Dynamic\nupdates in this context are presented as an extension of our work on\nchoreographies and behavioural contracts in multiparty interactions. We show\nhow update mechanisms considered for adaptable processes can be used to extend\nthe theory of choreography and orchestration/contracts, allowing them to be\nmodified at run-time by internal (self-adaptation) or external intervention.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 01:39:38 GMT"}], "update_date": "2015-12-25", "authors_parsed": [["Bravetti", "Mario", "", "University of Bologna, Italy / INRIA, France"]]}, {"id": "1512.07684", "submitter": "EPTCS", "authors": "Asma Cherif (Umm al-Qura University, Saudi Arabia), Abdessamad Imine\n  (Lorraine University and Inria Nancy Grand-Est, France)", "title": "A Constraint-based Approach for Generating Transformation Patterns", "comments": "In Proceedings FOCLASA 2015, arXiv:1512.06947", "journal-ref": "EPTCS 201, 2015, pp. 48-62", "doi": "10.4204/EPTCS.201.4", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undoing operations is an indispensable feature for many collaborative\napplications, mainly collaborative editors. It provides the ability to restore\na correct state of shared data after erroneous operations. In particular,\nselective undo allows to undo any operation and is based on rearranging\noperations in the history thanks to the Operational Transformation (OT)\napproach. OT is an optimistic replication technique allowing for updating the\nshared data concurrently while maintaining convergence. It is a challenging\ntask how to meaningfully combine OT and undo approaches. Indeed, undoing\noperations that are received and executed out-of-order at different sites leads\nto divergence cases. Even though various undo solutions have been proposed over\nthe recent years, they are either limited or erroneous.\n  In this paper, we propose a constraint-based approach to address the undo\nproblem. We use Constraint Satisfaction Problem (CSP) theory to devise correct\nand undoable transformation patterns (w.r.t OT and undo properties) which\nconsiderably simplifies the design of collaborative objects.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 01:40:09 GMT"}], "update_date": "2016-01-04", "authors_parsed": [["Cherif", "Asma", "", "Umm al-Qura University, Saudi Arabia"], ["Imine", "Abdessamad", "", "Lorraine University and Inria Nancy Grand-Est, France"]]}, {"id": "1512.07780", "submitter": "Ruben Verborgh", "authors": "Ruben Verborgh, D\\\"orthe Arndt, Sofie Van Hoecke, Jos De Roo, Giovanni\n  Mels, Thomas Steiner, Joaquim Gabarro", "title": "The Pragmatic Proof: Hypermedia API Composition and Execution", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068416000016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine clients are increasingly making use of the Web to perform tasks.\nWhile Web services traditionally mimic remote procedure calling interfaces, a\nnew generation of so-called hypermedia APIs works through hyperlinks and forms,\nin a way similar to how people browse the Web. This means that existing\ncomposition techniques, which determine a procedural plan upfront, are not\nsufficient to consume hypermedia APIs, which need to be navigated at runtime.\nClients instead need a more dynamic plan that allows them to follow hyperlinks\nand use forms with a preset goal. Therefore, in this article, we show how\ncompositions of hypermedia APIs can be created by generic Semantic Web\nreasoners. This is achieved through the generation of a proof based on semantic\ndescriptions of the APIs' functionality. To pragmatically verify the\napplicability of compositions, we introduce the notion of pre-execution and\npost-execution proofs. The runtime interaction between a client and a server is\nguided by proofs but driven by hypermedia, allowing the client to react to the\napplication's actual state indicated by the server's response. We describe how\nto generate compositions from descriptions, discuss a computer-assisted process\nto generate descriptions, and verify reasoner performance on various\ncomposition tasks using a benchmark suite. The experimental results lead to the\nconclusion that proof-based consumption of hypermedia APIs is a feasible\nstrategy at Web scale.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 10:30:25 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Verborgh", "Ruben", ""], ["Arndt", "D\u00f6rthe", ""], ["Van Hoecke", "Sofie", ""], ["De Roo", "Jos", ""], ["Mels", "Giovanni", ""], ["Steiner", "Thomas", ""], ["Gabarro", "Joaquim", ""]]}, {"id": "1512.07956", "submitter": "Bardh Hoxha", "authors": "Bardh Hoxha, Adel Dokhanchi and Georgios Fainekos", "title": "Mining Parametric Temporal Logic Properties in Model Based Design for\n  Cyber-Physical Systems", "comments": "18 Pages, 15 figures, 2 tables, 2 algorithms", "journal-ref": null, "doi": "10.1007/s10009-017-0447-4", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the advantages of adopting a Model Based Development (MBD) process is\nthat it enables testing and verification at early stages of development.\nHowever, it is often desirable to not only verify/falsify certain formal system\nspecifications, but also to automatically explore the properties that the\nsystem satisfies. In this work, we present a framework that enables property\nexploration for Cyber-Physical Systems. Namely, given a parametric\nspecification with multiple parameters, our solution can automatically infer\nthe ranges of parameters for which the property does not hold on the system. In\nthis paper, we consider parametric specifications in Metric or Signal Temporal\nLogic (MTL or STL). Using robust semantics for MTL, the parameter mining\nproblem can be converted into a Pareto optimization problem for which we can\nprovide an approximate solution by utilizing stochastic optimization methods.\nWe include algorithms for the exploration and visualization of multi-parametric\nspecifications. The framework is demonstrated on an industrial size,\nhigh-fidelity engine model as well as examples from related literature.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2015 05:01:32 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 22:24:03 GMT"}, {"version": "v3", "created": "Wed, 6 Jul 2016 21:26:10 GMT"}, {"version": "v4", "created": "Wed, 24 Aug 2016 23:36:08 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Hoxha", "Bardh", ""], ["Dokhanchi", "Adel", ""], ["Fainekos", "Georgios", ""]]}, {"id": "1512.08009", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Matthijs V\\'ak\\'ar", "title": "A Framework for Dependent Types and Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise Levy's call-by-push-value (CBPV) to dependent type theory, to\ngain a better understanding of how to combine dependent types with effects. We\ndefine a dependently typed extension of CBPV, dCBPV-, and show that it has a\nvery natural small-step operational semantics, which satisfies subject\nreduction and (depending on the effects present) determinism and strong\nnormalization, and an elegant categorical semantics, which - surprisingly - is\nno more complicated than the simply typed semantics.\n  We have full and faithful translations from a dependently typed version of\nMoggi's monadic metalanguage and of a call-by-name (CBN) dependent type theory\ninto dCBPV- which give rise to the expected operational behaviour. However, it\nturns out that dCBPV- does not suffice to encode call-by-value (CBV) dependent\ntype theory or the strong (dependent) elimination rules for positive\nconnectives in CBN-dependent type theory.\n  To mend this problem, we discuss a second, more expressive system dCBPV+,\nwhich additionally has a principle of Kleisli extension for dependent\nfunctions. We obtain the desired CBV- and CBN-translations of dependent type\ntheory into dCBPV+. It too has a natural categorical semantics and operational\nsemantics. However, depending on the effects we consider, we may lose\nuniqueness of typing, as the type of a computation may become more specified as\ncertain effects are executed. This idea can be neatly formalized using a notion\nof subtyping.\n  We hope that the theoretical framework of this paper on the one hand provides\nat least a partial answer to the fundamental type theoretic question of how one\ncan understand the relationship between computational effects and dependent\ntypes. On the other hand, we hope it can contribute a small-step towards the\nultimate goal of an elegant fully fledged language for certified effectful\nprogramming.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2015 15:29:30 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 14:55:52 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "1512.08055", "submitter": "Andrea Censi", "authors": "Andrea Censi", "title": "A Mathematical Theory of Co-Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges of modern engineering, and robotics in particular, is\ndesigning complex systems, composed of many subsystems, rigorously and with\noptimality guarantees. This paper introduces a theory of co-design that\ndescribes \"design problems\", defined as tuples of \"functionality space\",\n\"implementation space\", and \"resources space\", together with a feasibility\nrelation that relates the three spaces. Design problems can be interconnected\ntogether to create \"co-design problems\", which describe possibly recursive\nco-design constraints among subsystems. A co-design problem induces a family of\noptimization problems of the type \"find the minimal resources needed to\nimplement a given functionality\"; the solution is an antichain (Pareto front)\nof resources. A special class of co-design problems are Monotone Co-Design\nProblems (MCDPs), for which functionality and resources are complete partial\norders and the feasibility relation is monotone and Scott continuous. The\ninduced optimization problems are multi-objective, nonconvex,\nnondifferentiable, noncontinuous, and not even defined on continuous spaces;\nyet, there exists a complete solution. The antichain of minimal resources can\nbe characterized as a least fixed point, and it can be computed using Kleene's\nalgorithm. The computation needed to solve a co-design problem can be bounded\nby a function of a graph property that quantifies the interdependence of the\nsubproblems. These results make us much more optimistic about the problem of\ndesigning complex systems in a rigorous way.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2015 23:49:15 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 03:27:27 GMT"}, {"version": "v3", "created": "Thu, 21 Jul 2016 22:57:58 GMT"}, {"version": "v4", "created": "Mon, 5 Sep 2016 00:24:56 GMT"}, {"version": "v5", "created": "Wed, 21 Sep 2016 22:59:08 GMT"}, {"version": "v6", "created": "Wed, 5 Oct 2016 17:30:11 GMT"}, {"version": "v7", "created": "Wed, 12 Oct 2016 16:09:05 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Censi", "Andrea", ""]]}, {"id": "1512.08062", "submitter": "William Zeng", "authors": "William Zeng", "title": "The Abstract Structure of Quantum Algorithms", "comments": "174 pages, many figures. University of Oxford doctoral thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum information brings together theories of physics and computer science.\nThis synthesis challenges the basic intuitions of both fields. In this thesis,\nwe show that adopting a unified and general language for process theories\nadvances foundations and practical applications of quantum information. Our\nfirst set of results analyze quantum algorithms with a process theoretic\nstructure. We contribute new constructions of the Fourier transform and\nPontryagin duality in dagger symmetric monoidal categories. We then use this\nsetting to study generalized unitary oracles and give a new quantum blackbox\nalgorithm for the identification of group homomorphisms, solving the GROUPHOMID\nproblem. In the remaining section, we construct a novel model of quantum\nblackbox algorithms in non-deterministic classical computation. Our second set\nof results concerns quantum foundations. We complete work begun by Coecke et\nal., definitively connecting the Mermin non-locality of a process theory with a\nsimple algebraic condition on that theory's phase groups. This result allows us\nto offer new experimental tests for Mermin non-locality and new protocols for\nquantum secret sharing. In our final chapter, we exploit the shared process\ntheoretic structure of quantum information and distributional compositional\nlinguistics. We propose a quantum algorithm adapted from Weibe et al. to\nclassify sentences by meaning. The clarity of the process theoretic setting\nallows us to recover a speedup that is lost in the naive application of the\nalgorithm. The main mathematical tools used in this thesis are group theory\n(esp. Fourier theory on finite groups), monoidal category theory, and\ncategorical algebra.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2015 01:07:00 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Zeng", "William", ""]]}, {"id": "1512.08106", "submitter": "Mickael Randour", "authors": "Patricia Bouyer and Nicolas Markey and Mickael Randour and Kim G.\n  Larsen and Simon Laursen", "title": "Average-energy games (full version)", "comments": "Full version of GandALF 2015 paper (arXiv:1509.07205)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player quantitative zero-sum games provide a natural framework to\nsynthesize controllers with performance guarantees for reactive systems within\nan uncontrollable environment. Classical settings include mean-payoff games,\nwhere the objective is to optimize the long-run average gain per action, and\nenergy games, where the system has to avoid running out of energy.\n  We study average-energy games, where the goal is to optimize the long-run\naverage of the accumulated energy. We show that this objective arises naturally\nin several applications, and that it yields interesting connections with\nprevious concepts in the literature. We prove that deciding the winner in such\ngames is in NP $\\cap$ coNP and at least as hard as solving mean-payoff games,\nand we establish that memoryless strategies suffice to win. We also consider\nthe case where the system has to minimize the average-energy while maintaining\nthe accumulated energy within predefined bounds at all times: this corresponds\nto operating with a finite-capacity storage for energy. We give results for\none-player and two-player games, and establish complexity bounds and memory\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2015 12:52:44 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 10:33:40 GMT"}, {"version": "v3", "created": "Fri, 8 Jul 2016 15:13:24 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Bouyer", "Patricia", ""], ["Markey", "Nicolas", ""], ["Randour", "Mickael", ""], ["Larsen", "Kim G.", ""], ["Laursen", "Simon", ""]]}, {"id": "1512.08366", "submitter": "Manoj Raut", "authors": "Manoj K. Raut", "title": "Computing Theory Prime Implicates in Modal Logic", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithm to compute theory prime implicates, a generalization of prime\nimplicates, in propositional logic has been suggested in \\cite{Marquis}. In\nthis paper we have extended that algorithm to compute theory prime implicates\nof a knowledge base $X$ with respect to another knowledge base $\\Box Y$ using\n\\cite{Bienvenu}, where $Y$ is a propositional knowledge base and $X\\models Y$,\nin modal system $\\mathcal{T}$ and we have also proved its correctness. We have\nalso proved that it is an equivalence preserving knowledge compilation and the\nsize of theory prime implicates of $X$ with respect to $\\Box Y$ is less than\nthe size of the prime implicates of $X\\cup\\Box Y$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 10:24:48 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 05:34:57 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Raut", "Manoj K.", ""]]}, {"id": "1512.08622", "submitter": "Silvia Steila", "authors": "Silvia Steila and Keita Yokoyama", "title": "Reverse Mathematical Bounds for the Termination Theorem", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2004 Podelski and Rybalchenko expressed the termination of\ntransition-based programs as a property of well-founded relations. The\nclassical proof by Podelski and Rybalchenko requires Ramsey's Theorem for pairs\nwhich is a purely classical result, therefore extracting bounds from the\noriginal proof is non-trivial task. Our goal is to investigate the termination\nanalysis from the point of view of Reverse Mathematics. By studying the\nstrength of Podelski and Rybalchenko's Termination Theorem we can extract some\ninformation about termination bounds.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 08:51:51 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Steila", "Silvia", ""], ["Yokoyama", "Keita", ""]]}, {"id": "1512.08689", "submitter": "Marc Brockschmidt", "authors": "Marc Brockschmidt, Byron Cook, Samin Ishtiaq, Heidy Khlaaf, Nir\n  Piterman", "title": "T2: Temporal Property Verification", "comments": "Full version of TACAS'16 tool paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the open-source tool T2, the first public release from the\nTERMINATOR project. T2 has been extended over the past decade to support\nautomatic temporal-logic proving techniques and to handle a general class of\nuser-provided liveness and safety properties. Input can be provided in a native\nformat and in C, via the support of the LLVM compiler framework. We briefly\ndiscuss T2's architecture, its underlying techniques, and conclude with an\nexperimental illustration of its competitiveness and directions for future\nextensions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 14:20:30 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 13:33:40 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Brockschmidt", "Marc", ""], ["Cook", "Byron", ""], ["Ishtiaq", "Samin", ""], ["Khlaaf", "Heidy", ""], ["Piterman", "Nir", ""]]}, {"id": "1512.08824", "submitter": "Richard Mayr", "authors": "Parosh Aziz Abdulla, Radu Ciobanu, Richard Mayr, Arnaud Sangnier,\n  Jeremy Sproston", "title": "Qualitative Analysis of VASS-Induced MDPs", "comments": "Extended version (including all proofs) of material presented at\n  FOSSACS 2016", "journal-ref": null, "doi": null, "report-no": "EDI-INF-RR1422", "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider infinite-state Markov decision processes (MDPs) that are induced\nby extensions of vector addition systems with states (VASS). Verification\nconditions for these MDPs are described by reachability and Buchi objectives\nw.r.t. given sets of control-states. We study the decidability of some\nqualitative versions of these objectives, i.e., the decidability of whether\nsuch objectives can be achieved surely, almost-surely, or limit-surely. While\nmost such problems are undecidable in general, some are decidable for large\nsubclasses in which either only the controller or only the random environment\ncan change the counter values (while the other side can only change\ncontrol-states).\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 01:19:12 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 11:17:37 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Ciobanu", "Radu", ""], ["Mayr", "Richard", ""], ["Sangnier", "Arnaud", ""], ["Sproston", "Jeremy", ""]]}, {"id": "1512.08867", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek and Peter H\\\"ofner and Marius Portmann and Wee Lum\n  Tan", "title": "Modelling and Verifying the AODV Routing Protocol", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.7645", "journal-ref": "Distributed Computing 29(4), 2016, pp. 279-315", "doi": "10.1007/s00446-015-0262-7", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a formal specification of the Ad hoc On-Demand Distance\nVector (AODV) routing protocol using AWN (Algebra for Wireless Networks), a\nrecent process algebra which has been tailored for the modelling of Mobile Ad\nHoc Networks and Wireless Mesh Network protocols. Our formalisation models the\nexact details of the core functionality of AODV, such as route discovery, route\nmaintenance and error handling. We demonstrate how AWN can be used to reason\nabout critical protocol properties by providing detailed proofs of loop freedom\nand route correctness.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 06:52:53 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["Portmann", "Marius", ""], ["Tan", "Wee Lum", ""]]}, {"id": "1512.08873", "submitter": "Rob van Glabbeek", "authors": "Peter H\\\"ofner, Rob van Glabbeek, Wee Lum Tan, Marius Portmann,\n  Annabelle McIver and Ansgar Fehnker", "title": "A Rigorous Analysis of AODV and its Variants", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.7645", "journal-ref": "Proc. Modeling, Analysis and Simulation of Wireless and Mobile\n  Systems, MSWiM'12, ACM, 2012, pp. 203-212", "doi": "10.1145/2387238.2387274", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a rigorous analysis of the Ad hoc On-Demand Distance\nVector (AODV) routing protocol using a formal specification in AWN (Algebra for\nWireless Networks), a process algebra which has been specifically tailored for\nthe modelling of Mobile Ad Hoc Networks and Wireless Mesh Network protocols.\nOur formalisation models the exact details of the core functionality of AODV,\nsuch as route discovery, route maintenance and error handling. We demonstrate\nhow AWN can be used to reason about critical protocol correctness properties by\nproviding a detailed proof of loop freedom. In contrast to evaluations using\nsimulation or other formal methods such as model checking, our proof is generic\nand holds for any possible network scenario in terms of network topology, node\nmobility, traffic pattern, etc. A key contribution of this paper is the\ndemonstration of how the reasoning and proofs can relatively easily be adapted\nto protocol variants.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 08:07:17 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["H\u00f6fner", "Peter", ""], ["van Glabbeek", "Rob", ""], ["Tan", "Wee Lum", ""], ["Portmann", "Marius", ""], ["McIver", "Annabelle", ""], ["Fehnker", "Ansgar", ""]]}, {"id": "1512.08891", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek, Peter H\\\"ofner, Wee Lum Tan and Marius Portmann", "title": "Sequence Numbers Do Not Guarantee Loop Freedom; AODV Can Yield Routing\n  Loops", "comments": "arXiv admin note: text overlap with arXiv:1312.7645", "journal-ref": "Proc. Modeling, Analysis and Simulation of Wireless and Mobile\n  Systems, MSWiM'13, ACM, 2013, pp. 91-100", "doi": "10.1145/2507924.2507943", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of mobile ad-hoc networks and wireless mesh networks, sequence\nnumbers are often used in routing protocols to avoid routing loops. It is\ncommonly stated in protocol specifications that sequence numbers are sufficient\nto guarantee loop freedom if they are monotonically increased over time. A\nclassical example for the use of sequence numbers is the popular Ad hoc\nOn-Demand Distance Vector (AODV) routing protocol. The loop freedom of AODV is\nnot only a common belief, it has been claimed in the abstract of its RFC and at\nleast two proofs have been proposed. AODV-based protocols such as AODVv2 (DYMO)\nand HWMP also claim loop freedom due to the same use of sequence numbers.\n  In this paper we show that AODV is not a priori loop free; by this we counter\nthe proposed proofs in the literature. In fact, loop freedom hinges on\nnon-evident assumptions to be made when resolving ambiguities occurring in the\nRFC. Thus, monotonically increasing sequence numbers, by themselves, do not\nguarantee loop freedom.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 09:51:05 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["Tan", "Wee Lum", ""], ["Portmann", "Marius", ""]]}, {"id": "1512.09032", "submitter": "Shankara Narayanan Krishna", "authors": "Khushraj Madnani, Shankara Narayanan Krishna and Paritosh Pandya", "title": "Metric Temporal Logic with Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability to count number of occurrences of events within a specified time\ninterval is very useful in specification of resource bounded real time\ncomputation. In this paper, we study an extension of Metric Temporal Logic\n($\\mathsf{MTL}$) with two different counting modalities called $\\mathsf{C}$ and\n$\\mathsf{UT}$ (until with threshold), which enhance the expressive power of\n$\\mathsf{MTL}$ in orthogonal fashion. We confine ourselves only to the future\nfragment of $\\mathsf{MTL}$ interpreted in a pointwise manner over finite timed\nwords. We provide a comprehensive study of the expressive power of logic\n$\\mathsf{CTMTL}$ and its fragments using the technique of EF games extended\nwith suitable counting moves. Finally, as our main result, we establish the\ndecidability of $\\mathsf{CTMTL}$ by giving an equisatisfiable reduction from\n$\\mathsf{CTMTL}$ to $\\mathsf{MTL}$. The reduction provides one more example of\nthe use of temporal projections with oversampling introduced earlier for\nproving decidability. Our reduction also implies that $\\mathsf{MITL}$ extended\nwith $\\mathsf{C}$ and $\\mathsf{UT}$ modalities is elementarily decidable.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 17:42:14 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Madnani", "Khushraj", ""], ["Krishna", "Shankara Narayanan", ""], ["Pandya", "Paritosh", ""]]}, {"id": "1512.09186", "submitter": "David Friggens", "authors": "David Friggens, Lindsay Groves", "title": "Collapsing Threads Safely with Soft Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Canonical abstraction is a static analysis technique that represents states\nas 3-valued logical structures, and produces finite abstract systems. Despite\nproviding a finite bound, these abstractions may still suffer from the state\nexplosion problem. Notably, for concurrent programs with arbitrary\ninterleaving, if threads in a state are abstracted based on their location,\nthen the number of locations will be a combinatorial factor in the size of the\nstatespace. We present an approach using canonical abstraction that avoids this\nstate explosion by \"collapsing\" all of the threads in a state into a single\nabstract representative. Properties of threads that would be lost by the\nabstraction, but are needed for verification, are retained by defining\nconditional \"soft invariant\" instrumentation predicates. This technique is used\nto adapt previous models for verifying linearizability of nonblocking\nconcurrent data structure algorithms, resulting in exponentially smaller\nstatespaces.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 00:23:29 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Friggens", "David", ""], ["Groves", "Lindsay", ""]]}, {"id": "1512.09369", "submitter": "Pedro Lopez-Garcia", "authors": "Pedro Lopez-Garcia and Remy Haemmerle and Maximiliano Klemen and Umer\n  Liqat and Manuel V. Hermenegildo", "title": "Towards Energy Consumption Verification via Static Analysis", "comments": "Presented at HIP3ES, 2015 (arXiv: 1501.03064)", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2015/04", "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we leverage an existing general framework for resource usage\nverification and specialize it for verifying energy consumption specifications\nof embedded programs. Such specifications can include both lower and upper\nbounds on energy usage, and they can express intervals within which energy\nusage is to be certified to be within such bounds. The bounds of the intervals\ncan be given in general as functions on input data sizes. Our verification\nsystem can prove whether such energy usage specifications are met or not. It\ncan also infer the particular conditions under which the specifications hold.\nTo this end, these conditions are also expressed as intervals of functions of\ninput data sizes, such that a given specification can be proved for some\nintervals but disproved for others. The specifications themselves can also\ninclude preconditions expressing intervals for input data sizes. We report on a\nprototype implementation of our approach within the CiaoPP system for the XC\nlanguage and XS1-L architecture, and illustrate with an example how embedded\nsoftware developers can use this tool, and in particular for determining values\nfor program parameters that ensure meeting a given energy budget while\nminimizing the loss in quality of service.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 20:57:50 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Lopez-Garcia", "Pedro", ""], ["Haemmerle", "Remy", ""], ["Klemen", "Maximiliano", ""], ["Liqat", "Umer", ""], ["Hermenegildo", "Manuel V.", ""]]}]