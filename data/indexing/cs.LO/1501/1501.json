[{"id": "1501.00386", "submitter": "Arno Pauly", "authors": "Arno Pauly", "title": "Computability on the space of countable ordinals", "comments": "corrected Theorem 21 from v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there is a well-established notion of what a computable ordinal is, the\nquestion which functions on the countable ordinals ought to be computable has\nreceived less attention so far. We propose a notion of computability on the\nspace of countable ordinals via a representation in the sense of computable\nanalysis. The computability structure is characterized by the computability of\nfour specific operations, and we prove further relevant operations to be\ncomputable. Some alternative approaches are discussed, too.\n  As an application in effective descriptive set theory, we can then state and\nprove computable uniform versions of the Lusin separation theorem and the\nHausdorff-Kuratowski theorem. Furthermore, we introduce an operator on the\nWeihrauch lattice corresponding to iteration of some principle over a countable\nordinal.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 11:32:12 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 16:52:37 GMT"}, {"version": "v3", "created": "Sun, 9 Apr 2017 13:26:54 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Pauly", "Arno", ""]]}, {"id": "1501.00433", "submitter": "Vasco Brattka", "authors": "Vasco Brattka, Matthew Hendtlass and Alexander P. Kreuzer", "title": "On the Uniform Computational Content of Computability Theory", "comments": "42 pages", "journal-ref": "Theory of Computing Systems 61:4 (2017) 1376-1426", "doi": "10.1007/s00224-017-9798-1", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that the Weihrauch lattice can be used to classify the uniform\ncomputational content of computability-theoretic properties as well as the\ncomputational content of theorems in one common setting. The properties that we\nstudy include diagonal non-computability, hyperimmunity, complete consistent\nextensions of Peano arithmetic, 1-genericity, Martin-L\\\"of randomness, and\ncohesiveness. The theorems that we include in our case study are the low basis\ntheorem of Jockusch and Soare, the Kleene-Post theorem, and Friedberg's jump\ninversion theorem. It turns out that all the aforementioned properties and many\ntheorems in computability theory, including all theorems that claim the\nexistence of some Turing degree, have very little uniform computational\ncontent: they are located outside of the upper cone of binary choice (also\nknown as LLPO); we call problems with this property indiscriminative. Since\npractically all theorems from classical analysis whose computational content\nhas been classified are discriminative, our observation could yield an\nexplanation for why theorems and results in computability theory typically have\nvery few direct consequences in other disciplines such as analysis. A notable\nexception in our case study is the low basis theorem which is discriminative.\nThis is perhaps why it is considered to be one of the most applicable theorems\nin computability theory. In some cases a bridge between the indiscriminative\nworld and the discriminative world of classical mathematics can be established\nvia a suitable residual operation and we demonstrate this in the case of the\ncohesiveness problem and the problem of consistent complete extensions of Peano\narithmetic. Both turn out to be the quotient of two discriminative problems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 16:23:48 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 10:44:09 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2016 21:01:15 GMT"}, {"version": "v4", "created": "Mon, 13 Mar 2017 17:58:16 GMT"}, {"version": "v5", "created": "Tue, 27 Jun 2017 14:08:40 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Brattka", "Vasco", ""], ["Hendtlass", "Matthew", ""], ["Kreuzer", "Alexander P.", ""]]}, {"id": "1501.00440", "submitter": "Tatjana Petrov", "authors": "Andreea Beica, Calin Guet, Tatjana Petrov", "title": "Efficient reduction of Kappa models by static inspection of the rule-set", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO cs.PL q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing genetic circuits, the typical primitives used in major\nexisting modelling formalisms are gene interaction graphs, where edges between\ngenes denote either an activation or inhibition relation. However, when\ndesigning experiments, it is important to be precise about the low-level\nmechanistic details as to how each such relation is implemented. The rule-based\nmodelling language Kappa allows to unambiguously specify mechanistic details\nsuch as DNA binding sites, dimerisation of transcription factors, or\nco-operative interactions. However, such a detailed description comes with\ncomplexity and computationally costly execution. We propose a general method\nfor automatically transforming a rule-based program, by eliminating\nintermediate species and adjusting the rate constants accordingly. Our method\nconsists of searching for those interaction patterns known to be amenable to\nequilibrium approximations (e.g. Michaelis-Menten scheme). The reduced model is\nefficiently obtained by static inspection over the rule-set, and it represents\na particular theoretical limit of the original model. The Bhattacharyya\ndistance is proposed as a metric to estimate the reduction error for a given\nobservable. The tool is tested on a detailed rule-based model of a\n$\\lambda$-phage switch, which lists $96$ rules and $16$ agents. The reduced\nmodel has $11$ rules and $5$ agents, and provides a dramatic reduction in\nsimulation time of several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 17:30:59 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Beica", "Andreea", ""], ["Guet", "Calin", ""], ["Petrov", "Tatjana", ""]]}, {"id": "1501.00820", "submitter": "Odell Hegna", "authors": "Odell Hegna", "title": "Software Safety Demonstration and Idemnification", "comments": "64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computers may control safety-critical operations in machines having embedded\nsoftware. This memoir proposes a regimen to verify such algorithms at\nprescribed levels of statistical confidence. The United States Department of\nDefense standard for system safety engineering (MIL-STD-882E) defines\ndevelopment procedures for safety-critical systems. However, a problem exists:\nthe Standard fails to distinguish quantitative product assurance technique from\ncategorical process assurance method for software development. Resulting is\nconflict in the technical definition of the term risk. The primary goal here is\nto show that a quantitative risk-based product assurance method exists and is\nconsistent with hardware practice. Discussion appears in two major parts:\ntheory, which shows the relationship between automata and software; and\napplication, which covers demonstration and indemnification. Demonstration is a\ntechnique for generating random tests; indemnification converts pass/fail test\nresults to compound Poisson parameters (severity and intensity). Together,\ndemonstration and indemnification yield statistical confidence that\nsafety-critical code meets design intent. Statistical confidence is the\nkeystone of quantitative product assurance. A secondary goal is resolving the\nconflict over the term risk. The first meaning is an accident model known in\nmathematics as the compound Poisson stochastic process, and so is called\nstatistical risk. Various of its versions underlie the theories of safety and\nreliability. The second is called developmental risk. It considers software\nautonomy, which considers time until manual recovery of control. Once these\nmeanings are separated, MIL-STD-882 can properly support either formal\nquantitative safety assurance or empirical process robustness, which differ in\nimpact.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 11:10:15 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 21:52:09 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2016 20:37:16 GMT"}, {"version": "v4", "created": "Mon, 11 Mar 2019 01:52:07 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Hegna", "Odell", ""]]}, {"id": "1501.01170", "submitter": "David Delahaye", "authors": "David Delahaye (CEDRIC, CNAM Paris), M\\'elanie Jacquel", "title": "Recovering Intuition from Automated Formal Proofs using Tableaux with\n  Superdeduction", "comments": "see https://php.radford.edu/~ejmt/ContentIndex.php#v7n2", "journal-ref": "electronic Journal of Mathematics and Technology, 2013, 7 (2),\n  pp.1 - 20", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an automated deduction method which allows us to produce proofs\nclose to the human intuition and practice. This method is based on tableaux,\nwhich generate more natural proofs than similar methods relying on clausal\nforms, and uses the principles of superdeduction, among which the theory is\nused to enrich the deduction system with new deduction rules. We present two\nimplementations of this method, which consist of extensions of the Zenon\nautomated theorem prover. The first implementation is a version dedicated to\nthe set theory of the B formal method, while the second implementation is a\ngeneric version able to deal with any first order theory. We also provide\nseveral examples of problems, which can be handled by these tools and which\ncome from different theories, such as the B set theory or theories of the TPTP\nlibrary.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 12:59:48 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Delahaye", "David", "", "CEDRIC, CNAM Paris"], ["Jacquel", "M\u00e9lanie", ""]]}, {"id": "1501.01301", "submitter": "David Delahaye", "authors": "M\\'elanie Jacquel, Karim Berkani, David Delahaye (CEDRIC, CNAM Paris,\n  INRIA), Catherine Dubois (CEDRIC, INRIA, ENSIIE)", "title": "Tableaux Modulo Theories Using Superdeduction", "comments": "arXiv admin note: substantial text overlap with arXiv:1501.01170", "journal-ref": "Global Journal of Advanced Software Engineering (GJASE), Avanti\n  Publishers, 2014, 1, pp.1 - 13", "doi": "10.1007/978-3-642-31365-3_26", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that allows us to develop tableaux modulo theories using\nthe principles of superdeduction, among which the theory is used to enrich the\ndeduction system with new deduction rules. This method is presented in the\nframework of the Zenon automated theorem prover, and is applied to the set\ntheory of the B method. This allows us to provide another prover to Atelier B,\nwhich can be used to verify B proof rules in particular. We also propose some\nbenchmarks, in which this prover is able to automatically verify a part of the\nrules coming from the database maintained by Siemens IC-MOL. Finally, we\ndescribe another extension of Zenon with superdeduction, which is able to deal\nwith any first order theory, and provide a benchmark coming from the TPTP\nlibrary, which contains a large set of first order problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 13:13:59 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Jacquel", "M\u00e9lanie", "", "CEDRIC, CNAM Paris,\n  INRIA"], ["Berkani", "Karim", "", "CEDRIC, CNAM Paris,\n  INRIA"], ["Delahaye", "David", "", "CEDRIC, CNAM Paris,\n  INRIA"], ["Dubois", "Catherine", "", "CEDRIC, INRIA, ENSIIE"]]}, {"id": "1501.01363", "submitter": "Charlie Volkstorf", "authors": "Charles Volkstorf", "title": "Program Synthesis from Axiomatic Proof of Correctness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program Synthesis is the mapping of a specification of what a computer\nprogram is supposed to do, into a computer program that does what the\nspecification says to do. This is equivalent to constructing any computer\nprogram and a sound proof that it meets the given specification.\n  We axiomatically prove statements of the form: program PROG meets\nspecification SPEC. We derive 7 axioms from the definition of the PHP\nprogramming language in which the programs are to be written. For each\nprimitive function or process described, we write a program that uses only that\nfeature (function or process), and we have an axiom that this program meets the\nspecification described. Generic ways to alter or combine programs, that meet\nknown specifications, into new programs that meet known specifications, are our\n7 rules of inference.\n  To efficiently prove statements that some program meets a given\nspecification, we work backwards from the specification. We apply the inverses\nof the rules to the specifications that we must meet, until we reach axioms\nthat are combined by these rules to prove that a particular program meets the\ngiven specification. Due to their distinct nature, typically few inverse rules\napply. To avoid complex wff and program manipulation algorithms, we advocate\nthe use of simple table maintenance and look-up functions to simulate these\ncomplexities as a prototype.\n  Examples Include:\n  \"$B=FALSE ; for ($a=1;!($j<$a);++$a){ $A=FALSE ; if (($a*$i)==$j) $A=TRUE ;\nif ($A) $B=TRUE ; } ; echo $B ;\" and \"echo ($j % $i) == 0\" : Is one number a\nfactor of another?\n  \"for ($a=1 ; !($i<$a) ;++$a) {if (($i%$a) == 0) echo $a ; }\" : List the\nfactors of I.\n  \"$A=FALSE ; for ($a=1;$a<$i;++$a){ if (1<$a) { if (($i % $a) == 0) $A=TRUE ;\n} ; } ; echo (!($A)) && (!($i<2)) ;\" : Is I a prime number?\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 03:57:24 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Volkstorf", "Charles", ""]]}, {"id": "1501.01693", "submitter": "EPTCS", "authors": "Santiago Escobar (Universitat Polit\\'ecnica de Val\\'encia)", "title": "Proceedings XIV Jornadas sobre Programaci\\'on y Lenguajes", "comments": null, "journal-ref": "EPTCS 173, 2015", "doi": "10.4204/EPTCS.173", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of the papers presented at the XIV Jornadas\nsobre Programaci\\'on y Lenguajes (PROLE 2014), held at C\\'adiz, Spain, during\nSeptember 17th-19th, 2014. Previous editions of the workshop were held in\nMadrid (2013), Almer\\'ia (2012), A Coru\\~na (2011), Val\\'encia (2010), San\nSebasti\\'an (2009), Gij\\'on (2008), Zaragoza (2007), Sitges (2006), Granada\n(2005), M\\'alaga (2004), Alicante (2003), El Escorial (2002), and Almagro\n(2001).\n  Programming languages provide a conceptual framework which is necessary for\nthe development, analysis, optimization and understanding of programs and\nprogramming tasks. The aim of the PROLE series of conferences (PROLE stems from\nthe spanish PROgramaci\\'on y LEnguajes) is to serve as a meeting point for\nspanish research groups which develop their work in the area of programming and\nprogramming languages. The organization of this series of events aims at\nfostering the exchange of ideas, experiences and results among these groups.\nPromoting further collaboration is also one of the main goals of PROLE.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 00:15:30 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Escobar", "Santiago", "", "Universitat Polit\u00e9cnica de Val\u00e9ncia"]]}, {"id": "1501.01779", "submitter": "Qixia Yuan", "authors": "Andrzej Mizera, Jun Pang, Qixia Yuan", "title": "Reviving the Two-state Markov Chain Approach (Technical Report)", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Boolean networks (PBNs) is a well-established computational\nframework for modelling biological systems. The steady-state dynamics of PBNs\nis of crucial importance in the study of such systems. However, for large PBNs,\nwhich often arise in systems biology, obtaining the steady-state distribution\nposes a significant challenge. In fact, statistical methods for steady-state\napproximation are the only viable means when dealing with large networks. In\nthis paper, we revive the two-state Markov chain approach presented in the\nliterature. We first identify a problem of generating biased results, due to\nthe size of the initial sample with which the approach needs to start and we\npropose a few heuristics to avoid such a pitfall. Second, we conduct an\nextensive experimental comparison of the two-state Markov chain approach and\nanother approach based on the Skart method and we show that statistically the\ntwo-state Markov chain has a better performance. Finally, we apply this\napproach to a large PBN model of apoptosis in hepatocytes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 09:48:58 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2015 14:30:17 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2016 13:31:36 GMT"}, {"version": "v4", "created": "Tue, 25 Oct 2016 12:16:38 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Mizera", "Andrzej", ""], ["Pang", "Jun", ""], ["Yuan", "Qixia", ""]]}, {"id": "1501.02030", "submitter": "EPTCS", "authors": "Dami\\'an Adalid (University of M\\'alaga), Mar\\'ia del Mar Gallardo\n  (University of M\\'alaga), Laura Titolo (University of M\\'alaga)", "title": "Modeling Hybrid Systems in the Concurrent Constraint Paradigm", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 1-15", "doi": "10.4204/EPTCS.173.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid systems, which combine discrete and continuous dynamics, require\nquality modeling languages to be either described or analyzed. The Concurrent\nConstraint paradigm (ccp) is an expressive declarative paradigm, characterized\nby the use of a common constraint store to communicate and synchronize\nconcurrent agents. In this paradigm, the information is stated in the form of\nconstraints, in contrast to the variable/value style typical of imperative\nlanguages. Several extensions of ccp have been proposed in order to model\nreactive systems. One of these extensions is the Timed Concurrent Constraint\nLanguage (tccp) that adds to ccp a notion of discrete time and new features to\nmodel time-out and preemption actions. The goal of this paper is to explore the\nexpressive power of tccp to describe hybrid systems. We introduce the language\nHy-tccp as a conservative extension of tccp, by adding a notion of continuous\ntime and new constructs to describe the continuous dynamics of hybrid systems.\nIn this paper, we present the syntax and the operational semantics of Hy-tccp\ntogether with some examples that show the expressive power of our new language.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 03:59:25 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Adalid", "Dami\u00e1n", "", "University of M\u00e1laga"], ["Gallardo", "Mar\u00eda del Mar", "", "University of M\u00e1laga"], ["Titolo", "Laura", "", "University of M\u00e1laga"]]}, {"id": "1501.02032", "submitter": "EPTCS", "authors": "Javier Albors (Universidad del Pa\\'is Vasco), Marisa Navarro\n  (Universidad del Pa\\'is Vasco)", "title": "SpecSatisfiabilityTool: A tool for testing the satisfiability of\n  specifications on XML documents", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 27-40", "doi": "10.4204/EPTCS.173.3", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a prototype that implements a set of logical rules to prove the\nsatisfiability for a class of specifications on XML documents. Specifications\nare given by means of constrains built on Boolean XPath patterns. The main goal\nof this tool is to test whether a given specification is satisfiable or not,\nand justify the decision showing the execution history. It can also be used to\ntest whether a given document is a model of a given specification and, as a\nby-product, it permits to look for all the relations (monomorphisms) between\ntwo patterns and to combine patterns in different ways. The results of these\noperations are visually shown and therefore the tool makes these operations\nmore understandable. The implementation of the algorithm has been written in\nProlog but the prototype has a Java interface for an easy and friendly use. In\nthis paper we show how to use this interface in order to test all the desired\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 03:59:47 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Albors", "Javier", "", "Universidad del Pa\u00eds Vasco"], ["Navarro", "Marisa", "", "Universidad del Pa\u00eds Vasco"]]}, {"id": "1501.02033", "submitter": "EPTCS", "authors": "Jes\\'us M. Almendros-Jim\\'enez (Universidad de Almer\\'ia)", "title": "XQOWL: An Extension of XQuery for OWL Querying and Reasoning", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 41-55", "doi": "10.4204/EPTCS.173.4", "report-no": null, "categories": "cs.PL cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main aims of the so-called Web of Data is to be able to handle\nheterogeneous resources where data can be expressed in either XML or RDF. The\ndesign of programming languages able to handle both XML and RDF data is a key\ntarget in this context. In this paper we present a framework called XQOWL that\nmakes possible to handle XML and RDF/OWL data with XQuery. XQOWL can be\nconsidered as an extension of the XQuery language that connects XQuery with\nSPARQL and OWL reasoners. XQOWL embeds SPARQL queries (via Jena SPARQL engine)\nin XQuery and enables to make calls to OWL reasoners (HermiT, Pellet and\nFaCT++) from XQuery. It permits to combine queries against XML and RDF/OWL\nresources as well as to reason with RDF/OWL data. Therefore input data can be\neither XML or RDF/OWL and output data can be formatted in XML (also using\nRDF/OWL XML serialization).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 03:59:54 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Almendros-Jim\u00e9nez", "Jes\u00fas M.", "", "Universidad de Almer\u00eda"]]}, {"id": "1501.02034", "submitter": "EPTCS", "authors": "Pascual Juli\\'an-Iranzo (Universidad de Castilla-La Mancha), Gin\\'es\n  Moreno (Universidad de Castilla-La Mancha), Jaime Penabad (Universidad de\n  Castilla-La Mancha), Carlos V\\'azquez (Universidad de Castilla-La Mancha)", "title": "A Fuzzy Logic Programming Environment for Managing Similarity and Truth\n  Degrees", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 71-86", "doi": "10.4204/EPTCS.173.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FASILL (acronym of \"Fuzzy Aggregators and Similarity Into a Logic Language\")\nis a fuzzy logic programming language with implicit/explicit truth degree\nannotations, a great variety of connectives and unification by similarity.\nFASILL integrates and extends features coming from MALP (Multi-Adjoint Logic\nProgramming, a fuzzy logic language with explicitly annotated rules) and\nBousi~Prolog (which uses a weak unification algorithm and is well suited for\nflexible query answering). Hence, it properly manages similarity and truth\ndegrees in a single framework combining the expressive benefits of both\nlanguages. This paper presents the main features and implementations details of\nFASILL. Along the paper we describe its syntax and operational semantics and we\ngive clues of the implementation of the lattice module and the similarity\nmodule, two of the main building blocks of the new programming environment\nwhich enriches the FLOPER system developed in our research group.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 04:00:25 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Juli\u00e1n-Iranzo", "Pascual", "", "Universidad de Castilla-La Mancha"], ["Moreno", "Gin\u00e9s", "", "Universidad de Castilla-La Mancha"], ["Penabad", "Jaime", "", "Universidad de\n  Castilla-La Mancha"], ["V\u00e1zquez", "Carlos", "", "Universidad de Castilla-La Mancha"]]}, {"id": "1501.02036", "submitter": "EPTCS", "authors": "Fernando S\\'aenz-P\\'erez (Universidad Complutense de Madrid)", "title": "Improving the Deductive System DES with Persistence by Using SQL DBMS's", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 100-114", "doi": "10.4204/EPTCS.173.8", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents how persistent predicates have been included in the\nin-memory deductive system DES by relying on external SQL database management\nsystems. We introduce how persistence is supported from a user-point of view\nand the possible applications the system opens up, as the deductive expressive\npower is projected to relational databases. Also, we describe how it is\npossible to intermix computations of the deductive engine and the external\ndatabase, explaining its implementation and some optimizations. Finally, a\nperformance analysis is undertaken, comparing the system with current\nrelational database systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 04:00:41 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["S\u00e1enz-P\u00e9rez", "Fernando", "", "Universidad Complutense de Madrid"]]}, {"id": "1501.02069", "submitter": "Carl Leonardsson", "authors": "Parosh Abdulla, Stavros Aronis, Mohammed Faouzi Atig, Bengt Jonsson,\n  Carl Leonardsson, Konstantinos Sagonas", "title": "Stateless Model Checking for TSO and PSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for efficient stateless model checking of programs\nthat execute under the relaxed memory models TSO and PSO. The basis for our\ntechnique is a novel representation of executions under TSO and PSO, called\nchronological traces. Chronological traces induce a partial order relation on\nrelaxed memory executions, capturing dependencies that are needed to represent\nthe interaction via shared variables. They are optimal in the sense that they\nonly distinguish computations that are inequivalent under the widely-used\nrepresentation by Shasha and Snir. This allows an optimal dynamic partial order\nreduction algorithm to explore a minimal number of executions while still\nguaranteeing full coverage. We apply our techniques to check, under the TSO and\nPSO memory models, LLVM assembly produced for C/pthreads programs. Our\nexperiments show that our technique reduces the verification effort for relaxed\nmemory models to be almost that for the standard model of sequential\nconsistency. In many cases, our implementation significantly outperforms other\ncomparable tools.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 09:06:31 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Abdulla", "Parosh", ""], ["Aronis", "Stavros", ""], ["Atig", "Mohammed Faouzi", ""], ["Jonsson", "Bengt", ""], ["Leonardsson", "Carl", ""], ["Sagonas", "Konstantinos", ""]]}, {"id": "1501.02155", "submitter": "Thomas Hales", "authors": "Thomas Hales and Mark Adams and Gertrud Bauer and Dat Tat Dang and\n  John Harrison and Truong Le Hoang and Cezary Kaliszyk and Victor Magron and\n  Sean McLaughlin and Thang Tat Nguyen and Truong Quang Nguyen and Tobias\n  Nipkow and Steven Obua and Joseph Pleso and Jason Rute and Alexey Solovyev,\n  An Hoai Thi Ta and Trung Nam Tran and Diep Thi Trieu and Josef Urban and Ky\n  Khac Vu and Roland Zumkeller", "title": "A formal proof of the Kepler conjecture", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a formal proof of the Kepler conjecture on dense\nsphere packings in a combination of the HOL Light and Isabelle proof\nassistants. This paper constitutes the official published account of the now\ncompleted Flyspeck project.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 14:32:24 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Hales", "Thomas", ""], ["Adams", "Mark", ""], ["Bauer", "Gertrud", ""], ["Dang", "Dat Tat", ""], ["Harrison", "John", ""], ["Hoang", "Truong Le", ""], ["Kaliszyk", "Cezary", ""], ["Magron", "Victor", ""], ["McLaughlin", "Sean", ""], ["Nguyen", "Thang Tat", ""], ["Nguyen", "Truong Quang", ""], ["Nipkow", "Tobias", ""], ["Obua", "Steven", ""], ["Pleso", "Joseph", ""], ["Rute", "Jason", ""], ["Solovyev", "Alexey", ""], ["Ta", "An Hoai Thi", ""], ["Tran", "Trung Nam", ""], ["Trieu", "Diep Thi", ""], ["Urban", "Josef", ""], ["Vu", "Ky Khac", ""], ["Zumkeller", "Roland", ""]]}, {"id": "1501.02190", "submitter": "Zoltan Esik", "authors": "Zoltan Esik", "title": "Equational axioms associated with finite automata for fixed point\n  operations in cartesian categories", "comments": "Accepted for publication in MSCS", "journal-ref": null, "doi": "10.1017/S0960129515000031", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The axioms of iteration theories, or iteration categories, capture the\nequational properties of fixed point operations in several computationally\nsignificant categories. Iteration categories may be axiomatized by the Conway\nidentities and identities associated with finite automata. We show that in\nconjunction with the Conway identities, each identity associated with a finite\nautomaton implies the identity associated with any input extension of the\nautomaton. We conclude that the Conway identities and the identities associated\nwith the members of a subclass $\\cQ$ of finite automata is complete for\niteration categories iff for every finite simple group $G$ there is an\nautomaton $\\bQ \\in \\cQ$ such that $G$ is a quotient of a group in the monoid\n$M(\\bQ)$ of the automaton $\\bQ$. We also prove a stronger result that concerns\nidentities associated with finite automata with a distinguished initial state.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 16:19:37 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 15:20:26 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Esik", "Zoltan", ""]]}, {"id": "1501.02250", "submitter": "Petr Savick\\'y", "authors": "Zuzana Hanikov\\'a, Petr Savick\\'y", "title": "Term satisfiability in FL$_\\mathrm{ew}$-algebras", "comments": "the revised version, which benefits from the comments of a reviewer\n  for Theoretical Computer Science, corrects a few minor errors, some parts are\n  reorganized for clarity, and Theorem 5.1 is slightly stronger than in the\n  original version", "journal-ref": "Theoretical Computer Science, Vol. 631, June 2016, pp. 1-15", "doi": "10.1016/j.tcs.2016.03.009", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FL$_\\mathrm{ew}$-algebras form the algebraic semantics of the full Lambek\ncalculus with exchange and weakening. We investigate two relations, called\nsatisfiability and positive satisfiability, between FL$_\\mathrm{ew}$-terms and\nFL$_\\mathrm{ew}$-algebras. For each FL$_\\mathrm{ew}$-algebra, the sets of its\nsatisfiable and positively satisfiable terms can be viewed as fragments of its\nexistential theory; we identify and investigate the complements as fragments of\nits universal theory. We offer characterizations of those algebras that\n(positively) satisfy just those terms that are satisfiable in the two-element\nBoolean algebra providing its semantics to classical propositional logic. In\ncase of positive satisfiability, these algebras are just the nontrivial weakly\ncontractive FL$_\\mathrm{ew}$-algebras. In case of satisfiability, we give a\ncharacterization by means of another property of the algebra, the existence of\na two-element congruence. Further, we argue that (positive) satisfiability\nproblems in FL$_\\mathrm{ew}$-algebras are computationally hard. Some previous\nresults in the area of term satisfiability in MV-algebras or BL-algebras are\nthus brought to a common footing with known facts on satisfiability in Heyting\nalgebras.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 19:59:35 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 09:09:49 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Hanikov\u00e1", "Zuzana", ""], ["Savick\u00fd", "Petr", ""]]}, {"id": "1501.02573", "submitter": "Robert Koenighofer", "authors": "Roderick Bloem and Bettina Koenighofer and Robert Koenighofer and Chao\n  Wang", "title": "Shield Synthesis: Runtime Enforcement for Reactive Systems", "comments": "This is an extended version of [5], featuring an additional appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalability issues may prevent users from verifying critical properties of a\ncomplex hardware design. In this situation, we propose to synthesize a \"safety\nshield\" that is attached to the design to enforce the properties at run time.\nShield synthesis can succeed where model checking and reactive synthesis fail,\nbecause it only considers a small set of critical properties, as opposed to the\ncomplex design, or the complete specification in the case of reactive\nsynthesis. The shield continuously monitors the input/output of the design and\ncorrects its erroneous output only if necessary, and as little as possible, so\nother non-critical properties are likely to be retained. Although runtime\nenforcement has been studied in other domains such as action systems, reactive\nsystems pose unique challenges where the shield must act without delay. We thus\npresent the first shield synthesis solution for reactive hardware systems and\nreport our experimental results. This is an extended version of [5], featuring\nan additional appendix.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 09:04:57 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 15:58:47 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Bloem", "Roderick", ""], ["Koenighofer", "Bettina", ""], ["Koenighofer", "Robert", ""], ["Wang", "Chao", ""]]}, {"id": "1501.02607", "submitter": "Facundo Carreiro", "authors": "Facundo Carreiro", "title": "Characterization theorems for PDL and FO(TC)", "comments": "Technical Report, 70 pages. arXiv admin note: text overlap with\n  arXiv:1401.4374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main contributions can be divided in three parts: (1) Fixpoint extensions\nof first-order logic: we give a precise syntactic and semantic characterization\nof the relationship between $\\mathrm{FO(TC^1)}$ and $\\mathrm{FO(LFP)}$; (2)\nAutomata and expressiveness on trees: we introduce a new class of parity\nautomata which, on trees, captures the expressive power of $\\mathrm{FO(TC^1)}$\nand WCL (weak chain logic). The latter logic is a variant of MSO which\nquantifies over finite chains; and (3) Expressiveness modulo bisimilarity: we\nshow that PDL is expressively equivalent to the bisimulation-invariant fragment\nof both $\\mathrm{FO(TC^1)}$ and WCL. In particular, point (3) closes the open\nproblems of the bisimulation-invariant characterizations of PDL,\n$\\mathrm{FO(TC^1)}$ and WCL all at once.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 11:36:21 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 21:24:10 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Carreiro", "Facundo", ""]]}, {"id": "1501.02623", "submitter": "Ale\\v{s} Bizjak", "authors": "Ale\\v{s} Bizjak and Lars Birkedal (Aarhus University, Denmark)", "title": "Step-Indexed Logical Relations for Probability (long version)", "comments": "Extended version with appendix of a FoSSaCS'15 paper", "journal-ref": null, "doi": "10.1007/978-3-662-46678-0_18", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that constructing models of higher-order probabilistic\nprogramming languages is challenging. We show how to construct step-indexed\nlogical relations for a probabilistic extension of a higher-order programming\nlanguage with impredicative polymorphism and recursive types. We show that the\nresulting logical relation is sound and complete with respect to the contextual\npreorder and, moreover, that it is convenient for reasoning about concrete\nprogram equivalences. Finally, we extend the language with dynamically\nallocated first-order references and show how to extend the logical relation to\nthis language. We show that the resulting relation remains useful for reasoning\nabout examples involving both state and probabilistic choice.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 12:50:18 GMT"}, {"version": "v2", "created": "Tue, 13 Jan 2015 07:13:51 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Bizjak", "Ale\u0161", "", "Aarhus University, Denmark"], ["Birkedal", "Lars", "", "Aarhus University, Denmark"]]}, {"id": "1501.02699", "submitter": "Bj\\\"orn Engelmann", "authors": "Bj\\\"orn Engelmann and Ernst-R\\\"udiger Olderog and Nils Erik Flick", "title": "Closing the Gap -- Formally Verifying Dynamically Typed Programs like\n  Statically Typed Ones Using Hoare Logic -- Extended Version --", "comments": "includes all appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamically typed object-oriented languages enable programmers to write\nelegant, reusable and extensible programs. However, with the current\nmethodology for program verification, the absence of static type information\ncreates significant overhead. Our proposal is two-fold:\n  First, we propose a layer of abstraction hiding the complexity of dynamic\ntyping when provided with sufficient type information. Since this essentially\ncreates the illusion of verifying a statically-typed program, the effort\nrequired is equivalent to the statically-typed case.\n  Second, we show how the required type information can be efficiently derived\nfor all type-safe programs by integrating a type inference algorithm into Hoare\nlogic, yielding a semi-automatic procedure allowing the user to focus on those\ntyping problems really requiring his attention. While applying type inference\nto dynamically typed programs is a well-established method by now, our approach\ncomplements conventional soft typing systems by offering formal proof as a\nthird option besides modifying the program (static typing) and accepting the\npresence of runtime type errors (dynamic typing).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 16:30:00 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Engelmann", "Bj\u00f6rn", ""], ["Olderog", "Ernst-R\u00fcdiger", ""], ["Flick", "Nils Erik", ""]]}, {"id": "1501.02834", "submitter": "Henning Urbat", "authors": "Jiri Adamek, Stefan Milius, Robert Myers and Henning Urbat", "title": "Generalized Eilenberg Theorem I: Local Varieties of Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the duality between algebraic and coalgebraic recognition of\nlanguages to derive a generalization of the local version of Eilenberg's\ntheorem. This theorem states that the lattice of all boolean algebras of\nregular languages over an alphabet {\\Sigma} closed under derivatives is\nisomorphic to the lattice of all pseudovarieties of {\\Sigma}-generated monoids.\nBy applying our method to different categories, we obtain three related\nresults: one, due to Gehrke, Grigorieff and Pin, weakens boolean algebras to\ndistributive lattices, one weakens them to join-semilattices, and the last one\nconsiders vector spaces over the binary field.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 21:48:01 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Adamek", "Jiri", ""], ["Milius", "Stefan", ""], ["Myers", "Robert", ""], ["Urbat", "Henning", ""]]}, {"id": "1501.02925", "submitter": "Ranald Clouston", "authors": "Ranald Clouston, Ale\\v{s} Bizjak, Hans Bugge Grathwohl, Lars Birkedal", "title": "Programming and Reasoning with Guarded Recursion for Coinductive Types", "comments": "Version of FoSSaCS 2015 paper with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the guarded lambda-calculus, an extension of the simply typed\nlambda-calculus with guarded recursive and coinductive types. The use of\nguarded recursive types ensures the productivity of well-typed programs.\nGuarded recursive types may be transformed into coinductive types by a\ntype-former inspired by modal logic and Atkey-McBride clock quantification,\nallowing the typing of acausal functions. We give a call-by-name operational\nsemantics for the calculus, and define adequate denotational semantics in the\ntopos of trees. The adequacy proof entails that the evaluation of a program\nalways terminates. We demonstrate the expressiveness of the calculus by showing\nthe definability of solutions to Rutten's behavioural differential equations.\nWe introduce a program logic with L\\\"{o}b induction for reasoning about the\ncontextual equivalence of programs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 09:24:28 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 12:37:21 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Clouston", "Ranald", ""], ["Bizjak", "Ale\u0161", ""], ["Grathwohl", "Hans Bugge", ""], ["Birkedal", "Lars", ""]]}, {"id": "1501.02997", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow", "title": "Profinite Techniques for Probabilistic Automata and the Markov Monoid\n  Algorithm", "comments": "Conference version: STACS'2016, Symposium on Theoretical Aspects of\n  Computer Science Journal version: TCS'2017, Theoretical Computer Science", "journal-ref": "Theoretical Computer Science 680C, 2017", "doi": "10.1016/j.tcs.2017.04.006", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the value 1 problem for probabilistic automata over finite words:\nit asks whether a given probabilistic automaton accepts words with probability\narbitrarily close to 1. This problem is known to be undecidable. However,\ndifferent algorithms have been proposed to partially solve it; it has been\nrecently shown that the Markov Monoid algorithm, based on algebra, is the most\ncorrect algorithm so far. The first contribution of this paper is to give a\ncharacterisation of the Markov Monoid algorithm. The second contribution is to\ndevelop a profinite theory for probabilistic automata, called the prostochastic\ntheory. This new framework gives a topological account of the value 1 problem,\nwhich in this context is cast as an emptiness problem. The above\ncharacterisation is reformulated using the prostochastic theory, allowing us to\ngive a simple and modular proof.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 13:28:30 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 08:35:06 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2016 09:38:52 GMT"}, {"version": "v4", "created": "Sat, 9 Sep 2017 18:59:16 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""]]}, {"id": "1501.03018", "submitter": "Nicholas Macias", "authors": "Nicholas J. Macias", "title": "Context-Dependent Functions: Narrowing the Realm of Turing's Halting\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Turing's Halting Problem (HP), and reviews the classic\nproof that no function exists that can solve HP. The concept of a\n\"Context-Dependent Function\" (CDF), whose behavior varies based on seemingly\nirrelevant changes to a program calling that function, is introduced, and the\nproof of HP's undecidability is re-examined in light of CDFs. The existence of\nCDFs is established via a pair of examples of such functions. The conclusion of\nthe proof of HP's undecidability is thus shown to be overly strong, as it\ndoesn't show that no solution to HP exists, but rather that a solution must be\na CDF. A higher-level analysis of this work is given, followed by conclusions\nand comments on future work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 14:35:58 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Macias", "Nicholas J.", ""]]}, {"id": "1501.03028", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Knowledge in Communication Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates epistemic properties of information flow under\ncommunication protocols with a given topological structure of the communication\nnetwork. The main result is a sound and complete logical system that describes\nall such properties. The system consists of a variation of the multi-agent\nepistemic logic S5 extended by a new network-specific Gateway axiom.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 15:01:47 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 21:37:34 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1501.03043", "submitter": "Stanis{\\l}aw  Ambroszkiewicz", "authors": "Stanislaw Ambroszkiewicz", "title": "Functionals and hardware", "comments": "minor changes - September 12, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functionals are an important research subject in Mathematics and Computer\nScience as well as a challenge in Information Technologies where the current\nprogramming paradigm states that only symbolic computations are possible on\nhigher order objects, i.e. functionals are terms, and computation is term\nrewriting. The idea explored in the paper is that functionals correspond to\ngeneric mechanisms for management of connections in arrays consisting of first\norder functional units. Functionals are higher order abstractions that are\nuseful for the management of such large arrays. Computations on higher order\nobjects comprise dynamic configuration of connections between first order\nelementary functions in the arrays. Once the functionals are considered as the\ngeneric mechanisms, they have a grounding in hardware. A conceptual framework\nfor constructing such mechanisms is presented, and their hardware realization\nis discussed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 15:39:06 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 19:36:32 GMT"}, {"version": "v3", "created": "Mon, 7 Mar 2016 20:43:03 GMT"}, {"version": "v4", "created": "Wed, 8 Feb 2017 15:18:21 GMT"}, {"version": "v5", "created": "Tue, 9 May 2017 11:43:48 GMT"}, {"version": "v6", "created": "Fri, 9 Mar 2018 20:47:35 GMT"}, {"version": "v7", "created": "Wed, 12 Sep 2018 11:45:02 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Ambroszkiewicz", "Stanislaw", ""]]}, {"id": "1501.03063", "submitter": "Carlo A. Furia", "authors": "Julian Tschannen, Carlo A. Furia, Martin Nordio, Nadia Polikarpova", "title": "AutoProof: Auto-active Functional Verification of Object-oriented\n  Programs", "comments": null, "journal-ref": "Proceedings of the 21st International Conference on Tools and\n  Algorithms for the Construction and Analysis of Systems (TACAS). Lecture\n  Notes in Computer Science, 9035:566--580, Springer, April 2015", "doi": "10.1007/978-3-662-46681-0_53", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-active verifiers provide a level of automation intermediate between\nfully automatic and interactive: users supply code with annotations as input\nwhile benefiting from a high level of automation in the back-end. This paper\npresents AutoProof, a state-of-the-art auto-active verifier for object-oriented\nsequential programs with complex functional specifications. AutoProof fully\nsupports advanced object-oriented features and a powerful methodology for\nframing and class invariants, which make it applicable in practice to idiomatic\nobject-oriented patterns. The paper focuses on describing AutoProof's\ninterface, design, and implementation features, and demonstrates AutoProof's\nperformance on a rich collection of benchmark problems. The results attest\nAutoProof's competitiveness among tools in its league on cutting-edge\nfunctional verification of object-oriented programs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 16:25:52 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 09:09:52 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Tschannen", "Julian", ""], ["Furia", "Carlo A.", ""], ["Nordio", "Martin", ""], ["Polikarpova", "Nadia", ""]]}, {"id": "1501.03093", "submitter": "Vojtech Forejt", "authors": "Tom\\'a\\v{s} Br\\'azdil, Krishnendu Chatterjee, Vojt\\v{e}ch Forejt, and\n  Anton\\'in Ku\\v{c}era", "title": "MultiGain: A controller synthesis tool for MDPs with multiple\n  mean-payoff objectives", "comments": "Extended version for a TACAS 2015 tool demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MultiGain, a tool to synthesize strategies for Markov decision\nprocesses (MDPs) with multiple mean-payoff objectives. Our models are described\nin PRISM, and our tool uses the existing interface and simulator of PRISM. Our\ntool extends PRISM by adding novel algorithms for multiple mean-payoff\nobjectives, and also provides features such as (i)~generating strategies and\nexploring them for simulation, and checking them with respect to other\nproperties; and (ii)~generating an approximate Pareto curve for two mean-payoff\nobjectives. In addition, we present a new practical algorithm for the analysis\nof MDPs with multiple mean-payoff objectives under memoryless strategies.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 18:04:46 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chatterjee", "Krishnendu", ""], ["Forejt", "Vojt\u011bch", ""], ["Ku\u010dera", "Anton\u00edn", ""]]}, {"id": "1501.03268", "submitter": "Peter H\\\"ofner", "authors": "Rob van Glabbeek, Peter H\\\"ofner", "title": "Progress, Fairness and Justness in Process Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prove liveness properties of concurrent systems, it is often necessary to\npostulate progress, fairness and justness properties. This paper investigates\nhow the necessary progress, fairness and justness assumptions can be added to\nor incorporated in a standard process-algebraic specification formalism. We\npropose a formalisation that can be applied to a wide range of process\nalgebras. The presented formalism is used to reason about route discovery and\npacket delivery in the setting of wireless networks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 08:04:10 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""]]}, {"id": "1501.03293", "submitter": "Ranald Clouston", "authors": "Ranald Clouston, Rajeev Gor\\'e", "title": "Sequent Calculus in the Topos of Trees", "comments": "Extended version, with full proof details, of a paper accepted to\n  FoSSaCS 2015 (this version edited to fix some minor typos)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nakano's \"later\" modality, inspired by G\\\"{o}del-L\\\"{o}b provability logic,\nhas been applied in type systems and program logics to capture guarded\nrecursion. Birkedal et al modelled this modality via the internal logic of the\ntopos of trees. We show that the semantics of the propositional fragment of\nthis logic can be given by linear converse-well-founded intuitionistic Kripke\nframes, so this logic is a marriage of the intuitionistic modal logic KM and\nthe intermediate logic LC. We therefore call this logic\n$\\mathrm{KM}_{\\mathrm{lin}}$. We give a sound and cut-free complete sequent\ncalculus for $\\mathrm{KM}_{\\mathrm{lin}}$ via a strategy that decomposes\nimplication into its static and irreflexive components. Our calculus provides\ndeterministic and terminating backward proof-search, yields decidability of the\nlogic and the coNP-completeness of its validity problem. Our calculus and\ndecision procedure can be restricted to drop linearity and hence capture KM.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 09:42:22 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 14:42:18 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Clouston", "Ranald", ""], ["Gor\u00e9", "Rajeev", ""]]}, {"id": "1501.03353", "submitter": "Fabian Bendun", "authors": "Michael Backes, Fabian Bendun, Joerg Hoffmann, Ninja Marnau", "title": "PriCL: Creating a Precedent A Framework for Reasoning about Privacy Case\n  Law", "comments": "Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PriCL: the first framework for expressing and automatically\nreasoning about privacy case law by means of precedent. PriCL is parametric in\nan underlying logic for expressing world properties, and provides support for\ncourt decisions, their justification, the circumstances in which the\njustification applies as well as court hierarchies. Moreover, the framework\noffers a tight connection between privacy case law and the notion of norms that\nunderlies existing rule-based privacy research. In terms of automation, we\nidentify the major reasoning tasks for privacy cases such as deducing legal\npermissions or extracting norms. For solving these tasks, we provide generic\nalgorithms that have particularly efficient realizations within an expressive\nunderlying logic. Finally, we derive a definition of deducibility based on\nlegal concepts and subsequently propose an equivalent characterization in terms\nof logic satisfiability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 14:05:18 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Backes", "Michael", ""], ["Bendun", "Fabian", ""], ["Hoffmann", "Joerg", ""], ["Marnau", "Ninja", ""]]}, {"id": "1501.03593", "submitter": "Thibaud Antignac", "authors": "Vinh-Thong Ta (Inria Grenoble Rh\\^one-Alpes / CITI Insa de Lyon,\n  CITI), Thibaud Antignac (Inria Grenoble Rh\\^one-Alpes / CITI Insa de Lyon,\n  CITI)", "title": "Privacy by Design: On the Conformance Between Protocols and\n  Architectures", "comments": "FPS - 7th International Symposium on Foundations \\& Practice of\n  Security, Nov 2014, Montreal, Canada. Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems design, we generally distinguish the architecture and the protocol\nlevels. In the context of privacy by design, in the first case, we talk about\nprivacy architectures, which define the privacy goals and the main features of\nthe system at high level. In the latter case, we consider the underlying\nconcrete protocols and privacy enhancing technologies that implement the\narchitectures. In this paper, we address the question that whether a given\nprotocol conforms to a privacy architecture and provide the answer based on\nformal methods. We propose a process algebra variant to define protocols and\nreason about privacy properties, as well as a mapping procedure from protocols\nto architectures that are defined in a high-level architecture language.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 07:34:33 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Ta", "Vinh-Thong", "", "Inria Grenoble Rh\u00f4ne-Alpes / CITI Insa de Lyon,\n  CITI"], ["Antignac", "Thibaud", "", "Inria Grenoble Rh\u00f4ne-Alpes / CITI Insa de Lyon,\n  CITI"]]}, {"id": "1501.03783", "submitter": "Robert Kenny", "authors": "Robert Kenny (The University of Western Australia, Perth, Australia)", "title": "Effective zero-dimensionality for computable metric spaces", "comments": "25 pages. To appear in Logical Methods in Computer Science. Results\n  in Section 4 have been presented at CCA 2013", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 25,\n  2015) lmcs:1023", "doi": "10.2168/LMCS-11(1:11)2015", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin to study classical dimension theory from the computable analysis\n(TTE) point of view. For computable metric spaces, several effectivisations of\nzero-dimensionality are shown to be equivalent. The part of this\ncharacterisation that concerns covering dimension extends to higher dimensions\nand to closed shrinkings of finite open covers. To deal with zero-dimensional\nsubspaces uniformly, four operations (relative to the space and a class of\nsubspaces) are defined; these correspond to definitions of inductive and\ncovering dimensions and a countable basis condition. Finally, an effective\nretract characterisation of zero-dimensionality is proven under an effective\ncompactness condition. In one direction this uses a version of the construction\nof bilocated sets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 04:56:47 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2015 09:01:09 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kenny", "Robert", "", "The University of Western Australia, Perth, Australia"]]}, {"id": "1501.03849", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Tomas Fiedor, Lukas Holik, Ondrej Lengal, and Tomas Vojnar", "title": "Nested Antichains for WS1S", "comments": "Accepted to TACAS'15", "journal-ref": null, "doi": null, "report-no": "FIT-TR-2014-06", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for coping with alternating quantification as the\nmain source of nonelementary complexity of deciding WS1S formulae. Our approach\nis applicable within the state-of-the-art automata-based WS1S decision\nprocedure implemented, e.g. in MONA. The way in which the standard decision\nprocedure processes quantifiers involves determinization, with its worst case\nexponential complexity, for every quantifier alternation in the prefix of a\nformula. Our algorithm avoids building the deterministic automata---instead, it\nconstructs only those of their states needed for (dis)proving validity of the\nformula. It uses a symbolic representation of the states, which have a deeply\nnested structure stemming from the repeated implicit subset construction, and\nprunes the search space by a nested subsumption relation, a generalization of\nthe one used by the so-called antichain algorithms for handling\nnondeterministic automata. We have obtained encouraging experimental results,\nin some cases outperforming MONA by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 23:15:08 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Fiedor", "Tomas", ""], ["Holik", "Lukas", ""], ["Lengal", "Ondrej", ""], ["Vojnar", "Tomas", ""]]}, {"id": "1501.03933", "submitter": "Thomas Bosch", "authors": "Thomas Bosch, Andreas Nolle, Erman Acar, Kai Eckert", "title": "RDF Validation Requirements - Evaluation and Logical Underpinning", "comments": "arXiv admin note: text overlap with arXiv:1504.04479", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many case studies for which the formulation of RDF constraints and\nthe validation of RDF data conforming to these constraint is very important. As\na part of the collaboration with the W3C and the DCMI working groups on RDF\nvalidation, we identified major RDF validation requirements and initiated an\nRDF validation requirements database which is available to contribute at\nhttp://purl.org/net/rdf-validation. The purpose of this database is to\ncollaboratively collect case studies, use cases, requirements, and solutions\nregarding RDF validation. Although, there are multiple constraint languages\nwhich can be used to formulate RDF constraints (associated with these\nrequirements), there is no standard way to formulate them. This paper serves to\nevaluate to which extend each requirement is satisfied by each of these\nconstraint languages. We take reasoning into account as an important\npre-validation step and therefore map constraints to DL in order to show that\neach constraint can be mapped to an ontology describing RDF constraints\ngenerically.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 10:16:08 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2015 11:14:50 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2015 10:32:18 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Bosch", "Thomas", ""], ["Nolle", "Andreas", ""], ["Acar", "Erman", ""], ["Eckert", "Kai", ""]]}, {"id": "1501.04100", "submitter": "Aws Albarghouthi", "authors": "Aws Albarghouthi, Josh Berdine, Byron Cook, Zachary Kincaid", "title": "Spatial Interpolants", "comments": "Short version published in ESOP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Splinter, a new technique for proving properties of\nheap-manipulating programs that marries (1) a new separation logic-based\nanalysis for heap reasoning with (2) an interpolation-based technique for\nrefining heap-shape invariants with data invariants. Splinter is property\ndirected, precise, and produces counterexample traces when a property does not\nhold. Using the novel notion of spatial interpolants modulo theories, Splinter\ncan infer complex invariants over general recursive predicates, e.g., of the\nform all elements in a linked list are even or a binary tree is sorted.\nFurthermore, we treat interpolation as a black box, which gives us the freedom\nto encode data manipulation in any suitable theory for a given program (e.g.,\nbit vectors, arrays, or linear arithmetic), so that our technique immediately\nbenefits from any future advances in SMT solving and interpolation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 17:10:32 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Albarghouthi", "Aws", ""], ["Berdine", "Josh", ""], ["Cook", "Byron", ""], ["Kincaid", "Zachary", ""]]}, {"id": "1501.04354", "submitter": "{\\L}ukasz Czajka", "authors": "{\\L}ukasz Czajka", "title": "Coinduction: an elementary approach", "comments": "Parts of this paper appear in arXiv:1808.05481", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main aim of this paper is to promote a certain style of doing coinductive\nproofs, similar to inductive proofs as commonly done by mathematicians. For\nthis purpose, we provide a reasonably direct justification for coinductive\nproofs written in this style, i.e., converting a coinductive proof into a\nnon-coinductive argument is purely a matter of routine. In this way, we provide\nan elementary explanation of how to interpret coinduction in set theory.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2015 21:33:49 GMT"}, {"version": "v2", "created": "Mon, 9 Feb 2015 21:21:02 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2015 12:09:32 GMT"}, {"version": "v4", "created": "Fri, 1 May 2015 14:17:04 GMT"}, {"version": "v5", "created": "Sat, 23 May 2015 16:25:20 GMT"}, {"version": "v6", "created": "Sat, 30 May 2015 19:58:44 GMT"}, {"version": "v7", "created": "Sun, 16 Aug 2015 12:35:44 GMT"}, {"version": "v8", "created": "Wed, 22 May 2019 18:40:48 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Czajka", "\u0141ukasz", ""]]}, {"id": "1501.04511", "submitter": "Conrad Cotton-Barratt", "authors": "Conrad Cotton-Barratt, David Hopkins, Andrzej S. Murawski, and C.-H.\n  Luke Ong", "title": "Fragments of ML Decidable by Nested Data Class Memory Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The call-by-value language RML may be viewed as a canonical restriction of\nStandard ML to ground-type references, augmented by a \"bad variable\" construct\nin the sense of Reynolds. We consider the fragment of (finitary) RML terms of\norder at most 1 with free variables of order at most 2, and identify two\nsubfragments of this for which we show observational equivalence to be\ndecidable. The first subfragment consists of those terms in which the\nP-pointers in the game semantic representation are determined by the underlying\nsequence of moves. The second subfragment consists of terms in which the\nO-pointers of moves corresponding to free variables in the game semantic\nrepresentation are determined by the underlying moves. These results are shown\nusing a reduction to a form of automata over data words in which the data\nvalues have a tree-structure, reflecting the tree-structure of the threads in\nthe game semantic plays. In addition we show that observational equivalence is\nundecidable at every third- or higher-order type, every second-order type which\ntakes at least two first-order arguments, and every second-order type (of arity\ngreater than one) that has a first-order argument which is not the final\nargument.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 15:03:46 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Cotton-Barratt", "Conrad", ""], ["Hopkins", "David", ""], ["Murawski", "Andrzej S.", ""], ["Ong", "C. -H. Luke", ""]]}, {"id": "1501.04572", "submitter": "Yuguo He", "authors": "Yuguo He", "title": "k variables are needed to define k-Clique in first-order logic", "comments": "148 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an early paper, Immerman raised a proposal on developing model-theoretic\ntechniques to prove lower bounds on ordered structures, which represents a\nlong-standing challenge in finite model theory. An iconic question standing for\nsuch a challenge is how many variables are needed to define $k$-Clique in\nfirst-order logic on the class of finite ordered graphs? If $k$ variables are\nnecessary, as widely believed, it would imply that the bounded (or finite)\nvariable hierarchy in first-order logic is strict on the class of finite\nordered graphs. In 2008, Rossman made a breakthrough by establishing an optimal\naverage-case lower bound on the size of constant-depth unbounded fan-in\ncircuits computing $k$-Clique. In terms of logic, this means that it needs\ngreater than $\\lfloor\\frac{k} {4}\\rfloor$ variables to describe the $k$-Clique\nproblem in first-order logic on the class of finite ordered graphs, even in the\npresence of arbitrary arithmetic predicates. It follows, with an unpublished\nresult of Immerman, that the bounded variable hierarchy in first-order logic is\nindeed strict. However, Rossman's methods come from circuit complexity and a\nnovel notion of sensitivity by himself. And the challenge before finite model\ntheory remains there. In this paper, we give an alternative proof for the\nstrictness of bounded variable hierarchy in $\\fo$ using pure model-theoretic\ntoolkit, and anwser the question completely for first-order logic, i.e.\n$k$-variables are indeed needed to describe $k$-Clique in this logic. In\ncontrast to Rossman's proof, our proof is purely constructive. Then we embed\nthe main structures into a pure arithmetic structure to show a similar result\nwhere arbitrary arithmetic predicates are presented. Finally, we discuss its\napplication in circuit complexity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 17:45:37 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["He", "Yuguo", ""]]}, {"id": "1501.04748", "submitter": "Chaodong He", "authors": "Chaodong He and Mingzhang Huang", "title": "Branching Bisimilarity on Normed BPA Is EXPTIME-complete", "comments": "We correct many typing errors, add several remarks and an interesting\n  toy example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forward an exponential-time algorithm for deciding branching\nbisimilarity on normed BPA (Bacis Process Algebra) systems. The decidability of\nbranching (or weak) bisimilarity on normed BPA was once a long standing open\nproblem which was closed by Yuxi Fu. The EXPTIME-hardness is an inference of a\nslight modification of the reduction presented by Richard Mayr. Our result\nclaims that this problem is EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 10:03:36 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2015 11:00:49 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["He", "Chaodong", ""], ["Huang", "Mingzhang", ""]]}, {"id": "1501.04789", "submitter": "Charles Grellois", "authors": "Charles Grellois and Paul-Andr\\'e Melli\\`es", "title": "Relational semantics of linear logic and higher-order model-checking", "comments": "24 pages. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we develop a new and somewhat unexpected connection between\nhigher-order model-checking and linear logic. Our starting point is the\nobservation that once embedded in the relational semantics of linear logic, the\nChurch encoding of any higher-order recursion scheme (HORS) comes together with\na dual Church encoding of an alternating tree automata (ATA) of the same\nsignature. Moreover, the interaction between the relational interpretations of\nthe HORS and of the ATA identifies the set of accepting states of the tree\nautomaton against the infinite tree generated by the recursion scheme. We show\nhow to extend this result to alternating parity automata (APT) by introducing a\nparametric version of the exponential modality of linear logic, capturing the\nformal properties of colors (or priorities) in higher-order model-checking. We\nshow in particular how to reunderstand in this way the type-theoretic approach\nto higher-order model-checking developed by Kobayashi and Ong. We briefly\nexplain in the end of the paper how his analysis driven by linear logic results\nin a new and purely semantic proof of decidability of the formulas of the\nmonadic second-order logic for higher-order recursion schemes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 12:51:34 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2015 14:35:28 GMT"}, {"version": "v3", "created": "Fri, 1 May 2015 10:11:26 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Grellois", "Charles", ""], ["Melli\u00e8s", "Paul-Andr\u00e9", ""]]}, {"id": "1501.04826", "submitter": "Thorsten Wissmann", "authors": "Albert Atserias and Jos\\'e L. Balc\\'azar and Marie Ely Piceno", "title": "Relative Entailment Among Probabilistic Implications", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  6, 2019) lmcs:5171", "doi": "10.23638/LMCS-15(1:10)2019", "report-no": null, "categories": "cs.LO cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a natural variant of the implicational fragment of propositional\nlogic. Its formulas are pairs of conjunctions of positive literals, related\ntogether by an implicational-like connective; the semantics of this sort of\nimplication is defined in terms of a threshold on a conditional probability of\nthe consequent, given the antecedent: we are dealing with what the data\nanalysis community calls confidence of partial implications or association\nrules. Existing studies of redundancy among these partial implications have\ncharacterized so far only entailment from one premise and entailment from two\npremises, both in the stand-alone case and in the case of presence of\nadditional classical implications (this is what we call \"relative entailment\").\nBy exploiting a previously noted alternative view of the entailment in terms of\nlinear programming duality, we characterize exactly the cases of entailment\nfrom arbitrary numbers of premises, again both in the stand-alone case and in\nthe case of presence of additional classical implications. As a result, we\nobtain decision algorithms of better complexity; additionally, for each\npotential case of entailment, we identify a critical confidence threshold and\nshow that it is, actually, intrinsic to each set of premises and antecedent of\nthe conclusion.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 14:41:36 GMT"}, {"version": "v2", "created": "Mon, 18 May 2015 12:02:40 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 09:37:28 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 17:02:21 GMT"}, {"version": "v5", "created": "Tue, 5 Feb 2019 11:44:54 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Atserias", "Albert", ""], ["Balc\u00e1zar", "Jos\u00e9 L.", ""], ["Piceno", "Marie Ely", ""]]}, {"id": "1501.05016", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Matthijs V\\'ak\\'ar", "title": "A Categorical Semantics for Linear Logical Frameworks", "comments": "Based on the technical report arXiv:1405.0033 . To appear in the\n  proceedings of FoSSaCS 2015, in the Advanced Research in Computing and\n  Software Science (ARCoSS) subline of Springer's Lecture Notes in Computer\n  Science series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A type theory is presented that combines (intuitionistic) linear types with\ntype dependency, thus properly generalising both intuitionistic dependent type\ntheory and full linear logic. A syntax and complete categorical semantics are\ndeveloped, the latter in terms of (strict) indexed symmetric monoidal\ncategories with comprehension. Various optional type formers are treated in a\nmodular way. In particular, we will see that the historically much-debated\nmultiplicative quantifiers and identity types arise naturally from categorical\nconsiderations. These new multiplicative connectives are further characterised\nby several identities relating them to the usual connectives from dependent\ntype theory and linear logic. Finally, one important class of models, given by\nfamilies with values in some symmetric monoidal category, is investigated in\ndetail.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 23:22:04 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "1501.05098", "submitter": "Thomas Sturm", "authors": "Marek Kosta, Thomas Sturm, Andreas Dolzmann", "title": "Better Answers to Real Questions", "comments": null, "journal-ref": "J. Symb. Comput., 74:255-275, 2016", "doi": "10.1016/j.jsc.2015.07.002", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider existential problems over the reals. Extended quantifier\nelimination generalizes the concept of regular quantifier elimination by\nproviding in addition answers, which are descriptions of possible assignments\nfor the quantified variables. Implementations of extended quantifier\nelimination via virtual substitution have been successfully applied to various\nproblems in science and engineering. So far, the answers produced by these\nimplementations included infinitesimal and infinite numbers, which are hard to\ninterpret in practice. We introduce here a post-processing procedure to\nconvert, for fixed parameters, all answers into standard real numbers. The\nrelevance of our procedure is demonstrated by application of our implementation\nto various examples from the literature, where it significantly improves the\nquality of the results.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 09:14:26 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Kosta", "Marek", ""], ["Sturm", "Thomas", ""], ["Dolzmann", "Andreas", ""]]}, {"id": "1501.05104", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert (LACL), Marc Bagnol (I2M), Thomas Seiller (IHES)", "title": "Memoization for Unary Logic Programming: Characterizing PTIME", "comments": "Soumis {\\`a} LICS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a characterization of deterministic polynomial time computation based\non an algebraic structure called the resolution semiring, whose elements can be\nunderstood as logic programs or sets of rewriting rules over first-order terms.\nMore precisely, we study the restriction of this framework to terms (and logic\nprograms, rewriting rules) using only unary symbols. We prove it is complete\nfor polynomial time computation, using an encoding of pushdown automata. We\nthen introduce an algebraic counterpart of the memoization technique in order\nto show its PTIME soundness. We finally relate our approach and complexity\nresults to complexity of logic programming. As an application of our\ntechniques, we show a PTIME-completeness result for a class of logic\nprogramming queries which use only unary function symbols.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 09:34:31 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 07:56:47 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LACL"], ["Bagnol", "Marc", "", "I2M"], ["Seiller", "Thomas", "", "IHES"]]}, {"id": "1501.05115", "submitter": "Noam Zeilberger", "authors": "Paul-Andr\\'e Melli\\`es and Noam Zeilberger", "title": "An Isbell Duality Theorem for Type Refinement Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any refinement system (= functor) has a fully faithful representation in the\nrefinement system of presheaves, by interpreting types as relative slice\ncategories, and refinement types as presheaves over those categories. Motivated\nby an analogy between side effects in programming and *context effects* in\nlinear logic, we study logical aspects of this \"positive\" (covariant)\nrepresentation, as well as of an associated \"negative\" (contravariant)\nrepresentation. We establish several preservation properties for these\nrepresentations, including a generalization of Day's embedding theorem for\nmonoidal closed categories. Then we establish that the positive and negative\nrepresentations satisfy an Isbell-style duality. As corollaries, we derive two\ndifferent formulas for the positive representation of a pushforward (inspired\nby the classical negative translations of proof theory), which express it\neither as the dual of a pullback of a dual, or as the double dual of a\npushforward. Besides explaining how these constructions on refinement systems\ngeneralize familiar category-theoretic ones (by viewing categories as special\nrefinement systems), our main running examples involve representations of Hoare\nLogic and linear sequent calculus.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 10:24:16 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2015 20:43:19 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Melli\u00e8s", "Paul-Andr\u00e9", ""], ["Zeilberger", "Noam", ""]]}, {"id": "1501.05147", "submitter": "Georg Struth", "authors": "Hitoshi Furusawa and Georg Struth", "title": "Taming Multirelations", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary multirelations generalise binary relations by associating elements of\na set to its subsets. We study the structure and algebra of multirelations\nunder the operations of union, intersection, sequential and parallel\ncomposition, as well as finite and infinite iteration. Starting from a\nset-theoretic investigation, we propose axiom systems for multirelations in\ncontexts ranging from bi-monoids to bi-quantales.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 12:00:10 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2015 14:00:12 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Furusawa", "Hitoshi", ""], ["Struth", "Georg", ""]]}, {"id": "1501.05180", "submitter": "Henning Urbat", "authors": "Jiri Adamek, Stefan Milius, Robert Myers and Henning Urbat", "title": "Varieties of Languages in a Category", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eilenberg's variety theorem, a centerpiece of algebraic automata theory,\nestablishes a bijective correspondence between varieties of languages and\npseudovarieties of monoids. In the present paper this result is generalized to\nan abstract pair of algebraic categories: we introduce varieties of languages\nin a category C, and prove that they correspond to pseudovarieties of monoids\nin a closed monoidal category D, provided that C and D are dual on the level of\nfinite objects. By suitable choices of these categories our result uniformly\ncovers Eilenberg's theorem and three variants due to Pin, Polak and Reutenauer,\nrespectively, and yields new Eilenberg-type correspondences.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 14:31:04 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Adamek", "Jiri", ""], ["Milius", "Stefan", ""], ["Myers", "Robert", ""], ["Urbat", "Henning", ""]]}, {"id": "1501.05260", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Reversible Quantum Process Algebra", "comments": "209 pages, 23 figures, 113 tables. arXiv admin note: substantial text\n  overlap with arXiv:1811.01070", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truly concurrent process algebras are generalizations to the traditional\nprocess algebras for true concurrency, CTC to CCS, APTC to ACP, $\\pi_{tc}$ to\n$\\pi$ calculus , APPTC to probabilistic process algebra. And we also did some\nwork on reversible process algebra and probabilistic truly concurrent process\nalgebra. In this book, we utilize reversible truly concurrent process algebras\nAPRTC and APPTC to model quantum computing and unify quantum and classical\ncomputing.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 04:55:39 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 03:17:35 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 16:05:33 GMT"}, {"version": "v4", "created": "Wed, 28 Jul 2021 06:24:16 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1501.05561", "submitter": "Vojtech Forejt", "authors": "Vojt\\v{e}ch Forejt and Jan Kr\\v{c}\\'al", "title": "On Frequency LTL in Probabilistic Systems", "comments": "A paper presented at CONCUR 2015, with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study frequency linear-time temporal logic (fLTL) which extends the\nlinear-time temporal logic (LTL) with a path operator $G^p$ expressing that on\na path, certain formula holds with at least a given frequency p, thus relaxing\nthe semantics of the usual G operator of LTL. Such logic is particularly useful\nin probabilistic systems, where some undesirable events such as random failures\nmay occur and are acceptable if they are rare enough.\n  Frequency-related extensions of LTL have been previously studied by several\nauthors, where mostly the logic is equipped with an extended \"until\" and\n\"globally\" operator, leading to undecidability of most interesting problems.\n  For the variant we study, we are able to establish fundamental decidability\nresults. We show that for Markov chains, the problem of computing the\nprobability with which a given fLTL formula holds has the same complexity as\nthe analogous problem for LTL. We also show that for Markov decision processes\nthe problem becomes more delicate, but when restricting the frequency bound $p$\nto be 1 and negations not to be outside any $G^p$ operator, we can compute the\nmaximum probability of satisfying the fLTL formula. This can be again performed\nwith the same time complexity as for the ordinary LTL formulas.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 16:30:43 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 16:26:58 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Forejt", "Vojt\u011bch", ""], ["Kr\u010d\u00e1l", "Jan", ""]]}, {"id": "1501.05673", "submitter": "Limin Jia", "authors": "Limin Jia, Shayak Sen, Deepak Garg, and Anupam Datta", "title": "System M: A Program Logic for Code Sandboxing and Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security-sensitive applications that execute untrusted code often check the\ncode's integrity by comparing its syntax to a known good value or sandbox the\ncode to contain its effects. System M is a new program logic for reasoning\nabout such security-sensitive applications. System M extends Hoare Type Theory\n(HTT) to trace safety properties and, additionally, contains two new reasoning\nprinciples. First, its type system internalizes logical equality, facilitating\nreasoning about applications that check code integrity. Second, a confinement\nrule assigns an effect type to a computation based solely on knowledge of the\ncomputation's sandbox. We prove the soundness of system M relative to a\nstep-indexed trace-based semantic model. We illustrate both new reasoning\nprinciples of system M by verifying the main integrity property of the design\nof Memoir, a previously proposed trusted computing system for ensuring state\ncontinuity of isolated security-sensitive applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 22:22:44 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Jia", "Limin", ""], ["Sen", "Shayak", ""], ["Garg", "Deepak", ""], ["Datta", "Anupam", ""]]}, {"id": "1501.05826", "submitter": "Thomas Sturm", "authors": "Marek Kosta, Thomas Sturm", "title": "A Generalized Framework for Virtual Substitution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the framework of virtual substitution for real quantifier\nelimination to arbitrary but bounded degrees. We make explicit the\nrepresentation of test points in elimination sets using roots of parametric\nunivariate polynomials described by Thom codes. Our approach follows an early\nsuggestion by Weispfenning, which has never been carried out explicitly.\nInspired by virtual substitution for linear formulas, we show how to\nsystematically construct elimination sets containing only test points\nrepresenting lower bounds.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 15:13:43 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Kosta", "Marek", ""], ["Sturm", "Thomas", ""]]}, {"id": "1501.06059", "submitter": "EPTCS", "authors": "Aleks Kissinger (University of Oxford), Vladimir Zamdzhiev (University\n  of Oxford)", "title": "!-Graphs with Trivial Overlap are Context-Free", "comments": "In Proceedings GaM 2015, arXiv:1504.02448", "journal-ref": "EPTCS 181, 2015, pp. 16-31", "doi": "10.4204/EPTCS.181.2", "report-no": null, "categories": "cs.LO cs.FL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String diagrams are a powerful tool for reasoning about composite structures\nin symmetric monoidal categories. By representing string diagrams as graphs,\nequational reasoning can be done automatically by double-pushout rewriting.\n!-graphs give us the means of expressing and proving properties about whole\nfamilies of these graphs simultaneously. While !-graphs provide elegant proofs\nof surprisingly powerful theorems, little is known about the formal properties\nof the graph languages they define. This paper takes the first step in\ncharacterising these languages by showing that an important subclass of\n!-graphs--those whose repeated structures only overlap trivially--can be\nencoded using a (context-free) vertex replacement grammar.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jan 2015 16:38:10 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 15:14:40 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2015 09:40:25 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Kissinger", "Aleks", "", "University of Oxford"], ["Zamdzhiev", "Vladimir", "", "University\n  of Oxford"]]}, {"id": "1501.06125", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro and Gilles Dowek", "title": "Proof Normalisation in a Logic Identifying Isomorphic Propositions", "comments": null, "journal-ref": "4th International Conference on Formal Structures for Computation\n  and Deduction (FSCD 2019) - LIPIcs 131:14, 2019", "doi": "10.4230/LIPIcs.FSCD.2019.14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a fragment of propositional logic where isomorphic propositions,\nsuch as $A\\land B$ and $B\\land A$, or $A\\Rightarrow (B\\land C)$ and\n$(A\\Rightarrow B)\\land(A\\Rightarrow C)$ are identified. We define System I, a\nproof language for this logic, and prove its normalisation and consistency.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 08:04:14 GMT"}, {"version": "v2", "created": "Tue, 24 Feb 2015 10:00:31 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2015 07:26:47 GMT"}, {"version": "v4", "created": "Tue, 7 Aug 2018 13:48:29 GMT"}, {"version": "v5", "created": "Fri, 10 Aug 2018 06:52:19 GMT"}, {"version": "v6", "created": "Fri, 17 Aug 2018 19:10:10 GMT"}, {"version": "v7", "created": "Tue, 12 Feb 2019 18:16:44 GMT"}, {"version": "v8", "created": "Mon, 22 Apr 2019 11:10:47 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Dowek", "Gilles", ""]]}, {"id": "1501.06206", "submitter": "Radhakrishnan Delhibabu", "authors": "Radhakrishnan Delhibabu", "title": "Dynamics of Belief: Abduction, Horn Knowledge Base And Database Updates", "comments": "arXiv admin note: substantial text overlap with arXiv:1411.2499,\n  arXiv:1405.2642, arXiv:1407.3512, arXiv:1301.5154", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The dynamics of belief and knowledge is one of the major components of any\nautonomous system that should be able to incorporate new pieces of information.\nIn order to apply the rationality result of belief dynamics theory to various\npractical problems, it should be generalized in two respects: first it should\nallow a certain part of belief to be declared as immutable; and second, the\nbelief state need not be deductively closed. Such a generalization of belief\ndynamics, referred to as base dynamics, is presented in this paper, along with\nthe concept of a generalized revision algorithm for knowledge bases (Horn or\nHorn logic with stratified negation). We show that knowledge base dynamics has\nan interesting connection with kernel change via hitting set and abduction. In\nthis paper, we show how techniques from disjunctive logic programming can be\nused for efficient (deductive) database updates. The key idea is to transform\nthe given database together with the update request into a disjunctive\n(datalog) logic program and apply disjunctive techniques (such as minimal model\nreasoning) to solve the original update problem. The approach extends and\nintegrates standard techniques for efficient query answering and integrity\nchecking. The generation of a hitting set is carried out through a hyper\ntableaux calculus and magic set that is focused on the goal of minimality. The\npresent paper provides a comparative study of view update algorithms in\nrational approach. For, understand the basic concepts with abduction, we\nprovide an abductive framework for knowledge base dynamics. Finally, we\ndemonstrate how belief base dynamics can provide an axiomatic characterization\nfor insertion a view atom to the database. We give a quick overview of the main\noperators for belief change, in particular, belief update versus database\nupdate.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 20:48:53 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 09:59:49 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Delhibabu", "Radhakrishnan", ""]]}, {"id": "1501.06522", "submitter": "Gilles Dowek", "authors": "Gilles Dowek (DEDUCTEAM, LSV)", "title": "Models and termination of proof reduction in the $\\lambda$$\\Pi$-calculus\n  modulo theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a notion of model for the $\\lambda$$\\Pi$-calculus modulo theory and\nprove a soundness theorem. We then define a notion of super-consistency and\nprove that proof reduction terminates in the $\\lambda$$\\Pi$-calculus modulo any\nsuper-consistent theory. We prove this way the termination of proof reduction\nin several theories including Simple type theory and the Calculus of\nconstructions .\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 18:49:49 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 07:00:19 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Dowek", "Gilles", "", "DEDUCTEAM, LSV"]]}, {"id": "1501.06523", "submitter": "Gilles Dowek", "authors": "Gilles Dowek (INRIA Paris-Rocquencourt)", "title": "Deduction modulo theory", "comments": null, "journal-ref": "All about proofs. Proofs for all., Jul 2014, Wien, Austria", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey on Deduction modulo theory\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 18:51:34 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Dowek", "Gilles", "", "INRIA Paris-Rocquencourt"]]}, {"id": "1501.07082", "submitter": "Amar Hadzihasanovic", "authors": "Amar Hadzihasanovic", "title": "A Diagrammatic Axiomatisation for Qubit Entanglement", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagrammatic techniques for reasoning about monoidal categories provide an\nintuitive understanding of the symmetries and connections of interacting\ncomputational processes. In the context of categorical quantum mechanics,\nCoecke and Kissinger suggested that two 3-qubit states, GHZ and W, may be used\nas the building blocks of a new graphical calculus, aimed at a diagrammatic\nclassification of multipartite qubit entanglement that would highlight the\ncommunicational properties of quantum states, and their potential uses in\ncryptographic schemes.\n  In this paper, we present a full graphical axiomatisation of the relations\nbetween GHZ and W: the ZW calculus. This refines a version of the preexisting\nZX calculus, while keeping its most desirable characteristics: undirectedness,\na large degree of symmetry, and an algebraic underpinning. We prove that the ZW\ncalculus is complete for the category of free abelian groups on a power of two\ngenerators - \"qubits with integer coefficients\" - and provide an explicit\nnormalisation procedure.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 12:20:58 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Hadzihasanovic", "Amar", ""]]}, {"id": "1501.07131", "submitter": "Dietmar Berwanger", "authors": "Dietmar Berwanger and Marie van den Bogaard", "title": "Consensus Game Acceptors and Iterated Transductions", "comments": "22 pages; extended version of a paper presented at DLT 2015:\n  \"Consensus Game Acceptors\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a game for recognising formal languages, in which two players with\nimperfect information need to coordinate on a common decision, given private\ninput words correlated by a finite graph. The players have a joint objective to\navoid an inadmissible decision, in spite of the uncertainty induced by the\ninput.\n  We show that the acceptor model based on consensus games characterises\ncontext-sensitive languages. Further, we describe the expressiveness of these\ngames in terms of iterated synchronous transductions and identify a subclass\nthat characterises context-free languages.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 15:06:28 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 12:07:25 GMT"}, {"version": "v3", "created": "Tue, 26 Apr 2016 09:05:48 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Berwanger", "Dietmar", ""], ["Bogaard", "Marie van den", ""]]}, {"id": "1501.07195", "submitter": "Stefan Mengel", "authors": "Hubie Chen and Stefan Mengel", "title": "The Logic of Counting Query Answers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of counting the number of answers to a first-order\nformula on a finite structure. We present and study an extension of first-order\nlogic in which algorithms for this counting problem can be naturally and\nconveniently expressed, in senses that are made precise and that are motivated\nby the wish to understand tractable cases of the counting problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 17:02:31 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 11:09:42 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 09:04:59 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Chen", "Hubie", ""], ["Mengel", "Stefan", ""]]}, {"id": "1501.07209", "submitter": "Marco Voigt", "authors": "Marco Voigt and Christoph Weidenbach", "title": "Bernays-Schoenfinkel-Ramsey with Simple Bounds is NEXPTIME-complete", "comments": "This is a revised version of the initial arXiv submission. Although\n  submitted in 2020, the last update of its contents dates back to June 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order predicate logic extended with linear arithmetic is undecidable,\nin general. We show that the Bernays-Sch\\\"onfinkel-Ramsey (BSR) fragment\nextended with linear arithmetic restricted to simple bounds (SB) is decidable\nthrough finite ground instantiation. The identified ground instances can be\nemployed to restrict the search space of existing automated reasoning\nprocedures for BSR(SB). Satisfiability of BSR(SB) compared to BSR remains\nNEXPTIME-complete. The decidability result is almost tight because BSR is\nundecidable if extended with linear difference inequations, simple additive\ninequations, quotient inequations and multiplicative inequations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 17:41:07 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 14:04:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Voigt", "Marco", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "1501.07215", "submitter": "Sebastian Enqvist", "authors": "Sebastian Enqvist, Fatemeh Seifan, Yde Venema", "title": "Monadic Second-Order Logic and Bisimulation Invariance for Coalgebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalizing standard monadic second-order logic for Kripke models, we\nintroduce monadic second-order logic interpreted over coalgebras for an\narbitrary set functor. Similar to well-known results for monadic second-order\nlogic over trees, we provide a translation of this logic into a class of\nautomata, relative to the class of coalgebras that admit a tree-like supporting\nKripke frame. We then consider invariance under behavioral equivalence of\nformulas; more in particular, we investigate whether the coalgebraic\nmu-calculus is the bisimulation-invariant fragment of monadic second-order\nlogic. Building on recent results by the third author we show that in order to\nprovide such a coalgebraic generalization of the Janin-Walukiewicz Theorem, it\nsuffices to find what we call an adequate uniform construction for the functor.\nAs applications of this result we obtain a partly new proof of the\nJanin-Walukiewicz Theorem, and bisimulation invariance results for the bag\nfunctor (graded modal logic) and all exponential polynomial functors.\n  Finally, we consider in some detail the monotone neighborhood functor, which\nprovides coalgebraic semantics for monotone modal logic. It turns out that\nthere is no adequate uniform construction for this functor, whence the\nautomata-theoretic approach towards bisimulation invariance does not apply\ndirectly. This problem can be overcome if we consider global bisimulations\nbetween neighborhood models: one of our main technical results provides a\ncharacterization of the monotone modal mu-calculus extended with the global\nmodalities, as the fragment of monadic second-order logic for the monotone\nneighborhood functor that is invariant for global bisimulations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 18:04:11 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Enqvist", "Sebastian", ""], ["Seifan", "Fatemeh", ""], ["Venema", "Yde", ""]]}, {"id": "1501.07429", "submitter": "Nans Lefebvre", "authors": "Nans Lefebvre", "title": "Convergence law for hyper-graphs with prescribed degree sequences", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view hyper-graphs as incidence graphs, i.e. bipartite graphs with a set of\nnodes representing vertices and a set of nodes representing hyper-edges, with\ntwo nodes being adjacent if the corresponding vertex belongs to the\ncorresponding hyper-edge. It defines a random hyper-multigraph specified by two\ndistributions, one for the degrees of the vertices, and one for the sizes of\nthe hyper-edges. We develop the logical analysis of this framework and first\nprove a convergence law for first-order logic, then characterise the limit\nfirst-order theories defined by a wide class of degree distributions.\nConvergence laws of other models follow, and in particular for the classical\nErd\\H{o}s-R\\'enyi graphs and $k$-uniform hyper-graphs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 12:07:25 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 01:02:47 GMT"}, {"version": "v3", "created": "Wed, 6 May 2015 21:36:34 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Lefebvre", "Nans", ""]]}]