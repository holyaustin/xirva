[{"id": "1809.00134", "submitter": "Frank Wolter", "authors": "Carsten Lutz, Inanc Seylan, and Frank Wolter", "title": "The Data Complexity of Ontology-Mediated Queries with Closed Predicates", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August\n  28, 2019) lmcs:5723", "doi": "10.23638/LMCS-15(3:23)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the context of ontology-mediated querying with description logics (DLs),\nwe study the data complexity of queries in which selected predicates can be\nclosed (OMQCs). We provide a non-uniform analysis, aiming at a classification\nof the complexity into tractable and non-tractable for ontologies in the\nlightweight DLs DL-Lite and EL, and the expressive DL ALCHI. At the level of\nontologies, we prove a dichotomy between FO-rewritable and coNP-complete for\nDL-Lite and between PTime and coNP-complete for EL. The meta problem of\ndeciding tractability is proved to be in PTime. At the level of OMQCs, we show\nthat there is no dichotomy (unless NP equals PTime) if both concept and role\nnames can be closed. If only concept names can be closed, we tightly link the\ncomplexity of query evaluation to the complexity of surjective CSPs. We also\nidentify a class of OMQCs based on ontologies formulated in DL-Lite that are\nguaranteed to be tractable and even FO-rewritable.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 08:31:32 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:38:55 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 11:06:13 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Lutz", "Carsten", ""], ["Seylan", "Inanc", ""], ["Wolter", "Frank", ""]]}, {"id": "1809.00167", "submitter": "Meghdad Ghari", "authors": "Meghdad Ghari", "title": "Linear Temporal Justification Logics with Past Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present various temporal justification logics involving both\npast and future time modalities. We combine Artemov's logic of proofs with\nlinear temporal logic (with both past and future operators), and establish its\nsoundness and completeness. Then we investigate several principles describing\nthe interaction of justification and time.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 13:03:47 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 07:37:00 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ghari", "Meghdad", ""]]}, {"id": "1809.00380", "submitter": "Vasco Brattka", "authors": "Vasco Brattka and Guido Gherardi", "title": "Weihrauch goes Brouwerian", "comments": "36 pages", "journal-ref": "J. symb. log. 85 (2020) 1614-1653", "doi": "10.1017/jsl.2020.76", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the Weihrauch lattice can be transformed into a Brouwer algebra\nby the consecutive application of two closure operators in the appropriate\norder: first completion and then parallelization. The closure operator of\ncompletion is a new closure operator that we introduce. It transforms any\nproblem into a total problem on the completion of the respective types, where\nwe allow any value outside of the original domain of the problem. This closure\noperator is of interest by itself, as it generates a total version of Weihrauch\nreducibility that is defined like the usual version of Weihrauch reducibility,\nbut in terms of total realizers. From a logical perspective completion can be\nseen as a way to make problems independent of their premises. Alongside with\nthe completion operator and total Weihrauch reducibility we need to study\nprecomplete representations that are required to describe these concepts. In\norder to show that the parallelized total Weihrauch lattice forms a Brouwer\nalgebra, we introduce a new multiplicative version of an implication. While the\nparallelized total Weihrauch lattice forms a Brouwer algebra with this\nimplication, the total Weihrauch lattice fails to be a model of intuitionistic\nlinear logic in two different ways. In order to pinpoint the algebraic reasons\nfor this failure, we introduce the concept of a Weihrauch algebra that allows\nus to formulate the failure in precise and neat terms. Finally, we show that\nthe Medvedev Brouwer algebra can be embedded into our Brouwer algebra, which\nalso implies that the theory of our Brouwer algebra is Jankov logic.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 19:53:35 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 12:23:13 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 15:27:31 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Brattka", "Vasco", ""], ["Gherardi", "Guido", ""]]}, {"id": "1809.00503", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Improving Convergence Rate Of IC3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IC3, a well-known model checker, proves a property of a transition system by\nbuilding a sequence of formulas $F_0,\\dots,F_k$. Formula $F_i$, $0 \\leq i \\leq\nk$ over-approximates the set of states reachable in at most $i$ transitions.\nThe basic algorithm of IC3 cannot guarantee that the value of $k$ never exceeds\nthe reachability diameter of the system. We describe an algorithm called IC4\nthat gives such a guarantee. (IC4 stands for 'IC3 + Improved Convergence'). One\ncan argue that the average convergence rate of IC4 is better than for IC3 as\nwell. Improving convergence can facilitate some other variations of the basic\nalgorithm. As an example, we describe a version of IC4 employing property\ndecomposition. The latter means replacing an original (strong) property with a\nconjunction of weaker properties to prove by IC4. We argue that addressing the\nconvergence problem is important for making the property decomposition approach\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 08:50:36 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 08:41:24 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2018 19:39:32 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "1809.00508", "submitter": "Joaqu\\'in Borrego-D\\'iaz", "authors": "Jos\\'e A. Alonso-Jim\\'enez, Gonzalo A. Aranda-Corral, Joaqu\\'in\n  Borrego-D\\'iaz, M. Magdalena Fern\\'andez-Lebr\\'on, M. Jos\\'e Hidalgo-Doblado", "title": "A logic-algebraic tool for reasoning with Knowledge-Based Systems", "comments": "41 pages, 7 figures. To appear in Journal of Logical and Algebraic\n  Methods in Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A detailed exposition of foundations of a logic-algebraic model for reasoning\nwith knowledge bases specified by propositional (Boolean) logic is presented.\nThe model is conceived from the logical translation of usual derivatives on\npolynomials (on residue rings) which is used to design a new inference rule of\nalgebro-geometric inspiration. Soundness and (refutational) completeness of the\nrule are proved. Some applications of the tools introduced in the paper are\nshown.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 09:00:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Alonso-Jim\u00e9nez", "Jos\u00e9 A.", ""], ["Aranda-Corral", "Gonzalo A.", ""], ["Borrego-D\u00edaz", "Joaqu\u00edn", ""], ["Fern\u00e1ndez-Lebr\u00f3n", "M. Magdalena", ""], ["Hidalgo-Doblado", "M. Jos\u00e9", ""]]}, {"id": "1809.00559", "submitter": "Yves Bertot", "authors": "Yves Bertot (MARELLE)", "title": "Formal Verification of a Geometry Algorithm: A Quest for Abstract Views\n  and Symmetry in Coq Proofs", "comments": null, "journal-ref": "International Colloquium on Theoretical of Computing (ICTAC), Oct\n  2018, Stellenbosch, South Africa", "doi": null, "report-no": null, "categories": "cs.LO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract is about an effort to build a formal description of a\ntriangulation algorithm starting with a naive description of the algorithm\nwhere triangles, edges, and triangulations are simply given as sets and the\nmost complex notions are those of boundary and separating edges. When\nperforming proofs about this algorithm, questions of symmetry appear and this\nexposition attempts to give an account of how these symmetries can be handled.\nAll this work relies on formal developments made with Coq and the mathematical\ncomponents library.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:32:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Bertot", "Yves", "", "MARELLE"]]}, {"id": "1809.00656", "submitter": "Larry Moss", "authors": "Alex Kruckman and Lawrence S. Moss", "title": "Exploring the Landscape of Relational Syllogistic Logics", "comments": null, "journal-ref": null, "doi": "10.1017/S1755020320000386", "report-no": null, "categories": "math.LO cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores relational syllogistic logics, a family of logical\nsystems related to reasoning about relations in extensions of the classical\nsyllogistic. These are all decidable logical systems. We prove completeness\ntheorems and complexity results for a natural subfamily of relational\nsyllogistic logics, parametrized by constructors for terms and for sentences.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:57:54 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kruckman", "Alex", ""], ["Moss", "Lawrence S.", ""]]}, {"id": "1809.00772", "submitter": "Zhongxi Zhang", "authors": "Zhongxi Zhang, Qingguo Li and Nan Zhang", "title": "A characterization of the consistent Hoare powerdomains over dcpos", "comments": "6 pages, a direct characterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that for a dcpo P, the Scott closure of \\Gamma_c(P) in\n\\Gamma(P) is a consistent Hoare powerdomain of P, where \\Gamma_c(P) is the\nfamily of nonempty, consistent and Scott closed subsets of P, and \\Gamma(P) is\nthe collection of all nonempty Scott closed subsets of P. In this paper, by\nintroducing the notion of a \\vee-existing set, we present a direct\ncharacterization of the consistent Hoare powerdomain: the set of all\n\\vee-existing Scott closed subsets of a dcpo P is exactly the consistent Hoare\npowerdomain of P. We also introduce the concept of an F-Scott closed set over\neach dcpo-\\vee-semilattice. We prove that the Scott closed set lattice of a\ndcpo P is isomorphic to the family of all F-Scott closed sets of P's consistent\nHoare powerdomain.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 02:23:09 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhang", "Zhongxi", ""], ["Li", "Qingguo", ""], ["Zhang", "Nan", ""]]}, {"id": "1809.01103", "submitter": "Adilson Bonifacio", "authors": "Adilson Luiz Bonifacio and Wellington Aparecido Della Mura", "title": "An automatic tool for checking multi-party contracts", "comments": "28 pages, 26 figures, 3 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contracts play an important role in business where relationships among\ndifferent parties are dictated by legal rules. The notion of electronic\ncontracts has emerged mostly due to technological advances and the electronic\ntrading among companies and customers. Thereby new challenges have arisen to\nguarantee reliability among the stakeholders in electronic negotiations. In\nthis scenery, the automatic verification of electronic contracts appeared as\nthe solution but as a new challenge at the same time. An important task on\nverifying contracts is concerned of detecting conflicts in multi-party\ncontracts. The problem of checking contracts has been largely addressed in the\nliterature, but we are not aware about any method and tool that deals with\nmulti-party contracts and conflict detection using a contract language. This\nwork presents an automatic checker, so-called RECALL, for finding conflicts on\nmulti-party contracts modeled by an extension of a contract language. We\ndeveloped an automatic checking tool and also applied it to a a well-known case\nstudy of selling products that is characterized by multi-party aspects of the\ncontracts. We also performed some experiments in order to show the tool\nperformance w.r.t. the size of contracts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 17:14:36 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Bonifacio", "Adilson Luiz", ""], ["Della Mura", "Wellington Aparecido", ""]]}, {"id": "1809.01607", "submitter": "Heinz Riener", "authors": "Roderick Bloem and Goerschwin Fey and Fabian Greif and Robert\n  Koenighofer and Ingo Pill and Heinz Riener and Franz Roeck", "title": "Synthesizing Adaptive Test Strategies from Temporal Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing good test cases is difficult and time-consuming, especially if\nthe system under test is still under development and its exact behavior is not\nyet fixed. We propose a new approach to compute test strategies for reactive\nsystems from a given temporal logic specification using formal methods. The\ncomputed strategies are guaranteed to reveal certain simple faults in every\nrealization of the specification and for every behavior of the uncontrollable\npart of the system's environment. The proposed approach supports different\nassumptions on occurrences of faults (ranging from a single transient fault to\na persistent fault) and by default aims at unveiling the weakest one. Based on\nwell-established hypotheses from fault-based testing, we argue that such tests\nare also sensitive for more complex bugs. Since the specification may not\ndefine the system behavior completely, we use reactive synthesis algorithms\nwith partial information. The computed strategies are adaptive test strategies\nthat react to behavior at runtime. We work out the underlying theory of\nadaptive test strategy synthesis and present experiments for a safety-critical\ncomponent of a real-world satellite system. We demonstrate that our approach\ncan be applied to industrial specifications and that the synthesized test\nstrategies are capable of detecting bugs that are hard to detect with random\ntesting.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:24:51 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bloem", "Roderick", ""], ["Fey", "Goerschwin", ""], ["Greif", "Fabian", ""], ["Koenighofer", "Robert", ""], ["Pill", "Ingo", ""], ["Riener", "Heinz", ""], ["Roeck", "Franz", ""]]}, {"id": "1809.01621", "submitter": "Marco Antonio Casanova", "authors": "Marco A. Casanova, R\\^omulo Magalh\\~aes", "title": "An Algebra of Lightweight Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues that certain ontology design problems are profitably\naddressed by treating ontologies as theories and by defining a set of\noperations that create new ontologies, including their constraints, out of\nother ontologies. The paper first shows how to use the operations in the\ncontext of ontology reuse, how to take advantage of the operations to compare\ndifferent ontologies, or different versions of an ontology, and how the\noperations may help design mediated schemas in a bottom up fashion. The core of\nthe paper discusses how to compute the operations for lightweight ontologies\nand addresses the question of minimizing the set of constraints of a\nlightweight ontology. Finally, the paper describes an implementation of the\noperations, as a Prot\\'eg\\'e plug-in.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:00:10 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Casanova", "Marco A.", ""], ["Magalh\u00e3es", "R\u00f4mulo", ""]]}, {"id": "1809.02229", "submitter": "Thorsten Wissmann", "authors": "Adriana Balan, Alexander Kurz and Ji\\v{r}\\'i Velebil", "title": "Extending set functors to generalised metric spaces", "comments": "57 pages; extended version of the paper presented at CALCO 2015;\n  accepted for publication in LMCS; Sections 2.4 and 3.3 were added", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (January\n  29, 2019) lmcs:5132", "doi": "10.23638/LMCS-15(1:5)2019", "report-no": null, "categories": "math.CT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a commutative quantale $\\mathcal{V}$, the category $\\mathcal{V}-cat$ can\nbe perceived as a category of generalised metric spaces and non-expanding maps.\nWe show that any type constructor $T$ (formalised as an endofunctor on sets)\ncan be extended in a canonical way to a type constructor $T_{\\mathcal{V}}$ on\n$\\mathcal{V}-cat$. The proof yields methods of explicitly calculating the\nextension in concrete examples, which cover well-known notions such as the\nPompeiu-Hausdorff metric as well as new ones.\n  Conceptually, this allows us to to solve the same recursive domain equation\n$X\\cong TX$ in different categories (such as sets and metric spaces) and we\nstudy how their solutions (that is, the final coalgebras) are related via\nchange of base.\n  Mathematically, the heart of the matter is to show that, for any commutative\nquantale $\\mathcal{V}$, the `discrete' functor $D:\\mathsf{Set}\\to\n\\mathcal{V}-cat$ from sets to categories enriched over $\\mathcal{V}$ is\n$\\mathcal{V}-cat$-dense and has a density presentation that allows us to\ncompute left-Kan extensions along $D$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 21:37:08 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 19:47:11 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 14:21:12 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Balan", "Adriana", ""], ["Kurz", "Alexander", ""], ["Velebil", "Ji\u0159\u00ed", ""]]}, {"id": "1809.02416", "submitter": "EPTCS", "authors": "Andrea Orlandini (National Research Council of Italy), Martin\n  Zimmermann (Saarland University)", "title": "Proceedings Ninth International Symposium on Games, Automata, Logics,\n  and Formal Verification", "comments": null, "journal-ref": "EPTCS 277, 2018", "doi": "10.4204/EPTCS.277", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Ninth International Symposium on\nGames, Automata, Logic and Formal Verification (GandALF 2018). The symposium\ntook place in Saarbr\\\"ucken, Germany, from the 26th to the 28th of September\n2018. The GandALF symposium was established by a group of Italian computer\nscientists interested in mathematical logic, automata theory, game theory, and\ntheir applications to the specification, design, and verification of complex\nsystems. Its aim is to provide a forum where people from different areas, and\npossibly with different backgrounds, can fruitfully interact. GandALF has a\ntruly international spirit, as witnessed by the composition of the program and\nsteering committee and by the country distribution of the submitted papers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 11:41:03 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Orlandini", "Andrea", "", "National Research Council of Italy"], ["Zimmermann", "Martin", "", "Saarland University"]]}, {"id": "1809.02659", "submitter": "Thorsten Wissmann", "authors": "Emma Kerinec, Giulio Manzonetto, Michele Pagani", "title": "Revisiting Call-by-value B\\\"ohm trees in light of their Taylor expansion", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (July 15,\n  2020) lmcs:6638", "doi": "10.23638/LMCS-16(3:6)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The call-by-value lambda calculus can be endowed with permutation rules,\narising from linear logic proof-nets, having the advantage of unblocking some\nredexes that otherwise get stuck during the reduction. We show that such an\nextension allows to define a satisfying notion of B\\\"ohm(-like) tree and a\ntheory of program approximation in the call-by-value setting. We prove that all\nlambda terms having the same B\\\"ohm tree are observationally equivalent, and\ncharacterize those B\\\"ohm-like trees arising as actual B\\\"ohm trees of lambda\nterms.\n  We also compare this approach with Ehrhard's theory of program approximation\nbased on the Taylor expansion of lambda terms, translating each lambda term\ninto a possibly infinite set of so-called resource terms. We provide sufficient\nand necessary conditions for a set of resource terms in order to be the Taylor\nexpansion of a lambda term. Finally, we show that the normal form of the Taylor\nexpansion of a lambda term can be computed by performing a normalized Taylor\nexpansion of its B\\\"ohm tree. From this it follows that two lambda terms have\nthe same B\\\"ohm tree if and only if the normal forms of their Taylor expansions\ncoincide.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:16:32 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 21:11:19 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 12:15:54 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 10:13:35 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kerinec", "Emma", ""], ["Manzonetto", "Giulio", ""], ["Pagani", "Michele", ""]]}, {"id": "1809.02781", "submitter": "Ale\\v{s} Bizjak", "authors": "Dimitris Mostrous, Vasco T. Vasconcelos", "title": "Affine Sessions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (November\n  15, 2018) lmcs:4973", "doi": "10.23638/LMCS-14(4:14)2018", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Session types describe the structure of communications implemented by\nchannels. In particular, they prescribe the sequence of communications, whether\nthey are input or output actions, and the type of value exchanged. Crucial to\nany language with session types is the notion of linearity, which is essential\nto ensure that channels exhibit the behaviour prescribed by their type without\ninterference in the presence of concurrency. In this work we relax the\ncondition of linearity to that of affinity, by which channels exhibit at most\nthe behaviour prescribed by their types. This more liberal setting allows us to\nincorporate an elegant error handling mechanism which simplifies and improves\nrelated works on exceptions. Moreover, our treatment does not affect the\nprogress properties of the language: sessions never get stuck.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 09:39:30 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 10:46:33 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Mostrous", "Dimitris", ""], ["Vasconcelos", "Vasco T.", ""]]}, {"id": "1809.02941", "submitter": "Victor Selivanov", "authors": "Victor Selivanov", "title": "Well Quasiorders and Hierarchy Theory", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss some applications of WQOs to several fields were hierarchies and\nreducibilities are the principal classification tools, notably to Descriptive\nSet Theory, Computability theory and Automata Theory. While the classical\nhierarchies of sets usually degenerate to structures very close to ordinals,\nthe extension of them to functions requires more complicated WQOs, and the same\napplies to reducibilities. We survey some results obtained so far and discuss\nopen problems and possible research directions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 08:49:12 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Selivanov", "Victor", ""]]}, {"id": "1809.03001", "submitter": "C. Maria Keet", "authors": "Pablo Rub\\'en Fillottrani and C. Maria Keet", "title": "Evidence-based lean logic profiles for conceptual data modelling\n  languages", "comments": "22 pages, 5 figures, 5 tables, 100 references; substantial extension\n  to the ADBIS'15 paper; submitted to an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple logic-based reconstructions of conceptual data modelling languages\nsuch as EER, UML Class Diagrams, and ORM exist. They mainly cover various\nfragments of the languages and none are formalised such that the logic applies\nsimultaneously for all three modelling language families as unifying mechanism.\nThis hampers interchangeability, interoperability, and tooling support. In\naddition, due to the lack of a systematic design process of the logic used for\nthe formalisation, hidden choices permeate the formalisations that have\nrendered them incompatible. We aim to address these problems, first, by\nstructuring the logic design process in a methodological way. We generalise and\nextend the DSL design process to apply to logic language design more generally\nand, in particular, by incorporating an ontological analysis of language\nfeatures in the process. Second, we specify minimal logic profiles availing of\nthis extended process, including the ontological commitments embedded in the\nlanguages, of evidence gathered of language feature usage, and of computational\ncomplexity insights from Description Logics (DL). The profiles characterise the\nessential logic structure needed to handle the semantics of conceptual models,\ntherewith enabling the development of interoperability tools. There is no known\nDL language that matches exactly the features of those profiles and the common\ncore is small (in the tractable DL $\\mathcal{ALNI}$). Although hardly any\ninconsistencies can be derived with the profiles, it is promising for scalable\nruntime use of conceptual data models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 16:22:43 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:19:26 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Fillottrani", "Pablo Rub\u00e9n", ""], ["Keet", "C. Maria", ""]]}, {"id": "1809.03094", "submitter": "EPTCS", "authors": "Federico Aschieri (TU Wien), Agata Ciabattoni (TU Wien), Francesco\n  Antonio Genco (TU Wien)", "title": "Classical Proofs as Parallel Programs", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416. arXiv admin note: text\n  overlap with arXiv:1607.05120", "journal-ref": "EPTCS 277, 2018, pp. 43-57", "doi": "10.4204/EPTCS.277.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a first proofs-as-parallel-programs correspondence for classical\nlogic. We define a parallel and more powerful extension of the simply typed\nlambda calculus corresponding to an analytic natural deduction based on the\nexcluded middle law. The resulting functional language features a natural\nhigher-order communication mechanism between processes, which also supports\nbroadcasting. The normalization procedure makes use of reductions that\nimplement novel techniques for handling and transmitting process closures.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:30:10 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Aschieri", "Federico", "", "TU Wien"], ["Ciabattoni", "Agata", "", "TU Wien"], ["Genco", "Francesco Antonio", "", "TU Wien"]]}, {"id": "1809.03095", "submitter": "EPTCS", "authors": "\\'Eric Goubault (\\'Ecole Polytechnique), J\\'er\\'emy Ledent (\\'Ecole\n  Polytechnique), Sergio Rajsbaum (UNAM)", "title": "A Simplicial Complex Model for Dynamic Epistemic Logic to study\n  Distributed Task Computability", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 73-87", "doi": "10.4204/EPTCS.277.6", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usual epistemic model S5n for a multi-agent system is based on a Kripke\nframe, which is a graph whose edges are labeled with agents that do not\ndistinguish between two states. We propose to uncover the higher dimensional\ninformation implicit in this structure, by considering a dual, simplicial\ncomplex model. We use dynamic epistemic logic (DEL) to study how an epistemic\nsimplicial complex model changes after a set of agents communicate with each\nother. We concentrate on an action model that represents the so called\nimmediate snapshot communication patterns of asynchronous agents, because it is\ncentral to distributed computability (but our setting works for other\ncommunication patterns). There are topological invariants preserved from the\ninitial epistemic complex to the one after the action model is applied, which\ndetermine the knowledge that the agents gain after communication. Finally, we\ndescribe how a distributed task specification can be modeled as a DEL action\nmodel, and show that the topological invariants determine whether the task is\nsolvable. We thus provide a bridge between DEL and the topological theory of\ndistributed computability, which studies task solvability in a shared memory or\nmessage passing architecture.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:30:43 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Goubault", "\u00c9ric", "", "\u00c9cole Polytechnique"], ["Ledent", "J\u00e9r\u00e9my", "", "\u00c9cole\n  Polytechnique"], ["Rajsbaum", "Sergio", "", "UNAM"]]}, {"id": "1809.03097", "submitter": "EPTCS", "authors": "Lisette Sanchez, Wieger Wesselink, Tim A.C. Willemse", "title": "A Comparison of BDD-Based Parity Game Solvers", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 103-117", "doi": "10.4204/EPTCS.277.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parity games are two player games with omega-winning conditions, played on\nfinite graphs. Such games play an important role in verification,\nsatisfiability and synthesis. It is therefore important to identify algorithms\nthat can efficiently deal with large games that arise from such applications.\nIn this paper, we describe our experiments with BDD-based implementations of\nfour parity game solving algorithms, viz. Zielonka's recursive algorithm, the\nmore recent Priority Promotion algorithm, the Fixpoint-Iteration algorithm and\nthe automata based APT algorithm. We compare their performance on several types\nof random games and on a number of cases taken from the Keiren benchmark set.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:31:25 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sanchez", "Lisette", ""], ["Wesselink", "Wieger", ""], ["Willemse", "Tim A. C.", ""]]}, {"id": "1809.03098", "submitter": "EPTCS", "authors": "Petra van den Bos, Marielle Stoelinga", "title": "Tester versus Bug: A Generic Framework for Model-Based Testing via Games", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 118-132", "doi": "10.4204/EPTCS.277.9", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic game-based approach for test case generation. We set up\na game between the tester and the System Under Test, in such a way that test\ncases correspond to game strategies, and the conformance relation ioco\ncorresponds to alternating refinement. We show that different test assumptions\nfrom the literature can be easily incorporated, by slightly varying the moves\nin the games and their outcomes. In this way, our framework allows a wide\nplethora of game-theoretic techniques to be deployed for model based testing.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:31:49 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bos", "Petra van den", ""], ["Stoelinga", "Marielle", ""]]}, {"id": "1809.03099", "submitter": "EPTCS", "authors": "A.R. Balasubramanian (Chennai Mathematical Institute)", "title": "Parameterized Verification of Coverability in Well-Structured Broadcast\n  Networks", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 133-146", "doi": "10.4204/EPTCS.277.10", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized verification of coverability in broadcast networks with finite\nstate processes has been studied for different types of models and topologies.\nIn this paper, we attempt to develop a theory of broadcast networks in which\nthe processes can be well-structured transition systems. The resulting\nformalism is called well-structured broadcast networks. We give an algorithm to\ndecide coverability of well-structured broadcast networks when reconfiguration\nof links between nodes is allowed. Further, for various types of communication\ntopologies, we also prove the decidability of coverability in the static case\nas well. We do this by showing that for these types of static communication\ntopologies, the broadcast network itself is a well-structured transition\nsystem, hence proving the decidability of coverability in the broadcast\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:32:08 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Balasubramanian", "A. R.", "", "Chennai Mathematical Institute"]]}, {"id": "1809.03100", "submitter": "EPTCS", "authors": "Michele Chiari (DEIB, Politecnico di Milano), Dino Mandrioli (DEIB,\n  Politecnico di Milano), Matteo Pradella (DEIB, Politecnico di Milano, and\n  IEIIT, Consiglio Nazionale delle Ricerche)", "title": "Temporal Logic and Model Checking for Operator Precedence Languages", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 161-175", "doi": "10.4204/EPTCS.277.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decades much research effort has been devoted to extending the\nsuccess of model checking from the traditional field of finite state machines\nand various versions of temporal logics to suitable subclasses of context-free\nlanguages and appropriate extensions of temporal logics. To the best of our\nknowledge such attempts only covered structured languages, i.e. languages whose\nstructure is immediately \"visible\" in their sentences, such as tree-languages\nor visibly pushdown ones. In this paper we present a new temporal logic\nsuitable to express and automatically verify properties of operator precedence\nlanguages. This \"historical\" language family has been recently proved to enjoy\nfundamental algebraic and logic properties that make it suitable for model\nchecking applications yet breaking the barrier of visible-structure languages\n(in fact the original motivation of its inventor Floyd was just to support\nefficient parsing, i.e. building the \"hidden syntax tree\" of language\nsentences). We prove that our logic is at least as expressive as analogous\nlogics defined for visible pushdown languages yet covering a much more powerful\nfamily; we design a procedure that, given a formula in our logic builds an\nautomaton recognizing the sentences satisfying the formula, whose size is at\nmost exponential in the length of the formula.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:32:56 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Chiari", "Michele", "", "DEIB, Politecnico di Milano"], ["Mandrioli", "Dino", "", "DEIB,\n  Politecnico di Milano"], ["Pradella", "Matteo", "", "DEIB, Politecnico di Milano, and\n  IEIIT, Consiglio Nazionale delle Ricerche"]]}, {"id": "1809.03101", "submitter": "EPTCS", "authors": "Luca Geatti (University of Udine, Italy), Nicola Gigante (University\n  of Udine, Italy), Angelo Montanari (University of Udine, Italy), Mark\n  Reynolds (University of Western Australia)", "title": "One-Pass and Tree-Shaped Tableau Systems for TPTL and TPTLb+Past", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 176-190", "doi": "10.4204/EPTCS.277.13", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel one-pass and tree-shaped tableau method for\nTimed Propositional Temporal Logic and for a bounded variant of its extension\nwith past operators. Timed Propositional Temporal Logic (TPTL) is a real-time\ntemporal logic, with an EXPSPACE-complete satisfiability problem, which has\nbeen successfully applied to the verification of real-time systems. In contrast\nto LTL, adding past operators to TPTL makes the satisfiability problem for the\nresulting logic (TPTL+P) non-elementary. In this paper, we devise a one-pass\nand tree-shaped tableau for both TPTL and bounded TPTL+P (TPTLb+P), a syntactic\nrestriction introduced to encode timeline-based planning problems, which\nrecovers the EXPSPACE-complete complexity. The tableau systems for TPTL and\nTPTLb+P are presented in a unified way, being very similar to each other,\nproviding a common skeleton that is then specialised to each logic. In doing\nthat, we characterise the semantics of TPTLb+P in terms of a purely syntactic\nfragment of TPTL+P, giving a translation that embeds the former into the\nlatter. Soundness and completeness of the system are proved fully. In\nparticular, we give a greatly simplified model-theoretic completeness proof,\nwhich sidesteps the complex combinatorial argument used by known proofs for the\none-pass and tree-shaped tableau systems for LTL and LTL+P.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:33:19 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Geatti", "Luca", "", "University of Udine, Italy"], ["Gigante", "Nicola", "", "University\n  of Udine, Italy"], ["Montanari", "Angelo", "", "University of Udine, Italy"], ["Reynolds", "Mark", "", "University of Western Australia"]]}, {"id": "1809.03103", "submitter": "EPTCS", "authors": "Laura Bozzelli (University of Napoli Federico II, Italy), Alberto\n  Molinari (University of Udine, Italy), Angelo Montanari (University of Udine,\n  Italy), Adriano Peron (University of Napoli Federico II, Italy)", "title": "Complexity of Timeline-Based Planning over Dense Temporal Domains:\n  Exploring the Middle Ground", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 191-205", "doi": "10.4204/EPTCS.277.14", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address complexity issues for timeline-based planning over\ndense temporal domains. The planning problem is modeled by means of a set of\nindependent, but interacting, components, each one represented by a number of\nstate variables, whose behavior over time (timelines) is governed by a set of\ntemporal constraints (synchronization rules). While the temporal domain is\nusually assumed to be discrete, here we consider the dense case. Dense\ntimeline-based planning has been recently shown to be undecidable in the\ngeneral case; decidability (NP-completeness) can be recovered by restricting to\npurely existential synchronization rules (trigger-less rules). In this paper,\nwe investigate the unexplored area of intermediate cases in between these two\nextremes. We first show that decidability and non-primitive recursive-hardness\ncan be proved by admitting synchronization rules with a trigger, but forcing\nthem to suitably check constraints only in the future with respect to the\ntrigger (future simple rules). More \"tractable\" results can be obtained by\nadditionally constraining the form of intervals in future simple rules:\nEXPSPACE-completeness is guaranteed by avoiding singular intervals,\nPSPACE-completeness by admitting only intervals of the forms [0,a] and\n[b,$\\infty$[.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:33:42 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bozzelli", "Laura", "", "University of Napoli Federico II, Italy"], ["Molinari", "Alberto", "", "University of Udine, Italy"], ["Montanari", "Angelo", "", "University of Udine,\n  Italy"], ["Peron", "Adriano", "", "University of Napoli Federico II, Italy"]]}, {"id": "1809.03104", "submitter": "EPTCS", "authors": "Marcin Przyby{\\l}ko", "title": "On Computing the Measures of First-Order Definable Sets of Trees", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 206-219", "doi": "10.4204/EPTCS.277.15", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the measure of a regular language of\ninfinite binary trees. While the general case remains unsolved, we show that\nthe measure of a language defined by a first-order formula with no descendant\nrelation or by a Boolean combination of conjunctive queries (with descendant\nrelation) is rational and computable. Additionally, we provide an example of a\nfirst-order formula that uses descendant relation and defines a language of\ninfinite trees having an irrational measure.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:34:04 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Przyby\u0142ko", "Marcin", ""]]}, {"id": "1809.03106", "submitter": "EPTCS", "authors": "Thiago Alves Rocha (Federal Institute of Cear\\'a), Ana Teresa Martins\n  (Federal University of Cear\\'a), Francicleber Martins Ferreira (Federal\n  University of Cear\\'a)", "title": "On Finding a First-Order Sentence Consistent with a Sample of Strings", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 220-234", "doi": "10.4204/EPTCS.277.16", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the following problem: given a sample of classified strings,\nfind a first-order sentence of minimal quantifier rank that is consistent with\nthe sample. We represent strings as successor string structures, that is,\nfinite structures with unary predicates to denote symbols in an alphabet, and a\nsuccessor relation. We use results of the Ehrenfeucht-Fra\\\"iss\\'e game over\nsuccessor string structures in order to design an algorithm to find such\nsentence. We use conditions characterizing the winning strategies for the\nSpoiler on successor strings structures in order to define formulas which\ndistinguish two strings. Our algorithm returns a boolean combination of such\nformulas.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:34:22 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Rocha", "Thiago Alves", "", "Federal Institute of Cear\u00e1"], ["Martins", "Ana Teresa", "", "Federal University of Cear\u00e1"], ["Ferreira", "Francicleber Martins", "", "Federal\n  University of Cear\u00e1"]]}, {"id": "1809.03107", "submitter": "EPTCS", "authors": "Patricia Bouyer, Mauricio Gonz\\'alez, Nicolas Markey, Mickael Randour", "title": "Multi-weighted Markov Decision Processes with Reachability Objectives", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 250-264", "doi": "10.4204/EPTCS.277.18", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are interested in the synthesis of schedulers in\ndouble-weighted Markov decision processes, which satisfy both a percentile\nconstraint over a weighted reachability condition, and a quantitative\nconstraint on the expected value of a random variable defined using a weighted\nreachability condition. This problem is inspired by the modelization of an\nelectric-vehicle charging problem. We study the cartography of the problem,\nwhen one parameter varies, and show how a partial cartography can be obtained\nvia two sequences of opimization problems. We discuss completeness and\nfeasability of the method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:34:59 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bouyer", "Patricia", ""], ["Gonz\u00e1lez", "Mauricio", ""], ["Markey", "Nicolas", ""], ["Randour", "Mickael", ""]]}, {"id": "1809.03162", "submitter": "Dmitry Brizhinev", "authors": "Dmitry Brizhinev, Rajeev Gor\\'e", "title": "A case study in formal verification of a Java program", "comments": "Written in August 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a successful attempt to formally verify a simple genetic\nalgorithm written in Java. To this end, we compare several formal verification\ntools designed for Java, and select Krakatoa as the most appropriate for the\ntask. Based on our experience, we present several suggestions for making the\ntools more user friendly, which we hope will lead to wider adoption of formal\nmethods. In particular, we discuss at length how useful it would be for provers\nto perform some form of abduction, that is, for them to guess which extra\nassumptions they need to prove a statement. It is our opinion that progress in\nthis area would produce the largest improvement in the usability of formal\nverification tools.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 07:41:46 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Brizhinev", "Dmitry", ""], ["Gor\u00e9", "Rajeev", ""]]}, {"id": "1809.03220", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (IMJ-PRG)", "title": "An Effective Property of $\\omega$-Rational Functions", "comments": "arXiv admin note: text overlap with arXiv:1107.5886", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that $\\omega$-regular languages accepted by B\\\"uchi or Muller\nautomata satisfy an effective automata-theoretic version of the Baire property.\nThen we use this result to obtain a new effective property of rational\nfunctions over infinite words which are realized by finite state B\\\"uchi\ntransducers: for each such function $F: \\Sigma^\\omega \\rightarrow\n\\Gamma^\\omega$, one can construct a deterministic B\\\"uchi automaton\n$\\mathcal{A}$ accepting a dense ${\\bf \\Pi}^0_2$-subset of $\\Sigma^\\omega$ such\nthat the restriction of $F$ to $L(\\mathcal{A})$ is continuous.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:48:11 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Finkel", "Olivier", "", "IMJ-PRG"]]}, {"id": "1809.03245", "submitter": "Emanuel Kieronski", "authors": "Daniel Danielski and Emanuel Kieronski", "title": "Finite Satisfiability of Unary Negation Fragment with Transitivity", "comments": "Accepted for MFCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the finite satisfiability problem for the unary negation\nfragment with arbitrary number of transitive relations is decidable and\n2-ExpTime-complete. Our result actually holds for a more general setting in\nwhich one can require that some binary symbols are interpreted as arbitrary\ntransitive relations, some as partial orders and some as equivalences. We also\nconsider finite satisfiability of various extensions of our primary logic, in\nparticular capturing the concepts of nominals and role hierarchies known from\ndescription logic. As the unary negation fragment can express unions of\nconjunctive queries our results have interesting implications for the problem\nof finite query answering, both in the classical scenario and in the\ndescription logics setting.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 11:43:47 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 17:20:36 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 08:36:17 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Danielski", "Daniel", ""], ["Kieronski", "Emanuel", ""]]}, {"id": "1809.03252", "submitter": "Satoshi Egi", "authors": "Satoshi Egi", "title": "Loop Patterns: Extension of Kleene Star Operator for More Expressive\n  Pattern Matching against Arbitrary Data Structures", "comments": "14 pages, Scheme and Functional Programming Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kleene star operator is an important pattern construct for representing a\npattern that repeats multiple times. Due to its simplicity and usefulness, it\nis imported into various pattern-matching systems other than regular\nexpressions. For example, Mathematica has a similar pattern construct called\nthe repeated pattern. However, they have the following limitations: (i) We\ncannot change the pattern repeated depending on the current repeat count, and\n(ii) we cannot apply them to arbitrary data structures such as trees and graphs\nother than lists. This paper proposes the loop patterns that overcome these\nlimitations. This paper presents numerous working examples and formal semantics\nof the loop patterns. The examples in this paper are coded in the Egison\nprogramming language, which features the customizable non-linear\npattern-matching facility for non-free data types.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 11:59:47 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Egi", "Satoshi", ""]]}, {"id": "1809.03254", "submitter": "Jakub Michaliszyn", "authors": "Jakub Michaliszyn", "title": "Elementary Multimodal Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multimodal logics over universally first-order definable classes of\nframes. We show that even for bimodal logics, there are universal Horn formulas\nthat define set of frames such that the satisfiability problem is undecidable,\neven if one or two of the binary relations are transitive.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:01:13 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Michaliszyn", "Jakub", ""]]}, {"id": "1809.03262", "submitter": "Fabio Zanasi", "authors": "Facundo Carreiro, Alessandro Facchini, Yde Venema, Fabio Zanasi", "title": "Model Theory of Monadic Predicate Logic with the Infinity Quantifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes model-theoretic properties of $\\mathrm{FOE}^{\\infty}$,\na variation of monadic first-order logic that features the generalised\nquantifier $\\exists^\\infty$ (`there are infinitely many').\n  We provide syntactically defined fragments of $\\mathrm{FOE}^{\\infty}$\ncharacterising four different semantic properties of\n$\\mathrm{FOE}^{\\infty}$-sentences: (1) being monotone and (2) (Scott)\ncontinuous in a given set of monadic predicates; (3) having truth preserved\nunder taking submodels or (4) invariant under taking quotients. In each case,\nwe produce an effectively defined map that translates an arbitrary sentence\n$\\varphi$ to a sentence $\\varphi^{p}$ belonging to the corresponding syntactic\nfragment, with the property that $\\varphi$ is equivalent to $\\varphi^{p}$\nprecisely when it has the associated semantic property.\n  Our methodology is first to provide these results in the simpler setting of\nmonadic first-order logic with ($\\mathrm{FOE}$) and without ($\\mathrm{FO}$)\nequality, and then move to $\\mathrm{FOE}^{\\infty}$ by including the generalised\nquantifier $\\exists^\\infty$ into the picture.\n  As a corollary of our developments, we obtain that the four semantic\nproperties above are decidable for $\\mathrm{FOE}^{\\infty}$-sentences. Moreover,\nour results are directly relevant to the characterisation of automata and\nexpressiveness modulo bisimilirity for variants of monadic second-order logic.\nThis application is developed in a companion paper.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:12:28 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Carreiro", "Facundo", ""], ["Facchini", "Alessandro", ""], ["Venema", "Yde", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1809.03299", "submitter": "Jan K\\v{r}et\\'insk\\'y", "authors": "Pranav Ashok, Tom\\'a\\v{s} Br\\'azdil, Jan K\\v{r}et\\'insk\\'y and\n  Ond\\v{r}ej Sl\\'ame\\v{c}ka", "title": "Monte Carlo Tree Search for Verifying Reachability in Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum reachability probabilities in a Markov decision process can be\ncomputed using value iteration (VI). Recently, simulation-based heuristic\nextensions of VI have been introduced, such as bounded real-time dynamic\nprogramming (BRTDP), which often manage to avoid explicit analysis of the whole\nstate space while preserving guarantees on the computed result. In this paper,\nwe introduce a new class of such heuristics, based on Monte Carlo tree search\n(MCTS), a technique celebrated in various machine-learning settings. We provide\na spectrum of algorithms ranging from MCTS to BRTDP. We evaluate these\ntechniques and show that for larger examples, where VI is no more applicable,\nour techniques are more broadly applicable than BRTDP with only a minor\nadditional overhead.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 13:31:02 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ashok", "Pranav", ""], ["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Sl\u00e1me\u010dka", "Ond\u0159ej", ""]]}, {"id": "1809.03656", "submitter": "Francesco Olivieri", "authors": "Francesco Olivieri, Guido Governatori, Matteo Cristani, Nick van\n  Beest, Silvano Colombo-Tosatto", "title": "Resource-driven Substructural Defeasible Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Logic and Defeasible Logic have been adopted to formalise different\nfeatures relevant to agents: consumption of resources, and reasoning with\nexceptions. We propose a framework to combine sub-structural features,\ncorresponding to the consumption of resources, with defeasibility aspects, and\nwe discuss the design choices for the framework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 02:09:03 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Olivieri", "Francesco", ""], ["Governatori", "Guido", ""], ["Cristani", "Matteo", ""], ["van Beest", "Nick", ""], ["Colombo-Tosatto", "Silvano", ""]]}, {"id": "1809.03739", "submitter": "Lucas Carvalho Cordeiro", "authors": "Lucas Cordeiro, Daniel Kroening and Peter Schrammel", "title": "Benchmarking of Java Verification Tools at the Software Verification\n  Competition (SV-COMP)", "comments": "JPF 2018 Java PathFinder Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evaluation of verification tools by benchmarking is a common method\nin software verification research. The Competition on Software Verification\n(SV-COMP) aims at standardization and reproducibility of benchmarking within\nthe software verification community on an annual basis, through comparative\nevaluation of fully automatic software verifiers for C programs. Building upon\nthis success, here we describe how to re-use the ecosystem developed around\nSV-COMP for benchmarking Java verification tools. We provide a detailed\ndescription of the rules for benchmark verification tasks, the integration of\nnew tools into SV-COMP's benchmarking framework and also give experimental\nresults of a benchmarking run on state-of-the-art Java verification tools, JPF,\nSPF, JayHorn and JBMC.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 08:31:56 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 10:00:12 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cordeiro", "Lucas", ""], ["Kroening", "Daniel", ""], ["Schrammel", "Peter", ""]]}, {"id": "1809.03889", "submitter": "EPTCS", "authors": "Tobias R. Gundersen (Aalborg University), Florian Lorber (Aalborg\n  University), Ulrik Nyman (Aalborg University), Christian Ovesen (Aalborg\n  University)", "title": "Effortless Fault Localisation: Conformance Testing of Real-Time Systems\n  in Ecdar", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 147-160", "doi": "10.4204/EPTCS.277.11", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking of real-time systems has evolved throughout the years.\nRecently, the model checker Ecdar, using timed I/O automata, was used to\nperform compositional verification. However, in order to fully integrate model\nchecking of real-time systems into industrial development, we need a productive\nand reliable way to test if such a system conforms to its corresponding model.\nHence, we present an extension of Ecdar that integrates conformance testing\ninto a new IDE that now features modelling, verification, and testing. The new\ntool uses model-based mutation testing, requiring only the model and the system\nunder test, to locate faults and to prove the absence of certain types of\nfaults. It supports testing using either real-time or simulated time. It\nparallelises test-case generation and test execution to provide a significant\nspeed-up. We also introduce new mutation operators that improve the ability to\ndetect and locate faults. Finally, we conduct a case study with 140 faulty\nsystems, where Ecdar detects all faults.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:32:30 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Gundersen", "Tobias R.", "", "Aalborg University"], ["Lorber", "Florian", "", "Aalborg\n  University"], ["Nyman", "Ulrik", "", "Aalborg University"], ["Ovesen", "Christian", "", "Aalborg\n  University"]]}, {"id": "1809.03896", "submitter": "Fabio Zanasi", "authors": "Facundo Carreiro, Alessandro Facchini, Yde Venema, Fabio Zanasi", "title": "The Power of the Weak", "comments": "arXiv admin note: text overlap with arXiv:1401.4374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A landmark result in the study of logics for formal verification is Janin &\nWalukiewicz's theorem, stating that the modal $\\mu$-calculus ($\\mu\\mathrm{ML}$)\nis equivalent modulo bisimilarity to standard monadic second-order logic (here\nabbreviated as $\\mathrm{smso}$), over the class of labelled transition systems\n(LTSs for short). Our work proves two results of the same kind, one for the\nalternation-free fragment of $\\mu\\mathrm{ML}$ ($\\mu_D\\mathrm{ML}$) and one for\nweak $\\mathrm{mso}$ ($\\mathrm{wmso}$). Whereas it was known that\n$\\mu_D\\mathrm{ML}$ and $\\mathrm{wmso}$ are equivalent modulo bisimilarity on\nbinary trees, our analysis shows that the picture radically changes once we\nreason over arbitrary LTSs. The first theorem that we prove is that, over LTSs,\n$\\mu_D\\mathrm{ML}$ is equivalent modulo bisimilarity to noetherian\n$\\mathrm{mso}$ ($\\mathrm{nmso}$), a newly introduced variant of $\\mathrm{smso}$\nwhere second-order quantification ranges over \"well-founded\" subsets only. Our\nsecond theorem starts from $\\mathrm{wmso}$, and proves it equivalent modulo\nbisimilarity to a fragment of $\\mu_D\\mathrm{ML}$ defined by a notion of\ncontinuity. Analogously to Janin & Walukiewicz's result, our proofs are\nautomata-theoretic in nature: as another contribution, we introduce classes of\nparity automata characterising the expressiveness of $\\mathrm{wmso}$ and\n$\\mathrm{nmso}$ (on tree models) and of $\\mu_C\\mathrm{ML}$ and\n$\\mu_D\\mathrm{ML}$ (for all transition systems).\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:05:05 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Carreiro", "Facundo", ""], ["Facchini", "Alessandro", ""], ["Venema", "Yde", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1809.04456", "submitter": "Jan Paseka", "authors": "Ivan Chajda and Jan Paseka", "title": "Dynamic logic assigned to automata", "comments": "12 pages. arXiv admin note: text overlap with arXiv:1510.02972", "journal-ref": "International Journal of Theoretical Physics 56 (2017), 3794-3806", "doi": "10.1007/s10773-017-3311-0", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dynamic logic ${\\mathbf B}$ can be assigned to every automaton ${\\mathcal\nA}$ without regard if ${\\mathcal A}$ is deterministic or nondeterministic. This\nlogic enables us to formulate observations on ${\\mathcal A}$ in the form of\ncomposed propositions and, due to a transition functor $T$, it captures the\ndynamic behaviour of ${\\mathcal A}$. There are formulated conditions under\nwhich the automaton ${\\mathcal A}$ can be recovered by means of ${\\mathbf B}$\nand $T$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 10:58:20 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Chajda", "Ivan", ""], ["Paseka", "Jan", ""]]}, {"id": "1809.04468", "submitter": "Christoph Rauch", "authors": "Willem Conradie, Salih Durhan and Guido Sciavicco", "title": "An Integrated First-Order Theory of Points and Intervals over Linear\n  Orders (Part II)", "comments": "This is Part II of the paper `An Integrated First-Order Theory of\n  Points and Intervals over Linear Orders' arXiv:1805.08425v2. Therefore the\n  introduction, preliminaries and conclusions of the two papers are the same.\n  This version implements a few minor corrections and an update to the\n  affiliation of the second author", "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 2, Logic for\n  knowledge representation (April 1, 2020) lmcs:6260", "doi": "10.23638/LMCS-16(2:1)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are two natural and well-studied approaches to temporal ontology and\nreasoning: point-based and interval-based. Usually, interval-based temporal\nreasoning deals with points as a particular case of duration-less intervals. A\nrecent result by Balbiani, Goranko, and Sciavicco presented an explicit\ntwo-sorted point-interval temporal framework in which time instants (points)\nand time periods (intervals) are considered on a par, allowing the perspective\nto shift between these within the formal discourse. We consider here two-sorted\nfirst-order languages based on the same principle, and therefore including\nrelations, as first studied by Reich, among others, between points, between\nintervals, and inter-sort. We give complete classifications of its\nsub-languages in terms of relative expressive power, thus determining how many,\nand which, are the intrinsically different extensions of two-sorted first-order\nlogic with one or more such relations. This approach roots out the classical\nproblem of whether or not points should be included in a interval-based\nsemantics. In this Part II, we deal with the cases of all dense and the case of\nall unbounded linearly ordered sets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:06:25 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 11:48:26 GMT"}, {"version": "v3", "created": "Sat, 15 Sep 2018 09:15:19 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 19:20:06 GMT"}, {"version": "v5", "created": "Tue, 31 Mar 2020 17:23:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Conradie", "Willem", ""], ["Durhan", "Salih", ""], ["Sciavicco", "Guido", ""]]}, {"id": "1809.04492", "submitter": "Paulo Oliva", "authors": "Rob Arthan and Paulo Oliva", "title": "A Curry-Howard Correspondence for the Minimal Fragment of {\\L}ukasiewicz\n  Logic", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a term calculus ${\\cal B}$ which adds to the\naffine $\\lambda$-calculus with pairing a new construct allowing for a\nrestricted form of contraction. We obtain a Curry-Howard correspondence between\n${\\cal B}$ and the sub-structural logical system which we call \"minimal\n{\\L}ukasiewicz logic\", also known in the literature as the logic of hoops (a\ngeneralisation of MV-algebras). This logic lies strictly in between affine\nminimal logic and standard minimal logic. We prove that ${\\cal B}$ is strongly\nnormalising and has the Church-Rosser property. We also give examples of terms\nin ${\\cal B}$ corresponding to some important derivations from our work and the\nliterature. Finally, we discuss the relation between normalisation in ${\\cal\nB}$ and cut-elimination for a Gentzen-style formulation of minimal\n{\\L}ukasiewicz logic.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:45:35 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Arthan", "Rob", ""], ["Oliva", "Paulo", ""]]}, {"id": "1809.04554", "submitter": "EPTCS", "authors": "Temesghen Kahsai (Amazon), German Vidal (Universitat Politecnica de\n  Valencia)", "title": "Proceedings 5th Workshop on Horn Clauses for Verification and Synthesis", "comments": null, "journal-ref": "EPTCS 278, 2018", "doi": "10.4204/EPTCS.278", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Program Verification and Synthesis problems of interest can be modeled\ndirectly using Horn clauses and many recent advances in the CLP and CAV\ncommunities have centered around efficiently solving problems presented as Horn\nclauses.\n  The HCVS series of workshops aims to bring together researchers working in\nthe two communities of Constraint/Logic Programming (e.g., ICLP and CP),\nProgram Verification (e.g., CAV, TACAS, and VMCAI), and Automated Deduction\n(e.g., CADE, IJCAR), on the topic of Horn clause based analysis, verification,\nand synthesis.\n  Horn clauses for verification and synthesis have been advocated by these\ncommunities in different times and from different perspectives and HCVS is\norganized to stimulate interaction and a fruitful exchange and integration of\nexperiences.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:44:51 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Kahsai", "Temesghen", "", "Amazon"], ["Vidal", "German", "", "Universitat Politecnica de\n  Valencia"]]}, {"id": "1809.04770", "submitter": "EPTCS", "authors": "Emanuele De Angelis (DEC, University \"G. d'Annunzio\" of\n  Chieti-Pescara, Pescara, Italy), Fabio Fioravanti (DEC, University \"G.\n  d'Annunzio\" of Chieti-Pescara, Pescara, Italy), Adri\\'an Palacios (MiST,\n  DSIC, Universitat Polit\\`ecnica de Val\\`encia, Val\\`encia, Spain), Alberto\n  Pettorossi (University of Roma Tor Vergata, Roma, Italy), Maurizio Proietti\n  (CNR-IASI, Roma, Italy)", "title": "Bounded Symbolic Execution for Runtime Error Detection of Erlang\n  Programs", "comments": "In Proceedings HCVS 2018, arXiv:1809.04554", "journal-ref": "EPTCS 278, 2018, pp. 19-26", "doi": "10.4204/EPTCS.278.4", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamically typed languages, like Erlang, allow developers to quickly write\nprograms without explicitly providing any type information on expressions or\nfunction definitions. However, this feature makes those languages less reliable\nthan statically typed languages, where many runtime errors can be detected at\ncompile time. In this paper, we present a preliminary work on a tool that, by\nusing the well-known techniques of metaprogramming and symbolic execution, can\nbe used to perform bounded verification of Erlang programs. In particular, by\nusing Constraint Logic Programming, we develop an interpreter that, given an\nErlang program and a symbolic input for that program, returns answer\nconstraints that represent sets of concrete data for which the Erlang program\ngenerates a runtime error.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 04:48:36 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["De Angelis", "Emanuele", "", "DEC, University \"G. d'Annunzio\" of\n  Chieti-Pescara, Pescara, Italy"], ["Fioravanti", "Fabio", "", "DEC, University \"G.\n  d'Annunzio\" of Chieti-Pescara, Pescara, Italy"], ["Palacios", "Adri\u00e1n", "", "MiST,\n  DSIC, Universitat Polit\u00e8cnica de Val\u00e8ncia, Val\u00e8ncia, Spain"], ["Pettorossi", "Alberto", "", "University of Roma Tor Vergata, Roma, Italy"], ["Proietti", "Maurizio", "", "CNR-IASI, Roma, Italy"]]}, {"id": "1809.04771", "submitter": "EPTCS", "authors": "Ekaterina Komendantskaya Dr (Heriot-Watt University), Yue Li\n  (Heriot-Watt University)", "title": "Towards Coinductive Theory Exploration in Horn Clause Logic: Position\n  Paper", "comments": "In Proceedings HCVS 2018, arXiv:1809.04554", "journal-ref": "EPTCS 278, 2018, pp. 27-33", "doi": "10.4204/EPTCS.278.5", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coinduction occurs in two guises in Horn clause logic: in proofs of\nself-referencing properties and relations, and in proofs involving construction\nof (possibly irregular) infinite data. Both instances of coinductive reasoning\nappeared in the literature before, but a systematic analysis of these two kinds\nof proofs and of their relation was lacking. We propose a general\nproof-theoretic framework for handling both kinds of coinduction arising in\nHorn clause logic. To this aim, we propose a coinductive extension of Miller et\nal's framework of uniform proofs and prove its soundness relative to\ncoinductive models of Horn clause logic.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 04:48:51 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Dr", "Ekaterina Komendantskaya", "", "Heriot-Watt University"], ["Li", "Yue", "", "Heriot-Watt University"]]}, {"id": "1809.04772", "submitter": "EPTCS", "authors": "Ant\\'onio Ravara (NOVA LINCS and Dep of Informatics, FCT, NOVA\n  University of Lisbon)", "title": "A Simple Functional Presentation and an Inductive Correctness Proof of\n  the Horn Algorithm", "comments": "In Proceedings HCVS 2018, arXiv:1809.04554", "journal-ref": "EPTCS 278, 2018, pp. 34-48", "doi": "10.4204/EPTCS.278.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recursive formulation of the Horn algorithm for deciding the\nsatisfiability of propositional clauses. The usual presentations in imperative\npseudo-code are informal and not suitable for simple proofs of its main\nproperties. By defining the algorithm as a recursive function (computing a\nleast fixed-point), we achieve: 1) a concise, yet rigorous, formalisation; 2) a\nclear form of visualising executions of the algorithm, step-by-step; 3) precise\nresults, simple to state and with clean inductive proofs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 04:49:05 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Ravara", "Ant\u00f3nio", "", "NOVA LINCS and Dep of Informatics, FCT, NOVA\n  University of Lisbon"]]}, {"id": "1809.05017", "submitter": "Ayrat Khalimov", "authors": "Ayrat Khalimov, Benedikt Maderbacher, Roderick Bloem", "title": "Bounded Synthesis of Register Transducers", "comments": "full version of our ATVA'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive synthesis aims at automatic construction of systems from their\nbehavioural specifications. The research mostly focuses on synthesis of systems\ndealing with Boolean signals. But real-life systems are often described using\nbit-vectors, integers, etc. Bit-blasting would make such systems unreadable,\nhit synthesis scalability, and is not possible for infinite data-domains. One\nstep closer to real-life systems are register transducers: they can store\ndata-input into registers and later output the content of a register, but they\ndo not directly depend on the data-input, only on its comparison with the\nregisters. Previously it was proven that synthesis of register transducers from\nregister automata is undecidable, but there the authors considered transducers\nequipped with the unbounded queue of registers. First, we prove the problem\nbecomes decidable if bound the number of registers in transducers, by reducing\nthe problem to standard synthesis of Boolean systems. Second, we show how to\nuse quantified temporal logic, instead of automata, for specifications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:30:13 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Khalimov", "Ayrat", ""], ["Maderbacher", "Benedikt", ""], ["Bloem", "Roderick", ""]]}, {"id": "1809.05049", "submitter": "Longchun Wang", "authors": "Longchun Wang, Qingguo Li", "title": "Categorical Representations of Continuous Domains and Continuous\n  L-Domains Based on Closure Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closure space has proven to be a useful tool to restructure lattices and\nvarious order structures.This paper aims to provide a novel approach to\ncharacterizing some important kinds of continuous domains by means of closure\nspaces. By introducing an additional map into a given closure space, the notion\nof F-augmented generalized closure space is presented. It is shown that\nF-augmented generalized closure spaces generate exactly continuous domains.\nMoreover, the notion of approximable mapping is identified to represent\nScott-continuous functions between continuous domains. These results produce a\ncategory equivalent to that of continuous domains with Scottcontinuous\nfunctions. At the same time, two subclasses of F-augmented generalized closure\nspaces are considered which are representations of continuous L-domains and\ncontinuous bounded complete domains, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:29:53 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 10:44:47 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Wang", "Longchun", ""], ["Li", "Qingguo", ""]]}, {"id": "1809.05309", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "On Plans With Loops and Noise", "comments": "Proceedings of AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an influential paper, Levesque proposed a formal specification for\nanalysing the correctness of program-like plans, such as conditional plans,\niterative plans, and knowledge-based plans. He motivated a logical\ncharacterisation within the situation calculus that included binary sensing\nactions. While the characterisation does not immediately yield a practical\nalgorithm, the specification serves as a general skeleton to explore the\nsynthesis of program-like plans for reasonable, tractable fragments.\n  Increasingly, classical plan structures are being applied to stochastic\nenvironments such as robotics applications. This raises the question as to what\nthe specification for correctness should look like, since Levesque's account\nmakes the assumption that sensing is exact and actions are deterministic.\nBuilding on a situation calculus theory for reasoning about degrees of belief\nand noise, we revisit the execution semantics of generalised plans. The\nspecification is then used to analyse the correctness of example plans.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 08:58:49 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "1809.05314", "submitter": "Vaishak Belle", "authors": "Vaishak Belle, Hector J. Levesque", "title": "Reasoning about Discrete and Continuous Noisy Sensors and Effectors in\n  Dynamical Systems", "comments": "To appear in Artificial Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many approaches for reasoning about degrees of belief in the\npresence of noisy sensing and acting, the logical account proposed by Bacchus,\nHalpern, and Levesque is perhaps the most expressive. While their formalism is\nquite general, it is restricted to fluents whose values are drawn from discrete\nfinite domains, as opposed to the continuous domains seen in many robotic\napplications. In this work, we show how this limitation in that approach can be\nlifted. By dealing seamlessly with both discrete distributions and continuous\ndensities within a rich theory of action, we provide a very general logical\nspecification of how belief should change after acting and sensing in complex\nnoisy domains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 09:09:04 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Belle", "Vaishak", ""], ["Levesque", "Hector J.", ""]]}, {"id": "1809.05485", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Blameworthiness in Strategic Games", "comments": null, "journal-ref": "33rd AAAI Conference on Artificial Intelligence (AAAI-19), January\n  27-February 1, 2019, Honolulu, Hawaii, USA", "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are multiple notions of coalitional responsibility. The focus of this\npaper is on the blameworthiness defined through the principle of alternative\npossibilities: a coalition is blamable for a statement if the statement is\ntrue, but the coalition had a strategy to prevent it. The main technical result\nis a sound and complete bimodal logical system that describes properties of\nblameworthiness in one-shot games.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 16:09:50 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1809.05723", "submitter": "Margherita Zorzi", "authors": "Luca Paolini and Mauro Piccolo and Margherita Zorzi", "title": "QPCF: higher order languages and quantum circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  qPCF is a paradigmatic quantum programming language that ex- tends PCF with\nquantum circuits and a quantum co-processor. Quantum circuits are treated as\nclassical data that can be duplicated and manipulated in flexible ways by means\nof a dependent type system. The co-processor is essentially a standard QRAM\ndevice, albeit we avoid to store permanently quantum states in between two\nco-processor's calls. Despite its quantum features, qPCF retains the classic\nprogramming approach of PCF. We introduce qPCF syntax, typing rules, and its\noperational semantics. We prove fundamental properties of the system, such as\nPreservation and Progress Theorems. Moreover, we provide some higher-order\nexamples of circuit encoding.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:33:42 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Paolini", "Luca", ""], ["Piccolo", "Mauro", ""], ["Zorzi", "Margherita", ""]]}, {"id": "1809.05771", "submitter": "Joaqu\\'in Arias M.Sc.", "authors": "Joaqu\\'in Arias and Manuel Carro", "title": "Description, Implementation, and Evaluation of a Generic Design for\n  Tabled CLP", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic programming with tabling and constraints (TCLP, tabled constraint logic\nprogramming) has been shown to be more expressive and in some cases more\nefficient than LP, CLP or LP + tabling. Previous designs of TCLP systems did\nnot fully use entailment to determine call / answer subsumption and did not\nprovide a simple and well-documented interface to facilitate the integration of\nconstraint solvers in existing tabling systems. We study the role of projection\nand entailment in the termination, soundness and completeness of TCLP systems,\nand present the design and an experimental evaluation of Mod TCLP, a framework\nthat eases the integration of additional constraint solvers. Mod TCLP views\nconstraint solvers as clients of the tabling system, which is generic w.r.t.\nthe solver and only requires a clear interface from the latter. We validate our\ndesign by integrating four constraint solvers: a previously existing constraint\nsolver for difference constraints, written in C; the standard versions of\nHolzbaur's CLP(Q) and CLP(R), written in Prolog; and a new constraint solver\nfor equations over finite lattices. We evaluate the performance of our\nframework in several benchmarks using the aforementioned constraint solvers.\nMod TCLP is developed in Ciao Prolog, a robust, mature, next-generation Prolog\nsystem. Under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 21:18:26 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Arias", "Joaqu\u00edn", ""], ["Carro", "Manuel", ""]]}, {"id": "1809.06233", "submitter": "Sebastiaan Terwijn", "authors": "H. P. Barendregt and S. A. Terwijn", "title": "Fixed point theorems for precomplete numberings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of his theory of numberings, Ershov showed that Kleene's\nrecursion theorem holds for any precomplete numbering. We discuss various\ngeneralizations of this result. Among other things, we show that Arslanov's\ncompleteness criterion also holds for every precomplete numbering, and we\ndiscuss the relation with Visser's ADN theorem, as well as the uniformity or\nnonuniformity of the various fixed point theorems. Finally, we base numberings\non partial combinatory algebras and prove a generalization of Ershov's theorem\nin this context.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 14:24:09 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 11:01:44 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Barendregt", "H. P.", ""], ["Terwijn", "S. A.", ""]]}, {"id": "1809.06638", "submitter": "Zeynep G\\\"ozen Saribatur", "authors": "Zeynep G. Saribatur, Thomas Eiter", "title": "Towards Abstraction in ASP with an Application on Reasoning about Agent\n  Policies", "comments": "Proceedings of the 11th Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ASP programs are a convenient tool for problem solving, whereas with large\nproblem instances the size of the state space can be prohibitive. We consider\nabstraction as a means of over-approximation and introduce a method to\nautomatically abstract (possibly non-ground) ASP programs that preserves their\nstructure, while reducing the size of the problem. One particular application\ncase is the problem of defining declarative policies for reactive agents and\nreasoning about them, which we illustrate on examples.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 10:54:40 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Saribatur", "Zeynep G.", ""], ["Eiter", "Thomas", ""]]}, {"id": "1809.06778", "submitter": "Francesco Giannini", "authors": "Francesco Giannini, Michelangelo Diligenti, Marco Gori and Marco\n  Maggini", "title": "On a Convex Logic Fragment for Learning and Reasoning", "comments": "Accepted in IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2018.2879627", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the convex fragment of {\\L}ukasiewicz Logic and\ndiscuss its possible applications in different learning schemes. Indeed, the\nprovided theoretical results are highly general, because they can be exploited\nin any learning framework involving logical constraints. The method is of\nparticular interest since the fragment guarantees to deal with convex\nconstraints, which are shown to be equivalent to a set of linear constraints.\nWithin this framework, we are able to formulate learning with kernel machines\nas well as collective classification as a quadratic programming problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 14:47:33 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 10:31:11 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Gori", "Marco", ""], ["Maggini", "Marco", ""]]}, {"id": "1809.06954", "submitter": "Jeremy Sproston", "authors": "Jeremy Sproston", "title": "Qualitative Reachability for Open Interval Markov Chains", "comments": "Full version of a paper published at RP 2018", "journal-ref": null, "doi": "10.1007/978-3-030-00250-3_11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interval Markov chains extend classical Markov chains with the possibility to\ndescribe transition probabilities using intervals, rather than exact values.\nWhile the standard formulation of interval Markov chains features closed\nintervals, previous work has considered also open interval Markov chains, in\nwhich the intervals can also be open or half-open. In this paper we focus on\nqualitative reachability problems for open interval Markov chains, which\nconsider whether the optimal (maximum or minimum) probability with which a\ncertain set of states can be reached is equal to 0 or 1. We present\npolynomial-time algorithms for these problems for both of the standard\nsemantics of interval Markov chains. Our methods do not rely on the closure of\nopen intervals, in contrast to previous approaches for open interval Markov\nchains, and can characterise situations in which probability 0 or 1 can be\nattained not exactly but arbitrarily closely.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 22:12:48 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 08:40:56 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Sproston", "Jeremy", ""]]}, {"id": "1809.07115", "submitter": "Jerome Leroux", "authors": "Wojciech Czerwinski, Slawomir Lasota, Ranko Lazic, Jerome Leroux,\n  Filip Mazowiecki", "title": "The Reachability Problem for Petri Nets is Not Elementary", "comments": "Final version of STOC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petri nets, also known as vector addition systems, are a long established\nmodel of concurrency with extensive applications in modelling and analysis of\nhardware, software and database systems, as well as chemical, biological and\nbusiness processes. The central algorithmic problem for Petri nets is\nreachability: whether from the given initial configuration there exists a\nsequence of valid execution steps that reaches the given final configuration.\nThe complexity of the problem has remained unsettled since the 1960s, and it is\none of the most prominent open questions in the theory of verification.\nDecidability was proved by Mayr in his seminal STOC 1981 work, and the\ncurrently best published upper bound is non-primitive recursive Ackermannian of\nLeroux and Schmitz from LICS 2019. We establish a non-elementary lower bound,\ni.e. that the reachability problem needs a tower of exponentials of time and\nspace. Until this work, the best lower bound has been exponential space, due to\nLipton in 1976. The new lower bound is a major breakthrough for several\nreasons. Firstly, it shows that the reachability problem is much harder than\nthe coverability (i.e., state reachability) problem, which is also ubiquitous\nbut has been known to be complete for exponential space since the late 1970s.\nSecondly, it implies that a plethora of problems from formal languages, logic,\nconcurrent systems, process calculi and other areas, that are known to admit\nreductions from the Petri nets reachability problem, are also not elementary.\nThirdly, it makes obsolete the currently best lower bounds for the reachability\nproblems for two key extensions of Petri nets: with branching and with a\npushdown stack.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 10:39:00 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 09:07:29 GMT"}, {"version": "v3", "created": "Fri, 9 Nov 2018 09:07:34 GMT"}, {"version": "v4", "created": "Thu, 11 Apr 2019 10:02:23 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Czerwinski", "Wojciech", ""], ["Lasota", "Slawomir", ""], ["Lazic", "Ranko", ""], ["Leroux", "Jerome", ""], ["Mazowiecki", "Filip", ""]]}, {"id": "1809.07177", "submitter": "Dai Liyun", "authors": "Liyun Dai and Taolue Chen and Zhiming Liu and Bican Xia and Naijun\n  Zhan and Kim G. Larsen", "title": "Parameter Synthesis Problems for one parametric clock Timed Automata", "comments": "20 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:1808.06792", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the parameter synthesis problem for a class of\nparametric timed automata. The problem asks to construct the set of valuations\nof the parameters in the parametric timed automa- ton, referred to as the\nfeasible region, under which the resulting timed automaton satisfies certain\nproperties. We show that the parameter syn- thesis problem of parametric timed\nautomata with only one parametric clock (unlimited concretely constrained\nclock) and arbitrarily many pa- rameters is solvable when all the expressions\nare linear expressions. And it is moreover the synthesis problem is solvable\nwhen the form of con- straints are parameter polynomial inequality not just\nsimple constraint and parameter domain is nonnegative real number.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 07:03:14 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Dai", "Liyun", ""], ["Chen", "Taolue", ""], ["Liu", "Zhiming", ""], ["Xia", "Bican", ""], ["Zhan", "Naijun", ""], ["Larsen", "Kim G.", ""]]}, {"id": "1809.07542", "submitter": "Tadeusz Litak", "authors": "Wesley H. Holliday and Tadeusz Litak", "title": "Complete Additivity and Modal Incompleteness", "comments": null, "journal-ref": "The Review of Symbolic Logic 12 (2019) 487-535", "doi": "10.1017/S1755020317000259", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tell a story about incompleteness in modal logic. The story\nweaves together a paper of van Benthem, `Syntactic aspects of modal\nincompleteness theorems,' and a longstanding open question: whether every\nnormal modal logic can be characterized by a class of completely additive modal\nalgebras, or as we call them, V-BAOs. Using a first-order reformulation of the\nproperty of complete additivity, we prove that the modal logic that starred in\nvan Benthem's paper resolves the open question in the negative. In addition,\nfor the case of bimodal logic, we show that there is a naturally occurring\nlogic that is incomplete with respect to V-BAOs, namely the provability logic\nGLB. We also show that even logics that are unsound with respect to such\nalgebras do not have to be more complex than the classical propositional\ncalculus. On the other hand, we observe that it is undecidable whether a\nsyntactically defined logic is V-complete. After these results, we generalize\nthe Blok Dichotomy to degrees of V-incompleteness. In the end, we return to van\nBenthem's theme of syntactic aspects of modal incompleteness.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 09:19:39 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 21:48:54 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Holliday", "Wesley H.", ""], ["Litak", "Tadeusz", ""]]}, {"id": "1809.07823", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Logically-Constrained Neural Fitted Q-Iteration", "comments": "AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for efficient training of Q-functions for\ncontinuous-state Markov Decision Processes (MDPs) such that the traces of the\nresulting policies satisfy a given Linear Temporal Logic (LTL) property. LTL, a\nmodal logic, can express a wide range of time-dependent logical properties\n(including \"safety\") that are quite similar to patterns in natural language. We\nconvert the LTL property into a limit deterministic Buchi automaton and\nconstruct an on-the-fly synchronised product MDP. The control policy is then\nsynthesised by defining an adaptive reward function and by applying a modified\nneural fitted Q-iteration algorithm to the synchronised structure, assuming\nthat no prior knowledge is available from the original MDP. The proposed method\nis evaluated in a numerical study to test the quality of the generated control\npolicy and is compared with conventional methods for policy synthesis such as\nMDP abstraction (Voronoi quantizer) and approximate dynamic programming (fitted\nvalue iteration).\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:52:06 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 19:39:49 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 12:04:34 GMT"}, {"version": "v4", "created": "Thu, 14 Mar 2019 11:17:57 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1809.07897", "submitter": "G. A. Kavvos", "authors": "G. A. Kavvos", "title": "Modalities, Cohesion, and Information Flow", "comments": null, "journal-ref": "G. A. Kavvos. 2019. Modalities, Cohesion, and Information Flow.\n  Proc. ACM Program. Lang. 3, POPL, Article 20 (January 2019), 29 pages", "doi": "10.1145/3290333", "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is informally understood that the purpose of modal type constructors in\nprogramming calculi is to control the flow of information between types. In\norder to lend rigorous support to this idea, we study the category of\nclassified sets, a variant of a denotational semantics for information flow\nproposed by Abadi et al. We use classified sets to prove multiple\nnoninterference theorems for modalities of a monadic and comonadic flavour. The\ncommon machinery behind our theorems stems from the the fact that classified\nsets are a (weak) model of Lawvere's theory of axiomatic cohesion. In the\nprocess, we show how cohesion can be used for reasoning about multi-modal\nsettings. This leads to the conclusion that cohesion is a particularly useful\nsetting for the study of both information flow, but also modalities in type\ntheory and programming languages at large.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 00:25:28 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 20:32:48 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Kavvos", "G. A.", ""]]}, {"id": "1809.08098", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana", "title": "Efficient Formal Safety Analysis of Neural Networks", "comments": "Accepted to NIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly deployed in real-world safety-critical\ndomains such as autonomous driving, aircraft collision avoidance, and malware\ndetection. However, these networks have been shown to often mispredict on\ninputs with minor adversarial or even accidental perturbations. Consequences of\nsuch errors can be disastrous and even potentially fatal as shown by the recent\nTesla autopilot crash. Thus, there is an urgent need for formal analysis\nsystems that can rigorously check neural networks for violations of different\nsafety properties such as robustness against adversarial perturbations within a\ncertain $L$-norm of a given image. An effective safety analysis system for a\nneural network must be able to either ensure that a safety property is\nsatisfied by the network or find a counterexample, i.e., an input for which the\nnetwork will violate the property. Unfortunately, most existing techniques for\nperforming such analysis struggle to scale beyond very small networks and the\nones that can scale to larger networks suffer from high false positives and\ncannot produce concrete counterexamples in case of a property violation. In\nthis paper, we present a new efficient approach for rigorously checking\ndifferent safety properties of neural networks that significantly outperforms\nexisting approaches by multiple orders of magnitude. Our approach can check\ndifferent safety properties and find concrete counterexamples for networks that\nare 10$\\times$ larger than the ones supported by existing analysis techniques.\nWe believe that our approach to estimating tight output bounds of a network for\na given input range can also help improve the explainability of neural networks\nand guide the training process of more robust neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:21:28 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:29:30 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 22:30:38 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Wang", "Shiqi", ""], ["Pei", "Kexin", ""], ["Whitehouse", "Justin", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""]]}, {"id": "1809.08101", "submitter": "Adeyinka K. Akanbi MR", "authors": "A. K. Akanbi, M. Masinde", "title": "Towards the Development of a Rule-based Drought Early Warning Expert\n  Systems using Indigenous Knowledge", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drought forecasting and prediction is a complicated process due to the\ncomplexity and scalability of the environmental parameters involved. Hence, it\nrequired a high level of expertise to predict. In this paper, we describe the\nresearch and development of a rule-based drought early warning expert systems\n(RB-DEWES) for forecasting drought using local indigenous knowledge obtained\nfrom domain experts. The system generates inference by using rule set and\nprovides drought advisory information with attributed certainty factor (CF)\nbased on the user's input. The system is believed to be the first expert system\nfor drought forecasting to use local indigenous knowledge on drought. The\narchitecture and components such as knowledge base, JESS inference engine and\nmodel base of the system and their functions are presented.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:22:28 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Akanbi", "A. K.", ""], ["Masinde", "M.", ""]]}, {"id": "1809.08169", "submitter": "Richard Statman", "authors": "Richard Statman, Andrew Polonsky", "title": "On sets of terms with a given intersection type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working in a variant of the intersection type assignment system of Coppo,\nDezani-Ciancaglini and Veneri [1981], we prove several facts about sets of\nterms having a given intersection type. Our main result is that every strongly\nnormalizing term M admits a *uniqueness typing*, which is a pair $(\\Gamma,A)$\nsuch that\n  1) $\\Gamma \\vdash M : A$\n  2) $\\Gamma \\vdash N : A \\Longrightarrow M =_{\\beta\\eta} N$\n  We also discuss several presentations of intersection type algebras, and the\ncorresponding choices of type assignment rules.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 13:44:13 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 00:01:41 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Statman", "Richard", ""], ["Polonsky", "Andrew", ""]]}, {"id": "1809.08576", "submitter": "Uri Abraham", "authors": "Uri Abraham", "title": "Kishon's Poker Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for proving the correctness of distributed algorithms\nthat obviate interleaving of processes' actions. The main part of the\ncorrectness proof is conducted at a higher abstract level and uses Tarskian\nsystem executions that combine two separate issues: the specification of the\nserial process that executes its protocol alone (no concurrency here), and the\nspecification of the communication objects (no code here). In order to explain\nthis approach a short algorithm for two concurrent processes that we call\n\"Kishon's Poker\" is introduced and is used as a platform where this approach is\ncompared to the standard one which is based on the notions of global state,\nstep, and history.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 10:56:55 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Abraham", "Uri", ""]]}, {"id": "1809.08646", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling and Bas Spitters", "title": "Normalization by gluing for free {\\lambda}-theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connection between normalization by evaluation, logical predicates and\nsemantic gluing constructions is a matter of folklore, worked out in varying\ndegrees within the literature. In this note, we present an elementary version\nof the gluing technique which corresponds closely with both semantic\nnormalization proofs and the syntactic normalization by evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 17:54:12 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Sterling", "Jonathan", ""], ["Spitters", "Bas", ""]]}, {"id": "1809.08695", "submitter": "Martin Ziegler", "authors": "Akitoshi Kawamura and Donghyun Lim and Svetlana Selivanova and Martin\n  Ziegler", "title": "Representation Theory of Compact Metric Spaces and Computational\n  Complexity of Continuous Data", "comments": "39 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing an encoding over binary strings for input/output to/by a Turing\nMachine is usually straightforward and/or inessential for discrete data (like\ngraphs), but delicate -- heavily affecting computability and even more\ncomputational complexity -- already regarding real numbers, not to mention more\nadvanced (e.g. Sobolev) spaces. For a general theory of computational\ncomplexity over continuous data we introduce and justify QUANTITATIVE\nadmissibility as requirement for sensible encodings of arbitrary compact metric\nspaces, a refinement of qualitative 'admissibility' due to\n[Kreitz&Weihrauch'85]:\n  An admissible representation of a T0 space $X$ is a (i) continuous partial\nsurjective mapping from the Cantor space of infinite binary sequences which is\n(ii) maximal w.r.t. continuous reduction. By the Kreitz-Weihrauch (aka \"Main\")\nTheorem of computability over continuous data, for fixed spaces $X,Y$ equipped\nwith admissible representations, a function $f:X\\to Y$ is continuous iff it\nadmits continuous a code-translating mapping on Cantor space, a so-called\nREALIZER. We define a QUANTITATIVELY admissible representation of a compact\nmetric space $X$ to have (i) asymptotically optimal modulus of continuity,\nnamely close to the entropy of $X$, and (ii) be maximal w.r.t. reduction having\noptimal modulus of continuity in a similar sense.\n  Careful constructions show the category of such representations to be\nCartesian closed, and non-empty: every compact $X$ admits a linearly-admissible\nrepresentation. Moreover such representations give rise to a tight quantitative\ncorrespondence between the modulus of continuity of a function $f:X\\to Y$ on\nthe one hand and on the other hand that of its realizer: the MAIN THEOREM of\ncomputational complexity. This suggests (how) to take into account the\nentropies of the spaces under consideration when measuring algorithmic cost\nover continuous data.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 23:09:49 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 01:08:08 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 01:06:50 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Kawamura", "Akitoshi", ""], ["Lim", "Donghyun", ""], ["Selivanova", "Svetlana", ""], ["Ziegler", "Martin", ""]]}, {"id": "1809.09278", "submitter": "J\\'er\\'emy Dubut", "authors": "J\\'er\\'emy Dubut, Ichiro Hasuo, Shin-ya Katsumata, David Sprunger", "title": "Quantitative bisimulations using coreflections and open morphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a canonical way of defining bisimilarity of systems when their\nsemantics is given by a coreflection, typically in a category of transition\nsystems. We use the fact, from Joyal et al., that coreflections preserve open\nmorphisms situations in the sense that a coreflection induces a path\nsubcategory in the category of systems in such a way that open bisimilarity\nwith respect to the induced path category coincides with usual bisimilarity of\ntheir semantics. We prove that this method is particularly well-suited for\nsystems with quantitative information: we canonically recover the path category\nof probabilistic systems from Cheng et al., and of timed systems from Nielsen\net al., and, finally, we propose a new canonical path category for hybrid\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 01:41:22 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Dubut", "J\u00e9r\u00e9my", ""], ["Hasuo", "Ichiro", ""], ["Katsumata", "Shin-ya", ""], ["Sprunger", "David", ""]]}, {"id": "1809.09319", "submitter": "Vu Phan", "authors": "Vu Phan", "title": "Syntactic Conditions for Antichain Property in Consistency Restoring\n  Prolog", "comments": "Proceedings of the 11th Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study syntactic conditions which guarantee when a CR-Prolog (Consistency\nRestoring Prolog) program has antichain property: no answer set is a proper\nsubset of another. A notable such condition is that the program's dependency\ngraph being acyclic and having no directed path from one cr-rule head literal\nto another.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 05:12:18 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Phan", "Vu", ""]]}, {"id": "1809.09550", "submitter": "Lillian Tsai", "authors": "Lillian Tsai, Eddie Kohler, M. Frans Kaashoek, and Nickolai Zeldovich", "title": "A Revised and Verified Proof of the Scalable Commutativity Rule", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explains a flaw in the published proof of the Scalable\nCommutativity Rule (SCR), presents a revised and formally verified proof of the\nSCR in the Coq proof assistant, and discusses the insights and open questions\nraised from our experience proving the SCR.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 11:52:39 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Tsai", "Lillian", ""], ["Kohler", "Eddie", ""], ["Kaashoek", "M. Frans", ""], ["Zeldovich", "Nickolai", ""]]}, {"id": "1809.09938", "submitter": "Christian Anti\\'c", "authors": "Christian Anti\\'c", "title": "Logic-Based Analogical Reasoning and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogy-making is at the core of human intelligence and creativity with\napplications to such diverse tasks as commonsense reasoning, learning, language\nacquisition, and story telling. This paper contributes to the foundations of\nartificial general intelligence by developing an abstract algebraic framework\nfor logic-based analogical reasoning and learning in the setting of logic\nprogramming. The main idea is to define analogy in terms of modularity and to\nderive abstract forms of concrete programs from a `known' source domain which\ncan then be instantiated in an `unknown' target domain to obtain analogous\nprograms. To this end, we introduce algebraic operations for syntactic program\ncomposition and concatenation and illustrate, by giving numerous examples, that\nprograms have nice decompositions. Moreover, we show how composition gives rise\nto a qualitative notion of syntactic program similarity. We then argue that\nreasoning and learning by analogy is the task of solving analogical proportions\nbetween logic programs. Interestingly, our work suggests a close relationship\nbetween modularity, generalization, and analogy which we believe should be\nexplored further in the future. In a broader sense, this paper is a first step\ntowards an algebraic and mainly syntactic theory of logic-based analogical\nreasoning and learning in knowledge representation and reasoning systems, with\npotential applications to fundamental AI-problems like commonsense reasoning\nand computational learning and creativity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 12:33:51 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 11:35:51 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Anti\u0107", "Christian", ""]]}, {"id": "1809.10620", "submitter": "Karl Schlechta", "authors": "Karl Schlechta", "title": "Operations on Partial Orders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define analogues of Boolean operations on not necessarily complete partial\norders, they often have as results sets of elements rather than single\nelements. It proves useful to add to such sets X if they are intended to be\nsup(X) or inf(X), even if sup and inf do not always exist.\n  We then define the height of an element as the maximal length of chains going\nfrom BOTTOM to that element, and use height to define probability measures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:34:32 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 09:19:19 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Schlechta", "Karl", ""]]}, {"id": "1809.10655", "submitter": "Paul Gainer", "authors": "Paul Gainer, Sven Linker, Clare Dixon, Ullrich Hustadt, Michael Fisher", "title": "Multi-Scale Verification of Distributed Synchronisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for the synchronisation of clocks across networks are both common\nand important within distributed systems. We here address not only the formal\nmodelling of these algorithms, but also the formal verification of their\nbehaviour. Of particular importance is the strong link between the very\ndifferent levels of abstraction at which the algorithms may be verified. Our\ncontribution is primarily the formalisation of this connection between\nindividual models and population-based models, and the subsequent verification\nthat is then possible. While the technique is applicable across a range of\nsynchronisation algorithms, we particularly focus on the synchronisation of\n(biologically-inspired) pulse-coupled oscillators, a widely used approach in\npractical distributed systems. For this application domain, different levels of\nabstraction are crucial: models based on the behaviour of an individual process\nare able to capture the details of distinguished nodes in possibly heterogenous\nnetworks, where each node may exhibit different behaviour. On the other hand,\ncollective models assume homogeneous sets of processes, and allow the behaviour\nof the network to be analysed at the global level. System-wide parameters may\nbe easily adjusted, for example environmental factors inhibiting the\nreliability of the shared communication medium. This work provides a formal\nbridge across the abstraction gap separating the individual models and the\npopulation-based models for this important class of synchronisation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 17:31:16 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Gainer", "Paul", ""], ["Linker", "Sven", ""], ["Dixon", "Clare", ""], ["Hustadt", "Ullrich", ""], ["Fisher", "Michael", ""]]}, {"id": "1809.10718", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Induction rules in bounded arithmetic", "comments": "40 pages", "journal-ref": "Archive for Mathematical Logic 59 (2020), no. 3, pp. 461--501", "doi": "10.1007/s00153-019-00702-w", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study variants of Buss's theories of bounded arithmetic axiomatized by\ninduction schemes disallowing the use of parameters, and closely related\ninduction inference rules. We put particular emphasis on $\\hat\\Pi^b_i$\ninduction schemes, which were so far neglected in the literature. We present\ninclusions and conservation results between the systems (including a witnessing\ntheorem for $T^i_2$ and $S^i_2$ of a new form), results on numbers of instances\nof the axioms or rules, connections to reflection principles for quantified\npropositional calculi, and separations between the systems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 18:48:32 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 15:54:31 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1809.10946", "submitter": "Giovanni Casini", "authors": "Richard Booth, Giovanni Casini, Thomas Meyer, Ivan Varzinczak", "title": "On Rational Entailment for Propositional Typicality Logic", "comments": "27 pages; extended and elaborated version of a paper presented at the\n  24th International Joint Conference on Artificial Intelligence (IJCAI 2015)", "journal-ref": null, "doi": "10.1016/j.artint.2019.103178", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional Typicality Logic (PTL) is a recently proposed logic, obtained\nby enriching classical propositional logic with a typicality operator capturing\nthe most typical (alias normal or conventional) situations in which a given\nsentence holds. The semantics of PTL is in terms of ranked models as studied in\nthe well-known KLM approach to preferential reasoning and therefore KLM-style\nrational consequence relations can be embedded in PTL. In spite of the\nnon-monotonic features introduced by the semantics adopted for the typicality\noperator, the obvious Tarskian definition of entailment for PTL remains\nmonotonic and is therefore not appropriate in many contexts. Our first\nimportant result is an impossibility theorem showing that a set of proposed\npostulates that at first all seem appropriate for a notion of entailment with\nregard to typicality cannot be satisfied simultaneously. Closer inspection\nreveals that this result is best interpreted as an argument for advocating the\ndevelopment of more than one type of PTL entailment. In the spirit of this\ninterpretation, we investigate three different (semantic) versions of\nentailment for PTL, each one based on the definition of rational closure as\nintroduced by Lehmann and Magidor for KLM-style conditionals, and constructed\nusing different notions of minimality.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 10:19:16 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 22:08:57 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Booth", "Richard", ""], ["Casini", "Giovanni", ""], ["Meyer", "Thomas", ""], ["Varzinczak", "Ivan", ""]]}]