[{"id": "1601.00239", "submitter": "Lili Shen", "authors": "Hongliang Lai, Lili Shen", "title": "Fixed points of adjoint functors enriched in a quantaloid", "comments": "27 pages, final version", "journal-ref": "Fuzzy Sets and Systems, 321:1-28, 2017", "doi": "10.1016/j.fss.2016.12.001", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation theorems are established for fixed points of adjoint functors\nbetween categories enriched in a small quantaloid. In a very general setting\nthese results set up a common framework for representation theorems of concept\nlattices in formal concept analysis (FCA) and rough set theory (RST), which not\nonly extend the realm of formal contexts to multi-typed and multi-valued ones,\nbut also provide a general approach to construct various kinds of\nrepresentation theorems. Besides incorporating several well-known\nrepresentation theorems in FCA and RST as well as formulating new ones, it is\nshown that concept lattices in RST can always be represented as those in FCA\nthrough relative pseudo-complements of the given contexts, especially if the\ncontexts are valued in a non-Girard quantaloid.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2016 01:39:30 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 06:35:04 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Lai", "Hongliang", ""], ["Shen", "Lili", ""]]}, {"id": "1601.00363", "submitter": "Jianxiong Shao", "authors": "Jianxiong Shao, Yu Qin, Dengguo Feng", "title": "Computational Soundness Results for Stateful Applied pi Calculus", "comments": "to appear in POST 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many researches have been done to establish symbolic models\nof stateful protocols. Two works among them, the SAPIC tool and StatVerif tool,\nprovide a high-level specification language and an automated analysis. Their\nlanguage, the stateful applied \\pi-calculus, is extended from the applied\n\\pi-calculus by defining explicit state constructs. Symbolic abstractions of\ncryptography used in it make the analysis amenable to automation. However, this\nmight overlook the attacks based on the algebraic properties of the\ncryptographic algorithms. In our paper, we establish the computational\nsoundness results for stateful applied \\pi-calculus used in SAPIC tool and\nStatVerif tool.\n  In our approach, we build our results on the CoSP framework. For SAPIC, we\nembed the non-monotonic protocol states into the CoSP protocols, and prove that\nthe resulting CoSP protocols are efficient. Through the embedding, we provide\nthe computational soundness result for SAPIC (by Theorem 1). For StatVerif, we\nencode the StatVerif process into a subset of SAPIC process, and obtain the\ncomputational soundness result for StatVerif (by Theorem 2). Our encoding shows\nthe differences between the semantics of the two languages. Our work inherits\nthe modularity of CoSP, which allows for easily extending the proofs to\nspecific cryptographic primitives. Thus we establish a computationally sound\nautomated verification result for the input languages of SAPIC and StatVerif\nthat use public-key encryption and signatures (by Theorem 3).\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 01:49:00 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Shao", "Jianxiong", ""], ["Qin", "Yu", ""], ["Feng", "Dengguo", ""]]}, {"id": "1601.00402", "submitter": "Luigi Santocanale", "authors": "Silvio Ghilardi, Maria Joao Gouveia (ULISBOA), Luigi Santocanale (LIF,\n  AMU)", "title": "Fixed-point elimination in the intuitionistic propositional calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a consequence of existing literature that least and greatest\nfixed-points of monotone polynomials on Heyting algebras-that is, the algebraic\nmodels of the Intuitionistic Propositional Calculus-always exist, even when\nthese algebras are not complete as lattices. The reason is that these extremal\nfixed-points are definable by formulas of the IPC. Consequently, the\n$\\mu$-calculus based on intuitionistic logic is trivial, every $\\mu$-formula\nbeing equivalent to a fixed-point free formula. We give in this paper an\naxiomatization of least and greatest fixed-points of formulas, and an algorithm\nto compute a fixed-point free formula equivalent to a given $\\mu$-formula. The\naxiomatization of the greatest fixed-point is simple. The axiomatization of the\nleast fixed-point is more complex, in particular every monotone formula\nconverges to its least fixed-point by Kleene's iteration in a finite number of\nsteps, but there is no uniform upper bound on the number of iterations. We\nextract, out of the algorithm, upper bounds for such n, depending on the size\nof the formula. For some formulas, we show that these upper bounds are\npolynomial and optimal.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 07:45:25 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Ghilardi", "Silvio", "", "ULISBOA"], ["Gouveia", "Maria Joao", "", "ULISBOA"], ["Santocanale", "Luigi", "", "LIF,\n  AMU"]]}, {"id": "1601.00501", "submitter": "Simone Bova", "authors": "Simone Bova", "title": "SDDs are Exponentially More Succinct than OBDDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduced by Darwiche (2011), sentential decision diagrams (SDDs) are\nessentially as tractable as ordered binary decision diagrams (OBDDs), but tend\nto be more succinct in practice. This makes SDDs a prominent representation\nlanguage, with many applications in artificial intelligence and knowledge\ncompilation. We prove that SDDs are more succinct than OBDDs also in theory, by\nconstructing a family of boolean functions where each member has polynomial SDD\nsize but exponential OBDD size. This exponential separation improves a\nquasipolynomial separation recently established by Razgon (2013), and settles\nan open problem in knowledge compilation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 13:38:35 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Bova", "Simone", ""]]}, {"id": "1601.00516", "submitter": "Carlo A. Furia", "authors": "Michael Ameri and Carlo A. Furia", "title": "Why Just Boogie? Translating Between Intermediate Verification Languages", "comments": null, "journal-ref": "Proceedings of the 12th International Conference on integrated\n  Formal Methods (iFM). Lecture Notes in Computer Science, 9681:1--17,\n  Springer, 2016", "doi": "10.1007/978-3-319-33693-0%206", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification systems Boogie and Why3 use their respective intermediate\nlanguages to generate verification conditions from high-level programs. Since\nthe two systems support different back-end provers (such as Z3 and Alt-Ergo)\nand are used to encode different high-level languages (such as C# and Java),\nbeing able to translate between their intermediate languages would provide a\nway to reuse one system's features to verify programs meant for the other. This\npaper describes a translation of Boogie into WhyML (Why3's intermediate\nlanguage) that preserves semantics, verifiability, and program structure to a\nlarge degree. We implemented the translation as a tool and applied it to 194\nBoogie-verified programs of various sources and sizes; Why3 verified 83% of the\ntranslated programs with the same outcome as Boogie. These results indicate\nthat the translation is often effective and practically applicable.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 14:30:48 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 12:38:43 GMT"}, {"version": "v3", "created": "Sat, 12 Mar 2016 15:19:17 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Ameri", "Michael", ""], ["Furia", "Carlo A.", ""]]}, {"id": "1601.00584", "submitter": "Cl\\'audio Belo Louren\\c{c}o", "authors": "Cl\\'audio Belo Louren\\c{c}o, Maria Jo\\~ao Frade, Jorge Sousa Pinto", "title": "A Single-Assignment Translation for Annotated Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a translation of While programs annotated with loop invariants\ninto a dynamic single-assignment language with a dedicated iterating construct.\nWe prove that the translation is sound and complete. This is a companion report\nto our paper Formalizing Single-assignment Program Verification: an\nAdaptation-complete Approach [6].\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 17:45:43 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 18:33:52 GMT"}, {"version": "v3", "created": "Thu, 5 May 2016 09:47:02 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Louren\u00e7o", "Cl\u00e1udio Belo", ""], ["Frade", "Maria Jo\u00e3o", ""], ["Pinto", "Jorge Sousa", ""]]}, {"id": "1601.01001", "submitter": "Christoph Matheja", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja,\n  Federico Olmedo", "title": "Weakest Precondition Reasoning for Expected Run-Times of Probabilistic\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a wp-style calculus for obtaining bounds on the expected\nrun-time of probabilistic programs. Its application includes determining the\n(possibly infinite) expected termination time of a probabilistic program and\nproving positive almost-sure termination - does a program terminate with\nprobability one in finite expected time? We provide several proof rules for\nbounding the run-time of loops, and prove the soundness of the approach with\nrespect to a simple operational model. We show that our approach is a\nconservative extension of Nielson's approach for reasoning about the run-time\nof deterministic programs. We analyze the expected run-time of some example\nprograms including a one-dimensional random walk and the coupon collector\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 22:31:57 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 16:22:15 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Matheja", "Christoph", ""], ["Olmedo", "Federico", ""]]}, {"id": "1601.01113", "submitter": "Sabine Frittella", "authors": "Samuel Balco and Sabine Frittella and Giuseppe Greco and Alexander\n  Kurz and Alessandra Palmigiano", "title": "Tool support for reasoning in display calculi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a tool for reasoning in and about propositional sequent calculi.\nOne aim is to support reasoning in calculi that contain a hundred rules or\nmore, so that even relatively small pen and paper derivations become tedious\nand error prone. As an example, we implement the display calculus D.EAK of\ndynamic epistemic logic. Second, we provide embeddings of the calculus in the\ntheorem prover Isabelle for formalising proofs about D.EAK. As a case study we\nshow that the solution of the muddy children puzzle is derivable for any number\nof muddy children. Third, there is a set of meta-tools, that allows us to adapt\nthe tool for a wide variety of user defined calculi.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 09:22:02 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Balco", "Samuel", ""], ["Frittella", "Sabine", ""], ["Greco", "Giuseppe", ""], ["Kurz", "Alexander", ""], ["Palmigiano", "Alessandra", ""]]}, {"id": "1601.01233", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli (INRIA), Ugo Dal Lago (University of Bologna &\n  INRIA)", "title": "(Leftmost-Outermost) Beta Reduction is Invariant, Indeed", "comments": "arXiv admin note: substantial text overlap with arXiv:1405.3311", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 1 (March 9,\n  2016) lmcs:1627", "doi": "10.2168/LMCS-12(1:4)2016", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot and van Emde Boas' weak invariance thesis states that reasonable\nmachines can simulate each other within a polynomially overhead in time. Is\nlambda-calculus a reasonable machine? Is there a way to measure the\ncomputational complexity of a lambda-term? This paper presents the first\ncomplete positive answer to this long-standing problem. Moreover, our answer is\ncompletely machine-independent and based over a standard notion in the theory\nof lambda-calculus: the length of a leftmost-outermost derivation to normal\nform is an invariant cost model. Such a theorem cannot be proved by directly\nrelating lambda-calculus with Turing machines or random access machines,\nbecause of the size explosion problem: there are terms that in a linear number\nof steps produce an exponentially long output. The first step towards the\nsolution is to shift to a notion of evaluation for which the length and the\nsize of the output are linearly related. This is done by adopting the linear\nsubstitution calculus (LSC), a calculus of explicit substitutions modeled after\nlinear logic proof nets and admitting a decomposition of leftmost-outermost\nderivations with the desired property. Thus, the LSC is invariant with respect\nto, say, random access machines. The second step is to show that LSC is\ninvariant with respect to the lambda-calculus. The size explosion problem seems\nto imply that this is not possible: having the same notions of normal form,\nevaluation in the LSC is exponentially longer than in the lambda-calculus. We\nsolve such an impasse by introducing a new form of shared normal form and\nshared reduction, deemed useful. Useful evaluation avoids those steps that only\nunshare the output without contributing to beta-redexes, i.e. the steps that\ncause the blow-up in size. The main technical contribution of the paper is\nindeed the definition of useful reductions and the thorough analysis of their\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 16:31:48 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 13:45:53 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Accattoli", "Beniamino", "", "INRIA"], ["Lago", "Ugo Dal", "", "University of Bologna &\n  INRIA"]]}, {"id": "1601.01478", "submitter": "Anton Wijs", "authors": "Jan Friso Groote and Anton Wijs", "title": "An O(m log n) Algorithm for Stuttering Equivalence and Branching\n  Bisimulation", "comments": "A shortened version of this technical report has been published in\n  the proceedings of TACAS 2016", "journal-ref": null, "doi": null, "report-no": "CSR-15-06", "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new algorithm to determine stuttering equivalence with time\ncomplexity $O(m \\log n)$, where $n$ is the number of states and $m$ is the\nnumber of transitions of a Kripke structure. This algorithm can also be used to\ndetermine branching bisimulation in $O(m(\\log |\\mathit{Act}|+ \\log n))$ time\nwhere $\\mathit{Act}$ is the set of actions in a labelled transition system.\nTheoretically, our algorithm substantially improves upon existing algorithms\nwhich all have time complexity $O(m n)$ at best. Moreover, it has better or\nequal space complexity. Practical results confirm these findings showing that\nour algorithm can outperform existing algorithms with orders of magnitude,\nespecially when the sizes of the Kripke structures are large. The importance of\nour algorithm stretches far beyond stuttering equivalence and branching\nbisimulation. The known $O(m n)$ algorithms were already far more efficient\n(both in space and time) than most other algorithms to determine behavioural\nequivalences (including weak bisimulation) and therefore it was often used as\nan essential preprocessing step. This new algorithm makes this use of\nstuttering equivalence and branching bisimulation even more attractive.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 10:58:36 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Groote", "Jan Friso", ""], ["Wijs", "Anton", ""]]}, {"id": "1601.01483", "submitter": "Gilles Dowek", "authors": "Gilles Dowek (DEDUCTEAM)", "title": "Rules and derivations in an elementary logic course", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When teaching an elementary logic course to students who have a general\nscientific background but have never been exposed to logic, we have to face the\nproblem that the notions of deduction rule and of derivation are completely new\nto them, and are related to nothing they already know, unlike, for instance,\nthe notion of model, that can be seen as a generalization of the notion of\nalgebraic structure. In this note, we defend the idea that one strategy to\nintroduce these notions is to start with the notion of inductive definition\n[1]. Then, the notion of derivation comes naturally. We also defend the idea\nthat derivations are pervasive in logic and that defining precisely this notion\nat an early stage is a good investment to later define other notions in proof\ntheory, computability theory, automata theory, ... Finally, we defend the idea\nthat to define the notion of derivation precisely, we need to distinguish two\nnotions of derivation: labeled with elements and labeled with rule names. This\napproach has been taken in [2].\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 11:03:46 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Dowek", "Gilles", "", "DEDUCTEAM"]]}, {"id": "1601.01484", "submitter": "Gilles Dowek", "authors": "Gilles Dowek (DEDUCTEAM), Ying Jiang (LCS)", "title": "Decidability, Introduction Rules and Automata", "comments": "International Conferences on Logic for Programming, Artificial\n  Intelligence and Reasoning, Nov 2015, Bula, Fiji. 2015, International\n  Conferences on Logic for Programming, Artificial Intelligence and Reasoning", "journal-ref": null, "doi": "10.1007/978-3-662-48899-7_8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to prove the decidability of provability in several\nwell-known inference systems. This method generalizes both cut-elimination and\nthe construction of an automaton recognizing the provable propositions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 11:05:14 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Dowek", "Gilles", "", "DEDUCTEAM"], ["Jiang", "Ying", "", "LCS"]]}, {"id": "1601.01532", "submitter": "Thorsten Wi{\\ss}mann", "authors": "Stefan Milius, Dirk Pattinson, Thorsten Wi{\\ss}mann", "title": "A New Foundation for Finitary Corecursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to a theory of the behaviour of \"finite-state\" systems\nthat is generic in the system type. We propose that such systems are modeled as\ncoalgebras with a finitely generated carrier for an endofunctor on a locally\nfinitely presentable category. Their behaviour gives rise to a new fixpoint of\nthe coalgebraic type functor called locally finite fixpoint (LFF). We prove\nthat if the given endofunctor preserves monomorphisms then the LFF always\nexists and is a subcoalgebra of the final coalgebra (unlike the rational\nfixpoint previously studied by Ad\\'amek, Milius and Velebil). Moreover, we show\nthat the LFF is characterized by two universal properties: 1. as the final\nlocally finitely generated coalgebra, and 2. as the initial fg-iterative\nalgebra. As instances of the LFF we first obtain the known instances of the\nrational fixpoint, e.g. regular languages, rational streams and formal\npower-series, regular trees etc. And we obtain a number of new examples, e.g.\n(realtime deterministic resp. non-deterministic) context-free languages,\nconstructively S-algebraic formal power-series (and any other instance of the\ngeneralized powerset construction by Silva, Bonchi, Bonsangue, and Rutten) and\nthe monad of Courcelle's algebraic trees.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 13:36:58 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 16:35:20 GMT"}, {"version": "v3", "created": "Fri, 20 Oct 2017 16:22:30 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Milius", "Stefan", ""], ["Pattinson", "Dirk", ""], ["Wi\u00dfmann", "Thorsten", ""]]}, {"id": "1601.01546", "submitter": "Fei  Yang", "authors": "Bas Luttik, Fei Yang", "title": "On the Executability of Interactive Computation", "comments": "15 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model of interactive Turing machines (ITMs) has been proposed to\ncharacterise which stream translations are interactively computable; the model\nof reactive Turing machines (RTMs) has been proposed to characterise which\nbehaviours are reactively executable. In this article we provide a comparison\nof the two models. We show, on the one hand, that the behaviour exhibited by\nITMs is reactively executable, and, on the other hand, that the stream\ntranslations naturally associated with RTMs are interactively computable. We\nconclude from these results that the theory of reactive executability subsumes\nthe theory of interactive computability. Inspired by the existing model of ITMs\nwith advice, which provides a model of evolving computation, we also consider\nRTMs with advice and we establish that a facility of advice considerably\nupgrades the behavioural expressiveness of RTMs: every countable transition\nsystem can be simulated by some RTM with advice up to a fine notion of\nbehavioural equivalence.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 14:38:51 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 10:33:57 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Luttik", "Bas", ""], ["Yang", "Fei", ""]]}, {"id": "1601.01586", "submitter": "Ranald Clouston", "authors": "Ale\\v{s} Bizjak, Hans Bugge Grathwohl, Ranald Clouston, Rasmus E.\n  M{\\o}gelberg, Lars Birkedal", "title": "Guarded Dependent Type Theory with Coinductive Types", "comments": "This is the technical report version of a paper to appear in the\n  proceedings of FoSSaCS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present guarded dependent type theory, gDTT, an extensional dependent type\ntheory with a `later' modality and clock quantifiers for programming and\nproving with guarded recursive and coinductive types. The later modality is\nused to ensure the productivity of recursive definitions in a modular, type\nbased, way. Clock quantifiers are used for controlled elimination of the later\nmodality and for encoding coinductive types using guarded recursive types. Key\nto the development of gDTT are novel type and term formers involving what we\ncall `delayed substitutions'. These generalise the applicative functor rules\nfor the later modality considered in earlier work, and are crucial for\nprogramming and proving with dependent types. We show soundness of the type\ntheory with respect to a denotational model.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 16:26:14 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Bizjak", "Ale\u0161", ""], ["Grathwohl", "Hans Bugge", ""], ["Clouston", "Ranald", ""], ["M\u00f8gelberg", "Rasmus E.", ""], ["Birkedal", "Lars", ""]]}, {"id": "1601.01587", "submitter": "Jan Kr\\v{c}\\'al", "authors": "Holger Hermanns, Jan Kr\\v{c}\\'al, Steen Vester", "title": "Distributed Synthesis in Continuous Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formalism modelling communication of distributed agents\nstrictly in continuous-time. Within this framework, we study the problem of\nsynthesising local strategies for individual agents such that a specified set\nof goal states is reached, or reached with at least a given probability. The\nflow of time is modelled explicitly based on continuous-time randomness, with\ntwo natural implications: First, the non-determinism stemming from interleaving\ndisappears. Second, when we restrict to a subclass of non-urgent models, the\nquantitative value problem for two players can be solved in EXPTIME. Indeed,\nthe explicit continuous time enables players to communicate their states by\ndelaying synchronisation (which is unrestricted for non-urgent models). In\ngeneral, the problems are undecidable already for two players in the\nquantitative case and three players in the qualitative case. The qualitative\nundecidability is shown by a reduction to decentralized POMDPs for which we\nprovide the strongest (and rather surprising) undecidability result so far.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 16:30:11 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Hermanns", "Holger", ""], ["Kr\u010d\u00e1l", "Jan", ""], ["Vester", "Steen", ""]]}, {"id": "1601.01648", "submitter": "Viorica  Sofronie-Stokkermans", "authors": "Werner Damm and Matthias Horbach and Viorica Sofronie-Stokkermans", "title": "Decidability of Verification of Safety Properties of Spatial Families of\n  Linear Hybrid Automata", "comments": "50 pages, AVACS Technical Report No. 111 (SFB/TR 14 AVACS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider systems composed of an unbounded number of uniformly designed\nlinear hybrid automata, whose dynamic behavior is determined by their relation\nto neighboring systems. We present a class of such systems and a class of\nsafety properties whose verification can be reduced to the verification of\n(small) families of neighbouring systems of bounded size, and identify\nsituations in which such verification problems are decidable, resp. fixed\nparameter tractable. We illustrate the approach with an example from\ncoordinated vehicle guidance, and describe an implementation which allows us to\nperform such verification tasks automatically.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 19:48:39 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Damm", "Werner", ""], ["Horbach", "Matthias", ""], ["Sofronie-Stokkermans", "Viorica", ""]]}, {"id": "1601.01660", "submitter": "Daniel Neider", "authors": "Daniel Neider, Ufuk Topcu", "title": "An Automaton Learning Approach to Solving Safety Games over Infinite\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to construct finite-state reactive controllers for\nsystems whose interactions with their adversarial environment are modeled by\ninfinite-duration two-player games over (possibly) infinite graphs. The\nproposed method targets safety games with infinitely many states or with such a\nlarge number of states that it would be impractical---if not impossible---for\nconventional synthesis techniques that work on the entire state space. We\nresort to constructing finite-state controllers for such systems through an\nautomata learning approach, utilizing a symbolic representation of the\nunderlying game that is based on finite automata. Throughout the learning\nprocess, the learner maintains an approximation of the winning region\n(represented as a finite automaton) and refines it using different types of\ncounterexamples provided by the teacher until a satisfactory controller can be\nderived (if one exists). We present a symbolic representation of safety games\n(inspired by regular model checking), propose implementations of the learner\nand teacher, and evaluate their performance on examples motivated by robotic\nmotion planning in dynamic environments.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 20:42:19 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Neider", "Daniel", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1601.01725", "submitter": "Emanuele D'Osualdo", "authors": "Emanuele D'Osualdo, C.-H. Luke Ong", "title": "On Hierarchical Communication Topologies in the pi-calculus", "comments": "42 pages, ESOP16. arXiv admin note: text overlap with\n  arXiv:1502.00944", "journal-ref": null, "doi": "10.1007/978-3-662-49498-1_7", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the shape invariants satisfied by the\ncommunication topology of {\\pi}-terms, and the automatic inference of these\ninvariants. A {\\pi}-term P is hierarchical if there is a finite forest T such\nthat the communication topology of every term reachable from P satisfies a\nT-shaped invariant. We design a static analysis to prove a term hierarchical by\nmeans of a novel type system that enjoys decidable inference. The soundness\nproof of the type system employs a non-standard view of {\\pi}-calculus\nreactions. The coverability problem for hierarchical terms is decidable. This\nis proved by showing that every hierarchical term is depth-bounded, an\nundecidable property known in the literature. We thus obtain an expressive\nstatic fragment of the {\\pi}-calculus with decidable safety verification\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 23:35:48 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2016 14:30:11 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["D'Osualdo", "Emanuele", ""], ["Ong", "C. -H. Luke", ""]]}, {"id": "1601.01782", "submitter": "Gilles Dowek", "authors": "Gilles Dowek (DEDUCTEAM)", "title": "On the definition of the classical connectives and quantifiers", "comments": "Why is this a Proof?, Festschrift for Luiz Carlos Pereira , 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical logic is embedded into constructive logic, through a definition of\nthe classical connectives and quantifiers in terms of the constructive ones.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 07:47:59 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Dowek", "Gilles", "", "DEDUCTEAM"]]}, {"id": "1601.01891", "submitter": "Silvia Steila", "authors": "Stefano Berardi and Silvia Steila", "title": "Ramsey's Theorem for Pairs and $k$ Colors as a Sub-Classical Principle\n  of Arithmetic", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose is to study the strength of Ramsey's Theorem for pairs restricted\nto recursive assignments of $k$-many colors, with respect to Intuitionistic\nHeyting Arithmetic. We prove that for every natural number $k \\geq 2$, Ramsey's\nTheorem for pairs and recursive assignments of $k$ colors is equivalent to the\nLimited Lesser Principle of Omniscience for $\\Sigma^0_3$ formulas over Heyting\nArithmetic. Alternatively, the same theorem over intuitionistic arithmetic is\nequivalent to: for every recursively enumerable infinite $k$-ary tree there is\nsome $i < k$ and some branch with infinitely many children of index $i$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 14:57:57 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Berardi", "Stefano", ""], ["Steila", "Silvia", ""]]}, {"id": "1601.01928", "submitter": "Philipp Hoffmann", "authors": "Javier Esparza and Philipp Hoffmann", "title": "Reduction Rules for Colored Workflow Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Colored Workflow nets, a model based on Workflow nets enriched with\ndata. Based on earlier work by Esparza and\nDesel[arXiv:1307.2145,arXiv:1403.4958] on the negotiation model of concurrency,\nwe present reduction rules for our model. Contrary to previous work, our rules\npreserve not only soundness, but also the data flow semantics. For free choice\nnets, the rules reduce all sound nets (and only them) to a net with one single\ntransition and the same data flow semantics. We give an explicit algorithm that\nrequires only a polynomial number of rule applications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 16:18:45 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Esparza", "Javier", ""], ["Hoffmann", "Philipp", ""]]}, {"id": "1601.02132", "submitter": "Cliff Jones", "authors": "Cliff B. Jones, Ian J. Hayes", "title": "Possible values: exploring a concept for concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An important issue in concurrency is interference. This issue manifests\nitself in both shared-variable and communication-based concurrency --- this\npaper focusses on the former case where interference is caused by the\nenvironment of a process changing the values of shared variables.\nRely/guarantee approaches have been shown to be useful in specifying and\nreasoning compositionally about concurrent programs. This paper explores the\nuse of a \"possible values\" notation for reasoning about variables whose values\ncan be changed multiple times by interference. Apart from the value of this\nconcept in providing clear specifications, it offers a principled way of\navoiding the need for some auxiliary (or ghost) variables whose unwise use can\ndestroy compositionality.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2016 16:53:15 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Jones", "Cliff B.", ""], ["Hayes", "Ian J.", ""]]}, {"id": "1601.02258", "submitter": "Jakub Szymanik", "authors": "Ronald de Haan and Jakub Szymanik", "title": "Characterizing Polynomial Ramsey Quantifiers", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 29 (2019) 896-908", "doi": "10.1017/S0960129518000397", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ramsey quantifiers are a natural object of study not only for logic and\ncomputer science, but also for the formal semantics of natural language.\nRestricting attention to finite models leads to the natural question whether\nall Ramsey quantifiers are either polynomial-time computable or NP-hard, and\nwhether we can give a natural characterization of the polynomial-time\ncomputable quantifiers. In this paper, we first show that there exist\nintermediate Ramsey quantifiers and then we prove a dichotomy result for a\nlarge and natural class of Ramsey quantifiers, based on a reasonable and\nwidely-believed complexity assumption. We show that the polynomial-time\ncomputable quantifiers in this class are exactly the constant-log-bounded\nRamsey quantifiers.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 19:25:25 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 11:37:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["de Haan", "Ronald", ""], ["Szymanik", "Jakub", ""]]}, {"id": "1601.02650", "submitter": "Dominik Tomaszuk Dr", "authors": "Dominik Tomaszuk", "title": "Inference rules for RDF(S) and OWL in N3Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents inference rules for Resource Description Framework (RDF),\nRDF Schema (RDFS) and Web Ontology Language (OWL). Our formalization is based\non Notation 3 Logic, which extended RDF by logical symbols and created Semantic\nWeb logic for deductive RDF graph stores. We also propose OWL-P that is a\nlightweight formalism of OWL and supports soft inferences by omitting complex\nlanguage constructs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 21:18:59 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Tomaszuk", "Dominik", ""]]}, {"id": "1601.02742", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Property Checking By Logic Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new framework for Property Checking (PC) of sequential\ncircuits. It is based on a method called Lo-gic Relaxation (LoR). Given a\nsafety property, the LoR method relaxes the transition system at hand, which\nleads to expanding the set of reachable states. For j-th time frame, the LoR\nmethod computes a superset A_j of the set of bad states reachable in j\ntransitions only by the relaxed system. Set A_j is constructed by a technique\ncalled partial quantifier elimination. If A_j does not contain a bad state and\nthis state is reachable in j transitions in the relaxed system, it is also\nreachable in the original system. Hence the property in question does not hold.\n  The appeal of PC by LoR is as follows. An inductive invariant (or a\ncounterexample) generated by LoR is a result of computing the states reachable\nonly in the relaxed system. So, the complexity of PC can be drastically reduced\nby finding a \"faulty\" relaxation that is close to the original system. This is\nanalogous to equivalence checking whose complexity strongly depends on how\nsimilar the designs to be compared are.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 06:18:34 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "1601.03195", "submitter": "Alberto Molinari", "authors": "A. Molinari, A. Montanari, A. Murano, G. Perelli, A. Peron", "title": "Checking Interval Properties of Computations", "comments": "In Journal: Acta Informatica, Springer Berlin Heidelber, 2015", "journal-ref": "Acta Informatica 53 (2016) 587-619", "doi": "10.1007/s00236-015-0250-1", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking is a powerful method widely explored in formal verification.\nGiven a model of a system, e.g., a Kripke structure, and a formula specifying\nits expected behaviour, one can verify whether the system meets the behaviour\nby checking the formula against the model.\n  Classically, system behaviour is expressed by a formula of a temporal logic,\nsuch as LTL and the like. These logics are \"point-wise\" interpreted, as they\ndescribe how the system evolves state-by-state. However, there are relevant\nproperties, such as those constraining the temporal relations between pairs of\ntemporally extended events or involving temporal aggregations, which are\ninherently \"interval-based\", and thus asking for an interval temporal logic.\n  In this paper, we give a formalization of the model checking problem in an\ninterval logic setting. First, we provide an interpretation of formulas of\nHalpern and Shoham's interval temporal logic HS over finite Kripke structures,\nwhich allows one to check interval properties of computations. Then, we prove\nthat the model checking problem for HS against finite Kripke structures is\ndecidable by a suitable small model theorem, and we provide a lower bound to\nits computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 10:41:32 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Molinari", "A.", ""], ["Montanari", "A.", ""], ["Murano", "A.", ""], ["Perelli", "G.", ""], ["Peron", "A.", ""]]}, {"id": "1601.03202", "submitter": "Alberto Molinari", "authors": "A. Molinari, A. Montanari, A. Peron", "title": "Complexity of ITL model checking: some well-behaved fragments of the\n  interval logic HS", "comments": null, "journal-ref": "In proceedings of 22nd TIME, Pages 90-100, 2015 IEEE", "doi": "10.1109/TIME.2015.12", "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking has been successfully used in many computer science fields,\nincluding artificial intelligence, theoretical computer science, and databases.\nMost of the proposed solutions make use of classical, point-based temporal\nlogics, while little work has been done in the interval temporal logic setting.\nRecently, a non-elementary model checking algorithm for Halpern and Shoham's\nmodal logic of time intervals HS over finite Kripke structures (under the\nhomogeneity assumption) and an EXPSPACE model checking procedure for two\nmeaningful fragments of it have been proposed. In this paper, we show that more\nefficient model checking procedures can be developed for some expressive enough\nfragments of HS.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 11:17:36 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Molinari", "A.", ""], ["Montanari", "A.", ""], ["Peron", "A.", ""]]}, {"id": "1601.03206", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "Termination of LCTRSs", "comments": "proceedings for WST 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logically Constrained Term Rewriting Systems (LCTRSs) provide a general\nframework for term rewriting with constraints. We discuss a simple dependency\npair approach to prove termination of LCTRSs. We see that existing techniques\ntransfer to the constrained setting in a natural way.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 11:37:40 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1601.03271", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Andr\\'es Viso, Eduardo Bonelli, Mauricio Ayala-Rinc\\'on", "title": "Type Soundness for Path Polymorphism", "comments": null, "journal-ref": null, "doi": "10.1016/j.entcs.2016.06.015", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path polymorphism is the ability to define functions that can operate\nuniformly over arbitrary recursively specified data structures. Its essence is\ncaptured by patterns of the form $x\\,y$ which decompose a compound data\nstructure into its parts. Typing these kinds of patterns is challenging since\nthe type of a compound should determine the type of its components. We propose\na static type system (i.e. no run-time analysis) for a pattern calculus that\ncaptures this feature. Our solution combines type application, constants as\ntypes, union types and recursive types. We address the fundamental properties\nof Subject Reduction and Progress that guarantee a well-behaved dynamics. Both\nthese results rely crucially on a notion of pattern compatibility and also on a\ncoinductive characterisation of subtyping.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 14:47:49 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 15:12:12 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Viso", "Andr\u00e9s", ""], ["Bonelli", "Eduardo", ""], ["Ayala-Rinc\u00f3n", "Mauricio", ""]]}, {"id": "1601.03370", "submitter": "Pavel Zaichenkov", "authors": "Pavel Zaichenkov, Olga Tveretina, Alex Shafarenko", "title": "A Constraint Satisfaction Method for Configuring Non-Local Service\n  Interfaces", "comments": "the short version of the paper is to appear in iFM 2016 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modularity and decontextualisation are core principles of a service-oriented\narchitecture. However, the principles are often lost when it comes to an\nimplementation of services, as a result of a rigidly defined service interface.\nThe interface, which defines a data format, is typically specific to a\nparticular context and its change entails significant redevelopment costs. This\npaper focuses on a two-fold problem. On the one hand, the interface description\nlanguage must be flexible enough for maintaining service compatibility in a\nvariety of different contexts without modification of the service itself. On\nthe other hand, the composition of interfaces in a distributed environment must\nbe provably consistent. The existing approaches for checking compatibility of\nservice choreographies are either inflexible (WS-CDL and WSCI) or require\nbehaviour specification associated with each service, which is often impossible\nto provide in practice.\n  We present a novel approach for automatic interface configuration in\ndistributed stream-connected components operating as closed-source services\n(i.e. the behavioural protocol is unknown). We introduce a Message Definition\nLanguage (MDL), which can extend the existing interfaces description languages,\nsuch as WSDL, with support of subtyping, inheritance and polymorphism. The MDL\nsupports configuration variables that link input and output interfaces of a\nservice and propagate requirements over an application graph. We present an\nalgorithm that solves the interface reconciliation problem using constraint\nsatisfaction that relies on Boolean satisfiability as a subproblem.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 20:14:19 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2016 12:32:14 GMT"}, {"version": "v3", "created": "Wed, 2 Mar 2016 13:51:25 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Zaichenkov", "Pavel", ""], ["Tveretina", "Olga", ""], ["Shafarenko", "Alex", ""]]}, {"id": "1601.03835", "submitter": "Shuling  Wang", "authors": "Tao Liu, Yangjia Li, Shuling Wang, Mingsheng Ying, Naijun Zhan", "title": "A Theorem Prover for Quantum Hoare Logic and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Hoare Logic (QHL) was introduced in Ying's work to specify and reason\nabout quantum programs. In this paper, we implement a theorem prover for QHL\nbased on Isabelle/HOL. By applying the theorem prover, verifying a quantum\nprogram against a specification is transformed equivalently into an order\nrelation between matrices. Due to the limitation of Isabelle/HOL, the\ncalculation of the order relation is solved by calling an outside oracle\nwritten in Python. To the best of our knowledge, this is the first theorem\nprover for quantum programs. To demonstrate its power, the correctness of two\nwell-known quantum algorithms, i.e., Grover Quantum Search and Quantum Phase\nEstimation (the key step in Shor's quantum algorithm of factoring in polynomial\ntime) are proved using the theorem prover. These are the first mechanized\nproofs for both of them.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 08:34:04 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Liu", "Tao", ""], ["Li", "Yangjia", ""], ["Wang", "Shuling", ""], ["Ying", "Mingsheng", ""], ["Zhan", "Naijun", ""]]}, {"id": "1601.04098", "submitter": "Pavel Naumov", "authors": "Sanaz Azimipour and Pavel Naumov", "title": "Lighthouse Principle for Diffusion in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article investigates influence relation between two sets of agents in a\nsocial network. It proposes a logical system that captures propositional\nproperties of this relation valid in all threshold models of social networks\nwith the same topological structure. The logical system consists of Armstrong\naxioms for functional dependence and an additional Lighthouse axiom. The main\nresults are soundness, completeness, and decidability theorems for this logical\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 23:42:50 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Azimipour", "Sanaz", ""], ["Naumov", "Pavel", ""]]}, {"id": "1601.04147", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada and Samson Abramsky", "title": "Dynamic Game Semantics", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 30 (2020) 892-951", "doi": "10.1017/S0960129520000250", "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper gives a mathematical, in particular, syntax-independent,\nformulation of intensionality and dynamics of computation in terms of games and\nstrategies. Specifically, we give a game semantics for a higher-order\nprogramming language that distinguishes programs with the same value yet\ndifferent algorithms (or intensionality), equipped with the hiding operation on\nstrategies that precisely corresponds to the (small-step) operational semantics\n(or dynamics) of the language. Categorically, our games and strategies give\nrise to a cartesian closed bicategory, and our game semantics forms an instance\nof a generalization of the standard interpretation of functional programming\nlanguages in cartesian closed categories. This work is intended to be the first\nstep towards a mathematical (both categorical and game-semantic) foundation of\nintensional and dynamic aspects of logic and computation; our approach should\nbe applicable to a wide range of logics and computations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 09:43:21 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2017 01:33:46 GMT"}, {"version": "v3", "created": "Thu, 19 Jan 2017 16:41:18 GMT"}, {"version": "v4", "created": "Sun, 19 Nov 2017 11:26:54 GMT"}, {"version": "v5", "created": "Mon, 22 Oct 2018 02:54:23 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Yamada", "Norihiro", ""], ["Abramsky", "Samson", ""]]}, {"id": "1601.04294", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro and Gilles Dowek and Juan Pablo Rinaldi", "title": "Two linearities for quantum computing in the lambda calculus", "comments": "Long journal version of TPNC'17 paper\n  (doi:10.1007/978-3-319-71069-3_22) extended with third author's\n  \"Licenciatura\"'s thesis", "journal-ref": "Biosystems Volume 186, December 2019, 104012. Post proceedings of\n  TPNC'17", "doi": "10.1016/j.biosystems.2019.104012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a way to unify two approaches of non-cloning in quantum\nlambda-calculi: logical and algebraic linearities. The first approach is to\nforbid duplicating variables, while the second is to consider all lambda-terms\nas algebraic-linear functions. We illustrate this idea by defining a quantum\nextension of first-order simply-typed lambda-calculus, where the type is linear\non superposition, while allows cloning base vectors. In addition, we provide an\ninterpretation of the calculus where superposed types are interpreted as vector\nspaces and non-superposed types as their basis.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2016 13:43:08 GMT"}, {"version": "v10", "created": "Wed, 31 Jul 2019 20:12:54 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2016 10:57:18 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2016 17:16:07 GMT"}, {"version": "v4", "created": "Wed, 6 Jul 2016 15:15:07 GMT"}, {"version": "v5", "created": "Fri, 21 Oct 2016 20:34:02 GMT"}, {"version": "v6", "created": "Sun, 6 Aug 2017 01:24:07 GMT"}, {"version": "v7", "created": "Fri, 6 Apr 2018 14:30:56 GMT"}, {"version": "v8", "created": "Thu, 16 Aug 2018 17:10:51 GMT"}, {"version": "v9", "created": "Tue, 18 Jun 2019 09:17:34 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Dowek", "Gilles", ""], ["Rinaldi", "Juan Pablo", ""]]}, {"id": "1601.04299", "submitter": "Benedikt Ahrens", "authors": "Benedikt Ahrens and Ralph Matthes", "title": "Heterogeneous substitution systems revisited", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matthes and Uustalu (TCS 327(1-2):155-174, 2004) presented a categorical\ndescription of substitution systems capable of capturing syntax involving\nbinding which is independent of whether the syntax is made up from least or\ngreatest fixed points. We extend this work in two directions: we continue the\nanalysis by creating more categorical structure, in particular by organizing\nsubstitution systems into a category and studying its properties, and we\ndevelop the proofs of the results of the cited paper and our new ones in\nUniMath, a recent library of univalent mathematics formalized in the Coq\ntheorem prover.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2016 14:14:37 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Ahrens", "Benedikt", ""], ["Matthes", "Ralph", ""]]}, {"id": "1601.04520", "submitter": "Ale\\v{s} Bizjak", "authors": "Manuel Bodirsky and Antoine Mottet", "title": "A Dichotomy for First-Order Reducts of Unary Structures", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (May 22,\n  2018) lmcs:4521", "doi": "10.23638/LMCS-14(2:13)2018", "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many natural decision problems can be formulated as constraint satisfaction\nproblems for reducts $\\mathbb{A}$ of finitely bounded homogeneous structures.\nThis class of problems is a large generalisation of the class of CSPs over\nfinite domains. Our first result is a general polynomial-time reduction from\nsuch infinite-domain CSPs to finite-domain CSPs. We use this reduction to\nobtain new powerful polynomial-time tractability conditions that can be\nexpressed in terms of the topological polymorphism clone of $\\mathbb{A}$.\nMoreover, we study the subclass $\\mathcal{C}$ of CSPs for structures\n$\\mathbb{A}$ that are reducts of a structure with a unary language. Also this\nclass $\\mathcal{C}$ properly extends the class of all finite-domain CSPs. We\napply our new tractability conditions to prove the general tractability\nconjecture of Bodirsky and Pinsker for reducts of finitely bounded homogeneous\nstructures for the class $\\mathcal{C}$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 14:05:00 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 09:26:26 GMT"}, {"version": "v3", "created": "Fri, 31 Mar 2017 14:54:05 GMT"}, {"version": "v4", "created": "Tue, 11 Apr 2017 16:58:28 GMT"}, {"version": "v5", "created": "Sat, 2 Dec 2017 09:39:32 GMT"}, {"version": "v6", "created": "Sun, 20 May 2018 10:24:36 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mottet", "Antoine", ""]]}, {"id": "1601.04661", "submitter": "Christoph Haase", "authors": "Christoph Haase and Stefan Kiefer and Markus Lohrey", "title": "Efficient Quantile Computation in Markov Chains via Counting Problems\n  for Parikh Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cost Markov chain is a Markov chain whose transitions are labelled with\nnon-negative integer costs. A fundamental problem on this model, with\napplications in the verification of stochastic systems, is to compute\ninformation about the distribution of the total cost accumulated in a run. This\nincludes the probability of large total costs, the median cost, and other\nquantiles. While expectations can be computed in polynomial time, previous work\nhas demonstrated that the computation of cost quantiles is harder but can be\ndone in PSPACE. In this paper we show that cost quantiles in cost Markov chains\ncan be computed in the counting hierarchy, thus providing evidence that\ncomputing those quantiles is likely not PSPACE-hard. We obtain this result by\nexhibiting a tight link to a problem in formal language theory: counting the\nnumber of words that are both accepted by a given automaton and have a given\nParikh image. Motivated by this link, we comprehensively investigate the\ncomplexity of the latter problem. Among other techniques, we rely on the\nso-called BEST theorem for efficiently computing the number of Eulerian\ncircuits in a directed graph.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 19:31:03 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Haase", "Christoph", ""], ["Kiefer", "Stefan", ""], ["Lohrey", "Markus", ""]]}, {"id": "1601.04802", "submitter": "Mingshuai Chen", "authors": "Ting Gan, Liyun Dai, Bican Xia, Naijun Zhan, Deepak Kapur and\n  Mingshuai Chen", "title": "Interpolation synthesis for quadratic polynomial inequalities and\n  combination with EUF", "comments": "40 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for generating interpolants for formulas which are conjunctions\nof quadratic polynomial inequalities (both strict and nonstrict) is proposed.\nThe algorithm is based on a key observation that quadratic polynomial\ninequalities can be linearized if they are concave. A generalization of\nMotzkin's transposition theorem is proved, which is used to generate an\ninterpolant between two mutually contradictory conjunctions of polynomial\ninequalities, using semi-definite programming in time complexity\n$\\mathcal{O}(n^3+nm))$, where $n$ is the number of variables and $m$ is the\nnumber of inequalities. Using the framework proposed by \\cite{SSLMCS2008} for\ncombining interpolants for a combination of quantifier-free theories which have\ntheir own interpolation algorithms, a combination algorithm is given for the\ncombined theory of concave quadratic polynomial inequalities and the equality\ntheory over uninterpreted functions symbols (\\textit{EUF}). The proposed\napproach is applicable to all existing abstract domains like \\emph{octagon},\n\\emph{polyhedra}, \\emph{ellipsoid} and so on, therefore it can be used to\nimprove the scalability of existing verification techniques for programs and\nhybrid systems. In addition, we also discuss how to extend our approach to\nformulas beyond concave quadratic polynomials using Gr\\\"{o}bner basis.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 05:05:49 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2016 05:46:45 GMT"}, {"version": "v3", "created": "Thu, 10 Nov 2016 22:35:04 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Gan", "Ting", ""], ["Dai", "Liyun", ""], ["Xia", "Bican", ""], ["Zhan", "Naijun", ""], ["Kapur", "Deepak", ""], ["Chen", "Mingshuai", ""]]}, {"id": "1601.04876", "submitter": "Danko Ilik", "authors": "Taus Brock-Nannestad and Danko Ilik", "title": "An Intuitionistic Formula Hierarchy Based on High-School Identities", "comments": null, "journal-ref": null, "doi": "10.1002/malq.201700047", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the notion of intuitionistic equivalence and formal proof\nrepresentations by adopting the view of formulas as exponential polynomials.\n  After observing that most of the invertible proof rules of intuitionistic\n(minimal) propositional sequent calculi are formula (i.e. sequent) isomorphisms\ncorresponding to the high-school identities, we show that one can obtain a more\ncompact variant of a proof system, consisting of non-invertible proof rules\nonly, and where the invertible proof rules have been replaced by a formula\nnormalisation procedure.\n  Moreover, for certain proof systems such as the G4ip sequent calculus of\nVorob'ev, Hudelmaier, and Dyckhoff, it is even possible to see all of the\nnon-invertible proof rules as strict inequalities between exponential\npolynomials; a careful combinatorial treatment is given in order to establish\nthis fact.\n  Finally, we extend the exponential polynomial analogy to the first-order\nquantifiers, showing that it gives rise to an intuitionistic hierarchy of\nformulas, resembling the classical arithmetical hierarchy, and the first one\nthat classifies formulas while preserving isomorphism.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 11:34:57 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 13:13:42 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 20:11:39 GMT"}, {"version": "v4", "created": "Sun, 17 Jun 2018 15:23:19 GMT"}, {"version": "v5", "created": "Sun, 12 Aug 2018 15:36:24 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Brock-Nannestad", "Taus", ""], ["Ilik", "Danko", ""]]}, {"id": "1601.04908", "submitter": "Martha Lewis", "authors": "Desislava Bankova, Bob Coecke, Martha Lewis, Daniel Marsden", "title": "Graded Entailment for Compositional Distributional Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The categorical compositional distributional model of natural language\nprovides a conceptually motivated procedure to compute the meaning of\nsentences, given grammatical structure and the meanings of its words. This\napproach has outperformed other models in mainstream empirical language\nprocessing tasks. However, until recently it has lacked the crucial feature of\nlexical entailment -- as do other distributional models of meaning.\n  In this paper we solve the problem of entailment for categorical\ncompositional distributional semantics. Taking advantage of the abstract\ncategorical framework allows us to vary our choice of model. This enables the\nintroduction of a notion of entailment, exploiting ideas from the categorical\nsemantics of partial knowledge in quantum computation.\n  The new model of language uses density matrices, on which we introduce a\nnovel robust graded order capturing the entailment strength between concepts.\nThis graded measure emerges from a general framework for approximate\nentailment, induced by any commutative monoid. Quantum logic embeds in our\ngraded order.\n  Our main theorem shows that entailment strength lifts compositionally to the\nsentence level, giving a lower bound on sentence entailment. We describe the\nessential properties of graded entailment such as continuity, and provide a\nprocedure for calculating entailment strength.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 13:13:25 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 20:10:27 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Bankova", "Desislava", ""], ["Coecke", "Bob", ""], ["Lewis", "Martha", ""], ["Marsden", "Daniel", ""]]}, {"id": "1601.04964", "submitter": "Ross Duncan", "authors": "Ross Duncan and Kevin Dunne", "title": "Interacting Frobenius Algebras are Hopf", "comments": "32 pages; submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theories featuring the interaction between a Frobenius algebra and a Hopf\nalgebra have recently appeared in several areas in computer science: concurrent\nprogramming, control theory, and quantum computing, among others. Bonchi,\nSobocinski, and Zanasi (2014) have shown that, given a suitable distributive\nlaw, a pair of Hopf algebras forms two Frobenius algebras. Here we take the\nopposite approach, and show that interacting Frobenius algebras form Hopf\nalgebras. We generalise (BSZ 2014) by including non-trivial dynamics of the\nunderlying object---the so-called phase group---and investigate the effects of\nfinite dimensionality of the underlying model. We recover the system of Bonchi\net al as a subtheory in the prime power dimensional case, but the more general\ntheory does not arise from a distributive law.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 15:53:33 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Duncan", "Ross", ""], ["Dunne", "Kevin", ""]]}, {"id": "1601.05002", "submitter": "Jo\\~ao Sousa Pinto", "authors": "Jo\\\"el Ouaknine, Amaury Pouly, Jo\\~ao Sousa-Pinto, James Worrell", "title": "Solvability of Matrix-Exponential Equations", "comments": "Accepted to LICS 2016", "journal-ref": null, "doi": "10.1145/2933575.2934538", "report-no": null, "categories": "cs.DM cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a continuous analogue of Babai et al.'s and Cai et al.'s problem\nof solving multiplicative matrix equations. Given $k+1$ square matrices $A_{1},\n\\ldots, A_{k}, C$, all of the same dimension, whose entries are real algebraic,\nwe examine the problem of deciding whether there exist non-negative reals\n$t_{1}, \\ldots, t_{k}$ such that \\begin{align*} \\prod \\limits_{i=1}^{k}\n\\exp(A_{i} t_{i}) = C . \\end{align*} We show that this problem is undecidable\nin general, but decidable under the assumption that the matrices $A_{1},\n\\ldots, A_{k}$ commute. Our results have applications to reachability problems\nfor linear hybrid automata. Our decidability proof relies on a number of\ntheorems from algebraic and transcendental number theory, most notably those of\nBaker, Kronecker, Lindemann, and Masser, as well as some useful geometric and\nlinear-algebraic results, including the Minkowski-Weyl theorem and a new (to\nthe best of our knowledge) result about the uniqueness of strictly upper\ntriangular matrix logarithms of upper unitriangular matrices. On the other\nhand, our undecidability result is shown by reduction from Hilbert's Tenth\nProblem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 17:14:39 GMT"}, {"version": "v2", "created": "Sun, 15 May 2016 17:44:40 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Ouaknine", "Jo\u00ebl", ""], ["Pouly", "Amaury", ""], ["Sousa-Pinto", "Jo\u00e3o", ""], ["Worrell", "James", ""]]}, {"id": "1601.05047", "submitter": "Justin Hsu", "authors": "Gilles Barthe, Marco Gaboardi, Benjamin Gr\\'egoire, Justin Hsu,\n  Pierre-Yves Strub", "title": "Proving Differential Privacy via Probabilistic Couplings", "comments": null, "journal-ref": null, "doi": "10.1145/2933575.2934554", "report-no": null, "categories": "cs.LO cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop compositional methods for formally verifying\ndifferential privacy for algorithms whose analysis goes beyond the composition\ntheorem. Our methods are based on the observation that differential privacy has\ndeep connections with a generalization of probabilistic couplings, an\nestablished mathematical tool for reasoning about stochastic processes. Even\nwhen the composition theorem is not helpful, we can often prove privacy by a\ncoupling argument.\n  We demonstrate our methods on two algorithms: the Exponential mechanism and\nthe Above Threshold algorithm, the critical component of the famous Sparse\nVector algorithm. We verify these examples in a relational program logic\napRHL+, which can construct approximate couplings. This logic extends the\nexisting apRHL logic with more general rules for the Laplace mechanism and the\none-sided Laplace mechanism, and new structural rules enabling pointwise\nreasoning about privacy; all the rules are inspired by the connection with\ncoupling. While our paper is presented from a formal verification perspective,\nwe believe that its main insight is of independent interest for the\ndifferential privacy community.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 19:37:19 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 09:27:19 GMT"}, {"version": "v3", "created": "Sun, 19 Jun 2016 18:57:10 GMT"}, {"version": "v4", "created": "Thu, 9 Mar 2017 16:00:41 GMT"}, {"version": "v5", "created": "Sun, 14 Mar 2021 14:06:26 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Gr\u00e9goire", "Benjamin", ""], ["Hsu", "Justin", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1601.05106", "submitter": "Jana Dunfield", "authors": "Jana Dunfield and Neelakantan R. Krishnaswami", "title": "Sound and Complete Bidirectional Typechecking for Higher-Rank\n  Polymorphism with Existentials and Indexed Types", "comments": "28 pages, plus lemmas and proofs (191 pages); accepted to POPL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional typechecking, in which terms either synthesize a type or are\nchecked against a known type, has become popular for its applicability to a\nvariety of type systems, its error reporting, and its ease of implementation.\nFollowing principles from proof theory, bidirectional typing can be applied to\nmany type constructs. The principles underlying a bidirectional approach to\nindexed types (generalized algebraic datatypes) are less clear. Building on\nproof-theoretic treatments of equality, we give a declarative specification of\ntyping based on focalization. This approach permits declarative rules for\ncoverage of pattern matching, as well as support for first-class existential\ntypes using a focalized subtyping judgment. We use refinement types to avoid\nexplicitly passing equality proofs in our term syntax, making our calculus\nsimilar to languages such as Haskell and OCaml. We also extend the declarative\nspecification with an explicit rules for deducing when a type is principal,\npermitting us to give a complete declarative specification for a rich type\nsystem with significant type inference. We also give a set of algorithmic\ntyping rules, and prove that it is sound and complete with respect to the\ndeclarative system. The proof requires a number of technical innovations,\nincluding proving soundness and completeness in a mutually recursive fashion.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 21:36:21 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 20:07:27 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 22:43:05 GMT"}, {"version": "v4", "created": "Sat, 19 Sep 2020 22:48:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Dunfield", "Jana", ""], ["Krishnaswami", "Neelakantan R.", ""]]}, {"id": "1601.05176", "submitter": "Hugo Gimbert", "authors": "Hugo Gimbert (LaBRI)", "title": "On the Control of Asynchronous Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decidability of the distributed version of the Ramadge and Wonham\ncontroller synthesis problem,where both the plant and the controllers are\nmodeled as asynchronous automataand the controllers have causal memoryis a\nchallenging open problem.There exist three classes of plants for which the\nexistence of a correct controller with causal memory has been shown decidable:\nwhen the dependency graph of actions is series-parallel, when the processes are\nconnectedly communicating and when the dependency graph of processes is a tree.\nWe design a class of plants, called decomposable games, with a decidable\ncontroller synthesis problem.This provides a unified proof of the three\nexisting decidability results as well as new examples of decidable plants.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 05:52:21 GMT"}, {"version": "v10", "created": "Fri, 28 Jul 2017 14:36:47 GMT"}, {"version": "v11", "created": "Tue, 1 Aug 2017 12:47:55 GMT"}, {"version": "v12", "created": "Fri, 4 Aug 2017 06:34:52 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 08:47:06 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2016 13:57:19 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2016 10:04:26 GMT"}, {"version": "v5", "created": "Mon, 24 Oct 2016 11:24:02 GMT"}, {"version": "v6", "created": "Tue, 25 Oct 2016 07:29:44 GMT"}, {"version": "v7", "created": "Tue, 13 Dec 2016 13:21:55 GMT"}, {"version": "v8", "created": "Wed, 1 Feb 2017 10:12:54 GMT"}, {"version": "v9", "created": "Mon, 24 Apr 2017 08:37:07 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Gimbert", "Hugo", "", "LaBRI"]]}, {"id": "1601.05228", "submitter": "Swen Jacobs", "authors": "Swen Jacobs and Felix Klein", "title": "A High-Level LTL Synthesis Format: TLSF v1.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Temporal Logic Synthesis Format (TLSF), a high-level format to\ndescribe synthesis problems via Linear Temporal Logic (LTL). The format builds\nupon standard LTL, but additionally allows to use high level constructs, such\nas sets and functions, to provide a compact and human readable representation.\nFurthermore, the format allows to identify parameters of a specification such\nthat a single description can be used to define a family of problems. We also\npresent a tool to automatically translate the format into plain LTL, which then\ncan be used for synthesis by a solver. The tool also allows to adjust\nparameters of the specification and to apply standard transformations on the\nresulting formula.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 10:38:10 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Jacobs", "Swen", ""], ["Klein", "Felix", ""]]}, {"id": "1601.05283", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Marketing Impact on Diffusion in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a way to add marketing into the standard threshold model\nof social networks. Within this framework, the paper studies logical properties\nof the influence relation between sets of agents in social networks. Two\ndifferent forms of this relation are considered: one for promotional marketing\nand the other for preventive marketing. In each case a sound and complete\nlogical system describing properties of the influence relation is proposed.\nBoth systems could be viewed as extensions of Armstrong's axioms of functional\ndependency from the database theory.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 14:40:47 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 17:48:18 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1601.05336", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "Game-theoretic Interpretation of Intuitionistic Type Theory", "comments": "This paper has been withdrawn by the author because he has\n  established a more reasonable game semantics for intuitionistic type theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a game semantics for intuitionistic type theory. Specifically, we\npropose categories with families of a new variant of games and strategies for\nboth extensional and intensional variants of the type theory with dependent\nfunction, dependent pair, and identity types as well as universes. Our games\nand strategies generalize the existing notion of games and strategies and\nachieve an interpretation of dependent types and the hierarchy of universes in\nan intuitive manner. We believe that it is a significant step towards a\ncomputational and intensional interpretation of the type theory.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 17:16:51 GMT"}, {"version": "v10", "created": "Mon, 3 Oct 2016 20:59:51 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2016 10:17:24 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2016 13:26:35 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2016 21:49:56 GMT"}, {"version": "v5", "created": "Fri, 12 Feb 2016 16:55:48 GMT"}, {"version": "v6", "created": "Mon, 7 Mar 2016 23:36:28 GMT"}, {"version": "v7", "created": "Mon, 25 Apr 2016 22:56:12 GMT"}, {"version": "v8", "created": "Tue, 10 May 2016 09:13:30 GMT"}, {"version": "v9", "created": "Mon, 15 Aug 2016 13:34:48 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1601.05372", "submitter": "Thorsten Wissmann", "authors": "Lawrence Dunn and Jamie Vicary", "title": "Coherence for Frobenius pseudomonoids and the geometry of linear proofs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (July 26,\n  2019) lmcs:5645", "doi": "10.23638/LMCS-15(3:5)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove coherence theorems for Frobenius pseudomonoids and snakeorators in\nmonoidal bicategories. As a consequence we obtain a 3d notation for proofs in\nnonsymmetric multiplicative linear logic, with a geometrical notion of\nequivalence, and without the need for a global correctness criterion or\nthinning links. We argue that traditional proof nets are the 2d projections of\nthese 3d diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 19:02:57 GMT"}, {"version": "v2", "created": "Thu, 10 Mar 2016 13:06:51 GMT"}, {"version": "v3", "created": "Sun, 17 Jul 2016 23:58:00 GMT"}, {"version": "v4", "created": "Fri, 6 Jul 2018 10:38:27 GMT"}, {"version": "v5", "created": "Wed, 24 Jul 2019 20:15:25 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Dunn", "Lawrence", ""], ["Vicary", "Jamie", ""]]}, {"id": "1601.05520", "submitter": "Christine Rizkallah", "authors": "Liam O'Connor, Christine Rizkallah, Zilin Chen, Sidney Amani, Japheth\n  Lim, Yutaka Nagashima, Thomas Sewell, Alex Hixon, Gabriele Keller, Toby\n  Murray, Gerwin Klein", "title": "COGENT: Certified Compilation for a Functional Systems Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-certifying compiler for the COGENT systems language. COGENT\nis a restricted, polymorphic, higher-order, and purely functional language with\nlinear types and without the need for a trusted runtime or garbage collector.\nIt compiles to efficient C code that is designed to interoperate with existing\nC functions. The language is suited for layered systems code with minimal\nsharing such as file systems or network protocol control code. For a well-typed\nCOGENT program, the compiler produces C code, a high-level shallow embedding of\nits semantics in Isabelle/HOL, and a proof that the C code correctly implements\nthis embedding. The aim is for proof engineers to reason about the full\nsemantics of real-world systems code productively and equationally, while\nretaining the interoperability and leanness of C. We describe the formal\nverification stages of the compiler, which include automated formal refinement\ncalculi, a switch from imperative update semantics to functional value\nsemantics formally justified by the linear type system, and a number of\nstandard compiler phases such as type checking and monomorphisation. The\ncompiler certificate is a series of language-level meta proofs and per-program\ntranslation validation phases, combined into one coherent top-level theorem in\nIsabelle/HOL.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 05:54:07 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["O'Connor", "Liam", ""], ["Rizkallah", "Christine", ""], ["Chen", "Zilin", ""], ["Amani", "Sidney", ""], ["Lim", "Japheth", ""], ["Nagashima", "Yutaka", ""], ["Sewell", "Thomas", ""], ["Hixon", "Alex", ""], ["Keller", "Gabriele", ""], ["Murray", "Toby", ""], ["Klein", "Gerwin", ""]]}, {"id": "1601.05656", "submitter": "Roman Kuznets", "authors": "Roman Kuznets", "title": "Proving Craig and Lyndon Interpolation Using Labelled Sequent Calculi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently presented a general method of proving the fundamental\nlogical properties of Craig and Lyndon Interpolation (IPs) by induction on\nderivations in a wide class of internal sequent calculi, including sequents,\nhypersequents, and nested sequents. Here we adapt the method to a more general\nexternal formalism of labelled sequents and provide sufficient criteria on the\nKripke-frame characterization of a logic that guarantee the IPs. In particular,\nwe show that classes of frames definable by quantifier-free Horn formulas\ncorrespond to logics with the IPs. These criteria capture the modal cube and\nthe infinite family of transitive Geach logics.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 14:34:16 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Kuznets", "Roman", ""]]}, {"id": "1601.06098", "submitter": "Noam Zeilberger", "authors": "Paul-Andr\\'e Melli\\`es and Noam Zeilberger", "title": "A bifibrational reconstruction of Lawvere's presheaf hyperdoctrine", "comments": "Identical to the final version of the paper as appears in proceedings\n  of LICS 2016, formatted for on-screen reading", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining insights from the study of type refinement systems and of monoidal\nclosed chiralities, we show how to reconstruct Lawvere's hyperdoctrine of\npresheaves using a full and faithful embedding into a monoidal closed\nbifibration living now over the compact closed category of small categories and\ndistributors. Besides revealing dualities which are not immediately apparent in\nthe traditional presentation of the presheaf hyperdoctrine, this reconstruction\nleads us to an axiomatic treatment of directed equality predicates (modelled by\nhom presheaves), realizing a vision initially set out by Lawvere (1970). It\nalso leads to a simple calculus of string diagrams (representing presheaves)\nthat is highly reminiscent of C. S. Peirce's existential graphs for predicate\nlogic, refining an earlier interpretation of existential graphs in terms of\nBoolean hyperdoctrines by Brady and Trimble. Finally, we illustrate how this\nwork extends to a bifibrational setting a number of fundamental ideas of linear\nlogic.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 18:39:48 GMT"}, {"version": "v2", "created": "Fri, 12 Aug 2016 12:44:25 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Melli\u00e8s", "Paul-Andr\u00e9", ""], ["Zeilberger", "Noam", ""]]}, {"id": "1601.06183", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer", "title": "A Complete Uniform Substitution Calculus for Differential Dynamic Logic", "comments": "Long article extending the conference version that appeared at CADE\n  2015, arXiv:1503.01981", "journal-ref": "Journal of Automated Reasoning, 59(2), pages 219-265, 2017", "doi": "10.1007/s10817-016-9385-1", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a relatively complete proof calculus for differential\ndynamic logic (dL) that is entirely based on uniform substitution, a proof rule\nthat substitutes a formula for a predicate symbol everywhere. Uniform\nsubstitutions make it possible to use axioms instead of axiom schemata, thereby\nsubstantially simplifying implementations. Instead of subtle schema variables\nand soundness-critical side conditions on the occurrence patterns of logical\nvariables to restrict infinitely many axiom schema instances to sound ones, the\nresulting calculus adopts only a finite number of ordinary dL formulas as\naxioms, which uniform substitutions instantiate soundly. The static semantics\nof differential dynamic logic and the soundness-critical restrictions it\nimposes on proof steps is captured exclusively in uniform substitutions and\nvariable renamings as opposed to being spread in delicate ways across the\nprover implementation. In addition to sound uniform substitutions, this article\nintroduces differential forms for differential dynamic logic that make it\npossible to internalize differential invariants, differential substitutions,\nand derivatives as first-class axioms to reason about differential equations\naxiomatically. The resulting axiomatization of differential dynamic logic is\nproved to be sound and relatively complete.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 22:00:10 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 14:37:41 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2016 18:50:35 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Platzer", "Andr\u00e9", ""]]}, {"id": "1601.06198", "submitter": "Marino Miculan", "authors": "Marco Bernardo and Marino Miculan", "title": "Disjunctive Probabilistic Modal Logic is Enough for Bisimilarity on\n  Reactive Probabilistic Systems", "comments": "Aligned content with version accepted at ICTCS 2016: fixed minor\n  typos, added reference, improved definitions in Section 3. Still 10 pages in\n  sigplanconf format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Larsen and Skou characterized probabilistic bisimilarity over reactive\nprobabilistic systems with a logic including true, negation, conjunction, and a\ndiamond modality decorated with a probabilistic lower bound. Later on,\nDesharnais, Edalat, and Panangaden showed that negation is not necessary to\ncharacterize the same equivalence. In this paper, we prove that the logical\ncharacterization holds also when conjunction is replaced by disjunction, with\nnegation still being not necessary. To this end, we introduce reactive\nprobabilistic trees, a fully abstract model for reactive probabilistic systems\nthat allows us to demonstrate expressiveness of the disjunctive probabilistic\nmodal logic, as well as of the previously mentioned logics, by means of a\ncompactness argument.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 23:10:29 GMT"}, {"version": "v2", "created": "Sat, 9 Apr 2016 08:23:38 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 08:00:03 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Bernardo", "Marco", ""], ["Miculan", "Marino", ""]]}, {"id": "1601.06298", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling and Darin Morrison", "title": "Syntax and Semantics of Abstract Binding Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this paper is the development of the syntax and semantics\nof multi-sorted nominal abstract binding trees (abts), an extension of second\norder universal algebra to support symbol-indexed families of operators.\nNominal abts are essential for correctly treating the syntax of languages with\ngenerative phenomena, including exceptions and mutable state. Additionally we\nhave developed the categorical semantics for abstract binding trees formally in\nConstructive Type Theory using the Agda proof assistant. Multi-sorted nominal\nabts also form the syntactic basis for the upcoming version of the JonPRL proof\nassistant, an implementation of an extensional constructive type theory in the\nNuprl tradition.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 17:37:40 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Sterling", "Jonathan", ""], ["Morrison", "Darin", ""]]}, {"id": "1601.06504", "submitter": "Yongming Li", "authors": "Yongming Li", "title": "Quantitative Model Checking of Linear-Time Properties Based on\n  Generalized Possibility Measures", "comments": "arXiv admin note: text overlap with arXiv:1409.6466", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking of linear-time properties based on possibility measures was\nstudied in previous work (Y. Li and L. Li, Model checking of linear-time\nproperties based on possibility measure, IEEE Transactions on Fuzzy Systems,\n21(5)(2013), 842-854). However, the linear-time properties considered in the\nprevious work was classical and qualitative, possibility information of the\nsystems was not considered at all. We shall study quantitative model checking\nof fuzzy linear-time properties based on generalized possibility measures in\nthe paper. Both the model of the system, as well as the properties the system\nneeds to adhere to, are described using possibility information to identify the\nuncertainty in the model/properties. The systems are modeled by {\\sl\ngeneralized possibilistic Kripke structures} (GPKS, in short), and the\nproperties are described by fuzzy linear-time properties. Concretely, fuzzy\nlinear-time properties about reachability, always reachability, constrain\nreachability, repeated reachability and persitence in GPKSs are introduced and\nstudied. Fuzzy regular safety properties and fuzzy $\\omega-$regular properties\nin GPKSs are introduced, the verification of fuzzy regular safety properties\nand fuzzy $\\omega-$regular properties using fuzzy finite automata are\nthoroughly studied. It has been shown that the verification of fuzzy regular\nsafety properties and fuzzy $\\omega-$regular properties in a finite GPKS can be\ntransformed into the verification of (always) reachability properties and\nrepeated reachability (persistence) properties in the product GPKS introduced\nin this paper. Several examples are given to illustrate the methods presented\nin the paper.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 08:10:12 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Li", "Yongming", ""]]}, {"id": "1601.06521", "submitter": "EPTCS", "authors": "Bishoksan Kafle (Roskilde University), John P. Gallagher (Roskilde\n  University)", "title": "Interpolant Tree Automata and their Application in Horn Clause\n  Verification", "comments": "In Proceedings VPT 2016, arXiv:1607.01835", "journal-ref": "EPTCS 216, 2016, pp. 104-117", "doi": "10.4204/EPTCS.216.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the combination of abstract interpretation over the\ndomain of convex polyhedra with interpolant tree automata, in an\nabstraction-refinement scheme for Horn clause verification. These techniques\nhave been previously applied separately, but are combined in a new way in this\npaper. The role of an interpolant tree automaton is to provide a generalisation\nof a spurious counterexample during refinement, capturing a possibly infinite\nset of spurious counterexample traces. In our approach these traces are then\neliminated using a transformation of the Horn clauses. We compare this approach\nwith two other methods; one of them uses interpolant tree automata in an\nalgorithm for trace abstraction and refinement, while the other uses abstract\ninterpretation over the domain of convex polyhedra without the generalisation\nstep. Evaluation of the results of experiments on a number of Horn clause\nverification problems indicates that the combination of interpolant tree\nautomaton with abstract interpretation gives some increase in the power of the\nverification tool, while sometimes incurring a performance overhead.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 09:16:44 GMT"}, {"version": "v2", "created": "Sun, 10 Jul 2016 04:49:20 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Kafle", "Bishoksan", "", "Roskilde University"], ["Gallagher", "John P.", "", "Roskilde\n  University"]]}, {"id": "1601.06522", "submitter": "\\\"Amin Baumeler", "authors": "\\\"Amin Baumeler and Stefan Wolf", "title": "Non-causal computation", "comments": "6 pages, 4 figures", "journal-ref": "Entropy 19(7), 326, 2017", "doi": "10.3390/e19070326", "report-no": null, "categories": "quant-ph cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation models such as circuits describe sequences of computation steps\nthat are carried out one after the other. In other words, algorithm design is\ntraditionally subject to the restriction imposed by a fixed causal order. We\naddress a novel computing paradigm beyond quantum computing, replacing this\nassumption by mere logical consistency: We study non-causal circuits, where a\nfixed time structure within a gate is locally assumed whilst the global causal\nstructure between the gates is dropped. We present examples of logically\nconsistent non- causal circuits outperforming all causal ones; they imply that\nsuppressing loops entirely is more restrictive than just avoiding the\ncontradictions they can give rise to. That fact is already known for\ncorrelations as well as for communication, and we here extend it to\ncomputation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 09:18:22 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 16:01:10 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Baumeler", "\u00c4min", ""], ["Wolf", "Stefan", ""]]}, {"id": "1601.06548", "submitter": "David Cerna", "authors": "David Cerna and Alexander Leitsch", "title": "Schematic Cut elimination and the Ordered Pigeonhole Principle [Extended\n  Version]", "comments": "Submitted to IJCAR 2016. Will be a reference for Appendix material in\n  that paper. arXiv admin note: substantial text overlap with arXiv:1503.08551", "journal-ref": null, "doi": "10.1007/978-3-319-40229-1\\_17", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, an attempt was made to apply the schematic CERES method [8]\nto a formal proof with an arbitrary number of {\\Pi} 2 cuts (a recursive proof\nencapsulating the infinitary pigeonhole principle) [5]. However the derived\nschematic refutation for the characteristic clause set of the proof could not\nbe expressed in the formal language provided in [8]. Without this formalization\na Herbrand system cannot be algorithmically extracted. In this work, we provide\na restriction of the proof found in [5], the ECA-schema (Eventually Constant\nAssertion), or ordered infinitary pigeonhole principle, whose analysis can be\ncompletely carried out in the framework of [8], this is the first time the\nframework is used for proof analysis. From the refutation of the clause set and\na substitution schema we construct a Herbrand system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 10:27:22 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Cerna", "David", ""], ["Leitsch", "Alexander", ""]]}, {"id": "1601.07403", "submitter": "Andrei Bulatov", "authors": "Andrei A. Bulatov", "title": "Graphs of finite algebras, edges, and connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We refine and advance the study of the local structure of idempotent finite\nalgebras started in [A.Bulatov, The Graph of a Relational Structure and\nConstraint Satisfaction Problems, LICS, 2004]. We introduce a graph-like\nstructure on an arbitrary finite idempotent algebra omitting type 1. We show\nthat this graph is connected, its edges can be classified into 3 types\ncorresponding to the local behavior (semilattice, majority, or affine) of\ncertain term operations, and that the structure of the algebra can be\n`improved' without introducing type 1 by choosing an appropriate reduct of the\noriginal algebra. Then we refine this structure demonstrating that the edges of\nthe graph of an algebra can be made `thin', that is, there are term operations\nthat behave very similar to semilattice, majority, or affine operations on\n2-element subsets of the algebra. Finally, we prove certain connectivity\nproperties of the refined structures.\n  This research is motivated by the study of the Constraint Satisfaction\nProblem, although the problem itself does not really show up in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2016 00:59:54 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Bulatov", "Andrei A.", ""]]}, {"id": "1601.07472", "submitter": "J?rgen Koslowski", "authors": "Guillaume Cano, Cyril Cohen, Maxime D\\'en\\`es, Anders M\\\"ortberg,\n  Vincent Siles", "title": "Formalized linear algebra over Elementary Divisor Rings in Coq", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 2 (June 22,\n  2016) lmcs:1639", "doi": "10.2168/LMCS-12(2:7)2016", "report-no": null, "categories": "cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Coq formalization of linear algebra over elementary\ndivisor rings, that is, rings where every matrix is equivalent to a matrix in\nSmith normal form. The main results are the formalization that these rings\nsupport essential operations of linear algebra, the classification theorem of\nfinitely presented modules over such rings and the uniqueness of the Smith\nnormal form up to multiplication by units. We present formally verified\nalgorithms computing this normal form on a variety of coefficient structures\nincluding Euclidean domains and constructive principal ideal domains. We also\nstudy different ways to extend B\\'ezout domains in order to be able to compute\nthe Smith normal form of matrices. The extensions we consider are: adequacy\n(i.e. the existence of a gdco operation), Krull dimension $\\leq 1$ and\nwell-founded strict divisibility.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 18:03:42 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 20:20:53 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Cano", "Guillaume", ""], ["Cohen", "Cyril", ""], ["D\u00e9n\u00e8s", "Maxime", ""], ["M\u00f6rtberg", "Anders", ""], ["Siles", "Vincent", ""]]}, {"id": "1601.07699", "submitter": "Mario Carneiro", "authors": "Mario Carneiro", "title": "Models for Metamath", "comments": "15 pages, 0 figures; submitted to CICM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although some work has been done on the metamathematics of Metamath, there\nhas not been a clear definition of a model for a Metamath formal system. We\ndefine the collection of models of an arbitrary Metamath formal system, both\nfor tree-based and string-based representations. This definition is\ndemonstrated with examples for propositional calculus, $\\textsf{ZFC}$ set\ntheory with classes, and Hofstadter's MIU system, with applications for proving\nthat statements are not provable, showing consistency of the main Metamath\ndatabase (assuming $\\textsf{ZFC}$ has a model), developing new independence\nproofs, and proving a form of G\\\"odel's completeness theorem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 09:26:52 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2016 18:04:31 GMT"}, {"version": "v3", "created": "Wed, 30 Mar 2016 14:33:43 GMT"}, {"version": "v4", "created": "Sat, 7 May 2016 03:40:37 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Carneiro", "Mario", ""]]}, {"id": "1601.07724", "submitter": "J\\\"urgen Koslowski", "authors": "Jean-Philippe Bernardy and Patrik Jansson", "title": "Certified Context-Free Parsing: A formalisation of Valiant's Algorithm\n  in Agda", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 2 (June 14,\n  2016) lmcs:1638", "doi": "10.2168/LMCS-12(2:6)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valiant (1975) has developed an algorithm for recognition of context free\nlanguages. As of today, it remains the algorithm with the best asymptotic\ncomplexity for this purpose. In this paper, we present an algebraic\nspecification, implementation, and proof of correctness of a generalisation of\nValiant's algorithm. The generalisation can be used for recognition, parsing or\ngeneric calculation of the transitive closure of upper triangular matrices. The\nproof is certified by the Agda proof assistant. The certification is\nrepresentative of state-of-the-art methods for specification and proofs in\nproof assistants based on type-theory. As such, this paper can be read as a\ntutorial for the Agda system.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 11:07:18 GMT"}, {"version": "v2", "created": "Sun, 12 Jun 2016 09:04:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bernardy", "Jean-Philippe", ""], ["Jansson", "Patrik", ""]]}]