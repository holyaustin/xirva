[{"id": "1405.0033", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Matthijs V\\'ak\\'ar", "title": "Syntax and Semantics of Linear Dependent Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A type theory is presented that combines (intuitionistic) linear types with\ntype dependency, thus properly generalising both intuitionistic dependent type\ntheory and full linear logic. A syntax and complete categorical semantics are\ndeveloped, the latter in terms of (strict) indexed symmetric monoidal\ncategories with comprehension. Various optional type formers are treated in a\nmodular way. In particular, we will see that the historically much-debated\nmultiplicative quantifiers and identity types arise naturally from categorical\nconsiderations. These new multiplicative connectives are further characterised\nby several identities relating them to the usual connectives from dependent\ntype theory and linear logic. Finally, one important class of models, given by\nfamilies with values in some symmetric monoidal category, is investigated in\ndetail.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 20:58:03 GMT"}, {"version": "v2", "created": "Thu, 21 Aug 2014 22:25:08 GMT"}, {"version": "v3", "created": "Tue, 7 Oct 2014 20:48:27 GMT"}, {"version": "v4", "created": "Fri, 16 Jan 2015 19:28:48 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "1405.0091", "submitter": "Hajime Ishihara", "authors": "Hajime Ishihara (Japan Advanced Institute of Science and Technology)", "title": "Classical propositional logic and decidability of variables in\n  intuitionistic propositional logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August 7,\n  2014) lmcs:1173", "doi": "10.2168/LMCS-10(3:1)2014", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the answer to the question: what set of excluded middles for\npropositional variables in a formula suffices to prove the formula in\nintuitionistic propositional logic whenever it is provable in classical\npropositional logic.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 04:32:05 GMT"}, {"version": "v2", "created": "Wed, 6 Aug 2014 12:44:39 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ishihara", "Hajime", "", "Japan Advanced Institute of Science and Technology"]]}, {"id": "1405.0293", "submitter": "Cl\\'audia Nalon", "authors": "Cl\\'audia Nalon, Jo\\~ao Marcos and Clare Dixon", "title": "Clausal Resolution for Modal Logics of Confluence", "comments": "15 pages, 1 figure. Preprint of the paper accepted to IJCAR 2014", "journal-ref": null, "doi": "10.1007/978-3-319-08587-6_24", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a clausal resolution-based method for normal multimodal logics of\nconfluence, whose Kripke semantics are based on frames characterised by\nappropriate instances of the Church-Rosser property. Here we restrict attention\nto eight families of such logics. We show how the inference rules related to\nthe normal logics of confluence can be systematically obtained from the\nparametrised axioms that characterise such systems. We discuss soundness,\ncompleteness, and termination of the method. In particular, completeness can be\nmodularly proved by showing that the conclusions of each newly added inference\nrule ensures that the corresponding conditions on frames hold. Some examples\nare given in order to illustrate the use of the method.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 20:03:39 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Nalon", "Cl\u00e1udia", ""], ["Marcos", "Jo\u00e3o", ""], ["Dixon", "Clare", ""]]}, {"id": "1405.0386", "submitter": "Michael Huth", "authors": "Michael Huth, Jim Huan-Pu Kuo, Nir Piterman", "title": "Fatal Attractors in Parity Games: Building Blocks for Partial Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attractors in parity games are a technical device for solving \"alternating\"\nreachability of given node sets. A well known solver of parity games -\nZielonka's algorithm - uses such attractor computations recursively. We here\npropose new forms of attractors that are monotone in that they are aware of\nspecific static patterns of colors encountered in reaching a given node set in\nalternating fashion. Then we demonstrate how these new forms of attractors can\nbe embedded within greatest fixed-point computations to design solvers of\nparity games that run in polynomial time but are partial in that they may not\ndecide the winning status of all nodes in the input game.\n  Experimental results show that our partial solvers completely solve\nbenchmarks that were constructed to challenge existing full solvers. Our\npartial solvers also have encouraging run times in practice. For one partial\nsolver we prove that its run-time is at most cubic in the number of nodes in\nthe parity game, that its output game is independent of the order in which\nmonotone attractors are computed, and that it solves all Buechi games and weak\ngames.\n  We then define and study a transformation that converts partial solvers into\nmore precise partial solvers, and we prove that this transformation is sound\nunder very reasonable conditions on the input partial solvers. Noting that one\nof our partial solvers meets these conditions, we apply its transformation on\n1.6 million randomly generated games and so experimentally validate that the\ntransformation can be very effective in increasing the precision of partial\nsolvers.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 11:45:18 GMT"}, {"version": "v2", "created": "Mon, 19 May 2014 16:59:12 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Huth", "Michael", ""], ["Kuo", "Jim Huan-Pu", ""], ["Piterman", "Nir", ""]]}, {"id": "1405.0424", "submitter": "Rodica Bozianu", "authors": "Rodica Bozianu, Catalin Dima, and Emmanuel Filiot", "title": "Safraless Synthesis for Epistemic Temporal Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the synthesis problem for specifications given in\nlinear temporal single-agent epistemic logic, KLTL (or $KL_1$), over\nsingle-agent systems having imperfect information of the environment state. Van\nder Meyden and Vardi have shown that this problem is 2Exptime complete.\nHowever, their procedure relies on complex automata constructions that are\nnotoriously resistant to efficient implementations as they use Safra-like\ndeterminization.\n  We propose a \"Safraless\" synthesis procedure for a large fragment of KLTL.\nThe construction transforms first the synthesis problem into the problem of\nchecking emptiness for universal co-B\\\"{u}chi tree automata using an\ninformation-set construction. Then we build a safety game that can be solved\nusing an antichain-based symbolic technique exploiting the structure of the\nunderlying automata. The technique is implemented and applied to a couple of\ncase studies.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 15:12:03 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Bozianu", "Rodica", ""], ["Dima", "Catalin", ""], ["Filiot", "Emmanuel", ""]]}, {"id": "1405.0541", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "How many times do we need and assumption ?", "comments": "15 pages, submitted to a workshop in Theoretical Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a class of formulas Fn, n in Nat, that need at\nleast 2^n assumptions to be proved in a normal proof in Natural Deduction for\npurely implicational minimal propositional logic. In purely implicational\nclassical propositional logic, with Peirce's rule, each Fn is proved with only\none assumption in Natural Deduction in a normal proof. Hence, the formulas Fn\nhave exponentially sized proofs in cut-free Sequent Calculus and Tableaux. In\nfact 2^n is the lower-bound for normal proofs in ND, cut-free Sequent proofs\nand Tableaux. We discuss the consequences of the existence of this class of\nformulas for designing automatic proof-procedures based on these deductive\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 00:28:58 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "1405.0559", "submitter": "Prof. Dr. Vladimir Rybakov", "authors": "Vladimir Rybakov", "title": "A Note on Parameterised Knowledge Operations in Temporal Logic", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider modeling the conception of knowledge in terms of temporal logic.\nThe study of knowledge logical operations is originated around 1962 by\nrepresentation of knowledge and belief using modalities. Nowadays, it is very\ngood established area. However, we would like to look to it from a bit another\npoint of view, our paper models knowledge in terms of linear temporal logic\nwith {\\em past}. We consider various versions of logical knowledge operations\nwhich may be defined in this framework. Technically, semantics, language and\ntemporal knowledge logics based on our approach are constructed. Deciding\nalgorithms are suggested, unification in terms of this approach is commented.\nThis paper does not offer strong new technical outputs, instead we suggest new\napproach to conception of knowledge (in terms of time).\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 07:36:59 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Rybakov", "Vladimir", ""]]}, {"id": "1405.0805", "submitter": "Hannes Strass", "authors": "Hannes Strass", "title": "On the Relative Expressiveness of Argumentation Frameworks, Normal Logic\n  Programs and Abstract Dialectical Frameworks", "comments": "Proceedings of the 15th International Workshop on Non-Monotonic\n  Reasoning (NMR 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the expressiveness of the two-valued semantics of abstract\nargumentation frameworks, normal logic programs and abstract dialectical\nframeworks. By expressiveness we mean the ability to encode a desired set of\ntwo-valued interpretations over a given propositional signature using only\natoms from that signature. While the computational complexity of the two-valued\nmodel existence problem for all these languages is (almost) the same, we show\nthat the languages form a neat hierarchy with respect to their expressiveness.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 07:39:50 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Strass", "Hannes", ""]]}, {"id": "1405.0809", "submitter": "Hannes Strass", "authors": "Jianmin Ji and Hannes Strass", "title": "Implementing Default and Autoepistemic Logics via the Logic of GK", "comments": "Proceedings of the 15th International Workshop on Non-Monotonic\n  Reasoning (NMR 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logic of knowledge and justified assumptions, also known as logic of\ngrounded knowledge (GK), was proposed by Lin and Shoham as a general logic for\nnonmonotonic reasoning. To date, it has been used to embed in it default logic\n(propositional case), autoepistemic logic, Turner's logic of universal\ncausation, and general logic programming under stable model semantics. Besides\nshowing the generality of GK as a logic for nonmonotonic reasoning, these\nembeddings shed light on the relationships among these other logics. In this\npaper, for the first time, we show how the logic of GK can be embedded into\ndisjunctive logic programming in a polynomial but non-modular translation with\nnew variables. The result can then be used to compute the extension/expansion\nsemantics of default logic, autoepistemic logic and Turner's logic of universal\ncausation by disjunctive ASP solvers such as claspD(-2), DLV, GNT and cmodels.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 07:45:30 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Ji", "Jianmin", ""], ["Strass", "Hannes", ""]]}, {"id": "1405.0835", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Martin Chmelik and Przemyslaw Daca", "title": "CEGAR for Qualitative Analysis of Probabilistic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov decision processes (MDPs) which are a standard model for\nprobabilistic systems. We focus on qualitative properties for MDPs that can\nexpress that desired behaviors of the system arise almost-surely (with\nprobability 1) or with positive probability. We introduce a new simulation\nrelation to capture the refinement relation of MDPs with respect to qualitative\nproperties, and present discrete graph theoretic algorithms with quadratic\ncomplexity to compute the simulation relation. We present an automated\ntechnique for assume-guarantee style reasoning for compositional analysis of\nMDPs with qualitative properties by giving a counter-example guided\nabstraction-refinement approach to compute our new simulation relation. We have\nimplemented our algorithms and show that the compositional analysis leads to\nsignificant improvements.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 09:36:22 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Chmelik", "Martin", ""], ["Daca", "Przemyslaw", ""]]}, {"id": "1405.0854", "submitter": "Christoph Rauch", "authors": "Sergey Goncharov, Lutz Schr\\\"oder, Christoph Rauch, and Julian Jakob", "title": "Unguarded Recursion on Coinductive Resumptions", "comments": "47 pages, extended version of\n  http://www.sciencedirect.com/science/article/pii/S1571066115000791", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (August\n  27, 2018) lmcs:4784", "doi": "10.23638/LMCS-14(3:10)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a model of side-effecting processes obtained by starting from a\nmonad modelling base effects and adjoining free operations using a cofree\ncoalgebra construction; one thus arrives at what one may think of as types of\nnon-wellfounded side-effecting trees, generalizing the infinite resumption\nmonad. Correspondingly, the arising monad transformer has been termed the\ncoinductive generalized resumption transformer. Monads of this kind have\nreceived some attention in the recent literature; in particular, it has been\nshown that they admit guarded iteration. Here, we show that they also admit\nunguarded iteration, i.e. form complete Elgot monads, provided that the\nunderlying base effect supports unguarded iteration. Moreover, we provide a\nuniversal characterization of the coinductive resumption monad transformer in\nterms of coproducts of complete Elgot monads.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 11:02:20 GMT"}, {"version": "v2", "created": "Wed, 21 Jan 2015 15:34:38 GMT"}, {"version": "v3", "created": "Fri, 18 Mar 2016 16:57:22 GMT"}, {"version": "v4", "created": "Fri, 27 Oct 2017 12:29:08 GMT"}, {"version": "v5", "created": "Fri, 10 Aug 2018 15:18:44 GMT"}, {"version": "v6", "created": "Thu, 23 Aug 2018 15:19:50 GMT"}, {"version": "v7", "created": "Fri, 24 Aug 2018 10:44:57 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Goncharov", "Sergey", ""], ["Schr\u00f6der", "Lutz", ""], ["Rauch", "Christoph", ""], ["Jakob", "Julian", ""]]}, {"id": "1405.1112", "submitter": "EPTCS", "authors": "\\'Etienne Andr\\'e (Universit\\'e Paris 13, France), Mohamed Mahdi\n  Benmoussa (Universit\\'e Paris 13, France), Christine Choppy (Universit\\'e\n  Paris 13, France)", "title": "Translating UML State Machines to Coloured Petri Nets Using Acceleo: A\n  Report", "comments": "In Proceedings ESSS 2014, arXiv:1405.0554", "journal-ref": "EPTCS 150, 2014, pp. 1-7", "doi": "10.4204/EPTCS.150.1", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UML state machines are widely used to specify dynamic systems behaviours.\nHowever its semantics is described informally, thus preventing the application\nof model checking techniques that could guarantee the system safety. In a\nformer work, we proposed a formalisation of non-concurrent UML state machines\nusing coloured Petri nets, so as to allow for formal verification. In this\npaper, we report our experience to implement this translation in an automated\nmanner using the model-to-text transformation tool Acceleo. Whereas Acceleo\nprovides interesting features that facilitated our translation process, it also\nsuffers from limitations uneasy to overcome.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 00:53:22 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", "", "Universit\u00e9 Paris 13, France"], ["Benmoussa", "Mohamed Mahdi", "", "Universit\u00e9 Paris 13, France"], ["Choppy", "Christine", "", "Universit\u00e9\n  Paris 13, France"]]}, {"id": "1405.1114", "submitter": "EPTCS", "authors": "Cornelius Diekmann (Technische Universit\\\"at M\\\"unchen), Lars Hupel\n  (Technische Universit\\\"at M\\\"unchen), Georg Carle (Technische Universit\\\"at\n  M\\\"unchen)", "title": "Directed Security Policies: A Stateful Network Implementation", "comments": "In Proceedings ESSS 2014, arXiv:1405.0554", "journal-ref": "EPTCS 150, 2014, pp. 20-34", "doi": "10.4204/EPTCS.150.3", "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large systems are commonly internetworked. A security policy describes the\ncommunication relationship between the networked entities. The security policy\ndefines rules, for example that A can connect to B, which results in a directed\ngraph. However, this policy is often implemented in the network, for example by\nfirewalls, such that A can establish a connection to B and all packets\nbelonging to established connections are allowed. This stateful implementation\nis usually required for the network's functionality, but it introduces the\nbackflow from B to A, which might contradict the security policy. We derive\ncompliance criteria for a policy and its stateful implementation. In\nparticular, we provide a criterion to verify the lack of side effects in linear\ntime. Algorithms to automatically construct a stateful implementation of\nsecurity policy rules are presented, which narrows the gap between\nformalization and real-world implementation. The solution scales to large\nnetworks, which is confirmed by a large real-world case study. Its correctness\nis guaranteed by the Isabelle/HOL theorem prover.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 00:53:42 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Diekmann", "Cornelius", "", "Technische Universit\u00e4t M\u00fcnchen"], ["Hupel", "Lars", "", "Technische Universit\u00e4t M\u00fcnchen"], ["Carle", "Georg", "", "Technische Universit\u00e4t\n  M\u00fcnchen"]]}, {"id": "1405.1192", "submitter": "Claudia Schon", "authors": "Ulrich Furbach and Claudia Schon", "title": "Semantically Guided Evolution of $\\mathcal{SHI}$ ABoxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for the evolution of SHI ABoxes which is based\non a compilation technique of the knowledge base. For this the ABox is regarded\nas an interpretation of the TBox which is close to a model. It is shown, that\nthe ABox can be used for a semantically guided transformation resulting in an\nequisatisfiable knowledge base. We use the result of this transformation to\nefficiently delete assertions from the ABox. Furthermore, insertion of\nassertions as well as repair of inconsistent ABoxes is addressed. For the\ncomputation of the necessary actions for deletion, insertion and repair, the\nE-KRHyper theorem prover is used.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 08:44:37 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Furbach", "Ulrich", ""], ["Schon", "Claudia", ""]]}, {"id": "1405.1229", "submitter": "Shahab Tasharrofi", "authors": "Shahab Tasharrofi and Eugenia Ternovska", "title": "Three Semantics for Modular Systems", "comments": "Current paper appears in the Proceedings of the 15th International\n  Workshop on Non-Monotonic Reasoning (NMR 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we further develop the framework of Modular Systems that lays\nmodel-theoretic foundations for combining different declarative languages,\nagents and solvers. We introduce a multi-language logic of modular systems. We\ndefine two novel semantics, a structural operational semantics, and an\ninference-based semantics. We prove the new semantics are equivalent to the\noriginal model-theoretic semantics and describe future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 11:19:32 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Tasharrofi", "Shahab", ""], ["Ternovska", "Eugenia", ""]]}, {"id": "1405.1295", "submitter": "Everardo Barcenas", "authors": "Everardo B\\'arcenas (Universidad Polit\\'ecnica de Puebla), Jes\\'us\n  Lavalle (Benem\\'erita Universidad Aut\\'onoma de Puebla)", "title": "Global Numerical Constraints on Trees", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 2 (June 16,\n  2014) lmcs:985", "doi": "10.2168/LMCS-10(2:10)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logical foundation to reason on tree structures with\nconstraints on the number of node occurrences. Related formalisms are limited\nto express occurrence constraints on particular tree regions, as for instance\nthe children of a given node. By contrast, the logic introduced in the present\nwork can concisely express numerical bounds on any region, descendants or\nancestors for instance. We prove that the logic is decidable in single\nexponential time even if the numerical constraints are in binary form. We also\nillustrate the usage of the logic in the description of numerical constraints\non multi-directional path queries on XML documents. Furthermore, numerical\nrestrictions on regular languages (XML schemas) can also be concisely described\nby the logic. This implies a characterization of decidable counting extensions\nof XPath queries and XML schemas. Moreover, as the logic is closed under\nnegation, it can thus be used as an optimal reasoning framework for testing\nemptiness, containment and equivalence.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 15:02:07 GMT"}, {"version": "v2", "created": "Fri, 13 Jun 2014 10:21:09 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["B\u00e1rcenas", "Everardo", "", "Universidad Polit\u00e9cnica de Puebla"], ["Lavalle", "Jes\u00fas", "", "Benem\u00e9rita Universidad Aut\u00f3noma de Puebla"]]}, {"id": "1405.1463", "submitter": "EPTCS", "authors": "Chris Heunen (University of Oxford), Jamie Vicary (National University\n  of Singapore, University of Oxford), Linde Wester (University of Oxford)", "title": "Mixed quantum states in higher categories", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 304-315", "doi": "10.4204/EPTCS.172.22", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two ways to describe the interaction between classical and quantum\ninformation categorically: one based on completely positive maps between\nFrobenius algebras, the other using symmetric monoidal 2-categories. This paper\nmakes a first step towards combining the two. The integrated approach allows a\nunified description of quantum teleportation and classical encryption in a\nsingle 2-category, as well as a universal security proof applicable\nsimultaneously to both scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 22:03:12 GMT"}, {"version": "v2", "created": "Tue, 30 Dec 2014 03:42:17 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Heunen", "Chris", "", "University of Oxford"], ["Vicary", "Jamie", "", "National University\n  of Singapore, University of Oxford"], ["Wester", "Linde", "", "University of Oxford"]]}, {"id": "1405.1523", "submitter": "Bart Bogaerts", "authors": "Bart Bogaerts, Joachim Jansen, Maurice Bruynooghe, Broes De Cat, Joost\n  Vennekens and Marc Denecker", "title": "Simulating dynamic systems using Linear Time Calculus theories", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 477-492", "doi": "10.1017/S1471068414000155", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear in Theory and Practice of Logic Programming (TPLP).\n  Dynamic systems play a central role in fields such as planning, verification,\nand databases. Fragmented throughout these fields, we find a multitude of\nlanguages to formally specify dynamic systems and a multitude of systems to\nreason on such specifications. Often, such systems are bound to one specific\nlanguage and one specific inference task. It is troublesome that performing\nseveral inference tasks on the same knowledge requires translations of your\nspecification to other languages. In this paper we study whether it is possible\nto perform a broad set of well-studied inference tasks on one specification.\nMore concretely, we extend IDP3 with several inferences from fields concerned\nwith dynamic specifications.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 07:38:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bogaerts", "Bart", ""], ["Jansen", "Joachim", ""], ["Bruynooghe", "Maurice", ""], ["De Cat", "Broes", ""], ["Vennekens", "Joost", ""], ["Denecker", "Marc", ""]]}, {"id": "1405.1546", "submitter": "Daniele Gorla", "authors": "Thomas Given-Wilson (NICTA (Sydney, Australia)), Daniele Gorla (Dip.\n  Informatica - Univ. di Roma), Barry Jay (Centre for Quantum Computation and\n  Intelligent Systems and School of Software)", "title": "A Concurrent Pattern Calculus", "comments": "Logical Methods in Computer Science (2014)", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August\n  23, 2014) lmcs:774", "doi": "10.2168/LMCS-10(3:10)2014", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent pattern calculus (CPC) drives interaction between processes by\ncomparing data structures, just as sequential pattern calculus drives\ncomputation. By generalising from pattern matching to pattern unification,\ninteraction becomes symmetrical, with information flowing in both directions.\nCPC provides a natural language to express trade where information exchange is\npivotal to interaction. The unification allows some patterns to be more\ndiscriminating than others; hence, the behavioural theory must take this aspect\ninto account, so that bisimulation becomes subject to compatibility of\npatterns. Many popular process calculi can be encoded in CPC; this allows for a\ngain in expressiveness, formalised through encodings.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 09:35:48 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2014 13:56:30 GMT"}, {"version": "v3", "created": "Wed, 20 Aug 2014 23:26:48 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Given-Wilson", "Thomas", "", "NICTA"], ["Gorla", "Daniele", "", "Dip.\n  Informatica - Univ. di Roma"], ["Jay", "Barry", "", "Centre for Quantum Computation and\n  Intelligent Systems and School of Software"]]}, {"id": "1405.1565", "submitter": "Leroy Chew", "authors": "Olaf Beyersdorff and Leroy Chew", "title": "Tableau vs. Sequent Calculi for Minimal Entailment", "comments": "9 pages, 3 figures, this paper appears in the Proceedings of the 15th\n  International Workshop on Non-Monotonic Reasoning (NMR 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we compare two proof systems for minimal entailment: a tableau\nsystem OTAB and a sequent calculus MLK, both developed by Olivetti (1992). Our\nmain result shows that OTAB-proofs can be efficiently translated into\nMLK-proofs, i.e; MLK p-simulates OTAB. The simulation is technically very\ninvolved and answers an open question posed by Olivetti (1992) on the relation\nbetween the two calculi. We also show that the two systems are exponentially\nseparated, i.e; there are formulas which have polynomial size MLK-proofs, but\nrequire exponential-size OTAB- proofs.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 10:37:12 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Beyersdorff", "Olaf", ""], ["Chew", "Leroy", ""]]}, {"id": "1405.1584", "submitter": "Pieter Van Hertum", "authors": "Marcos Cramer, Pieter Van Hertum, Diego Agustin Ambrossio, Marc\n  Denecker", "title": "Modelling Delegation and Revocation Schemes in IDP", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ownership-based access control frameworks with the possibility of\ndelegating permissions and administrative rights, chains of delegated accesses\nwill form. There are different ways to treat these delegation chains when\nrevoking rights, which give rise to different revocation schemes. In this\npaper, we show how IDP - a knowledge base system that integrates technology\nfrom ASP, SAT and CP - can be used to efficiently implement executable\nrevocation schemes for an ownership-based access control system based on a\ndeclarative specification of their properties.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 12:27:59 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Cramer", "Marcos", ""], ["Van Hertum", "Pieter", ""], ["Ambrossio", "Diego Agustin", ""], ["Denecker", "Marc", ""]]}, {"id": "1405.1590", "submitter": "Walid Gomaa", "authors": "Walid Gomaa", "title": "Computability and Complexity over the Product Topology of Real Numbers", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kawamura and Cook have developed a framework for studying the computability\nand complexity theoretic problems over \"large\" topological spaces. This\nframework has been applied to study the complexity of the differential operator\nand the complexity of functionals over the space of continuous functions on the\nunit interval $C[0,1]$. In this paper we apply the ideas of Kawamura and Cook\nto the product space of the real numbers endowed with the product topology. We\nshow that no computable norm can be defined over such topology. We investigate\ncomputability and complexity of total functions over the product space in two\ncases: (1) when the computing machine submits a uniformally bounded number of\nqueries to the oracle and (2) when the number of queries submitted by the\nmachine is not uniformally bounded. In the first case we show that the function\nover the product space can be reduced to a function over a finite-dimensional\nspace. However, in general there exists functions whose computing machines must\nsubmit a non-uniform number of queries to the oracle indicating that computing\nover the product topology can not in general be reduced to computing over\nfinite-dimensional spaces.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 12:40:41 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Gomaa", "Walid", ""]]}, {"id": "1405.1703", "submitter": "EPTCS", "authors": "Ling Fang (National Institute of Advanced Industrial Science and\n  Technology, Japan), Yoriyuki Yamagata (National Institute of Advanced\n  Industrial Science and Technology, Japan), Yutaka Oiwa (National Institute of\n  Advanced Industrial Science and Technology, Japan)", "title": "Evaluation of A Resilience Embedded System Using Probabilistic\n  Model-Checking", "comments": "In Proceedings ESSS 2014, arXiv:1405.0554", "journal-ref": "EPTCS 150, 2014, pp. 35-49", "doi": "10.4204/EPTCS.150.4", "report-no": null, "categories": "cs.SE cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If a Micro Processor Unit (MPU) receives an external electric signal as\nnoise, the system function will freeze or malfunction easily. A new resilience\nstrategy is implemented in order to reset the MPU automatically and stop the\nMPU from freezing or malfunctioning. The technique is useful for embedded\nsystems which work in non-human environments. However, evaluating resilience\nstrategies is difficult because their effectiveness depends on numerous,\ncomplex, interacting factors.\n  In this paper, we use probabilistic model checking to evaluate the embedded\nsystems installed with the above mentioned new resilience strategy. Qualitative\nevaluations are implemented with 6 PCTL formulas, and quantitative evaluations\nuse two kinds of evaluation. One is system failure reduction, and the other is\nADT (Average Down Time), the industry standard. Our work demonstrates the\nbenefits brought by the resilience strategy. Experimental results indicate that\nour evaluation is cost-effective and reliable.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 00:53:56 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Fang", "Ling", "", "National Institute of Advanced Industrial Science and\n  Technology, Japan"], ["Yamagata", "Yoriyuki", "", "National Institute of Advanced\n  Industrial Science and Technology, Japan"], ["Oiwa", "Yutaka", "", "National Institute of\n  Advanced Industrial Science and Technology, Japan"]]}, {"id": "1405.1715", "submitter": "EPTCS", "authors": "Antti Kuusisto", "title": "Some Turing-Complete Extensions of First-Order Logic", "comments": "In Proceedings GandALF 2014, arXiv:1408.5560", "journal-ref": "EPTCS 161, 2014, pp. 4-17", "doi": "10.4204/EPTCS.161.4", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a natural Turing-complete extension of first-order logic FO. The\nextension adds two novel features to FO. The first one of these is the capacity\nto add new points to models and new tuples to relations. The second one is the\npossibility of recursive looping when a formula is evaluated using a semantic\ngame. We first define a game-theoretic semantics for the logic and then prove\nthat the expressive power of the logic corresponds in a canonical way to the\nrecognition capacity of Turing machines. Finally, we show how to incorporate\ngeneralized quantifiers into the logic and argue for a highly natural\nconnection between oracles and generalized quantifiers.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 19:37:07 GMT"}, {"version": "v2", "created": "Tue, 3 Jun 2014 17:42:33 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 15:45:14 GMT"}, {"version": "v4", "created": "Thu, 3 Jul 2014 14:53:00 GMT"}, {"version": "v5", "created": "Tue, 26 Aug 2014 01:55:11 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Kuusisto", "Antti", ""]]}, {"id": "1405.1828", "submitter": "Meghdad Ghari", "authors": "Meghdad Ghari", "title": "Tableau Proof Systems for Justification Logics", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present tableau proof systems for various justification\nlogics. We show that the tableau systems are sound and complete with respect to\nMkrtychev models. In order to prove the completeness of the tableaux, we give a\nsyntactic proof of cut elimination. We also show the subformula property for\nour tableaux.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 07:45:46 GMT"}, {"version": "v2", "created": "Sun, 1 Jun 2014 11:59:17 GMT"}, {"version": "v3", "created": "Tue, 28 Oct 2014 08:03:37 GMT"}, {"version": "v4", "created": "Sat, 13 Feb 2016 13:53:36 GMT"}, {"version": "v5", "created": "Mon, 11 Apr 2016 08:07:35 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Ghari", "Meghdad", ""]]}, {"id": "1405.1833", "submitter": "Bart Bogaerts", "authors": "Bart Bogaerts, Joost Vennekens, Marc Denecker, Jan Van den Bussche", "title": "FO(C): A Knowledge Representation Language of Causality", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cause-effect relations are an important part of human knowledge. In real\nlife, humans often reason about complex causes linked to complex effects. By\ncomparison, existing formalisms for representing knowledge about causal\nrelations are quite limited in the kind of specifications of causes and effects\nthey allow. In this paper, we present the new language C-Log, which offers a\nsignificantly more expressive representation of effects, including such\nfeatures as the creation of new objects. We show how C-Log integrates with\nfirst-order logic, resulting in the language FO(C). We also compare FO(C) with\nseveral related languages and paradigms, including inductive definitions,\ndisjunctive logic programming, business rules and extensions of Datalog.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 08:25:52 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 08:20:22 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Bogaerts", "Bart", ""], ["Vennekens", "Joost", ""], ["Denecker", "Marc", ""], ["Bussche", "Jan Van den", ""]]}, {"id": "1405.1841", "submitter": "Javier Esparza", "authors": "Javier Esparza", "title": "Keeping a Crowd Safe: On the Complexity of Parameterized Verification\n  (Corrected version)", "comments": "A former version of this paper was published in the Proceedings of\n  STACS 2014. This version corrects two mistakes in Sections 3.3. and 3.4, and\n  some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We survey some results on the automatic verification of parameterized\nprograms without identities. These are systems composed of arbitrarily many\ncomponents, all of them running exactly the same finite-state program. We\ndiscuss the complexity of deciding that no component reaches an unsafe state.\nThe note is addressed at theoretical computer scientists in general.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 08:58:33 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Esparza", "Javier", ""]]}, {"id": "1405.2234", "submitter": "Christoph Dittmann", "authors": "Mikolaj Bojanczyk, Christoph Dittmann, Stephan Kreutzer", "title": "Decomposition Theorems and Model-Checking for the Modal $\\mu$-Calculus", "comments": null, "journal-ref": null, "doi": "10.1145/2603088.2603144", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a general decomposition theorem for the modal $\\mu$-calculus $L_\\mu$\nin the spirit of Feferman and Vaught's theorem for disjoint unions. In\nparticular, we show that if a structure (i.e., transition system) is composed\nof two substructures $M_1$ and $M_2$ plus edges from $M_1$ to $M_2$, then the\nformulas true at a node in $M$ only depend on the formulas true in the\nrespective substructures in a sense made precise below. As a consequence we\nshow that the model-checking problem for $L_\\mu$ is fixed-parameter tractable\n(fpt) on classes of structures of bounded Kelly-width or bounded DAG-width. As\nfar as we are aware, these are the first fpt results for $L_\\mu$ which do not\nfollow from embedding into monadic second-order logic.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 14:03:27 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Bojanczyk", "Mikolaj", ""], ["Dittmann", "Christoph", ""], ["Kreutzer", "Stephan", ""]]}, {"id": "1405.2329", "submitter": "Carlos Olarte", "authors": "Elaine Pimentel, Carlos Olarte, Vivek Nigam", "title": "A Proof Theoretic Study of Soft Concurrent Constraint Programming", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 649-663", "doi": "10.1017/S147106841400026X", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent Constraint Programming (CCP) is a simple and powerful model for\nconcurrency where agents interact by telling and asking constraints. Since\ntheir inception, CCP-languages have been designed for having a strong\nconnection to logic. In fact, the underlying constraint system can be built\nfrom a suitable fragment of intuitionistic (linear) logic --ILL-- and processes\ncan be interpreted as formulas in ILL. Constraints as ILL formulas fail to\nrepresent accurately situations where \"preferences\" (called soft constraints)\nsuch as probabilities, uncertainty or fuzziness are present. In order to\ncircumvent this problem, c-semirings have been proposed as algebraic structures\nfor defining constraint systems where agents are allowed to tell and ask soft\nconstraints. Nevertheless, in this case, the tight connection to logic and\nproof theory is lost. In this work, we give a proof theoretical interpretation\nto soft constraints: they can be defined as formulas in a suitable fragment of\nILL with subexponentials (SELL) where subexponentials, ordered in a c-semiring\nstructure, are interpreted as preferences. We hence achieve two goals: (1)\nobtain a CCP language where agents can tell and ask soft constraints and (2)\nprove that the language in (1) has a strong connection with logic. Hence we\nkeep a declarative reading of processes as formulas while providing a logical\nframework for soft-CCP based systems. An interesting side effect of (1) is that\none is also able to handle probabilities (and other modalities) in SELL, by\nrestricting the use of the promotion rule for non-idempotent c-semirings.This\nfiner way of controlling subexponentials allows for considering more\ninteresting spaces and restrictions, and it opens the possibility of specifying\nmore challenging computational systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 19:51:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Pimentel", "Elaine", ""], ["Olarte", "Carlos", ""], ["Nigam", "Vivek", ""]]}, {"id": "1405.2409", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Chung-Hao Huang, Harald Ruess, Stefan Stattelmann", "title": "G4LTL-ST: Automatic Generation of PLC Programs", "comments": "This is the full version of the CAV'14 paper. Research concepts\n  developed this paper are mainly from the technical report \"Numerical LTL\n  synthesis for cyber-physical systems\", coauthored by Chih-Hong Cheng (ABB\n  Research) and Edward A. Lee (UC Berkeley)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  G4LTL-ST automatically synthesizes control code for industrial Programmable\nLogic Controls (PLC) from timed behavioral specifications of input-output\nsignals. These specifications are expressed in a linear temporal logic (LTL)\nextended with non-linear arithmetic constraints and timing constraints on\nsignals. G4LTL-ST generates code in IEC 61131-3-compatible Structured Text,\nwhich is compiled into executable code for a large number of industrial\nfield-level devices. The synthesis algorithm of G4LTL-ST implements\npseudo-Boolean abstraction of data constraints and the compilation of timing\nconstraints into LTL, together with a counterstrategy-guided abstraction\nrefinement synthesis loop. Since temporal logic specifications are notoriously\ndifficult to use in practice, G4LTL-ST supports engineers in specifying\nrealizable control problems by suggesting suitable restrictions on the behavior\nof the control environment from failed synthesis attempts.\n", "versions": [{"version": "v1", "created": "Sat, 10 May 2014 09:25:31 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 19:32:52 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Huang", "Chung-Hao", ""], ["Ruess", "Harald", ""], ["Stattelmann", "Stefan", ""]]}, {"id": "1405.2494", "submitter": "Miroslaw Truszczynski", "authors": "Luciano Caroprese, Irina Trubitsyna, Miroslaw Truszczynski and Ester\n  Zumpano", "title": "A Measure of Arbitrariness in Abductive Explanations", "comments": "25 pages (including appendix)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 665-679", "doi": "10.1017/S1471068414000271", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the framework of abductive logic programming extended with integrity\nconstraints. For this framework, we introduce a new measure of the simplicity\nof an explanation based on its degree of \\emph{arbitrariness}: the more\narbitrary the explanation, the less appealing it is, with explanations having\nno arbitrariness - they are called constrained - being the preferred ones. In\nthe paper, we study basic properties of constrained explanations. For the case\nwhen programs in abductive theories are stratified we establish results\nproviding a detailed picture of the complexity of the problem to decide whether\nconstrained explanations exist. (To appear in Theory and Practice of Logic\nProgramming (TPLP).)\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 02:46:00 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Caroprese", "Luciano", ""], ["Trubitsyna", "Irina", ""], ["Truszczynski", "Miroslaw", ""], ["Zumpano", "Ester", ""]]}, {"id": "1405.2559", "submitter": "Elena Nogina", "authors": "Elena Nogina", "title": "On Logic of Formal Provability and Explicit Proofs", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1933, G\\\"odel considered two modal approaches to describing provability.\nOne captured formal provability and resulted in the logic GL and Solovay's\nCompleteness Theorem. The other was based on the modal logic S4 and led to\nArtemov's Logic of Proofs LP. In this paper, we study introduced by the author\nlogic GLA, which is a fusion of GL and LP in the union of their languages. GLA\nis supplied with a Kripke-style semantics and the corresponding completeness\ntheorem. Soundness and completeness of GLA with respect to the arithmetical\nprovability semantics is established.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 18:11:19 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Nogina", "Elena", ""]]}, {"id": "1405.2642", "submitter": "Radhakrishnan Delhibabu", "authors": "Radhakrishnan Delhibabu", "title": "An Abductive Framework for Horn Knowledge Base Dynamics", "comments": "Applied Mathematics & Information Sciences, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The dynamics of belief and knowledge is one of the major components of any\nautonomous system that should be able to incorporate new pieces of information.\nWe introduced the Horn knowledge base dynamics to deal with two important\npoints: first, to handle belief states that need not be deductively closed; and\nthe second point is the ability to declare certain parts of the belief as\nimmutable. In this paper, we address another, radically new approach to this\nproblem. This approach is very close to the Hansson's dyadic representation of\nbelief. Here, we consider the immutable part as defining a new logical system.\nBy a logical system, we mean that it defines its own consequence relation and\nclosure operator. Based on this, we provide an abductive framework for Horn\nknowledge base dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 06:54:12 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 16:29:54 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Delhibabu", "Radhakrishnan", ""]]}, {"id": "1405.2705", "submitter": "Paolo Zuliani", "authors": "Paolo Zuliani", "title": "Statistical Model Checking for Biological Applications", "comments": null, "journal-ref": null, "doi": "10.1007/s10009-014-0343-0", "report-no": null, "categories": "cs.LO cs.SY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we survey recent work on the use of statistical model checking\ntechniques for biological applications. We begin with an overview of the basic\nmodelling techniques for biochemical reactions and their corresponding\nstochastic simulation algorithm - the Gillespie algorithm. We continue by\ngiving a brief description of the relation between stochastic models and\ncontinuous (ordinary differential equation) models. Next we present a\nliterature survey, divided in two general areas. In the first area we focus on\nworks addressing verification of biological models, while in the second area we\nfocus on papers tackling the parameter synthesis problem. We conclude with some\nopen problems and directions for further research.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 10:55:23 GMT"}, {"version": "v2", "created": "Fri, 13 Jun 2014 12:26:37 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Zuliani", "Paolo", ""]]}, {"id": "1405.2801", "submitter": "Aya Saad", "authors": "Aya Saad and Thom Fruehwirth and Carmen Gervet", "title": "The P-Box CDF-Intervals: Reliable Constraint Reasoning with Quantifiable\n  Information", "comments": "12 pages + references, accepted paper in the ICLP2014, 14 Postscript\n  figures, uses new_tlp.cls and acmtrans.bst", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new constraint domain for reasoning about data with\nuncertainty. It extends convex modeling with the notion of p-box to gain\nadditional quantifiable information on the data whereabouts. Unlike existing\napproaches, the p-box envelops an unknown probability instead of approximating\nits representation. The p-box bounds are uniform cumulative distribution\nfunctions (cdf) in order to employ linear computations in the probabilistic\ndomain. The reasoning by means of p-box cdf-intervals is an interval\ncomputation which is exerted on the real domain then it is projected onto the\ncdf domain. This operation conveys additional knowledge represented by the\nobtained probabilistic bounds. The empirical evaluation of our implementation\nshows that, with minimal overhead, the output solution set realizes a full\nenclosure of the data along with tighter bounds on its probabilistic\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 15:25:46 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 04:44:21 GMT"}, {"version": "v3", "created": "Tue, 24 Jun 2014 09:18:54 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Saad", "Aya", ""], ["Fruehwirth", "Thom", ""], ["Gervet", "Carmen", ""]]}, {"id": "1405.2852", "submitter": "Stefan Kiefer", "authors": "Taolue Chen and Stefan Kiefer", "title": "On the Total Variation Distance of Labelled Markov Chains", "comments": "This is a technical report for a LICS'14 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labelled Markov chains (LMCs) are widely used in probabilistic verification,\nspeech recognition, computational biology, and many other fields. Checking two\nLMCs for equivalence is a classical problem subject to extensive studies, while\nthe total variation distance provides a natural measure for the \"inequivalence\"\nof two LMCs: it is the maximum difference between probabilities that the LMCs\nassign to the same event.\n  In this paper we develop a theory of the total variation distance between two\nLMCs, with emphasis on the algorithmic aspects: (1) we provide a\npolynomial-time algorithm for determining whether two LMCs have distance 1,\ni.e., whether they can almost always be distinguished; (2) we provide an\nalgorithm for approximating the distance with arbitrary precision; and (3) we\nshow that the threshold problem, i.e., whether the distance exceeds a given\nthreshold, is NP-hard and hard for the square-root-sum problem. We also make a\nconnection between the total variation distance and Bernoulli convolutions.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 17:47:36 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Chen", "Taolue", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1405.2891", "submitter": "Robert Ganian", "authors": "Simone Bova, Robert Ganian, Stefan Szeider", "title": "Model Checking Existential Logic on Partially Ordered Sets", "comments": "accepted at CSL-LICS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of checking whether an existential sentence (that is, a\nfirst-order sentence in prefix form built using existential quantifiers and all\nBoolean connectives) is true in a finite partially ordered set (in short, a\nposet). A poset is a reflexive, antisymmetric, and transitive digraph. The\nproblem encompasses the fundamental embedding problem of finding an isomorphic\ncopy of a poset as an induced substructure of another poset.\n  Model checking existential logic is already NP-hard on a fixed poset; thus we\ninvestigate structural properties of posets yielding conditions for\nfixed-parameter tractability when the problem is parameterized by the sentence.\nWe identify width as a central structural property (the width of a poset is the\nmaximum size of a subset of pairwise incomparable elements); our main\nalgorithmic result is that model checking existential logic on classes of\nfinite posets of bounded width is fixed-parameter tractable. We observe a\nsimilar phenomenon in classical complexity, where we prove that the isomorphism\nproblem is polynomial-time tractable on classes of posets of bounded width;\nthis settles an open problem in order theory.\n  We surround our main algorithmic result with complexity results on less\nrestricted, natural neighboring classes of finite posets, establishing its\ntightness in this sense. We also relate our work with (and demonstrate its\nindependence of) fundamental fixed-parameter tractability results for model\nchecking on digraphs of bounded degree and bounded clique-width.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 12:19:26 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Bova", "Simone", ""], ["Ganian", "Robert", ""], ["Szeider", "Stefan", ""]]}, {"id": "1405.3073", "submitter": "Raphael kena Poss", "authors": "Raphael Poss", "title": "Categories from scratch", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of category from mathematics happens to be useful to computer\nprogrammers in many ways. Unfortunately, all \"good\" explanations of categories\nso far have been designed by mathematicians, or at least theoreticians with a\nstrong background in mathematics, and this makes categories especially\ninscrutable to external audiences. More specifically, the common explanatory\nroute to approach categories is usually: \"here is a formal specification of\nwhat a category is; then look at these known things from maths and theoretical\ncomputer science, and admire how they can be described using the notions of\ncategory theory.\" This approach is only successful if the audience can fully\nunderstand a conceptual object using only its formal specification. In\npractice, quite a few people only adopt conceptual objects by abstracting from\ntwo or more contexts where the concepts are applicable, instead. This is the\nroad taken below: reconstruct the abstractions from category theory using\nscratches of understanding from various fields of computer engineering.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 09:11:47 GMT"}, {"version": "v2", "created": "Wed, 14 May 2014 11:12:19 GMT"}, {"version": "v3", "created": "Mon, 21 Jul 2014 14:54:40 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Poss", "Raphael", ""]]}, {"id": "1405.3097", "submitter": "Boris Konev", "authors": "Boris Konev and Alexei Lisitsa", "title": "Computer-Aided Proof of Erdos Discrepancy Properties", "comments": "Revised and extended journal version of arXiv:1402.2184,\n  http://arxiv.org/abs/1402.2184", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1930s Paul Erdos conjectured that for any positive integer $C$ in any\ninfinite $\\pm 1$ sequence $(x_n)$ there exists a subsequence $x_d, x_{2d},\nx_{3d},\\dots, x_{kd}$, for some positive integers $k$ and $d$, such that $\\mid\n\\sum_{i=1}^k x_{i\\cdot d} \\mid >C$. The conjecture has been referred to as one\nof the major open problems in combinatorial number theory and discrepancy\ntheory. For the particular case of $C=1$ a human proof of the conjecture\nexists; for $C=2$ a bespoke computer program had generated sequences of length\n$1124$ of discrepancy $2$, but the status of the conjecture remained open even\nfor such a small bound. We show that by encoding the problem into Boolean\nsatisfiability and applying the state of the art SAT solvers, one can obtain a\ndiscrepancy $2$ sequence of length $1160$ and a proof of the Erd\\H{o}s\ndiscrepancy conjecture for $C=2$, claiming that no discrepancy 2 sequence of\nlength $1161$, or more, exists. In the similar way, we obtain a precise bound\nof $127\\,645$ on the maximal lengths of both multiplicative and completely\nmultiplicative sequences of discrepancy $3$. We also demonstrate that\nunrestricted discrepancy 3 sequences can be longer than $130\\,000$.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 10:46:07 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 16:01:51 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Konev", "Boris", ""], ["Lisitsa", "Alexei", ""]]}, {"id": "1405.3250", "submitter": "Eric Gribkoff", "authors": "Eric Gribkoff, Guy Van den Broeck, and Dan Suciu", "title": "Understanding the Complexity of Lifted Inference and Asymmetric Weighted\n  Model Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study lifted inference for the Weighted First-Order Model\nCounting problem (WFOMC), which counts the assignments that satisfy a given\nsentence in first-order logic (FOL); it has applications in Statistical\nRelational Learning (SRL) and Probabilistic Databases (PDB). We present several\nresults. First, we describe a lifted inference algorithm that generalizes prior\napproaches in SRL and PDB. Second, we provide a novel dichotomy result for a\nnon-trivial fragment of FO CNF sentences, showing that for each sentence the\nWFOMC problem is either in PTIME or #P-hard in the size of the input domain; we\nprove that, in the first case our algorithm solves the WFOMC problem in PTIME,\nand in the second case it fails. Third, we present several properties of the\nalgorithm. Finally, we discuss limitations of lifted inference for symmetric\nprobabilistic databases (where the weights of ground literals depend only on\nthe relation name, and not on the constants of the domain), and prove the\nimpossibility of a dichotomy result for the complexity of probabilistic\ninference for the entire language FOL.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 18:39:11 GMT"}, {"version": "v2", "created": "Tue, 29 Jul 2014 17:31:31 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gribkoff", "Eric", ""], ["Broeck", "Guy Van den", ""], ["Suciu", "Dan", ""]]}, {"id": "1405.3311", "submitter": "Ugo Dal Lago", "authors": "Beniamino Accattoli, Ugo Dal Lago", "title": "Beta Reduction is Invariant, Indeed (Long Version)", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot and van Emde Boas' weak invariance thesis states that reasonable\nmachines can simulate each other within a polynomially overhead in time. Is\n$\\lambda$-calculus a reasonable machine? Is there a way to measure the\ncomputational complexity of a $\\lambda$-term? This paper presents the first\ncomplete positive answer to this long-standing problem. Moreover, our answer is\ncompletely machine-independent and based over a standard notion in the theory\nof $\\lambda$-calculus: the length of a leftmost-outermost derivation to normal\nform is an invariant cost model. Such a theorem cannot be proved by directly\nrelating $\\lambda$-calculus with Turing machines or random access machines,\nbecause of the size explosion problem: there are terms that in a linear number\nof steps produce an exponentially long output. The first step towards the\nsolution is to shift to a notion of evaluation for which the length and the\nsize of the output are linearly related. This is done by adopting the linear\nsubstitution calculus (LSC), a calculus of explicit substitutions modelled\nafter linear logic and proof-nets and admitting a decomposition of\nleftmost-outermost derivations with the desired property. Thus, the LSC is\ninvariant with respect to, say, random access machines. The second step is to\nshow that LSC is invariant with respect to the $\\lambda$-calculus. The size\nexplosion problem seems to imply that this is not possible: having the same\nnotions of normal form, evaluation in the LSC is exponentially longer than in\nthe $\\lambda$-calculus. We solve such an impasse by introducing a new form of\nshared normal form and shared reduction, deemed useful. Useful evaluation\navoids those steps that only unshare the output without contributing to\n$\\beta$-redexes, i.e., the steps that cause the blow-up in size.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 21:23:58 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "1405.3391", "submitter": "Julien Narboux", "authors": "Sana Stojanovic, Julien Narboux (INRIA Nancy - Grand Est / LSIIT,\n  ICube), Marc Bezem, Predrag Janicic", "title": "A Vernacular for Coherent Logic", "comments": "CICM 2014 - Conferences on Intelligent Computer Mathematics (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple, yet expressive proof representation from which proofs\nfor different proof assistants can easily be generated. The representation uses\nonly a few inference rules and is based on a frag- ment of first-order logic\ncalled coherent logic. Coherent logic has been recognized by a number of\nresearchers as a suitable logic for many ev- eryday mathematical developments.\nThe proposed proof representation is accompanied by a corresponding XML format\nand by a suite of XSL transformations for generating formal proofs for\nIsabelle/Isar and Coq, as well as proofs expressed in a natural language form\n(formatted in LATEX or in HTML). Also, our automated theorem prover for\ncoherent logic exports proofs in the proposed XML format. All tools are\npublicly available, along with a set of sample theorems.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 07:48:29 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Stojanovic", "Sana", "", "INRIA Nancy - Grand Est / LSIIT,\n  ICube"], ["Narboux", "Julien", "", "INRIA Nancy - Grand Est / LSIIT,\n  ICube"], ["Bezem", "Marc", ""], ["Janicic", "Predrag", ""]]}, {"id": "1405.3426", "submitter": "Moa Johansson", "authors": "Moa Johansson and Dan Rosen and Nicholas Smallbone and Koen Claessen", "title": "Hipster: Integrating Theory Exploration in a Proof Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Hipster, a system integrating theory exploration with\nthe proof assistant Isabelle/HOL. Theory exploration is a technique for\nautomatically discovering new interesting lemmas in a given theory development.\nHipster can be used in two main modes. The first is exploratory mode, used for\nautomatically generating basic lemmas about a given set of datatypes and\nfunctions in a new theory development. The second is proof mode, used in a\nparticular proof attempt, trying to discover the missing lemmas which would\nallow the current goal to be proved. Hipster's proof mode complements and\nboosts existing proof automation techniques that rely on automatically\nselecting existing lemmas, by inventing new lemmas that need induction to be\nproved. We show example uses of both modes.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 09:43:09 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Johansson", "Moa", ""], ["Rosen", "Dan", ""], ["Smallbone", "Nicholas", ""], ["Claessen", "Koen", ""]]}, {"id": "1405.3427", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Claudia Faggian, Ichiro Hasuo, Akira Yoshimizu", "title": "The Geometry of Synchronization (Long Version)", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We graft synchronization onto Girard's Geometry of Interaction in its most\nconcrete form, namely token machines. This is realized by introducing\nproof-nets for SMLL, an extension of multiplicative linear logic with a\nspecific construct modeling synchronization points, and of a multi-token\nabstract machine model for it. Interestingly, the correctness criterion ensures\nthe absence of deadlocks along reduction and in the underlying machine, this\nway linking logical and operational properties.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 09:48:08 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Faggian", "Claudia", ""], ["Hasuo", "Ichiro", ""], ["Yoshimizu", "Akira", ""]]}, {"id": "1405.3603", "submitter": "Kyle Marple", "authors": "Kyle Marple and Gopal Gupta", "title": "Dynamic Consistency Checking in Goal-Directed Answer Set Programming", "comments": "12 pages. Accepted to ICLP 2014. To appear in Theory and Practice of\n  Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 415-427", "doi": "10.1017/S1471068414000118", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In answer set programming, inconsistencies arise when the constraints placed\non a program become unsatisfiable. In this paper, we introduce a technique for\ndynamic consistency checking for our goal-directed method for computing answer\nsets, under which only those constraints deemed relevant to the partial answer\nset are tested, allowing inconsistent knowledgebases to be successfully\nqueried. However, the algorithm guarantees that, if a program has at least one\nconsistent answer set, any partial answer set returned will be a subset of some\nconsistent answer set. To appear in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 18:09:59 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Marple", "Kyle", ""], ["Gupta", "Gopal", ""]]}, {"id": "1405.3608", "submitter": "Christian Anti\\'c", "authors": "Christian Anti\\'c", "title": "On cascade products of answer set programs", "comments": "Appears in Theory and Practice of Logic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing complex objects by elementary ones is a common strategy in\nmathematics and science in general. In their seminal 1965 paper, Kenneth Krohn\nand John Rhodes showed that every finite deterministic automaton can be\nrepresented (or \"emulated\") by a cascade product of very simple automata. This\nled to an elegant algebraic theory of automata based on finite semigroups\n(Krohn-Rhodes Theory). Surprisingly, by relating logic programs and automata,\nwe can show in this paper that the Krohn-Rhodes Theory is applicable in Answer\nSet Programming (ASP). More precisely, we recast the concept of a cascade\nproduct to ASP, and prove that every program can be represented by a product of\nvery simple programs, the reset and standard programs. Roughly, this implies\nthat the reset and standard programs are the basic building blocks of ASP with\nrespect to the cascade product. In a broader sense, this paper is a first step\ntowards an algebraic theory of products and networks of nonmonotonic reasoning\nsystems based on Krohn-Rhodes Theory, aiming at important open issues in ASP\nand AI in general.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 18:18:36 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Anti\u0107", "Christian", ""]]}, {"id": "1405.3623", "submitter": "Thomas Gransden", "authors": "Thomas Gransden and Neil Walkinshaw and Rajeev Raman", "title": "Mining State-Based Models from Proof Corpora", "comments": "To Appear at Conferences on Intelligent Computer Mathematics 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive theorem provers have been used extensively to reason about\nvarious software/hardware systems and mathematical theorems. The key challenge\nwhen using an interactive prover is finding a suitable sequence of proof steps\nthat will lead to a successful proof requires a significant amount of human\nintervention. This paper presents an automated technique that takes as input\nexamples of successful proofs and infers an Extended Finite State Machine as\noutput. This can in turn be used to generate proofs of new conjectures. Our\npreliminary experiments show that the inferred models are generally accurate\n(contain few false-positive sequences) and that representing existing proofs in\nsuch a way can be very useful when guiding new ones.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 19:04:11 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Gransden", "Thomas", ""], ["Walkinshaw", "Neil", ""], ["Raman", "Rajeev", ""]]}, {"id": "1405.3681", "submitter": "EPTCS", "authors": "Bob Coecke (University of Oxford)", "title": "Terminality implies non-signalling", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 27-35", "doi": "10.4204/EPTCS.172.3", "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 'process theory' is any theory of systems and processes which admits\nsequential and parallel composition. `Terminality' unifies normalisation of\npure states, trace-preservation of CP-maps, and adding up to identity of\npositive operators in quantum theory, and generalises this to arbitrary process\ntheories. We show that terminality and non-signalling coincide in any process\ntheory, provided one makes causal structure explicit. In fact, making causal\nstructure explicit is necessary to even make sense of non-signalling in process\ntheories. We conclude that because of its much simpler mathematical form,\nterminality should be taken to be a more fundamental notion than\nnon-signalling.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 20:52:39 GMT"}, {"version": "v2", "created": "Fri, 16 May 2014 13:26:54 GMT"}, {"version": "v3", "created": "Tue, 30 Dec 2014 03:00:16 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Coecke", "Bob", "", "University of Oxford"]]}, {"id": "1405.3790", "submitter": "Ana Sofia Gomes", "authors": "Ana Sofia Gomes and Jos\\'e J\\'ulio Alferes", "title": "Transaction Logic with (Complex) Events", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with the problem of combining reactive features, such as the\nability to respond to events and define complex events, with the execution of\ntransactions over general Knowledge Bases (KBs).\n  With this as goal, we build on Transaction Logic (TR), a logic precisely\ndesigned to model and execute transactions in KBs defined by arbitrary logic\ntheories. In it, transactions are written in a logic-programming style, by\ncombining primitive update operations over a general KB, with the usual logic\nprogramming connectives and some additional connectives e.g. to express\nsequence of actions. While TR is a natural choice to deal with transactions, it\nremains the question whether TR can be used to express complex events, but also\nto deal simultaneously with the detection of complex events and the execution\nof transactions. In this paper we show that the former is possible while the\nlatter is not. For that, we start by illustrating how TR can express complex\nevents, and in particular, how SNOOP event expressions can be translated in the\nlogic. Afterwards, we show why TR fails to deal with the two issues together,\nand to solve the intended problem propose Transaction Logic with Events, its\nsyntax, model theory and executional semantics. The achieved solution is a\nnon-monotonic extension of TR, which guarantees that every complex event\ndetected in a transaction is necessarily responded.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 10:18:12 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Gomes", "Ana Sofia", ""], ["Alferes", "Jos\u00e9 J\u00falio", ""]]}, {"id": "1405.3792", "submitter": "Angelos Charalambidis", "authors": "Angelos Charalambidis, Zolt\\'an \\'Esik, Panos Rondogiannis", "title": "Minimum Model Semantics for Extensional Higher-order Logic Programming\n  with Negation", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 725-737", "doi": "10.1017/S1471068414000313", "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensional higher-order logic programming has been introduced as a\ngeneralization of classical logic programming. An important characteristic of\nthis paradigm is that it preserves all the well-known properties of traditional\nlogic programming. In this paper we consider the semantics of negation in the\ncontext of the new paradigm. Using some recent results from non-monotonic\nfixed-point theory, we demonstrate that every higher-order logic program with\nnegation has a unique minimum infinite-valued model. In this way we obtain the\nfirst purely model-theoretic semantics for negation in extensional higher-order\nlogic programming. Using our approach, we resolve an old paradox that was\nintroduced by W. W. Wadge in order to demonstrate the semantic difficulties of\nhigher-order logic programming.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 10:37:42 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Charalambidis", "Angelos", ""], ["\u00c9sik", "Zolt\u00e1n", ""], ["Rondogiannis", "Panos", ""]]}, {"id": "1405.3906", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier, Cezary Kaliszyk", "title": "Matching concepts across HOL libraries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many proof assistant libraries contain formalizations of the same\nmathematical concepts. The concepts are often introduced (defined) in different\nways, but the properties that they have, and are in turn formalized, are the\nsame. For the basic concepts, like natural numbers, matching them between\nlibraries is often straightforward, because of mathematical naming conventions.\nHowever, for more advanced concepts, finding similar formalizations in\ndifferent libraries is a non-trivial task even for an expert.\n  In this paper we investigate automatic discovery of similar concepts across\nlibraries of proof assistants. We propose an approach for normalizing\nproperties of concepts in formal libraries and a number of similarity measures.\nWe evaluate the approach on HOL based proof assistants HOL4, HOL Light and\nIsabelle/HOL, discovering 398 pairs of isomorphic constants and types.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 16:42:29 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Gauthier", "Thibault", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1405.3955", "submitter": "Zoran Majkic", "authors": "Zoran Majkic", "title": "Saturation of the morphisms in the database category", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the problem of saturation of a given morphism in the\ndatabase category DB, which is the base category for the functiorial semantics\nof the database schema mapping systems used in Data Integration theory. This\nphenomena appears in the case when we are using the Second-Order\ntuple-generating dependencies (SOtgd) with existentially quantified\nnon-built-in functions, for the database schema mappings. We provide the\nalgorithm of the saturation for a given morphism, which represents a mapping\nbetween two relational databases, and show that the original morphism in DB can\nbe equivalently substituted by its more powerful saturated version in any\ncommutative diagram in DB.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 14:31:43 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Majkic", "Zoran", ""]]}, {"id": "1405.4008", "submitter": "Aya Saad", "authors": "Aya Saad", "title": "CDF-Intervals: A Reliable Framework to Reason about Data with\n  Uncertainty", "comments": "10 pages, 15 Postscript figures, uses new_tlp.cls and acmtrans.bst,\n  full version of a paper accepted to be presented at the Doctoral Consortium\n  of the 30th International Conference on Logic Programming (ICLP 2014), July\n  19-22, Vienna, Austria. arXiv admin note: substantial text overlap with\n  arXiv:1405.2801", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research introduces a new constraint domain for reasoning about data\nwith uncertainty. It extends convex modeling with the notion of p-box to gain\nadditional quantifiable information on the data whereabouts. Unlike existing\napproaches, the p-box envelops an unknown probability instead of approximating\nits representation. The p-box bounds are uniform cumulative distribution\nfunctions (cdf) in order to employ linear computations in the probabilistic\ndomain. The reasoning by means of p-box cdf-intervals is an interval\ncomputation which is exerted on the real domain then it is projected onto the\ncdf domain. This operation conveys additional knowledge represented by the\nobtained probabilistic bounds. Empirical evaluation shows that, with minimal\noverhead, the output solution set realizes a full enclosure of the data along\nwith tighter bounds on its probabilistic distributions.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 20:48:41 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Saad", "Aya", ""]]}, {"id": "1405.4021", "submitter": "Stefan Brass", "authors": "Stefan Brass", "title": "A Framework for Bottom-Up Simulation of SLD-Resolution", "comments": "ICLP 2014 Technical Communication. To appear in Theory and Practice\n  of Logic Programming (TPLP). 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a framework for the bottom-up simulation of\nSLD-resolution based on partial evaluation. The main idea is to use database\nfacts to represent a set of SLD goals. For deductive databases it is natural to\nassume that the rules defining derived predicates are known at \"compile time\",\nwhereas the database predicates are known only later at runtime. The framework\nis inspired by the author's own SLDMagic method, and a variant of Earley\ndeduction recently introduced by Heike Stephan and the author. However, it\nopens a much broader perspective. [To appear in Theory and Practice of Logic\nProgramming (TPLP)]\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 21:40:14 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Brass", "Stefan", ""]]}, {"id": "1405.4028", "submitter": "Anvesh Komuravelli", "authors": "Anvesh Komuravelli, Arie Gurfinkel, Sagar Chaki", "title": "SMT-based Model Checking for Recursive Programs", "comments": "originally published as part of the proceedings of CAV 2014; fixed\n  typos, better wording at some places", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an SMT-based symbolic model checking algorithm for safety\nverification of recursive programs. The algorithm is modular and analyzes\nprocedures individually. Unlike other SMT-based approaches, it maintains both\n\"over-\" and \"under-approximations\" of procedure summaries. Under-approximations\nare used to analyze procedure calls without inlining. Over-approximations are\nused to block infeasible counterexamples and detect convergence to a proof. We\nshow that for programs and properties over a decidable theory, the algorithm is\nguaranteed to find a counterexample, if one exists. However, efficiency depends\non an oracle for quantifier elimination (QE). For Boolean Programs, the\nalgorithm is a polynomial decision procedure, matching the worst-case bounds of\nthe best BDD-based algorithms. For Linear Arithmetic (integers and rationals),\nwe give an efficient instantiation of the algorithm by applying QE \"lazily\". We\nuse existing interpolation techniques to over-approximate QE and introduce\n\"Model Based Projection\" to under-approximate QE. Empirical evaluation on\nSV-COMP benchmarks shows that our algorithm improves significantly on the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 22:31:03 GMT"}, {"version": "v2", "created": "Sun, 25 May 2014 17:52:17 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Komuravelli", "Anvesh", ""], ["Gurfinkel", "Arie", ""], ["Chaki", "Sagar", ""]]}, {"id": "1405.4034", "submitter": "Sanaz Khan-Afshar", "authors": "Sanaz Khan-Afshar and Vincent Aravantinos and Osman Hasan and Sofiene\n  Tahar", "title": "Formalization of Complex Vectors in Higher-Order Logic", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex vector analysis is widely used to analyze continuous systems in many\ndisciplines, including physics and engineering. In this paper, we present a\nhigher-order-logic formalization of the complex vector space to facilitate\nconducting this analysis within the sound core of a theorem prover: HOL Light.\nOur definition of complex vector builds upon the definitions of complex numbers\nand real vectors. This extension allows us to extensively benefit from the\nalready verified theorems based on complex analysis and real vector analysis.\nTo show the practical usefulness of our library we adopt it to formalize\nelectromagnetic fields and to prove the law of reflection for the planar waves.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 23:21:34 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Khan-Afshar", "Sanaz", ""], ["Aravantinos", "Vincent", ""], ["Hasan", "Osman", ""], ["Tahar", "Sofiene", ""]]}, {"id": "1405.4100", "submitter": "Cristian Prisacariu", "authors": "Cristian Prisacariu", "title": "Higher Dimensional Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Higher dimensional automata (HDA) are a model of concurrency that can express\nmost of the traditional partial order models like Mazurkiewicz traces, pomsets,\nevent structures, or Petri nets. Modal logics, interpreted over Kripke\nstructures, are the logics for reasoning about sequential behavior and\ninterleaved concurrency. Modal logic is a well behaved subset of first-order\nlogic; many variants of modal logic are decidable. However, there are no\nmodal-like logics for the more expressive HDA models. In this paper we\nintroduce and investigate a modal logic over HDAs which incorporates two\nmodalities for reasoning about \"during\" and \"after\". We prove that this general\nhigher dimensional modal logic (HDML) is decidable and we define an axiomatic\nsystem for it. We also show how, when the HDA model is restricted to Kripke\nstructures, a syntactic restriction of HDML becomes the standard modal logic.\nThen we isolate the class of HDAs that encode Mazurkiewicz traces and show how\nHDML, with natural definitions of corresponding Until operators, can be\nrestricted to LTrL (the linear time temporal logic over Mazurkiewicz traces) or\nthe branching time ISTL. We also study the expressiveness of the basic HDML\nlanguage wrt. bisimulations and conclude that HDML captures the\nsplit-bisimulation.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 09:11:38 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Prisacariu", "Cristian", ""]]}, {"id": "1405.4189", "submitter": "Matthias Heizmann", "authors": "Matthias Heizmann, Jochen Hoenicke, Andreas Podelski", "title": "Termination Analysis by Learning Terminating Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to termination analysis. In a first step, the\nanalysis uses a program as a black-box which exhibits only a finite set of\nsample traces. Each sample trace is infinite but can be represented by a finite\nlasso. The analysis can \"learn\" a program from a termination proof for the\nlasso, a program that is terminating by construction. In a second step, the\nanalysis checks that the set of sample traces is representative in a sense that\nwe can make formal. An experimental evaluation indicates that the approach is a\npotentially useful addition to the portfolio of existing approaches to\ntermination analysis.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 14:45:44 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Heizmann", "Matthias", ""], ["Hoenicke", "Jochen", ""], ["Podelski", "Andreas", ""]]}, {"id": "1405.4211", "submitter": "Alexei Lisitsa", "authors": "Andrew Fish and Alexei Lisitsa", "title": "Detecting unknots via equational reasoning, I: Exploration", "comments": "To appear in Proceedings of CICM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of automated reasoning techniques to unknot\ndetection, a classical problem of computational topology. We adopt a\ntwo-pronged experimental approach, using a theorem prover to try to establish a\npositive result (i.e. that a knot is the unknot), whilst simultaneously using a\nmodel finder to try to establish a negative result (i.e. that the knot is not\nthe unknot). The theorem proving approach utilises equational reasoning, whilst\nthe model finder searches for a minimal size counter-model. We present and\ncompare experimental data using the involutary quandle of the knot, as well as\ncomparing with alternative approaches, highlighting instances of interest.\nFurthermore, we present theoretical connections of the minimal countermodels\nobtained with existing knot invariants, for all prime knots of up to 10\ncrossings: this may be useful for developing advanced search strategies.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 15:34:46 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Fish", "Andrew", ""], ["Lisitsa", "Alexei", ""]]}, {"id": "1405.4413", "submitter": "Jan Leike", "authors": "Jan Leike and Matthias Heizmann", "title": "Geometric Series as Nontermination Arguments for Linear Lasso Programs", "comments": "WST 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a new kind of nontermination argument for linear lasso programs,\ncalled geometric nontermination argument. A geometric nontermination argument\nis a finite representation of an infinite execution of the form $(\\vec{x} +\n\\sum_{i=0}^t \\lambda^i \\vec{y})_{t \\geq 0}$. The existence of this\nnontermination argument can be stated as a set of nonlinear algebraic\nconstraints. We show that every linear loop program that has a bounded infinite\nexecution also has a geometric nontermination argument. Furthermore, we discuss\nnonterminating programs that do not have a geometric nontermination argument.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 15:42:32 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Leike", "Jan", ""], ["Heizmann", "Matthias", ""]]}, {"id": "1405.4443", "submitter": "Mingsheng Ying", "authors": "Mingsheng Ying", "title": "Quantum Recursion and Second Quantisation", "comments": "talk at Tsinghua Software Day 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new notion of quantum recursion of which the control\nflow of the computation is quantum rather than classical as in the notions of\nrecursion considered in the previous studies of quantum programming. A typical\nexample is recursive quantum walks, which are obtained by slightly modifying\nthe construction of the ordinary quantum walks. The operational and\ndenotational semantics of quantum recursions are defined by employing the\nsecond quantisation method, and they are proved to be equivalent.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 22:41:08 GMT"}, {"version": "v2", "created": "Wed, 6 Aug 2014 10:51:45 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Ying", "Mingsheng", ""]]}, {"id": "1405.4491", "submitter": "Hermann K.-G. Walter", "authors": "Hermann K.-G. Walter (FB Informatik-TU Darmstadt), Ulrike Brandt (FB\n  Informatik-TU Darmstadt)", "title": "Unsolvability Cores in Classification Problems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 2 (June 19,\n  2014) lmcs:1021", "doi": "10.2168/LMCS-10(2:12)2014", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification problems have been introduced by M. Ziegler as a\ngeneralization of promise problems. In this paper we are concerned with\nsolvability and unsolvability questions with respect to a given set or language\nfamily, especially with cores of unsolvability. We generalize the results about\nunsolvability cores in promise problems to classification problems. Our main\nresults are a characterization of unsolvability cores via cohesiveness and\nexistence theorems for such cores in unsolvable classification problems. In\ncontrast to promise problems we have to strengthen the conditions to assert the\nexistence of such cores. In general unsolvable classification problems with\nmore than two components exist, which possess no cores, even if the set family\nunder consideration satisfies the assumptions which are necessary to prove the\nexistence of cores in unsolvable promise problems. But, if one of the\ncomponents is fixed we can use the results on unsolvability cores in promise\nproblems, to assert the existence of such cores in general. In this case we\nspeak of conditional classification problems and conditional cores. The\nexistence of conditional cores can be related to complexity cores. Using this\nconnection we can prove for language families, that conditional cores with\nrecursive components exist, provided that this family admits an uniform\nsolution for the word problem.\n", "versions": [{"version": "v1", "created": "Sun, 18 May 2014 11:45:37 GMT"}, {"version": "v2", "created": "Wed, 18 Jun 2014 16:09:19 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Walter", "Hermann K. -G.", "", "FB Informatik-TU Darmstadt"], ["Brandt", "Ulrike", "", "FB\n  Informatik-TU Darmstadt"]]}, {"id": "1405.4560", "submitter": "James Worrell", "authors": "Michael Benedikt, Rastislav Lenhardt, James Worrell", "title": "Model Checking Markov Chains Against Unambiguous Buchi Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a polynomial-time algorithm for model checking finite Markov chains\nagainst omega-regular specifications given as unambiguous Buchi automata.\n", "versions": [{"version": "v1", "created": "Sun, 18 May 2014 21:55:12 GMT"}, {"version": "v2", "created": "Sat, 26 Mar 2016 23:17:34 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Benedikt", "Michael", ""], ["Lenhardt", "Rastislav", ""], ["Worrell", "James", ""]]}, {"id": "1405.4699", "submitter": "Thanasis Naskos", "authors": "Athanasios Naskos, Emmanouela Stachtiari, Anastasios Gounaris,\n  Panagiotis Katsaros, Dimitrios Tsoumakos, Ioannis Konstantinou, Spyros\n  Sioutas", "title": "Cloud elasticity using probabilistic model checking", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has become the leading paradigm for deploying large-scale\ninfrastructures and running big data applications, due to its capacity of\nachieving economies of scale. In this work, we focus on one of the most\nprominent advantages of cloud computing, namely the on-demand resource\nprovisioning, which is commonly referred to as elasticity. Although a lot of\neffort has been invested in developing systems and mechanisms that enable\nelasticity, the elasticity decision policies tend to be designed without\nguaranteeing or quantifying the quality of their operation. This work aims to\nmake the development of elasticity policies more formalized and dependable. We\nmake two distinct contributions. First, we propose an extensible approach to\nenforcing elasticity through the dynamic instantiation and online quantitative\nverification of Markov Decision Processes (MDP) using probabilistic model\nchecking. Second, we propose concrete elasticity models and related elasticity\npolicies. We evaluate our decision policies using both real and synthetic\ndatasets in clusters of NoSQL databases. According to the experimental results,\nour approach improves upon the state-of-the-art in significantly increasing\nuser-defined utility values and decreasing user-defined threshold violations.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 12:47:16 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Naskos", "Athanasios", ""], ["Stachtiari", "Emmanouela", ""], ["Gounaris", "Anastasios", ""], ["Katsaros", "Panagiotis", ""], ["Tsoumakos", "Dimitrios", ""], ["Konstantinou", "Ioannis", ""], ["Sioutas", "Spyros", ""]]}, {"id": "1405.4733", "submitter": "Ocan Sankur", "authors": "Jean-Fran\\c{c}ois Raskin, Ocan Sankur", "title": "Multiple-Environment Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Multi-Environment Markov Decision Processes (MEMDPs) which are\nMDPs with a set of probabilistic transition functions. The goal in a MEMDP is\nto synthesize a single controller with guaranteed performances against all\nenvironments even though the environment is unknown a priori. While MEMDPs can\nbe seen as a special class of partially observable MDPs, we show that several\nverification problems that are undecidable for partially observable MDPs, are\ndecidable for MEMDPs and sometimes have even efficient solutions.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 14:21:15 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 10:42:46 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""]]}, {"id": "1405.4806", "submitter": "Tianrong Lin", "authors": "Tianrong Lin", "title": "Undecidability of model-checking branching-time properties of stateless\n  probabilistic pushdown process", "comments": "Author's comments on referee's report added, Interesting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we settle a problem in probabilistic verification of\ninfinite--state process (specifically, {\\it probabilistic pushdown process}).\nWe show that model checking {\\it stateless probabilistic pushdown process}\n(pBPA) against {\\it probabilistic computational tree logic} (PCTL) is\nundecidable.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 16:58:04 GMT"}, {"version": "v10", "created": "Tue, 2 Apr 2019 14:12:15 GMT"}, {"version": "v11", "created": "Wed, 1 May 2019 05:19:19 GMT"}, {"version": "v12", "created": "Tue, 3 Mar 2020 17:17:35 GMT"}, {"version": "v2", "created": "Mon, 26 May 2014 13:30:09 GMT"}, {"version": "v3", "created": "Tue, 17 Jun 2014 14:07:31 GMT"}, {"version": "v4", "created": "Sun, 17 Aug 2014 12:36:23 GMT"}, {"version": "v5", "created": "Sat, 14 Mar 2015 16:58:52 GMT"}, {"version": "v6", "created": "Tue, 21 Jul 2015 17:59:49 GMT"}, {"version": "v7", "created": "Wed, 22 Jul 2015 12:21:45 GMT"}, {"version": "v8", "created": "Thu, 23 Jul 2015 16:38:38 GMT"}, {"version": "v9", "created": "Wed, 27 Mar 2019 21:49:48 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Lin", "Tianrong", ""]]}, {"id": "1405.4917", "submitter": "Hubie Chen", "authors": "Hubie Chen", "title": "An Algebraic Hardness Criterion for Surjective Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) on a relational structure B is to\ndecide, given a set of constraints on variables where the relations come from\nB, whether or not there is a assignment to the variables satisfying all of the\nconstraints; the surjective CSP is the variant where one decides the existence\nof a surjective satisfying assignment onto the universe of B. We present an\nalgebraic condition on the polymorphism clone of B and prove that it is\nsufficient for the hardness of the surjective CSP on a finite structure B, in\nthe sense that this problem admits a reduction from a certain fixed-structure\nCSP. To our knowledge, this is the first result that allows one to use\nalgebraic information from a relational structure B to infer information on the\ncomplexity hardness of surjective constraint satisfaction on B. A corollary of\nour result is that, on any finite non-trivial structure having only essentially\nunary polymorphisms, surjective constraint satisfaction is NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 23:23:24 GMT"}, {"version": "v2", "created": "Mon, 2 Jun 2014 10:29:27 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Chen", "Hubie", ""]]}, {"id": "1405.5109", "submitter": "Michael Morak", "authors": "Michael Morak", "title": "The Impact of Disjunction on Reasoning under Existential Rules: Research\n  Summary", "comments": "A full version of a paper accepted to be presented at the Doctoral\n  Consortium of the 30th International Conference on Logic Programming (ICLP\n  2014), July 19-22, Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Datalog+/- is a Datalog-based language family enhanced with existential\nquantification in rule heads, equalities and negative constraints. Query\nanswering over databases with respect to a Datalog+/- theory is generally\nundecidable, however several syntactic restrictions have been proposed to\nremedy this fact. However, a useful and natural feature however is as of yet\nmissing from Datalog+/-: The ability to express uncertain knowledge, or\nchoices, using disjunction. It is the precise objective of the doctoral thesis\nherein discussed, to investigate the impact on the complexity of query\nanswering, of adding disjunction to well-known decidable Datalog+/- fragments,\nnamely guarded, sticky and weakly-acyclic Datalog+/- theories. For guarded\ntheories with disjunction, we obtain a strong 2EXP lower bound in the combined\ncomplexity, even for very restricted formalisms like fixed sets of\n(disjunctive) inclusion dependencies. For sticky theories, the query answering\nproblem becomes undecidable, even in the data complexity, and for\nweakly-acyclic query answering we see a reasonable and expected increase in\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 04:40:20 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Morak", "Michael", ""]]}, {"id": "1405.5133", "submitter": "Volker Diekert", "authors": "Volker Diekert and Artur Je\\.z and Wojciech Plandowski", "title": "Finding All Solutions of Equations in Free Groups and Monoids with\n  Involution", "comments": "A preliminary version of this paper was presented as an invited talk\n  at CSR 2014 in Moscow, June 7 - 11, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to present a PSPACE algorithm which yields a finite\ngraph of exponential size and which describes the set of all solutions of\nequations in free groups as well as the set of all solutions of equations in\nfree monoids with involution in the presence of rational constraints. This\nbecame possible due to the recently invented emph{recompression} technique of\nthe second author.\n  He successfully applied the recompression technique for pure word equations\nwithout involution or rational constraints. In particular, his method could not\nbe used as a black box for free groups (even without rational constraints).\nActually, the presence of an involution (inverse elements) and rational\nconstraints complicates the situation and some additional analysis is\nnecessary. Still, the recompression technique is general enough to accommodate\nboth extensions. In the end, it simplifies proofs that solving word equations\nis in PSPACE (Plandowski 1999) and the corresponding result for equations in\nfree groups with rational constraints (Diekert, Hagenah and Gutierrez 2001). As\na byproduct we obtain a direct proof that it is decidable in PSPACE whether or\nnot the solution set is finite.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 15:48:28 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 14:25:39 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Diekert", "Volker", ""], ["Je\u017c", "Artur", ""], ["Plandowski", "Wojciech", ""]]}, {"id": "1405.5279", "submitter": "Ricardo Fernandes", "authors": "Ricardo Q. A. Fernandes, Edward H. Haeusler, Luiz Carlos Pereira", "title": "Intuitionistic PUC-Logic for Constructive Counterfactuals", "comments": "arXiv admin note: text overlap with arXiv:1402.1535", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the intuitionistic version of PUC-Logic. After that, we present a\nconstructive approach to Lewis' counterfactual abstraction to show that it does\nnot require the classical absurd rule.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 02:05:36 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Fernandes", "Ricardo Q. A.", ""], ["Haeusler", "Edward H.", ""], ["Pereira", "Luiz Carlos", ""]]}, {"id": "1405.5393", "submitter": "Marie Kerjean", "authors": "Marie Kerjean (Laboratoire PPS)", "title": "Weak topologies for Linear Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 1 (March 9,\n  2016) lmcs:1626", "doi": "10.2168/LMCS-12(1:3)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a denotational model of linear logic, whose objects are all the\nlocally convex and separated topological vector spaces endowed with their weak\ntopology. The negation is interpreted as the dual, linear proofs are\ninterpreted as continuous linear functions, and non-linear proofs as sequences\nof monomials. We do not complete our constructions by a double-orthogonality\noperation. This yields an interpretation of the polarity of the connectives in\nterms of topology.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 12:30:53 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 08:26:40 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2015 18:17:59 GMT"}, {"version": "v4", "created": "Mon, 7 Mar 2016 23:22:13 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Kerjean", "Marie", "", "Laboratoire PPS"]]}, {"id": "1405.5593", "submitter": "EPTCS", "authors": "Arnaud Carayol (LIGM, Universit\\'e Paris-Est, CNRS), Matthew Hague\n  (Department of Computer Science, Royal Holloway University of London)", "title": "Saturation algorithms for model-checking pushdown systems", "comments": "In Proceedings AFL 2014, arXiv:1405.5272", "journal-ref": "EPTCS 151, 2014, pp. 1-24", "doi": "10.4204/EPTCS.151.1", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a survey of the saturation method for model-checking pushdown\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 02:11:30 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Carayol", "Arnaud", "", "LIGM, Universit\u00e9 Paris-Est, CNRS"], ["Hague", "Matthew", "", "Department of Computer Science, Royal Holloway University of London"]]}, {"id": "1405.5626", "submitter": "Samuel R Buss", "authors": "Samuel R. Buss (Univ. of California, San Diego), Leszek Aleksander\n  Kolodziejczyk (University of Warsaw)", "title": "Small Stone in Pool", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 2 (June 27,\n  2014) lmcs:852", "doi": "10.2168/LMCS-10(2:16)2014", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stone tautologies are known to have polynomial size resolution\nrefutations and require exponential size regular refutations. We prove that the\nStone tautologies also have polynomial size proofs in both pool resolution and\nthe proof system of regular tree-like resolution with input lemmas (regRTI).\nTherefore, the Stone tautologies do not separate resolution from DPLL with\nclause learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 03:36:48 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 05:35:22 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Buss", "Samuel R.", "", "Univ. of California, San Diego"], ["Kolodziejczyk", "Leszek Aleksander", "", "University of Warsaw"]]}, {"id": "1405.5628", "submitter": "Alban Gabillon", "authors": "Fr\\'ed\\'eric Cuppens (LUSSI, Lab-STICC), Alban Gabillon (GePaSUD)", "title": "Cover Story Management", "comments": null, "journal-ref": "Data and Knowledge Engineering 37, 2 (2001) 177-201", "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multilevel database, cover stories are usually managed using the\nambiguous technique of polyinstantiation. In this paper, we define a new\ntechnique to manage cover stories and propose a formal representation of a\nmultilevel database containing cover stories. Our model aims to be a generic\nmodel, that is, it can be interpreted for any kind of database (e.g.\nrelational, object- oriented etc). We then consider the problem of updating a\nmultilevel database containing cover stories managed with our technique.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 04:13:15 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Cuppens", "Fr\u00e9d\u00e9ric", "", "LUSSI, Lab-STICC"], ["Gabillon", "Alban", "", "GePaSUD"]]}, {"id": "1405.5645", "submitter": "Heike Stephan", "authors": "Heike Stephan, Stefan Brass", "title": "A Variant of Earley Deduction With Partial Evaluation", "comments": "WLP 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for query evaluation given a logic program consisting\nof function-free Datalog rules. It is based on Earley Deduction [4, 6] and uses\na partial evaluation similar to the one we devel oped for our SLDMagic method\n[1]. With this, finite automata modeling the evaluation of given queries are\ngenerated. In certain cases, the new method is more efficient than SLDMagic and\nthe standard Magic Set method since it can process several deduction steps as\none.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 07:31:16 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Stephan", "Heike", ""], ["Brass", "Stefan", ""]]}, {"id": "1405.5662", "submitter": "Joerg Endrullis", "authors": "J\\\"org Endrullis, Hans Zantema", "title": "Non-termination using Regular Languages", "comments": "Published at International Workshop on Termination 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for proving non-looping non-termination, that is, of\nterm rewriting systems that do not admit looping reductions. As certificates of\nnon-termination, we employ regular (tree) automata.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 08:16:19 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Zantema", "Hans", ""]]}, {"id": "1405.5668", "submitter": "Victor Magron", "authors": "Victor Magron", "title": "NLCertify: A Tool for Formal Nonlinear Optimization", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLCertify is a software package for handling formal certification of\nnonlinear inequalities involving transcendental multivariate functions. The\ntool exploits sparse semialgebraic optimization techniques with approximation\nmethods for transcendental functions, as well as formal features. Given a box\nand a transcendental multivariate function as input, NLCertify provides OCaml\nlibraries that produce nonnegativity certificates for the function over the\nbox, which can be ultimately proved correct inside the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 08:41:00 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Magron", "Victor", ""]]}, {"id": "1405.5671", "submitter": "Alban Gabillon", "authors": "Alban Gabillon (GePaSUD)", "title": "A Logical Formalization of a Secure XML Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first define a logical theory representing an XML database\nsupporting XPath as query language and XUpdate as modification language. We\nthen extend our theory with predicates allowing us to specify the security\npolicy protecting the database. The security policy includes rules addressing\nthe read and write privileges. We propose axioms to derive the database view\neach user is permitted to see. We also propose axioms to derive the new\ndatabase content after an update.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 08:56:01 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Gabillon", "Alban", "", "GePaSUD"]]}, {"id": "1405.5902", "submitter": "Xavier Urbain", "authors": "Pierre Courtieu (CEDRIC), Lionel Rieg (CEDRIC, ENSIIE), Xavier Urbain\n  (CEDRIC, ENSIIE, LRI), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "Impossibility of Gathering, a Certification", "comments": "10p", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Distributed Computing highlight models and algorithms for\nautonomous swarms of mobile robots that self-organise and cooperate to solve\nglobal objectives. The overwhelming majority of works so far considers handmade\nalgorithms and proofs of correctness. This paper builds upon a previously\nproposed formal framework to certify the correctness of impossibility results\nregarding distributed algorithms that are dedicated to autonomous mobile robots\nevolving in a continuous space. As a case study, we consider the problem of\ngathering all robots at a particular location, not known beforehand. A\nfundamental (but not yet formally certified) result, due to Suzuki and\nYamashita, states that this simple task is impossible for two robots executing\ndeterministic code and initially located at distinct positions. Not only do we\nobtain a certified proof of the original impossibility result, we also get the\nmore general impossibility of gathering with an even number of robots, when any\ntwo robots are possibly initially at the same exact location.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 20:34:03 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Courtieu", "Pierre", "", "CEDRIC"], ["Rieg", "Lionel", "", "CEDRIC, ENSIIE"], ["Urbain", "Xavier", "", "CEDRIC, ENSIIE, LRI"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1405.5927", "submitter": "Christopher M. Poskitt", "authors": "Christopher M. Poskitt and Detlef Plump", "title": "Verifying Monadic Second-Order Properties of Graph Programs", "comments": "Extended version of a paper to appear at ICGT 2014", "journal-ref": "Proc. International Conference on Graph Transformation (ICGT\n  2014), volume 8571 of LNCS, pages 33-48. Springer, 2014", "doi": "10.1007/978-3-319-09108-2_3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core challenge in a Hoare- or Dijkstra-style proof system for graph\nprograms is in defining a weakest liberal precondition construction with\nrespect to a rule and a postcondition. Previous work addressing this has\nfocused on assertion languages for first-order properties, which are unable to\nexpress important global properties of graphs such as acyclicity,\nconnectedness, or existence of paths. In this paper, we extend the nested graph\nconditions of Habel, Pennemann, and Rensink to make them equivalently\nexpressive to monadic second-order logic on graphs. We present a weakest\nliberal precondition construction for these assertions, and demonstrate its use\nin verifying non-local correctness specifications of graph programs in the\nsense of Habel et al.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 23:17:22 GMT"}, {"version": "v2", "created": "Mon, 16 Jun 2014 20:15:05 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Poskitt", "Christopher M.", ""], ["Plump", "Detlef", ""]]}, {"id": "1405.5956", "submitter": "Jacques Carette", "authors": "Jacques Carette, William M. Farmer, Michael Kohlhase", "title": "Realms: A Structure for Consolidating Knowledge about Mathematical\n  Theories", "comments": "As accepted for CICM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since there are different ways of axiomatizing and developing a mathematical\ntheory, knowledge about a such a theory may reside in many places and in many\nforms within a library of formalized mathematics. We introduce the notion of a\nrealm as a structure for consolidating knowledge about a mathematical theory. A\nrealm contains several axiomatizations of a theory that are separately\ndeveloped. Views interconnect these developments and establish that the\naxiomatizations are equivalent in the sense of being mutually interpretable. A\nrealm also contains an external interface that is convenient for users of the\nlibrary who want to apply the concepts and facts of the theory without delving\ninto the details of how the concepts and facts were developed. We illustrate\nthe utility of realms through a series of examples. We also give an outline of\nthe mechanisms that are needed to create and maintain realms.\n", "versions": [{"version": "v1", "created": "Fri, 23 May 2014 03:05:42 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Carette", "Jacques", ""], ["Farmer", "William M.", ""], ["Kohlhase", "Michael", ""]]}, {"id": "1405.6095", "submitter": "Marius Buliga", "authors": "Marius Buliga", "title": "Zipper logic", "comments": "16 pages, 24 colour figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zipper logic is a graph rewrite system, consisting in only local rewrites on\na class of zipper graphs. Connections with the chemlambda artificial chemistry\nand with knot diagrammatics based computation are explored in the article.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 16:18:06 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Buliga", "Marius", ""]]}, {"id": "1405.6100", "submitter": "Adrian Francalanza", "authors": "Adrian Francalanza (University of Malta), Edsko DeVries (Well-Typed\n  LLP), Matthew Hennessy (Trinity College Dublin, Ireland)", "title": "Compositional Reasoning for Explicit Resource Management in\n  Channel-Based Concurrency", "comments": "51 pages, 7 figures", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 2 (June 26,\n  2014) lmcs:691", "doi": "10.2168/LMCS-10(2:15)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a pi-calculus variant with a costed semantics where channels are\ntreated as resources that must explicitly be allocated before they are used and\ncan be deallocated when no longer required. We use a substructural type system\ntracking permission transfer to construct coinductive proof techniques for\ncomparing behaviour and resource usage efficiency of concurrent processes. We\nestablish full abstraction results between our coinductive definitions and a\ncontextual behavioural preorder describing a notion of process efficiency\nw.r.t. its management of resources. We also justify these definitions and\nrespective proof techniques through numerous examples and a case study\ncomparing two concurrent implementations of an extensible buffer.\n", "versions": [{"version": "v1", "created": "Fri, 23 May 2014 15:38:17 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 08:44:49 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Francalanza", "Adrian", "", "University of Malta"], ["DeVries", "Edsko", "", "Well-Typed\n  LLP"], ["Hennessy", "Matthew", "", "Trinity College Dublin, Ireland"]]}, {"id": "1405.6317", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth", "title": "Herbrand's Fundamental Theorem: The Historical Facts and their\n  Streamlining", "comments": "ii + 47 pages", "journal-ref": null, "doi": null, "report-no": "SEKI Report SR-2014-01", "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Heijenoort's unpublished generalized rules of quantification, we\ndiscuss the proof of Herbrand's Fundamental Theorem in the form of Heijenoort's\ncorrection of Herbrand's \"False Lemma\" and present a didactic example. Although\nwe are mainly concerned with the inner structure of Herbrand's Fundamental\nTheorem and the questions of its quality and its depth, we also discuss the\nouter questions of its historical context and why Bernays called it \"the\ncentral theorem of predicate logic\" and considered the form of its expression\nto be \"concise and felicitous\".\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2014 16:30:37 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2014 05:05:54 GMT"}], "update_date": "2014-08-15", "authors_parsed": [["Wirth", "Claus-Peter", ""]]}, {"id": "1405.6331", "submitter": "Thomas Seiller", "authors": "Thomas Seiller", "title": "Interaction Graphs: Graphings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two previous papers, we exposed a combinatorial approach to the program of\nGeometry of Interaction, a program initiated by Jean-Yves Girard. The strength\nof our approach lies in the fact that we interpret proofs by simpler structures\n- graphs - than Girard's constructions, while generalizing the latter since\nthey can be recovered as special cases of our setting. This third paper extends\nthis approach by considering a generalization of graphs named graphings, which\nis in some way a geometric realization of a graph. This very general framework\nleads to a number of new models of multiplicative-additive linear logic which\ngeneralize Girard's geometry of interaction models and opens several new lines\nof research. As an example, we exhibit a family of such models which account\nfor second-order quantification without suffering the same limitations as\nGirard's models.\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2014 18:31:29 GMT"}, {"version": "v2", "created": "Sun, 1 Jun 2014 08:04:54 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2015 17:05:35 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Seiller", "Thomas", ""]]}, {"id": "1405.6380", "submitter": "EPTCS", "authors": "Clemens Grabmayer (VU University Amsterdam), Vincent van Oostrom\n  (Utrecht University)", "title": "Nested Term Graphs (Work In Progress)", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818", "journal-ref": "EPTCS 183, 2015, pp. 48-65", "doi": "10.4204/EPTCS.183.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on work in progress on 'nested term graphs' for formalizing\nhigher-order terms (e.g. finite or infinite lambda-terms), including those\nexpressing recursion (e.g. terms in the lambda-calculus with letrec). The idea\nis to represent the nested scope structure of a higher-order term by a nested\nstructure of term graphs.\n  Based on a signature that is partitioned into atomic and nested function\nsymbols, we define nested term graphs both in a functional representation, as\ntree-like recursive graph specifications that associate nested symbols with\nusual term graphs, and in a structural representation, as enriched term graph\nstructures. These definitions induce corresponding notions of bisimulation\nbetween nested term graphs. Our main result states that nested term graphs can\nbe implemented faithfully by first-order term graphs.\n  keywords: higher-order term graphs, context-free grammars, cyclic\nlambda-terms, higher-order rewrite systems\n", "versions": [{"version": "v1", "created": "Sun, 25 May 2014 11:53:09 GMT"}, {"version": "v2", "created": "Wed, 27 May 2015 07:49:17 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Grabmayer", "Clemens", "", "VU University Amsterdam"], ["van Oostrom", "Vincent", "", "Utrecht University"]]}, {"id": "1405.6678", "submitter": "Richard Moot", "authors": "Richard Moot (LaBRI)", "title": "Hybrid Type-Logical Grammars, First-Order Linear Logic and the\n  Descriptive Inadequacy of Lambda Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we show that hybrid type-logical grammars are a fragment of\nfirst-order linear logic. This embedding result has several important\nconsequences: it not only provides a simple new proof theory for the calculus,\nthereby clarifying the proof-theoretic foundations of hybrid type-logical\ngrammars, but, since the translation is simple and direct, it also provides\nseveral new parsing strategies for hybrid type-logical grammars. Second,\nNP-completeness of hybrid type-logical grammars follows immediately. The main\nembedding result also sheds new light on problems with lambda grammars/abstract\ncategorial grammars and shows lambda grammars/abstract categorial grammars\nsuffer from problems of over-generation and from problems at the\nsyntax-semantics interface unlike any other categorial grammar.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 18:48:15 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Moot", "Richard", "", "LaBRI"]]}, {"id": "1405.6820", "submitter": "Philipp Hoffmann", "authors": "Javier Esparza and Philipp Hoffmann", "title": "Negotiation Games (with abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negotiations, a model of concurrency with multi party negotiation as\nprimitive, have been recently introduced in arXiv:1307.2145, arXiv:1403.4958.\nWe initiate the study of games for this model. We study coalition problems: can\na given coalition of agents force that a negotiation terminates (resp. block\nthe negotiation so that it goes on forever)?; can the coalition force a given\noutcome of the negotiation? We show that for arbitrary negotiations the\nproblems are EXPTIME-complete. Then we show that for sound and deterministic or\neven weakly deterministic negotiations the problems can be solved in PTIME.\nNotice that the input of the problems is a negotiation, which can be\nexponentially more compact than its state space.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 07:25:27 GMT"}, {"version": "v2", "created": "Tue, 10 Jun 2014 13:21:17 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2015 08:26:32 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Esparza", "Javier", ""], ["Hoffmann", "Philipp", ""]]}, {"id": "1405.6866", "submitter": "Arno Pauly", "authors": "Takayuki Kihara and Arno Pauly", "title": "Point degree spectra of represented spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GN cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the point degree spectrum of a represented space as a\nsubstructure of the Medvedev degrees, which integrates the notion of Turing\ndegrees, enumeration degrees, continuous degrees, and so on. The notion of\npoint degree spectrum creates a connection among various areas of mathematics\nincluding computability theory, descriptive set theory, infinite dimensional\ntopology and Banach space theory. Through this new connection, for instance, we\nconstruct a family of continuum many infinite dimensional Cantor manifolds with\nproperty $C$ whose Borel structures at an arbitrary finite rank are mutually\nnon-isomorphic. This provides new examples of Banach algebras of real valued\nBaire class two functions on metrizable compacta, and strengthen various\ntheorems in infinite dimensional topology such as Pol's solution to\nAlexandrov's old problem.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 10:54:22 GMT"}, {"version": "v2", "created": "Sun, 27 Jul 2014 11:26:33 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 05:09:49 GMT"}, {"version": "v4", "created": "Fri, 4 Aug 2017 07:44:46 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Kihara", "Takayuki", ""], ["Pauly", "Arno", ""]]}, {"id": "1405.6899", "submitter": "Piotr Ka\\'zmierczak", "authors": "Truls Pedersen, Sjur Dyrkolbotn and Piotr Ka\\'zmierczak", "title": "Big, but not unruly: Tractable norms for anonymous game structures", "comments": "Accepted at COIN@PRIMA 2013 workshop and presented on December 3rd,\n  2013 in Dunedin, New Zealand. http://coin2013-prima.tudelft.nl/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new strategic logic NCHATL that allows for reasoning about norm\ncompliance on concurrent game structures that satisfy anonymity. We represent\nsuch game structures compactly, avoiding models that have exponential size in\nthe number of agents. Then we show that model checking can be done in\npolynomial time with respect to this compact representation, even for normative\nsystems that are not anonymous. That is, as long as the underlying game\nstructures are anonymous, model checking normative formulas is tractable even\nif norms can prescribe different sets of forbidden actions to different agents.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 13:15:48 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Pedersen", "Truls", ""], ["Dyrkolbotn", "Sjur", ""], ["Ka\u017amierczak", "Piotr", ""]]}, {"id": "1405.6939", "submitter": "J\\\"urgen Christ", "authors": "J\\\"urgen Christ and Jochen Hoenicke", "title": "Weakly Equivalent Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (extensional) theory of arrays is widely used to model systems. Hence,\nefficient decision procedures are needed to model check such systems. Current\ndecision procedures for the theory of arrays saturate the read-over-write and\nextensionality axioms originally proposed by McCarthy. Various filters are used\nto limit the number of axiom instantiations while preserving completeness. We\npresent an algorithm that lazily instantiates lemmas based on weak equivalence\nclasses. These lemmas are easier to interpolate as they only contain existing\nterms. We formally define weak equivalence and show correctness of the\nresulting decision procedure.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 14:53:36 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Christ", "J\u00fcrgen", ""], ["Hoenicke", "Jochen", ""]]}, {"id": "1405.6985", "submitter": "Waqar  Ahmed", "authors": "Waqar Ahmed, Osman Hasan, Sofiene Tahar, and Mohammad Salah Hamdi", "title": "Towards the Formal Reliability Analysis of Oil and Gas Pipelines", "comments": "15 pages", "journal-ref": "Intelligent Computer Mathematics, pp. 30-44. (Lecture Notes in\n  Artificial Intelligence, 8543). Springer Berlin Heidelberg, 2014", "doi": "10.1007/978-3-319-08434-3_4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is customary to assess the reliability of underground oil and gas\npipelines in the presence of excessive loading and corrosion effects to ensure\na leak-free transport of hazardous materials. The main idea behind this\nreliability analysis is to model the given pipeline system as a Reliability\nBlock Diagram (RBD) of segments such that the reliability of an individual\npipeline segment can be represented by a random variable. Traditionally,\ncomputer simulation is used to perform this reliability analysis but it\nprovides approximate results and requires an enormous amount of CPU time for\nattaining reasonable estimates. Due to its approximate nature, simulation is\nnot very suitable for analyzing safety-critical systems like oil and gas\npipelines, where even minor analysis flaws may result in catastrophic\nconsequences. As an accurate alternative, we propose to use a\nhigher-order-logic theorem prover (HOL) for the reliability analysis of\npipelines. As a first step towards this idea, this paper provides a\nhigher-order-logic formalization of reliability and the series RBD using the\nHOL theorem prover. For illustration, we present the formal analysis of a\nsimple pipeline that can be modeled as a series RBD of segments with\nexponentially distributed failure times.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 06:50:27 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Ahmed", "Waqar", ""], ["Hasan", "Osman", ""], ["Tahar", "Sofiene", ""], ["Hamdi", "Mohammad Salah", ""]]}, {"id": "1405.7012", "submitter": "Johannes H\\\"olzl", "authors": "Jeremy Avigad and Johannes H\\\"olzl and Luke Serafin", "title": "A formally verified proof of the Central Limit Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a proof of the Central Limit Theorem that has been formally\nverified in the Isabelle proof assistant. Our formalization builds upon and\nextends Isabelle's libraries for analysis and measure-theoretic probability.\nThe proof of the theorem uses characteristic functions, which are a kind of\nFourier transform, to demonstrate that, under suitable hypotheses, sums of\nrandom variables converge weakly to the standard normal distribution. We also\ndiscuss the libraries and infrastructure that supported the formalization, and\nreflect on some of the lessons we have learned from the effort.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 19:01:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 14:49:45 GMT"}, {"version": "v3", "created": "Wed, 18 Jan 2017 21:09:09 GMT"}, {"version": "v4", "created": "Wed, 1 Feb 2017 15:53:42 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Avigad", "Jeremy", ""], ["H\u00f6lzl", "Johannes", ""], ["Serafin", "Luke", ""]]}, {"id": "1405.7058", "submitter": "Asiri Rathnayake", "authors": "Asiri Rathnayake and Hayo Thielecke", "title": "Static Analysis for Regular Expression Exponential Runtime via\n  Substructural Logics (Extended)", "comments": "Extended version with a sketch of the completeness proof - work in\n  progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular expression matching using backtracking can have exponential runtime,\nleading to an algorithmic complexity attack known as REDoS in the systems\nsecurity literature. In this paper, we build on a recently published static\nanalysis that detects whether a given regular expression can have exponential\nruntime for some inputs. We systematically construct a more accurate analysis\nby forming powers and products of transition relations and thereby reducing the\nREDoS problem to reachability. The correctness of the analysis is proved using\na substructural calculus of search trees, where the branching of the tree\ncausing exponential blowup is characterized as a form of non-linearity.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 20:33:14 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 11:41:37 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Rathnayake", "Asiri", ""], ["Thielecke", "Hayo", ""]]}, {"id": "1405.7141", "submitter": "Ernst-Erich Doberkat", "authors": "Ernst-Erich Doberkat and Pedro S\\'anchez Terraf", "title": "Stochastic Nondeterminism and Effectivity Functions", "comments": "Minor changes in the text, correction of typos; new and extended\n  abstract; added an acknowledgement (paper accepted by J. Logic Comput.)", "journal-ref": null, "doi": null, "report-no": "SWT-Memo 200", "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates stochastic nondeterminism on continuous state spaces\nby relating nondeterministic kernels and stochastic effectivity functions to\neach other. Nondeterministic kernels are functions assigning each state a set o\nsubprobability measures, and effectivity functions assign to each state an\nupper-closed set of subsets of measures. Both concepts are generalizations of\nMarkov kernels used for defining two different models: Nondeterministic\nlabelled Markov processes and stochastic game models, respectively. We show\nthat an effectivity function that maps into principal filters is given by an\nimage-countable nondeterministic kernel, and that image-finite kernels give\nrise to effectivity functions. We define state bisimilarity for the latter,\nconsidering its connection to morphisms. We provide a logical characterization\nof bisimilarity in the finitary case. A generalization of congruences (event\nbisimulations) to effectivity functions and its relation to the categorical\npresentation of bisimulation are also studied.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 07:21:03 GMT"}, {"version": "v2", "created": "Wed, 12 Nov 2014 09:27:02 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2015 12:19:44 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2015 11:00:49 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Doberkat", "Ernst-Erich", ""], ["Terraf", "Pedro S\u00e1nchez", ""]]}, {"id": "1405.7221", "submitter": "Linh Anh Nguyen D.Sc.", "authors": "Linh Anh Nguyen and Joanna Goli\\'nska-Pilarek", "title": "ExpTime Tableaux with Global Caching for the Description Logic SHOQ", "comments": "arXiv admin note: substantial text overlap with arXiv:1205.5838", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first ExpTime (complexity-optimal) tableau decision procedure for\nchecking satisfiability of a knowledge base in the description logic SHOQ,\nwhich extends the basic description logic ALC with transitive roles,\nhierarchies of roles, nominals and quantified number restrictions. The\ncomplexity is measured using unary representation for numbers. Our procedure is\nbased on global caching and integer linear feasibility checking.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 12:53:23 GMT"}, {"version": "v2", "created": "Mon, 21 Jul 2014 10:49:57 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Nguyen", "Linh Anh", ""], ["Goli\u0144ska-Pilarek", "Joanna", ""]]}, {"id": "1405.7253", "submitter": "Florian Lonsing", "authors": "Uwe Egly and Martin Kronegger and Florian Lonsing and Andreas Pfandler", "title": "Conformant Planning as a Case Study of Incremental QBF Solving", "comments": "added reference to extended journal article; revision (camera-ready,\n  to appear in the proceedings of AISC 2014, volume 8884 of LNAI, Springer)", "journal-ref": null, "doi": "10.1007/978-3-319-13770-4_11", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider planning with uncertainty in the initial state as a case study of\nincremental quantified Boolean formula (QBF) solving. We report on experiments\nwith a workflow to incrementally encode a planning instance into a sequence of\nQBFs. To solve this sequence of incrementally constructed QBFs, we use our\ngeneral-purpose incremental QBF solver DepQBF. Since the generated QBFs have\nmany clauses and variables in common, our approach avoids redundancy both in\nthe encoding phase and in the solving phase. Experimental results show that\nincremental QBF solving outperforms non-incremental QBF solving. Our results\nare the first empirical study of incremental QBF solving in the context of\nplanning and motivate its use in other application domains.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 14:23:50 GMT"}, {"version": "v2", "created": "Wed, 8 Oct 2014 12:04:01 GMT"}, {"version": "v3", "created": "Mon, 4 Apr 2016 11:06:57 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Egly", "Uwe", ""], ["Kronegger", "Martin", ""], ["Lonsing", "Florian", ""], ["Pfandler", "Andreas", ""]]}, {"id": "1405.7285", "submitter": "Ricardo Fernandes", "authors": "Ricardo Q. A. Fernandes, Edward H. Haeusler, Luiz Carlos Pereira", "title": "PUC-Logic embedding of Lewis' Deontic Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a embedding of Lewis Deontic logics in PUC-Logic. We achieve this\nby representing the vary basic $\\boldsymbol{CO}$ logic and showing its relative\ncompleteness.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 01:58:00 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Fernandes", "Ricardo Q. A.", ""], ["Haeusler", "Edward H.", ""], ["Pereira", "Luiz Carlos", ""]]}, {"id": "1405.7320", "submitter": "Daniel Fremont", "authors": "Daniel J. Fremont and Sanjit A. Seshia", "title": "Speeding Up SMT-Based Quantitative Program Analysis", "comments": "Full version of an SMT 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative program analysis involves computing numerical quantities about\nindividual or collections of program executions. An example of such a\ncomputation is quantitative information flow analysis, where one estimates the\namount of information leaked about secret data through a program's output\nchannels. Such information can be quantified in several ways, including channel\ncapacity and (Shannon) entropy. In this paper, we formalize a class of\nquantitative analysis problems defined over a weighted control flow graph of a\nloop-free program. These problems can be solved using a combination of path\nenumeration, SMT solving, and model counting. However, existing methods can\nonly handle very small programs, primarily because the number of execution\npaths can be exponential in the program size. We show how path explosion can be\nmitigated in some practical cases by taking advantage of special branching\nstructure and by novel algorithm design. We demonstrate our techniques by\ncomputing the channel capacities of the timing side-channels of two programs\nwith extremely large numbers of paths.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 18:10:22 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Fremont", "Daniel J.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1405.7375", "submitter": "Jacob Turner", "authors": "Jacob D. Biamonte, Jason Morton, Jacob W. Turner", "title": "Tensor Network Contractions for #SAT", "comments": "16 pages, 8 diagrams", "journal-ref": "Journal of Statistical Physics 160:5 1389-1404 (2015)", "doi": "10.1007/s10955-015-1276-z", "report-no": null, "categories": "quant-ph cs.CC cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational cost of counting the number of solutions satisfying a\nBoolean formula, which is a problem instance of #SAT, has proven subtle to\nquantify. Even when finding individual satisfying solutions is computationally\neasy (e.g. 2-SAT, which is in P), determining the number of solutions is\n#P-hard. Recently, computational methods simulating quantum systems experienced\nadvancements due to the development of tensor network algorithms and associated\nquantum physics-inspired techniques. By these methods, we give an algorithm\nusing an axiomatic tensor contraction language for n-variable #SAT instances\nwith complexity $O((g+cd)^{O(1)} 2^c)$ where $c$ is the number of COPY-tensors,\n$g$ is the number of gates, and $d$ is the maximal degree of any COPY-tensor.\nThus, counting problems can be solved efficiently when their tensor network\nexpression has at most $O(\\log c)$ COPY-tensors and polynomial fan-out. This\nframework also admits an intuitive proof of a variant of the Tovey conjecture\n(the r,1-SAT instance of the Dubois-Tovey theorem). This study increases the\ntheory, expressiveness and application of tensor based algorithmic tools and\nprovides an alternative insight on these problems which have a long history in\nstatistical physics and computer science.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 20:00:25 GMT"}, {"version": "v2", "created": "Fri, 26 Sep 2014 17:58:59 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Biamonte", "Jacob D.", ""], ["Morton", "Jason", ""], ["Turner", "Jacob W.", ""]]}, {"id": "1405.7500", "submitter": "Joerg Endrullis", "authors": "J\\\"org Endrullis, Dimitri Hendriks, Jan Willem Klop, Andrew Polonsky", "title": "An Introduction to the Clocked Lambda Calculus", "comments": null, "journal-ref": null, "doi": "10.1017/S0960129515000389", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a brief introduction to the clocked lambda calculus, an extension of\nthe classical lambda calculus with a unary symbol tau used to witness the\nbeta-steps. In contrast to the classical lambda calculus, this extension is\ninfinitary strongly normalising and infinitary confluent. The infinitary normal\nforms are enriched Boehm Trees, which we call clocked Boehm Trees.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 08:59:37 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Hendriks", "Dimitri", ""], ["Klop", "Jan Willem", ""], ["Polonsky", "Andrew", ""]]}, {"id": "1405.7615", "submitter": "Dejanira Araiza-Illan", "authors": "Dejanira Araiza-Illan, Kerstin Eder and Arthur Richards", "title": "Formal Verification of Control Systems Properties with Theorem Proving", "comments": "Accepted to be presented in UKACC, Loughborough, UK, 2014. Final\n  reference to appear on publication", "journal-ref": "Proc. IEEE CONTROL (International Conference on Control) 2014, pp.\n  244 - 249, Loughborough, UK", "doi": "10.1109/CONTROL.2014.6915147", "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the deductive formal verification of high-level\nproperties of control systems with theorem proving, using the Why3 tool.\nProperties that can be verified with this approach include stability, feedback\ngain, and robustness, among others. For the systems, modelled in Simulink, we\npropose three main steps to achieve the verification: specifying the properties\nof interest over the signals within the model using Simulink blocks, an\nautomatic translation of the model into Why3, and the automatic verification of\nthe properties with theorem provers in Why3. We present a methodology to\nspecify the properties in the model and a library of relevant assertion blocks\n(logic expressions), currently in development. The functionality of the blocks\nin the Simulink models are automatically translated to Why3 as theories and\nverification goals by our tool implemented in MATLAB. A library of theories in\nWhy3 corresponding to each supported block has been developed to facilitate the\nprocess of translation. The goals are automatically verified in Why3 with\nrelevant theorem provers. A simple first-order discrete system is used to\nexemplify the specification of the Simulink model, the translation process from\nSimulink to the Why3 formal logic language, and the verification of Lyapunov\nstability.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 17:01:32 GMT"}, {"version": "v2", "created": "Sun, 8 Jun 2014 11:46:42 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Araiza-Illan", "Dejanira", ""], ["Eder", "Kerstin", ""], ["Richards", "Arthur", ""]]}, {"id": "1405.7739", "submitter": "Andrey Rybalchenko", "authors": "Andrey Rybalchenko", "title": "(Quantified) Horn Constraint Solving for Program Verification and\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how automatic tools for the verification of linear and branching time\nproperties of procedural, multi-threaded, and functional programs as well as\nprogram synthesis can be naturally and uniformly seen as solvers of constraints\nin form of (quantified) Horn clauses over background logical theories. Such a\nperspective can offer various advantages, e. g., a logical separation of\nconcerns between constraint generation (also known as generation of proof\nobligations) and constraint solving (also known as proof discovery), reuse of\nsolvers across different verifications tasks, and liberation of proof designers\nfrom low level algorithmic concerns and vice versa.\n  To appear in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 22:26:23 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Rybalchenko", "Andrey", ""]]}, {"id": "1405.7923", "submitter": "Petr Jancar", "authors": "Petr Jancar", "title": "Bisimulation Equivalence of First-Order Grammars", "comments": "This paper extends the version accepted to ICALP'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decidability proof for bisimulation equivalence of first-order grammars\n(finite sets of labelled rules for rewriting roots of first-order terms) is\npresented. The equivalence generalizes the DPDA (deterministic pushdown\nautomata) equivalence, and the result corresponds to the result achieved by\nSenizergues (1998, 2005) in the framework of equational graphs, or of PDA with\nrestricted epsilon-steps. The framework of classical first-order terms seems\nparticularly useful for providing a proof that should be understandable for a\nwider audience. We also discuss an extension to branching bisimilarity,\nannounced by Fu and Yin (2014).\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2014 17:32:24 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Jancar", "Petr", ""]]}, {"id": "1405.7962", "submitter": "David Monniaux", "authors": "Julien Henry (VERIMAG - IMAG), Mihail Asavoae (VERIMAG - IMAG), David\n  Monniaux (VERIMAG - IMAG), Claire Ma\\\"iza (VERIMAG - IMAG)", "title": "How to Compute Worst-Case Execution Time by Optimization Modulo Theory\n  and a Clever Encoding of Program Semantics", "comments": "ACM SIGPLAN/SIGBED Conference on Languages, Compilers and Tools for\n  Embedded Systems 2014, Edimbourg : United Kingdom (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems with hard real-time constraints, it is necessary to compute upper\nbounds on the worst-case execution time (WCET) of programs; the closer the\nbound to the real WCET, the better. This is especially the case of synchronous\nreactive control loops with a fixed clock; the WCET of the loop body must not\nexceed the clock period. We compute the WCET (or at least a close upper bound\nthereof) as the solution of an optimization modulo theory problem that takes\ninto account the semantics of the program, in contrast to other methods that\ncompute the longest path whether or not it is feasible according to these\nsemantics. Optimization modulo theory extends satisfiability modulo theory\n(SMT) to maximization problems. Immediate encodings of WCET problems into SMT\nyield formulas intractable for all current production-grade solvers; this is\ninherent to the DPLL(T) approach to SMT implemented in these solvers. By\nconjoining some appropriate \"cuts\" to these formulas, we considerably reduce\nthe computation time of the SMT-solver. We experimented our approach on a\nvariety of control programs, using the OTAWA analyzer both as baseline and as\nunderlying microarchitectural analysis for our analysis, and show notable\nimprovement on the WCET bound on a variety of benchmarks and control programs.\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2014 19:29:16 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Henry", "Julien", "", "VERIMAG - IMAG"], ["Asavoae", "Mihail", "", "VERIMAG - IMAG"], ["Monniaux", "David", "", "VERIMAG - IMAG"], ["Ma\u00efza", "Claire", "", "VERIMAG - IMAG"]]}]