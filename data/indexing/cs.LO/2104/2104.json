[{"id": "2104.00406", "submitter": "Dmitriy Zhuk", "authors": "Dmitriy Zhuk and Barnaby Martin", "title": "The complete classification for quantified equality constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We prove that QCSP$(\\mathbb{N};x=y\\rightarrow y=z)$ is PSpace-complete,\nsettling a question open for more than ten years. This completes the complexity\nclassification for quantified equality languages as a trichotomy between\nLogspace, NP-complete and PSpace-complete.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:32:24 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhuk", "Dmitriy", ""], ["Martin", "Barnaby", ""]]}, {"id": "2104.00762", "submitter": "Samuel Gruetter", "authors": "Thomas Bourgeat, Ian Clester, Andres Erbsen, Samuel Gruetter, Andrew\n  Wright, Adam Chlipala", "title": "A Multipurpose Formal RISC-V Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RISC-V is a relatively new, open instruction set architecture with a mature\necosystem and an official formal machine-readable specification. It is\ntherefore a promising playground for formal-methods research.\n  However, we observe that different formal-methods research projects are\ninterested in different aspects of RISC-V and want to simplify, abstract,\napproximate, or ignore the other aspects. Often, they also require different\nencoding styles, resulting in each project starting a new formalization\nfrom-scratch. We set out to identify the commonalities between projects and to\nrepresent the RISC-V specification as a program with holes that can be\ninstantiated differently by different projects.\n  Our formalization of the RISC-V specification is written in Haskell and\nleverages existing tools rather than requiring new domain-specific tools,\ncontrary to other approaches. To our knowledge, it is the first RISC-V\nspecification able to serve as the interface between a processor-correctness\nproof and a compiler-correctness proof, while supporting several other projects\nwith diverging requirements as well.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 20:47:23 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Bourgeat", "Thomas", ""], ["Clester", "Ian", ""], ["Erbsen", "Andres", ""], ["Gruetter", "Samuel", ""], ["Wright", "Andrew", ""], ["Chlipala", "Adam", ""]]}, {"id": "2104.00872", "submitter": "Matvey Soloviev", "authors": "Matvey Soloviev, Joseph Y. Halpern", "title": "Security Properties as Nested Causal Statements", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thinking in terms of causality helps us structure how different parts of a\nsystem depend on each other, and how interventions on one part of a system may\nresult in changes to other parts. Therefore, formal models of causality are an\nattractive tool for reasoning about security, which concerns itself with\nsafeguarding properties of a system against interventions that may be\nmalicious. As we show, many security properties are naturally expressed as\nnested causal statements: not only do we consider what caused a particular\nundesirable effect, but we also consider what caused this causal relationship\nitself to hold. We present a natural way to extend the Halpern-Pearl (HP)\nframework for causality to capture such nested causal statements. This\nextension adds expressivity, enabling the HP framework to distinguish between\ncausal scenarios that it could not previously naturally tell apart. We moreover\nrevisit some design decisions of the HP framework that were made with\nnon-nested causal statements in mind, such as the choice to treat specific\nvalues of causal variables as opposed to the variables themselves as causes,\nand may no longer be appropriate for nested ones.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 03:29:00 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Soloviev", "Matvey", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2104.01052", "submitter": "Jacques Fleuriot", "authors": "Carlin MacKenzie, Jacques Fleuriot and James Vaughan", "title": "An Evaluation of the Archive of Formal Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Archive of Formal Proofs (AFP) is an online repository of formal proofs\nfor the Isabelle proof assistant. It serves as a central location for\npublishing, discovering, and viewing libraries of proofs. We conducted an\nonline survey in November 2020 to assess the suitability of the website. In\nthis report, we present and discuss the results, which showed that long-term\nusers of the website are generally satisfied with the AFP but that there are a\nnumber of areas, such as navigation, search and script browsing, that need\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 14:02:39 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["MacKenzie", "Carlin", ""], ["Fleuriot", "Jacques", ""], ["Vaughan", "James", ""]]}, {"id": "2104.01193", "submitter": "Ana Ozaki", "authors": "Ana Ozaki", "title": "Learning Description Logic Ontologies. Five Approaches. Where Do They\n  Stand?", "comments": null, "journal-ref": "KI Kunstliche Intelligenz (2020) 34 317-327", "doi": "10.1007/s13218-020-00656-9", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The quest for acquiring a formal representation of the knowledge of a domain\nof interest has attracted researchers with various backgrounds into a diverse\nfield called ontology learning. We highlight classical machine learning and\ndata mining approaches that have been proposed for (semi-)automating the\ncreation of description logic (DL) ontologies. These are based on association\nrule mining, formal concept analysis, inductive logic programming,\ncomputational learning theory, and neural networks. We provide an overview of\neach approach and how it has been adapted for dealing with DL ontologies.\nFinally, we discuss the benefits and limitations of each of them for learning\nDL ontologies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:36:45 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ozaki", "Ana", ""]]}, {"id": "2104.01195", "submitter": "Daniel O. Martinez-Rivillas", "authors": "Daniel O. Mart\\'inez-Rivillas and Ruy J.G.B. de Queiroz", "title": "Solving Homotopy Domain Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to get $\\lambda$-models with a rich structure of $\\infty$-groupoid,\nwhich we call \"homotopy $\\lambda$-models\", a general technique is described for\nsolving domain equations on any cartesian closed $\\infty$-category (c.c.i.)\nwith enough points. Finally, the technique is applied in a particular c.c.i.,\nwhere some examples of homotopy $\\lambda$-models are given.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:45:39 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Mart\u00ednez-Rivillas", "Daniel O.", ""], ["de Queiroz", "Ruy J. G. B.", ""]]}, {"id": "2104.01358", "submitter": "Ugo de'Liguoro", "authors": "Ugo de'Liguoro and Riccardo Treglia", "title": "Intersection Types for a Computational Lambda-Calculus with Global State", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the semantics of an untyped lambda-calculus equipped with operators\nrepresenting read and write operations from and to a global state. We adopt the\nmonadic approach to model side effects and treat read and write as algebraic\noperations over a computational monad. We introduce an operational semantics\nand a type assignment system of intersection types, and prove that types are\ninvariant under reduction and expansion of term and state configurations, and\ncharacterize convergent terms via their typings.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 09:29:27 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["de'Liguoro", "Ugo", ""], ["Treglia", "Riccardo", ""]]}, {"id": "2104.01392", "submitter": "Roberto Gorrieri", "authors": "Roberto Gorrieri", "title": "Place Bisimilarity is Decidable, Indeed!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Place bisimilarity is a behavioral equivalence for finite Petri nets,\nproposed by Schnoebelen and co-workers in 1991. Differently from all the other\nbehavioral relations proposed so far, a place bisimulation is not defined over\nthe markings of a finite net, rather over its places, which are finitely many.\nHowever, place bisimilarity is not coinductive, as the union of place\nbisimulations may be not a place bisimulation. Place bisimilarity was claimed\ndecidable in [1], even if the algorithm used to this aim [2] does not\ncharacterize this equivalence, rather the unique maximal place bisimulation\nwhich is also an equivalence relation; hence, its decidability was not proved.\nHere we show that it is possible to decide place bisimilarity with a simple,\nyet inefficient, algorithm, which essentially scans all the place relations\n(which are finitely many) to check whether they are place bisimulations.\nMoreover, we propose a slightly coarser variant, we call d-place bisimilarity,\nthat we conjecture to be the coarsest equivalence, fully respecting causality\nand branching time, to be decidable on finite Petri nets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 12:59:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gorrieri", "Roberto", ""]]}, {"id": "2104.01667", "submitter": "Rene Haberland", "authors": "Ren\\'e Haberland", "title": "A Logical Programming Language as an Instrument for Specifying and\n  Verifying Dynamic Memory", "comments": "209 pages, 97 figures, 6 appendices", "journal-ref": "Dissertation, Thesis, 2017", "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL cs.SC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a Prolog-dialect for the found and prioritised problems on\nexpressibility and automation. Given some given C-like program, if dynamic\nmemory is allocated, altered and freed on runtime, then a description of\ndesired dynamic memory is a heap specification. The check of calculated memory\nstate against a given specification is dynamic memory verification. This\ncontribution only considers formal specification and verification in a Hoare\ncalculus. Issues found include: invalid assignment, (temporary) unavailable\ndata in memory cells, excessive memory allocation, (accidental) heap alteration\nin unexpected regions and others. Excessive memory allocation is nowadays\nsuccessfully resolved by memory analysers like Valgrind. Essentially, papers in\nthose areas did not bring any big breakthrough. Possible reasons may also\ninclude the decrease of tension due to more available memory and parallel\nthreads. However, starting with Apt, problems related to variable modes have\nnot yet been resolved -- neither entirely nor in an acceptable way. Research\ncontributions over the last decades show again and again that heap issues\nremain and remain complex and still important. A significant contribution was\nreached in 2016 by Peter O'Hearn, who accepted the G\\\"{o}del prize for his\nparallel approach on a spatial heap operation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 19:18:07 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Haberland", "Ren\u00e9", ""]]}, {"id": "2104.02287", "submitter": "Wesley Holliday", "authors": "Matthew Harrison-Trainor, Wesley H. Holliday, and Thomas F. Icard III", "title": "Preferential Structures for Comparative Probabilistic Reasoning", "comments": "Postprint of AAAI 2017 paper, corrected to include a distinguished\n  set of states in Definitions 2-3 and 5 (resp. before Theorem 3) to match the\n  appropriate special case of the semantics of Holliday and Icard 2013 (resp.\n  van der Hoek 1996)", "journal-ref": "AAAI Conference on Artificial Intelligence, 2017, pp. 1135-1141", "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative and quantitative approaches to reasoning about uncertainty can\nlead to different logical systems for formalizing such reasoning, even when the\nlanguage for expressing uncertainty is the same. In the case of reasoning about\nrelative likelihood, with statements of the form $\\varphi\\succsim\\psi$\nexpressing that $\\varphi$ is at least as likely as $\\psi$, a standard\nqualitative approach using preordered preferential structures yields a\ndramatically different logical system than a quantitative approach using\nprobability measures. In fact, the standard preferential approach validates\nprinciples of reasoning that are incorrect from a probabilistic point of view.\nHowever, in this paper we show that a natural modification of the preferential\napproach yields exactly the same logical system as a probabilistic\napproach--not using single probability measures, but rather sets of probability\nmeasures. Thus, the same preferential structures used in the study of\nnon-monotonic logics and belief revision may be used in the study of\ncomparative probabilistic reasoning based on imprecise probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 05:00:20 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Harrison-Trainor", "Matthew", ""], ["Holliday", "Wesley H.", ""], ["Icard", "Thomas F.", "III"]]}, {"id": "2104.02466", "submitter": "Caterina Urban", "authors": "Caterina Urban and Antoine Min\\'e", "title": "A Review of Formal Methods applied to Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We review state-of-the-art formal methods applied to the emerging field of\nthe verification of machine learning systems. Formal methods can provide\nrigorous correctness guarantees on hardware and software systems. Thanks to the\navailability of mature tools, their use is well established in the industry,\nand in particular to check safety-critical applications as they undergo a\nstringent certification process. As machine learning is becoming more popular,\nmachine-learned components are now considered for inclusion in critical\nsystems. This raises the question of their safety and their verification. Yet,\nestablished formal methods are limited to classic, i.e. non machine-learned\nsoftware. Applying formal methods to verify systems that include machine\nlearning has only been considered recently and poses novel challenges in\nsoundness, precision, and scalability.\n  We first recall established formal methods and their current use in an\nexemplar safety-critical field, avionic software, with a focus on abstract\ninterpretation based techniques as they provide a high level of scalability.\nThis provides a golden standard and sets high expectations for machine learning\nverification. We then provide a comprehensive and detailed review of the formal\nmethods developed so far for machine learning, highlighting their strengths and\nlimitations. The large majority of them verify trained neural networks and\nemploy either SMT, optimization, or abstract interpretation techniques. We also\ndiscuss methods for support vector machines and decision tree ensembles, as\nwell as methods targeting training and data preparation, which are critical but\noften neglected aspects of machine learning. Finally, we offer perspectives for\nfuture research directions towards the formal verification of machine learning\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:48:17 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 15:32:51 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Urban", "Caterina", ""], ["Min\u00e9", "Antoine", ""]]}, {"id": "2104.02536", "submitter": "Grigory Devadze", "authors": "Grigory Devadze, Lars Flessing, Stefan Streif", "title": "Extraction of a computer-certified ODE solver", "comments": "arXiv admin note: text overlap with arXiv:2006.09884", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reliably determining system trajectories is essential in many analysis and\ncontrol design approaches. To this end, an initial value problem has to be\nusually solved via numerical algorithms which rely on a certain software\nrealization. Because software realizations can be error-prone, proof assistants\nmay be used to verify the underlying mathematical concepts and corresponding\nalgorithms. In this work we present a computer-certified formalization of the\nsolution of the initial value problem of ordinary differential equations. The\nconcepts are performed in the framework of constructive analysis and the proofs\nare written in the \\texttt{Minlog} proof system. We show the extraction of a\nprogram, which solves an ODE numerically and provide some possible optimization\nregarding the efficiency. Finally, we provide numerical experiments to\ndemonstrate how programs of a certain high level of abstraction can be obtained\nefficiently. The presented concepts may also be viewed as a part of preliminary\nwork for the development of formalized nonlinear control theory, hence offering\nthe possibility of computer-assisted controller design and program extraction\nfor the controller implementation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:27:13 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Devadze", "Grigory", ""], ["Flessing", "Lars", ""], ["Streif", "Stefan", ""]]}, {"id": "2104.02549", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus and Fredrik Nordvall Forsberg and Chuangjie Xu", "title": "Connecting Constructive Notions of Ordinals in Homotopy Type Theory", "comments": "main part (16 pages) published at MFCS'21; arXiv version contains an\n  appendix with proofs (27 pages total)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical set theory, there are many equivalent ways to introduce\nordinals. In a constructive setting, however, the different notions split\napart, with different advantages and disadvantages for each. We consider three\ndifferent notions of ordinals in homotopy type theory, and show how they relate\nto each other: A notation system based on Cantor normal forms, a refined notion\nof Brouwer trees (inductively generated by zero, successor and countable\nlimits), and wellfounded extensional orders. For Cantor normal forms, most\nproperties are decidable, whereas for wellfounded extensional transitive\norders, most are undecidable. Formulations for Brouwer trees are usually\npartially decidable. We demonstrate that all three notions have properties\nexpected of ordinals: their order relations, although defined differently in\neach case, are all extensional and wellfounded, and the usual arithmetic\noperations can be defined in each case. We connect these notions by\nconstructing structure preserving embeddings of Cantor normal forms into\nBrouwer trees, and of these in turn into wellfounded extensional orders. We\nhave formalised most of our results in cubical Agda.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:41:27 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 11:56:03 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kraus", "Nicolai", ""], ["Forsberg", "Fredrik Nordvall", ""], ["Xu", "Chuangjie", ""]]}, {"id": "2104.02563", "submitter": "Stefan Mengel", "authors": "Stefan Mengel, Friedrich Slivovsky", "title": "Proof Complexity of Symbolic QBF Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and investigate symbolic proof systems for Quantified Boolean\nFormulas (QBF) operating on Ordered Binary Decision Diagrams (OBDDs). These\nsystems capture QBF solvers that perform symbolic quantifier elimination, and\nas such admit short proofs of formulas of bounded path-width and quantifier\ncomplexity. As a consequence, we obtain exponential separations from standard\nclausal proof systems, specifically (long-distance) QU-Resolution and IR-Calc.\n  We further develop a lower bound technique for symbolic QBF proof systems\nbased on strategy extraction that lifts known lower bounds from communication\ncomplexity. This allows us to derive strong lower bounds against symbolic QBF\nproof systems that are independent of the variable ordering of the underlying\nOBDDs, and that hold even if the proof system is allowed access to an\nNP-oracle.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 15:01:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Mengel", "Stefan", ""], ["Slivovsky", "Friedrich", ""]]}, {"id": "2104.02973", "submitter": "Pierre Gutierrez", "authors": "Antoine Cordier, Deepan Das, and Pierre Gutierrez", "title": "Active learning using weakly supervised signals for quality inspection", "comments": "8 pages, 3 Figures, QCAV 2021 conference (proceedings published in\n  SPIE)", "journal-ref": null, "doi": "10.1117/12.2586595", "report-no": null, "categories": "cs.CV cs.AI cs.LO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Because manufacturing processes evolve fast, and since production visual\naspect can vary significantly on a daily basis, the ability to rapidly update\nmachine vision based inspection systems is paramount. Unfortunately, supervised\nlearning of convolutional neural networks requires a significant amount of\nannotated images for being able to learn effectively from new data.\nAcknowledging the abundance of continuously generated images coming from the\nproduction line and the cost of their annotation, we demonstrate it is possible\nto prioritize and accelerate the annotation process. In this work, we develop a\nmethodology for learning actively, from rapidly mined, weakly (i.e. partially)\nannotated data, enabling a fast, direct feedback from the operators on the\nproduction line and tackling a big machine vision weakness: false positives. We\nalso consider the problem of covariate shift, which arises inevitably due to\nchanging conditions during data acquisition. In that regard, we show\ndomain-adversarial training to be an efficient way to address this issue.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 07:49:07 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cordier", "Antoine", ""], ["Das", "Deepan", ""], ["Gutierrez", "Pierre", ""]]}, {"id": "2104.02998", "submitter": "Petr Golovach", "authors": "Fedor V. Fomin, Petr A. Golovach, Dimitrios M. Thilikos", "title": "Parameterized Complexity of Elimination Distance to First-Order Logic\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The elimination distance to some target graph property P is a general graph\nmodification parameter introduced by Bulian and Dawar. We initiate the study of\nelimination distances to graph properties expressible in first-order logic. We\ndelimit the problem's fixed-parameter tractability by identifying sufficient\nand necessary conditions on the structure of prefixes of first-order logic\nformulas. Our main result is the following meta-theorem: for every graph\nproperty P expressible by a first order-logic formula \\phi\\in \\Sigma_3, that\nis, of the form \\phi=\\exists x_1\\exists x_2\\cdots \\exists x_r \\forall\ny_1\\forall y_2\\cdots \\forall y_s \\exists z_1\\exists z_2\\cdots \\exists z_t \\psi,\nwhere \\psi is a quantifier-free first-order formula, checking whether the\nelimination distance of a graph to P does not exceed k, is fixed-parameter\ntractable parameterized by k. Properties of graphs expressible by formulas from\n\\Sigma_3 include being of bounded degree, excluding a forbidden subgraph, or\ncontaining a bounded dominating set. We complement this theorem by showing that\nsuch a general statement does not hold for formulas with even slightly more\nexpressive prefix structure: there are formulas \\phi\\in \\Pi_3, for which\ncomputing elimination distance is W[2]-hard.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:55:36 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2104.04095", "submitter": "Louis Warren", "authors": "Louis Warren", "title": "First-order natural deduction in Agda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agda is a dependently-typed functional programming language, based on an\nextension of intuitionistic Martin-L\\\"of type theory. We implement first order\nnatural deduction in Agda. We use Agda's type checker to verify the correctness\nof natural deduction proofs, and also prove properties of natural deduction,\nusing Agda's proof assistant functionality. This implementation corresponds to\na formalisation of natural deduction in constructive type theory, and the\nproofs are verified by Agda to be correct (under the assumption that Agda\nitself is correct).\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 22:06:09 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Warren", "Louis", ""]]}, {"id": "2104.04224", "submitter": "Zafer Esen", "authors": "Zafer Esen and Philipp R\\\"ummer", "title": "A Theory of Heap for Constrained Horn Clauses (Extended Technical\n  Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Horn Clauses (CHCs) are an intermediate program representation\nthat can be generated by several verification tools, and that can be processed\nand solved by a number of Horn solvers. One of the main challenges when using\nCHCs in verification is the encoding of heap-allocated data-structures: such\ndata-structures are today either represented explicitly using the theory of\narrays, or transformed away with the help of invariants or refinement types,\ndefeating the purpose of CHCs as a representation that is language-independent\nas well as agnostic of the algorithm implemented by the Horn solver. This paper\npresents an SMT-LIB theory of heap tailored to CHCs, with the goal of enabling\na standard interchange format for programs with heap data-structures. We\nintroduce the syntax of the theory of heap, define its semantics in terms of\naxioms and using a reduction to SMT-LIB arrays and data-types, and discuss its\nproperties and outline possible extensions and future work.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 07:34:18 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Esen", "Zafer", ""], ["R\u00fcmmer", "Philipp", ""]]}, {"id": "2104.04284", "submitter": "David Fuenmayor", "authors": "David Fuenmayor", "title": "Topological semantics for paraconsistent and paracomplete logics in\n  Isabelle/HOL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We encode a topological semantics for paraconsistent and paracomplete logics\nenriched with recovery operators, by drawing upon early works on topological\nBoolean algebras (by Kuratowski, Zarycki, McKinsey & Tarski, etc.). This work\nexemplarily illustrates the shallow semantical embedding approach using\nIsabelle/HOL and shows how we can effectively harness theorem provers, model\nfinders and \"hammers\" for reasoning with quantified non-classical logics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:09:40 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Fuenmayor", "David", ""]]}, {"id": "2104.04313", "submitter": "Minna Hirvonen", "authors": "Miika Hannula, Minna Hirvonen, and Juha Kontinen", "title": "On elementary logics for quantitative dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study logics in the framework of probabilistic team semantics\nand over metafinite structures. Our work is paralleled by the recent\ndevelopment of novel axiomatizable and tractable logics in team semantics that\nare closed under the Boolean negation. Our logics employ new probabilistic\natoms that resemble so-called extended atoms from the team semantics\nliterature. We also define counterparts of our logics over metafinite\nstructures and show that all of our logics can be translated into functional\nfixed point logic implying a polynomial time upper bound for data complexity\nwith respect to BSS-computations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 11:35:11 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Hannula", "Miika", ""], ["Hirvonen", "Minna", ""], ["Kontinen", "Juha", ""]]}, {"id": "2104.04566", "submitter": "Jamie Tucker-Foltz", "authors": "Jamie Tucker-Foltz", "title": "Inapproximability of Unique Games in Fixed-Point Logic with Counting", "comments": "Extended version of LICS 2021 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the extent to which it is possible to approximate the optimal value\nof a Unique Games instance in Fixed-Point Logic with Counting (FPC). We prove\ntwo new FPC-inexpressibility results for Unique Games: the existence of a (1/2,\n1/3 + delta)-inapproximability gap, and inapproximability to within any\nconstant factor. Previous recent work has established similar\nFPC-inapproximability results for a small handful of other problems. Our\nconstruction builds upon some of these ideas, but contains a novel technique.\nWhile most FPC-inexpressibility results are based on variants of the\nCFI-construction, ours is significantly different.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 18:51:51 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Tucker-Foltz", "Jamie", ""]]}, {"id": "2104.04589", "submitter": "Pablo Barenbaum", "authors": "Pablo Barenbaum and Teodoro Freund", "title": "A Constructive Logic with Classical Proofs and Refutations (Extended\n  Version)", "comments": "Accepted in LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a conservative extension of classical propositional logic\ndistinguishing between four modes of statement: a proposition may be affirmed\nor denied, and it may be strong or classical. Proofs of strong propositions\nmust be constructive in some sense, whereas proofs of classical propositions\nproceed by contradiction. The system, in natural deduction style, is shown to\nbe sound and complete with respect to a Kripke semantics. We develop the system\nfrom the perspective of the propositions-as-types correspondence by deriving a\nterm assignment system with confluent reduction. The proof of strong\nnormalization relies on a translation to System F with Mendler-style recursion.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 19:58:07 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 19:46:17 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Barenbaum", "Pablo", ""], ["Freund", "Teodoro", ""]]}, {"id": "2104.04758", "submitter": "Sam Thompson", "authors": "Dominik D. Freydenberger, Sam M. Thompson", "title": "Splitting Spanner Atoms: A Tool for Acyclic Core Spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates regex CQs with string equalities (SERCQs), a subclass\nof core spanners. As shown by Freydenberger, Kimelfeld, and Peterfreund (PODS\n2018), these queries are intractable, even if restricted to acyclic queries.\nThis previous result defines acyclicity by treating regex formulas as atoms. In\ncontrast to this, we propose an alternative definition by converting SERCQs\ninto FC-CQs -- conjunctive queries in FC, a logic that is based on word\nequations. We introduce a way to decompose word equations of unbounded arity\ninto a conjunction of binary word equations. If the result of the decomposition\nis acyclic, then evaluation and enumeration of results become tractable. The\nmain result of this work is an algorithm that decides in polynomial time\nwhether an FC-CQ can be decomposed into an acyclic FC-CQ. We also give an\nefficient conversion from synchronized SERCQs to FC-CQs with regular\nconstraints. As a consequence, tractability results for acyclic relational CQs\ndirectly translate to a large class of SERCQs.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 13:15:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Freydenberger", "Dominik D.", ""], ["Thompson", "Sam M.", ""]]}, {"id": "2104.04990", "submitter": "Raven Beutner", "authors": "Raven Beutner, Luke Ong", "title": "On Probabilistic Termination of Functional Programs with Continuous\n  Distributions", "comments": "PLDI 2021", "journal-ref": null, "doi": "10.1145/3453483.3454111", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study termination of higher-order probabilistic functional programs with\nrecursion, stochastic conditioning and sampling from continuous distributions.\n  Reasoning about the termination probability of programs with continuous\ndistributions is hard, because the enumeration of terminating executions cannot\nprovide any non-trivial bounds. We present a new operational semantics based on\ntraces of intervals, which is sound and complete with respect to the standard\nsampling-based semantics, in which (countable) enumeration can provide\narbitrarily tight lower bounds. Consequently we obtain the first proof that\ndeciding almost-sure termination (AST) for programs with continuous\ndistributions is $\\Pi^0_2$-complete. We also provide a compositional\nrepresentation of our semantics in terms of an intersection type system.\n  In the second part, we present a method of proving AST for non-affine\nprograms, i.e., recursive programs that can, during the evaluation of the\nrecursive body, make multiple recursive calls (of a first-order function) from\ndistinct call sites. Unlike in a deterministic language, the number of\nrecursion call sites has direct consequences on the termination probability.\nOur framework supports a proof system that can verify AST for programs that are\nwell beyond the scope of existing methods.\n  We have constructed prototype implementations of our method of computing\nlower bounds of termination probability, and AST verification.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 10:57:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Beutner", "Raven", ""], ["Ong", "Luke", ""]]}, {"id": "2104.05065", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "The algebraic structure of the densification and the sparsification\n  tasks for CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tractability of certain CSPs for dense or sparse instances is known from\nthe 90s. Recently, the densification and the sparsification of CSPs were\nformulated as computational tasks and the systematical study of their\ncomputational complexity was initiated.\n  We approach this problem by introducing the densification operator, i.e. the\nclosure operator that, given an instance of a CSP, outputs all constraints that\nare satisfied by all of its solutions. According to the Galois theory of\nclosure operators, any such operator is related to a certain implicational\nsystem (or, a functional dependency) $\\Sigma$. We are specifically interested\nin those classes of fixed-template CSPs, parameterized by constraint languages\n$\\Gamma$, for which the size of an implicational system $\\Sigma$ is a\npolynomial in the number of variables $n$. We show that in the Boolean case,\n$\\Sigma$ is of polynomial size if and only if $\\Gamma$ is of bounded width. For\nsuch languages, $\\Sigma$ can be computed in log-space or in a logarithmic time\nwith a polynomial number of processors. Given an implicational system $\\Sigma$,\nthe densification task is equivalent to the computation of the closure of input\nconstraints. The sparsification task is equivalent to the computation of the\nminimal key. This leads to ${\\mathcal O}({\\rm poly}(n)\\cdot N^2)$-algorithm for\nthe sparsification task where $N$ is the number of non-redundant\nsparsifications of an original CSP.\n  Finally, we give a complete classification of constraint languages over the\nBoolean domain for which the densification problem is tractable.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 18:10:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Takhanov", "Rustem", ""]]}, {"id": "2104.05128", "submitter": "Dan Plyukhin", "authors": "Dan Plyukhin and Gul Agha", "title": "A Scalable Algorithm for Decentralized Actor Termination Detection", "comments": "33 pages, 4 figures. Extended version of CONCUR 2020 paper\n  arXiv:2007.10553", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic garbage collection (GC) prevents certain kinds of bugs and reduces\nprogramming overhead. GC techniques for sequential programs are based on\nreachability analysis. However, testing reachability from a root set is\ninadequate for determining whether an actor is garbage: Observe that an\nunreachable actor may send a message to a reachable actor. Instead, it is\nsufficient to check termination (sometimes also called quiescence): an actor is\nterminated if it is not currently processing a message and cannot receive a\nmessage in the future. Moreover, many actor frameworks provide all actors with\naccess to file I/O or external storage; without inspecting an actor's internal\ncode, it is necessary to check that the actor has terminated to ensure that it\nmay be garbage collected in these frameworks. Previous algorithms to detect\nactor garbage require coordination mechanisms such as causal message delivery\nor nonlocal monitoring of actors for mutation. Such coordination mechanisms\nadversely affect concurrency and are therefore expensive in distributed\nsystems. We present a low-overhead reference listing technique (called DRL) for\ntermination detection in actor systems. DRL is based on asynchronous local\nsnapshots and message-passing between actors. This enables a decentralized\nimplementation and transient network partition tolerance. The paper provides a\nformal description of DRL, shows that all actors identified as garbage have\nindeed terminated (safety), and that all terminated actors--under certain\nreasonable assumptions--will eventually be identified (liveness).\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 22:36:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Plyukhin", "Dan", ""], ["Agha", "Gul", ""]]}, {"id": "2104.05207", "submitter": "Cezary Kaliszyk", "authors": "Liao Zhang, Lasse Blaauwbroek, Bartosz Piotrowski, Prokop \\v{C}ern\\'y,\n  Cezary Kaliszyk, and Josef Urban", "title": "Online Machine Learning Techniques for Coq: A Comparison", "comments": "Intelligent Computer Mathematics 14th International Conference, CICM\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparison of several online machine learning techniques for\ntactical learning and proving in the Coq proof assistant. This work builds on\ntop of Tactician, a plugin for Coq that learns from proofs written by the user\nto synthesize new proofs. Learning happens in an online manner, meaning that\nTactician's machine learning model is updated immediately every time the user\nperforms a step in an interactive proof. This has important advantages compared\nto the more studied offline learning systems: (1) it provides the user with a\nseamless, interactive experience with Tactician and, (2) it takes advantage of\nlocality of proof similarity, which means that proofs similar to the current\nproof are likely to be found close by. We implement two online methods, namely\napproximate k-nearest neighbors based on locality sensitive hashing forests and\nrandom decision forests. Additionally, we conduct experiments with gradient\nboosted trees in an offline setting using XGBoost. We compare the relative\nperformance of Tactician using these three learning methods on Coq's standard\nlibrary.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 05:12:35 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 08:11:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Liao", ""], ["Blaauwbroek", "Lasse", ""], ["Piotrowski", "Bartosz", ""], ["\u010cern\u00fd", "Prokop", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "2104.05256", "submitter": "Francois Clement", "authors": "Sylvie Boldo, Fran\\c{c}ois Cl\\'ement, Florian Faissole, Vincent\n  Martin, Micaela Mayero", "title": "A Coq Formalization of Lebesgue Integration of Nonnegative Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration, just as much as differentiation, is a fundamental calculus tool\nthat is widely used in many scientific domains. Formalizing the mathematical\nconcept of integration and the associated results in a formal proof assistant\nhelps providing the highest confidence on the correction of numerical programs\ninvolving the use of integration, directly or indirectly. By its capability to\nextend the (Riemann) integral to a wide class of irregular functions, and to\nfunctions defined on more general spaces than the real line, the Lebesgue\nintegral is considered as perfectly suited for use in mathematical fields such\nas probability theory, numerical mathematics, and real analysis. In this\narticle, we present the Coq formalization of $\\sigma$-algebras, measures,\nsimple functions, and integration of nonnegative measurable functions, up to\nthe full formal proofs of the Beppo Levi (monotone convergence) theorem and\nFatou's lemma. More than a plain formalization of known literature, we present\nseveral design choices made to balance the harmony between mathematical\nreadability and usability of Coq theorems. These results are a first milestone\ntowards the formalization of $L^p$~spaces such as Banach spaces.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 07:45:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Boldo", "Sylvie", ""], ["Cl\u00e9ment", "Fran\u00e7ois", ""], ["Faissole", "Florian", ""], ["Martin", "Vincent", ""], ["Mayero", "Micaela", ""]]}, {"id": "2104.05348", "submitter": "Dmitriy Traytel", "authors": "Basil F\\\"urer, Andreas Lochbihler, Joshua Schneider, Dmitriy Traytel", "title": "Quotients of Bounded Natural Functors", "comments": "Extended version of homonymous IJCAR 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The functorial structure of type constructors is the foundation for many\ndefinition and proof principles in higher-order logic (HOL). For example,\ninductive and coinductive datatypes can be built modularly from bounded natural\nfunctors (BNFs), a class of well-behaved type constructors. Composition,\nfixpoints, and, under certain conditions, subtypes are known to preserve the\nBNF structure. In this article, we tackle the preservation question for\nquotients, the last important principle for introducing new types in HOL. We\nidentify sufficient conditions under which a quotient inherits the BNF\nstructure from its underlying type. Surprisingly, lifting the structure in the\nobvious manner fails for some quotients, a problem that also affects the\nquotients of polynomial functors used in the Lean proof assistant. We provide a\nstrictly more general lifting scheme that supports such problematic quotients.\nWe extend the Isabelle/HOL proof assistant with a command that automates the\nregistration of a quotient type as a BNF, reducing the proof burden on the user\nfrom the full set of BNF axioms to our inheritance conditions. We demonstrate\nthe command's usefulness through several case studies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:56:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["F\u00fcrer", "Basil", ""], ["Lochbihler", "Andreas", ""], ["Schneider", "Joshua", ""], ["Traytel", "Dmitriy", ""]]}, {"id": "2104.05438", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Actors -- A Process Algebra Based Approach", "comments": "143 pages, 12 figures, 29 tables. arXiv admin note: text overlap with\n  arXiv:2101.05140", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model actors based on truly concurrent process algebra, and capture the\nactor model in the following characteristics: (1) Concurrency: all actors\nexecute concurrently; (2) Asynchrony: an actor receives and sends messages\nasynchronously; (3) Uniqueness: an actor has a unique name and the associate\nunique mail box name; (4) Concentration: an actor focuses on the processing\nmessages, including some local computations, creations of some new actors, and\nsending some messages to other actors; (5) Communication Dependency: the only\nway of affecting an actor is sending a message to it; (6) Abstraction: except\nfor the receiving and sending message, and creating new actors, the local\ncomputations are abstracted; (7) Persistence: an actor does not disappear after\nprocessing a message. Truly concurrent process algebra has rich expressive\nability to model the above characteristics of actors, and more importantly,\nthey are models for true concurrency, Comparing with other models of actors,\nthe truly concurrent process algebra based model has the following advantages:\n(1) The truly concurrent process algebra has rich expressive abilities to\ndescribe almost all characteristics of actors, especially for asynchronous\ncommunication, actor creation, recursion, abstraction, etc; (2) The truly\nconcurrent process algebra and actors are all models for true concurrency, and\nhave inborn intimacy; (3) The truly concurrent process algebra has a firm\nsemantics foundation and a powerful proof theory, the correctness of an actor\nsystem can be proven easily.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:25:21 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "2104.05558", "submitter": "Francesco Dagnino", "authors": "Francesco Dagnino", "title": "A meta-theory for big-step semantics", "comments": "arXiv admin note: text overlap with arXiv:2002.08738", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well-known that big-step semantics is not able to distinguish stuck and\nnon-terminating computations. This is a strong limitation as it makes very\ndifficult to reason about properties involving infinite computations, such as\ntype soundness, which cannot even be expressed. To face this problem, we\ndevelop a systematic study of big-step semantics: we introduce an abstract\ndefinition of what a big-step semantics is, we formalise the evaluation\nalgorithm implicitly associated with any big-step semantics and we identify\ncomputations with executions of such an algorithm, thus recovering the\ndistinction between stuckness an non-termination. Then, we define constructions\nyielding an extended version of a given arbitrary big-step semantics, where\nsuch a difference is made explicit. Building on such constructions, we describe\na general proof technique to show that a predicate is sound, that is, prevents\nstuck computation, with respect to a big-step semantics. The extended semantics\nare exploited in the meta-theory, notably they are necessary to show that the\nproof technique works. However, they remain transparent when using the proof\ntechnique, since it consists in checking three conditions on the original rules\nonly. We illustrate the technique by several examples, showing that it is\napplicable also in cases where subject reduction does not hold, hence the\nstandard technique for small-step semantics cannot be used.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:24:24 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 21:22:20 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Dagnino", "Francesco", ""]]}, {"id": "2104.06016", "submitter": "Guillaume Geoffroy", "authors": "Guillaume Geoffroy (UNIBO, FOCUS)", "title": "Extensional Denotational Semantics of Higher-Order Probabilistic\n  Programs, Beyond the Discrete Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a mathematical structure that can give extensional denotational\nsemantics to higher-order probabilistic programs. It is not limited to discrete\nprobabilities, and it is compatible with integration in a way the models that\nhave been proposed before are not. It is organised as a model of propositional\nlinear logic in which all the connectives have intuitive probabilistic\ninterpretations. In addition, it has least fixed points for all maps, so it can\ninterpret recursion.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:31:53 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Geoffroy", "Guillaume", "", "UNIBO, FOCUS"]]}, {"id": "2104.06085", "submitter": "Dylan Bellier", "authors": "Dylan Bellier (1), Massimo Benerecetti (2), Dario Della Monica (3),\n  Fabio Mogavero (2) ((1) UnivRennes (2) Universit\\`a di Napoli Federico II (3)\n  Universit\\`a di Udine)", "title": "Good-for-Game QPTL: An Alternating Hodges Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  An extension of QPTL is considered where functional dependencies among the\nquantified variables can be restricted in such a way that their current values\nare independent of the future values of the other variables. This restriction\nis tightly connected to the notion of behavioral strategies in game-theory and\nallows the resulting logic to naturally express game-theoretic concepts. The\nfragment where only restricted quantifications are considered, called\nbehavioral quantifications, can be decided, for both model checking and\nsatisfiability, in 2ExpTime and is expressively equivalent to QPTL, though\nsignificantly less succinct.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 10:42:45 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 14:36:01 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bellier", "Dylan", ""], ["Benerecetti", "Massimo", ""], ["Della Monica", "Dario", ""], ["Mogavero", "Fabio", ""]]}, {"id": "2104.06178", "submitter": "Geoffrey Litt", "authors": "Daniel Jackson, Valerie Richmond, Mike Wang, Jeff Chow, Uriel\n  Guajardo, Soonho Kong, Sergio Campos, Geoffrey Litt, and Nikos Arechiga", "title": "Certified Control: An Architecture for Verifiable Safety of Autonomous\n  Vehicles", "comments": "18 pages + 15 page Appendix, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LO cs.SE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widespread adoption of autonomous cars will require greater confidence in\ntheir safety than is currently possible. Certified control is a new safety\narchitecture whose goal is two-fold: to achieve a very high level of safety,\nand to provide a framework for justifiable confidence in that safety. The key\nidea is a runtime monitor that acts, along with sensor hardware and low-level\ncontrol and actuators, as a small trusted base, ensuring the safety of the\nsystem as a whole.\n  Unfortunately, in current systems complex perception makes the verification\neven of a runtime monitor challenging. Unlike traditional runtime monitoring,\ntherefore, a certified control monitor does not perform perception and analysis\nitself. Instead, the main controller assembles evidence that the proposed\naction is safe into a certificate that is then checked independently by the\nmonitor. This exploits the classic gap between the costs of finding and\nchecking. The controller is assigned the task of finding the certificate, and\ncan thus use the most sophisticated algorithms available (including\nlearning-enabled software); the monitor is assigned only the task of checking,\nand can thus run quickly and be smaller and formally verifiable.\n  This paper explains the key ideas of certified control and illustrates them\nwith a certificate for LiDAR data and its formal verification. It shows how the\narchitecture dramatically reduces the amount of code to be verified, providing\nan end-to-end safety analysis that would likely not be achievable in a\ntraditional architecture.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 01:12:15 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Jackson", "Daniel", ""], ["Richmond", "Valerie", ""], ["Wang", "Mike", ""], ["Chow", "Jeff", ""], ["Guajardo", "Uriel", ""], ["Kong", "Soonho", ""], ["Campos", "Sergio", ""], ["Litt", "Geoffrey", ""], ["Arechiga", "Nikos", ""]]}, {"id": "2104.06718", "submitter": "Alessandro De Palma", "authors": "Alessandro De Palma, Rudy Bunel, Alban Desmaison, Krishnamurthy\n  Dvijotham, Pushmeet Kohli, Philip H.S. Torr, M. Pawan Kumar", "title": "Improved Branch and Bound for Neural Network Verification via Lagrangian\n  Decomposition", "comments": "Submitted for review to JMLR. This is an extended version of our\n  paper in the UAI-20 conference (arXiv:2002.10410)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the scalability of Branch and Bound (BaB) algorithms for formally\nproving input-output properties of neural networks. First, we propose novel\nbounding algorithms based on Lagrangian Decomposition. Previous works have used\noff-the-shelf solvers to solve relaxations at each node of the BaB tree, or\nconstructed weaker relaxations that can be solved efficiently, but lead to\nunnecessarily weak bounds. Our formulation restricts the optimization to a\nsubspace of the dual domain that is guaranteed to contain the optimum,\nresulting in accelerated convergence. Furthermore, it allows for a massively\nparallel implementation, which is amenable to GPU acceleration via modern deep\nlearning frameworks. Second, we present a novel activation-based branching\nstrategy. By coupling an inexpensive heuristic with fast dual bounding, our\nbranching scheme greatly reduces the size of the BaB tree compared to previous\nheuristic methods. Moreover, it performs competitively with a recent strategy\nbased on learning algorithms, without its large offline training cost. Finally,\nwe design a BaB framework, named Branch and Dual Network Bound (BaDNB), based\non our novel bounding and branching algorithms. We show that BaDNB outperforms\nprevious complete verification systems by a large margin, cutting average\nverification times by factors up to 50 on adversarial robustness properties.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:22:42 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["De Palma", "Alessandro", ""], ["Bunel", "Rudy", ""], ["Desmaison", "Alban", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2104.06723", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "Zaionc paradox revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical expressions are representative of implicative propositions upto\nrenaming of variables. In this paper we explore, using a Monte-Carlo approach,\nthe model of canonical expressions in order to confirm the paradox that says\nthat asymptotically almost all classical theorems are intuitionistic.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:26:05 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 09:30:11 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 12:22:24 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}, {"id": "2104.06932", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "The theory of hereditarily bounded sets", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any $k\\in\\omega$, the structure $(H_k,\\in)$ of sets that are\nhereditarily of size at most $k$ is decidable. We provide a transparent\ncomplete axiomatization of its theory, a quantifier elimination result, and\ntight bounds on its computational complexity. This stands in stark contrast to\nthe structure $V_\\omega=\\bigcup_k H_k$ of hereditarily finite sets, which is\nwell known to be bi-interpretable with the standard model of arithmetic\n$(\\mathbb N,+,\\cdot)$.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:32:31 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "2104.07159", "submitter": "Maren Koyda", "authors": "Maren Koyda, Gerd Stumme", "title": "Boolean Substructures in Formal Concept Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that a (concept) lattice contains an n-dimensional Boolean\nsuborder if and only if the context contains an n-dimensional contra-nominal\nscale as subcontext. In this work, we investigate more closely the interplay\nbetween the Boolean subcontexts of a given finite context and the Boolean\nsuborders of its concept lattice. To this end, we define mappings from the set\nof subcontexts of a context to the set of suborders of its concept lattice and\nvice versa and study their structural properties. In addition, we introduce\nclosed-subcontexts as an extension of closed relations to investigate the set\nof all sublattices of a given lattice.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 23:08:33 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Koyda", "Maren", ""], ["Stumme", "Gerd", ""]]}, {"id": "2104.07278", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Laurent Doyen", "title": "Stochastic Processes with Expected Stopping Time", "comments": "A preliminary version will appear at LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chains are the de facto finite-state model for stochastic dynamical\nsystems, and Markov decision processes (MDPs) extend Markov chains by\nincorporating non-deterministic behaviors. Given an MDP and rewards on states,\na classical optimization criterion is the maximal expected total reward where\nthe MDP stops after $T$ steps, which can be computed by a simple dynamic\nprogramming algorithm. We consider a natural generalization of the problem\nwhere the stopping times can be chosen according to a probability distribution,\nsuch that the expected stopping time is $T$, to optimize the expected total\nreward. Quite surprisingly we establish inter-reducibility of the expected\nstopping-time problem for Markov chains with the Positivity problem (which is\nrelated to the well-known Skolem problem), for which establishing either\ndecidability or undecidability would be a major breakthrough. Given the\nhardness of the exact problem, we consider the approximate version of the\nproblem: we show that it can be solved in exponential time for Markov chains\nand in exponential space for MDPs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 07:12:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""]]}, {"id": "2104.07411", "submitter": "Dieter Brughmans", "authors": "Dieter Brughmans and David Martens", "title": "NICE: An Algorithm for Nearest Instance Counterfactual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest NICE: a new algorithm to generate counterfactual\nexplanations for heterogeneous tabular data. The design of our algorithm\nspecifically takes into account algorithmic requirements that often emerge in\nreal-life deployments: the ability to provide an explanation for all\npredictions, being efficient in run-time, and being able to handle any\nclassification model (also non-differentiable ones). More specifically, our\napproach exploits information from a nearest instance tospeed up the search\nprocess. We propose four versions of NICE, where three of them optimize the\nexplanations for one of the following properties: sparsity, proximity or\nplausibility. An extensive empirical comparison on 10 datasets shows that our\nalgorithm performs better on all properties than the current state-of-the-art.\nThese analyses show a trade-off between on the one hand plausiblity and on the\nother hand proximity or sparsity, with our different optimization methods\noffering the choice to select the preferred trade-off. An open-source\nimplementation of NICE can be found at https://github.com/ADMAntwerp/NICE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:21:01 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Brughmans", "Dieter", ""], ["Martens", "David", ""]]}, {"id": "2104.07466", "submitter": "Alexander Svozil", "authors": "Krishnendu Chatterjee, Wolfgang Dvo\\v{r}\\'ak, Monika Henzinger and\n  Alexander Svozil", "title": "Symbolic Time and Space Tradeoffs for Probabilistic Verification", "comments": "Accepted at LICS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a faster symbolic algorithm for the following central problem in\nprobabilistic verification: Compute the maximal end-component (MEC)\ndecomposition of Markov decision processes (MDPs). This problem generalizes the\nSCC decomposition problem of graphs and closed recurrent sets of Markov chains.\nThe model of symbolic algorithms is widely used in formal verification and\nmodel-checking, where access to the input model is restricted to only symbolic\noperations (e.g., basic set operations and computation of one-step\nneighborhood). For an input MDP with $n$ vertices and $m$ edges, the classical\nsymbolic algorithm from the 1990s for the MEC decomposition requires $O(n^2)$\nsymbolic operations and $O(1)$ symbolic space. The only other symbolic\nalgorithm for the MEC decomposition requires $O(n \\sqrt{m})$ symbolic\noperations and $O(\\sqrt{m})$ symbolic space. A main open question is whether\nthe worst-case $O(n^2)$ bound for symbolic operations can be beaten. We present\na symbolic algorithm that requires $\\widetilde{O}(n^{1.5})$ symbolic operations\nand $\\widetilde{O}(\\sqrt{n})$ symbolic space. Moreover, the parametrization of\nour algorithm provides a trade-off between symbolic operations and symbolic\nspace: for all $0<\\epsilon \\leq 1/2$ the symbolic algorithm requires\n$\\widetilde{O}(n^{2-\\epsilon})$ symbolic operations and\n$\\widetilde{O}(n^{\\epsilon})$ symbolic space ($\\widetilde{O}$ hides\npoly-logarithmic factors).\n  Using our techniques we present faster algorithms for computing the\nalmost-sure winning regions of $\\omega$-regular objectives for MDPs. We\nconsider the canonical parity objectives for $\\omega$-regular objectives, and\nfor parity objectives with $d$-priorities we present an algorithm that computes\nthe almost-sure winning region with $\\widetilde{O}(n^{2-\\epsilon})$ symbolic\noperations and $\\widetilde{O}(n^{\\epsilon})$ symbolic space, for all $0 <\n\\epsilon \\leq 1/2$.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 13:53:28 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Svozil", "Alexander", ""]]}, {"id": "2104.08130", "submitter": "Maximiliano Cristia", "authors": "Maximiliano Cristi\\'a and Gianfranco Rossi", "title": "$\\{log\\}$: Set Formulas as Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  $\\{log\\}$ is a programming language at the intersection of Constraint Logic\nProgramming, set programming and declarative programming. But $\\{log\\}$ is also\na satisfiability solver for a theory of finite sets and finite binary\nrelations. With $\\{log\\}$ programmers can write abstract programs using all the\npower of set theory and binary relations. These programs are not very efficient\nbut they are very close to specifications. Then, their correctness is more\nevident. Furthermore, $\\{log\\}$ programs are also set formulas. Hence,\nprogrammers can use $\\{log\\}$ again to automatically prove their programs\nverify non trivial properties. In this paper we show this development\nmethodology by means of several examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:25:06 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Cristi\u00e1", "Maximiliano", ""], ["Rossi", "Gianfranco", ""]]}, {"id": "2104.08437", "submitter": "Suneel Sarswat", "authors": "Raja Natarajan and Suneel Sarswat and Abhishek Kr Singh", "title": "Verified Double Sided Auctions for Financial Markets", "comments": "ITP 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Double sided auctions are widely used in financial markets to match demand\nand supply. Prior works on double sided auctions have focused primarily on\nsingle quantity trade requests. We extend various notions of double sided\nauctions to incorporate multiple quantity trade requests and provide fully\nformalized matching algorithms for double sided auctions with their correctness\nproofs. We establish new uniqueness theorems that enable automatic detection of\nviolations in an exchange program by comparing its output with that of a\nverified program. All proofs are formalized in the Coq proof assistant without\nadding any axiom to the system. We extract verified OCaml and Haskell programs\nthat can be used by the exchanges and the regulators of the financial markets.\nWe demonstrate the practical applicability of our work by running the verified\nprogram on real market data from an exchange to automatically check for\nviolations in the exchange algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 03:58:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Natarajan", "Raja", ""], ["Sarswat", "Suneel", ""], ["Singh", "Abhishek Kr", ""]]}, {"id": "2104.08958", "submitter": "David  McAllester", "authors": "David McAllester", "title": "Dependent Type Theory as Related to the Bourbaki Notions of Structure\n  and Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a version of dependent type theory in which isomorphism\nis handled through a direct generalization of the 1939 definitions of Bourbaki.\nMore specifically we generalize the Bourbaki definition of structure from\nsimple type signatures to dependent type signatures. Both the original Bourbaki\nnotion of isomorphism and its generalization given here define an isomorphism\nbetween two structures $N$ and $N'$ to consist of bijections between their\nsorts that transport the structure of $N$ to the structure of $N'$. Here\ntransport is defined by commutativity conditions stated with set-theoretic\nequality. This differs from the dependent type theoretic treatments of\nisomorphism given in the groupoid model and homotopy type theory where no\nanalogously straightforward set-theoretic definition of transport is specified.\nThe straightforward definition of transport also leads to a straightforward\nconstructive proof (constructive content) for the validity of the substitution\nof isomorphics -- something that is difficult in the groupoid model or homotopy\ntype theory.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 21:25:32 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["McAllester", "David", ""]]}, {"id": "2104.08980", "submitter": "Daniel Selvaratnam", "authors": "Daniel Selvaratnam, Michael Cantoni, J. M. Davoren, Iman Shames", "title": "Sampling Polynomial Trajectories for LTL Verification", "comments": "Submitted to Theoretical Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper concerns the verification of continuous-time polynomial spline\ntrajectories against linear temporal logic specifications (LTL without 'next').\nEach atomic proposition is assumed to represent a state space region described\nby a multivariate polynomial inequality. The proposed approach is based on\nsampling the trajectories in a manner that captures all region transitions, to\nyield a discrete word called a trace, which is amenable to established formal\nmethods for path checking. The continuous-time trajectory is shown to satisfy\nthe specification if and only if the trace does. General topological conditions\non the sample points are derived that ensure a trace is recorded for arbitrary\ncontinuous paths, given arbitrary region descriptions. Using techniques from\ncomputer algebra, a trace generation algorithm is developed to satisfy these\nconditions when the path and region boundaries are defined by polynomials. The\nproposed PolyTrace algorithm has polynomial complexity in the number of atomic\npropositions, and is guaranteed to produce a trace of any polynomial path. Its\nperformance is demonstrated via numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 00:12:47 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Selvaratnam", "Daniel", ""], ["Cantoni", "Michael", ""], ["Davoren", "J. M.", ""], ["Shames", "Iman", ""]]}, {"id": "2104.09115", "submitter": "Matteo Acclavio", "authors": "Matteo Acclavio, Davide Catta (UM), Lutz Stra{\\ss}burger (LIX)", "title": "Towards a Denotational Semantics for Proofs in Constructive Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide two new semantics for proofs in the constructive\nmodal logics CK and CD. The first semantics is given by extending the syntax of\ncombinatorial proofs for propositional intuitionistic logic, in which proofs\nare factorised in a linear fragment (arena net) and a parallel\nweakening-contraction fragment (skew fibration). In particular we provide an\nencoding of modal formulas by means of directed graphs (modal arenas), and an\nencoding of linear proofs as modal arenas equipped with vertex partitions\nsatisfying topological criteria. The second semantics is given by means of\nwinning innocent strategies of a two-player game over modal arenas. This is\ngiven by extending the Heijltjes-Hughes-Stra{\\ss}burger correspondence between\nintuitionistic combinatorial proofs and winning innocent strategies in a\nHyland-Ong arena. Using our first result, we provide a characterisation of\nwinning strategies for games on a modal arena corresponding to proofs with\nmodalities.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:12:35 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Acclavio", "Matteo", "", "UM"], ["Catta", "Davide", "", "UM"], ["Stra\u00dfburger", "Lutz", "", "LIX"]]}, {"id": "2104.09215", "submitter": "Tim Lyon", "authors": "Tim Lyon", "title": "On the Correspondence between Nested Calculi and Semantic Systems for\n  Intuitionistic Logics", "comments": "arXiv admin note: text overlap with arXiv:1910.06576", "journal-ref": null, "doi": "10.1093/logcom/exaa078", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies the relationship between labelled and nested calculi for\npropositional intuitionistic logic, first-order intuitionistic logic with\nnon-constant domains and first-order intuitionistic logic with constant\ndomains. It is shown that Fitting's nested calculi naturally arise from their\ncorresponding labelled calculi--for each of the aforementioned logics--via the\nelimination of structural rules in labelled derivations. The translational\ncorrespondence between the two types of systems is leveraged to show that the\nnested calculi inherit proof-theoretic properties from their associated\nlabelled calculi, such as completeness, invertibility of rules and cut\nadmissibility. Since labelled calculi are easily obtained via a logic's\nsemantics, the method presented in this paper can be seen as one whereby\nrefined versions of labelled calculi (containing nested calculi as fragments)\nwith favourable properties are derived directly from a logic's semantics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 11:20:58 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lyon", "Tim", ""]]}, {"id": "2104.09366", "submitter": "Anthony Bordg", "authors": "Anthony Bordg, Lawrence Paulson, Wenda Li", "title": "Simple Type Theory is not too Simple: Grothendieck's Schemes without\n  Dependent Types", "comments": "Our code can be found on the Archive of Formal Proofs, see\n  https://www.isa-afp.org/entries/Grothendieck_Schemes.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report on a formalization of schemes in the proof assistant Isabelle/HOL,\nand we discuss the design choices made in the process. Schemes are\nsophisticated mathematical objects in algebraic geometry introduced by\nAlexander Grothendieck in 1960. This experiment shows that the simple type\ntheory implemented in Isabelle can handle such elaborate constructions despite\ndoubts raised about Isabelle's capability in that direction. We show in the\nparticular case of schemes how the powerful dependent types of Coq or Lean can\nbe traded for a minimalist apparatus called locales.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 14:54:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bordg", "Anthony", ""], ["Paulson", "Lawrence", ""], ["Li", "Wenda", ""]]}, {"id": "2104.09716", "submitter": "Revantha Ramanayake Dr", "authors": "A. R. Balasubramanian, Timo Lang, Revantha Ramanayake", "title": "Decidability and Complexity in Weakening and Contraction Hypersequent\n  Substructural Logics", "comments": "Accepted for publication in the proceedings of LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish decidability for the infinitely many axiomatic extensions of the\ncommutative Full Lambek logic with weakening FLew (i.e. IMALLW) that have a\ncut-free hypersequent proof calculus (specifically: every analytic structural\nrule extension). Decidability for the corresponding extensions of its\ncontraction counterpart FLec was established recently but their computational\ncomplexity was left unanswered. In the second part of this paper, we introduce\njust enough on length functions for well-quasi-orderings and the fast-growing\ncomplexity classes to obtain complexity upper bounds for both the weakening and\ncontraction extensions. A specific instance of this result yields the first\ncomplexity bound for the prominent fuzzy logic MTL (monoidal t-norm based\nlogic) providing an answer to a long-standing open problem.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 02:02:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Balasubramanian", "A. R.", ""], ["Lang", "Timo", ""], ["Ramanayake", "Revantha", ""]]}, {"id": "2104.09816", "submitter": "Sujata Ghosh", "authors": "Sujata Ghosh, Shreyas Gupta, Lei Li", "title": "On link deletion and point deletion in games on graphs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We discuss link and point deletion operators on graph games and provide a\ncomparative logic-algorithmic study of the same. In particular, we focus on a\npopular notion of invariance in transition systems, namely, bisimulation,\nbetween the respective games on graphs. We present both logical and algorithmic\nanalyses of the concepts so as to provide a more formal analysis of the natural\nconnection between these two operators.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 08:03:46 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ghosh", "Sujata", ""], ["Gupta", "Shreyas", ""], ["Li", "Lei", ""]]}, {"id": "2104.09837", "submitter": "Stefan Milius", "authors": "Ji\\v{r}\\'i Ad\\'amek and Stefan Milius and Lawrence S. Moss", "title": "An Initial Algebra Theorem Without Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Initial Algebra Theorem by Trnkov\\'a et al. states, under mild\nassumptions, that an endofunctor has an initial algebra provided it has a\npre-fixed point. The proof crucially depends on transfinitely iterating the\nfunctor and in fact shows that, equivalently, the (transfinite) initial-algebra\nchain stops. We give a constructive proof of the Initial Algebra Theorem that\navoids transfinite iteration of the functor. For a given pre-fixed point $A$ of\nthe functor, it uses Pataraia's theorem to obtain the least fixed point of a\nmonotone function on the partial order formed by all subobjects of $A$. Thanks\nto properties of recursive coalgebras, this least fixed point yields an initial\nalgebra. We obtain new results on fixed points and initial algebras in\ncategories enriched over directed-complete partial orders, again without\niteration. Using transfinite iteration we equivalently obtain convergence of\nthe initial-algebra chain as an equivalent condition, overall yielding a\nstreamlined version of the original proof.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 08:54:03 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 10:40:33 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Ad\u00e1mek", "Ji\u0159\u00ed", ""], ["Milius", "Stefan", ""], ["Moss", "Lawrence S.", ""]]}, {"id": "2104.09850", "submitter": "Silvano Dal Zilio", "authors": "Nicolas Amat (LAAS-VERTICS), Bernard Berthomieu (LAAS-VERTICS),\n  Silvano Dal Zilio (LAAS-VERTICS)", "title": "On the Combination of Polyhedral Abstraction and SMT-based Model\n  Checking for Petri nets", "comments": null, "journal-ref": "International Conference on Application and Theory of Petri Nets\n  and Concurrency (Petri Nets), 2021, Paris, France", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a method for taking advantage of net reductions in combination with\na SMT-based model checker. We prove the correctness of this method using a new\nnotion of equivalence between nets that we call polyhedral abstraction. Our\napproach has been implemented in a tool, named SMPT, that provides two main\nprocedures: Bounded Model Checking (BMC) and Property Directed Reachability\n(PDR). Each procedure has been adapted in order to use reductions and to work\nwith arbitrary Petri nets. We tested SMPT on a large collection of queries used\nduring the 2020 edition of the Model Checking Contest. Our experimental results\nshow that our approach works well, even when we only have a moderate amount of\nreductions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:34:50 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Amat", "Nicolas", "", "LAAS-VERTICS"], ["Berthomieu", "Bernard", "", "LAAS-VERTICS"], ["Zilio", "Silvano Dal", "", "LAAS-VERTICS"]]}, {"id": "2104.09940", "submitter": "Paul Piho", "authors": "Paul Piho, Jane Hillston", "title": "Active and sparse methods in smoothed model checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smoothed model checking based on Gaussian process classification provides a\npowerful approach for statistical model checking of parametric continuous time\nMarkov chain models. The method constructs a model for the functional\ndependence of satisfaction probability on the Markov chain parameters. This is\ndone via Gaussian process inference methods from a limited number of\nobservations for different parameter combinations. In this work we consider\nextensions to smoothed model checking based on sparse variational methods and\nactive learning. Both are used successfully to improve the scalability of\nsmoothed model checking. In particular, we see that active learning-based ideas\nfor iteratively querying the simulation model for observations can be used to\nsteer the model-checking to more informative areas of the parameter space and\nthus improve sample efficiency. Online extensions of sparse variational\nGaussian process inference algorithms are demonstrated to provide a scalable\nmethod for implementing active learning approaches for smoothed model checking.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 13:03:25 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Piho", "Paul", ""], ["Hillston", "Jane", ""]]}, {"id": "2104.10267", "submitter": "Riccardo Treglia", "authors": "Claudia Faggian, Giulio Guerrieri, Ugo de'Liguoro, Riccardo Treglia", "title": "On reduction and normalization in the computational core", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reduction in a lambda-calculus derived from Moggi's\ncomputational one, that we call the computational core. The reduction relation\nconsists of rules obtained by orienting three monadic laws. Such laws, in\nparticular associativity and identity, introduce intricacies in the operational\nanalysis. We investigate the central notions of returning a value versus having\na normal form, and address the question of normalizing strategies. Our analysis\nrelies on factorization results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 22:12:02 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 10:29:44 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Faggian", "Claudia", ""], ["Guerrieri", "Giulio", ""], ["de'Liguoro", "Ugo", ""], ["Treglia", "Riccardo", ""]]}, {"id": "2104.10286", "submitter": "Mateus de Oliveira Oliveira", "authors": "Alexsander Andrade de Melo and Mateus de Oliveira Oliveira", "title": "On the Width of Regular Classes of Finite Structures", "comments": "A preliminary version of this work was published in the proceedings\n  of the 27th International Conference on Automated Deduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we introduce the notion of decisional width of a finite\nrelational structure and the notion of decisional width of a regular class of\nfinite structures. Our main result states that given a first-order formula\n{\\psi} over a vocabulary {\\tau}, and a finite automaton F over a suitable\nalphabet B({\\Sigma},w,{\\tau}) representing a width-w regular-decisional class\nof {\\tau}-structures C, one can decide in time f({\\tau},{\\Sigma},{\\psi},w)|F|\nwhether some {\\tau}-structure in C satisfies {\\psi}. Here, f is a function that\ndepends on the parameters {\\tau},{\\Sigma},{\\psi},w, but not on the size of the\nautomaton F representing the class. Therefore, besides implying that the\nfirst-order theory of any given regular-decisional class of finite structures\nis decidable, it also implies that when the parameters {\\tau}, {\\psi}, {\\Sigma}\nand w are fixed, decidability can be achieved in linear time on the size of the\ninput automaton F. Building on the proof of our main result, we show that the\nproblem of counting satisfying assignments for a first-order logic formula in a\ngiven structure A of width w is fixed-parameter tractable with respect to w,\nand can be solved in quadratic time on the length of the input representation\nof A.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 00:10:38 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["de Melo", "Alexsander Andrade", ""], ["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "2104.10446", "submitter": "Jan Dreier", "authors": "Jan Dreier", "title": "Lacon- and Shrub-Decompositions: A New Characterization of First-Order\n  Transductions of Bounded Expansion Classes", "comments": "to be published in the proceedings of LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of bounded expansion provides a robust way to capture sparse\ngraph classes with interesting algorithmic properties. Most notably, every\nproblem definable in first-order logic can be solved in linear time on bounded\nexpansion graph classes. First-order interpretations and transductions of\nsparse graph classes lead to more general, dense graph classes that seem to\ninherit many of the nice algorithmic properties of their sparse counterparts.\n  In this work we introduce lacon- and shrub-decompositions and use them to\ncharacterize transductions of bounded expansion graph classes and other graph\nclasses. If one can efficiently compute sparse shrub- or lacon-decompositions\nof transductions of bounded expansion classes then one can solve every problem\ndefinable in first-order logic in linear time on these classes.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:25:15 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Dreier", "Jan", ""]]}, {"id": "2104.10519", "submitter": "Walid Gomaa", "authors": "Akthem Rehab, Islam Ali, Walid Gomaa, M. Nashat Fors", "title": "Bearings Fault Detection Using Hidden Markov Models and Principal\n  Component Analysis Enhanced Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Asset health monitoring continues to be of increasing importance on\nproductivity, reliability, and cost reduction. Early Fault detection is a\nkeystone of health management as part of the emerging Prognostics and Health\nManagement (PHM) philosophy. This paper proposes a Hidden Markov Model (HMM) to\nassess the machine health degradation. using Principal Component Analysis (PCA)\nto enhance features extracted from vibration signals is considered. The\nenhanced features capture the second order structure of the data. The\nexperimental results based on a bearing test bed show the plausibility of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:20:06 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Rehab", "Akthem", ""], ["Ali", "Islam", ""], ["Gomaa", "Walid", ""], ["Fors", "M. Nashat", ""]]}, {"id": "2104.10542", "submitter": "Jeroen Keiren", "authors": "Jan Friso Groote and Jeroen J.A. Keiren", "title": "Tutorial: Designing Distributed Software in mCRL2", "comments": "Preprint of the paper that has been accepted as a tutorial for FORTE\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed software is very tricky to implement correctly as some errors\nonly occur in peculiar situations. For such errors testing is not effective.\nMathematically proving correctness is hard and time consuming, and therefore,\nit is rarely done. Fortunately, there is a technique in between, namely model\nchecking, that, if applied with skill, is both efficient and able to find rare\nerrors.\n  In this tutorial we show how to create behavioural models of parallel\nsoftware, how to specify requirements using modal formulas, and how to verify\nthese. For that we use the mCRL2 language and toolset (https://www.mcrl2.org/).\nWe discuss the design of an evolution of well-known mutual exclusion protocols,\nand how model checking not only provides insight in their behaviour and\ncorrectness, but also guides their design.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:59:30 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Groote", "Jan Friso", ""], ["Keiren", "Jeroen J. A.", ""]]}, {"id": "2104.10621", "submitter": "Tony Tan", "authors": "Ting-Wei Lin, Chia-Hsuan Lu, Tony Tan", "title": "Towards a more efficient approach for the satisfiability of two-variable\n  logic", "comments": "To appear in the proceedings of LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the satisfiability problem for two-variable logic, denoted by\nSAT(FO2), which is known to be NEXP-complete. The upper bound is usually\nderived from its well known \"exponential size model\" property. Whether it can\nbe determinized/randomized efficiently is still an open question.\n  In this paper we present a different approach by reducing it to a novel\ngraph-theoretic problem that we call \"Conditional Independent Set\" (CIS). We\nshow that CIS is NP-complete and present three simple algorithms for it:\nDeterministic, randomized with zero error and randomized with small one-sided\nerror, with run time O(1.4423^n), O(1.6181^n) and O(1.3661^n), respectively.\n  We then show that without the equality predicate SAT(FO2) is in fact\nequivalent to CIS in succinct representation. This yields the same three simple\nalgorithms as above for SAT(FO2) without the the equality predicate with run\ntime O(1.4423^(2^n)), O(1.6181^(2^n)) and O(1.3661^(2^n)), respectively, where\nn is the number of predicates in the input formula. To the best of our\nknowledge, these are the first deterministic/randomized algorithms for an\nNEXP-complete decidable logic with time complexity significantly lower than\nO(2^(2^n)). We also identify a few lower complexity fragments of SAT(FO2) which\ncorrespond to the tractable fragments of CIS.\n  For the fragment with the equality predicate, we present a linear time\nmany-one reduction to the fragment without the equality predicate. The\nreduction yields equi-satisfiable formulas and incurs a small constant blow-up\nin the number of predicates.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:29:09 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 01:59:24 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lin", "Ting-Wei", ""], ["Lu", "Chia-Hsuan", ""], ["Tan", "Tony", ""]]}, {"id": "2104.10634", "submitter": "David Purser", "authors": "Christel Baier, Florian Funke, Simon Jantsch, Engel Lefaucheux,\n  Florian Luca, Jo\\\"el Ouaknine, David Purser, Markus A. Whiteland and James\n  Worrell", "title": "The Orbit Problem for Parametric Linear Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a parametric version of the Kannan-Lipton Orbit Problem for linear\ndynamical systems. We show decidability in the case of one parameter and\nSkolem-hardness with four or more parameters.\n  More precisely, consider $M$ a d-dimensional square matrix whose entries are\nrational functions in one or more real variables. Given initial and target\nvectors $u,v \\in \\mathbb{Q}^d$, the parametrised point-to-point reachability\nproblem asks whether there exist values of the parameters giving rise to a\nconcrete matrix $N \\in \\mathbb{R}^{d\\times d}$, and a positive integer $n$,\nsuch that $N^n u = v$.\n  We show decidability in the case where $M$ depends only upon a single\nparameter, and we exhibit a reduction from the well-known Skolem problem for\nlinear recurrence sequences, indicating intractability in the case of four or\nmore parameters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 16:59:44 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Baier", "Christel", ""], ["Funke", "Florian", ""], ["Jantsch", "Simon", ""], ["Lefaucheux", "Engel", ""], ["Luca", "Florian", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Purser", "David", ""], ["Whiteland", "Markus A.", ""], ["Worrell", "James", ""]]}, {"id": "2104.10942", "submitter": "Daniel Hirschkoff", "authors": "Daniel Hirschkoff (ENS Lyon), Enguerrand Prebet (ENS Lyon), Davide\n  Sangiorgi (UNIBO, FOCUS)", "title": "On sequentiality and well-bracketing in the $\\pi$-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\pi$ -calculus is used as a model for programminglanguages. Its contexts\nexhibit arbitrary concurrency, makingthem very discriminating. This may prevent\nvalidating desir-able behavioural equivalences in cases when more\ndisciplinedcontexts are expected.In this paper we focus on two such common\ndisciplines:sequentiality, meaning that at any time there is a single threadof\ncomputation, and well-bracketing, meaning that calls toexternal services obey a\nstack-like discipline. We formalise thedisciplines by means of type systems.\nThe main focus of thepaper is on studying the consequence of the disciplines\nonbehavioural equivalence. We define and study labelled bisim-ilarities for\nsequentiality and well-bracketing. These relationsare coarser than ordinary\nbisimilarity. We prove that they aresound for the respective (contextual)\nbarbed equivalence, andalso complete under a certain technical condition.We\nshow the usefulness of our techniques on a number ofexamples, that have mainly\nto do with the representation offunctions and store.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 09:13:57 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Hirschkoff", "Daniel", "", "ENS Lyon"], ["Prebet", "Enguerrand", "", "ENS Lyon"], ["Sangiorgi", "Davide", "", "UNIBO, FOCUS"]]}, {"id": "2104.10998", "submitter": "Yehia Abd Alrahman", "authors": "Yehia Abd Alrahman and Nir Piterman", "title": "Modelling and Verification of Reconfigurable Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalism to model and reason about reconfigurable multi-agent\nsystems. In our formalism, agents interact and communicate in different modes\nso that they can pursue joint tasks; agents may dynamically synchronize,\nexchange data, adapt their behaviour, and reconfigure their communication\ninterfaces. Inspired by existing multi-robot systems, we represent a system as\na set of agents (each with local state), executing independently and only\ninfluence each other by means of message exchange. Agents are able to sense\ntheir local states and partially their surroundings. We extend LTL to be able\nto reason explicitly about the intentions of agents in the interaction and\ntheir communication protocols. We also study the complexity of satisfiability\nand model-checking of this extension.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:43:09 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 08:49:33 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 19:27:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Alrahman", "Yehia Abd", ""], ["Piterman", "Nir", ""]]}, {"id": "2104.11050", "submitter": "M\\'ario Pereira", "authors": "M\\'ario Pereira and Ant\\'onio Ravara", "title": "Cameleer: a Deductive Verification Tool for OCaml", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  OCaml is particularly well-fitted for formal verification. On one hand, it is\na multi-paradigm language with a well-defined semantics, allowing one to write\nclean, concise, type-safe, and efficient code. On the other hand, it is a\nlanguage of choice for the implementation of sensible software, e.g.,\nindustrial compilers, proof assistants, and automated solvers. Yet, with the\nnotable exception of some interactive tools, formal verification has been\nseldom applied to OCaml-written programs. In this paper, we present the ongoing\nproject Cameleer, aiming for the development of a deductive verification tool\nfor OCaml, with a clear focus on proof automation. We leverage on the recently\nproposed GOSPEL, Generic OCaml SPE cification Language, to attach rigorous, yet\nreadable, behavioral specification to OCaml code. The formally-specified\nprogram is fed to our toolchain, which translates it into an equivalent program\nin WhyML, the programming and specification language of the Why3 verification\nframework. Finally, Why3 is used to compute verification conditions for the\ngenerated program, which can be discharged by off-the-shelf SMT solvers. We\npresent successful applications of the Cameleer tool to prove functional\ncorrectness of several significant case studies, like FIFO queues (ephemeral\nand applicative implementations) and leftist heaps, issued from existing OCaml\nlibraries.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:28:52 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Pereira", "M\u00e1rio", ""], ["Ravara", "Ant\u00f3nio", ""]]}, {"id": "2104.11123", "submitter": "Jakub Rydval", "authors": "Manuel Bodirsky and Jakub Rydval and Andr\\'e Schrottenloher", "title": "Universal Horn Sentences and the Joint Embedding Property", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite models of a universal sentence $\\Phi$ are the age of a structure\nif and only if $\\Phi$ has the joint embedding property. We prove that the\ncomputational problem whether a given universal sentence $\\Phi$ has the joint\nembedding property is undecidable, even if $\\Phi$ is additionally Horn and the\nsignature is binary.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:16:26 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Rydval", "Jakub", ""], ["Schrottenloher", "Andr\u00e9", ""]]}, {"id": "2104.11157", "submitter": "Lawrence Paulson", "authors": "Lawrence C Paulson", "title": "Ackermann's Function in Iterative Form: A Proof Assistant Experiment", "comments": "Submitted to Bulletin of Symbolic Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ackermann's function can be expressed using an iterative algorithm, which\nessentially takes the form of a term rewriting system. Although the termination\nof this algorithm is far from obvious, its equivalence to the traditional\nrecursive formulation--and therefore its totality--has a simple proof in\nIsabelle/HOL. This is a small example of formalising mathematics using a proof\nassistant, with a focus on the treatment of difficult recursions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 16:20:24 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Paulson", "Lawrence C", ""]]}, {"id": "2104.11233", "submitter": "Hazem Alkhatib", "authors": "Hazem J. Alkhatib (1 and 2), Majd N. Bohssas (1 and 2), Rawad H. Hatem\n  (1 and 2), and Odey N. Kassam Alhennawi (1 and 2) ((1) The Center for\n  Advanced Science (CAS), (2) Syrian Virtual University)", "title": "A New Approach to CNF-SAT From a Probabilistic Point of View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO physics.gen-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following paper proposes a new approach to determine whether a logical\n(CNF) formula is satisfiable or not using probability theory methods.\nFurthermore, we will introduce an algorithm that speeds up the standard\nsolution for (CNF-SAT) in some cases. It is known that any (CNF) formula is\nsolved with a time complexity of $2^n$ where n is the number of different\nliterals in the (CNF) formula. In our approach, we will follow an enhanced\nmethod from a probabilistic point of view that does not always increase\nexponentially with the number of different literals. This will enhance the\nchance of determining whether a large formula is satisfiable or not in many\ncases. Additionally, we will point out at some promising properties that follow\nfrom applying probability theory concepts and axioms to logic, which might\noriginate more insights about the satisfiability of logical formulas.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:29:45 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Alkhatib", "Hazem J.", "", "1 and 2"], ["Bohssas", "Majd N.", "", "1 and 2"], ["Hatem", "Rawad H.", "", "1 and 2"], ["Alhennawi", "Odey N. Kassam", "", "1 and 2"]]}, {"id": "2104.11241", "submitter": "Rui Soares Barbosa", "authors": "Rui Soares Barbosa, Martti Karvonen, Shane Mansfield", "title": "Closing Bell: Boxing black box simulations in the resource theory of\n  contextuality", "comments": "36 pages. To appear as part of a volume dedicated to Samson Abramsky\n  in Springer's Outstanding Contributions to Logic series", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter contains an exposition of the sheaf-theoretic framework for\ncontextuality emphasising resource-theoretic aspects, as well as some original\nresults on this topic. In particular, we consider functions that transform\nempirical models on a scenario S to empirical models on another scenario T, and\ncharacterise those that are induced by classical procedures between S and T\ncorresponding to 'free' operations in the (non-adaptive) resource theory of\ncontextuality. We proceed by expressing such functions as empirical models\nthemselves, on a new scenario built from S and T. Our characterisation then\nboils down to the non-contextuality of these models. We also show that this\nconstruction on scenarios provides a closed structure in the category of\nmeasurement scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 18:00:01 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Barbosa", "Rui Soares", ""], ["Karvonen", "Martti", ""], ["Mansfield", "Shane", ""]]}, {"id": "2104.11359", "submitter": "Mingsheng Ying", "authors": "Mingsheng Ying", "title": "Model Checking for Verification of Quantum Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this talk, we will describe a framework for assertion-based verification\n(ABV) of quantum circuits by applying model checking techniques for quantum\nsystems developed in our previous work, in which:\n  (i) Noiseless and noisy quantum circuits are modelled as operator- and\nsuper-operator-valued transition systems, respectively, both of which can be\nfurther represented by tensor networks.\n  (ii) Quantum assertions are specified by a temporal extension of Birkhoff-von\nNeumann quantum logic. Their semantics is defined based on the design decision:\nthey will be used in verification of quantum circuits by simulation on\nclassical computers or human reasoning rather than by quantum physics\nexperiments (e.g. testing through measurements);\n  (iii) Algorithms for reachability analysis and model checking of quantum\ncircuits are developed based on contraction of tensor networks. We observe that\nmany optimisation techniques for computing relational products used in\nBDD-based model checking algorithms can be generalised for contracting tensor\nnetworks of quantum circuits.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 00:43:37 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ying", "Mingsheng", ""]]}, {"id": "2104.11442", "submitter": "Micha{\\l} Wrona", "authors": "Manuel Bodirsky, Hubie Chen, Micha{\\l} Wrona", "title": "Tractability of Quantified Temporal Constraints To The Max", "comments": null, "journal-ref": "Int. J. Algebra Comput. 24(8): 1141-1156 (2014)", "doi": "10.1142/S0218196714500507", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A temporal constraint language is a set of relations that are first-order\ndefinable over (Q;<). We show that several temporal constraint languages whose\nconstraint satisfaction problem is maximally tractable are also maximally\ntractable for the more expressive quantified constraint satisfaction problem.\nThese constraint languages are defined in terms of preservation under certain\nbinary polymorphisms. We also present syntactic characterizations of the\nrelations in these languages.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 07:14:31 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Chen", "Hubie", ""], ["Wrona", "Micha\u0142", ""]]}, {"id": "2104.11449", "submitter": "Tatsuji Kawai", "authors": "Marlou M. Gijzen, Hajime Ishihara, Tatsuji Kawai", "title": "Algebraic combinatory models", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an equationally definable counterpart of the notion of\ncombinatory model. The new notion, called an algebraic combinatory model, is\nweaker than that of a lambda algebra but is strong enough to interpret lambda\ncalculus. The class of algebraic combinatory models admits finite\naxiomatisation with seven closed equations, and they are shown to be exactly\nthe retracts of combinatory models. Lambda algebras are then characterised as\nalgebraic combinatory models which are stable; moreover there is a canonical\nconstruction of a lambda algebra from an algebraic combinatory model. The\nresulting axiomatisation of lambda algebras with the seven equations and the\naxiom of stability corresponds to that of Selinger [J. Funct. Programming,\n12(6), 549--566, 2002], which would clarify the origin and the role of each\naxiom in his axiomatisation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 07:49:43 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 01:08:05 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Gijzen", "Marlou M.", ""], ["Ishihara", "Hajime", ""], ["Kawai", "Tatsuji", ""]]}, {"id": "2104.11463", "submitter": "Satoshi Kura", "authors": "Satoshi Kura, Hiroshi Unno, and Ichiro Hasuo", "title": "Decision Tree Learning in CEGIS-Based Termination Analysis", "comments": "camera ready for CAV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel decision tree-based synthesis algorithm of ranking\nfunctions for verifying program termination. Our algorithm is integrated into\nthe workflow of CounterExample Guided Inductive Synthesis (CEGIS). CEGIS is an\niterative learning model where, at each iteration, (1) a synthesizer\nsynthesizes a candidate solution from the current examples, and (2) a validator\naccepts the candidate solution if it is correct, or rejects it providing\ncounterexamples as part of the next examples. Our main novelty is in the design\nof a synthesizer: building on top of a usual decision tree learning algorithm,\nour algorithm detects cycles in a set of example transitions and uses them for\nrefining decision trees. We have implemented the proposed method and obtained\npromising experimental results on existing benchmark sets of (non-)termination\nverification problems that require synthesis of piecewise-defined lexicographic\naffine ranking functions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:27:32 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 05:22:15 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 01:55:09 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kura", "Satoshi", ""], ["Unno", "Hiroshi", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "2104.11538", "submitter": "M\\'ario S. Alvim", "authors": "M\\'ario S. Alvim, Bernardo Amorim, Sophia Knight, Santiago Quintero,\n  and Frank Valencia", "title": "A Multi-Agent Model for Polarization under Confirmation Bias in Social\n  Networks", "comments": "24 pages, 6 figures. Pre-print of work to appear in the 41st\n  International Conference on Formal Techniques for Distributed Objects,\n  Components, and Systems (FORTE 2021). arXiv admin note: text overlap with\n  arXiv:2012.02703", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a model for polarization in multi-agent systems based on Esteban\nand Ray's standard measure of polarization from economics. Agents evolve by\nupdating their beliefs (opinions) based on an underlying influence graph, as in\nthe standard DeGroot model for social learning, but under a confirmation bias;\ni.e., a discounting of opinions of agents with dissimilar views. We show that\neven under this bias polarization eventually vanishes (converges to zero) if\nthe influence graph is strongly-connected. If the influence graph is a regular\nsymmetric circulation, we determine the unique belief value to which all agents\nconverge. Our more insightful result establishes that, under some natural\nassumptions, if polarization does not eventually vanish then either there is a\ndisconnected subgroup of agents, or some agent influences others more than she\nis influenced. We also show that polarization does not necessarily vanish in\nweakly-connected graphs under confirmation bias. We illustrate our model with a\nseries of case studies and simulations, and show how it relates to the classic\nDeGroot model for social learning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 11:13:45 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Alvim", "M\u00e1rio S.", ""], ["Amorim", "Bernardo", ""], ["Knight", "Sophia", ""], ["Quintero", "Santiago", ""], ["Valencia", "Frank", ""]]}, {"id": "2104.11622", "submitter": "\\v{S}t\\v{e}p\\'an Starosta", "authors": "Martin Ra\\v{s}ka and \\v{S}t\\v{e}p\\'an Starosta", "title": "Producing symmetrical facts for lists induced by the list reversal\n  mapping in Isabelle/HOL", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many facts possess symmetrical counterparts that often require a separate\nformal proof, depending on the nature of the involved symmetry. We introduce a\nmethod in Isabelle/HOL which produces such a symmetrical fact for the list\ndatatype and the symmetry induced by the list reversal mapping. The method is\nimplemented as an attribute and its result is based on user-declared symmetry\nrules. Besides general rules, we provide rules that are aimed to be applied in\nthe domain of Combinatorics on Words.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:17:03 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ra\u0161ka", "Martin", ""], ["Starosta", "\u0160t\u011bp\u00e1n", ""]]}, {"id": "2104.11738", "submitter": "Yoni Zohar", "authors": "Ying Sheng, Yoni Zohar, Christophe Ringeissen, Andrew Reynolds, Clark\n  Barrett, Cesare Tinelli", "title": "Politeness and Stable Infiniteness: Stronger Together", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make two contributions to the study of polite combination in\nsatisfiability modulo theories.\n  The first contribution is a separation between politeness and strong\npoliteness, by presenting a polite theory that is not strongly polite. This\nresult shows that proving strong politeness\n  (which is often harder than proving politeness) is sometimes needed in order\nto use polite combination.\n  The second contribution is an optimization to the polite combination method,\nobtained by borrowing from the Nelson-Oppen method. In its non-deterministic\nform, the Nelson-Oppen method is based on guessing arrangements over shared\nvariables. In contrast, polite combination requires an arrangement over\n\\emph{all} variables of the shared sort (not just the shared variables). We\nshow that when using polite combination, if the other theory is stably infinite\nwith respect to a shared sort, only the shared variables of that sort need be\nconsidered in arrangements, as in the Nelson-Oppen method.\n  Reasoning about arrangements of variables is exponential in the worst case,\nso reducing the number of variables that are considered has the potential to\nimprove performance significantly.\n  We show preliminary evidence for this in practice by demonstrating a speed-up\non a smart contract verification benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 17:49:00 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 04:01:30 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sheng", "Ying", ""], ["Zohar", "Yoni", ""], ["Ringeissen", "Christophe", ""], ["Reynolds", "Andrew", ""], ["Barrett", "Clark", ""], ["Tinelli", "Cesare", ""]]}, {"id": "2104.11808", "submitter": "Libor Barto", "authors": "Libor Barto, Zarathustra Brady, Andrei Bulatov, Marcin Kozik, Dmitriy\n  Zhuk", "title": "Minimal Taylor Algebras as a Common Framework for the Three Algebraic\n  Approaches to the CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focuses on the algebraic theory underlying the study of the\ncomplexity and the algorithms for the Constraint Satisfaction Problem (CSP). We\nunify, simplify, and extend parts of the three approaches that have been\ndeveloped to study the CSP over finite templates - absorption theory that was\nused to characterize CSPs solvable by local consistency methods (JACM'14), and\nBulatov's and Zhuk's theories that were used for two independent proofs of the\nCSP Dichotomy Theorem (FOCS'17, JACM'20).\n  As the first contribution we present an elementary theorem about primitive\npositive definability and use it to obtain the starting points of Bulatov's and\nZhuk's proofs as corollaries. As the second contribution we propose and\ninitiate a systematic study of minimal Taylor algebras. This class of algebras\nis broad enough so that it suffices to verify the CSP Dichotomy Theorem on this\nclass only, but still is unusually well behaved. In particular, many concepts\nfrom the three approaches coincide in the class, which is in striking contrast\nwith the general setting.\n  We believe that the theory initiated in this paper will eventually result in\na simple and more natural proof of the Dichotomy Theorem that employs a simpler\nand more efficient algorithm, and will help in attacking complexity questions\nin other CSP-related problems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 20:12:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Barto", "Libor", ""], ["Brady", "Zarathustra", ""], ["Bulatov", "Andrei", ""], ["Kozik", "Marcin", ""], ["Zhuk", "Dmitriy", ""]]}, {"id": "2104.11955", "submitter": "Sebastian Rudolph", "authors": "Manuel Bodirsky, Thomas Feller, Simon Kn\\\"auer, Sebastian Rudolph", "title": "On Logics and Homomorphism Closure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicate logic is the premier choice for specifying classes of relational\nstructures. Homomorphisms are key to describing correspondences between\nrelational structures. Questions concerning the interdependencies between these\ntwo means of characterizing (classes of) structures are of fundamental interest\nand can be highly non-trivial to answer. We investigate several problems\nregarding the homomorphism closure (homclosure) of the class of all (finite or\narbitrary) models of logical sentences: membership of structures in a\nsentence's homclosure; sentence homclosedness; homclosure characterizability in\na logic; normal forms for homclosed sentences in certain logics. For a wide\nvariety of fragments of first- and second-order predicate logic, we clarify\nthese problems' computational properties.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 13:55:07 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 12:07:37 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 20:46:24 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Feller", "Thomas", ""], ["Kn\u00e4uer", "Simon", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2104.12018", "submitter": "S{\\l}awomir Lasota", "authors": "Piotr Hofman and Marta Juzepczuk and S{\\l}awomir Lasota and Mohnish\n  Pattathurajan", "title": "Parikh's theorem for infinite alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate commutative images of languages recognised by register\nautomata and grammars. Semi-linear and rational sets can be naturally extended\nto this setting by allowing for orbit-finite unions instead of only finite\nones. We prove that commutative images of languages of one-register automata\nare not always semi-linear, but they are always rational. We also lift the\nlatter result to grammars: commutative images of one-register context-free\nlanguages are rational, and in consequence commutatively equivalent to register\nautomata. We conjecture analogous results for automata and grammars with\narbitrarily many registers.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 20:31:06 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hofman", "Piotr", ""], ["Juzepczuk", "Marta", ""], ["Lasota", "S\u0142awomir", ""], ["Pattathurajan", "Mohnish", ""]]}, {"id": "2104.12124", "submitter": "Paolo Pistone", "authors": "Melissa Antonelli, Ugo Dal Lago, Paolo Pistone", "title": "On Measure Quantifiers in First-Order Arithmetic (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the logic obtained by endowing the language of first-order\narithmetic with second-order measure quantifiers. This new kind of\nquantification allows us to express that the argument formula is true in a\ncertain portion of all possible interpretations of the quantified variable. We\nshow that first-order arithmetic with measure quantifiers is capable of\nformalizing simple results from probability theory and, most importantly, of\nrepresenting every recursive random function. Moreover, we introduce a\nrealizability interpretation of this logic in which programs have access to an\noracle from the Cantor space.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 10:29:25 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Antonelli", "Melissa", ""], ["Lago", "Ugo Dal", ""], ["Pistone", "Paolo", ""]]}, {"id": "2104.12156", "submitter": "Christian Anti\\'c", "authors": "Christian Antic", "title": "Algebraic answer set programming", "comments": "arXiv admin note: text overlap with arXiv:2009.05774", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-monotonic reasoning is an essential part of human intelligence\nprominently formalized in artificial intelligence research via answer set\nprogramming. Describing complex objects as the composition of elementary ones\nis a common strategy in computer science and science in general. This paper\ncontributes to the foundations of answer set programming and artificial\nintelligence by introducing and studying the sequential composition of answer\nset programs. Specifically, we show that the notion of composition gives rise\nto a family of finite monoids and seminearrings, baptized {\\em ASP monoids} and\n{\\em ASP seminearrings} in this paper. Particularly, we show that the\ncombination of composition and union yields the structure of a finite\nidempotent seminearring. We also show that the restricted class of proper\nKrom-Horn programs, which only contain rules with exactly one body atom, yields\na finite idempotent semiring. On the semantic side, we show that the van\nEmden-Kowalski immediate consequence operator of a program can be represented\nvia composition, which allows us to compute the least model semantics of Horn\nprograms without any explicit reference to operators. As a result, we\ncharacterize answer sets algebraically, which bridges the conceptual gap\nbetween the syntax and semantics of an answer set program in a mathematically\nsatisfactory way, and which provides an algebraic characterization of strong\nand uniform equivalence. Moreover, it gives rise to an algebraic meta-calculus\nfor answer set programs. In a broader sense, this paper is a further step\ntowards an algebra of rule-based logical theories and in the future we plan to\nadapt and generalize the methods of this paper to wider classes of formalisms,\nmost importantly to first-order and disjunctive answer set programs and\nextensions thereof.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 13:27:22 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Antic", "Christian", ""]]}, {"id": "2104.12224", "submitter": "Simon Ro{\\ss}kopf", "authors": "Tobias Nipkow, Simon Ro{\\ss}kopf", "title": "Isabelle's Metalogic: Formalization and Proof Checker", "comments": "to be published in In Platzer, A., Sutcliffe, G. (eds.) 28th\n  International Conference on Automated Deduction (CADE-28), LNCS, Springer,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isabelle is a generic theorem prover with a fragment of higher-order logic as\na metalogic for defining object logics. Isabelle also provides proof terms. We\nformalize this metalogic and the language of proof terms in Isabelle/HOL,\ndefine an executable (but inefficient) proof term checker and prove its\ncorrectness w.r.t. the metalogic. We integrate the proof checker with Isabelle\nand run it on a range of logics and theories to check the correctness of all\nthe proofs in those theories.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 18:21:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Nipkow", "Tobias", ""], ["Ro\u00dfkopf", "Simon", ""]]}, {"id": "2104.12444", "submitter": "Marcello M. Bersani", "authors": "Robert L. Smith, Marcello M. Bersani, Matteo Rossi, Pierluigi San\n  Pietro", "title": "Improved Bounded Model Checking of Timed Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timed Automata (TA) are a very popular modeling formalism for systems with\ntime-sensitive properties. A common task is to verify if a network of TA\nsatisfies a given property, usually expressed in Linear Temporal Logic (LTL),\nor in a subset of Timed Computation Tree Logic (TCTL). In this paper, we build\nupon the TACK bounded model checker for TA, which supports a signal-based\nsemantics of TA and the richer Metric Interval Temporal Logic (MITL). TACK\nencodes both the TA network and property into a variant of LTL, Constraint LTL\nover clocks (CLTLoc). The produced CLTLoc formula can then be solved by tools\nsuch as Zot, which transforms CLTLoc properties into the input logics of\nSatisfiability Modulo Theories (SMT) solvers. We present a novel method that\npreserves TACK's encoding of MITL properties while encoding the TA network\ndirectly into the SMT solver language, making use of both the BitVector logic\nand the logic of real arithmetics. We also introduce several optimizations that\nallow us to significantly outperform the CLTLoc encoding in many practical\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:23:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Smith", "Robert L.", ""], ["Bersani", "Marcello M.", ""], ["Rossi", "Matteo", ""], ["Pietro", "Pierluigi San", ""]]}, {"id": "2104.12445", "submitter": "Luigi Santocanale", "authors": "Luigi Santocanale (LIRICA, LIS)", "title": "Bijective proofs for Eulerian numbers in types B and D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Bigl\\langle\\matrix{n\\cr k}\\Bigr\\rangle$, $\\Bigl\\langle\\matrix{B_n\\cr\nk}\\Bigr\\rangle$, and $\\Bigl\\langle\\matrix{D_n\\cr k}\\Bigr\\rangle$ be the\nEulerian numbers in the types A, B, and D, respectively -- that is, the number\nof permutations of n elements with $k$ descents, the number of signed\npermutations (of $n$ elements) with $k$ type B descents, the number of even\nsigned permutations (of $n$ elements) with $k$ type D descents. Let $S_n(t) =\n\\sum_{k = 0}^{n-1} \\Bigl\\langle\\matrix{n\\cr k}\\Bigr\\rangle t^k$, $B_n(t) =\n\\sum_{k = 0}^n \\Bigl\\langle\\matrix{B_n\\cr k}\\Bigr\\rangle t^k$, and $D_n(t) =\n\\sum_{k = 0}^n \\Bigl\\langle\\matrix{D_n\\cr k}\\Bigr\\rangle t^k$. We give\nbijective proofs of the identity $$B_n(t^2) = (1 + t)^{n+1}S_n(t) -\n2nt_n(t^2)$$ and of Stembridge's identity $$D_n(t) = B_n (t) -\nn2^(n-1)tS_{n-1}(t).$$ These bijective proofs rely on a representation of\nsigned permutations as paths. Using this representation we also establish a\nbijective correspondence between even signed permutations and pairs $(w, E)$\nwith $([n], E)$ a threshold graph and $w$ a degree ordering of $([n], E)$.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:23:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Santocanale", "Luigi", "", "LIRICA, LIS"]]}, {"id": "2104.12577", "submitter": "Damien Busatto-Gaston", "authors": "Damien Busatto-Gaston, Benjamin Monmege, Pierre-Alain Reynier", "title": "Optimal controller synthesis for timed systems", "comments": "arXiv admin note: text overlap with arXiv:1812.01062", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted timed games are zero-sum games played by two players on a timed\nautomaton equipped with weights, where one player wants to minimise the\ncumulative weight while reaching a target. Used in a reactive synthesis\nperspective, this quantitative extension of timed games allows one to measure\nthe quality of controllers in real-time systems. Weighted timed games are\nnotoriously difficult and quickly undecidable, even when restricted to\nnon-negative weights. For non-negative weights, the largest class that can be\nanalysed has been introduced by Bouyer, Jaziri and Markey in 2015. Though the\nvalue problem is undecidable, the authors show how to approximate the value by\nconsidering regions with a refined granularity. In this work, we extend this\nclass to incorporate negative weights, allowing one to model energy for\ninstance, and prove that the value can still be approximated, with the same\ncomplexity. A small restriction also allows us to obtain a class of decidable\nweighted timed games with negative weights and an arbitrary number of clocks.\nIn addition, we show that a symbolic algorithm, relying on the paradigm of\nvalue iteration, can be used as an approximation/computation schema over these\nclasses. We also consider the special case of untimed weighted games, where the\nsame fragments are solvable in polynomial time: this contrasts with the\npseudo-polynomial complexity, known so far, for weighted games without\nrestrictions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 13:48:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Busatto-Gaston", "Damien", ""], ["Monmege", "Benjamin", ""], ["Reynier", "Pierre-Alain", ""]]}, {"id": "2104.12674", "submitter": "Lawrence Paulson", "authors": "Lawrence C. Paulson", "title": "The Relative Consistency of the Axiom of Choice Mechanized Using\n  Isabelle/ZF", "comments": null, "journal-ref": "LMS Journal of Computation and Mathematics, Volume 6, 2003, pp.\n  198-248", "doi": "10.1112/S1461157000000449", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The proof of the relative consistency of the axiom of choice has been\nmechanized using Isabelle/ZF. The proof builds upon a previous mechanization of\nthe reflection theorem. The heavy reliance on metatheory in the original proof\nmakes the formalization unusually long, and not entirely satisfactory: two\nparts of the proof do not fit together. It seems impossible to solve these\nproblems without formalizing the metatheory. However, the present development\nfollows a standard textbook, Kunen's Set Theory, and could support the\nformalization of further material from that book. It also serves as an example\nof what to expect when deep mathematics is formalized.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:00:22 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Paulson", "Lawrence C.", ""]]}, {"id": "2104.12695", "submitter": "Jerome Leroux", "authors": "J\\'er\\^ome Leroux", "title": "The Reachability Problem for Petri Nets is Not Primitive Recursive", "comments": "Version submitted to FOCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a way to lift up the Tower complexity lower bound of the\nreachability problem for Petri nets to match the Ackermannian upper bound\nclosing a long standing open problem. We also prove that the reachability\nproblem in dimension 17 is not elementary.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:37:34 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 16:54:03 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 10:07:37 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Leroux", "J\u00e9r\u00f4me", ""]]}, {"id": "2104.12886", "submitter": "Cesar Sanchez", "authors": "Laura Bozzelli, Adriano Peron and Cesar Sanchez", "title": "Asynchronous Extensions of HyperLTL", "comments": null, "journal-ref": "LICS 2021", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties are a modern specification paradigm that extends trace\nproperties to express properties of sets of traces. Temporal logics for\nhyperproperties studied in the literature, including HyperLTL, assume a\nsynchronous semantics and enjoy a decidable model checking problem. In this\npaper, we introduce two asynchronous and orthogonal extensions of HyperLTL,\nnamely Stuttering HyperLTL (HyperLTLS) and Context HyperLTL (HyperLTLC). Both\nof these extensions are useful, for instance, to formulate asynchronous\nvariants of information-flow security properties. We show that for these\nlogics, model checking is in general undecidable. On the positive side, for\neach of them, we identify a fragment with a decidable model checking that\nsubsumes HyperLTL and that can express meaningful asynchronous requirements.\nMoreover, we provide the exact computational complexity of model checking for\nthese two fragments which, for the HyperLTLS fragment, coincides with that of\nthe strictly less expressive logic HyperLTL.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 21:25:13 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bozzelli", "Laura", ""], ["Peron", "Adriano", ""], ["Sanchez", "Cesar", ""]]}, {"id": "2104.12999", "submitter": "Moritz Lichter", "authors": "Moritz Lichter", "title": "Separating Rank Logic from Polynomial Time", "comments": "54 pages. Full version of a paper to appear at LICS 2021. Fixed some\n  minor mistakes/typos in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the search for a logic capturing polynomial time the most promising\ncandidates are Choiceless Polynomial Time (CPT) and rank logic. Rank logic\nextends fixed-point logic with counting by a rank operator over prime fields.\nWe show that the isomorphism problem for CFI graphs over $\\mathbb{Z}_{2^i}$\ncannot be defined in rank logic, even if the base graph is totally ordered.\nHowever, CPT can define this isomorphism problem. We thereby separate rank\nlogic from CPT and in particular from polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 06:42:06 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 15:28:44 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 09:56:25 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lichter", "Moritz", ""]]}, {"id": "2104.13021", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Coinductive Validity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note formally defines the concept of coinductive validity of judgements,\nand contrasts it with inductive validity. For both notions it shows how a\njudgement is valid iff it has a formal proof. Finally, it defines and\nillustrates the notion of a proof by coinduction.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 07:48:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "2104.13117", "submitter": "Lukas Stevens", "authors": "Lukas Stevens and Tobias Nipkow", "title": "A Verified Decision Procedure for Orders in Isabelle/HOL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present the first verified implementation of a decision procedure for the\nquantifier-free theory of partial and linear orders. We formalise the procedure\nin Isabelle/HOL and provide a specification that is made executable using\nIsabelle's code generator. The procedure is already part of the development\nversion of Isabelle as a sub-procedure of the simplifier.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 11:31:27 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 12:10:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Stevens", "Lukas", ""], ["Nipkow", "Tobias", ""]]}, {"id": "2104.13122", "submitter": "Bartosz Bednarczyk", "authors": "Bartosz Bednarczyk and St\\'ephane Demri", "title": "Why Propositional Quantification Makes Modal and Temporal Logics on\n  Trees Robustly Hard?", "comments": "Submitted to LMCS. Full version of our LICS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding propositional quantification to the modal logics K, T or S4 is known\nto lead to undecidability but CTL with propositional quantification under the\ntree semantics (tQCTL) admits a non-elementary Tower-complete satisfiability\nproblem. We investigate the complexity of strict fragments of tQCTL as well as\nof the modal logic K with propositional quantification under the tree\nsemantics. More specifically, we show that tQCTL restricted to the temporal\noperator EX is already Tower-hard, which is unexpected as EX can only enforce\nlocal properties. When tQCTL restricted to EX is interpreted on N-bounded trees\nfor some N >= 2, we prove that the satisfiability problem is AExpPol-complete;\nAExpPol-hardness is established by reduction from a recently introduced tiling\nproblem, instrumental for studying the model-checking problem for interval\ntemporal logics. As consequences of our proof method, we prove Tower-hardness\nof tQCTL restricted to EF or to EXEF and of the well-known modal logics such as\nK, KD, GL, K4 and S4 with propositional quantification under a semantics based\non classes of trees.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 11:53:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Demri", "St\u00e9phane", ""]]}, {"id": "2104.13124", "submitter": "Lutz Strassburger", "authors": "Dominic Hughes, Lutz Stra{\\ss}burger, Jui-Hsuan Wu", "title": "Combinatorial Proofs and Decomposition Theorems for First-order Logic", "comments": "To be published in LICS 2021. This is the author version of the paper\n  with full proofs in the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We uncover a close relationship between combinatorial and syntactic proofs\nfor first-order logic (without equality). Whereas syntactic proofs are\nformalized in a deductive proof system based on inference rules, a\ncombinatorial proof is a syntax-free presentation of a proof that is\nindependent from any set of inference rules. We show that the two proof\nrepresentations are related via a deep inference decomposition theorem that\nestablishes a new kind of normal form for syntactic proofs. This yields (a) a\nsimple proof of soundness and completeness for first-order combinatorial\nproofs, and (b) a full completeness theorem: every combinatorial proof is the\nimage of a syntactic proof.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 11:56:01 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hughes", "Dominic", ""], ["Stra\u00dfburger", "Lutz", ""], ["Wu", "Jui-Hsuan", ""]]}, {"id": "2104.13138", "submitter": "Patrick Koopmann", "authors": "Christian Alrabbaa and Franz Baader and Stefan Borgwardt and Patrick\n  Koopmann and Alisa Kovtunova", "title": "Finding Good Proofs for Description Logic Entailments Using Recursive\n  Quality Measures (Extended Technical Report)", "comments": "Extended version of a paper accepted at CADE-28", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based approaches to AI have the advantage that their behavior can in\nprinciple be explained to a user. If, for instance, a Description Logic\nreasoner derives a consequence that triggers some action of the overall system,\nthen one can explain such an entailment by presenting a proof of the\nconsequence in an appropriate calculus. How comprehensible such a proof is\ndepends not only on the employed calculus, but also on the properties of the\nparticular proof, such as its overall size, its depth, the complexity of the\nemployed sentences and proof steps, etc. For this reason, we want to determine\nthe complexity of generating proofs that are below a certain threshold w.r.t. a\ngiven measure of proof quality. Rather than investigating this problem for a\nfixed proof calculus and a fixed measure, we aim for general results that hold\nfor wide classes of calculi and measures. In previous work, we first restricted\nthe attention to a setting where proof size is used to measure the quality of a\nproof. We then extended the approach to a more general setting, but important\nmeasures such as proof depth were not covered. In the present paper, we provide\nresults for a class of measures called recursive, which yields lower\ncomplexities and also encompasses proof depth. In addition, we close some gaps\nleft open in our previous work, thus providing a comprehensive picture of the\ncomplexity landscape.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 12:34:13 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Alrabbaa", "Christian", ""], ["Baader", "Franz", ""], ["Borgwardt", "Stefan", ""], ["Koopmann", "Patrick", ""], ["Kovtunova", "Alisa", ""]]}, {"id": "2104.13160", "submitter": "Giorgio Bacci", "authors": "Giorgio Bacci, Giovanni Bacci, Kim G. Larsen, Mirco Tribastone, Max\n  Tschaikowski, Andrea Vandin", "title": "Efficient Local Computation of Differential Bisimulations via Coupling\n  and Up-to Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce polynomial couplings, a generalization of probabilistic\ncouplings, to develop an algorithm for the computation of equivalence relations\nwhich can be interpreted as a lifting of probabilistic bisimulation to\npolynomial differential equations, a ubiquitous model of dynamical systems\nacross science and engineering. The algorithm enjoys polynomial time complexity\nand complements classical partition-refinement approaches because: (a) it\nimplements a local exploration of the system, possibly yielding equivalences\nthat do not necessarily involve the inspection of the whole system of\ndifferential equations; (b) it can be enhanced by up-to techniques; and (c) it\nallows the specification of pairs which ought not to be included in the output.\nUsing a prototype, these advantages are demonstrated on case studies from\nsystems biology for applications to model reduction and comparison. Notably, we\nreport four orders of magnitude smaller runtimes than partition-refinement\napproaches when disproving equivalences between Markov chains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:08:59 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bacci", "Giorgio", ""], ["Bacci", "Giovanni", ""], ["Larsen", "Kim G.", ""], ["Tribastone", "Mirco", ""], ["Tschaikowski", "Max", ""], ["Vandin", "Andrea", ""]]}, {"id": "2104.13269", "submitter": "Franz Brau{\\ss}e", "authors": "Franz Brau{\\ss}e, Konstantin Korovin, Margarita V. Korovina and\n  Norbert Th. M\\\"uller", "title": "The ksmt calculus is a $\\delta$-complete decision procedure for\n  non-linear constraints", "comments": "The conference version of this paper is accepted at CADE-28", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ksmt is a CDCL-style calculus for solving non-linear constraints over real\nnumbers involving polynomials and transcendental functions.\n  In this paper we investigate properties of the ksmt calculus and show that it\nis a $\\delta$-complete decision procedure for bounded problems.\n  We also propose an extension with local linearisations, which allow for more\nefficient treatment of non-linear constraints.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:38:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Brau\u00dfe", "Franz", ""], ["Korovin", "Konstantin", ""], ["Korovina", "Margarita V.", ""], ["M\u00fcller", "Norbert Th.", ""]]}, {"id": "2104.13324", "submitter": "Paolo Pistone", "authors": "Paolo Pistone", "title": "On Generalized Metric Spaces for the Simply Typed Lambda-Calculus\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalized metrics, arising from Lawvere's view of metric spaces as enriched\ncategories, have been widely applied in denotational semantics as a way to\nmeasure to which extent two programs behave in a similar, although non\nequivalent, way. However, the application of generalized metrics to\nhigher-order languages like the simply typed lambda calculus has so far proved\nunsatisfactory. In this paper we investigate a new approach to the construction\nof cartesian closed categories of generalized metric spaces. Our starting point\nis a quantitative semantics based on a generalization of usual logical\nrelations. Within this setting, we show that several families of generalized\nmetrics provide ways to extend the Euclidean metric to all higher-order types.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:56:01 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Pistone", "Paolo", ""]]}, {"id": "2104.13573", "submitter": "Karl Schlechta", "authors": "Karl Schlechta", "title": "Truth and Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main subjects of this text are:\n  (1) Generalization of concepts and operations, like distance and size, to\nsituations where they are not definable in the usual way.\n  (2) A pragmatic theory of handling contradictions using reliability of the\ninformation sources.\n  (3) Relation of formal semantics to brain processes.\n  (4) Remarks on Yablo's coding of the liar paradox in infinite acyclic graphs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 05:10:45 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 14:48:55 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Schlechta", "Karl", ""]]}, {"id": "2104.13604", "submitter": "Florian Funke", "authors": "Christel Baier, Florian Funke, Simon Jantsch, Jakob Piribauer, Robin\n  Ziemek", "title": "Probabilistic causes in Markov chains", "comments": "Full version of a conference paper at ATVA'21; 26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper studies a probabilistic notion of causes in Markov chains that\nrelies on the counterfactuality principle and the probability-raising property.\nThis notion is motivated by the use of causes for monitoring purposes where the\naim is to detect faulty or undesired behaviours before they actually occur. A\ncause is a set of finite executions of the system after which the probability\nof the effect exceeds a given threshold. We introduce multiple types of costs\nthat capture the consumption of resources from different perspectives, and\nstudy the complexity of computing cost-minimal causes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 07:27:30 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 11:30:20 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Baier", "Christel", ""], ["Funke", "Florian", ""], ["Jantsch", "Simon", ""], ["Piribauer", "Jakob", ""], ["Ziemek", "Robin", ""]]}, {"id": "2104.13645", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard and Wolfgang Bibel", "title": "Learning from {\\L}ukasiewicz and Meredith: Investigations into Proof\n  Structures (Extended Version)", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-79876-5_4", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The material presented in this paper contributes to establishing a basis\ndeemed essential for substantial progress in Automated Deduction. It identifies\nand studies global features in selected problems and their proofs which offer\nthe potential of guiding proof search in a more direct way. The studied\nproblems are of the wide-spread form of \"axiom(s) and rule(s) imply goal(s)\".\nThe features include the well-known concept of lemmas. For their elaboration\nboth human and automated proofs of selected theorems are taken into a close\ncomparative consideration. The study at the same time accounts for a coherent\nand comprehensive formal reconstruction of historical work by {\\L}ukasiewicz,\nMeredith and others. First experiments resulting from the study indicate novel\nways of lemma generation to supplement automated first-order provers of various\nfamilies, strengthening in particular their ability to find short proofs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:09:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wernhard", "Christoph", ""], ["Bibel", "Wolfgang", ""]]}, {"id": "2104.13675", "submitter": "Gilda Ferreira", "authors": "M. Clarence Protin and Gilda Ferreira", "title": "Typability and Type Inference in Atomic Polymorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that typability, type inhabitation and type inference are\nundecidable in the Girard-Reynolds polymorphic system F. It has recently been\nproven that type inhabitation remains undecidable even in the predicative\nfragment of system F in which all universal instantiations have an atomic\nwitness (system Fat). In this paper we analyze typability and type inference in\nsystem Fat and show that these two problems are decidable in the atomic\npolymorphic system.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:54:38 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Protin", "M. Clarence", ""], ["Ferreira", "Gilda", ""]]}, {"id": "2104.13681", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate, Cosmin Bonchis and Adrian Craciun", "title": "Kernelization, Proof Complexity and Social Choice", "comments": "Revised version will appear in the Proceedings of ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.GT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We display an application of the notions of kernelization and data reduction\nfrom parameterized complexity to proof complexity: Specifically, we show that\nthe existence of data reduction rules for a parameterized problem having (a). a\nsmall-length reduction chain, and (b). small-size (extended) Frege proofs\ncertifying the soundness of reduction steps implies the existence of\nsubexponential size (extended) Frege proofs for propositional formalizations of\nthe given problem.\n  We apply our result to infer the existence of subexponential Frege and\nextended Frege proofs for a variety of problems. Improving earlier results of\nAisenberg et al. (ICALP 2015), we show that propositional formulas expressing\n(a stronger form of) the Kneser-Lov\\'asz Theorem have polynomial size Frege\nproofs for each constant value of the parameter k. Previously only\nquasipolynomial bounds were known (and only for the ordinary Kneser-Lov\\'asz\nTheorem).\n  Another notable application of our framework is to impossibility results in\ncomputational social choice: we show that, for any fixed number of agents,\npropositional translations of the Arrow and Gibbard-Satterthwaite impossibility\ntheorems have subexponential size Frege proofs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 10:09:14 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Istrate", "Gabriel", ""], ["Bonchis", "Cosmin", ""], ["Craciun", "Adrian", ""]]}, {"id": "2104.13739", "submitter": "Gianluca Curzi", "authors": "Gianluca Curzi", "title": "Linear Additives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce $\\mathsf{LAM}$, a subsystem of $\\mathsf{IMALL}_2$ with\nrestricted additive rules able to manage duplication linearly, called\n\\textit{linear additive rules}. $\\mathsf{LAM}$ is presented as the type\nassignment system for a calculus endowed with copy constructors, which deal\nwith substitution in a linear fashion. As opposed to the standard additive\nrules, the linear additive rules do not affect the complexity of term\nreduction: typable terms of $\\mathsf{LAM}$ enjoy linear strong normalization.\nMoreover, a mildly weakened version of cut-elimination for this system is\nproven which takes a cubic number of steps. Finally, we define a sound\ntranslation from $\\mathsf{LAM}$'s proofs into $\\mathsf{IMLL}_2$'s linear lambda\nterms, and we study its complexity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 13:01:30 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Curzi", "Gianluca", ""]]}, {"id": "2104.13792", "submitter": "Lawrence Paulson", "authors": "Lawrence C. Paulson", "title": "A Mechanised Proof of G\\\"odel's Incompleteness Theorems using Nominal\n  Isabelle", "comments": null, "journal-ref": "J Autom Reasoning 55, 1-37 (2015)", "doi": "10.1007/s10817-015-9322-8", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An Isabelle/HOL formalisation of G\\\"odel's two incompleteness theorems is\npresented. The work follows \\'Swierczkowski's detailed proof of the theorems\nusing hereditarily finite (HF) set theory. Avoiding the usual arithmetical\nencodings of syntax eliminates the necessity to formalise elementary number\ntheory within an embedded logical calculus. The Isabelle formalisation uses two\nseparate treatments of variable binding: the nominal package is shown to scale\nto a development of this complexity, while de Bruijn indices turn out to be\nideal for coding syntax. Critical details of the Isabelle proof are described,\nin particular gaps and errors found in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:26:47 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Paulson", "Lawrence C.", ""]]}, {"id": "2104.13795", "submitter": "Gabriele Vanoni", "authors": "Beniamino Accattoli, Ugo Dal Lago, Gabriele Vanoni", "title": "The Space of Interaction (long version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The space complexity of functional programs is not well understood. In\nparticular, traditional implementation techniques are tailored to time\nefficiency, and space efficiency induces time inefficiencies, as it prefers\nre-computing to saving. Girard's geometry of interaction underlies an\nalternative approach based on the interaction abstract machine (IAM), claimed\nas space efficient in the literature. It has also been conjectured to provide a\nreasonable notion of space for the lambda-calculus, but such an important\nresult seems to be elusive.\n  In this paper we introduce a new intersection type system precisely measuring\nthe space consumption of the IAM on the typed term. Intersection types have\nbeen repeatedly used to measure time, which they achieve by dropping\nidempotency, turning intersections into multisets. Here we show that the space\nconsumption of the IAM is connected to a further structural modification,\nturning multisets into trees. Tree intersection types lead to a finer\nunderstanding of some space complexity results from the literature. They also\nshed new light on the conjecture about reasonable space: we show that the usual\nway of encoding Turing machines into the lambda calculus cannot be used to\nprove that the space of the IAM is a reasonable cost model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:33:28 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Lago", "Ugo Dal", ""], ["Vanoni", "Gabriele", ""]]}, {"id": "2104.13851", "submitter": "Simon Robillard", "authors": "Robin E{\\ss}mann, Tobias Nipkow, Simon Robillard", "title": "Verified Approximation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first formal verification of approximation algorithms for\nNP-complete optimization problems: vertex cover, independent set, set cover,\nload balancing, and bin packing. We uncover incompletenesses in existing proofs\nand improve the approximation ratio in one case.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:56:16 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["E\u00dfmann", "Robin", ""], ["Nipkow", "Tobias", ""], ["Robillard", "Simon", ""]]}, {"id": "2104.13866", "submitter": "Wojciech Czerwi\\'nski", "authors": "Wojciech Czerwi\\'nski, {\\L}ukasz Orlikowski", "title": "Reachability in Vector Addition Systems is Ackermann-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector Addition Systems and equivalent Petri nets are a well established\nmodels of concurrency. The central algorithmic problem for Vector Addition\nSystems with a long research history is the reachability problem asking whether\nthere exists a run from one given configuration to another. We settle its\ncomplexity to be Ackermann-complete thus closing the problem open for 45 years.\nIn particular we prove that the problem is $\\mathcal{F}_k$-hard for Vector\nAddition Systems with States in dimension $6k$, where $\\mathcal{F}_k$ is the\n$k$-th complexity class from the hierarchy of fast-growing complexity classes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:23:18 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 10:56:14 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Czerwi\u0144ski", "Wojciech", ""], ["Orlikowski", "\u0141ukasz", ""]]}, {"id": "2104.13910", "submitter": "Tejas Bhojraj", "authors": "Tejas Bhojraj", "title": "Notions of indifference for genericity: Union and subsequence sets", "comments": "9 pages", "journal-ref": "Journal of Logic and Computation, 2021;, exab035", "doi": "10.1093/logcom/exab035", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set $I$ is said to be a universal indifferent set for $1$-genericity if for\nevery $1$-generic $G$ and for all $X \\subseteq I$, $G \\Delta X$ is also\n$1$-generic. Miller showed that there is no infinite universal indifferent set\nfor $1$-genericity. We introduce two variants (union and subsequence sets for\n$1$-genericity) of the notion of universal indifference and prove that there\nare no non-trivial universal sets for $1$-genericity with respect to these\nnotions. In contrast, we show that there is a non-computable subsequence set\nfor weak-$1$-genericity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 17:47:16 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Bhojraj", "Tejas", ""]]}, {"id": "2104.13979", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli, Giulio Guerrieri, Maico Leberle", "title": "Semantic Bounds and Strong Call-by-Value Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores two topics at once: the use of denotational semantics to\nbound the evaluation length of functional programs, and the semantics of strong\n(that is, possibly under abstractions) call-by-value evaluation.\n  About the first, we analyze de Carvalho's seminal use of relational semantics\nfor bounding the evaluation length of lambda-terms, starting from the\npresentation of the semantics as an intersection types system. We focus on the\npart of his work which is usually neglected in its many recent adaptations,\ndespite being probably the conceptually deeper one: how to transfer the\nbounding power from the type system to the relational semantics itself. We\ndissect this result and re-understand it via the isolation of a simpler size\nrepresentation property.\n  About the second, we use relational semantics to develop a semantical study\nof strong call-by-value evaluation, which is both a delicate and neglected\ntopic. We give a semantic characterization of terms normalizable with respect\nto strong evaluation, providing in particular the first result of adequacy with\nrespect to strong call-by-value. Moreover, we extract bounds about strong\nevaluation from both the type systems and the relational semantics.\n  Essentially, we use strong call-by-value to revisit de Carvalho's semantic\nbounds, and de Carvalho's technique to provide semantical foundations for\nstrong call-by-value.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 19:09:30 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Guerrieri", "Giulio", ""], ["Leberle", "Maico", ""]]}, {"id": "2104.14025", "submitter": "Cesar Sanchez", "authors": "Jan Baumeister, Norine Coenen, Borzoo Bonakdarpour, Bernd Finkbeiner\n  and Cesar Sanchez", "title": "A Temporal Logic for Asynchronous Hyperproperties", "comments": null, "journal-ref": "CAV 2021", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties are properties of computational systems that require more\nthan one trace to evaluate, e.g., many information-flow security and\nconcurrency requirements. Where a trace property defines a set of traces, a\nhyperproperty defines a set of sets of traces. The temporal logics HyperLTL and\nHyperCTL* have been proposed to express hyperproperties. However, their\nsemantics are synchronous in the sense that all traces proceed at the same\nspeed and are evaluated at the same position. This precludes the use of these\nlogics to analyze systems whose traces can proceed at different speeds and\nallow that different traces take stuttering steps independently. To solve this\nproblem in this paper, we propose an asynchronous variant of HyperLTL. On the\nnegative side, we show that the model-checking problem for this variant is\nundecidable. On the positive side, we identify a decidable fragment which\ncovers a rich set of formulas with practical applications. We also propose two\nmodel-checking algorithms that reduce our problem to the HyperLTL\nmodel-checking problem in the synchronous semantics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 21:17:52 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Baumeister", "Jan", ""], ["Coenen", "Norine", ""], ["Bonakdarpour", "Borzoo", ""], ["Finkbeiner", "Bernd", ""], ["Sanchez", "Cesar", ""]]}, {"id": "2104.14098", "submitter": "S. Akshay", "authors": "Preey Shah, Aman Bansal, S. Akshay and Supratik Chakraborty", "title": "A Normal Form Characterization for Efficient Boolean Skolem Function\n  Synthesis", "comments": "Full version of conference paper accepted at LICS'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Boolean Skolem function synthesis concerns synthesizing outputs as Boolean\nfunctions of inputs such that a relational specification between inputs and\noutputs is satisfied. This problem, also known as Boolean functional synthesis,\nhas several applications, including design of safe controllers for autonomous\nsystems, certified QBF solving, cryptanalysis etc. Recently, complexity\ntheoretic hardness results have been shown for the problem, although several\nalgorithms proposed in the literature are known to work well in practice. This\ndichotomy between theoretical hardness and practical efficacy has motivated the\nresearch into normal forms or representations of input specifications that\npermit efficient synthesis, thus explaining perhaps the efficacy of these\nalgorithms.\n  In this paper we go one step beyond this and ask if there exists a normal\nform representation that can in fact precisely characterize \"efficient\"\nsynthesis. We present a normal form called SAUNF that precisely characterizes\ntractable synthesis in the following sense: a specification is polynomial time\nsynthesizable iff it can be compiled to SAUNF in polynomial time. Additionally,\na specification admits a polynomial-sized functional solution iff there exists\na semantically equivalent polynomial-sized SAUNF representation. SAUNF is\nexponentially more succinct than well-established normal forms like BDDs and\nDNNFs, used in the context of AI problems, and strictly subsumes other more\nrecently proposed forms like SynNNF. It enjoys compositional properties that\nare similar to those of DNNF. Thus, SAUNF provides the right trade-off in\nknowledge representation for Boolean functional synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 04:16:41 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 12:52:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Shah", "Preey", ""], ["Bansal", "Aman", ""], ["Akshay", "S.", ""], ["Chakraborty", "Supratik", ""]]}, {"id": "2104.14175", "submitter": "Toby Cathcart Burn", "authors": "Toby Cathcart Burn (1), Luke Ong (1), Steven Ramsay (2), Dominik\n  Wagner (1) ((1) University of Oxford, (2) University of Bristol)", "title": "Initial Limit Datalog: a New Extensible Class of Decidable Constrained\n  Horn Clauses", "comments": "18 pages. To be published in LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present initial limit Datalog, a new extensible class of constrained Horn\nclauses for which the satisfiability problem is decidable. The class may be\nviewed as a generalisation to higher-order logic (with a simple restriction on\ntypes) of the first-order language limit Datalog$_Z$ (a fragment of Datalog\nmodulo linear integer arithmetic), but can be instantiated with any suitable\nbackground theory. For example, the fragment is decidable over any countable\nwell-quasi-order with a decidable first-order theory, such as natural number\nvectors under componentwise linear arithmetic, and words of a bounded,\ncontext-free language ordered by the subword relation. Formulas of initial\nlimit Datalog have the property that, under some assumptions on the background\ntheory, their satisfiability can be witnessed by a new kind of term model which\nwe call entwined structures. Whilst the set of all models is typically\nuncountable, the set of all entwined structures is recursively enumerable, and\nmodel checking is decidable.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 07:58:01 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Burn", "Toby Cathcart", "", "University of Oxford"], ["Ong", "Luke", "", "University of Oxford"], ["Ramsay", "Steven", "", "University of Bristol"], ["Wagner", "Dominik", "", "University of Oxford"]]}, {"id": "2104.14226", "submitter": "Ross Horne", "authors": "Rob van Glabbeek and Peter H\\\"ofner and Ross Horne", "title": "Assuming Just Enough Fairness to make Session Types Complete for\n  Lock-freedom", "comments": "To appear in the Proceedings of LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how different fairness assumptions affect results concerning\nlock-freedom, a typical liveness property targeted by session type systems. We\nfix a minimal session calculus and systematically take into account all known\nfairness assumptions, thereby identifying precisely three interesting and\nsemantically distinct notions of lock-freedom, all of which having a sound\nsession type system. We then show that, by using a general merge operator in an\notherwise standard approach to global session types, we obtain a session type\nsystem complete for the strongest amongst those notions of lock-freedom, which\nassumes only justness of execution paths, a minimal fairness assumption for\nconcurrent systems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 09:24:58 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["Horne", "Ross", ""]]}, {"id": "2104.14266", "submitter": "Mathias Ruggaard Pedersen", "authors": "Antonis Achilleos, Mathias Ruggaard Pedersen", "title": "Axiomatizations and Computability of Weighted Monadic Second-Order Logic", "comments": "Full version of paper to be published in the proceedings of LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weighted monadic second-order logic is a weighted extension of monadic\nsecond-order logic that captures exactly the behaviour of weighted automata.\nIts semantics is parameterized with respect to a semiring on which the values\nthat weighted formulas output are evaluated. Gastin and Monmege (2018) gave\nabstract semantics for a version of weighted monadic second-order logic to give\na more general and modular proof of the equivalence of the logic with weighted\nautomata. We focus on the abstract semantics of the logic and we give a\ncomplete axiomatization both for the full logic and for a fragment without\ngeneral sum, thus giving a more fine-grained understanding of the logic. We\ndiscuss how common decision problems for logical languages can be adapted to\nthe weighted setting, and show that many of these are decidable, though they\ninherit bad complexity from the underlying first- and second-order logics.\nHowever, we show that a weighted adaptation of satisfiability is undecidable\nfor the logic when one uses the abstract interpretation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 11:24:26 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Achilleos", "Antonis", ""], ["Pedersen", "Mathias Ruggaard", ""]]}, {"id": "2104.14333", "submitter": "Laura Nenzi", "authors": "Ezio Bartocci, Luca Bortolussi, Michele Loreti, Laura Nenzi, Simone\n  Silvetti", "title": "MoonLight: A Lightweight Tool for Monitoring Spatio-Temporal Properties", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present MoonLight, a tool for monitoring temporal and spatio-temporal\nproperties of mobile and spatially distributed cyber-physical systems (CPS). In\nthe proposed framework, space is represented as a weighted graph, describing\nthe topological configurations in which the single CPS entities (nodes of the\ngraph) are arranged. Both nodes and edges have attributes modelling physical\nand logical quantities that can change in time. MoonLight is implemented in\nJava and supports the monitoring of Spatio-Temporal Reach and Escape Logic\n(STREL). MoonLight can be used as a standalone command line tool, as a Java\nAPI, or via Matlab interface. We provide here some examples using the Matlab\ninterface and we evaluate the tool performance also by comparing with other\ntools specialized in monitoring only temporal properties.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 13:39:13 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Bartocci", "Ezio", ""], ["Bortolussi", "Luca", ""], ["Loreti", "Michele", ""], ["Nenzi", "Laura", ""], ["Silvetti", "Simone", ""]]}, {"id": "2104.14445", "submitter": "Dominique Larchey-Wendling", "authors": "Dominik Kirst and Dominique Larchey-Wendling", "title": "Trakhtenbrot's Theorem in Coq: Finite Model Theory through the\n  Constructive Lens", "comments": "26 pages, extended version of the IJCAR 2020 paper. arXiv admin note:\n  substantial text overlap with arXiv:2004.07390", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study finite first-order satisfiability (FSAT) in the constructive setting\nof dependent type theory. Employing synthetic accounts of enumerability and\ndecidability, we give a full classification of FSAT depending on the\nfirst-order signature of non-logical symbols. On the one hand, our development\nfocuses on Trakhtenbrot's theorem, stating that FSAT is undecidable as soon as\nthe signature contains an at least binary relation symbol. Our proof proceeds\nby a many-one reduction chain starting from the Post correspondence problem. On\nthe other hand, we establish the decidability of FSAT for monadic first-order\nlogic, i.e. where the signature only contains at most unary function and\nrelation symbols, as well as the enumerability of FSAT for arbitrary enumerable\nsignatures. To showcase an application of Trakthenbrot's theorem, we continue\nour reduction chain with a many-one reduction from FSAT to separation logic.\nAll our results are mechanised in the framework of a growing Coq library of\nsynthetic undecidability proofs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 16:05:31 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kirst", "Dominik", ""], ["Larchey-Wendling", "Dominique", ""]]}, {"id": "2104.14512", "submitter": "Kai Sauerwald", "authors": "Faiq Miftakhul Falakh and Sebastian Rudolph and Kai Sauerwald", "title": "A General Katsuno-Mendelzon-Style Characterization of AGM Belief Base\n  Revision for Arbitrary Monotonic Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AGM postulates by Alchourr\\'{o}n, G\\\"{a}rdenfors, and Makinson continue\nto represent a cornerstone in research related to belief change. We generalize\nthe approach of Katsuno and Mendelzon (KM) for characterizing AGM base revision\nfrom propositional logic to the setting of (multiple) base revision in\narbitrary monotonic logics. Our core result is a representation theorem using\nthe assignment of total - yet not transitive - \"preference\" relations to belief\nbases. We also provide a characterization of all logics for which our result\ncan be strengthened to preorder assignments (as in KM's original work).\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:24:21 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Falakh", "Faiq Miftakhul", ""], ["Rudolph", "Sebastian", ""], ["Sauerwald", "Kai", ""]]}, {"id": "2104.14519", "submitter": "Rohit Chadha", "authors": "Rohit Chadha, A. Prasad Sistla and Mahesh Viswanathan", "title": "On Linear Time Decidability of Differential Privacy for Programs with\n  Unbounded Inputs", "comments": "An extended abstract to be published in 36th Annual IEEE Symposium on\n  Logic in Computer Science (LICS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automata model for describing interesting classes of\ndifferential privacy mechanisms/algorithms that include known mechanisms from\nthe literature. These automata can model algorithms whose inputs can be an\nunbounded sequence of real-valued query answers. We consider the problem of\nchecking whether there exists a constant $d$ such that the algorithm described\nby these automata are $d\\epsilon$-differentially private for all positive\nvalues of the privacy budget parameter $\\epsilon$. We show that this problem\ncan be decided in time linear in the automaton's size by identifying a\nnecessary and sufficient condition on the underlying graph of the automaton.\nThis paper's results are the first decidability results known for algorithms\nwith an unbounded number of query answers taking values from the set of reals.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:34:44 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chadha", "Rohit", ""], ["Sistla", "A. Prasad", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "2104.14624", "submitter": "Martin Grohe", "authors": "Martin Grohe", "title": "The Logic of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are deep learning architectures for machine\nlearning problems on graphs. It has recently been shown that the expressiveness\nof GNNs can be characterised precisely by the combinatorial Weisfeiler-Leman\nalgorithms and by finite variable counting logics. The correspondence has even\nled to new, higher-order GNNs corresponding to the WL algorithm in higher\ndimensions.\n  The purpose of this paper is to explain these descriptive characterisations\nof GNNs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:23:26 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Grohe", "Martin", ""]]}, {"id": "2104.14669", "submitter": "Ulrich Berger", "authors": "Ulrich Berger and Hideki Tsuiki", "title": "Extracting total Amb programs from proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a logical system CFP (Concurrent Fixed Point Logic) from whose\nproofs one can extract nondeterministic and concurrent programs that are\nprovably total and correct with respect to the proven formula. CFP is an\nintuitionistic first-order logic with inductive and coinductive definitions\nextended by two propositional operators, A || B (restriction, a strengthening\nof the implication B -> A) and $\\ddownarrow(A)$ (total concurrency). The target\nof the extraction is a lambda calculus with constructors and recursion extended\nby a constructor Amb (for McCarthy's amb) which is interpreted operationally as\nglobally angelic choice. The correctness of extracted programs is proven via an\nintermediate domain-theoretic denotational semantics. We demonstrate the\nusefulness of our system by extracting a concurrent program that translates\ninfinite Gray code into the signed digit representation. A noteworthy feature\nof our system is that the proof rules for restriction and concurrency involve\nvariants of the classical law of excluded middle that would not be\ninterpretable computationally without Amb.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 21:45:17 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Berger", "Ulrich", ""], ["Tsuiki", "Hideki", ""]]}, {"id": "2104.14686", "submitter": "Fabio Zanasi", "authors": "Filippo Bonchi, Fabio Gadducci, Aleks Kissinger, Pawel Sobocinski,\n  Fabio Zanasi", "title": "String Diagram Rewrite Theory II: Rewriting with Symmetric Monoidal\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Symmetric monoidal theories (SMTs) generalise algebraic theories in a way\nthat make them suitable to express resource-sensitive systems, in which\nvariables cannot be copied or discarded at will.\n  In SMTs, traditional tree-like terms are replaced by string diagrams,\ntopological entities that can be intuitively thoughts as diagrams of wires and\nboxes. Recently, string diagrams have become increasingly popular as a\ngraphical syntax to reason about computational models across diverse fields,\nincluding programming language semantics, circuit theory, quantum mechanics,\nlinguistics, and control theory. In applications, it is often convenient to\nimplement the equations appearing in SMTs as rewriting rules. This poses the\nchallenge of extending the traditional theory of term rewriting, which has been\ndeveloped for algebraic theories, to string diagrams.\n  In this paper, we develop a mathematical theory of string diagram rewriting\nfor SMTs. Our approach exploits the correspondence between string diagram\nrewriting and double pushout (DPO) rewriting of certain graphs, introduced in\nthe first paper of this series. Such a correspondence is only sound when the\nSMT includes a Frobenius algebra structure. In the present work, we show how an\nanalogous correspondence may be established for arbitrary SMTs, once an\nappropriate notion of DPO rewriting (which we call convex) is identified.\n  As proof of concept, we use our approach to show termination of two SMTs of\ninterest: Frobenius semi-algebras and bialgebras.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 22:39:54 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Bonchi", "Filippo", ""], ["Gadducci", "Fabio", ""], ["Kissinger", "Aleks", ""], ["Sobocinski", "Pawel", ""], ["Zanasi", "Fabio", ""]]}, {"id": "2104.14697", "submitter": "Micha{\\l} Zawidzki", "authors": "Joanna Goli\\'nska Pilarek, Taneli Huuskonen, Micha{\\l} Zawidzki", "title": "Tableau-based decision procedure for non-Fregean logic of sentential\n  identity", "comments": "This is a full version of a conference paper that will appear in the\n  proceedings of the 28th International Conference on Automated Deduction\n  (CADE)", "journal-ref": null, "doi": "10.1007/978-3-030-79876-5_3", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentential Calculus with Identity (SCI) is an extension of classical\npropositional logic, featuring a new connective of identity between formulas.\nIn SCI two formulas are said to be identical if they share the same denotation.\nIn the semantics of the logic, truth values are distinguished from denotations,\nhence the identity connective is strictly stronger than classical equivalence.\nIn this paper we present a sound, complete, and terminating algorithm deciding\nthe satisfiability of SCI-formulas, based on labelled tableaux. To the best of\nour knowledge, it is the first implemented decision procedure for SCI which\nruns in NP, i.e., is complexity-optimal. The obtained complexity bound is a\nresult of dividing derivation rules in the algorithm into two sets:\ndecomposition and equality rules, whose interplay yields derivation trees with\nbranches of polynomial length with respect to the size of the investigated\nformula. We describe an implementation of the procedure and compare its\nperformance with implementations of other calculi for SCI (for which, however,\nthe termination results were not established). We show possible refinements of\nour algorithm and discuss the possibility of extending it to other non-Fregean\nlogics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 23:42:27 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Pilarek", "Joanna Goli\u0144ska", ""], ["Huuskonen", "Taneli", ""], ["Zawidzki", "Micha\u0142", ""]]}, {"id": "2104.14709", "submitter": "Nikhil Vyas", "authors": "Ronald Fagin, Jonathan Lenchner, Kenneth W. Regan, Nikhil Vyas", "title": "Multi-Structural Games and Number of Quantifiers", "comments": "To appear in LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multi-structural games, played on two sets $\\mathcal{A}$ and\n$\\mathcal{B}$ of structures. These games generalize Ehrenfeucht-Fra\\\"{i}ss\\'{e}\ngames. Whereas Ehrenfeucht-Fra\\\"{i}ss\\'{e} games capture the quantifier rank of\na first-order sentence, multi-structural games capture the number of\nquantifiers, in the sense that Spoiler wins the $r$-round game if and only if\nthere is a first-order sentence $\\phi$ with at most $r$ quantifiers, where\nevery structure in $\\mathcal{A}$ satisfies $\\phi$ and no structure in\n$\\mathcal{B}$ satisfies $\\phi$. We use these games to give a complete\ncharacterization of the number of quantifiers required to distinguish linear\norders of different sizes, and develop machinery for analyzing structures\nbeyond linear orders.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 00:57:23 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Fagin", "Ronald", ""], ["Lenchner", "Jonathan", ""], ["Regan", "Kenneth W.", ""], ["Vyas", "Nikhil", ""]]}, {"id": "2104.14759", "submitter": "Jorge A. P\\'erez", "authors": "Joseph W. N. Paulus and Daniele Nantes-Sobrinho and Jorge A. P\\'erez", "title": "Non-Deterministic Functions as Non-Deterministic Processes (Extended\n  Version)", "comments": "Extended version of an FSCD 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study encodings of the lambda-calculus into the pi-calculus in the\nunexplored case of calculi with non-determinism and failures. On the sequential\nside, we consider lambdafail, a new non-deterministic calculus in which\nintersection types control resources (terms); on the concurrent side, we\nconsider spi, a pi-calculus in which non-determinism and failure rest upon a\nCurry-Howard correspondence between linear logic and session types. We present\na typed encoding of lambdafail into spi and establish its correctness. Our\nencoding precisely explains the interplay of non-deterministic and fail-prone\nevaluation in lambdafail via typed processes in spi. In particular, it shows\nhow failures in sequential evaluation (absence/excess of resources) can be\nneatly codified as interaction protocols.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 05:17:14 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Paulus", "Joseph W. N.", ""], ["Nantes-Sobrinho", "Daniele", ""], ["P\u00e9rez", "Jorge A.", ""]]}, {"id": "2104.14789", "submitter": "Linde Vanbesien", "authors": "Linde Vanbesien, Maurice Bruynooghe and Marc Denecker", "title": "Analyzing Semantics of Aggregate Answer Set Programming Using\n  Approximation Fixpoint Theory", "comments": "10pages, submitted to KR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregates provide a concise way to express complex knowledge. While they are\neasily understood by humans, formalizing aggregates for answer set programming\n(ASP) has proven to be challenging . The literature offers many approaches that\nare not always compatible. One of these approaches, based on Approximation\nFixpoint Theory (AFT), has been developed in a logic programming context and\nhas not found much resonance in the ASP-community. In this paper we revisit\nthis work. We introduce the abstract notion of a ternary satisfaction relation\nand define stable semantics in terms of it. We show that ternary satisfaction\nrelations bridge the gap between the standard Gelfond-Lifschitz reduct, and\nstable semantics as defined in the framework of AFT. We analyse the properties\nof ternary satisfaction relations for handling aggregates in ASP programs.\nFinally, we show how different methods for handling aggregates taken from the\nliterature can be described in the framework and we study the corresponding\nternary satisfaction relations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 07:06:27 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Vanbesien", "Linde", ""], ["Bruynooghe", "Maurice", ""], ["Denecker", "Marc", ""]]}, {"id": "2104.14796", "submitter": "Yuan Feng", "authors": "Yuan Feng, Sanjiang Li, Mingsheng Ying", "title": "Verification of Distributed Quantum Programs", "comments": "arXiv admin note: text overlap with arXiv:2008.06812", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Distributed quantum systems and especially the Quantum Internet have the\never-increasing potential to fully demonstrate the power of quantum\ncomputation. This is particularly true given that developing a general-purpose\nquantum computer is much more difficult than connecting many small quantum\ndevices. One major challenge of implementing distributed quantum systems is\nprogramming them and verifying their correctness. In this paper, we propose a\nCSP-like distributed programming language to facilitate the specification and\nverification of such systems. After presenting its operational and denotational\nsemantics, we develop a Hoare-style logic for distributed quantum programs and\nestablish its soundness and (relative) completeness with respect to both\npartial and total correctness. The effectiveness of the logic is demonstrated\nby its applications in the verification of quantum teleportation and local\nimplementation of non-local CNOT gates, two important algorithms widely used in\ndistributed quantum systems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 07:23:55 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Feng", "Yuan", ""], ["Li", "Sanjiang", ""], ["Ying", "Mingsheng", ""]]}, {"id": "2104.14856", "submitter": "Roberto Gorrieri", "authors": "Arnaldo Cesco and Roberto Gorrieri", "title": "Decidability of Two Truly Concurrent Equivalences for Finite Bounded\n  Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove that (strong) fully-concurrent bisimilarity and causal-net\nbisimilarity are decidable for finite bounded Petri nets. The proofs are based\non a generalization of the ordered marking proof technique that Vogler used to\ndemonstrate that (strong) fully-concurrent bisimilarity (or, equivalently,\nhistorypreserving bisimilarity) is decidable on finite safe nets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 09:20:04 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cesco", "Arnaldo", ""], ["Gorrieri", "Roberto", ""]]}, {"id": "2104.14859", "submitter": "Roberto Gorrieri", "authors": "Arnaldo Cesco and Roberto Gorrieri", "title": "A Decidable Equivalence for a Turing-complete, Distributed Model of\n  Computation", "comments": "arXiv admin note: substantial text overlap with arXiv:2104.01392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Place/Transition Petri nets with inhibitor arcs (PTI nets for short), which\nare a well-known Turing-complete, distributed model of computation, are\nequipped with a decidable, behavioral equivalence, called pti-place\nbisimilarity, that conservatively extends place bisimilarity defined over\nPlace/Transition nets (without inhibitor arcs). We prove that pti-place\nbisimilarity is sensible, as it respects the causal semantics of PTI nets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 09:23:41 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cesco", "Arnaldo", ""], ["Gorrieri", "Roberto", ""]]}, {"id": "2104.14877", "submitter": "Robin Kaarsgaard", "authors": "Siddharth Bhaskar and Robin Kaarsgaard", "title": "Graph Traversals as Universal Constructions", "comments": "21 pages (including 9 pages in appendix), 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit a decomposition of graph traversals to give a novel\ncharacterization of depth-first and breadth-first traversals as universal\nconstructions. Specifically, we introduce functors from two different\ncategories of edge-ordered directed graphs into two different categories of\ntransitively closed edge-ordered graphs; one defines the lexicographic\ndepth-first traversal and the other the lexicographic breadth-first traversal.\nWe show that each functor factors as a composition of universal constructions,\nand that the usual presentation of traversals as linear orders on vertices can\nbe recovered with the addition of an inclusion functor. Finally, we raise the\nquestion of to what extent we can recover search algorithms from the\ncategorical description of the traversal they compute.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 10:05:47 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Bhaskar", "Siddharth", ""], ["Kaarsgaard", "Robin", ""]]}, {"id": "2104.14884", "submitter": "Nicolas Troquard", "authors": "Joseph Boudou and Andreas Herzig and Nicolas Troquard", "title": "Resource separation in dynamic logic of propositional assignments", "comments": null, "journal-ref": "Journal of Logical and Algebraic Methods in Programming, 2021,\n  100683, ISSN 2352-2208, https://doi.org/10.1016/j.jlamp.2021.100683.\n  (https://www.sciencedirect.com/science/article/pii/S2352220821000468)", "doi": "10.1016/j.jlamp.2021.100683", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend dynamic logic of propositional assignments by adding an operator of\nparallel composition that is inspired by separation logics. We provide an\naxiomatisation via reduction axioms, thereby establishing decidability. We also\nprove that the complexity of both the model checking and the satisfiability\nproblem stay in PSPACE.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 10:14:46 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Boudou", "Joseph", ""], ["Herzig", "Andreas", ""], ["Troquard", "Nicolas", ""]]}, {"id": "2104.14988", "submitter": "Noemi Passing", "authors": "Bernd Finkbeiner, Philippe Heim, Noemi Passing", "title": "Temporal Stream Logic modulo Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Stream Logic (TSL) is a temporal logic that extends LTL with updates\nand predicates over arbitrary function terms. This allows for specifying\ndata-intensive systems for which LTL is not expressive enough. In TSL,\nfunctions and predicates are uninterpreted. In this paper, we investigate the\nsatisfiability problem of TSL both with respect to the standard underlying\ntheory of uninterpreted functions and with respect to other theories such as\nPresburger arithmetic. We present an algorithm for checking the satisfiability\nof a TSL formula in the theory of uninterpreted functions and evaluate it on\ndifferent benchmarks: It scales well and is able to validate assumptions in a\nreal-world system design. The algorithm is not guaranteed to terminate. In\nfact, we show that TSL satisfiability is highly undecidable in the theories of\nuninterpreted functions, equality, and Presburger arithmetic, proving that no\ncomplete algorithm exists. However, we identify three fragments of TSL for\nwhich the satisfiability problem is (semi-)decidable in the theory of\nuninterpreted functions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:22:41 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Heim", "Philippe", ""], ["Passing", "Noemi", ""]]}, {"id": "2104.15021", "submitter": "Xavier Allamigeon", "authors": "Xavier Allamigeon, Ricardo D. Katz and Pierre-Yves Strub", "title": "Formalizing the Face Lattice of Polyhedra", "comments": "22 pages, 4 figures, extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faces play a central role in the combinatorial and computational aspects of\npolyhedra. In this paper, we present the first formalization of faces of\npolyhedra in the proof assistant Coq. This builds on the formalization of a\nlibrary providing the basic constructions and operations over polyhedra,\nincluding projections, convex hulls and images under linear maps. Moreover, we\ndesign a special mechanism which automatically introduces an appropriate\nrepresentation of a polyhedron or a face, depending on the context of the\nproof. We demonstrate the usability of this approach by establishing some of\nthe most important combinatorial properties of faces, namely that they\nconstitute a family of graded atomistic and coatomistic lattices closed under\ninterval sublattices. We also prove a theorem due to Balinski on the\n$d$-connectedness of the adjacency graph of polytopes of dimension $d$.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 14:19:11 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Allamigeon", "Xavier", ""], ["Katz", "Ricardo D.", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "2104.15053", "submitter": "Martin Dieguez", "authors": "Philippe Balbiani, Mart\\'in Di\\'eguez and David Fern\\'andez-Duque", "title": "Some constructive variants of S4 with the finite model property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logics CS4 and IS4 are intuitionistic variants of the modal logic S4.\nWhether the finite model property holds for each of these logics has been a\nlong-standing open problem. In this paper we introduce two logics closely\nrelated to IS4: GS4, obtained by adding the Godel-Dummett axiom to IS4, and\nS4I, obtained by reversing the roles of the modal and intuitionistic relations.\nWe then prove that CS4, GS4, and S4I all enjoy the finite model property.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:21:01 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Balbiani", "Philippe", ""], ["Di\u00e9guez", "Mart\u00edn", ""], ["Fern\u00e1ndez-Duque", "David", ""]]}]