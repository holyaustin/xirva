[{"id": "1502.00112", "submitter": "Jean-Louis Krivine", "authors": "Jean-Louis Krivine", "title": "Bar recursion in classical realisability : dependent choice and\n  continuum hypothesis", "comments": "11 pages", "journal-ref": "Proceedings CSL 2016 LIPIcs vol. 62 pp. 25:1--25:11 (2016)", "doi": "10.4230/LIPIcs.CSL.2016.25", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about the bar recursion operator in the context of classical\nrealizability. After the pioneering work of Berardi, Bezem & Coquand [1], T.\nStreicher has shown [10], by means of their bar recursion operator, that the\nrealizability models of ZF, obtained from usual models of $\\lambda$-calculus\n(Scott domains, coherent spaces, . . .), satisfy the axiom of dependent choice.\nWe give a proof of this result, using the tools of classical realizability.\nMoreover, we show that these realizability models satisfy the well ordering of\n$\\mathbb{R}$ and the continuum hypothesis These formulas are therefore realized\nby closed $\\lambda_c$-terms. This allows to obtain programs from proofs of\narithmetical formulas using all these axioms.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 14:35:20 GMT"}, {"version": "v2", "created": "Wed, 6 May 2015 15:00:57 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2015 10:56:48 GMT"}, {"version": "v4", "created": "Mon, 16 May 2016 17:21:20 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Krivine", "Jean-Louis", ""]]}, {"id": "1502.00138", "submitter": "Zachary Kincaid", "authors": "Azadeh Farzan and Zachary Kincaid", "title": "Compositional Invariant Generation via Linear Recurrence Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method for automatically generating numerical\ninvariants for imperative programs. Given a program, our procedure computes a\nbinary input/output relation on program states which over-approximates the\nbehaviour of the program. It is compositional in the sense that it operates by\ndecomposing the program into parts, computing an abstract meaning of each part,\nand then composing the meanings. Our method for approximating loop behaviour is\nbased on first approximating the meaning of the loop body, extracting\nrecurrence relations from that approximation, and then using the closed forms\nto approximate the loop. Our experiments demonstrate that on verification\ntasks, our method is competitive with leading invariant generation and\nverification tools.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 16:43:46 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Farzan", "Azadeh", ""], ["Kincaid", "Zachary", ""]]}, {"id": "1502.00145", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert (LACL)", "title": "An in-between \"implicit\" and \"explicit\" complexity: Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit Computational Complexity makes two aspects implicit, by manipulating\nprogramming languages rather than models of com-putation, and by internalizing\nthe bounds rather than using external measure. We survey how automata theory\ncontributed to complexity with a machine-dependant with implicit bounds model.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 18:44:47 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 07:33:03 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LACL"]]}, {"id": "1502.00611", "submitter": "J\\\"urgen Koslowski", "authors": "Krishnendu Chatterjee and Zuzana K\\v{r}et\\'insk\\'a and Jan\n  K\\v{r}et\\'insk\\'y", "title": "Unifying Two Views on Multiple Mean-Payoff Objectives in Markov Decision\n  Processes", "comments": "Extended journal version of the LICS'15 paper", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (July 3,\n  2017) lmcs:3757", "doi": "10.23638/LMCS-13(2:15)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov decision processes (MDPs) with multiple limit-average (or\nmean-payoff) objectives. There exist two different views: (i) the expectation\nsemantics, where the goal is to optimize the expected mean-payoff objective,\nand (ii) the satisfaction semantics, where the goal is to maximize the\nprobability of runs such that the mean-payoff value stays above a given vector.\nWe consider optimization with respect to both objectives at once, thus unifying\nthe existing semantics. Precisely, the goal is to optimize the expectation\nwhile ensuring the satisfaction constraint. Our problem captures the notion of\noptimization with respect to strategies that are risk-averse (i.e., ensure\ncertain probabilistic guarantee). Our main results are as follows: First, we\npresent algorithms for the decision problems which are always polynomial in the\nsize of the MDP. We also show that an approximation of the Pareto-curve can be\ncomputed in time polynomial in the size of the MDP, and the approximation\nfactor, but exponential in the number of dimensions. Second, we present a\ncomplete characterization of the strategy complexity (in terms of memory bounds\nand randomization) required to solve our problem.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 20:34:02 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2015 11:46:02 GMT"}, {"version": "v3", "created": "Thu, 22 Dec 2016 13:45:44 GMT"}, {"version": "v4", "created": "Thu, 29 Jun 2017 17:23:08 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["K\u0159et\u00ednsk\u00e1", "Zuzana", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""]]}, {"id": "1502.00814", "submitter": "Roman Kuznets", "authors": "Roman Kuznets and Bj\\\"orn Lellmann", "title": "Grafting Hypersequents onto Nested Sequents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new Gentzen-style framework of grafted hypersequents that\ncombines the formalism of nested sequents with that of hypersequents. To\nillustrate the potential of the framework, we present novel calculi for the\nmodal logics $\\mathsf{K5}$ and $\\mathsf{KD5}$, as well as for extensions of the\nmodal logics $\\mathsf{K}$ and $\\mathsf{KD}$ with the axiom for shift\nreflexivity. The latter of these extensions is also known as $\\mathsf{SDL}^+$\nin the context of deontic logic. All our calculi enjoy syntactic cut\nelimination and can be used in backwards proof search procedures of optimal\ncomplexity. The tableaufication of the calculi for $\\mathsf{K5}$ and\n$\\mathsf{KD5}$ yields simplified prefixed tableau calculi for these logic\nreminiscent of the simplified tableau system for $\\mathsf{S5}$, which might be\nof independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 11:24:42 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 17:54:52 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Kuznets", "Roman", ""], ["Lellmann", "Bj\u00f6rn", ""]]}, {"id": "1502.00831", "submitter": "Robin Piedeleu", "authors": "Robin Piedeleu, Dimitri Kartsaklis, Bob Coecke and Mehrnoosh Sadrzadeh", "title": "Open System Categorical Quantum Semantics in Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO math.CT math.QA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Originally inspired by categorical quantum mechanics (Abramsky and Coecke,\nLiCS'04), the categorical compositional distributional model of natural\nlanguage meaning of Coecke, Sadrzadeh and Clark provides a conceptually\nmotivated procedure to compute the meaning of a sentence, given its grammatical\nstructure within a Lambek pregroup and a vectorial representation of the\nmeaning of its parts. The predictions of this first model have outperformed\nthat of other models in mainstream empirical language processing tasks on large\nscale data. Moreover, just like CQM allows for varying the model in which we\ninterpret quantum axioms, one can also vary the model in which we interpret\nword meaning.\n  In this paper we show that further developments in categorical quantum\nmechanics are relevant to natural language processing too. Firstly, Selinger's\nCPM-construction allows for explicitly taking into account lexical ambiguity\nand distinguishing between the two inherently different notions of homonymy and\npolysemy. In terms of the model in which we interpret word meaning, this means\na passage from the vector space model to density matrices. Despite this change\nof model, standard empirical methods for comparing meanings can be easily\nadopted, which we demonstrate by a small-scale experiment on real-world data.\nThis experiment moreover provides preliminary evidence of the validity of our\nproposed new model for word meaning.\n  Secondly, commutative classical structures as well as their non-commutative\ncounterparts that arise in the image of the CPM-construction allow for encoding\nrelative pronouns, verbs and adjectives, and finally, iteration of the\nCPM-construction, something that has no counterpart in the quantum realm,\nenables one to accommodate both entailment and ambiguity.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 12:16:19 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 19:06:34 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Piedeleu", "Robin", ""], ["Kartsaklis", "Dimitri", ""], ["Coecke", "Bob", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1502.00944", "submitter": "Emanuele D'Osualdo", "authors": "Emanuele D'Osualdo, Luke Ong", "title": "A Type System for proving Depth Boundedness in the pi-calculus", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The depth-bounded fragment of the pi-calculus is an expressive class of\nsystems enjoying decidability of some important verification problems.\nUnfortunately membership of the fragment is undecidable. We propose a novel\ntype system, parameterised over a finite forest, that formalises name usage by\npi-terms in a manner that respects the forest. Type checking is decidable and\ntype inference is computable; furthermore typable pi-terms are guaranteed to be\ndepth bounded.\n  The second contribution of the paper is a proof of equivalence between the\nsemantics of typable terms and nested data class memory automata, a class of\nautomata over data words. We believe this connection can help to establish new\nlinks between the rich theory of infinite-alphabet automata and nominal\ncalculi.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 18:02:32 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2015 12:44:18 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["D'Osualdo", "Emanuele", ""], ["Ong", "Luke", ""]]}, {"id": "1502.00978", "submitter": "Grigoriy Bokov", "authors": "Grigoriy V. Bokov", "title": "Undecidable problems for propositional calculi with implication", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1407.7010", "journal-ref": null, "doi": "10.1093/jigpal/jzw013", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we deal with propositional calculi over a signature\ncontaining the classical implication $\\to$ with the rules of modus ponens and\nsubstitution. For these calculi we consider few recognizing problems such as\nrecognizing derivations, extensions, completeness, and axiomatizations. The\nmain result of this paper is to prove that the problem of recognizing\nextensions is undecidable for every propositional calculus, and the problems of\nrecognizing axiomatizations and completeness are undecidable for propositional\ncalculi containing the formula $x \\to ( y \\to x )$. As a corollary, the problem\nof derivability of a fixed formula $A$ is also undecidable for all $A$.\nMoreover, we give a historical survey of related results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 19:49:52 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Bokov", "Grigoriy V.", ""]]}, {"id": "1502.01257", "submitter": "Thomas Seiller", "authors": "Thomas Seiller", "title": "Towards a Complexity-through-Realisability Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain how recent developments in the fields of realisability models for\nlinear logic -- or geometry of interaction -- and implicit computational\ncomplexity can lead to a new approach of implicit computational complexity.\nThis semantic-based approach should apply uniformly to various computational\nparadigms, and enable the use of new mathematical methods and tools to attack\nproblem in computational complexity. This paper provides the background,\nmotivations and perspectives of this complexity-through-realisability theory to\nbe developed, and illustrates it with recent results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 17:15:16 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 05:25:49 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Seiller", "Thomas", ""]]}, {"id": "1502.01838", "submitter": "Sean Sedwards", "authors": "Cyrille Jegourel, Axel Legay, Sean Sedwards and Louis-Marie Traonouez", "title": "Distributed Verification of Rare Properties using Importance Splitting\n  Observers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare properties remain a challenge for statistical model checking (SMC) due\nto the quadratic scaling of variance with rarity. We address this with a\nvariance reduction framework based on lightweight importance splitting\nobservers. These expose the model-property automaton to allow the construction\nof score functions for high performance algorithms.\n  The confidence intervals defined for importance splitting make it appealing\nfor SMC, but optimising its performance in the standard way makes distribution\ninefficient. We show how it is possible to achieve equivalently good results in\nless time by distributing simpler algorithms. We first explore the challenges\nposed by importance splitting and present an algorithm optimised for\ndistribution. We then define a specific bounded time logic that is compiled\ninto memory-efficient observers to monitor executions. Finally, we demonstrate\nour framework on a number of challenging case studies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 10:00:23 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 14:41:26 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Jegourel", "Cyrille", ""], ["Legay", "Axel", ""], ["Sedwards", "Sean", ""], ["Traonouez", "Louis-Marie", ""]]}, {"id": "1502.01993", "submitter": "Marc Bagnol", "authors": "Marc Bagnol", "title": "MALL proof equivalence is Logspace-complete, via binary decision\n  diagrams", "comments": "in TLCA 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof equivalence in a logic is the problem of deciding whether two proofs\nare equivalent modulo a set of permutation of rules that reflects the\ncommutative conversions of its cut-elimination procedure. As such, it is\nrelated to the question of proofnets: finding canonical representatives of\nequivalence classes of proofs that have good computational properties. It can\nalso be seen as the word problem for the notion of free category corresponding\nto the logic.\n  It has been recently shown that proof equivalence in MLL (the multiplicative\nwith units fragment of linear logic) is PSPACE-complete, which rules out any\nlow-complexity notion of proofnet for this particular logic.\n  Since it is another fragment of linear logic for which attempts to define a\nfully satisfactory low-complexity notion of proofnet have not been successful\nso far, we study proof equivalence in MALL- (multiplicative-additive without\nunits fragment of linear logic) and discover a situation that is totally\ndifferent from the MLL case. Indeed, we show that proof equivalence in MALL-\ncorresponds (under AC0 reductions) to equivalence of binary decision diagrams,\na data structure widely used to represent and analyze Boolean functions\nefficiently.\n  We show these two equivalent problems to be LOGSPACE-complete. If this\ntechnically leaves open the possibility for a complete solution to the question\nof proofnets for MALL-, the established relation with binary decision diagrams\nactually suggests a negative solution to this problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 19:11:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 15:56:43 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Bagnol", "Marc", ""]]}, {"id": "1502.02030", "submitter": "Lu\\'is Tarrataca", "authors": "Lu\\'is Tarrataca and Andreas Wichert", "title": "Quantum Iterative Deepening with an application to the Halting problem", "comments": null, "journal-ref": "PLOS One, March 2013", "doi": "10.1371/journal.pone.0057309", "report-no": null, "categories": "quant-ph cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical models of computation traditionally resort to halting schemes in\norder to enquire about the state of a computation. In such schemes, a\ncomputational process is responsible for signalling an end of a calculation by\nsetting a halt bit, which needs to be systematically checked by an observer.\nThe capacity of quantum computational models to operate on a superposition of\nstates requires an alternative approach. From a quantum perspective, any\nmeasurement of an equivalent halt qubit would have the potential to inherently\ninterfere with the computation by provoking a random collapse amongst the\nstates. This issue is exacerbated by undecidable problems such as the\n\\textit{Entscheidungsproblem} which require universal computational models,\n\\textit{e.g.} the classical Turing machine, to be able to proceed indefinitely.\nIn this work we present an alternative view of quantum computation based on\nproduction system theory in conjunction with Grover's amplitude amplification\nscheme that allows for (1) a detection of halt states without interfering with\nthe final result of a computation; (2) the possibility of non-terminating\ncomputation and (3) an inherent speedup to occur during computations\nsusceptible of parallelization. We discuss how such a strategy can be employed\nin order to simulate classical Turing machines.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 17:28:02 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Tarrataca", "Lu\u00eds", ""], ["Wichert", "Andreas", ""]]}, {"id": "1502.02131", "submitter": "Ulrich Berger", "authors": "Ulrich Berger (Swansea University), Andrew Lawrence (Swansea\n  University), Fredrik Nordvall Forsberg (University of Birmingham), Monika\n  Seisenberger (Swansea University)", "title": "Extracting verified decision procedures: DPLL and Resolution", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 10,\n  2015) lmcs:766", "doi": "10.2168/LMCS-11(1:6)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is concerned with the application of the program extraction\ntechnique to a new class of problems: the synthesis of decision procedures for\nthe classical satisfiability problem that are correct by construction. To this\nend, we formalize a completeness proof for the DPLL proof system and extract a\nSAT solver from it. When applied to a propositional formula in conjunctive\nnormal form the program produces either a satisfying assignment or a DPLL\nderivation showing its unsatisfiability. We use non-computational quantifiers\nto remove redundant computational content from the extracted program and\ntranslate it into Haskell to improve performance. We also prove the equivalence\nbetween the resolution proof system and the DPLL proof system with a bound on\nthe size of the resulting resolution proof. This demonstrates that it is\npossible to capture quantitative information about the extracted program on the\nproof level. The formalization is carried out in the interactive proof\nassistant Minlog.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 12:18:54 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2015 14:55:12 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Berger", "Ulrich", "", "Swansea University"], ["Lawrence", "Andrew", "", "Swansea\n  University"], ["Forsberg", "Fredrik Nordvall", "", "University of Birmingham"], ["Seisenberger", "Monika", "", "Swansea University"]]}, {"id": "1502.02272", "submitter": "Robert Dustin Wehr", "authors": "Robert Dustin Wehr", "title": "Rigorous Deductive Argumentation for Socially Relevant Issues", "comments": "PhD Thesis. 130 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important problems for society are describable only in vague terms,\ndependent on subjective positions, and missing highly relevant data. This\nthesis is intended to revive and further develop the view that giving\nnon-trivial, rigorous deductive arguments concerning such problems -without\neliminating the complications of vagueness, subjectivity, and uncertainty- is,\nthough very difficult, not problematic in principle, does not require the\ninvention of new logics -classical first-order logic will do- and is something\nthat more mathematically-inclined people should be pursuing. The framework of\ninterpreted formal proofs is presented for formalizing and criticizing rigorous\ndeductive arguments about vague, subjective, and uncertain issues, and its\nadequacy is supported largely by a number of major examples. This thesis also\ndocuments progress towards a web system for collaboratively authoring and\ncriticizing such arguments, which is the ultimate goal of this project.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 16:57:15 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 17:47:50 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Wehr", "Robert Dustin", ""]]}, {"id": "1502.02327", "submitter": "Herbert Rocha", "authors": "Herbert Rocha and Hussama Ismail and Lucas Cordeiro and Raimundo\n  Barreto", "title": "Model Checking C Programs with Loops via k-Induction and Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel proof by induction algorithm, which combines k-induction\nwith invariants to model check C programs with bounded and unbounded loops. The\nk-induction algorithm consists of three cases: in the base case, we aim to find\na counterexample with up to k loop unwindings; in the forward condition, we\ncheck whether loops have been fully unrolled and that the safety property P\nholds in all states reachable within k unwindings; and in the inductive step,\nwe check that whenever P holds for k unwindings, it also holds after the next\nunwinding of the system. For each step of the k-induction algorithm, we infer\ninvariants using affine constraints (i.e., polyhedral) to specify pre- and\npost-conditions. The algorithm was implemented in two different ways, with and\nwithout invariants using polyhedral, and the results were compared.\nExperimental results show that both forms can handle a wide variety of safety\nproperties; however, the k-induction algorithm adopting polyhedral solves more\nverification tasks, which demonstrate an improvement of the induction algorithm\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 01:37:48 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Rocha", "Herbert", ""], ["Ismail", "Hussama", ""], ["Cordeiro", "Lucas", ""], ["Barreto", "Raimundo", ""]]}, {"id": "1502.02388", "submitter": "Dag Normann", "authors": "Dag Normann (University of Oslo)", "title": "The extensional realizability model of continuous functionals and three\n  weakly non-constructive classical theorems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 16,\n  2015) lmcs:1174", "doi": "10.2168/LMCS-11(1:8)2015", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate wether three statements in analysis, that can be proved\nclassically, are realizable in the realizability model of extensional\ncontinuous functionals induced by Kleene's second model $K_2$. We prove that a\nformulation of the Riemann Permutation Theorem as well as the statement that\nall partially Cauchy sequences are Cauchy cannot be realized in this model,\nwhile the statement that the product of two anti-Specker spaces is anti-Specker\ncan be realized.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 07:24:52 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2015 20:08:25 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Normann", "Dag", "", "University of Oslo"]]}, {"id": "1502.02404", "submitter": "Daniel de Carvalho", "authors": "Daniel de Carvalho", "title": "The relational model is injective for Multiplicative Exponential Linear\n  Logic", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a completeness result for Multiplicative Exponential Linear Logic\n(MELL): we show that the relational model is injective for MELL proof-nets,\ni.e. the equality between MELL proof-nets in the relational model is exactly\naxiomatized by cut-elimination.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 09:16:26 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 19:17:38 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2015 20:57:59 GMT"}, {"version": "v4", "created": "Tue, 10 May 2016 22:19:49 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["de Carvalho", "Daniel", ""]]}, {"id": "1502.02448", "submitter": "Tom Crick", "authors": "Tom Crick and Benjamin A. Hall and Samin Ishtiaq", "title": "Dear CAV, We Need to Talk About Reproducibility", "comments": "Submitted to the 27th International Conference on Computer Aided\n  Verification (CAV 2015); 9 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many times have you tried to re-implement a past CAV tool paper, and\nfailed?\n  Reliably reproducing published scientific discoveries has been acknowledged\nas a barrier to scientific progress for some time but there remains only a\nsmall subset of software available to support the specific needs of the\nresearch community (i.e. beyond generic tools such as source code\nrepositories). In this paper we propose an infrastructure for enabling\nreproducibility in our community, by automating the build, unit testing and\nbenchmarking of research software.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 11:59:40 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Crick", "Tom", ""], ["Hall", "Benjamin A.", ""], ["Ishtiaq", "Samin", ""]]}, {"id": "1502.02484", "submitter": "Florian Lonsing", "authors": "Florian Lonsing and Uwe Egly", "title": "Incrementally Computing Minimal Unsatisfiable Cores of QBFs via a Clause\n  Group Solver API", "comments": "(fixed typo), camera-ready version, 6-page tool paper, to appear in\n  proceedings of SAT 2015, LNCS, Springer", "journal-ref": null, "doi": "10.1007/978-3-319-24318-4_14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the incremental computation of minimal unsatisfiable cores (MUCs)\nof QBFs. To this end, we equipped our incremental QBF solver DepQBF with a\nnovel API to allow for incremental solving based on clause groups. A clause\ngroup is a set of clauses which is incrementally added to or removed from a\npreviously solved QBF. Our implementation of the novel API is related to\nincremental SAT solving based on selector variables and assumptions. However,\nthe API entirely hides selector variables and assumptions from the user, which\nfacilitates the integration of DepQBF in other tools. We present implementation\ndetails and, for the first time, report on experiments related to the\ncomputation of MUCs of QBFs using DepQBF's novel clause group API.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 13:48:31 GMT"}, {"version": "v2", "created": "Tue, 12 May 2015 08:12:49 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2015 13:51:32 GMT"}, {"version": "v4", "created": "Thu, 23 Jul 2015 10:08:56 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Lonsing", "Florian", ""], ["Egly", "Uwe", ""]]}, {"id": "1502.02585", "submitter": "Jorge A. P\\'erez", "authors": "Dimitrios Kouzapas, Jorge A. P\\'erez, Nobuko Yoshida", "title": "Core Higher-Order Session Processes: Tractable Equivalences and Relative\n  Expressiveness", "comments": "90 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes tractable bisimulations for the higher-order pi-calculus\nwith session primitives (HOpi) and offers a complete study of the expressivity\nof its most significant subcalculi. First we develop three typed bisimulations,\nwhich are shown to coincide with contextual equivalence. These\ncharacterisations demonstrate that observing as inputs only a specific finite\nset of higher-order values (which inhabit session types) suffices to reason\nabout HOp} processes. Next, we identify HO, a minimal, second-order subcalculus\nof HOpi in which higher-order applications/abstractions, name-passing, and\nrecursion are absent. We show that HO can encode HOpi extended with\nhigher-order applications and abstractions and that a first-order session\npi-calculus can encode HOpi. Both encodings are fully abstract. We also prove\nthat the session pi-calculus with passing of shared names cannot be encoded\ninto HOpi without shared names. We show that HOpi, HO, and pi are equally\nexpressive; the expressivity of HO enables effective reasoning about typed\nequivalences for higher-order processes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 18:13:14 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 17:07:55 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Kouzapas", "Dimitrios", ""], ["P\u00e9rez", "Jorge A.", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1502.02834", "submitter": "Martin Chmel\\'ik", "authors": "Tom\\'a\\v{s} Br\\'azdil and Krishnendu Chatterjee and Martin Chmel\\'ik\n  and Andreas Fellner and Jan K\\v{r}et\\'insk\\'y", "title": "Counterexample Explanation by Learning Small Strategies in Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While for deterministic systems, a counterexample to a property can simply be\nan error trace, counterexamples in probabilistic systems are necessarily more\ncomplex. For instance, a set of erroneous traces with a sufficient cumulative\nprobability mass can be used. Since these are too large objects to understand\nand manipulate, compact representations such as subchains have been considered.\nIn the case of probabilistic systems with non-determinism, the situation is\neven more complex. While a subchain for a given strategy (or scheduler,\nresolving non-determinism) is a straightforward choice, we take a different\napproach. Instead, we focus on the strategy - which can be a counterexample to\nviolation of or a witness of satisfaction of a property - itself, and extract\nthe most important decisions it makes, and present its succinct representation.\nThe key tools we employ to achieve this are (1) introducing a concept of\nimportance of a state w.r.t. the strategy, and (2) learning using decision\ntrees. There are three main consequent advantages of our approach. Firstly, it\nexploits the quantitative information on states, stressing the more important\ndecisions. Secondly, it leads to a greater variability and degree of freedom in\nrepresenting the strategies. Thirdly, the representation uses a\nself-explanatory data structure. In summary, our approach produces more\nsuccinct and more explainable strategies, as opposed to e.g. binary decision\ndiagrams. Finally, our experimental results show that we can extract several\nrules describing the strategy even for very large systems that do not fit in\nmemory, and based on the rules explain the erroneous behaviour.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 10:06:17 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chatterjee", "Krishnendu", ""], ["Chmel\u00edk", "Martin", ""], ["Fellner", "Andreas", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""]]}, {"id": "1502.02910", "submitter": "Georgiana Caltais", "authors": "Georgiana Caltais", "title": "Coalgebraic Tools for Bisimilarity and Decorated Trace Semantics", "comments": "thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modelling, specification and study of the semantics of concurrent\nreactive systems have been interesting research topics for many years now. The\naim of this thesis is to exploit the strengths of the (co)algebraic framework\nin modelling reactive systems and reasoning on several types of associated\nsemantics, in a uniform fashion. In particular, we are interested in handling\nnotions of behavioural equivalence/preorder ranging from bisimilarity for\nsystems that can be represented as non-deterministic coalgebras, to decorated\ntrace semantics for labelled transition systems and probabilistic systems, and\ntesting semantics for labelled transition systems with internal behaviour.\nMoreover, we aim at deriving a suite of corresponding verification algorithms\nsuitable for implementation in automated tools.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 13:51:08 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Caltais", "Georgiana", ""]]}, {"id": "1502.02942", "submitter": "Mitesh Jain", "authors": "Mitesh Jain and Panagiotis Manolios", "title": "Skipping Refinement", "comments": "Submitted to CAV 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce skipping refinement, a new notion of correctness for reasoning\nabout optimized reactive systems. Reasoning about reactive systems using\nrefinement involves defining an abstract, high-level specification system and a\nconcrete, low-level implementation system. One then shows that every behavior\nallowed by the implementation is also allowed by the specification. Due to the\ndifference in abstraction levels, it is often the case that the implementation\nrequires many steps to match one step of the specification, hence, it is quite\nuseful for refinement to directly account for stuttering. Some optimized\nimplementations, however, can actually take multiple specification steps at\nonce. For example, a memory controller can buffer the commands to the memory\nand at a later time simultaneously update multiple memory locations, thereby\nskipping several observable states of the abstract specification, which only\nupdates one memory location at a time. We introduce skipping simulation\nrefinement and provide a sound and complete characterization consisting of\n\"local\" proof rules that are amenable to mechanization and automated\nverification. We present case studies that highlight the applicability of\nskipping refinement: a JVM-inspired stack machine, a simple memory controller\nand a scalar to vector compiler transformation. Our experimental results\ndemonstrate that current model-checking and automated theorem proving tools\nhave difficultly automatically analyzing these systems using existing notions\nof correctness, but they can analyze the systems if we use skipping refinement.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 15:16:50 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Jain", "Mitesh", ""], ["Manolios", "Panagiotis", ""]]}, {"id": "1502.03097", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Rui Soares Barbosa and Kohei Kishida and Raymond\n  Lal and Shane Mansfield", "title": "Contextuality, Cohomology and Paradox", "comments": "18 pages, 4 figures", "journal-ref": "24th EACSL Annual Conference on Computer Science Logic (CSL 2015),\n  Leibniz International Proceedings in Informatics (LIPIcs), 41: 211-228, 2015", "doi": "10.4230/LIPIcs.CSL.2015.211", "report-no": null, "categories": "quant-ph cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextuality is a key feature of quantum mechanics that provides an\nimportant non-classical resource for quantum information and computation.\nAbramsky and Brandenburger used sheaf theory to give a general treatment of\ncontextuality in quantum theory [New Journal of Physics 13 (2011) 113036].\nHowever, contextual phenomena are found in other fields as well, for example\ndatabase theory. In this paper, we shall develop this unified view of\ncontextuality. We provide two main contributions: firstly, we expose a\nremarkable connection between contexuality and logical paradoxes; secondly, we\nshow that an important class of contextuality arguments has a topological\norigin. More specifically, we show that \"All-vs-Nothing\" proofs of\ncontextuality are witnessed by cohomological obstructions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 21:00:13 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 17:49:27 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Abramsky", "Samson", ""], ["Barbosa", "Rui Soares", ""], ["Kishida", "Kohei", ""], ["Lal", "Raymond", ""], ["Mansfield", "Shane", ""]]}, {"id": "1502.03157", "submitter": "EPTCS", "authors": "Javier C\\'amara (Carnegie Mellon University), Jos\\'e Proen\\c{c}a (KU\n  Leuven)", "title": "Proceedings 13th International Workshop on Foundations of Coordination\n  Languages and Self-Adaptive Systems", "comments": null, "journal-ref": "EPTCS 175, 2015", "doi": "10.4204/EPTCS.175", "report-no": null, "categories": "cs.DC cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of FOCLASA 2014, the 13th International\nWorkshop on the Foundations of Coordination Languages and Self-Adaptive\nSystems. FOCLASA 2014 was held in Rome, Italy, on September 9, 2014 as a\nsatellite event of CONCUR 2014, the 25th International Conference on\nConcurrency Theory.\n  Modern software systems are distributed, concurrent, mobile, and often\ninvolve composition of heterogeneous components and stand-alone services.\nService coordination and self-adaptation constitute the core characteristics of\ndistributed and service-oriented systems. Coordination languages and formal\napproaches to modelling and reasoning about self-adaptive behaviour help to\nsimplify the development of complex distributed service-based systems, enable\nfunctional correctness proofs and improve reusability and maintainability of\nsuch systems. The goal of the FOCLASA workshop is to put together researchers\nand practitioners of the aforementioned fields, to share and identify common\nproblems, and to devise general solutions in the context of coordination\nlanguages and self-adaptive systems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 00:30:30 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["C\u00e1mara", "Javier", "", "Carnegie Mellon University"], ["Proen\u00e7a", "Jos\u00e9", "", "KU\n  Leuven"]]}, {"id": "1502.03216", "submitter": "David Sabel", "authors": "Manfred Schmidt-Schau{\\ss} (Dept. Informatik und Mathematik, Inst.\n  Informatik, J.W. Goethe-University, Frank), David Sabel (Dept. Informatik und\n  Mathematik, Inst. Informatik, J.W. Goethe-University, Frank), Elena\n  Machkasova (Division of Science and Mathematics, University of Minnesota,\n  Morris, MN, U.S.A)", "title": "Simulation in the Call-by-Need Lambda-Calculus with Letrec, Case,\n  Constructors, and Seq", "comments": "50 pages, 11 figures", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 16,\n  2015) lmcs:930", "doi": "10.2168/LMCS-11(1:7)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows equivalence of several versions of applicative similarity\nand contextual approximation, and hence also of applicative bisimilarity and\ncontextual equivalence, in LR, the deterministic call-by-need lambda calculus\nwith letrec extended by data constructors, case-expressions and Haskell's\nseq-operator. LR models an untyped version of the core language of Haskell. The\nuse of bisimilarities simplifies equivalence proofs in calculi and opens a way\nfor more convenient correctness proofs for program transformations. The proof\nis by a fully abstract and surjective transfer into a call-by-name calculus,\nwhich is an extension of Abramsky's lazy lambda calculus. In the latter\ncalculus equivalence of our similarities and contextual approximation can be\nshown by Howe's method. Similarity is transferred back to LR on the basis of an\ninductively defined similarity. The translation from the call-by-need letrec\ncalculus into the extended call-by-name lambda calculus is the composition of\ntwo translations. The first translation replaces the call-by-need strategy by a\ncall-by-name strategy and its correctness is shown by exploiting infinite trees\nwhich emerge by unfolding the letrec expressions. The second translation\nencodes letrec-expressions by using multi-fixpoint combinators and its\ncorrectness is shown syntactically by comparing reductions of both calculi. A\nfurther result of this paper is an isomorphism between the mentioned calculi,\nwhich is also an identity on letrec-free expressions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 08:29:38 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2015 20:09:15 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Schmidt-Schau\u00df", "Manfred", "", "Dept. Informatik und Mathematik, Inst.\n  Informatik, J.W. Goethe-University, Frank"], ["Sabel", "David", "", "Dept. Informatik und\n  Mathematik, Inst. Informatik, J.W. Goethe-University, Frank"], ["Machkasova", "Elena", "", "Division of Science and Mathematics, University of Minnesota,\n  Morris, MN, U.S.A"]]}, {"id": "1502.03258", "submitter": "George  Fletcher", "authors": "George H. L. Fletcher, Marc Gyssens, Jan Paredaens, Dirk Van Gucht,\n  Yuqing Wu", "title": "Structural characterizations of the navigational expressiveness of\n  relation algebras on a tree", "comments": "58 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a document D in the form of an unordered node-labeled tree, we study\nthe expressiveness on D of various basic fragments of XPath, the core\nnavigational language on XML documents. Working from the perspective of these\nlanguages as fragments of Tarski's relation algebra, we give characterizations,\nin terms of the structure of D, for when a binary relation on its nodes is\ndefinable by an expression in these algebras. Since each pair of nodes in such\na relation represents a unique path in D, our results therefore capture the\nsets of paths in D definable in each of the fragments. We refer to this\nperspective on language semantics as the \"global view.\" In contrast with this\nglobal view, there is also a \"local view\" where one is interested in the nodes\nto which one can navigate starting from a particular node in the document. In\nthis view, we characterize when a set of nodes in D can be defined as the\nresult of applying an expression to a given node of D. All these definability\nresults, both in the global and the local view, are obtained by using a robust\ntwo-step methodology, which consists of first characterizing when two nodes\ncannot be distinguished by an expression in the respective fragments of XPath,\nand then bootstrapping these characterizations to the desired results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 10:49:04 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Fletcher", "George H. L.", ""], ["Gyssens", "Marc", ""], ["Paredaens", "Jan", ""], ["Van Gucht", "Dirk", ""], ["Wu", "Yuqing", ""]]}, {"id": "1502.03426", "submitter": "Murray Elder", "authors": "Laura Ciobanu and Volker Diekert and Murray Elder", "title": "Solution sets for equations over free groups are EDT0L languages --\n  ICALP 2015 version", "comments": "37 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.FL math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, given a word equation over a finitely generated free group, the\nset of all solutions in reduced words forms an EDT0L language. In particular,\nit is an indexed language in the sense of Aho. The question of whether a\ndescription of solution sets in reduced words as an indexed language is\npossible has been been open for some years, apparently without much hope that a\npositive answer could hold. Nevertheless, our answer goes far beyond: they are\nEDT0L, which is a proper subclass of indexed languages. We can additionally\nhandle the existential theory of equations with rational constraints in free\nproducts $\\star_{1 \\leq i \\leq s}F_i$, where each $F_i$ is either a free or\nfinite group, or a free monoid with involution. In all cases the result is the\nsame: the set of all solutions in reduced words is EDT0L. This was known only\nfor quadratic word equations by Fert\\'e, Marin and S\\'enizergues (ToCS 2014),\nwhich is a very restricted case. Our general result became possible due to the\nrecent recompression technique of Je\\.z. In this paper we use a new method to\nintegrate solutions of linear Diophantine equations into the process and obtain\nmore general results than in the related paper (arXiv 1405.5133). For example,\nwe improve the complexity from quadratic nondeterministic space in (arXiv\n1405.5133) to quasi-linear nondeterministic space here. This implies an\nimproved complexity for deciding the existential theory of non-abelian free\ngroups: NSPACE($n\\log n$). The conjectured complexity is NP, however, we\nbelieve that our results are optimal with respect to space complexity,\nindependent of the conjectured NP.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 20:23:41 GMT"}, {"version": "v2", "created": "Mon, 4 May 2015 03:24:25 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2015 09:11:26 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Ciobanu", "Laura", ""], ["Diekert", "Volker", ""], ["Elder", "Murray", ""]]}, {"id": "1502.03514", "submitter": "EPTCS", "authors": "Ian Cassar, Adrian Francalanza", "title": "On Synchronous and Asynchronous Monitor Instrumentation for Actor-based\n  systems", "comments": "In Proceedings FOCLASA 2014, arXiv:1502.03157", "journal-ref": "EPTCS 175, 2015, pp. 54-68", "doi": "10.4204/EPTCS.175.4", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of synchronous and asynchronous monitoring\ninstrumentation on runtime overheads in the context of a runtime verification\nframework for actor-based systems. We show that, in such a context,\nasynchronous monitoring incurs substantially lower overhead costs. We also show\nhow, for certain properties that require synchronous monitoring, a hybrid\napproach can be used that ensures timely violation detections for the important\nevents while, at the same time, incurring lower overhead costs that are closer\nto those of an asynchronous instrumentation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 02:15:12 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Cassar", "Ian", ""], ["Francalanza", "Adrian", ""]]}, {"id": "1502.03629", "submitter": "Yan Zhang", "authors": "Yan Zhang, Zhaohui Zhu, Jinjin Zhang", "title": "On the greatest solution of equations in $\\text{CLL}_R$", "comments": "9 pages. arXiv admin note: text overlap with arXiv:1411.0756", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that, for any equation $X=_{RS} t_X$ in the LLTS-oriented process\ncalculus $\\text{CLL}_R$, if $X$ is strongly guarded in $t_X$, then the\nrecursive term $\\langle X|X=t_X \\rangle$ is the greatest solution of this\nequation w.r.t L\\\"{u}ttgen and Vogler's ready simulation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 12:32:21 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Zhang", "Yan", ""], ["Zhu", "Zhaohui", ""], ["Zhang", "Jinjin", ""]]}, {"id": "1502.03636", "submitter": "Yan Zhang", "authors": "Yan Zhang, Zhaohui Zhu, Jinjin Zhang", "title": "Axiomatizing L\\\"{u}ttgen and Vogler's ready simulation for finite\n  processes in $\\text{CLL}_R$", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of logic labelled transition system, a variant of weak ready\nsimulation has been presented by L\\\"{u}ttgen and Vogler. It has been shown that\nsuch behavioural preorder is the largest precongruence w.r.t parallel and\nconjunction composition satisfying desired properties. This paper offers a\nground-complete axiomatization for this precongruence over processes containing\nno recursion in the calculus $\\text{CLL}_R$. Compared with usual inference\nsystem for process calculus, in addition to axioms about process operators,\nsuch system contains a number of axioms to characterize the interaction between\nprocess operators and logical operators.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 12:45:57 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Zhang", "Yan", ""], ["Zhu", "Zhaohui", ""], ["Zhang", "Jinjin", ""]]}, {"id": "1502.03683", "submitter": "Paolo Turrini", "authors": "Paolo Turrini", "title": "Computing rational decisions in extensive games with limited foresight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of extensive form games where players might not be able\nto foresee the possible consequences of their decisions and form a model of\ntheir opponents which they exploit to achieve a more profitable outcome. We\nimprove upon existing models of games with limited foresight, endowing players\nwith the ability of higher-order reasoning and proposing a novel solution\nconcept to address intuitions coming from real game play. We analyse the\nresulting equilibria, devising an effective procedure to compute them.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 14:45:22 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2015 10:49:09 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2015 10:22:56 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2015 11:17:17 GMT"}, {"version": "v5", "created": "Thu, 21 Apr 2016 10:32:27 GMT"}, {"version": "v6", "created": "Sun, 29 May 2016 17:21:44 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Turrini", "Paolo", ""]]}, {"id": "1502.03974", "submitter": "Albert Atserias", "authors": "Albert Atserias", "title": "A Note on Semi-Algebraic Proofs and Gaussian Elimination over Prime\n  Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we show that unsatisfiable systems of linear equations with a\nconstant number of variables per equation over prime finite fields have\npolynomial-size constant-degree semi-algebraic proofs of unsatisfiability.\nThese are proofs that manipulate polynomial inequalities over the reals with\nvariables ranging in $\\{0,1\\}$. This upper bound is to be put in contrast with\nthe known fact that, for certain explicit systems of linear equations over the\ntwo-element field, such refutations require linear degree and exponential size\nif they are restricted to so-called static semi-algebraic proofs, and even\ntree-like semi-algebraic and sums-of-squares proofs. Our upper bound is a more\nor less direct translation of an argument due to Grigoriev, Hirsch and\nPasechnik (Moscow Mathematical Journal, 2002) who did it for a family of linear\nsystems of interest in propositional proof complexity. We point out that their\nmethod is more general and can be thought of as simulating Gaussian\nelimination.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 13:03:53 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Atserias", "Albert", ""]]}, {"id": "1502.04052", "submitter": "Justin Hsu", "authors": "Gilles Barthe, Marco Gaboardi, Emilio Jes\\'us Gallego Arias, Justin\n  Hsu, Aaron Roth, Pierre-Yves Strub", "title": "Computer-aided verification in mechanism design", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-54110-4_20", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mechanism design, the gold standard solution concepts are dominant\nstrategy incentive compatibility and Bayesian incentive compatibility. These\nsolution concepts relieve the (possibly unsophisticated) bidders from the need\nto engage in complicated strategizing. While incentive properties are simple to\nstate, their proofs are specific to the mechanism and can be quite complex.\nThis raises two concerns. From a practical perspective, checking a complex\nproof can be a tedious process, often requiring experts knowledgeable in\nmechanism design. Furthermore, from a modeling perspective, if unsophisticated\nagents are unconvinced of incentive properties, they may strategize in\nunpredictable ways.\n  To address both concerns, we explore techniques from computer-aided\nverification to construct formal proofs of incentive properties. Because formal\nproofs can be automatically checked, agents do not need to manually check the\nproperties, or even understand the proof. To demonstrate, we present the\nverification of a sophisticated mechanism: the generic reduction from Bayesian\nincentive compatible mechanism design to algorithm design given by Hartline,\nKleinberg, and Malekian. This mechanism presents new challenges for formal\nverification, including essential use of randomness from both the execution of\nthe mechanism and from the prior type distributions. As an immediate\nconsequence, our work also formalizes Bayesian incentive compatibility for the\nentire family of mechanisms derived via this reduction. Finally, as an\nintermediate step in our formalization, we provide the first formal\nverification of incentive compatibility for the celebrated\nVickrey-Clarke-Groves mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 16:31:55 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2015 20:51:30 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2016 16:02:27 GMT"}, {"version": "v4", "created": "Sun, 16 Oct 2016 03:40:58 GMT"}, {"version": "v5", "created": "Sun, 25 Dec 2016 02:11:52 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Arias", "Emilio Jes\u00fas Gallego", ""], ["Hsu", "Justin", ""], ["Roth", "Aaron", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1502.04419", "submitter": "EPTCS", "authors": "Sandra Alves (University of Porto), Iliano Cervesato (Carnegie Mellon\n  University)", "title": "Proceedings Third International Workshop on Linearity", "comments": null, "journal-ref": "EPTCS 176, 2015", "doi": "10.4204/EPTCS.176", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at LINEARITY 2014, the Third\nInternational Workshop on Linearity, held on July 13, 2014 in Vienna, Austria.\nThe workshop was a one-day satellite event of FLoC 2014, the sixth Federated\nLogic Conference. It was held as part of the 2014 Vienna Summer of Logic.\n  The aim of this workshop was to bring together researchers who are exploring\ntheory and applications of linear calculi, to foster their interaction and\nprovide a forum for presenting new ideas and work in progress, and enable\nnewcomers to learn about current activities in this area. Of interest were new\nresults that made a central use of linearity, ranging from foundational work to\napplications in any field. This included: sub-linear logics, linear term\ncalculi, linear type systems, linear proof-theory, linear programming\nlanguages, applications to concurrency, interaction-based systems, verification\nof linear systems, quantum models of computation, and biological and chemical\nmodels of computation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 04:00:20 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Alves", "Sandra", "", "University of Porto"], ["Cervesato", "Iliano", "", "Carnegie Mellon\n  University"]]}, {"id": "1502.04464", "submitter": "Andrew Reynolds", "authors": "Andrew Reynolds, Morgan Deters, Viktor Kuncak, Cesare Tinelli, Clark\n  Barrett", "title": "On Counterexample Guided Quantifier Instantiation for Synthesis in CVC4", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first program synthesis engine implemented inside an SMT\nsolver. We present an approach that extracts solution functions from\nunsatisfiability proofs of the negated form of synthesis conjectures. We also\ndiscuss novel counterexample-guided techniques for quantifier instantiation\nthat we use to make finding such proofs practically feasible. A particularly\nimportant class of specifications are single-invocation properties, for which\nwe present a dedicated algorithm. To support syntax restrictions on generated\nsolutions, our approach can transform a solution found without restrictions\ninto the desired syntactic form. As an alternative, we show how to use\nevaluation function axioms to embed syntactic restrictions into constraints\nover algebraic datatypes, and then use an algebraic datatype decision procedure\nto drive synthesis. Our experimental evaluation on syntax-guided synthesis\nbenchmarks shows that our implementation in the CVC4 SMT solver is competitive\nwith state-of-the-art tools for synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 09:08:23 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 09:12:55 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2015 17:44:51 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Reynolds", "Andrew", ""], ["Deters", "Morgan", ""], ["Kuncak", "Viktor", ""], ["Tinelli", "Cesare", ""], ["Barrett", "Clark", ""]]}, {"id": "1502.04578", "submitter": "Szymon Toru\\'nczyk", "authors": "Miko{\\l}aj Boja\\'nczyk, Pawe{\\l} Parys, Szymon Toru\\'nczyk", "title": "The MSO+U theory of (N, <) is undecidable", "comments": "9 pages, with 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the logic MSO+U, which is monadic second-order logic extended\nwith the unbounding quantifier. The unbounding quantifier is used to say that a\nproperty of finite sets holds for sets of arbitrarily large size. We prove that\nthe logic is undecidable on infinite words, i.e. the MSO+U theory of (N,<) is\nundecidable. This settles an open problem about the logic, and improves a\nprevious undecidability result, which used infinite trees and additional axioms\nfrom set theory.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 15:35:39 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 13:28:44 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Parys", "Pawe\u0142", ""], ["Toru\u0144czyk", "Szymon", ""]]}, {"id": "1502.04634", "submitter": "Danko Ilik", "authors": "Danko Ilik", "title": "The exp-log normal form of types", "comments": null, "journal-ref": "POPL 2017 Proceedings of the 44th ACM SIGPLAN Symposium on\n  Principles of Programming Languages. Pages 387-399. Paris, France -- January\n  15 - 21, 2017", "doi": "10.1145/3009837.3009841", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lambda calculi with algebraic data types lie at the core of functional\nprogramming languages and proof assistants, but conceal at least two\nfundamental theoretical problems already in the presence of the simplest\nnon-trivial data type, the sum type. First, we do not know of an explicit and\nimplemented algorithm for deciding the beta-eta-equality of terms---and this in\nspite of the first decidability results proven two decades ago. Second, it is\nnot clear how to decide when two types are essentially the same, i.e.\nisomorphic, in spite of the meta-theoretic results on decidability of the\nisomorphism.\n  In this paper, we present the exp-log normal form of types---derived from the\nrepresentation of exponential polynomials via the unary exponential and\nlogarithmic functions---that any type built from arrows, products, and sums,\ncan be isomorphically mapped to. The type normal form can be used as a simple\nheuristic for deciding type isomorphism, thanks to the fact that it is a\nsystematic application of the high-school identities.\n  We then show that the type normal form allows to reduce the standard beta-eta\nequational theory of the lambda calculus to a specialized version of itself,\nwhile preserving the completeness of equality on terms. We end by describing an\nalternative representation of normal terms of the lambda calculus with sums,\ntogether with a Coq-implemented converter into/from our new term calculus. The\ndifference with the only other previously implemented heuristic for deciding\ninteresting instances of eta-equality by Balat, Di Cosmo, and Fiore, is that we\nexploit the type information of terms substantially and this often allows us to\nobtain a canonical representation of terms without performing sophisticated\nterm analyses.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 17:14:52 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 18:34:09 GMT"}, {"version": "v3", "created": "Tue, 10 May 2016 09:41:43 GMT"}, {"version": "v4", "created": "Thu, 30 Jun 2016 13:39:23 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ilik", "Danko", ""]]}, {"id": "1502.04769", "submitter": "EPTCS", "authors": "Kaustuv Chaudhuri (INRIA)", "title": "Undecidability of Multiplicative Subexponential Logic", "comments": "In Proceedings LINEARITY 2014, arXiv:1502.04419", "journal-ref": "EPTCS 176, 2015, pp. 1-8", "doi": "10.4204/EPTCS.176.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subexponential logic is a variant of linear logic with a family of\nexponential connectives--called subexponentials--that are indexed and arranged\nin a pre-order. Each subexponential has or lacks associated structural\nproperties of weakening and contraction. We show that classical propositional\nmultiplicative linear logic extended with one unrestricted and two incomparable\nlinear subexponentials can encode the halting problem for two register Minsky\nmachines, and is hence undecidable.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 02:27:07 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Chaudhuri", "Kaustuv", "", "INRIA"]]}, {"id": "1502.04770", "submitter": "EPTCS", "authors": "Jennifer Paykin (University of Pennsylvania), Steve Zdancewic\n  (University of Pennsylvania)", "title": "A Linear/Producer/Consumer Model of Classical Linear Logic", "comments": "In Proceedings LINEARITY 2014, arXiv:1502.04419", "journal-ref": "EPTCS 176, 2015, pp. 9-23", "doi": "10.4204/EPTCS.176.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a new proof- and category-theoretic framework for\nclassical linear logic that separates reasoning into one linear regime and two\npersistent regimes corresponding to ! and ?. The resulting\nlinear/producer/consumer (LPC) logic puts the three classes of propositions on\nthe same semantic footing, following Benton's linear/non-linear formulation of\nintuitionistic linear logic. Semantically, LPC corresponds to a system of three\ncategories connected by adjunctions reflecting the linear/producer/consumer\nstructure. The paper's metatheoretic results include admissibility theorems for\nthe cut and duality rules, and a translation of the LPC logic into category\ntheory. The work also presents several concrete instances of the LPC model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 02:27:16 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Paykin", "Jennifer", "", "University of Pennsylvania"], ["Zdancewic", "Steve", "", "University of Pennsylvania"]]}, {"id": "1502.04771", "submitter": "EPTCS", "authors": "Taus Brock-Nannestad (INRIA & LIX, \\'Ecole Polytechnique), Nicolas\n  Guenot (IT University of Copenhagen)", "title": "Cut Elimination in Multifocused Linear Logic", "comments": "In Proceedings LINEARITY 2014, arXiv:1502.04419", "journal-ref": "EPTCS 176, 2015, pp. 24-33", "doi": "10.4204/EPTCS.176.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study cut elimination for a multifocused variant of full linear logic in\nthe sequent calculus. The multifocused normal form of proofs yields problems\nthat do not appear in a standard focused system, related to the constraints in\ngrouping rule instances in focusing phases. We show that cut elimination can be\nperformed in a sensible way even though the proof requires some specific lemmas\nto deal with multifocusing phases, and discuss the difficulties arising with\ncut elimination when considering normal forms of proofs in linear logic.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 02:27:23 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Brock-Nannestad", "Taus", "", "INRIA & LIX, \u00c9cole Polytechnique"], ["Guenot", "Nicolas", "", "IT University of Copenhagen"]]}, {"id": "1502.04773", "submitter": "EPTCS", "authors": "Michele Basaldella (Universit\\'e d'Aix-Marseille, CNRS, I2M,\n  Marseille, France)", "title": "Ludics without Designs I: Triads", "comments": "In Proceedings LINEARITY 2014, arXiv:1502.04419", "journal-ref": "EPTCS 176, 2015, pp. 49-63", "doi": "10.4204/EPTCS.176.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the concept of triad. Using this notion, we\nstudy, revisit, discover and rediscover some basic properties of ludics from a\nvery general point of view.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 02:27:41 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Basaldella", "Michele", "", "Universit\u00e9 d'Aix-Marseille, CNRS, I2M,\n  Marseille, France"]]}, {"id": "1502.04774", "submitter": "EPTCS", "authors": "Ugo Dal Lago (Universit\\`a di Bologna & INRIA), Margherita Zorzi\n  (Universit\\`a di Verona)", "title": "Wave-Style Token Machines and Quantum Lambda Calculi", "comments": "In Proceedings LINEARITY 2014, arXiv:1502.04419", "journal-ref": "EPTCS 176, 2015, pp. 64-78", "doi": "10.4204/EPTCS.176.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle-style token machines are a way to interpret proofs and programs,\nwhen the latter are written following the principles of linear logic. In this\npaper, we show that token machines also make sense when the programs at hand\nare those of a simple quantum lambda-calculus with implicit qubits. This,\nhowever, requires generalising the concept of a token machine to one in which\nmore than one particle travel around the term at the same time. The presence of\nmultiple tokens is intimately related to entanglement and allows us to give a\nsimple operational semantics to the calculus, coherently with the principles of\nquantum computation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 02:27:51 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Lago", "Ugo Dal", "", "Universit\u00e0 di Bologna & INRIA"], ["Zorzi", "Margherita", "", "Universit\u00e0 di Verona"]]}, {"id": "1502.04775", "submitter": "EPTCS", "authors": "Marco Solieri (LIPN, Paris 13, Sorbonne Paris Cit\\'e, CNRS -- DISI,\n  Bologna, INRIA)", "title": "Geometry of Resource Interaction - A Minimalist Approach", "comments": "In Proceedings LINEARITY 2014, arXiv:1502.04419", "journal-ref": "EPTCS 176, 2015, pp. 79-94", "doi": "10.4204/EPTCS.176.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Resource $\\lambda$-calculus is a variation of the $\\lambda$-calculus\nwhere arguments can be superposed and must be linearly used. Hence it is a\nmodel for linear and non-deterministic programming languages, and the target\nlanguage of Ehrhard-Taylor expansion of $\\lambda$-terms. In a strictly typed\nrestriction of the Resource $\\lambda$-calculus, we study the notion of path\npersistence, and we define a Geometry of Interaction that characterises it, is\ninvariant under reduction, and counts addends in normal forms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 02:28:03 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Solieri", "Marco", "", "LIPN, Paris 13, Sorbonne Paris Cit\u00e9, CNRS -- DISI,\n  Bologna, INRIA"]]}, {"id": "1502.04844", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee, Laurent Doyen, Moshe Y. Vardi", "title": "The Complexity of Synthesis from Probabilistic Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synthesis problem asks for the automatic construction of a system from\nits specification. In the traditional setting, the system is \"constructed from\nscratch\" rather than composed from reusable components. However, this is rare\nin practice, and almost every non-trivial software system relies heavily on the\nuse of libraries of reusable components. Recently, Lustig and Vardi introduced\ndataflow and controlflow synthesis from libraries of reusable components. They\nproved that dataflow synthesis is undecidable, while controlflow synthesis is\ndecidable. The problem of controlflow synthesis from libraries of probabilistic\ncomponents was considered by Nain, Lustig and Vardi, and was shown to be\ndecidable for qualitative analysis (that asks that the specification be\nsatisfied with probability 1). Our main contributions for controlflow synthesis\nfrom probabilistic components are to establish better complexity bounds for the\nqualitative analysis problem, and to show that the more general quantitative\nproblem is undecidable. For the qualitative analysis, we show that the problem\n(i) is EXPTIME-complete when the specification is given as a deterministic\nparity word automaton, improving the previously known 2EXPTIME upper bound; and\n(ii) belongs to UP $\\cap$ coUP and is parity-games hard, when the specification\nis given directly as a parity condition on the components, improving the\npreviously known EXPTIME upper bound.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 10:11:26 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1502.04898", "submitter": "Miko{\\l}aj Boja\\'nczyk", "authors": "Miko{\\l}aj Boja\\'nczyk", "title": "Recognisable languages over monads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle behind algebraic language theory for various kinds of\nstructures, such as words or trees, is to use a compositional function from the\nstructures into a finite set. To talk about compositionality, one needs some\nway of composing structures into bigger structures. It so happens that category\ntheory has an abstract concept for this, namely a monad. The goal of this paper\nis to propose monads as a unifying framework for discussing existing algebras\nand designing new algebras.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 14:07:12 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""]]}, {"id": "1502.05147", "submitter": "Charles Grellois", "authors": "Charles Grellois and Paul-Andr\\'e Melli\\`es", "title": "Finitary semantics of linear logic and higher-order model-checking", "comments": "12 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explain how the connection between higher-order\nmodel-checking and linear logic recently exhibited by the authors leads to a\nnew and conceptually enlightening proof of the selection problem originally\nestablished by Carayol and Serre using collapsible pushdown automata. The main\nidea is to start from an infinitary and colored relational semantics of the\nlambdaY-calculus already formulated, and to replace it by its finitary\ncounterpart based on finite prime-algebraic lattices. Given a higher-order\nrecursion scheme G, the finiteness of its interpretation in the model enables\nus to associate to any MSO formula phi a new higher-order recursion scheme\nG_phi resolving the selection problem.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 07:56:25 GMT"}, {"version": "v2", "created": "Fri, 1 May 2015 10:06:17 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Grellois", "Charles", ""], ["Melli\u00e8s", "Paul-Andr\u00e9", ""]]}, {"id": "1502.05209", "submitter": "Peter Schneider-Kamp", "authors": "Lu\\'is Cruz-Filipe and Peter Schneider-Kamp", "title": "Formalizing Size-Optimal Sorting Networks: Extracting a Certified Proof\n  Checker", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": "10.1007/978-3-319-22102-1_10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the proof of the four color theorem in 1976, computer-generated proofs\nhave become a reality in mathematics and computer science. During the last\ndecade, we have seen formal proofs using verified proof assistants being used\nto verify the validity of such proofs.\n  In this paper, we describe a formalized theory of size-optimal sorting\nnetworks. From this formalization we extract a certified checker that\nsuccessfully verifies computer-generated proofs of optimality on up to 8\ninputs. The checker relies on an untrusted oracle to shortcut the search for\nwitnesses on more than 1.6 million NP-complete subproblems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 13:02:02 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2015 08:28:12 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Schneider-Kamp", "Peter", ""]]}, {"id": "1502.05501", "submitter": "G\\'abor Alagi", "authors": "G\\'abor Alagi and Christoph Weidenbach", "title": "NRCL - A Model Building Approach to the Bernays-Sch\\\"onfinkel Fragment\n  (Full Paper)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine constrained literals for model representation with key concepts\nfrom first-order superposition and propositional conflict-driven clause\nlearning (CDCL) to create the new calculus Non-Redundant Clause Learning (NRCL)\ndeciding the Bernays-Sch\\\"onfinkel fragment. Our calculus uses first-order\nliterals constrained by disequations between tuples of terms for compact model\nrepresentation. From superposition, NRCL inherits the abstract redundancy\ncriterion and the monotone model operator. CDCL adds the dynamic,\nconflict-driven search for an atom ordering inducing a model. As a result, in\nNRCL a false clause can be found effectively modulo the current model\ncandidate. It guides the derivation of a first-order ordered resolvent that is\nnever redundant. Similar to 1UIP-learning in CDCL, the learned resolvent\ninduces backtracking and, by blocking the previous conflict state via\npropagation, it enforces progress towards finding a model or a refutation. The\nnon-redundancy result also implies that only finitely many clauses can be\ngenerated by NRCL on the Bernays-Sch\\\"onfinkel fragment, which serves as an\nargument for termination.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 09:05:23 GMT"}, {"version": "v2", "created": "Wed, 13 May 2015 13:39:05 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2015 19:26:40 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Alagi", "G\u00e1bor", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "1502.05561", "submitter": "Fredrik Nordvall Forsberg", "authors": "Neil Ghani (University of Strathclyde), Fredrik Nordvall Forsberg\n  (University of Strathclyde), Lorenzo Malatesta (University of Strathclyde)", "title": "Positive Inductive-Recursive Definitions", "comments": "21 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 27,\n  2015) lmcs:1154", "doi": "10.2168/LMCS-11(1:13)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new theory of data types which allows for the definition of types as\ninitial algebras of certain functors Fam(C) -> Fam(C) is presented. This\ntheory, which we call positive inductive-recursive definitions, is a\ngeneralisation of Dybjer and Setzer's theory of inductive-recursive definitions\nwithin which C had to be discrete -- our work can therefore be seen as lifting\nthis restriction. This is a substantial endeavour as we need to not only\nintroduce a type of codes for such data types (as in Dybjer and Setzer's work),\nbut also a type of morphisms between such codes (which was not needed in Dybjer\nand Setzer's development). We show how these codes are interpreted as functors\non Fam(C) and how these morphisms of codes are interpreted as natural\ntransformations between such functors. We then give an application of positive\ninductive-recursive definitions to the theory of nested data types and we give\nconcrete examples of recursive functions defined on universes by using their\nelimination principle. Finally we justify the existence of positive\ninductive-recursive definitions by adapting Dybjer and Setzer's set-theoretic\nmodel to our setting.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 13:19:36 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 19:52:35 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ghani", "Neil", "", "University of Strathclyde"], ["Forsberg", "Fredrik Nordvall", "", "University of Strathclyde"], ["Malatesta", "Lorenzo", "", "University of Strathclyde"]]}, {"id": "1502.05632", "submitter": "Raine Ronnholm", "authors": "Raine R\\\"onnholm", "title": "Capturing k-ary Existential Second Order Logic with k-ary\n  Inclusion-Exclusion Logic", "comments": "Extended version of a paper published in Annals of Pure and Applied\n  Logic 169 (3), 177-215", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze k-ary inclusion-exclusion logic, INEX[k], which is\nobtained by extending first order logic with k-ary inclusion and exclusion\natoms. We show that every formula of INEX[k] can be expressed with a formula of\nk-ary existential second order logic, ESO[k]. Conversely, every formula of\nESO[k] with at most k-ary free relation variables can be expressed with a\nformula of INEX[k]. From this it follows that, on the level of sentences,\nINEX[k] captures the expressive power of ESO[k].\n  We also introduce several useful operators that can be expressed in INEX[k].\nIn particular, we define inclusion and exclusion quantifiers and so-called term\nvalue preserving disjunction which is essential for the proofs of the main\nresults in this paper. Furthermore, we present a novel method of relativization\nfor team semantics and analyze the duality of inclusion and exclusion atoms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 17:20:25 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2015 14:11:37 GMT"}, {"version": "v3", "created": "Tue, 22 Mar 2016 19:15:45 GMT"}, {"version": "v4", "created": "Mon, 18 Jun 2018 17:21:22 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["R\u00f6nnholm", "Raine", ""]]}, {"id": "1502.05748", "submitter": "Amnon  Rosenmann", "authors": "Amnon Rosenmann", "title": "A Multiple-Valued Logic Approach to the Design and Verification of\n  Hardware Circuits", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach, which is based on multiple-valued logic (MVL),\nto the verification and analysis of digital hardware designs, which extends the\ncommon ternary or quaternary approaches for simulations. The simulations which\nare performed in the more informative MVL setting reveal details which are\neither invisible or harder to detect through binary or ternary simulations. In\nequivalence verification, detecting different behavior under MVL simulations\nmay lead to the discovery of a genuine binary nonequivalence or to a\nqualitative gap between two designs. The value of a variable in a simulation\nmay hold information about its degree of truth and its \"place of birth\" and\n\"date of birth.\" Applications include equivalence verification, initialization,\nassertions generation and verification, partial control on the flow of data by\nprioritizing and block-oriented simulations. Much of the paper is devoted to\ntheoretical aspects behind the MVL approach, including the reason for choosing\na specific algebra for computations, and the introduction of the verification\ncomplexity of a Boolean expression. Two basic algorithms are presented.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 23:33:52 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 00:39:53 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Rosenmann", "Amnon", ""]]}, {"id": "1502.05834", "submitter": "Agi Kurucz", "authors": "Agi Kurucz", "title": "Bimodal logics with a `weakly connected' component without the finite\n  model property", "comments": null, "journal-ref": "Notre Dame J. Formal Logic 58, no. 2 (2017), 287-299", "doi": "10.1215/00294527-3870247", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two known general results on the finite model property (fmp) of\ncommutators [L,L'] (bimodal logics with commuting and confluent modalities). If\nL is finitely axiomatisable by modal formulas having universal Horn first-order\ncorrespondents, then both [L,K] and [L,S5] are determined by classes of frames\nthat admit filtration, and so have the fmp. On the negative side, if both L and\nL' are determined by transitive frames and have frames of arbitrarily large\ndepth, then [L,L'] does not have the fmp. In this paper we show that\ncommutators with a `weakly connected' component often lack the fmp. Our results\nimply that the above positive result does not generalise to universally\naxiomatisable component logics, and even commutators without `transitive'\ncomponents such as [K.3,K] can lack the fmp. We also generalise the above\nnegative result to cases where one of the component logics has frames of depth\none only, such as [S4.3,S5] and the decidable product logic S4.3xS5. We also\nshow cases when already half of commutativity is enough to force infinite\nframes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 11:25:32 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Kurucz", "Agi", ""]]}, {"id": "1502.05838", "submitter": "Claudia Schon", "authors": "Ulrich Furbach, Claudia Schon, Frieder Stolzenburg", "title": "Automated Reasoning for Robot Ethics", "comments": "arXiv admin note: substantial text overlap with arXiv:1411.4823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deontic logic is a very well researched branch of mathematical logic and\nphilosophy. Various kinds of deontic logics are considered for different\napplication domains like argumentation theory, legal reasoning, and acts in\nmulti-agent systems. In this paper, we show how standard deontic logic can be\nused to model ethical codes for multi-agent systems. Furthermore we show how\nHyper, a high performance theorem prover, can be used to prove properties of\nthese ethical codes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 11:38:58 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Furbach", "Ulrich", ""], ["Schon", "Claudia", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "1502.05860", "submitter": "Anupam Das", "authors": "Anupam Das (\\'Ecole Normale Sup\\'erieure de Lyon (ENS Lyon), France)", "title": "On the relative proof complexity of deep inference via atomic flows", "comments": "27 pages, 2 figures, full version of conference paper", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 6,\n  2015) lmcs:735", "doi": "10.2168/LMCS-11(1:4)2015", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the proof complexity of the minimal complete fragment, KS, of\nstandard deep inference systems for propositional logic. To examine the size of\nproofs we employ atomic flows, diagrams that trace structural changes through a\nproof but ignore logical information. As results we obtain a polynomial\nsimulation of versions of Resolution, along with some extensions. We also show\nthat these systems, as well as bounded-depth Frege systems, cannot polynomially\nsimulate KS, by giving polynomial-size proofs of certain variants of the\npropositional pigeonhole principle in KS.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 12:53:38 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 12:28:52 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Das", "Anupam", "", "\u00c9cole Normale Sup\u00e9rieure de Lyon"]]}, {"id": "1502.05910", "submitter": "Jannis Bulian", "authors": "Jannis Bulian and Anuj Dawar", "title": "Fixed-parameter Tractable Distances to Sparse Graph Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for various classes C of sparse graphs, and several measures of\ndistance to such classes (such as edit distance and elimination distance), the\nproblem of determining the distance of a given graph G to C is fixed-parameter\ntractable. The results are based on two general techniques. The first of these,\nbuilding on recent work of Grohe et al. establishes that any class of graphs\nthat is slicewise nowhere dense and slicewise first-order definable is FPT. The\nsecond shows that determining the elimination distance of a graph G to a\nminor-closed class C is FPT.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 15:44:17 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Bulian", "Jannis", ""], ["Dawar", "Anuj", ""]]}, {"id": "1502.05912", "submitter": "Martin Grohe", "authors": "Christoph Berkholz and Martin Grohe", "title": "Limitations of Algebraic Approaches to Graph Isomorphism Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of graph isomorphism algorithms based on algebraic\nreasoning techniques like Gr\\\"obner basis computation. The idea of these\nalgorithms is to encode two graphs into a system of equations that are\nsatisfiable if and only if if the graphs are isomorphic, and then to (try to)\ndecide satisfiability of the system using, for example, the Gr\\\"obner basis\nalgorithm. In some cases this can be done in polynomial time, in particular, if\nthe equations admit a bounded degree refutation in an algebraic proof systems\nsuch as Nullstellensatz or polynomial calculus. We prove linear lower bounds on\nthe polynomial calculus degree over all fields of characteristic different from\n2 and also linear lower bounds for the degree of Positivstellensatz calculus\nderivations.\n  We compare this approach to recently studied linear and semidefinite\nprogramming approaches to isomorphism testing, which are known to be related to\nthe combinatorial Weisfeiler-Lehman algorithm. We exactly characterise the\npower of the Weisfeiler-Lehman algorithm in terms of an algebraic proof system\nthat lies between degree-k Nullstellensatz and degree-k polynomial calculus.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 15:50:43 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Berkholz", "Christoph", ""], ["Grohe", "Martin", ""]]}, {"id": "1502.06021", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (INRIA Paris-Rocquencourt)", "title": "A point on fixpoints in posets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X,\\le)$ be a {\\em non-empty strictly inductive poset}, that is, a\nnon-empty partially ordered set such that every non-empty chain $Y$ has a least\nupper bound lub$(Y)\\in X$, a chain being a subset of $X$ totally ordered by\n$\\le$. We are interested in sufficient conditions such that, given an element\n$a_0\\in X$ and a function $f:X\\a X$, there is some ordinal $k$ such that\n$a_{k+1}=a_k$, where $a\\_k$ is the transfinite sequence of iterates of $f$\nstarting from $a_0$ (implying that $a_k$ is a fixpoint of $f$):\n  \\begin{itemize}\\itemsep=0mm \\item $a_{k+1}=f(a_k)$ \\item $a_l=\\lub\\{a_k\\mid k\n\\textless{} l\\}$ if $l$ is a limit ordinal, i.e. $l=lub(l)$ \\end{itemize}\n  This note summarizes known results about this problem and provides a slight\ngeneralization of some of them.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 20:06:27 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "INRIA Paris-Rocquencourt"]]}, {"id": "1502.06095", "submitter": "Fabio Zanasi", "authors": "Filippo Bonchi, Fabio Zanasi", "title": "Bialgebraic Semantics for Logic Programming", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 30,\n  2015) lmcs:1155", "doi": "10.2168/LMCS-11(1:14)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bialgebrae provide an abstract framework encompassing the semantics of\ndifferent kinds of computational models. In this paper we propose a bialgebraic\napproach to the semantics of logic programming. Our methodology is to study\nlogic programs as reactive systems and exploit abstract techniques developed in\nthat setting. First we use saturation to model the operational semantics of\nlogic programs as coalgebrae on presheaves. Then, we make explicit the\nunderlying algebraic structure by using bialgebrae on presheaves. The resulting\nsemantics turns out to be compositional with respect to conjunction and term\nsubstitution. Also, it encodes a parallel model of computation, whose soundness\nis guaranteed by a built-in notion of synchronisation between different\nthreads.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 11:31:10 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2015 16:38:28 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bonchi", "Filippo", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1502.06359", "submitter": "Luca Amaru", "authors": "Luca Amaru, Pierre-Emmanuel Gaillardon, Anupam Chattopadhyay, Giovanni\n  De Micheli", "title": "A Sound and Complete Axiomatization of Majority-n Logic", "comments": "Accepted by the IEEE Transactions on Computers", "journal-ref": null, "doi": "10.1109/TC.2015.2506566", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating logic functions via majority operators recently drew the\nattention of researchers in computer science. For example, circuit optimization\nbased on majority operators enables superior results as compared to traditional\nlogic systems. Also, the Boolean satisfiability problem finds new solving\napproaches when described in terms of majority decisions. To support computer\nlogic applications based on majority a sound and complete set of axioms is\nrequired. Most of the recent advances in majority logic deal only with ternary\nmajority (MAJ- 3) operators because the axiomatization with solely MAJ-3 and\ncomplementation operators is well understood. However, it is of interest\nextending such axiomatization to n-ary majority operators (MAJ-n) from both the\ntheoretical and practical perspective. In this work, we address this issue by\nintroducing a sound and complete axiomatization of MAJ-n logic. Our\naxiomatization naturally includes existing majority logic systems. Based on\nthis general set of axioms, computer applications can now fully exploit the\nexpressive power of majority logic.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 09:42:56 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 20:38:22 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2015 10:36:25 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Amaru", "Luca", ""], ["Gaillardon", "Pierre-Emmanuel", ""], ["Chattopadhyay", "Anupam", ""], ["De Micheli", "Giovanni", ""]]}, {"id": "1502.06360", "submitter": "Giovanni Bernardi", "authors": "Giovanni Bernardi (Trinity College Dublin), Matthew Hennessy (Trinity\n  College Dublin)", "title": "Mutually Testing Processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (April 14,\n  2015) lmcs:776", "doi": "10.2168/LMCS-11(2:1)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the standard testing theory of DeNicola-Hennessy one process is considered\nto be a refinement of another if every test guaranteed by the former is also\nguaranteed by the latter. In the domain of web services this has been recast,\nwith processes viewed as servers and tests as clients. In this way the standard\nrefinement preorder between servers is determined by their ability to satisfy\nclients. But in this setting there is also a natural refinement preorder\nbetween clients, determined by their ability to be satisfied by servers. In\nmore general settings where there is no distinction between clients and\nservers, but all processes are peers, there is a further refinement preorder\nbased on the mutual satisfaction of peers. We give a uniform account of these\nthree preorders. In particular we give two characterisations. The first is\nbehavioural, in terms of traces and ready sets. The second, for finite\nprocesses, is equational.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 09:44:11 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2015 19:51:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bernardi", "Giovanni", "", "Trinity College Dublin"], ["Hennessy", "Matthew", "", "Trinity\n  College Dublin"]]}, {"id": "1502.06759", "submitter": "EPTCS", "authors": "Olivier Brunet", "title": "Quantum Measurements from a Logical Point of View", "comments": "In Proceedings QPL 2015, arXiv:1511.01181", "journal-ref": "EPTCS 195, 2015, pp. 84-95", "doi": "10.4204/EPTCS.195.7", "report-no": null, "categories": "quant-ph cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logic modelling some aspects of the behaviour of the\nmeasurement process, in such a way that no direct mention of quantum states is\nmade, thus avoiding the problems associated to this rather evasive notion. We\nthen study some properties of the models of this logic, and deduce some\ncharacteristics that any model (and hence, any formulation of quantum mechanics\ncompatible with its predictions and relying on a notion of measurement) should\nverify. The main results we obtain are that in the case of a Hilbert space of\ndimension at least 3, using a strengthening of the Kochen-Specker theorem, we\nshow that no model can lead to the certain prediction of more than one atomic\noutcome. Moreover, if the Hilbert space is finite dimensional, then we are able\nto precisely describe the structure of the predictions of any model of our\nlogic. In particular, we show that all the models of our logic do exactly make\nthe same predictions regarding whether a given sequence of outcomes is possible\nor not, so that quantum mechanics can be considered complete as long as the\npossibility of outcomes is considered.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 10:59:09 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 01:42:10 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Brunet", "Olivier", ""]]}, {"id": "1502.06875", "submitter": "Sylvain Schmitz", "authors": "Marcin Jurdzi\\'nski and Ranko Lazi\\'c and Sylvain Schmitz", "title": "Fixed-Dimensional Energy Games are in Pseudo-Polynomial Time", "comments": "Corrected proof of Lemma 6.2 (thanks to Dmitry Chistikov for spotting\n  an error in the previous proof)", "journal-ref": "Proceedings of ICALP 2015, Lecture Notes in Computer Science vol.\n  9135, pp. 260--272, Springer", "doi": "10.1007/978-3-662-47666-6_21", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise the hyperplane separation technique (Chatterjee and Velner,\n2013) from multi-dimensional mean-payoff to energy games, and achieve an\nalgorithm for solving the latter whose running time is exponential only in the\ndimension, but not in the number of vertices of the game graph. This answers an\nopen question whether energy games with arbitrary initial credit can be solved\nin pseudo-polynomial time for fixed dimensions 3 or larger (Chaloupka, 2013).\nIt also improves the complexity of solving multi-dimensional energy games with\ngiven initial credit from non-elementary (Br\\'azdil, Jan\\v{c}ar, and\nKu\\v{c}era, 2010) to 2EXPTIME, thus establishing their 2EXPTIME-completeness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 16:52:59 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2015 15:37:31 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Jurdzi\u0144ski", "Marcin", ""], ["Lazi\u0107", "Ranko", ""], ["Schmitz", "Sylvain", ""]]}, {"id": "1502.06882", "submitter": "Jad Hamza", "authors": "Ahmed Bouajjani, Michael Emmi, Constantin Enea, Jad Hamza", "title": "On Reducing Linearizability to State Reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient implementations of atomic objects such as concurrent stacks and\nqueues are especially susceptible to programming errors, and necessitate\nautomatic verification. Unfortunately their correctness criteria -\nlinearizability with respect to given ADT specifications - are hard to verify.\nEven on classes of implementations where the usual temporal safety properties\nlike control-state reachability are decidable, linearizability is undecidable.\n  In this work we demonstrate that verifying linearizability for certain fixed\nADT specifications is reducible to control-state reachability, despite being\nharder for arbitrary ADTs. We effectuate this reduction for several of the most\npopular atomic objects. This reduction yields the first decidability results\nfor verification without bounding the number of concurrent threads.\nFurthermore, it enables the application of existing safety-verification tools\nto linearizability verification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 17:06:51 GMT"}, {"version": "v2", "created": "Mon, 25 May 2015 15:03:15 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Bouajjani", "Ahmed", ""], ["Emmi", "Michael", ""], ["Enea", "Constantin", ""], ["Hamza", "Jad", ""]]}, {"id": "1502.07326", "submitter": "Vilem Vychodil", "authors": "Vilem Vychodil", "title": "Rational fuzzy attribute logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logic for reasoning with if-then formulas which involve\nconstants for rational truth degrees from the unit interval. We introduce\ngraded semantic and syntactic entailment of formulas. We prove the logic is\ncomplete in Pavelka style and depending on the choice of structure of truth\ndegrees, the logic is a decidable fragment of the Rational Pavelka logic (RPL)\nor the Rational Product Logic (R{\\Pi}L). We also present a characterization of\nthe entailment based on least models and study related closure structures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 20:19:03 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Vychodil", "Vilem", ""]]}, {"id": "1502.07466", "submitter": "Hernan Ponce de Leon", "authors": "Hern\\'an Ponce de Le\\'on, Gonzalo Bonigo, Laura Brand\\'an Briones", "title": "Distributed Analysis for Diagnosability in Concurrent Systems", "comments": "In International Workshop on Principles of Diagnosis. 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems often exhibit unexpected faults that are difficult to handle.\nSuch systems are desirable to be diagnosable, i.e. faults can be automatically\ndetected as they occur (or shortly afterwards), enabling the system to handle\nthe fault or recover. A system is diagnosable if it is possible to detect every\nfault, in a finite time after they occurred, by only observing the available\ninformation from the system. Complex systems are usually built from simpler\ncomponents running concurrently. We study how to infer the diagnosability\nproperty of a complex system (distributed and with multiple faults) from a\nparallelized analysis of the diagnosability of each of its components\nsynchronizing with fault free versions of the others.\n  In this paper we make the following contributions: (1) we address the\ndiagnosability problem of concurrent systems with arbitrary faults occurring\nfreely in each component. (2) We distribute the diagnosability analysis and\nillustrate our approach with examples. Moreover, (3) we present a prototype\ntool that implements our techniques showing promising results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 08:30:41 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["de Le\u00f3n", "Hern\u00e1n Ponce", ""], ["Bonigo", "Gonzalo", ""], ["Briones", "Laura Brand\u00e1n", ""]]}, {"id": "1502.07467", "submitter": "Thomas Zeume", "authors": "Samir Datta, Raghav Kulkarni, Anish Mukherjee, Thomas Schwentick,\n  Thomas Zeume", "title": "Reachability is in DynFO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patnaik and Immerman introduced the dynamic complexity class DynFO of\ndatabase queries that can be maintained by first-order dynamic programs with\nthe help of auxiliary relations under insertions and deletions of edges\n(Patnaik and Immerman 1997). This article confirms their conjecture that the\nReachability query is in DynFO.\n  As a byproduct it is shown that the rank of a matrix with small values can be\nmaintained in DynFO(+,x). It is further shown that the (size of the) maximum\nmatching of a graph can be maintained in non-uniform DynFO, another extension\nof DynFO, with non-uniform initialisation of the auxiliary relations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 08:30:57 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 17:54:46 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 07:28:08 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Datta", "Samir", ""], ["Kulkarni", "Raghav", ""], ["Mukherjee", "Anish", ""], ["Schwentick", "Thomas", ""], ["Zeume", "Thomas", ""]]}, {"id": "1502.07549", "submitter": "Tianrong Lin", "authors": "T. Lin", "title": "Model-checking branching-time properties of probabilistic automata and\n  probabilistic one-counter automata", "comments": "Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper studies the problem of model-checking of probabilistic automaton\nand probabilistic one-counter automata against probabilistic branching-time\ntemporal logics (PCTL and PCTL$^*$). We show that it is undecidable for these\nproblems.\n  We first show, by reducing to emptiness problem of probabilistic automata,\nthat the model-checking of probabilistic finite automata against branching-time\ntemporal logics are undecidable. And then, for each probabilistic automata, by\nconstructing a probabilistic one-counter automaton with the same behavior as\nquestioned probabilistic automata the undecidability of model-checking problems\nagainst branching-time temporal logics are derived, herein.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 13:35:31 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Lin", "T.", ""]]}, {"id": "1502.07634", "submitter": "Jamal Atif", "authors": "Marc Aiguier, Jamal Atif, Isabelle Bloch, C\\'eline Hudelot", "title": "A finite basis theorem for the description logic ${\\cal ALC}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result of this paper is to prove the existence of a finite basis in\nthe description logic ${\\cal ALC}$. We show that the set of General Concept\nInclusions (GCIs) holding in a finite model has always a finite basis, i.e.\nthese GCIs can be derived from finitely many of the GCIs. This result extends a\nprevious result from Baader and Distel, which showed the existence of a finite\nbasis for GCIs holding in a finite model but for the inexpressive description\nlogics ${\\cal EL}$ and ${\\cal EL}_{gfp}$. We also provide an algorithm for\ncomputing this finite basis, and prove its correctness. As a byproduct, we\nextend our finite basis theorem to any finitely generated complete covariety\n(i.e. any class of models closed under morphism domain, coproduct and quotient,\nand generated from a finite set of finite models).\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 16:58:58 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 20:24:39 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Aiguier", "Marc", ""], ["Atif", "Jamal", ""], ["Bloch", "Isabelle", ""], ["Hudelot", "C\u00e9line", ""]]}, {"id": "1502.07639", "submitter": "Viktor Vafeiadis", "authors": "Soham Chakraborty (MPI-SWS), Thomas A. Henzinger (IST Austria), Ali\n  Sezgin (University of Cambridge), Viktor Vafeiadis (MPI-SWS)", "title": "Aspect-oriented linearizability proofs", "comments": "33 pages, LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (April 1,\n  2015) lmcs:1051", "doi": "10.2168/LMCS-11(1:20)2015", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability of concurrent data structures is usually proved by monolithic\nsimulation arguments relying on the identification of the so-called\nlinearization points. Regrettably, such proofs, whether manual or automatic,\nare often complicated and scale poorly to advanced non-blocking concurrency\npatterns, such as helping and optimistic updates. In response, we propose a\nmore modular way of checking linearizability of concurrent queue algorithms\nthat does not involve identifying linearization points. We reduce the task of\nproving linearizability with respect to the queue specification to establishing\nfour basic properties, each of which can be proved independently by simpler\narguments. As a demonstration of our approach, we verify the Herlihy and Wing\nqueue, an algorithm that is challenging to verify by a simulation proof.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 17:17:23 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2015 18:08:10 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Chakraborty", "Soham", "", "MPI-SWS"], ["Henzinger", "Thomas A.", "", "IST Austria"], ["Sezgin", "Ali", "", "University of Cambridge"], ["Vafeiadis", "Viktor", "", "MPI-SWS"]]}, {"id": "1502.07744", "submitter": "Hernan Ponce de Leon", "authors": "Laura Brand\\'an-Briones, Agnes Madalinski, Hern\\'an Ponce-de-Le\\'on", "title": "Distributed Diagnosability Analysis with Petri Nets", "comments": "In International Workshop on Principles of Diagnosis. 2014. arXiv\n  admin note: text overlap with arXiv:1502.07466", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to distributed diagnos- ability analysis of concurrent\nsystems modeled with Petri nets as a collection of components synchronizing on\ncommon observable transitions, where faults can occur in several components.\nThe diagnosability analysis of the entire system is done in parallel by\nverifying the interaction of each component with the fault free versions of the\nother components. Furthermore, we use existing efficient methods and tools, in\nparticular parallel LTL-X model checking based on unfoldings, for\ndiagnosability verification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 08:42:19 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Brand\u00e1n-Briones", "Laura", ""], ["Madalinski", "Agnes", ""], ["Ponce-de-Le\u00f3n", "Hern\u00e1n", ""]]}, {"id": "1502.07884", "submitter": "Jonni Virtema", "authors": "Katsuhiko Sano and Jonni Virtema", "title": "Characterising Modal Definability of Team-Based Logics via the Universal\n  Modality", "comments": "30 pages. This is a preprint of a journal article to appear in Annals\n  of Pure and Applied Logic. The preprint combines and extends two conference\n  papers arXiv:1502.07884v1 and arXiv:1606.05140. The title of this preprint is\n  changed to reflect this", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model and frame definability of various modal logics. Let ML(A+)\ndenote the fragment of modal logic extended with the universal modality in\nwhich the universal modality occurs only positively. We show that a class of\nKripke models is definable in ML(A+) if and only if the class is elementary and\nclosed under disjoint unions and surjective bisimulations. We also characterise\nthe definability of ML(A+) in the spirit of the well-known Goldblatt--Thomason\ntheorem. We show that an elementary class F of Kripke frames is definable in\nML(A+) if and only if F is closed under taking generated subframes and bounded\nmorphic images, and reflects ultrafilter extensions and finitely generated\nsubframes. In addition we study frame definability relative to finite\ntransitive frames and give an analogous characterisation of ML(A+)-definability\nrelative to finite transitive frames. Finally, we initiate the study of model\nand frame definability in team-based logics. We study (extended) modal\ndependence logic, (extended) modal inclusion logic, and modal team logic. We\nestablish strict linear hierarchies with respect to model definability and\nframe definability, respectively. We show that, with respect to model and frame\ndefinability, the before mentioned team-based logics, except modal dependence\nlogic, either coincide with ML(A+) or plain modal logic ML. Thus as a corollary\nwe obtain model theoretic characterisation of model and frame definability for\nthe team-based logics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 12:59:50 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 15:22:38 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sano", "Katsuhiko", ""], ["Virtema", "Jonni", ""]]}, {"id": "1502.07889", "submitter": "Sebastian Enqvist", "authors": "Sebastian Enqvist, Fatemeh Seifan, Yde Venema", "title": "Expressiveness of the modal mu-calculus on monotone neighborhood\n  structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the expressive power of the modal mu-calculus on monotone\nneighborhood structures, in the style of the Janin-Walukiewicz theorem for the\nstandard modal mu-calculus. For this purpose we consider a monadic second-order\nlogic for monotone neighborhood structures. Our main result shows that the\nmonotone modal mu-calculus corresponds exactly to the fragment of this\nsecond-order language that is invariant for neighborhood bisimulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 13:28:42 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Enqvist", "Sebastian", ""], ["Seifan", "Fatemeh", ""], ["Venema", "Yde", ""]]}, {"id": "1502.08008", "submitter": "Peter Schneider-Kamp", "authors": "Lu\\'is Cruz-Filipe and Peter Schneider-Kamp", "title": "Optimizing a Certified Proof Checker for a Large-Scale\n  Computer-Generated Proof", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": "10.1007/978-3-319-20615-8_4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, we formalized the theory of optimal-size sorting networks\nwith the goal of extracting a verified checker for the large-scale\ncomputer-generated proof that 25 comparisons are optimal when sorting 9 inputs,\nwhich required more than a decade of CPU time and produced 27 GB of proof\nwitnesses. The checker uses an untrusted oracle based on these witnesses and is\nable to verify the smaller case of 8 inputs within a couple of days, but it did\nnot scale to the full proof for 9 inputs. In this paper, we describe several\nnon-trivial optimizations of the algorithm in the checker, obtained by\nappropriately changing the formalization and capitalizing on the symbiosis with\nan adequate implementation of the oracle. We provide experimental evidence of\norders of magnitude improvements to both runtime and memory footprint for 8\ninputs, and actually manage to check the full proof for 9 inputs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 18:55:16 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Schneider-Kamp", "Peter", ""]]}]