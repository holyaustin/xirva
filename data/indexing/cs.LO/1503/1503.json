[{"id": "1503.00043", "submitter": "Laura Bozzelli", "authors": "Laura Bozzelli and David Pearce", "title": "On the complexity of Temporal Equilibrium Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Equilibrium Logic (TEL) is a promising framework that extends the\nknowledge representation and reasoning capabilities of Answer Set Programming\nwith temporal operators in the style of LTL. To our knowledge it is the first\nnonmonotonic logic that accommodates fully the syntax of a standard temporal\nlogic (specifically LTL) without requiring further constructions. This paper\nprovides a systematic complexity analysis for the (consistency) problem of\nchecking the existence of a temporal equilibrium model of a TEL formula. It was\npreviously shown that this problem in the general case lies somewhere between\nPSPACE and EXPSPACE. Here we establish a lower bound matching the known\nEXPSPACE upper bound. Additionally we analyse the complexity for various\nnatural subclasses of TEL formulas, identifying both tractable and intractable\nfragments. Finally the paper offers some new insights on the logic LTL by\naddressing satisfiability for minimal LTL models. The complexity results\nobtained highlight a substantial difference between interpreting LTL over\nfinite or infinite words.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2015 00:43:27 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Bozzelli", "Laura", ""], ["Pearce", "David", ""]]}, {"id": "1503.00193", "submitter": "Juergen Koslowski", "authors": "Jan Leike (The Australian National University) and Matthias Heizmann\n  (University of Freiburg)", "title": "Ranking Templates for Linear Loops", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 31,\n  2015) lmcs:797", "doi": "10.2168/LMCS-11(1:16)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for the constraint-based synthesis of termination\narguments for linear loop programs based on linear ranking templates. Linear\nranking templates are parameterized, well-founded relations such that an\nassignment to the parameters gives rise to a ranking function. Our approach\ngeneralizes existing methods and enables us to use templates for many different\nranking functions with affine-linear components. We discuss templates for\nmultiphase, nested, piecewise, parallel, and lexicographic ranking functions.\nThese ranking templates can be combined to form more powerful templates.\nBecause these ranking templates require both strict and non-strict\ninequalities, we use Motzkin's transposition theorem instead of Farkas' lemma\nto transform the generated $\\exists\\forall$-constraint into an\n$\\exists$-constraint.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2015 23:01:40 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2015 13:14:08 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Leike", "Jan", "", "The Australian National University"], ["Heizmann", "Matthias", "", "University of Freiburg"]]}, {"id": "1503.00258", "submitter": "Radu Iosif", "authors": "Radu Iosif", "title": "Decidable Horn Systems with Difference Constraints Arithmetic", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  Lemma 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of the existence of solutions for recursive\nsystems of Horn clauses with second-order variables interpreted as integer\nrelations, and harnessed by quantifier-free difference bounds arithmetic. We\nstart by proving the decidability of the problem \"does the system have a\nsolution ?\" for a simple class of Horn systems with one second-order variable\nand one non-linear recursive rule. The proof relies on a construction of a tree\nautomaton recognizing all cycles in the weighted graph corresponding to every\nunfolding tree of the Horn system. We constrain the tree to recognize only\ncycles of negative weight by adding a Presburger formula that harnesses the\nnumber of times each rule is fired, and reduce our problem to the universality\nof a Presburger-constrained tree automaton. We studied the complexity of this\nproblem and found it to be in \\textsc{NEXPtime} with an \\textsc{EXPtime}-hard\nlower bound. Second, we drop the univariate restriction and consider\nmultivariate second-order Horn systems with a structural restriction, called\n\\emph{flatness}. This more general class of Horn systems is found to be\ndecidable, within the same complexity bounds. Finally, we encode the\nreachability problem for Alternating Branching Vector Addition Systems (ABVASS)\nusing Horn systems and prove that, for flat ABVASS, this problem is in\nco-\\textsc{NEXPtime}.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 11:52:57 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2015 20:40:24 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2016 14:57:50 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Iosif", "Radu", ""]]}, {"id": "1503.00336", "submitter": "Temur Kutsia", "authors": "Besik Dundua, M\\'ario Florido, Temur Kutsia, and Mircea Marin", "title": "CLP(H): Constraint Logic Programming for Hedges", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CLP(H) is an instantiation of the general constraint logic programming scheme\nwith the constraint domain of hedges. Hedges are finite sequences of unranked\nterms, built over variadic function symbols and three kinds of variables: for\nterms, for hedges, and for function symbols. Constraints involve equations\nbetween unranked terms and atoms for regular hedge language membership. We\nstudy algebraic semantics of CLP(H) programs, define a sound, terminating, and\nincomplete constraint solver, investigate two fragments of constraints for\nwhich the solver returns a complete set of solutions, and describe classes of\nprograms that generate such constraints.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 19:16:53 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Dundua", "Besik", ""], ["Florido", "M\u00e1rio", ""], ["Kutsia", "Temur", ""], ["Marin", "Mircea", ""]]}, {"id": "1503.00362", "submitter": "Antonis Achilleos", "authors": "Antonis Achilleos", "title": "NEXP-completeness and Universal Hardness Results for Justification Logic", "comments": "Shorter version has been accepted for publication by CSR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a lower complexity bound for the satisfiability problem of a\nmulti-agent justification logic, establishing that the general NEXP upper bound\nfrom our previous work is tight. We then use a simple modification of the\ncorresponding reduction to prove that satisfiability for all multi-agent\njustification logics from there is hard for the Sigma 2 p class of the second\nlevel of the polynomial hierarchy - given certain reasonable conditions. Our\nmethods improve on these required conditions for the same lower bound for the\nsingle-agent justification logics, proven by Buss and Kuznets in 2009, thus\nanswering one of their open questions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 22:07:21 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Achilleos", "Antonis", ""]]}, {"id": "1503.00368", "submitter": "Steven Kelk", "authors": "Steven Kelk, Leo van Iersel, Celine Scornavacca", "title": "Phylogenetic incongruence through the lens of Monadic Second Order logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.LO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the field of phylogenetics there is growing interest in measures for\nsummarising the dissimilarity, or 'incongruence', of two or more phylogenetic\ntrees. Many of these measures are NP-hard to compute and this has stimulated a\nconsiderable volume of research into fixed parameter tractable algorithms. In\nthis article we use Monadic Second Order logic (MSOL) to give alternative,\ncompact proofs of fixed parameter tractability for several well-known\nincongruency measures. In doing so we wish to demonstrate the considerable\npotential of MSOL - machinery still largely unknown outside the algorithmic\ngraph theory community - within phylogenetics. A crucial component of this work\nis the observation that many of these measures, when bounded, imply the\nexistence of an 'agreement forest' of bounded size, which in turn implies that\nan auxiliary graph structure, the display graph, has bounded treewidth. It is\nthis bound on treewidth that makes the machinery of MSOL available for proving\nfixed parameter tractability. We give a variety of different MSOL formulations.\nSome are based on explicitly encoding agreement forests, while some only use\nthem implicitly to generate the treewidth bound. Our formulations introduce a\nnumber of \"phylogenetics MSOL primitives\" which will hopefully be of use to\nother researchers.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 22:31:31 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Kelk", "Steven", ""], ["van Iersel", "Leo", ""], ["Scornavacca", "Celine", ""]]}, {"id": "1503.00493", "submitter": "Silvano Dal Zilio", "authors": "B Berthomieu (LAAS), J.-P Bodeveix (IRIT), S Dal Zilio (LAAS), M\n  Filali (IRIT), D Le Botlan (LAAS), G Verdier (IRIT), F Vernadat (LAAS)", "title": "Real-Time Model Checking Support for AADL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a model-checking toolchain for the behavioral verification of\nAADL models that takes into account the realtime semantics of the language and\nthat is compatible with the AADL Behavioral Annex. We give a high-level view of\nthe tools and transformations involved in the verification process and focus on\nthe support offered by our framework for checking user-defined properties. We\nalso describe the experimental results obtained on a significant avionic\ndemonstrator, that models a network protocol in charge of data communications\nbetween an airplane and ground stations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 12:20:29 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Berthomieu", "B", "", "LAAS"], ["Bodeveix", "J. -P", "", "IRIT"], ["Zilio", "S Dal", "", "LAAS"], ["Filali", "M", "", "IRIT"], ["Botlan", "D Le", "", "LAAS"], ["Verdier", "G", "", "IRIT"], ["Vernadat", "F", "", "LAAS"]]}, {"id": "1503.00745", "submitter": "Sylvain Schmitz", "authors": "J\\'er\\^ome Leroux and Sylvain Schmitz", "title": "Demystifying Reachability in Vector Addition Systems", "comments": "To appear in the Proceedings of LICS 2015", "journal-ref": "Proceedings of LICS 2015, pp. 56--67, IEEE Press", "doi": "10.1109/LICS.2015.16", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 30 years after their inception, the decidability proofs for\nreachability in vector addition systems (VAS) still retain much of their\nmystery. These proofs rely crucially on a decomposition of runs successively\nrefined by Mayr, Kosaraju, and Lambert, which appears rather magical, and for\nwhich no complexity upper bound is known.\n  We first offer a justification for this decomposition technique, by showing\nthat it computes the ideal decomposition of the set of runs, using the natural\nembedding relation between runs as well quasi ordering. In a second part, we\napply recent results on the complexity of termination thanks to well quasi\norders and well orders to obtain a cubic Ackermann upper bound for the\ndecomposition algorithms, thus providing the first known upper bounds for\ngeneral VAS reachability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 21:12:14 GMT"}, {"version": "v2", "created": "Wed, 13 May 2015 08:29:17 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Leroux", "J\u00e9r\u00f4me", ""], ["Schmitz", "Sylvain", ""]]}, {"id": "1503.00793", "submitter": "Neeraj Kumar", "authors": "Therese Biedl, Sebastian Fischmeister and Neeraj Kumar", "title": "DAG-width of Control Flow Graphs with Applications to Model Checking", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The treewidth of control flow graphs arising from structured programs is\nknown to be at most six. However, as a control flow graph is inherently\ndirected, it makes sense to consider a measure of width for digraphs instead.\nWe use the so-called DAG-width and show that the DAG-width of control flow\ngraphs arising from structured (goto-free) programs is at most three.\nAdditionally, we also give a linear time algorithm to compute the DAG\ndecomposition of these control flow graphs. One consequence of this result is\nthat parity games (and hence the $\\mu$-calculus model checking problem), which\nare known to be tractable on graphs of bounded DAG-width, can be solved\nefficiently in practice on control flow graphs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 01:05:06 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Biedl", "Therese", ""], ["Fischmeister", "Sebastian", ""], ["Kumar", "Neeraj", ""]]}, {"id": "1503.00806", "submitter": "Joseph Y. Halpern", "authors": "Hans van Ditmarsch and Joseph Y. Halpern and Wiebe van der Hoek and\n  Barteld Kooi", "title": "An Introduction to Logics of Knowledge and Belief", "comments": "FIrst chapter of \"Handbook of Epistemic Logic\", by Hans van\n  Ditmarsch, Joseph Y. Halpern, Wiebe van der Hoek, and Barteld Kooi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides an introduction to some basic concepts of epistemic\nlogic, basic formal languages, their semantics, and proof systems. It also\ncontains an overview of the handbook, and a brief history of epistemic logic\nand pointers to the literature.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 02:20:43 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["van Ditmarsch", "Hans", ""], ["Halpern", "Joseph Y.", ""], ["van der Hoek", "Wiebe", ""], ["Kooi", "Barteld", ""]]}, {"id": "1503.00826", "submitter": "Dan DaCosta", "authors": "Daniel DaCosta", "title": "Towards Reasoning About Properties of Imperative Programs using Linear\n  Logic", "comments": "This report was submitted in partial fulfillment of my preliminary\n  examination", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper we propose an approach to reasoning about properties of\nimperative programs. We assume in this context that the meanings of program\nconstructs are described using rules in the natural semantics style with the\nadditional observation that these rules may involve the treatment of state. Our\napproach involves modeling natural semantics style rules within a logic and\nthen reasoning about the behavior of particular programs by reasoning about\nproofs in that logic. A key aspect of our proposal is to use a fragment of\nlinear logic called Lolli (invented by Hodas and Miller) to model natural\nsemantics style descriptions. Being based on linear logic, Lolli can provide\nlogical expression to resources such as state. Lolli additionally possesses\nproof-theoretic properties that allow it to encode natural semantics style\ndescriptions in such a way that proofs in Lolli mimic the structure of\nderivations based on the natural semantics rules. We will discuss these\nproperties of Lolli and demonstrate how they can be exploited in modeling the\nsemantics of imperative programs and in reasoning about such models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 04:41:49 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["DaCosta", "Daniel", ""]]}, {"id": "1503.00886", "submitter": "Masahiro Hamano", "authors": "Masahiro Hamano and Philip Scott", "title": "On Geometry of Interaction for Polarized Linear Logic", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Geometry of Interaction (GoI) models for Multiplicative Polarized\nLinear Logic, MLLP, which is the multiplicative fragment of Olivier Laurent's\nPolarized Linear Logic. This is done by uniformly adding multipoints to various\ncategorical models of GoI. Multipoints are shown to play an essential role in\nsemantically characterizing the dynamics of proof networks in polarized proof\ntheory. For example, they permit us to characterize the key feature of\npolarization, focusing, as well as being fundamental to our construction of\nconcrete polarized GoI models.\n  Our approach to polarized GoI involves two independent studies, based on\ndifferent categorical perspectives of GoI.\n  (i) Inspired by the work of Abramsky, Haghverdi, and Scott, a polarized GoI\nsituation is defined in which multipoints are added to a traced monoidal\ncategory equipped with a reflexive object $U$. Using this framework,\ncategorical versions of Girard's Execution formula are defined, as well as the\nGoI interpretation of MLLP, proofs. Running the Execution formula is shown to\ncharacterize the focusing property (and thus polarities) as well as the\ndynamics of cut-elimination.\n  (ii) The Int construction of Joyal-Street-Verity is another fundamental\ncategorical structure for modelling GoI. Here, we investigate it in a\nmultipointed setting. Our presentation yields a compact version of\nHamano-Scott's polarized categories, and thus denotational models of MLLP.\nThese arise from a contravariant duality between monoidal categories of\npositive and negative objects, along with an appropriate bimodule structure\n(representing \"non-focused proofs\") between them.\n  Finally, as a special case of (ii) above, a compact model of MLLP is also\npresented based on Rel (the category of sets and relations) equipped with\nmulti-points.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 10:38:18 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 05:54:58 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 05:59:03 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Hamano", "Masahiro", ""], ["Scott", "Philip", ""]]}, {"id": "1503.00948", "submitter": "Jean-Guillaume Dumas", "authors": "Jean-Guillaume Dumas (LJK), Dominique Duval (LJK), Burak Ekici (LJK),\n  Damien Pous (LIP), Jean-Claude Reynaud (RC)", "title": "Hilbert-Post completeness for the state and the exception effects", "comments": "Siegfried Rump (Hamburg University of Technology), Chee Yap (Courant\n  Institute, NYU). Sixth International Conference on Mathematical Aspects of\n  Computer and Information Sciences , Nov 2015, Berlin, Germany. 2015, LNCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel framework for studying the syntactic\ncompleteness of computational effects and we apply it to the exception effect.\nWhen applied to the states effect, our framework can be seen as a\ngeneralization of Pretnar's work on this subject. We first introduce a relative\nnotion of Hilbert-Post completeness, well-suited to the composition of effects.\nThen we prove that the exception effect is relatively Hilbert-Post complete, as\nwell as the \"core\" language which may be used for implementing it; these proofs\nhave been formalized and checked with the proof assistant Coq.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 14:05:12 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 11:39:14 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2015 09:48:25 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "LJK"], ["Duval", "Dominique", "", "LJK"], ["Ekici", "Burak", "", "LJK"], ["Pous", "Damien", "", "LIP"], ["Reynaud", "Jean-Claude", "", "RC"]]}, {"id": "1503.01034", "submitter": "Vladimir Zamdzhiev", "authors": "Aleks Kissinger and Vladimir Zamdzhiev", "title": "Quantomatic: A Proof Assistant for Diagrammatic Reasoning", "comments": "International Conference on Automated Deduction, CADE 2015 (CADE-25).\n  The final publication is available at Springer via\n  http://dx.doi.org/10.1007/978-3-319-21401-6_22", "journal-ref": null, "doi": "10.1007/978-3-319-21401-6_22", "report-no": null, "categories": "cs.LO cs.MS math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monoidal algebraic structures consist of operations that can have multiple\noutputs as well as multiple inputs, which have applications in many areas\nincluding categorical algebra, programming language semantics, representation\ntheory, algebraic quantum information, and quantum groups. String diagrams\nprovide a convenient graphical syntax for reasoning formally about such\nstructures, while avoiding many of the technical challenges of a term-based\napproach. Quantomatic is a tool that supports the (semi-)automatic construction\nof equational proofs using string diagrams. We briefly outline the theoretical\nbasis of Quantomatic's rewriting engine, then give an overview of the core\nfeatures and architecture and give a simple example project that computes\nnormal forms for commutative bialgebras.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 18:20:39 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 15:30:29 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Kissinger", "Aleks", ""], ["Zamdzhiev", "Vladimir", ""]]}, {"id": "1503.01144", "submitter": "EPTCS", "authors": "Arnaud Durand, Juha Kontinen, Nicolas de Rugy-Altherre, Jouko\n  V\\\"a\\\"an\\\"anen", "title": "Tractability Frontier of Data Complexity in Team Semantics", "comments": "In Proceedings GandALF 2015, arXiv:1509.06858", "journal-ref": "EPTCS 193, 2015, pp. 73-85", "doi": "10.4204/EPTCS.193.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the data complexity of model-checking for logics with team\nsemantics. For dependence and independence logic, we completely characterize\nthe tractability/intractability frontier of data complexity of both\nquantifier-free and quantified formulas. For inclusion logic formulas, we\nreduce the model-checking problem to the satisfiability problem of so-called\nDual-Horn propositional formulas. Via this reduction, we give an alternative\nproof for the recent result showing that the data complexity of inclusion logic\nis in PTIME.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 22:00:45 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2015 01:52:48 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Durand", "Arnaud", ""], ["Kontinen", "Juha", ""], ["de Rugy-Altherre", "Nicolas", ""], ["V\u00e4\u00e4n\u00e4nen", "Jouko", ""]]}, {"id": "1503.01348", "submitter": "Aleks Kissinger", "authors": "Aleks Kissinger and David Quick", "title": "Tensors, !-graphs, and non-commutative quantum structures (extended\n  version)", "comments": "extended version of arXiv:1412.8552 [cs.LO], adds additional examples\n  and soundness proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  !-graphs provide a means of reasoning about infinite families of string\ndiagrams and have proven useful in manipulation of (co)algebraic structures\nlike Hopf algebras, Frobenius algebras, and compositions thereof. However, they\nhave previously been limited by an inability to express families of diagrams\ninvolving non-commutative structures which play a central role in algebraic\nquantum information and the theory of quantum groups. In this paper, we fix\nthis shortcoming by offering a new semantics for non-commutative !-graphs using\nan enriched version of Penrose's abstract tensor notation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2015 15:44:07 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Kissinger", "Aleks", ""], ["Quick", "David", ""]]}, {"id": "1503.01547", "submitter": "Arlen Cox", "authors": "Arlen Cox", "title": "Binary-Decision-Diagrams for Set Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether explicit or implicit, sets are a critical part of many pieces of\nsoftware. As a result, it is necessary to develop abstractions of sets for the\npurposes of abstract interpretation, model checking, and deductive\nverification. However, the construction of effective abstractions for sets is\nchallenging because they are a higher-order construct. It is necessary to\nreason about contents of sets as well as relationships between sets. This paper\npresents a new abstraction for sets that is based on binary decision diagrams.\nIt is optimized for precisely and efficiently representing relations between\nsets while still providing limited support for content reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 06:11:25 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Cox", "Arlen", ""]]}, {"id": "1503.01604", "submitter": "Lars Jaffke", "authors": "Lars Jaffke and Hans L. Bodlaender", "title": "MSOL-Definability Equals Recognizability for Halin Graphs and Bounded\n  Degree $k$-Outerplanar Graphs", "comments": "39 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most famous algorithmic meta-theorems states that every graph\nproperty that can be defined by a sentence in counting monadic second order\nlogic (CMSOL) can be checked in linear time for graphs of bounded treewidth,\nwhich is known as Courcelle's Theorem. These algorithms are constructed as\nfinite state tree automata, and hence every CMSOL-definable graph property is\nrecognizable. Courcelle also conjectured that the converse holds, i.e. every\nrecognizable graph property is definable in CMSOL for graphs of bounded\ntreewidth. We prove this conjecture for a number of special cases in a stronger\nform. That is, we show that each recognizable property is definable in MSOL,\ni.e. the counting operation is not needed in our expressions. We give proofs\nfor Halin graphs, bounded degree $k$-outerplanar graphs and some related graph\nclasses. We furthermore show that the conjecture holds for any graph class that\nadmits tree decompositions that can be defined in MSOL, thus providing a useful\ntool for future proofs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 11:07:23 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Jaffke", "Lars", ""], ["Bodlaender", "Hans L.", ""]]}, {"id": "1503.01707", "submitter": "Jan Van den Bussche", "authors": "Angela Bonifati, Werner Nutt, Riccardo Torlone, Jan Van den Bussche", "title": "Mapping-equivalence and oid-equivalence of single-function\n  object-creating conjunctive queries", "comments": "This revised version has been accepted on 11 January 2016 for\n  publication in The VLDB Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjunctive database queries have been extended with a mechanism for object\ncreation to capture important applications such as data exchange, data\nintegration, and ontology-based data access. Object creation generates new\nobject identifiers in the result, that do not belong to the set of constants in\nthe source database. The new object identifiers can be also seen as Skolem\nterms. Hence, object-creating conjunctive queries can also be regarded as\nrestricted second-order tuple-generating dependencies (SO tgds), considered in\nthe data exchange literature.\n  In this paper, we focus on the class of single-function object-creating\nconjunctive queries, or sifo CQs for short. We give a new characterization for\noid-equivalence of sifo CQs that is simpler than the one given by Hull and\nYoshikawa and places the problem in the complexity class NP. Our\ncharacterization is based on Cohen's equivalence notions for conjunctive\nqueries with multiplicities. We also solve the logical entailment problem for\nsifo CQs, showing that also this problem belongs to NP. Results by Pichler et\nal. have shown that logical equivalence for more general classes of SO tgds is\neither undecidable or decidable with as yet unknown complexity upper bounds.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 17:47:04 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 14:59:40 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Bonifati", "Angela", ""], ["Nutt", "Werner", ""], ["Torlone", "Riccardo", ""], ["Bussche", "Jan Van den", ""]]}, {"id": "1503.01723", "submitter": "Rod Moten", "authors": "Rod Moten", "title": "Modelling the Semantic Web using a Type System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for modeling the Semantic Web as a type system. By\nusing a type system, we can use symbolic representation for representing linked\ndata. Objects with only data properties and references to external resources\nare represented as terms in the type system. Triples are represented\nsymbolically using type constructors as the predicates. In our type system, we\nallow users to add analytics that utilize machine learning or knowledge\ndiscovery to perform inductive reasoning over data. These analytics can be used\nby the inference engine when performing reasoning to answer a query.\nFurthermore, our type system defines a means to resolve semantic heterogeneity\non-the-fly.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 18:22:52 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Moten", "Rod", ""]]}, {"id": "1503.01793", "submitter": "Min  Wen", "authors": "Min Wen, Ruediger Ehlers, Ufuk Topcu", "title": "Correct-by-synthesis reinforcement learning with temporal logic\n  constraints", "comments": "8 pages, 3 figures, 2 tables, submitted to IROS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem on the synthesis of reactive controllers that optimize\nsome a priori unknown performance criterion while interacting with an\nuncontrolled environment such that the system satisfies a given temporal logic\nspecification. We decouple the problem into two subproblems. First, we extract\na (maximally) permissive strategy for the system, which encodes multiple\n(possibly all) ways in which the system can react to the adversarial\nenvironment and satisfy the specifications. Then, we quantify the a priori\nunknown performance criterion as a (still unknown) reward function and compute\nan optimal strategy for the system within the operating envelope allowed by the\npermissive strategy by using the so-called maximin-Q learning algorithm. We\nestablish both correctness (with respect to the temporal logic specifications)\nand optimality (with respect to the a priori unknown performance criterion) of\nthis two-step technique for a fragment of temporal logic specifications. For\nspecifications beyond this fragment, correctness can still be preserved, but\nthe learned strategy may be sub-optimal. We present an algorithm to the overall\nproblem, and demonstrate its use and computational requirements on a set of\nrobot motion planning examples.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 21:23:45 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Wen", "Min", ""], ["Ehlers", "Ruediger", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1503.01981", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer", "title": "A Uniform Substitution Calculus for Differential Dynamic Logic", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-21401-6_32", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new proof calculus for differential dynamic logic\n(dL) that is entirely based on uniform substitution, a proof rule that\nsubstitutes a formula for a predicate symbol everywhere. Uniform substitutions\nmake it possible to rely on axioms rather than axiom schemata, substantially\nsimplifying implementations. Instead of nontrivial schema variables and\nsoundness-critical side conditions on the occurrence patterns of variables, the\nresulting calculus adopts only a finite number of ordinary dL formulas as\naxioms. The static semantics of differential dynamic logic is captured\nexclusively in uniform substitutions and bound variable renamings as opposed to\nbeing spread in delicate ways across the prover implementation. In addition to\nsound uniform substitutions, this paper introduces differential forms for\ndifferential dynamic logic that make it possible to internalize differential\ninvariants, differential substitutions, and derivations as first-class axioms\nin dL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2015 15:05:30 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2015 15:23:32 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2015 19:53:19 GMT"}, {"version": "v4", "created": "Fri, 15 May 2015 02:22:37 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2015 19:18:02 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Platzer", "Andr\u00e9", ""]]}, {"id": "1503.02210", "submitter": "Evgeny Sherkhonov", "authors": "Alessandro Facchini (University of Warsaw), Yoichi Hirai (National\n  Institute of Advanced Industrial Science and Technology), Maarten Marx\n  (University of Amsterdam), Evgeny Sherkhonov (University of Amsterdam)", "title": "Containment for Conditional Tree Patterns", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (June 9,\n  2015) lmcs:1564", "doi": "10.2168/LMCS-11(2:4)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Conditional Tree Pattern (CTP) expands an XML tree pattern with labels\nattached to the descendant edges. These labels can be XML element names or\nBoolean CTPs. The meaning of a descendant edge labelled by A and ending in a\nnode labelled by B is a path of child steps ending in a B node such that all\nintermediate nodes are A nodes. In effect this expresses the until B, A holds\nconstruction from temporal logic.This paper studies the containment problem for\nCTP. For tree patterns (TP), this problem is known to be coNP-complete. We show\nthat it is PSPACE-complete for CTP. This increase in complexity is due to the\nfact that CTP is expressive enough to encode an unrestricted form of label\nnegation: ${*}\\setminus a$, meaning \"any node except an a-node\". Containment of\nTP expanded with this type of negation is already PSPACE-hard. CTP is a\npositive, forward, first order fragment of Regular XPath. Unlike TP, CTP\nexpanded with disjunction is not equivalent to unions of CTP's. Like TP, CTP is\na natural fragment to consider: CTP is closed under intersections and CTP with\ndisjunction is equally expressive as positive existential first order logic\nexpanded with the until operator.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2015 20:22:45 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2015 20:31:48 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Facchini", "Alessandro", "", "University of Warsaw"], ["Hirai", "Yoichi", "", "National\n  Institute of Advanced Industrial Science and Technology"], ["Marx", "Maarten", "", "University of Amsterdam"], ["Sherkhonov", "Evgeny", "", "University of Amsterdam"]]}, {"id": "1503.02319", "submitter": "Fatemeh Seifan", "authors": "Johannes Marti, Fatemeh Seifan and Yde Venema", "title": "Uniform Interpolation for Coalgebraic Fixpoint Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the connection between automata and logic to prove that a wide class\nof coalgebraic fixpoint logics enjoys uniform interpolation. To this aim, first\nwe generalize one of the central results in coalgebraic automata theory, namely\nclosure under projection, which is known to hold for weak-pullback preserving\nfunctors, to a more general class of functors, i.e.; functors with\nquasi-functorial lax extensions. Then we will show that closure under\nprojection implies definability of the bisimulation quantifier in the language\nof coalgebraic fixpoint logic, and finally we prove the uniform interpolation\ntheorem.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2015 20:44:58 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Marti", "Johannes", ""], ["Seifan", "Fatemeh", ""], ["Venema", "Yde", ""]]}, {"id": "1503.02349", "submitter": "Mario Carneiro", "authors": "Mario Carneiro", "title": "Arithmetic in Metamath, Case Study: Bertrand's Postulate", "comments": "16 pages, 0 figures; submitted to CICM 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike some other formal systems, the proof system Metamath has no built-in\nconcept of \"decimal number\" in the sense that arbitrary digit strings are not\nrecognized by the system without prior definition. We present a system of\ntheorems and definitions and an algorithm to apply these as basic operations to\nperform arithmetic calculations with a number of steps proportional to an\narbitrary-precision arithmetic calculation. We consider as case study the\nformal proof of Bertrand's postulate, which required the calculation of many\nsmall primes. Using a Mathematica implementation, we were able to complete the\nfirst formal proof in Metamath using numbers larger than 10. Applications to\nthe mechanization of Metamath proofs are discussed, and a heuristic argument\nfor the feasability of large proofs such as Tom Hales' proof of the Kepler\nconjecture is presented.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 00:46:46 GMT"}, {"version": "v2", "created": "Sun, 3 May 2015 05:37:43 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Carneiro", "Mario", ""]]}, {"id": "1503.02422", "submitter": "Lorenzo Clemente Lorenzo Clemente", "authors": "Lorenzo Clemente and S{\\l}awomir Lasota", "title": "Timed pushdown automata revisited", "comments": "full technical report of LICS'15 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper contains two results on timed extensions of pushdown automata\n(PDA). As our first result we prove that the model of dense-timed PDA of\nAbdulla et al. collapses: it is expressively equivalent to dense-timed PDA with\ntimeless stack. Motivated by this result, we advocate the framework of\nfirst-order definable PDA, a specialization of PDA in sets with atoms, as the\nright setting to define and investigate timed extensions of PDA. The general\nmodel obtained in this way is Turing complete. As our second result we prove\nNEXPTIME upper complexity bound for the non-emptiness problem for an expressive\nsubclass. As a byproduct, we obtain a tight EXPTIME complexity bound for a more\nrestrictive subclass of PDA with timeless stack, thus subsuming the complexity\nbound known for dense-timed PDA.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 10:59:48 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 16:03:44 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Clemente", "Lorenzo", ""], ["Lasota", "S\u0142awomir", ""]]}, {"id": "1503.02447", "submitter": "Marcello M. Bonsangue", "authors": "Marcello M. Bonsangue (Leiden University), Helle Hvid Hansen (Radboud\n  University Nijmegen), Alexander Kurz (University of Leicester), Jurriaan Rot\n  (Leiden University)", "title": "Presenting Distributive Laws", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (August 7,\n  2015) lmcs:1578", "doi": "10.2168/LMCS-11(3:2)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributive laws of a monad T over a functor F are categorical tools for\nspecifying algebra-coalgebra interaction. They proved to be important for\nsolving systems of corecursive equations, for the specification of well-behaved\nstructural operational semantics and, more recently, also for enhancements of\nthe bisimulation proof method. If T is a free monad, then such distributive\nlaws correspond to simple natural transformations. However, when T is not free\nit can be rather difficult to prove the defining axioms of a distributive law.\nIn this paper we describe how to obtain a distributive law for a monad with an\nequational presentation from a distributive law for the underlying free monad.\nWe apply this result to show the equivalence between two different\nrepresentations of context-free languages.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 12:16:17 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2015 23:33:18 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Bonsangue", "Marcello M.", "", "Leiden University"], ["Hansen", "Helle Hvid", "", "Radboud\n  University Nijmegen"], ["Kurz", "Alexander", "", "University of Leicester"], ["Rot", "Jurriaan", "", "Leiden University"]]}, {"id": "1503.02627", "submitter": "Brett McLean", "authors": "Brett McLean and Szabolcs Mikul\\'as", "title": "The finite representation property for composition, intersection, domain\n  and range", "comments": "15 pages. Results extended from antidomain-containing signatures to\n  domain-containing signatures", "journal-ref": "International Journal of Algebra and Computation, Volume 26, Issue\n  6 (2016) 1199-1216", "doi": "10.1142/S0218196716500508", "report-no": null, "categories": "math.RA cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the finite representation property holds for representation by\npartial functions for the signature consisting of composition, intersection,\ndomain and range and for any expansion of this signature by the antidomain,\nfixset, preferential union, maximum iterate and opposite operations. The proof\nshows that, for all these signatures, the size of base required is bounded by a\ndouble-exponential function of the size of the algebra. This establishes that\nrepresentability of finite algebras is decidable for all these signatures. We\nalso give an example of a signature for which the finite representation\nproperty fails to hold for representation by partial functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 19:20:20 GMT"}, {"version": "v2", "created": "Fri, 4 Mar 2016 17:59:44 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["McLean", "Brett", ""], ["Mikul\u00e1s", "Szabolcs", ""]]}, {"id": "1503.02948", "submitter": "Martin Bromberger", "authors": "Martin Bromberger, Thomas Sturm, and Christoph Weidenbach", "title": "Linear Integer Arithmetic Revisited", "comments": "Extended version of our CADE-25 conference paper, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider feasibility of linear integer programs in the context of\nverification systems such as SMT solvers or theorem provers. Although\nsatisfiability of linear integer programs is decidable, many state-of-the-art\nsolvers neglect termination in favor of efficiency. It is challenging to design\na solver that is both terminating and practically efficient. Recent work by\nJovanovic and de Moura constitutes an important step into this direction. Their\nalgorithm CUTSAT is sound, but does not terminate, in general. In this paper we\nextend their CUTSAT algorithm by refined inference rules, a new type of\nconflicting core, and a dedicated rule application strategy. This leads to our\nalgorithm CUTSAT++, which guarantees termination.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2015 15:13:52 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 18:41:45 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 11:39:43 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bromberger", "Martin", ""], ["Sturm", "Thomas", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "1503.02971", "submitter": "Andreas Teucke", "authors": "Andreas Teucke and Christoph Weidenbach", "title": "First-Order Logic Theorem Proving and Model Building via Approximation\n  and Instantiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider first-order logic theorem proving and model\nbuilding via approximation and instantiation. Given a clause set we propose its\napproximation into a simplified clause set where satisfiability is decidable.\nThe approximation extends the signature and preserves unsatisfiability: if the\nsimplified clause set is satisfiable in some model, so is the original clause\nset in the same model interpreted in the original signature. A refutation\ngenerated by a decision procedure on the simplified clause set can then either\nbe lifted to a refutation in the original clause set, or it guides a refinement\nexcluding the previously found unliftable refutation. This way the approach is\nrefutationally complete. We do not step-wise lift refutations but conflicting\ncores, finite unsatisfiable clause sets representing at least one refutation.\nThe approach is dual to many existing approaches in the literature because our\napproximation preserves unsatisfiability.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2015 16:16:56 GMT"}, {"version": "v2", "created": "Thu, 21 May 2015 09:08:44 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Teucke", "Andreas", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "1503.03324", "submitter": "Wlodzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "On definite program answers and least Herbrand models", "comments": "11 pages. This version - small changes, version 2 - technical core of\n  the paper corrected, simplified and improved. To appear in Theory and\n  Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 16 (2016) 498-508", "doi": "10.1017/S1471068416000089", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sufficient and necessary condition is given under which least Herbrand\nmodels exactly characterize the answers of definite clause programs.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 13:32:49 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2015 17:28:57 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2016 21:00:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}, {"id": "1503.03715", "submitter": "Gunther Rei{\\ss}ig", "authors": "Gunther Reissig, Alexander Weber, Matthias Rungger", "title": "Feedback Refinement Relations for the Synthesis of Symbolic Controllers", "comments": "This work has been accepted for publication in the IEEE Trans.\n  Automatic Control. v3: Definition VIII.2 corrected; plus minor modifications;\n  accepted version", "journal-ref": "IEEE Trans. Automat. Control 62, no 4, pp 1781-1796, 2017", "doi": "10.1109/TAC.2016.2593947", "report-no": null, "categories": "math.OC cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an abstraction and refinement methodology for the automated\ncontroller synthesis to enforce general predefined specifications. The designed\ncontrollers require quantized (or symbolic) state information only and can be\ninterfaced with the system via a static quantizer. Both features are\nparticularly important with regard to any practical implementation of the\ndesigned controllers and, as we prove, are characterized by the existence of a\nfeedback refinement relation between plant and abstraction. Feedback refinement\nrelations are a novel concept introduced in this paper. Our work builds on a\ngeneral notion of system with set-valued dynamics and possibly\nnon-deterministic quantizers to permit the synthesis of controllers that\nrobustly, and provably, enforce the specification in the presence of various\ntypes of uncertainties and disturbances. We identify a class of abstractions\nthat is canonical in a well-defined sense, and provide a method to efficiently\ncompute canonical abstractions. We demonstrate the practicality of our approach\non two examples.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 13:45:10 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 19:04:05 GMT"}, {"version": "v3", "created": "Mon, 2 Jan 2017 13:14:24 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Reissig", "Gunther", ""], ["Weber", "Alexander", ""], ["Rungger", "Matthias", ""]]}, {"id": "1503.04034", "submitter": "Pierre Clairambault", "authors": "Pierre Clairambault (CNRS and ENS Lyon)", "title": "Bounding linear head reduction and visible interaction through skeletons", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (June 10,\n  2015) lmcs:1566", "doi": "10.2168/LMCS-11(2:6)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the complexity of execution in higher-order\nprogramming languages. Our study has two facets: on the one hand we give an\nupper bound to the length of interactions between bounded P-visible strategies\nin Hyland-Ong game semantics. This result covers models of programming\nlanguages with access to computational effects like non-determinism, state or\ncontrol operators, but its semantic formulation causes a loose connection to\nsyntax. On the other hand we give a syntactic counterpart of our semantic\nstudy: a non-elementary upper bound to the length of the linear head reduction\nsequence (a low-level notion of reduction, close to the actual implementation\nof the reduction of higher-order programs by abstract machines) of simply-typed\nlambda-terms. In both cases our upper bounds are proved optimal by giving\nmatching lower bounds. These two results, although different in scope, are\nproved using the same method: we introduce a simple reduction on finite trees\nof natural numbers, hereby called interaction skeletons. We study this\nreduction and give upper bounds to its complexity. We then apply this study by\ngiving two simulation results: a semantic one measuring progress in\ngame-theoretic interaction via interaction skeletons, and a syntactic one\nestablishing a correspondence between linear head reduction of terms satisfying\na locality condition called local scope and the reduction of interaction\nskeletons. This result is then generalized to arbitrary terms by a local\nscopization transformation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2015 12:23:50 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2015 08:20:01 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Clairambault", "Pierre", "", "CNRS and ENS Lyon"]]}, {"id": "1503.04135", "submitter": "Giuseppe Sanfilippo", "authors": "Angelo Gilio, Niki Pfeifer and Giuseppe Sanfilippo", "title": "Transitive reasoning with imprecise probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistically informative (weak) versions of transitivity, by\nusing suitable definitions of defaults and negated defaults, in the setting of\ncoherence and imprecise probabilities. We represent p-consistent sequences of\ndefaults and/or negated defaults by g-coherent imprecise probability\nassessments on the respective sequences of conditional events. Finally, we\nprove the coherent probability propagation rules for Weak Transitivity and the\nvalidity of selected inference patterns by proving the p-entailment for the\nassociated knowledge bases.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2015 16:34:04 GMT"}], "update_date": "2015-03-16", "authors_parsed": [["Gilio", "Angelo", ""], ["Pfeifer", "Niki", ""], ["Sanfilippo", "Giuseppe", ""]]}, {"id": "1503.04193", "submitter": "Nicolas Troquard", "authors": "Daniele Porello, Nicolas Troquard", "title": "Non-normal modalities in variants of Linear Logic", "comments": null, "journal-ref": null, "doi": "10.1080/11663081.2015.1080422", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents modal versions of resource-conscious logics. We\nconcentrate on extensions of variants of Linear Logic with one minimal\nnon-normal modality. In earlier work, where we investigated agency in\nmulti-agent systems, we have shown that the results scale up to logics with\nmultiple non-minimal modalities. Here, we start with the language of\npropositional intuitionistic Linear Logic without the additive disjunction, to\nwhich we add a modality. We provide an interpretation of this language on a\nclass of Kripke resource models extended with a neighbourhood function: modal\nKripke resource models. We propose a Hilbert-style axiomatization and a\nGentzen-style sequent calculus. We show that the proof theories are sound and\ncomplete with respect to the class of modal Kripke resource models. We show\nthat the sequent calculus admits cut elimination and that proof-search is in\nPSPACE. We then show how to extend the results when non-commutative connectives\nare added to the language. Finally, we put the logical framework to use by\ninstantiating it as logics of agency. In particular, we propose a logic to\nreason about the resource-sensitive use of artefacts and illustrate it with a\nvariety of examples.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2015 19:54:15 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2015 15:16:44 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Porello", "Daniele", ""], ["Troquard", "Nicolas", ""]]}, {"id": "1503.04320", "submitter": "Sylvain Salvati", "authors": "Sylvain Salvati (INRIA, LaBRI, universit\\'e de Bordeaux), Igor\n  Walukiewicz (CNRS, LaBRI, universit\\'e de Bordeaux)", "title": "Using models to model-check recursive schemes", "comments": "Long version of a paper presented at TLCA 2013", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (June 11,\n  2015) lmcs:1567", "doi": "10.2168/LMCS-11(2:7)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-based approach to the model checking problem for recursive\nschemes. Since simply typed lambda calculus with the fixpoint operator,\nlambda-Y-calculus, is equivalent to schemes, we propose the use of a model of\nlambda-Y-calculus to discriminate the terms that satisfy a given property. If a\nmodel is finite in every type, this gives a decision procedure. We provide a\nconstruction of such a model for every property expressed by automata with\ntrivial acceptance conditions and divergence testing. Such properties pose\nalready interesting challenges for model construction. Moreover, we argue that\nhaving models capturing some class of properties has several other virtues in\naddition to providing decidability of the model-checking problem. As an\nillustration, we show a very simple construction transforming a scheme to a\nscheme reflecting a property captured by a given model.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2015 16:29:34 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2015 19:56:41 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Salvati", "Sylvain", "", "INRIA, LaBRI, universit\u00e9 de Bordeaux"], ["Walukiewicz", "Igor", "", "CNRS, LaBRI, universit\u00e9 de Bordeaux"]]}, {"id": "1503.04377", "submitter": "EPTCS", "authors": "Jakob Rehof (TU-Dortmund)", "title": "Proceedings Seventh Workshop on Intersection Types and Related Systems", "comments": null, "journal-ref": "EPTCS 177, 2015", "doi": "10.4204/EPTCS.177", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a final and revised selection of papers presented at the\nSeventh Workshop on Intersection Types and Related Systems (ITRS 2014), held in\nVienna (Austria) on July 18th, affiliated with TLCA 2014, Typed Lambda Calculi\nand Applications (held jointly with RTA, Rewriting Techniques and Applications)\nas part of FLoC and the Vienna Summer of Logic (VSL) 2014. Intersection types\nhave been introduced in the late 1970s as a language for describing properties\nof lambda calculus which were not captured by all previous type systems. They\nprovided the first characterisation of strongly normalising lambda terms and\nhave become a powerful syntactic and semantic tool for analysing various\nnormalisation properties as well as lambda models. Over the years the scope of\nresearch on intersection types has broadened. Recently, there have been a\nnumber of breakthroughs in the use of intersection types and similar technology\nfor practical purposes such as program analysis, verification and concurrency,\nand program synthesis. The aim of the ITRS workshop series is to bring together\nresearchers working on both the theory and practical applications of systems\nbased on intersection types and related approaches (e.g., union types,\nrefinement types, behavioral types).\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2015 02:58:54 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Rehof", "Jakob", "", "TU-Dortmund"]]}, {"id": "1503.04522", "submitter": "Justin Hsu", "authors": "Arthur Azevedo de Amorim, Emilio Jes\\'us Gallego Arias, Marco\n  Gaboardi, Justin Hsu", "title": "Really Natural Linear Indexed Type Checking", "comments": null, "journal-ref": null, "doi": "10.1145/2746325.2746335", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown the power of linear indexed type systems for\nenforcing complex program properties. These systems combine linear types with a\nlanguage of type-level indices, allowing more fine-grained analyses. Such\nsystems have been fruitfully applied in diverse domains, including implicit\ncomplexity and differential privacy. A natural way to enhance the\nexpressiveness of this approach is by allowing the indices to depend on runtime\ninformation, in the spirit of dependent types. This approach is used in DFuzz,\na language for differential privacy. The DFuzz type system relies on an index\nlanguage supporting real and natural number arithmetic over constants and\nvariables. Moreover, DFuzz uses a subtyping mechanism to make types more\nflexible. By themselves, linearity, dependency, and subtyping each require\ndelicate handling when performing type checking or type inference; their\ncombination increases this challenge substantially, as the features can\ninteract in non-trivial ways. In this paper, we study the type-checking problem\nfor DFuzz. We show how we can reduce type checking for (a simple extension of)\nDFuzz to constraint solving over a first-order theory of naturals and real\nnumbers which, although undecidable, can often be handled in practice by\nstandard numeric solvers.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2015 04:45:58 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["de Amorim", "Arthur Azevedo", ""], ["Arias", "Emilio Jes\u00fas Gallego", ""], ["Gaboardi", "Marco", ""], ["Hsu", "Justin", ""]]}, {"id": "1503.04906", "submitter": "EPTCS", "authors": "Rick Statman (Carnegie Mellon University)", "title": "A Finite Model Property for Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 1-9", "doi": "10.4204/EPTCS.177.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the relational theory of intersection types known as BCD has the\nfinite model property; that is, BCD is complete for its finite models. Our\nproof uses rewriting techniques which have as an immediate by-product the\npolynomial time decidability of the preorder <= (although this also follows\nfrom the so called beta soundness of BCD).\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:58:23 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Statman", "Rick", "", "Carnegie Mellon University"]]}, {"id": "1503.04907", "submitter": "EPTCS", "authors": "Kentaro Kikuchi (RIEC, Tohoku University, Japan)", "title": "Uniform Proofs of Normalisation and Approximation for Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 10-23", "doi": "10.4204/EPTCS.177.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present intersection type systems in the style of sequent calculus,\nmodifying the systems that Valentini introduced to prove normalisation\nproperties without using the reducibility method. Our systems are more natural\nthan Valentini's ones and equivalent to the usual natural deduction style\nsystems. We prove the characterisation theorems of strong and weak\nnormalisation through the proposed systems, and, moreover, the approximation\ntheorem by means of direct inductive arguments. This provides in a uniform way\nproofs of the normalisation and approximation theorems via type systems in\nsequent calculus style.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:58:35 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Kikuchi", "Kentaro", "", "RIEC, Tohoku University, Japan"]]}, {"id": "1503.04909", "submitter": "EPTCS", "authors": "Charles Grellois (Laboratoires PPS and LIAFA, Universit\\'e Paris\n  Diderot), Paul-Andr\\'e Melli\\`es (Laboratoire PPS, CNRS and Universit\\'e\n  Paris Diderot)", "title": "Indexed linear logic and higher-order model checking", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 43-52", "doi": "10.4204/EPTCS.177.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, Kobayashi observed that the acceptance by an alternating tree\nautomaton A of an infinite tree T generated by a higher-order recursion scheme\nG may be formulated as the typability of the recursion scheme G in an\nappropriate intersection type system associated to the automaton A. The purpose\nof this article is to establish a clean connection between this line of work\nand Bucciarelli and Ehrhard's indexed linear logic. This is achieved in two\nsteps. First, we recast Kobayashi's result in an equivalent infinitary\nintersection type system where intersection is not idempotent anymore. Then, we\nshow that the resulting type system is a fragment of an infinitary version of\nBucciarelli and Ehrhard's indexed linear logic. While this work is very\npreliminary and does not integrate key ingredients of higher-order\nmodel-checking like priorities, it reveals an interesting and promising\nconnection between higher-order model-checking and linear logic.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:58:53 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Grellois", "Charles", "", "Laboratoires PPS and LIAFA, Universit\u00e9 Paris\n  Diderot"], ["Melli\u00e8s", "Paul-Andr\u00e9", "", "Laboratoire PPS, CNRS and Universit\u00e9\n  Paris Diderot"]]}, {"id": "1503.04910", "submitter": "EPTCS", "authors": "Mario Coppo (Universit\\`a di Torino), Mariangiola Dezani-Ciancaglini\n  (Universit\\`a di Torino), Ines Margaria (Universit\\`a di Torino), Maddalena\n  Zacchi (Universit\\`a di Torino)", "title": "On Isomorphism of \"Functional\" Intersection and Union Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 53-64", "doi": "10.4204/EPTCS.177.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type isomorphism is useful for retrieving library components, since a\nfunction in a library can have a type different from, but isomorphic to, the\none expected by the user. Moreover type isomorphism gives for free the coercion\nrequired to include the function in the user program with the right type. The\npresent paper faces the problem of type isomorphism in a system with\nintersection and union types. In the presence of intersection and union,\nisomorphism is not a congruence and cannot be characterised in an equational\nway. A characterisation can still be given, quite complicated by the\ninterference between functional and non functional types. This drawback is\nfaced in the paper by interpreting each atomic type as the set of functions\nmapping any argument into the interpretation of the type itself. This choice\nhas been suggested by the initial projection of Scott's inverse limit\nlambda-model. The main result of this paper is a condition assuring type\nisomorphism, based on an isomorphism preserving reduction.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:59:01 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Coppo", "Mario", "", "Universit\u00e0 di Torino"], ["Dezani-Ciancaglini", "Mariangiola", "", "Universit\u00e0 di Torino"], ["Margaria", "Ines", "", "Universit\u00e0 di Torino"], ["Zacchi", "Maddalena", "", "Universit\u00e0 di Torino"]]}, {"id": "1503.04911", "submitter": "EPTCS", "authors": "Jan Bessai (Technical University of Dortmund), Boris D\\\"udder\n  (Technical University of Dortmund), Andrej Dudenhefner (Technical University\n  of Dortmund), Tzu-Chun Chen (Technical University of Darmstadt), Ugo\n  de'Liguoro (University of Torino)", "title": "Typing Classes and Mixins with Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 79-93", "doi": "10.4204/EPTCS.177.7", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an assignment system of intersection types for a lambda-calculus\nwith records and a record-merge operator, where types are preserved both under\nsubject reduction and expansion. The calculus is expressive enough to naturally\nrepresent mixins as functions over recursively defined classes, whose fixed\npoints, the objects, are recursive records. In spite of the double recursion\nthat is involved in their definition, classes and mixins can be meaningfully\ntyped without resorting to neither recursive nor F-bounded polymorphic types.\n  We then adapt mixin construct and composition to Java and C#, relying solely\non existing features in such a way that the resulting code remains typable in\nthe respective type systems. We exhibit some example code, and study its\ntypings in the intersection type system via interpretation into the\nlambda-calculus with records we have proposed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:59:20 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Bessai", "Jan", "", "Technical University of Dortmund"], ["D\u00fcdder", "Boris", "", "Technical University of Dortmund"], ["Dudenhefner", "Andrej", "", "Technical University\n  of Dortmund"], ["Chen", "Tzu-Chun", "", "Technical University of Darmstadt"], ["de'Liguoro", "Ugo", "", "University of Torino"]]}, {"id": "1503.04913", "submitter": "EPTCS", "authors": "Nils J\\\"ahnig (TU Berlin), Thomas G\\\"othel (TU Berlin), Sabine Glesner\n  (TU Berlin)", "title": "A Denotational Semantics for Communicating Unstructured Code", "comments": "In Proceedings FESCA 2015, arXiv:1503.04378", "journal-ref": "EPTCS 178, 2015, pp. 9-21", "doi": "10.4204/EPTCS.178.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important property of programming language semantics is that they should\nbe compositional. However, unstructured low-level code contains goto-like\ncommands making it hard to define a semantics that is compositional. In this\npaper, we follow the ideas of Saabas and Uustalu to structure low-level code.\nThis gives us the possibility to define a compositional denotational semantics\nbased on least fixed points to allow for the use of inductive verification\nmethods. We capture the semantics of communication using finite traces similar\nto the denotations of CSP. In addition, we examine properties of this semantics\nand give an example that demonstrates reasoning about communication and jumps.\nWith this semantics, we lay the foundations for a proof calculus that captures\nboth, the semantics of unstructured low-level code and communication.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:59:45 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["J\u00e4hnig", "Nils", "", "TU Berlin"], ["G\u00f6thel", "Thomas", "", "TU Berlin"], ["Glesner", "Sabine", "", "TU Berlin"]]}, {"id": "1503.04917", "submitter": "EPTCS", "authors": "Vasileios Koutsoumpas (TUM)", "title": "A Formal Approach based on Fuzzy Logic for the Specification of\n  Component-Based Interactive Systems", "comments": "In Proceedings FESCA 2015, arXiv:1503.04378", "journal-ref": "EPTCS 178, 2015, pp. 62-76", "doi": "10.4204/EPTCS.178.6", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal methods are widely recognized as a powerful engineering method for the\nspecification, simulation, development, and verification of distributed\ninteractive systems. However, most formal methods rely on a two-valued logic,\nand are therefore limited to the axioms of that logic: a specification is valid\nor invalid, component behavior is realizable or not, safety properties hold or\nare violated, systems are available or unavailable. Especially when the problem\ndomain entails uncertainty, impreciseness, and vagueness, the appliance of such\nmethods becomes a challenging task. In order to overcome the limitations\nresulting from the strict modus operandi of formal methods, the main objective\nof this work is to relax the boolean notion of formal specifications by using\nfuzzy logic. The present approach is based on Focus theory, a model-based and\nstrictly formal method for componentbased interactive systems. The contribution\nof this work is twofold: i) we introduce a specification technique based on\nfuzzy logic which can be used on top of Focus to develop formal specifications\nin a qualitative fashion; ii) we partially extend Focus theory to a fuzzy one\nwhich allows the specification of fuzzy components and fuzzy interactions.\nWhile the former provides a methodology for approximating I/O behaviors under\nimprecision, the latter enables to capture a more quantitative view of\nspecification properties such as realizability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 04:00:31 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Koutsoumpas", "Vasileios", "", "TUM"]]}, {"id": "1503.04918", "submitter": "EPTCS", "authors": "Marcin Benke, Viviana Bono, Aleksy Schubert", "title": "Lucretia - intersection type polymorphism for scripting languages", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 65-78", "doi": "10.4204/EPTCS.177.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scripting code may present maintenance problems in the long run. There is,\nthen, the call for methodologies that make it possible to control the\nproperties of programs written in dynamic languages in an automatic fashion. We\nintroduce Lucretia, a core language with an introspection primitive. Lucretia\nis equipped with a (retrofitted) static type system based on local updates of\ntypes that describe the structure of objects being used. In this way, we deal\nwith one of the most dynamic features of scripting languages, that is, the\nruntime modification of object interfaces. Judgements in our systems have a\nHoare-like shape, as they have a precondition and a postcondition part.\nPreconditions describe static approximations of the interfaces of visible\nobjects before a certain expression has been executed and postconditions\ndescribe them after its execution. The field update operation complicates the\nissue of aliasing in the system. We cope with it by introducing intersection\ntypes in method signatures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 04:03:54 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Benke", "Marcin", ""], ["Bono", "Viviana", ""], ["Schubert", "Aleksy", ""]]}, {"id": "1503.04928", "submitter": "Ashutosh Trivedi", "authors": "Shankara Narayanan Krishna and Ashutosh Trivedi", "title": "Hybrid Automata for Formal Modeling and Verification of Cyber-Physical\n  Systems", "comments": "17 pages", "journal-ref": "Journal of Indian Institute of Science, Special Issue on Cyber\n  Physical Systems, vol. 93 (3), 2013", "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of a tight integration between the discrete control (the\n\"cyber\") and the analog environment (the \"physical\")---via sensors and\nactuators over wired or wireless communication networks---is the defining\nfeature of cyber-physical systems. Hence, the functional correctness of a\ncyber- physical system is crucially dependent not only on the dynamics of the\nanalog physical environment, but also on the decisions taken by the discrete\ncontrol that alter the dynamics of the environment. The framework of Hybrid\nautomata---introduced by Alur, Courcoubetis, Henzinger, and Ho---provides a\nformal modeling and specification environment to analyze the interaction\nbetween the discrete and continuous parts of a cyber-physical system. Hybrid\nautomata can be considered as generalizations of finite state automata\naugmented with a finite set of real-valued variables whose dynamics in each\nstate is governed by a system of ordinary differential equations. Moreover, the\ndiscrete transitions of hybrid automata are guarded by constraints over the\nvalues of these real-valued variables, and enable discontinuous jumps in the\nevolution of these variables. Considering the richness of the dynamics in a\nhybrid automaton, it is perhaps not surprising that the fundamental\nverification questions, like reachability and schedulability, for the general\nmodel are undecidable. In this article we present a review of hybrid automata\nas modeling and verification framework for cyber-physical systems, and survey\nsome of the key results related to practical verification questions related to\nhybrid automata.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 05:57:49 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Krishna", "Shankara Narayanan", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1503.04957", "submitter": "Andrea Burattin", "authors": "Andrea Burattin, Fabrizio Maria Maggi, Alessandro Sperduti", "title": "Conformance Checking Based on Multi-Perspective Declarative Process\n  Models", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2016.08.040", "report-no": null, "categories": "cs.SE cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining is a family of techniques that aim at analyzing business\nprocess execution data recorded in event logs. Conformance checking is a branch\nof this discipline embracing approaches for verifying whether the behavior of a\nprocess, as recorded in a log, is in line with some expected behaviors provided\nin the form of a process model. The majority of these approaches require the\ninput process model to be procedural (e.g., a Petri net). However, in turbulent\nenvironments, characterized by high variability, the process behavior is less\nstable and predictable. In these environments, procedural process models are\nless suitable to describe a business process. Declarative specifications,\nworking in an open world assumption, allow the modeler to express several\npossible execution paths as a compact set of constraints. Any process execution\nthat does not contradict these constraints is allowed. One of the open\nchallenges in the context of conformance checking with declarative models is\nthe capability of supporting multi-perspective specifications. In this paper,\nwe close this gap by providing a framework for conformance checking based on\nMP-Declare, a multi-perspective version of the declarative process modeling\nlanguage Declare. The approach has been implemented in the process mining tool\nProM and has been experimented in three real life case studies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 09:09:30 GMT"}], "update_date": "2016-08-19", "authors_parsed": [["Burattin", "Andrea", ""], ["Maggi", "Fabrizio Maria", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1503.04991", "submitter": "Luca Ferrari", "authors": "Luca Ferrari", "title": "Dyck algebras, interval temporal logic and posets of intervals", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a natural Heyting algebra structure on the set of Dyck paths\nof the same length. We provide a geometrical description of the operations of\npseudocomplement and relative pseudocomplement, as well as of regular elements.\nWe also find a logic-theoretic interpretation of such Heyting algebras, which\nwe call Dyck algebras, by showing that they are the algebraic counterpart of a\ncertain fragment of a classical interval temporal logic (also known as\nHalpern-Shoham logic). Finally, we propose a generalization of our approach,\nsuggesting a similar study of the Heyting algebra arising from the poset of\nintervals of a finite poset using Birkh\\\"off duality. In order to illustrate\nthis, we show how several combinatorial parameters of Dyck paths can be\nexpressed in terms of the Heyting algebra structure of Dyck algebras together\nwith a certain total order on the set of atoms of each Dyck algebra.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 10:54:47 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Ferrari", "Luca", ""]]}, {"id": "1503.05025", "submitter": "Mathieu Hoyrup", "authors": "Mathieu Hoyrup", "title": "A Rice-like theorem for primitive recursive functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an explicit characterization of the properties of primitive\nrecursive functions that are decidable or semi-decidable, given a primitive\nrecursive index for the function. The result is much more general as it applies\nto any c.e. class of total computable functions. This is an analog of Rice and\nRice-Shapiro theorem, for restricted classes of total computable functions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 12:56:59 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Hoyrup", "Mathieu", ""]]}, {"id": "1503.05124", "submitter": "Zoltan Esik", "authors": "Zoltan Esik", "title": "A representation theorem for stratified complete lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider complete lattices equipped with preorderings indexed by the\nordinals less than a given (limit) ordinal subject to certain axioms. These\nstructures, called stratified complete lattices, and weakly monotone functions\nover them, provide a framework for solving fixed point equations involving\nnon-monotone operations such as negation or complement, and have been used to\ngive semantics to logic programs with negation.\n  More precisely, we consider stratified complete lattices subject to two\nslightly different systems of axioms defining `models' and `strong models'. We\nprove that a stratified complete lattice is a model iff it is isomorphic to the\nstratified complete lattice determined by the limit of an inverse system of\ncomplete lattices with `locally completely additive' projections. Moreover, we\nprove that a stratified complete lattice is a strong model iff it is isomorphic\nto the stratified complete lattice determined by the limit of an inverse system\nof complete lattices with completely additive projections.\n  We use the inverse limit representation to give alternative proofs of some\nrecent results and to derive some new ones for models and strong models. In\nparticular, we use the representation theorem to prove that every model gives\nrise to another complete lattice structure, which in limit models corresponds\nto the lexicographic order. Moreover, we prove that the set of all fixed points\nof a weakly monotone function over a model, equipped with the new ordering, is\na complete lattice. We also consider symmetric models that satisfy, together\nwith each axiom, the dual axiom, and use the inverse limit representation to\nprove that every strong model is symmetric.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 17:05:37 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2015 17:10:02 GMT"}, {"version": "v3", "created": "Thu, 3 Mar 2016 18:28:10 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Esik", "Zoltan", ""]]}, {"id": "1503.05423", "submitter": "Wied Pakusa", "authors": "Erich Gr\\\"adel and Wied Pakusa", "title": "Rank logic is dead, long live rank logic!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the search for a logic for polynomial time, we study rank logic\n(FPR) which extends fixed-point logic with counting (FPC) by operators that\ndetermine the rank of matrices over finite fields. While FPR can express most\nof the known queries that separate FPC from PTIME, nearly nothing was known\nabout the limitations of its expressive power.\n  In our first main result we show that the extensions of FPC by rank operators\nover different prime fields are incomparable. This solves an open question\nposed by Dawar and Holm and also implies that rank logic, in its original\ndefinition with a distinct rank operator for every field, fails to capture\npolynomial time. In particular we show that the variant of rank logic FPR* with\nan operator that uniformly expresses the matrix rank over finite fields is more\nexpressive than FPR.\n  One important step in our proof is to consider solvability logic FPS which is\nthe analogous extension of FPC by quantifiers which express the solvability\nproblem for linear equation systems over finite fields. Solvability logic can\neasily be embedded into rank logic, but it is open whether it is a strict\nfragment. In our second main result we give a partial answer to this question:\nin the absence of counting, rank operators are strictly more expressive than\nsolvability quantifiers.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 14:18:03 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Gr\u00e4del", "Erich", ""], ["Pakusa", "Wied", ""]]}, {"id": "1503.05496", "submitter": "Burak Ekici", "authors": "Burak Ekici (CASYS)", "title": "IMP with exceptions over decorated logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we facilitate the reasoning about impure programming\nlanguages, by annotating terms with `decorations' that describe what\ncomputational (side) effect evaluation of a term may involve. In a point-free\ncategorical language,called the `decorated logic', we formalize the mutable\nstate and the exception effects first separately, exploiting anice duality\nbetween them, and then combined. The combined decorated logic is used as the\ntarget language forthe denotational semantics of the IMP+Exc imperative\nprogramming language, and allows us to prove equivalencesbetween programs\nwritten in IMP+Exc. The combined logic is encoded in Coq, and this encoding is\nused to certifysome program equivalence proofs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 17:20:52 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 13:54:16 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 08:40:43 GMT"}, {"version": "v4", "created": "Tue, 11 Apr 2017 07:42:36 GMT"}, {"version": "v5", "created": "Fri, 14 Apr 2017 14:39:56 GMT"}, {"version": "v6", "created": "Tue, 18 Apr 2017 13:00:13 GMT"}, {"version": "v7", "created": "Fri, 23 Feb 2018 12:31:50 GMT"}, {"version": "v8", "created": "Thu, 20 Sep 2018 09:23:46 GMT"}, {"version": "v9", "created": "Tue, 16 Oct 2018 09:41:34 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Ekici", "Burak", "", "CASYS"]]}, {"id": "1503.05847", "submitter": "Abhishek Bose-Kolanu", "authors": "Abhishek Bose-Kolanu", "title": "Hypercomputation, Frege, Deleuze: Solving Thomson's Lamp", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first known solution to the original supertask, the Thomson\nLamp Paradox.\n  We also offer preliminary resources for classifying computational complexity\nof various supertasks. In so doing we consider a newly apparent paradox between\nthe metrical limit and the ordinal limit. We use this distinction between the\nmetrical and ordinal limits to explain the shortcomings both of Thomson's\noriginal formulation of the Lamp Paradox and Benacerraf's consequent critique.\n  We resolve this paradox through a careful consideration of transfinite\nordinals and locate its ambiguity as inherent to the identity relation under\nlogic with a close reading of Frege's Begriffsschrift. With this close reading\nin hand we expose how the identity relation is counter-intuitively polyvalent\nand, with supertasks, how the logico-mathematical field operates on the basis\nof Deleuzian point-folds. Our results combine resources from philosophy,\nmathematics, and computer science to ground the field of hypercomputation for\nlogically rigorous study.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 17:20:09 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bose-Kolanu", "Abhishek", ""]]}, {"id": "1503.05857", "submitter": "William Zeng", "authors": "William Zeng", "title": "Models of Quantum Algorithms in Sets and Relations", "comments": "fixed classical relation errors, and clarified terminology/defns", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT math.QA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct abstract models of blackbox quantum algorithms using a model of\nquantum computation in sets and relations, a setting that is usually considered\nfor nondeterministic classical computation. This alternative model of quantum\ncomputation (QCRel), though unphysical, nevertheless faithfully models its\ncomputational structure. Our main results are models of the Deutsch-Jozsa,\nsingle-shot Grovers, and GroupHomID algorithms in QCRel. These results provide\nnew tools to analyze the semantics of quantum computation and improve our\nunderstanding of the relationship between computational speedups and the\nstructure of physical theories. They also exemplify a method of extending\nphysical/computational intuition into new mathematical settings.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 17:57:30 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2015 18:54:31 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2015 13:32:10 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Zeng", "William", ""]]}, {"id": "1503.06022", "submitter": "Russell Harmer", "authors": "Vincent Danos (University of Edinburgh), Russell Harmer (CNRS & ENS\n  Lyon), Ricardo Honorato-Zimmer (University of Edinburgh)", "title": "Thermodynamic graph-rewriting", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (June 24,\n  2015) lmcs:1573", "doi": "10.2168/LMCS-11(2:13)2015", "report-no": null, "categories": "cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new thermodynamic approach to stochastic graph-rewriting. The\ningredients are a finite set of reversible graph-rewriting rules called\ngenerating rules, a finite set of connected graphs P called energy patterns and\nan energy cost function. The idea is that the generators define the qualitative\ndynamics, by showing which transformations are possible, while the energy\npatterns and cost function specify the long-term probability $\\pi$ of any\nreachable graph. Given the generators and energy patterns, we construct a\nfinite set of rules which (i) has the same qualitative transition system as the\ngenerators; and (ii) when equipped with suitable rates, defines a\ncontinuous-time Markov chain of which $\\pi$ is the unique fixed point. The\nconstruction relies on the use of site graphs and a technique of `growth\npolicy' for quantitative rule refinement which is of independent interest. This\ndivision of labour between the qualitative and long-term quantitative aspects\nof the dynamics leads to intuitive and concise descriptions for realistic\nmodels (see the examples in S4 and S5). It also guarantees thermodynamical\nconsistency (AKA detailed balance), otherwise known to be undecidable, which is\nimportant for some applications. Finally, it leads to parsimonious\nparameterizations of models, again an important point in some applications.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 09:20:05 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 16:24:55 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Danos", "Vincent", "", "University of Edinburgh"], ["Harmer", "Russell", "", "CNRS & ENS\n  Lyon"], ["Honorato-Zimmer", "Ricardo", "", "University of Edinburgh"]]}, {"id": "1503.06072", "submitter": "Jules Hedges", "authors": "Jules Hedges", "title": "String diagrams for game theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a monoidal category whose morphisms are games (in the\nsense of game theory, not game semantics) and an associated diagrammatic\nlanguage. The two basic operations of a monoidal category, namely categorical\ncomposition and tensor product, correspond roughly to sequential and\nsimultaneous composition of games. This leads to a compositional theory in\nwhich we can reason about properties of games in terms of corresponding\nproperties of the component parts. In particular, we give a definition of Nash\nequilibrium which is recursive on the causal structure of the game.\n  The key technical idea in this paper is the use of continuation passing style\nfor reasoning about the future consequences of players' choices, closely based\non applications of selection functions in game theory. Additionally, the clean\ncategorical foundation gives many opportunities for generalisation, for example\nto learning agents.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 13:50:05 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Hedges", "Jules", ""]]}, {"id": "1503.06095", "submitter": "Amy Felty", "authors": "Amy P. Felty, Alberto Momigliano and Brigitte Pientka", "title": "The Next 700 Challenge Problems for Reasoning with Higher-Order Abstract\n  Syntax Representations: Part 1-A Common Infrastructure for Benchmarks", "comments": "42 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of logical frameworks support the use of higher-order abstract\nsyntax (HOAS) in representing formal systems. Although these systems seem\nsuperficially the same, they differ in a variety of ways; for example, how they\nhandle a context of assumptions and which theorems about a given formal system\ncan be concisely expressed and proved. Our contributions in this paper are\nthree-fold: 1) we develop a common infrastructure for representing benchmarks\nfor systems supporting reasoning with binders, 2) we present several concrete\nbenchmarks, which highlight a variety of different aspects of reasoning within\na context of assumptions, and 3) we design an open repository ORBI, (Open\nchallenge problem Repository for systems supporting reasoning with BInders).\nOur work sets the stage for providing a basis for qualitative comparison of\ndifferent systems. This allows us to review and survey the state of the art,\nwhich we do in great detail for four systems in Part 2 of this paper (Felty et\nal, 2015). It also allows us to outline future fundamental research questions\nregarding the design and implementation of meta-reasoning systems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 14:54:15 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Felty", "Amy P.", ""], ["Momigliano", "Alberto", ""], ["Pientka", "Brigitte", ""]]}, {"id": "1503.06480", "submitter": "Md Ariful Islam", "authors": "Md. Ariful Islam, Richard DeFrancisco, Chuchu Fan, Radu Grosu, Sayan\n  Mitra, Scott A. Smolka", "title": "Model Checking Tap Withdrawal in C. Elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CE cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present what we believe to be the first formal verification of a\nbiologically realistic (nonlinear ODE) model of a neural circuit in a\nmulticellular organism: Tap Withdrawal (TW) in \\emph{C. Elegans}, the common\nroundworm. TW is a reflexive behavior exhibited by \\emph{C. Elegans} in\nresponse to vibrating the surface on which it is moving; the neural circuit\nunderlying this response is the subject of this investigation. Specifically, we\nperform reachability analysis on the TW circuit model of Wicks et al. (1996),\nwhich enables us to estimate key circuit parameters. Underlying our approach is\nthe use of Fan and Mitra's recently developed technique for automatically\ncomputing local discrepancy (convergence and divergence rates) of general\nnonlinear systems. We show that the results we obtain are in agreement with the\nexperimental results of Wicks et al. (1995). As opposed to the fixed parameters\nfound in most biological models, which can only produce the predominant\nbehavior, our techniques characterize ranges of parameters that produce (and do\nnot produce) all three observed behaviors: reversal of movement, acceleration,\nand lack of response.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2015 21:12:42 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Islam", "Md. Ariful", ""], ["DeFrancisco", "Richard", ""], ["Fan", "Chuchu", ""], ["Grosu", "Radu", ""], ["Mitra", "Sayan", ""], ["Smolka", "Scott A.", ""]]}, {"id": "1503.06514", "submitter": "Haoxiang Lin", "authors": "Haoxiang Lin", "title": "On the Well Extension of Partial Well Orderings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the well extension of strict(irreflective) partial\nwell orderings. We first prove that any partially well-ordered structure <A, R>\ncan be extended to a well-ordered one. Then we prove that every linear\nextension of <A, R> is well-ordered if and only if A has no infinite totally\nunordered subset under R.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 02:58:46 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2015 09:47:04 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2015 01:46:04 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2015 11:29:19 GMT"}, {"version": "v5", "created": "Thu, 21 May 2015 12:23:13 GMT"}, {"version": "v6", "created": "Mon, 27 Jul 2015 10:35:47 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Lin", "Haoxiang", ""]]}, {"id": "1503.06647", "submitter": "Lili Shen", "authors": "Lili Shen, Yuanye Tao, Dexue Zhang", "title": "Chu connections and back diagonals between $\\mathcal{Q}$-distributors", "comments": "39 pages, final version. License updated", "journal-ref": "Journal of Pure and Applied Algebra, 220(5):1858-1901, 2016", "doi": "10.1016/j.jpaa.2015.10.005", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chu connections and back diagonals are introduced as morphisms for\ndistributors between categories enriched in a small quantaloid $\\mathcal{Q}$.\nThese notions, meaningful for closed bicategories, dualize the constructions of\narrow categories and the Freyd completion of categories. It is shown that, for\na small quantaloid $\\mathcal{Q}$, the category of complete\n$\\mathcal{Q}$-categories and left adjoints is a retract of the dual of the\ncategory of $\\mathcal{Q}$-distributors and Chu connections, and it is dually\nequivalent to the category of $\\mathcal{Q}$-distributors and back diagonals. As\nan application of Chu connections, a postulation of the intuitive idea of\nreduction of formal contexts in the theory of formal concept analysis is\npresented, and a characterization of reducts of formal contexts is obtained.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 14:13:51 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2015 18:31:24 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2015 12:46:07 GMT"}, {"version": "v4", "created": "Fri, 1 Jan 2016 15:48:56 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Shen", "Lili", ""], ["Tao", "Yuanye", ""], ["Zhang", "Dexue", ""]]}, {"id": "1503.06687", "submitter": "Andrew M Marshall", "authors": "Andrew M Marshall (The University of Mary Washington), Catherine\n  Meadows (U.S. Naval Research Laboratory), Paliath Narendran (University at\n  Albany, SUNY)", "title": "On Unification Modulo One-Sided Distributivity: Algorithms, Variants and\n  Asymmetry", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (June 19,\n  2015) lmcs:1571", "doi": "10.2168/LMCS-11(2:11)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for unification modulo one-sided distributivity is an early\nresult by Tid\\'en and Arnborg. More recently this theory has been of interest\nin cryptographic protocol analysis due to the fact that many cryptographic\noperators satisfy this property. Unfortunately the algorithm presented in the\npaper, although correct, has recently been shown not to be polynomial time\nbounded as claimed. In addition, for some instances, there exist most general\nunifiers that are exponentially large with respect to the input size. In this\npaper we first present a new polynomial time algorithm that solves the decision\nproblem for a non-trivial subcase, based on a typed theory, of unification\nmodulo one-sided distributivity. Next we present a new polynomial algorithm\nthat solves the decision problem for unification modulo one-sided\ndistributivity. A construction, employing string compression, is used to\nachieve the polynomial bound. Lastly, we examine the one-sided distributivity\nproblem in the new asymmetric unification paradigm. We give the first\nasymmetric unification algorithm for one-sided distributivity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 15:28:19 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 18:16:24 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Marshall", "Andrew M", "", "The University of Mary Washington"], ["Meadows", "Catherine", "", "U.S. Naval Research Laboratory"], ["Narendran", "Paliath", "", "University at\n  Albany, SUNY"]]}, {"id": "1503.06826", "submitter": "Nicolas Markey", "authors": "Patricia Bouyer (LSV -- ENS Cachan & CNRS), Romain Brenguier (LSV --\n  ENS Cachan & CNRS), Nicolas Markey (LSV -- ENS Cachan & CNRS), Michael Ummels\n  (TU Dresden)", "title": "Pure Nash Equilibria in Concurrent Deterministic Games", "comments": "72 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 2 (June 19,\n  2015) lmcs:1569", "doi": "10.2168/LMCS-11(2:9)2015", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pure-strategy Nash equilibria in multi-player concurrent\ndeterministic games, for a variety of preference relations. We provide a novel\nconstruction, called the suspect game, which transforms a multi-player\nconcurrent game into a two-player turn-based game which turns Nash equilibria\ninto winning strategies (for some objective that depends on the preference\nrelations of the players in the original game). We use that transformation to\ndesign algorithms for computing Nash equilibria in finite games, which in most\ncases have optimal worst-case complexity, for large classes of preference\nrelations. This includes the purely qualitative framework, where each player\nhas a single omega-regular objective that she wants to satisfy, but also the\nlarger class of semi-quantitative objectives, where each player has several\nomega-regular objectives equipped with a preorder (for instance, a player may\nwant to satisfy all her objectives, or to maximise the number of objectives\nthat she achieves.)\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 20:39:20 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 04:38:37 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Bouyer", "Patricia", "", "LSV -- ENS Cachan & CNRS"], ["Brenguier", "Romain", "", "LSV --\n  ENS Cachan & CNRS"], ["Markey", "Nicolas", "", "LSV -- ENS Cachan & CNRS"], ["Ummels", "Michael", "", "TU Dresden"]]}, {"id": "1503.07025", "submitter": "Pierre-Loic Garoche", "authors": "Assal\\'e Adj\\'e (Toulouse), Pierre-Lo\\\"ic Garoche (Toulouse), Victor\n  Magron", "title": "Property-based Polynomial Invariant Generation using Sums-of-Squares\n  Optimization", "comments": "arXiv admin note: substantial text overlap with arXiv:1409.3941", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While abstract interpretation is not theoretically restricted to specific\nkinds of properties, it is, in practice, mainly developed to compute linear\nover-approximations of reachable sets, aka. the collecting semantics of the\nprogram. The verification of user-provided properties is not easily compatible\nwith the usual forward fixpoint computation using numerical abstract domains.\nWe propose here to rely on sums-of-squares programming to characterize a\nproperty-driven polynomial invariant. This invariant generation can be guided\nby either boundedness, or in contrary, a given zone of the state space to\navoid. While the target property is not necessarily inductive with respect to\nthe program semantics, our method identifies a stronger inductive polynomial\ninvariant using numerical optimization. Our method applies to a wide set of\nprograms: a main while loop composed of a disjunction (if-then-else) of\npolynomial updates e.g. piecewise polynomial controllers. It has been evaluated\non various programs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 13:25:48 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Adj\u00e9", "Assal\u00e9", "", "Toulouse"], ["Garoche", "Pierre-Lo\u00efc", "", "Toulouse"], ["Magron", "Victor", ""]]}, {"id": "1503.07139", "submitter": "Anne-Kathrin Schmuck", "authors": "Anne-Kathrin Schmuck, Paulo Tabuada, J\\\"org Raisch", "title": "Comparing Asynchronous $l$-Complete Approximations and Quotient Based\n  Abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with a detailed comparison of two different\nabstraction techniques for the construction of finite state symbolic models for\ncontroller synthesis of hybrid systems. Namely, we compare quotient based\nabstractions (QBA), with different realizations of strongest (asynchronous)\n$l$-complete approximations (SAlCA) Even though the idea behind their\nconstruction is very similar, we show that they are generally incomparable both\nin terms of behavioral inclusion and similarity relations. We therefore derive\nnecessary and sufficient conditions for QBA to coincide with particular\nrealizations of SAlCA. Depending on the original system, either QBA or SAlCA\ncan be a tighter abstraction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 18:53:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 14:20:04 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Schmuck", "Anne-Kathrin", ""], ["Tabuada", "Paulo", ""], ["Raisch", "J\u00f6rg", ""]]}, {"id": "1503.07717", "submitter": "Claire Lef\\`evre", "authors": "Claire Lef\\`evre, Christopher B\\'eatrix, Igor St\\'ephan, Laurent\n  Garcia", "title": "ASPeRiX, a First Order Forward Chaining Approach for Answer Set\n  Computing", "comments": "50 pages. To appear in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural way to use Answer Set Programming (ASP) to represent knowledge in\nArtificial Intelligence or to solve a combinatorial problem is to elaborate a\nfirst order logic program with default negation. In a preliminary step this\nprogram with variables is translated in an equivalent propositional one by a\nfirst tool: the grounder. Then, the propositional program is given to a second\ntool: the solver. This last one computes (if they exist) one or many answer\nsets (stable models) of the program, each answer set encoding one solution of\nthe initial problem. Until today, almost all ASP systems apply this two steps\ncomputation. In this article, the project ASPeRiX is presented as a first order\nforward chaining approach for Answer Set Computing. This project was amongst\nthe first to introduce an approach of answer set computing that escapes the\npreliminary phase of rule instantiation by integrating it in the search\nprocess. The methodology applies a forward chaining of first order rules that\nare grounded on the fly by means of previously produced atoms. Theoretical\nfoundations of the approach are presented, the main algorithms of the ASP\nsolver ASPeRiX are detailed and some experiments and comparisons with existing\nsystems are provided.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 12:57:22 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 15:08:22 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lef\u00e8vre", "Claire", ""], ["B\u00e9atrix", "Christopher", ""], ["St\u00e9phan", "Igor", ""], ["Garcia", "Laurent", ""]]}, {"id": "1503.08090", "submitter": "Assal\\'e Adj\\'e", "authors": "Assal\\'e Adj\\'e and Pierre-Lo\\\"ic Garoche and Victor Magron", "title": "A Sums-of-Squares Extension of Policy Iterations", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to address the imprecision often introduced by widening operators in\nstatic analysis, policy iteration based on min-computations amounts to\nconsidering the characterization of reachable value set of a program as an\niterative computation of policies, starting from a post-fixpoint. Computing\neach policy and the associated invariant relies on a sequence of numerical\noptimizations. While the early research efforts relied on linear programming\n(LP) to address linear properties of linear programs, the current state of the\nart is still limited to the analysis of linear programs with at most quadratic\ninvariants, relying on semidefinite programming (SDP) solvers to compute\npolicies, and LP solvers to refine invariants.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) based optimization. Our approach enables the precise\nanalysis of switched systems with polynomial updates and guards. The analysis\npresented has been implemented in Matlab and applied on existing programs\ncoming from the system control literature, improving both the range of\nanalyzable systems and the precision of previously handled ones.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 14:26:54 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 08:31:19 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2016 09:35:45 GMT"}, {"version": "v4", "created": "Tue, 6 Dec 2016 16:38:31 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Adj\u00e9", "Assal\u00e9", ""], ["Garoche", "Pierre-Lo\u00efc", ""], ["Magron", "Victor", ""]]}, {"id": "1503.08141", "submitter": "Bryan Renne", "authors": "Alexandru Baltag, Bryan Renne, Sonja Smets", "title": "Revisable Justified Belief: Preliminary Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory $\\mathsf{CDL}$ of Conditional Doxastic Logic is the single-agent\nversion of Board's multi-agent theory $\\mathsf{BRSIC}$ of conditional belief.\n$\\mathsf{CDL}$ may be viewed as a version of AGM belief revision theory in\nwhich Boolean combinations of revisions are expressible in the language. We\nintroduce a theory $\\mathsf{JCDL}$ of Justified Conditional Doxastic Logic that\nreplaces conditional belief formulas $B^\\psi\\varphi$ by expressions\n$t{\\,:^{\\psi}}\\varphi$ made up of a term $t$ whose syntactic structure suggests\na derivation of the belief $\\varphi$ after revision by $\\psi$. This allows us\nto think of terms $t$ as reasons justifying a belief in various formulas after\na revision takes place. We show that $\\mathsf{JCDL}$-theorems are the exact\nanalogs of $\\mathsf{CDL}$-theorems, and that this result holds the other way\naround as well. This allows us to think of $\\mathsf{JCDL}$ as a theory of\nrevisable justified belief.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 16:46:04 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Baltag", "Alexandru", ""], ["Renne", "Bryan", ""], ["Smets", "Sonja", ""]]}, {"id": "1503.08454", "submitter": "Joao Marques-Silva", "authors": "M. Fareed Arif, Joao Marques-Silva", "title": "Towards Efficient Axiom Pinpointing of EL+ Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EL family of Description Logics (DLs) has been the subject of interest in\nrecent years. On the one hand, these DLs are tractable, but fairly\ninexpressive. On the other hand, these DLs can be used for designing different\nclasses of ontologies, most notably ontologies from the medical domain.\nUnfortunately, building ontologies is error-prone. As a result, inferable\nsubsumption relations among concepts may be unintended. In recent years, the\nproblem of axiom pinpointing has been studied with the purpose of providing\nminimal sets of axioms that explain unintended subsumption relations. For the\nconcrete case of EL and EL+, the most efficient approaches consist of encoding\nthe problem into propositional logic, specifically as a Horn formula, which is\nthen analyzed with a dedicated algorithm. This paper builds on this earlier\nwork, but exploits the important relationship between minimal axioms sets and\nminimal unsatisfiable subformulas in the propositional domain. In turn, this\nrelationship allows applying a vast body of recent work in the propositional\ndomain to the concrete case of axiom pinpointing for EL and its variants. From\na practical perspective, the algorithms described in this paper are often\nseveral orders of magnitude more efficient that the current state of the art in\naxiom pinpointing for the EL family of DLs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2015 16:15:34 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Arif", "M. Fareed", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1503.08551", "submitter": "David Cerna", "authors": "David Cerna and Alexander Leitsch", "title": "Analysis of Clause set Schema Aided by Automated Theorem Proving: A Case\n  Study [Extended Paper]", "comments": "Submitted to Cade 2015. if published, will be published without\n  appendix. Full paper, as provided here, is 23 pages. Published will be 15\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The schematic CERES method [8] is a recently developed method of cut\nelimination for proof schemata, that is a sequence of proofs with a recursive\nconstruction. Proof schemata can be thought of as a way to circumvent adding an\ninduction rule to the LK-calculus. In this work, we formalize a schematic\nversion of the infinitary pigeonhole principle, which we call the\nNon-injectivity Assertion schema (NiA-schema), in the LKS-calculus [8], and\nanalyse the clause set schema extracted from the NiA-schema using some of the\nstructure provided by the schematic CERES method. To the best of our knowledge,\nthis is the first appli- cation of the constructs built for proof analysis of\nproof schemata to a mathematical argument since its publication. We discuss the\nrole of Automated Theorem Proving (ATP) in schematic proof analysis, as well as\nthe shortcomings of the schematic CERES method concerning the formalization of\nthe NiA-schema, namely, the expressive power of the schematic resolution\ncalculus. We conclude with a discussion concerning the usage of ATP in\nschematic proof analysis.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 06:31:25 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Cerna", "David", ""], ["Leitsch", "Alexander", ""]]}, {"id": "1503.08744", "submitter": "Floris van Doorn", "authors": "Floris van Doorn", "title": "Propositional Calculus in Coq", "comments": "11 pages, project for 2014 Proof Theory class at CMU. Added ancillary\n  files (Coq source files) in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  I formalize important theorems about classical propositional logic in the\nproof assistant Coq. The main theorems I prove are (1) the soundness and\ncompleteness of natural deduction calculus, (2) the equivalence between natural\ndeduction calculus, Hilbert systems and sequent calculus and (3) cut\nelimination for sequent calculus.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 17:07:58 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2015 19:34:20 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["van Doorn", "Floris", ""]]}, {"id": "1503.08761", "submitter": "Prof. Dr. Vladimir Rybakov Mr", "authors": "Vladimir Rybakov", "title": "Intransitive Linear Temporal Logic, Knowledge from Past, Decidability,\n  Admissible Rules", "comments": "arXiv admin note: text overlap with arXiv:1406.2783", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our manuscript studies linear temporal (with UNTIL and NEXT) logic based at a\nconception of intransitive time. non-transitive time. In particular, we\ndemonstrate how the notion of knowledge might be represented in such a\nframework (here we consider logical operation NN and the operation UNTIL\n(actually, the time overall) to be directed to past). The basic mathematical\nproblems we study are the fundamental ones for any logical system\n  - decidability and decidability w.r.t. admissible rules. First, we consider\nthe logic with non-uniform non-transitivity, and describe how to solve the\ndecidability problem for this logic. Then we consider a modification of this\nlogic - linear temporal logic with uniform intransitivity and solve the problem\nof admissibility for inference rules. A series of open problems is enumerated\nin the concluding part of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 17:43:52 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Rybakov", "Vladimir", ""]]}, {"id": "1503.08792", "submitter": "Pascal Schweitzer", "authors": "Sandra Kiefer, Pascal Schweitzer and Erkal Selman", "title": "Graphs Identified by Logics with Counting", "comments": "33 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify graphs and, more generally, finite relational structures that are\nidentified by C2, that is, two-variable first-order logic with counting. Using\nthis classification, we show that it can be decided in almost linear time\nwhether a structure is identified by C2. Our classification implies that for\nevery graph identified by this logic, all vertex-colored versions of it are\nalso identified. A similar statement is true for finite relational structures.\n  We provide constructions that solve the inversion problem for finite\nstructures in linear time. This problem has previously been shown to be\npolynomial time solvable by Martin Otto. For graphs, we conclude that every\nC2-equivalence class contains a graph whose orbits are exactly the classes of\nthe C2-partition of its vertex set and which has a single automorphism\nwitnessing this fact.\n  For general k, we show that such statements are not true by providing\nexamples of graphs of size linear in k which are identified by C3 but for which\nthe orbit partition is strictly finer than the Ck-partition. We also provide\nidentified graphs which have vertex-colored versions that are not identified by\nCk.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 18:56:51 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Kiefer", "Sandra", ""], ["Schweitzer", "Pascal", ""], ["Selman", "Erkal", ""]]}, {"id": "1503.08925", "submitter": "Masahiro Hamano", "authors": "Masahiro Hamano", "title": "Geometry of Interaction for MALL via Hughes-vanGlabbeek Proof-Nets", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents, for the first time, a Geometry of Interaction (GoI)\ninterpretation inspired from Hughes-vanGlabbeek (HvG) proof-nets for\nmultiplicative additive linear logic (MALL). Our GoI dynamically captures HvG's\ngeometric correctness criterion-the toggling cycle condition-in terms of\nalgebraic operators. Our new ingredient is a scalar extension of the *-algebra\nin Girard's *-ring of partial isometries over a boolean polynomial ring with\nliterals of eigenweights as indeterminates. In order to capture feedback\narising from cuts, we construct a finer grained execution formula. The\nexpansion of this execution formula is longer than that for collections of\nslices for multiplicative GoI, hence it is harder to prove termination. Our GoI\ngives a dynamical, semantical account of boolean valuations (in particular,\npruning sub-proofs), conversion of weights (in particular, alpha-conversion),\nand additive (co)contraction, peculiar to additive proof-theory. Termination of\nour execution formula is shown to correspond to HvG's toggling criterion. The\nslice-wise restriction of our execution formula (by collapsing the boolean\nstructure) yields the well known correspondence, explicit or implicit in\nprevious works on multiplicative GoI, between the convergence of execution\nformulas and acyclicity of proof-nets. Feedback arising from the execution\nformula by restricting to the boolean polynomial structure yields autonomous\ndefinability of eigenweights among cuts from the rest of the eigenweights.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 06:13:06 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 02:14:01 GMT"}, {"version": "v3", "created": "Sun, 25 Feb 2018 07:41:21 GMT"}, {"version": "v4", "created": "Sun, 8 Jul 2018 04:23:18 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Hamano", "Masahiro", ""]]}, {"id": "1503.08936", "submitter": "Samuel J. Van Gool", "authors": "Silvio Ghilardi and Samuel J. van Gool", "title": "A model-theoretic characterization of monadic second order logic on\n  infinite words", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monadic second order logic and linear temporal logic are two logical\nformalisms that can be used to describe classes of infinite words, i.e.,\nfirst-order models based on the natural numbers with order, successor, and\nfinitely many unary predicate symbols.\n  Monadic second order logic over infinite words (S1S) can alternatively be\ndescribed as a first-order logic interpreted in $\\mathcal{P}(\\omega)$, the\npower set Boolean algebra of the natural numbers, equipped with modal operators\nfor 'initial', 'next' and 'future' states. We prove that the first-order theory\nof this structure is the model companion of a class of algebras corresponding\nto the appropriate version of linear temporal logic (LTL) without until.\n  The proof makes crucial use of two classical, non-trivial results from the\nliterature, namely the completeness of LTL with respect to the natural numbers,\nand the correspondence between S1S-formulas and B\\\"uchi automata.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 07:22:11 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 14:10:34 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Ghilardi", "Silvio", ""], ["van Gool", "Samuel J.", ""]]}, {"id": "1503.09025", "submitter": "Jos\\'e L Balc\\'azar", "authors": "Marta Arias, Jos\\'e L. Balc\\'azar, Cristina T\\^irn\\u{a}uc\\u{a}", "title": "Learning Definite Horn Formulas from Closure Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A definite Horn theory is a set of n-dimensional Boolean vectors whose\ncharacteristic function is expressible as a definite Horn formula, that is, as\nconjunction of definite Horn clauses. The class of definite Horn theories is\nknown to be learnable under different query learning settings, such as learning\nfrom membership and equivalence queries or learning from entailment. We propose\nyet a different type of query: the closure query. Closure queries are a natural\nextension of membership queries and also a variant, appropriate in the context\nof definite Horn formulas, of the so-called correction queries. We present an\nalgorithm that learns conjunctions of definite Horn clauses in polynomial time,\nusing closure and equivalence queries, and show how it relates to the canonical\nGuigues-Duquenne basis for implicational systems. We also show how the\ndifferent query models mentioned relate to each other by either showing\nfull-fledged reductions by means of query simulation (where possible), or by\nshowing their connections in the context of particular algorithms that use them\nfor learning definite Horn formulas.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 12:41:01 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 09:27:43 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2015 12:02:25 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Arias", "Marta", ""], ["Balc\u00e1zar", "Jos\u00e9 L.", ""], ["T\u00eern\u0103uc\u0103", "Cristina", ""]]}, {"id": "1503.09060", "submitter": "Raul Rojas Prof.", "authors": "Raul Rojas", "title": "A Tutorial Introduction to the Lambda Calculus", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a concise and painless introduction to the $\\lambda$-calculus.\nThis formalism was developed by Alonzo Church as a tool for studying the\nmathematical properties of effectively computable functions. The formalism\nbecame popular and has provided a strong theoretical foundation for the family\nof functional programming languages. This tutorial shows how to perform\narithmetical and logical computations using the $\\lambda$-calculus and how to\ndefine recursive functions, even though $\\lambda$-calculus functions are\nunnamed and thus cannot refer explicitly to themselves.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2015 00:38:33 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Rojas", "Raul", ""]]}]