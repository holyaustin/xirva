[{"id": "2010.00168", "submitter": "Helio Henrique Monte-Alto", "authors": "Helio H. L. C. Monte-Alto, Mariela Morveli-Espinoza, Cesar A. Tacla", "title": "Multi-Agent Systems based on Contextual Defeasible Logic considering\n  Focus", "comments": "11 pages, 3 figures, paper was accepted for conference ICAART 2020:\n  12th International Conference on Agents and Artificial Intelligence, but was\n  withdrew", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend previous work on distributed reasoning using\nContextual Defeasible Logic (CDL), which enables decentralised distributed\nreasoning based on a distributed knowledge base, such that the knowledge from\ndifferent knowledge bases may conflict with each other. However, there are many\nuse case scenarios that are not possible to represent in this model. One kind\nof such scenarios are the ones that require that agents share and reason with\nrelevant knowledge when issuing a query to others. Another kind of scenarios\nare those in which the bindings among the agents (defined by means of mapping\nrules) are not static, such as in knowledge-intensive and dynamic environments.\nThis work presents a multi-agent model based on CDL that not only allows agents\nto reason with their local knowledge bases and mapping rules, but also allows\nagents to reason about relevant knowledge (focus) -- which are not known by the\nagents a priori -- in the context of a specific query. We present a use case\nscenario, some formalisations of the model proposed, and an initial\nimplementation based on the BDI (Belief-Desire-Intention) agent model.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 01:50:08 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Monte-Alto", "Helio H. L. C.", ""], ["Morveli-Espinoza", "Mariela", ""], ["Tacla", "Cesar A.", ""]]}, {"id": "2010.00191", "submitter": "Yi-Dong Shen", "authors": "Yi-Dong Shen and Thomas Eiter", "title": "Constraint Monotonicity, Epistemic Splitting and Foundedness Could in\n  General Be Too Strong in Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the notions of subjective constraint monotonicity, epistemic\nsplitting, and foundedness have been introduced for epistemic logic programs,\nwith the aim to use them as main criteria respectively intuitions to compare\ndifferent answer set semantics proposed in the literature on how they comply\nwith these intuitions. In this note, we consider these three notions and\ndemonstrate on some examples that they may be too strong in general and may\nexclude some desired answer sets respectively world views. In conclusion, these\nproperties should not be regarded as mandatory properties that every answer set\nsemantics must satisfy in general.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 04:03:11 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 11:16:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shen", "Yi-Dong", ""], ["Eiter", "Thomas", ""]]}, {"id": "2010.00296", "submitter": "Benedikt Bollig", "authors": "Benedikt Bollig, Normann Decker, Martin Leucker", "title": "Erratum to \"Frequency Linear-time Temporal Logic\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We correct our proof of a theorem stating that satisfiability of frequency\nlinear-time temporal logic is undecidable [TASE 2012].\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 10:56:22 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Bollig", "Benedikt", ""], ["Decker", "Normann", ""], ["Leucker", "Martin", ""]]}, {"id": "2010.00791", "submitter": "Keng Meng Ng", "authors": "Keng Meng Ng and Nazanin R. Tavana and Yue Yang", "title": "A recursion theoretic foundation of computation over real numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a class of computable functions over real numbers using functional\nschemes similar to the class of primitive and partial recursive functions\ndefined by G\\\"odel and Kleene. We show that this class of functions can also be\ncharacterized by master-slave machines, which are Turing machine like devices.\nThe proof of the characterization gives a normal form theorem in the style of\nKleene. Furthermore, this characterization is a natural combination of two most\ninfluential theories of computation over real numbers, namely, the type-two\ntheory of effectivity (TTE) (see, for example, Weihrauch) and the\nBlum-Shub-Smale model of computation (BSS). Under this notion of computability,\nthe recursive (or computable) subsets of real numbers are exactly effective\n$\\Delta^0_2$ sets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 05:25:20 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Ng", "Keng Meng", ""], ["Tavana", "Nazanin R.", ""], ["Yang", "Yue", ""]]}, {"id": "2010.00810", "submitter": "Christoph Benzm\\\"uller", "authors": "Sebastian Reiche and Christoph Benzm\\\"uller", "title": "Public Announcement Logic in HOL", "comments": "3rd DaL\\'i Workshop, Dynamic Logic: New Trends and Applications,\n  Online, 9-10 October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A shallow semantical embedding for public announcement logic with relativized\ncommon knowledge is presented. This embedding enables the first-time automation\nof this logic with off-the-shelf theorem provers for classical higher-order\nlogic. It is demonstrated (i) how meta-theoretical studies can be automated\nthis way, and (ii) how non-trivial reasoning in the target logic (public\nannouncement logic), required e.g. to obtain a convincing encoding and\nautomation of the wise men puzzle, can be realized. Key to the presented\nsemantical embedding -- in contrast, e.g., to related work on the semantical\nembedding of normal modal logics -- is that evaluation domains are modeled\nexplicitly and treated as additional parameter in the encodings of the\nconstituents of the embedded target logic, while they were previously\nimplicitly shared between meta logic and target logic.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:46:02 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Reiche", "Sebastian", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2010.00811", "submitter": "Alexandre Goy", "authors": "Alexandre Goy and Daniela Petrisan", "title": "Combining Weak Distributive Laws: Application to Up-To Techniques", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coalgebraic modelling of alternating automata and of probabilistic\nautomata has long been obstructed by the absence of distributive laws of the\npowerset monad over itself, respectively of the powerset monad over the finite\ndistribution monad. This can be fixed using the framework of weak distributive\nlaws. We extend this framework to the case when one of the monads is only a\nfunctor. We provide abstract compositionality results, a generalized\ndeterminization procedure, and systematic soundness of up-to techniques. Along\nthe way, we apply these results to alternating automata as a motivating\nexample. Another example is given by probabilistic automata, for which our\nresults yield soundness of bisimulation up-to convex hull.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:48:06 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Goy", "Alexandre", ""], ["Petrisan", "Daniela", ""]]}, {"id": "2010.00825", "submitter": "Ronny Tredup", "authors": "Ronny Tredup, Evgeny Erofeev", "title": "The Complexity of Boolean State Separation (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a Boolean type of nets $\\tau$, a transition system $A$ is synthesizeable\ninto a $\\tau$-net $N$ if and only if distinct states of $A$ correspond to\ndistinct markings of $N$, and $N$ prevents a transition firing if there is no\nrelated transition in $A$. The former property is called $\\tau$-state\nseparation property ($\\tau$-SSP) while the latter -- $\\tau$-event/state\nseparation property ($\\tau$-ESSP). $A$ is embeddable into the reachability\ngraph of a $\\tau$-net $N$ if and only if $A$ has the $\\tau$-SSP. This paper\npresents a complete characterization of the computational complexity of\n\\textsc{$\\tau$-SSP} for all Boolean Petri net types.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 07:42:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Tredup", "Ronny", ""], ["Erofeev", "Evgeny", ""]]}, {"id": "2010.01050", "submitter": "Alper Kamil Bozkurt", "authors": "Alper Kamil Bozkurt, Yu Wang, Michael Zavlanos, and Miroslav Pajic", "title": "Model-Free Reinforcement Learning for Stochastic Games with Linear\n  Temporal Logic Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of synthesizing control strategies for Linear Temporal\nLogic (LTL) objectives in unknown environments. We model this problem as a\nturn-based zero-sum stochastic game between the controller and the environment,\nwhere the transition probabilities and the model topology are fully unknown.\nThe winning condition for the controller in this game is the satisfaction of\nthe given LTL specification, which can be captured by the acceptance condition\nof a deterministic Rabin automaton (DRA) directly derived from the LTL\nspecification. We introduce a model-free reinforcement learning (RL)\nmethodology to find a strategy that maximizes the probability of satisfying a\ngiven LTL specification when the Rabin condition of the derived DRA has a\nsingle accepting pair. We then generalize this approach to LTL formulas for\nwhich the Rabin condition has a larger number of accepting pairs, providing a\nlower bound on the satisfaction probability. Finally, we illustrate\napplicability of our RL method on two motion planning case studies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:29:32 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Bozkurt", "Alper Kamil", ""], ["Wang", "Yu", ""], ["Zavlanos", "Michael", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2010.01087", "submitter": "Giuseppe Cota", "authors": "Giuseppe Cota and Riccardo Zese and Elena Bellodi and Evelina Lamma\n  and Fabrizio Riguzzi", "title": "A Framework for Reasoning on Probabilistic Description Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there exist several reasoners for Description Logics, very few of them\ncan cope with uncertainty. BUNDLE is an inference framework that can exploit\nseveral OWL (non-probabilistic) reasoners to perform inference over\nProbabilistic Description Logics.\n  In this chapter, we report the latest advances implemented in BUNDLE. In\nparticular, BUNDLE can now interface with the reasoners of the TRILL system,\nthus providing a uniform method to execute probabilistic queries using\ndifferent settings. BUNDLE can be easily extended and can be used either as a\nstandalone desktop application or as a library in OWL API-based applications\nthat need to reason over Probabilistic Description Logics.\n  The reasoning performance heavily depends on the reasoner and method used to\ncompute the probability. We provide a comparison of the different reasoning\nsettings on several datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:41:06 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Cota", "Giuseppe", ""], ["Zese", "Riccardo", ""], ["Bellodi", "Elena", ""], ["Lamma", "Evelina", ""], ["Riguzzi", "Fabrizio", ""]]}, {"id": "2010.01164", "submitter": "Carmine Dodaro", "authors": "Riccardo Bertolucci, Alessio Capitanelli, Carmine Dodaro, Nicola\n  Leone, Marco Maratea, Fulvio Mastrogiovanni, Mauro Vallati", "title": "Manipulation of Articulated Objects using Dual-arm Robots via Answer Set\n  Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manipulation of articulated objects is of primary importance in Robotics,\nand can be considered as one of the most complex manipulation tasks.\nTraditionally, this problem has been tackled by developing ad-hoc approaches,\nwhich lack flexibility and portability.\n  In this paper we present a framework based on Answer Set Programming (ASP)\nfor the automated manipulation of articulated objects in a robot control\narchitecture. In particular, ASP is employed for representing the configuration\nof the articulated object, for checking the consistency of such representation\nin the knowledge base, and for generating the sequence of manipulation actions.\n  The framework is exemplified and validated on the Baxter dual-arm manipulator\nin a first, simple scenario. Then, we extend such scenario to improve the\noverall setup accuracy, and to introduce a few constraints in robot actions\nexecution to enforce their feasibility. The extended scenario entails a high\nnumber of possible actions that can be fruitfully combined together. Therefore,\nwe exploit macro actions from automated planning in order to provide more\neffective plans. We validate the overall framework in the extended scenario,\nthereby confirming the applicability of ASP also in more realistic Robotics\nsettings, and showing the usefulness of macro actions for the robot-based\nmanipulation of articulated objects. Under consideration in Theory and Practice\nof Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 18:50:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bertolucci", "Riccardo", ""], ["Capitanelli", "Alessio", ""], ["Dodaro", "Carmine", ""], ["Leone", "Nicola", ""], ["Maratea", "Marco", ""], ["Mastrogiovanni", "Fulvio", ""], ["Vallati", "Mauro", ""]]}, {"id": "2010.01187", "submitter": "Andrew Swan", "authors": "Andrew W Swan", "title": "On the Nielsen-Schreier Theorem in Homotopy Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a formulation of the Nielsen-Schreier theorem (subgroups of free\ngroups are free) in homotopy type theory using the presentation of groups as\npointed connected 1-truncated types. We show the special case of finite index\nsubgroups holds constructively and the full theorem follows from the axiom of\nchoice. We give an example of a boolean infinity topos where our formulation of\nthe theorem does not hold and show a stronger \"untruncated\" version of the\ntheorem is provably false in homotopy type theory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:27:31 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 19:07:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Swan", "Andrew W", ""]]}, {"id": "2010.01943", "submitter": "Valentina Castiglioni", "authors": "Luca Aceto, Valentina Castiglioni, Wan Fokkink, Anna Igolfsdottir and\n  Bas Luttik", "title": "Are Two Binary Operators Necessary to Finitely Axiomatise Parallel\n  Composition?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bergstra and Klop have shown that bisimilarity has a finite equational\naxiomatisation over ACP/CCS extended with the binary left and communication\nmerge operators. Moller proved that auxiliary operators are necessary to obtain\na finite axiomatisation of bisimilarity over CCS, and Aceto et al. showed that\nthis remains true when Hennessy's merge is added to that language. These\nresults raise the question of whether there is one auxiliary binary operator\nwhose addition to CCS leads to a finite axiomatisation of bisimilarity. This\nstudy provides a negative answer to that question based on three reasonable\nassumptions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 12:13:47 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 11:43:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Aceto", "Luca", ""], ["Castiglioni", "Valentina", ""], ["Fokkink", "Wan", ""], ["Igolfsdottir", "Anna", ""], ["Luttik", "Bas", ""]]}, {"id": "2010.02340", "submitter": "Aquinas Hobor", "authors": "Xuan-Bach Le and Aquinas Hobor and Anthony W. Lin", "title": "Complexity Analysis of Tree Share Structure", "comments": "20 pages including appendix. Published at the 16th Asian Symposium on\n  Programming Languages and Systems (APLAS 2018) in December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tree share structure proposed by Dockins et al. is an elegant model for\ntracking disjoint ownership in concurrent separation logic, but decision\nprocedures for tree shares are hard to implement due to a lack of a systematic\ntheoretical study. We show that the first-order theory of the full Boolean\nalgebra of tree shares (that is, with all tree-share constants) is decidable\nand has the same complexity as of the first-order theory of Countable Atomless\nBoolean Algebras. We prove that combining this additive structure with a\nconstant-restricted unary multiplicative \"relativization\" operator has a\nnon-elementary lower bound. We examine the consequences of this lower bound and\nprove that it comes from the combination of both theories by proving an upper\nbound on a generalization of the restricted multiplicative theory in isolation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 21:17:18 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Le", "Xuan-Bach", ""], ["Hobor", "Aquinas", ""], ["Lin", "Anthony W.", ""]]}, {"id": "2010.02595", "submitter": "Robert Y. Lewis", "authors": "Johan Commelin and Robert Y. Lewis", "title": "Formalizing the Ring of Witt Vectors", "comments": null, "journal-ref": "Proceedings of Certified Programs and Proofs (CPP 2021)", "doi": "10.1145/3437992.3439919", "report-no": null, "categories": "cs.LO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ring of Witt vectors $\\mathbb{W} R$ over a base ring $R$ is an important\ntool in algebraic number theory and lies at the foundations of modern $p$-adic\nHodge theory. $\\mathbb{W} R$ has the interesting property that it constructs a\nring of characteristic $0$ out of a ring of characteristic $p > 1$, and it can\nbe used more specifically to construct from a finite field containing\n$\\mathbb{Z}/p\\mathbb{Z}$ the corresponding unramified field extension of the\n$p$-adic numbers $\\mathbb{Q}_p$ (which is unique up to isomorphism).\n  We formalize the notion of a Witt vector in the Lean proof assistant, along\nwith the corresponding ring operations and other algebraic structure. We prove\nin Lean that, for prime $p$, the ring of Witt vectors over\n$\\mathbb{Z}/p\\mathbb{Z}$ is isomorphic to the ring of $p$-adic integers\n$\\mathbb{Z}_p$. In the process we develop idioms to cleanly handle calculations\nof identities between operations on the ring of Witt vectors. These\ncalculations are intractable with a naive approach, and require a proof\ntechnique that is usually skimmed over in the informal literature. Our proofs\nresemble the informal arguments while being fully rigorous.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:10:46 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 17:20:40 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Commelin", "Johan", ""], ["Lewis", "Robert Y.", ""]]}, {"id": "2010.02607", "submitter": "Sebastian Siebertz", "authors": "Jaroslav Nesetril and Patrice Ossona de Mendez and Sebastian Siebertz", "title": "Structural properties of the first-order transduction quasiorder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical transductions provide a very useful tool to encode classes of\nstructures inside other classes of structures. In this paper we study\nfirst-order (FO) transductions and the quasiorder they induce on infinite\nclasses of finite graphs. Surprisingly, this quasiorder is very complex, though\nshaped by the locality properties of first-order logic. This contrasts with the\nconjectured simplicity of the monadic second order (MSO) transduction\nquasiorder.\n  We first establish a local normal form for FO transductions, which is of\nindependent interest. Then we prove that the quotient partial order is a\nbounded distributive join-semilattice, and that the subposet of \\emph{additive}\nclasses is also a bounded distributive join-semilattice. The FO transduction\nquasiorder has a great expressive power, and many well studied class properties\ncan be defined using it. We apply these structural properties to prove, among\nother results, that FO transductions of the class of paths are exactly\nperturbations of classes with bounded bandwidth, that the local variants of\nmonadic stability and monadic dependence are equivalent to their (standard)\nnon-local versions, and that the classes with pathwidth at most $k$, for $k\\geq\n1$ form a strict hierarchy in the FO transduction quasiorder.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:31:40 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 08:22:53 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Nesetril", "Jaroslav", ""], ["de Mendez", "Patrice Ossona", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "2010.02752", "submitter": "Jonathan Gorard", "authors": "Jonathan Gorard, Manojna Namuduri and Xerxes D. Arsiwalla", "title": "ZX-Calculus and Extended Hypergraph Rewriting Systems I: A Multiway\n  Approach to Categorical Quantum Information Theory", "comments": "103 pages, 65 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical quantum mechanics and the Wolfram model offer distinct but\ncomplementary approaches to studying the relationship between diagrammatic\nrewriting systems over combinatorial structures and the foundations of physics;\nthe objective of the present article is to begin elucidating the formal\ncorrespondence between the two methodologies in the context of the ZX-calculus\nformalism of Coecke and Duncan for reasoning diagrammatically about linear maps\nbetween qubits. After briefly summarizing the relevant formalisms, and\npresenting a categorical formulation of the Wolfram model in terms of adhesive\ncategories and double-pushout rewriting systems, we illustrate how the\ndiagrammatic rewritings of the ZX-calculus can be embedded and realized within\nthe broader context of Wolfram model multiway systems, and illustrate some of\nthe capabilities of the software framework (ZXMultiwaySystem) that we have\ndeveloped specifically for this purpose. Finally, we present a proof (along\nwith an explicitly computed example) based on the methods of Dixon and\nKissinger that the multiway evolution graphs and branchial graphs of the\nWolfram model are naturally endowed with a monoidal structure based on rulial\ncomposition that is, furthermore, compatible with the monoidal product of\nZX-diagrams.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:21:21 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Gorard", "Jonathan", ""], ["Namuduri", "Manojna", ""], ["Arsiwalla", "Xerxes D.", ""]]}, {"id": "2010.02823", "submitter": "Geoff Hamilton", "authors": "A. M. Ben-Amram and G. W. Hamilton", "title": "Tight Polynomial Bounds for Loop Programs in Polynomial Space", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem: given a program, find tight asymptotic\nbounds on the values of some variables at the end of the computation (or at any\ngiven program point) in terms of its input values. We focus on the case of\npolynomially-bounded variables, and on a weak programming language for which we\nhave recently shown that tight bounds for polynomially-bounded variables are\ncomputable. These bounds are sets of multivariate polynomials. While their\ncomputability has been settled, the complexity of this program-analysis problem\nremained open. In this paper, we show the problem to be PSPACE-complete. The\nmain contribution is a new, space-efficient analysis algorithm. This algorithm\nis obtained in a few steps. First, we develop an algorithm for univariate\nbounds, a sub-problem which is already PSPACE-hard. Then, a decision procedure\nfor multivariate bounds is achieved by reducing this problem to the univariate\ncase; this reduction is orthogonal to the solution of the univariate problem\nand uses observations on the geometry of a set of vectors that represent\nmultivariate bounds. Finally, we transform the univariate-bound algorithm to\nproduce multivariate bounds.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:38:00 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 14:51:26 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ben-Amram", "A. M.", ""], ["Hamilton", "G. W.", ""]]}, {"id": "2010.02922", "submitter": "Bernd Schuh", "authors": "Bernd. R. Schuh", "title": "Balanced incomplete block designs and exact satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explores the correspondence between balanced incomplete block\ndesigns (BIBD) and certain linear CNF formulas by identifying the points of a\nblock design with the clauses of the Boolean formula and blocks with Boolean\nvariables. Parallel classes in BIBDs correspond to XSAT solutions in the\ncorresponding formula. This correspondence allows for transfers of results from\none field to the other. As a new result we deduce from known satisfiability\ntheorems that the problem of finding a parallel class in a partially balanced\nincomplete block design is NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 19:54:49 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Schuh", "Bernd. R.", ""]]}, {"id": "2010.02982", "submitter": "Alexandre Vigny", "authors": "Alexandre Vigny", "title": "Dynamic Query Evaluation Over Structures with Low Degree", "comments": "21 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the evaluation of first-order queries over classes of databases\nthat have bounded degree and low degree. More precisely, given a query and a\ndatabase, we want to efficiently test whether there is a solution, count how\nmany solutions there are, or be able to enumerate the set of all solutions.\n  Bounded and low degree are rather natural notions and both yield efficient\nalgorithms. For example, Berkholz, Keppeler, and Schweikardt showed in 2017\nthat over databases of bounded degree, not only any first order query can\nefficiently be tested, counted and enumerated, but the data structure used can\nbe updated when the database itself is updated.\n  This paper extends existing results in two directions. First, we show that\nover classes of databases with low degree, there is a data structure that\nenables us to test, count and enumerate the solutions of first order queries.\nThis data structure can also be efficiently recomputed when the database is\nupdated. Secondly, for classes of databases with bounded degree we show that,\nwithout increasing the preprocessing time, we can compute a data structure that\ndoes not depend on the query but only on its quantifier rank. We can therefore\nperform a single preprocessing that can later be used for many queries.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 19:16:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Vigny", "Alexandre", ""]]}, {"id": "2010.03185", "submitter": "Francois Laroussinie", "authors": "A. Hossain and F. Laroussinie", "title": "QCTL model-checking with QBF solvers", "comments": "31 pages. arXiv admin note: substantial text overlap with\n  arXiv:1906.10005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantified CTL (QCTL) extends the temporal logic CTL with quantifications\nover atomic propositions. This extension is known to be very expressive: QCTL\nallows us to express complex properties over Kripke structures (it is as\nexpressive as MSO). Several semantics exist for the quantifications: here, we\nwork with the structure semantics, where the extra propositions label the\nKripke structure (and not its execution tree), and the model-checking problem\nis known to be PSPACE-complete in this framework. We propose a new\nmodel-checking algorithm for QCTL based on a reduction to QBF. We consider\nseveral reduction strategies and we compare them with a prototype (based on\nseveral QBF solvers) on different examples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:30:35 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Hossain", "A.", ""], ["Laroussinie", "F.", ""]]}, {"id": "2010.03311", "submitter": "Jonni Virtema", "authors": "Jonni Virtema, Jana Hofmann, Bernd Finkbeiner, Juha Kontinen, and Fan\n  Yang", "title": "Linear-time Temporal Logic with Team Semantics: Expressivity and\n  Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressivity and the model checking problem of linear temporal\nlogic with team semantics (TeamLTL). In contrast to LTL, TeamLTL is capable of\ndefining hyperproperties, i.e., properties which relate multiple execution\ntraces. Logics for hyperproperties have so far been mostly obtained by\nextending temporal logics like LTL and QPTL with trace quantification,\nresulting in HyperLTL and HyperQPTL. We study the expressivity of TeamLTL and\nits extensions in comparison to HyperLTL and HyperQPTL. By doing so we obtain a\nnumber of model checking results for TeamLTL and identify its undecidability\nfrontier. The two types of logics follow a fundamentally different approach to\nhyperproperties and are of incomparable expressivity. We establish that the\nuniversally quantified fragment of HyperLTL subsumes the so-called k-coherent\nfragment of TeamLTL with contradictory negation. This also implies that the\nmodel checking problem is decidable for the fragment. We show decidability of\nmodel checking of the so-called left-flat fragment of TeamLTL with\ndownward-closed generalised atoms and Boolean disjunction via a translation to\na decidable fragment of HyperQPTL. Finally, we show that the model checking\nproblem of TeamLTL with Boolean disjunction and inclusion atoms is undecidable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 10:10:02 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 11:36:06 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Virtema", "Jonni", ""], ["Hofmann", "Jana", ""], ["Finkbeiner", "Bernd", ""], ["Kontinen", "Juha", ""], ["Yang", "Fan", ""]]}, {"id": "2010.03840", "submitter": "Manlio Valenti", "authors": "Jun Le Goh and Arno Pauly and Manlio Valenti", "title": "Finding descending sequences through ill-founded linear orders", "comments": "Fixed minor typos. To appear in The Journal of Symbolic Logic", "journal-ref": null, "doi": "10.1017/jsl.2021.15", "report-no": null, "categories": "math.LO cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate the Weihrauch degree of the problem $\\mathsf{DS}$\nof finding an infinite descending sequence through a given ill-founded linear\norder, which is shared by the problem $\\mathsf{BS}$ of finding a bad sequence\nthrough a given non-well quasi-order. We show that $\\mathsf{DS}$, despite being\nhard to solve (it has computable inputs with no hyperarithmetic solution), is\nrather weak in terms of uniform computational strength. To make the latter\nprecise, we introduce the notion of the deterministic part of a Weihrauch\ndegree. We then generalize $\\mathsf{DS}$ and $\\mathsf{BS}$ by considering\n$\\boldsymbol{\\Gamma}$-presented orders, where $\\boldsymbol{\\Gamma}$ is a Borel\npointclass or $\\boldsymbol{\\Delta}^1_1$, $\\boldsymbol{\\Sigma}^1_1$,\n$\\boldsymbol{\\Pi}^1_1$. We study the obtained $\\mathsf{DS}$-hierarchy and\n$\\mathsf{BS}$-hierarchy of problems in comparison with the (effective) Baire\nhierarchy and show that they do not collapse at any finite level.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 08:42:15 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:46:50 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Goh", "Jun Le", ""], ["Pauly", "Arno", ""], ["Valenti", "Manlio", ""]]}, {"id": "2010.03842", "submitter": "Bettina K\\\"onighofer", "authors": "Stefan Pranger, Bettina K\\\"onighofer, Martin Tappler, Martin\n  Deixelberger, Nils Jansen, Roderick Bloem", "title": "Adaptive Shielding under Uncertainty", "comments": "8 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets control problems that exhibit specific safety and\nperformance requirements. In particular, the aim is to ensure that an agent,\noperating under uncertainty, will at runtime strictly adhere to such\nrequirements. Previous works create so-called shields that correct an existing\ncontroller for the agent if it is about to take unbearable safety risks.\nHowever, so far, shields do not consider that an environment may not be fully\nknown in advance and may evolve for complex control and learning tasks. We\npropose a new method for the efficient computation of a shield that is adaptive\nto a changing environment. In particular, we base our method on problems that\nare sufficiently captured by potentially infinite Markov decision processes\n(MDP) and quantitative specifications such as mean payoff objectives. The\nshield is independent of the controller, which may, for instance, take the form\nof a high-performing reinforcement learning agent. At runtime, our method\nbuilds an internal abstract representation of the MDP and constantly adapts\nthis abstraction and the shield based on observations from the environment. We\nshowcase the applicability of our method via an urban traffic control problem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 08:45:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Pranger", "Stefan", ""], ["K\u00f6nighofer", "Bettina", ""], ["Tappler", "Martin", ""], ["Deixelberger", "Martin", ""], ["Jansen", "Nils", ""], ["Bloem", "Roderick", ""]]}, {"id": "2010.04000", "submitter": "Kyriaki Psara", "authors": "Anna Philippou, Kyriaki Psara", "title": "Reversible Computation in Cyclic Petri Nets", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.04607", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petri nets are a mathematical language for modeling and reasoning about\ndistributed systems. In this paper we propose an approach to Petri nets for\nembedding reversibility, i.e., the ability of reversing an executed sequence of\noperations at any point during operation. Specifically, we introduce machinery\nand associated semantics to support the three main forms of reversibility\nnamely, backtracking, causal reversing, and out-of-causal-order reversing in a\nvariation of cyclic Petri nets where tokens are persistent and are\ndistinguished from each other by an identity. Our formalism is influenced by\napplications in biochemistry but the methodology can be applied to a wide range\nof problems that feature reversibility. In particular, we demonstrate the\napplicability of our approach with a model of the ERK signalling pathway, an\nexample that inherently features reversible behavior.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 08:51:31 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Philippou", "Anna", ""], ["Psara", "Kyriaki", ""]]}, {"id": "2010.04749", "submitter": "Christoph Sprenger", "authors": "Christoph Sprenger and Tobias Klenze and Marco Eilers and Felix A.\n  Wolf and Peter M\\\"uller and Martin Clochard and David Basin", "title": "Igloo: Soundly Linking Compositional Refinement and Separation Logic for\n  Distributed System Verification", "comments": null, "journal-ref": null, "doi": "10.1145/3428220", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lighthouse projects such as CompCert, seL4, IronFleet, and DeepSpec have\ndemonstrated that full verification of entire systems is feasible by\nestablishing a refinement relation between an abstract system specification and\nan executable implementation. Existing approaches however impose severe\nrestrictions on either the abstract system specifications due to their limited\nexpressiveness or versatility, or on the executable code due to their reliance\non suboptimal code extraction or inexpressive program logics. We propose a\nnovel methodology that combines the compositional refinement of abstract,\nevent-based models of distributed systems with the verification of full-fledged\nprogram code using expressive separation logics, which support features of\nrealistic programming languages like mutable heap data structures and\nconcurrency. The main technical contribution of our work is a formal framework\nthat soundly relates event-based system models to program specifications in\nseparation logics, such that successful verification establishes a refinement\nrelation between the model and the code. We formalized our framework, Igloo, in\nIsabelle/HOL. Our framework enables the sound combination of tools for protocol\ndevelopment with existing program verifiers. We report on three case studies, a\nleader election protocol, a replication protocol, and a security protocol, for\nwhich we refine formal requirements into program specifications (in\nIsabelle/HOL) that we implement in Java and Python and prove correct using the\nVeriFast and Nagini tools.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 18:10:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sprenger", "Christoph", ""], ["Klenze", "Tobias", ""], ["Eilers", "Marco", ""], ["Wolf", "Felix A.", ""], ["M\u00fcller", "Peter", ""], ["Clochard", "Martin", ""], ["Basin", "David", ""]]}, {"id": "2010.04958", "submitter": "Antoine Mottet", "authors": "Libor Barto and William DeMeo and Antoine Mottet", "title": "Constraint Satisfaction Problems over Finite Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.RA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We initiate a systematic study of the computational complexity of the\nConstraint Satisfaction Problem (CSP) over finite structures that may contain\nboth relations and operations. We show the close connection between this\nproblem and a natural algebraic question: which finite algebras admit only\npolynomially many homomorphisms into them? We give some sufficient and some\nnecessary conditions for a finite algebra to have this property. In particular,\nwe show that every finite equationally nontrivial algebra has this property\nwhich gives us, as a simple consequence, a complete complexity classification\nof CSPs over two-element structures, thus extending the classification for\ntwo-element relational structures by Schaefer (STOC'78). We also present\nexamples of two-element structures that have bounded width but do not have\nrelational width (2,3), thus demonstrating that, from a descriptive complexity\nperspective, allowing operations leads to a richer theory.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 09:43:55 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 08:14:40 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Barto", "Libor", ""], ["DeMeo", "William", ""], ["Mottet", "Antoine", ""]]}, {"id": "2010.04965", "submitter": "Kiarash Mohammadi", "authors": "Kiarash Mohammadi, Amir-Hossein Karimi, Gilles Barthe, Isabel Valera", "title": "Scaling Guarantees for Nearest Counterfactual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations (CFE) are being widely used to explain\nalgorithmic decisions, especially in consequential decision-making contexts\n(e.g., loan approval or pretrial bail). In this context, CFEs aim to provide\nindividuals affected by an algorithmic decision with the most similar\nindividual (i.e., nearest individual) with a different outcome. However, while\nan increasing number of works propose algorithms to compute CFEs, such\napproaches either lack in optimality of distance (i.e., they do not return the\nnearest individual) and perfect coverage (i.e., they do not provide a CFE for\nall individuals); or they cannot handle complex models, such as neural\nnetworks. In this work, we provide a framework based on Mixed-Integer\nProgramming (MIP) to compute nearest counterfactual explanations with provable\nguarantees and with runtimes comparable to gradient-based approaches. Our\nexperiments on the Adult, COMPAS, and Credit datasets show that, in contrast\nwith previous methods, our approach allows for efficiently computing diverse\nCFEs with both distance guarantees and perfect coverage.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 10:05:50 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:15:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mohammadi", "Kiarash", ""], ["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Valera", "Isabel", ""]]}, {"id": "2010.05023", "submitter": "Gidon Ernst", "authors": "Gidon Ernst", "title": "Cuv\\'ee: Blending SMT-LIB with Programs and Weakest Preconditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cuv\\'ee is a program verification tool that reads SMT-LIB-like input files\nwhere terms may additionally contain weakest precondition operators over\nabstract programs. Cuv\\'ee translates such inputs into first-order SMT-LIB by\nsymbolically executing these programs. The input format used by Cuv\\'ee is\nintended to achieve a similar unification of tools for that for example\nsynthesize loop summaries. A notable technical aspect of Cuv\\'ee itself is the\nconsequent use of loop pre-/postconditions instead of invariants, and we\ndemonstrate how this lowers the annotation burden on some simple while\nprograms.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 15:13:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ernst", "Gidon", ""]]}, {"id": "2010.05167", "submitter": "Tatsuya Hagino", "authors": "Tatsuya Hagino", "title": "A Categorical Programming Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theory of data types based on category theory is presented. We organize\ndata types under a new categorical notion of F,G-dialgebras which is an\nextension of the notion of adjunctions as well as that of T-algebras.\nT-algebras are also used in domain theory, but while domain theory needs some\nprimitive data types, like products, to start with, we do not need any.\nProducts, coproducts and exponentiations (i.e. function spaces) are defined\nexactly like in category theory using adjunctions. F,G-dialgebras also enable\nus to define the natural number object, the object for finite lists and other\nfamiliar data types in programming. Furthermore, their symmetry allows us to\nhave the dual of the natural number object and the object for infinite lists\n(or lazy lists). We also introduce a programming language in a categorical\nstyle using F,G-dialgebras as its data type declaration mechanism. We define\nthe meaning of the language operationally and prove that any program terminates\nusing Tait's computability method.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 04:44:19 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hagino", "Tatsuya", ""]]}, {"id": "2010.05446", "submitter": "Bo Chen", "authors": "Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, Haipeng Ding", "title": "Neural, Symbolic and Neural-Symbolic Reasoning on Knowledge Graphs", "comments": "29 pages, AI Open Journal 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph reasoning is the fundamental component to support machine\nlearning applications such as information extraction, information retrieval,\nand recommendation. Since knowledge graphs can be viewed as the discrete\nsymbolic representations of knowledge, reasoning on knowledge graphs can\nnaturally leverage the symbolic techniques. However, symbolic reasoning is\nintolerant of the ambiguous and noisy data. On the contrary, the recent\nadvances of deep learning promote neural reasoning on knowledge graphs, which\nis robust to the ambiguous and noisy data, but lacks interpretability compared\nto symbolic reasoning. Considering the advantages and disadvantages of both\nmethodologies, recent efforts have been made on combining the two reasoning\nmethods. In this survey, we take a thorough look at the development of the\nsymbolic, neural and hybrid reasoning on knowledge graphs. We survey two\nspecific reasoning tasks, knowledge graph completion and question answering on\nknowledge graphs, and explain them in a unified reasoning framework. We also\nbriefly discuss the future directions for knowledge graph reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 04:28:57 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 06:47:45 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 04:49:30 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 06:46:16 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 02:53:48 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhang", "Jing", ""], ["Chen", "Bo", ""], ["Zhang", "Lingxi", ""], ["Ke", "Xirui", ""], ["Ding", "Haipeng", ""]]}, {"id": "2010.05677", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky, Simon Kn\\\"auer and Sebastian Rudolph", "title": "Datalog-Expressibility for Monadic and Guarded Second-Order Logic", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterise the sentences in Monadic Second-order Logic (MSO) that are\nover finite structures equivalent to a Datalog program, in terms of an\nexistential pebble game. We also show that for every class C of finite\nstructures that can be expressed in MSO and is closed under homomorphisms, and\nfor all integers l,k, there exists a *canonical* Datalog program Pi of width\n(l,k), that is, a Datalog program of width (l,k) which is sound for C (i.e., Pi\nonly derives the goal predicate on a finite structure A if A is in C) and with\nthe property that Pi derives the goal predicate whenever *some* Datalog program\nof width (l,k) which is sound for C derives the goal predicate. The same\ncharacterisations also hold for Guarded Second-order Logic (GSO), which\nproperly extends MSO. To prove our results, we show that every class C in GSO\nwhose complement is closed under homomorphisms is a finite union of constraint\nsatisfaction problems (CSPs) of countably categorical structures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 13:18:14 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2010.05689", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Rongjie Yan", "title": "Continuous Safety Verification of Neural Networks", "comments": "work-in-progress report; 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep neural networks (DNNs) as core functions in autonomous driving\ncreates unique verification and validation challenges. In particular, the\ncontinuous engineering paradigm of gradually perfecting a DNN-based perception\ncan make the previously established result of safety verification no longer\nvalid. This can occur either due to the newly encountered examples (i.e., input\ndomain enlargement) inside the Operational Design Domain or due to the\nsubsequent parameter fine-tuning activities of a DNN. This paper considers\napproaches to transfer results established in the previous DNN safety\nverification problem to the modified problem setting. By considering the reuse\nof state abstractions, network abstractions, and Lipschitz constants, we\ndevelop several sufficient conditions that only require formally analyzing a\nsmall part of the DNN in the new problem. The overall concept is evaluated in a\n$1/10$-scaled vehicle that equips a DNN controller to determine the visual\nwaypoint from the perceived image.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 13:28:04 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Yan", "Rongjie", ""]]}, {"id": "2010.05694", "submitter": "EPTCS", "authors": "Viviana Mascardi (University of Genova, DIBRIS, Italy), Domenico\n  Pellegrini (Ministry of Justice, Tribunale di Genova, Italy)", "title": "Logical Judges Challenge Human Judges on the Strange Case of\n  B.C.-Valjean", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 268-275", "doi": "10.4204/EPTCS.325.32", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On May 12th, 2020, during the course entitled Artificial Intelligence and\nJurisdiction Practice organized by the Italian School of Magistracy, more than\n70 magistrates followed our demonstration of a Prolog logical judge reasoning\non an armed robbery case. Although the implemented logical judge is just an\nexercise of knowledge representation and simple deductive reasoning, a\npractical demonstration of an automated reasoning tool to such a large audience\nof potential end-users represents a first and unique attempt in Italy and, to\nthe best of our knowledge, in the international panorama. In this paper we\npresent the case addressed by the logical judge - a real case already addressed\nby a human judge in 2015 - and the feedback on the demonstration collected from\nthe attendees.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:51:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mascardi", "Viviana", "", "University of Genova, DIBRIS, Italy"], ["Pellegrini", "Domenico", "", "Ministry of Justice, Tribunale di Genova, Italy"]]}, {"id": "2010.05799", "submitter": "Abhisekh Sankaran", "authors": "Abhisekh Sankaran", "title": "Some classical model theoretic aspects of bounded shrub-depth classes", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider classes of arbitrary (finite or infinite) graphs of bounded\nshrub-depth, specifically the class $\\mathrm{TM}_{r, p}(d)$ of $p$-labeled\narbitrary graphs whose underlying unlabeled graphs have tree models of height\n$d$ and $r$ labels. We show that this class satisfies an extension of the\nclassical L\\\"owenheim-Skolem property into the finite and for $\\mathrm{MSO}$.\nThis extension being a generalization of the small model property, we obtain\nthat the graphs of $\\mathrm{TM}_{r, p}(d)$ are pseudo-finite. In addition, we\nobtain as consequences entirely new proofs of a number of known results\nconcerning bounded shrub-depth classes (of finite graphs) and $\\mathrm{TM}_{r,\np}(d)$. These include the small model property for $\\mathrm{MSO}$ with\nelementary bounds, the classical compactness theorem from model theory over\n$\\mathrm{TM}_{r, p}(d)$, and the equivalence of $\\mathrm{MSO}$ and\n$\\mathrm{FO}$ over $\\mathrm{TM}_{r, p}(d)$ and hence over bounded shrub-depth\nclasses. The proof for the last of these is via an adaptation of the proof of\nthe classical Lindstr\\\"om's theorem characterizing $\\mathrm{FO}$ over arbitrary\nstructures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 15:54:43 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sankaran", "Abhisekh", ""]]}, {"id": "2010.05812", "submitter": "Gidon Ernst", "authors": "Gidon Ernst", "title": "A Complete Approach to Loop Verification with Invariants and Summaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Loop invariants characterize the partial result computed by a loop so far up\nto an intermediate state. It has been noted, however, that complementing\ninvariants by summaries, which characterize the remaining iterations of a loop,\ncan often lead to simpler correctness proofs. In this paper, we derive sound\nverification conditions for this approach, and moreover characterize\ncompleteness relative to a class of \"safe\" invariants, alongside with\nfundamental and novel insights in the relation between invariants and\nsummaries. All theoretical results have immediate practical consequences for\ntool use and construction. Summaries should therefore be regarded as a\nprincipal alternative to invariants. To substantiate this claim experimentally,\nwe evaluate the automation potential using state-of-the-art Horn solvers, which\nshows that the the proposed approach is competitive, even without specialized\nsolving strategies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:07:17 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 08:37:49 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ernst", "Gidon", ""]]}, {"id": "2010.06216", "submitter": "Koar Marntirosian", "authors": "Koar Marntirosian, Tom Schrijvers, Bruno C. d. S. Oliveira, Georgios\n  Karachalias", "title": "Resolution as Intersection Subtyping via Modus Ponens", "comments": "43 pages, 20 figures; typos corrected, link to artifact added", "journal-ref": null, "doi": "10.1145/3428274", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Resolution and subtyping are two common mechanisms in programming languages.\nResolution is used by features such as type classes or Scala-style implicits to\nsynthesize values automatically from contextual type information. Subtyping is\ncommonly used to automatically convert the type of a value into another\ncompatible type. So far the two mechanisms have been considered independently\nof each other. This paper shows that, with a small extension, subtyping with\nintersection types can subsume resolution. This has three main consequences.\nFirstly, resolution does not need to be implemented as a separate mechanism.\nSecondly, the interaction between resolution and subtyping becomes apparent.\nFinally, the integration of resolution into subtyping enables first-class\n(implicit) environments. The extension that recovers the power of resolution\nvia subtyping is the modus ponens rule of propositional logic. While it is\neasily added to declarative subtyping, significant care needs to be taken to\nretain desirable properties, such as transitivity and decidability of\nalgorithmic subtyping, and coherence. To materialize these ideas we develop\n$\\lambda_i^{\\mathsf{MP}}$, a calculus that extends a iprevious calculus with\ndisjoint intersection types, and develop its metatheory in the Coq theorem\nprover.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 07:58:17 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 09:32:19 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Marntirosian", "Koar", ""], ["Schrijvers", "Tom", ""], ["Oliveira", "Bruno C. d. S.", ""], ["Karachalias", "Georgios", ""]]}, {"id": "2010.06361", "submitter": "Olivier Serre", "authors": "Christopher H. Broadbent, Arnaud Carayol, Matthew Hague, Andrzej S.\n  Murawski, C.-H. Luke Ong, Olivier Serre", "title": "Collapsible Pushdown Parity Games", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a large class of two-player perfect-information turn-based\nparity games on infinite graphs, namely those generated by collapsible pushdown\nautomata. The main motivation for studying these games comes from the\nconnections from collapsible pushdown automata and higher-order recursion\nschemes, both models being equi-expressive for generating infinite trees. Our\nmain result is to establish the decidability of such games and to provide an\neffective representation of the winning region as well as of a winning\nstrategy. Thus, the results obtained here provide all necessary tools for an\nin-depth study of logical properties of trees generated by collapsible pushdown\nautomata/recursion schemes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 13:15:46 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Broadbent", "Christopher H.", ""], ["Carayol", "Arnaud", ""], ["Hague", "Matthew", ""], ["Murawski", "Andrzej S.", ""], ["Ong", "C. -H. Luke", ""], ["Serre", "Olivier", ""]]}, {"id": "2010.06366", "submitter": "Olivier Serre", "authors": "Christopher H. Broadbent, Arnaud Carayol, C.-H. Luke Ong, Olivier\n  Serre", "title": "Higher-Order Recursion Schemes and Collapsible Pushdown Automata:\n  Logical Properties", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the logical properties of a very general class of infinite\nranked trees, namely those generated by higher-order recursion schemes. We\nconsider, for both monadic second-order logic and modal mu-calculus, three main\nproblems: model-checking, logical reflection (aka global model-checking, that\nasks for a finite description of the set of elements for which a formula holds)\nand selection (that asks, if exists, for some finite description of a set of\nelements for which an MSO formula with a second-order free variable holds). For\neach of these problems we provide an effective solution. This is obtained\nthanks to a known connection between higher-order recursion schemes and\ncollapsible pushdown automata and on previous work regarding parity games\nplayed on transition graphs of collapsible pushdown automata.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 13:19:39 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 14:05:30 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Broadbent", "Christopher H.", ""], ["Carayol", "Arnaud", ""], ["Ong", "C. -H. Luke", ""], ["Serre", "Olivier", ""]]}, {"id": "2010.06367", "submitter": "Marcel Hark", "authors": "Fabian Meyer, Marcel Hark, and J\\\"urgen Giesl", "title": "Inferring Expected Runtimes of Probabilistic Integer Programs Using\n  Expected Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel modular approach to infer upper bounds on the expected\nruntime of probabilistic integer programs automatically. To this end, it\ncomputes bounds on the runtime of program parts and on the sizes of their\nvariables in an alternating way. To evaluate its power, we implemented our\napproach in a new version of our open-source tool KoAT.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 13:24:41 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 10:29:07 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 19:09:33 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Meyer", "Fabian", ""], ["Hark", "Marcel", ""], ["Giesl", "J\u00fcrgen", ""]]}, {"id": "2010.06482", "submitter": "Ankush Das", "authors": "Ankush Das, Henry DeYoung, Andreia Mordido, Frank Pfenning", "title": "Nested Session Types", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types statically describe communication protocols between concurrent\nmessage-passing processes. Unfortunately, parametric polymorphism even in its\nrestricted prenex form is not fully understood in the context of session types.\nIn this paper, we present the metatheory of session types extended with prenex\npolymorphism and, as a result, nested recursive datatypes. Remarkably, we prove\nthat type equality is decidable by exhibiting a reduction to trace equivalence\nof deterministic first-order grammars. Recognizing the high theoretical\ncomplexity of the latter, we also propose a novel type equality algorithm and\nprove its soundness. We observe that the algorithm is surprisingly efficient\nand, despite its incompleteness, sufficient for all our examples. We have\nimplemented our ideas by extending the Rast programming language with nested\nsession types. We conclude with several examples illustrating the expressivity\nof our enhanced type system.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:40:39 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 02:30:52 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 01:10:04 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 21:10:46 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Das", "Ankush", ""], ["DeYoung", "Henry", ""], ["Mordido", "Andreia", ""], ["Pfenning", "Frank", ""]]}, {"id": "2010.06496", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Nihil Shah", "title": "Relating Structure and Power: Extended Version", "comments": "Extended version of paper arXiv:1806.09031 which appeared in CSL\n  2018. To appear in Journal of Logic and Computation 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial games are widely used in finite model theory, constraint\nsatisfaction, modal logic and concurrency theory to characterize logical\nequivalences between structures. In particular, Ehrenfeucht-Fraisse games,\npebble games, and bisimulation games play a central role. We show how each of\nthese types of games can be described in terms of an indexed family of comonads\non the category of relational structures and homomorphisms. The index $k$ is a\nresource parameter which bounds the degree of access to the underlying\nstructure. The coKleisli categories for these comonads can be used to give\nsyntax-free characterizations of a wide range of important logical\nequivalences. Moreover, the coalgebras for these indexed comonads can be used\nto characterize key combinatorial parameters: tree-depth for the\nEhrenfeucht-Fraisse comonad, tree-width for the pebbling comonad, and\nsynchronization-tree depth for the modal unfolding comonad. These results pave\nthe way for systematic connections between two major branches of the field of\nlogic in computer science which hitherto have been almost disjoint: categorical\nsemantics, and finite and algorithmic model theory.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:56:45 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 16:56:14 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 19:01:31 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 16:07:03 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 17:12:18 GMT"}, {"version": "v6", "created": "Fri, 19 Mar 2021 17:46:23 GMT"}, {"version": "v7", "created": "Sat, 24 Jul 2021 19:24:50 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Abramsky", "Samson", ""], ["Shah", "Nihil", ""]]}, {"id": "2010.06674", "submitter": "Niveditha Manjunath", "authors": "Ezio Bartocci (1), Roderick Bloem (2), Benedikt Maderbacher (2),\n  Niveditha Manjunath (1 and 3), Dejan Ni\\v{c}kovi\\'c (3) ((1) Vienna\n  University of Technology, (2) Graz University of Technology, (3) AIT Austrian\n  Institute of Technology)", "title": "Adaptive Testing for Specification Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.GT cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring correctness of cyber-physical systems (CPS) is an extremely\nchallenging task that is in practice often addressed with simulation based\ntesting. Formal specification languages, such as Signal Temporal Logic (STL),\nare used to mathematically express CPS requirements and thus render the\nsimulation activity more systematic and principled. We propose a novel method\nfor adaptive generation of tests with specification coverage for STL. To\nachieve this goal, we devise cooperative reachability games that we combine\nwith numerical optimization to create tests that explore the system in a way\nthat exercise various parts of the specification. To the best of our knowledge\nour approach is the first adaptive testing approach that can be applied\ndirectly to MATLAB\\texttrademark\\; Simulink/Stateflow models. We implemented\nour approach in a prototype tool and evaluated it on several illustrating\nexamples and a case study from the avionics domain, demonstrating the\neffectiveness of adaptive testing to (1) incrementally build a test case that\nreaches a test objective, (2) generate a test suite that increases the\nspecification coverage, and (3) infer what part of the specification is\nactually implemented.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 20:14:51 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 15:09:57 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Bartocci", "Ezio", "", "1 and 3"], ["Bloem", "Roderick", "", "1 and 3"], ["Maderbacher", "Benedikt", "", "1 and 3"], ["Manjunath", "Niveditha", "", "1 and 3"], ["Ni\u010dkovi\u0107", "Dejan", ""]]}, {"id": "2010.07031", "submitter": "Josef Widder", "authors": "Sean Braithwaite and Ethan Buchman and Ismail Khoffi and Igor Konnov\n  and Zarko Milosevic and Romain Ruetschi and Josef Widder", "title": "A Tendermint Light Client", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Tendermint blockchains, the proof-of-stake mechanism and the underlying\nconsensus algorithm entail a dynamic fault model that implies that the active\nvalidators (nodes that sign blocks) may change over time, and a quorum of these\nvalidators is assumed to be correct only for a limited period of time (called\ntrusting period). The changes of the validator set are under control of the\nblockchain application, and are committed in every block. In order to check\nwhat is the state of the blockchain application at some height h, one needs to\nknow the validator set at that height so that one can verify the corresponding\ndigital signatures and hashes. A naive way of determining the validator set for\nheight h requires one to: (i) download all blocks before h, (ii) verify blocks\nby checking digital signatures and hashes and (iii) execute the corresponding\ntransactions so the changes in the validator sets are reproduced. This can\npotentially be very slow and computationally and data intensive.\n  In this paper we formalize the dynamic fault model imposed by Tendermint, and\ndescribe a light client protocol that allows to check the state of the\nblockchain application that, in realistic settings, reduces significantly the\namount of data needed to be downloaded, and the number of required\ncomputationally expensive signature verification operations. In addition to\nmathematical proofs, we have formalized the light client protocol in TLA+, and\nchecked safety and liveness with the APALACHE model checker.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 12:42:28 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 07:35:52 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Braithwaite", "Sean", ""], ["Buchman", "Ethan", ""], ["Khoffi", "Ismail", ""], ["Konnov", "Igor", ""], ["Milosevic", "Zarko", ""], ["Ruetschi", "Romain", ""], ["Widder", "Josef", ""]]}, {"id": "2010.07082", "submitter": "Alessandro Gianola", "authors": "Silvio Ghilardi and Alessandro Gianola and Deepak Kapur", "title": "Interpolation and Amalgamation for Arrays with MaxDiff (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the theory of McCarthy's extensional arrays enriched with a\nmaxdiff operation (this operation returns the biggest index where two given\narrays differ) is proposed. It is known from the literature that a diff\noperation is required for the theory of arrays in order to enjoy the Craig\ninterpolation property at the quantifier-free level. However, the diff\noperation introduced in the literature is merely instrumental to this purpose\nand has only a purely formal meaning (it is obtained from the Skolemization of\nthe extensionality axiom). Our maxdiff operation significantly increases the\nlevel of expressivity; however, obtaining interpolation results for the\nresulting theory becomes a surprisingly hard task. We obtain such results via a\nthorough semantic analysis of the models of the theory and of their\namalgamation properties. The results are modular with respect to the index\ntheory and it is shown how to convert them into concrete interpolation\nalgorithms via a hierarchical approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:37:05 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 22:51:22 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Ghilardi", "Silvio", ""], ["Gianola", "Alessandro", ""], ["Kapur", "Deepak", ""]]}, {"id": "2010.07253", "submitter": "Murphy Berzish", "authors": "Murphy Berzish, Mitja Kulczynski, Federico Mora, Florin Manea, Joel D.\n  Day, Dirk Nowotka, Vijay Ganesh", "title": "An SMT Solver for Regular Expressions and Linear Arithmetic over String\n  Length", "comments": "25 pages (main body 21 pages). 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel length-aware solving algorithm for the quantifier-free\nfirst-order theory over regex membership predicate and linear arithmetic over\nstring length. We implement and evaluate this algorithm and related heuristics\nin the Z3 theorem prover. A crucial insight that underpins our algorithm is\nthat real-world instances contain a wealth of information about upper and lower\nbounds on lengths of strings under constraints, and such information can be\nused very effectively to simplify operations on automata representing regular\nexpressions. Additionally, we present a number of novel general heuristics,\nsuch as the prefix/suffix method, that can be used in conjunction with a\nvariety of regex solving algorithms, making them more efficient. We showcase\nthe power of our algorithm and heuristics via an extensive empirical evaluation\nover a large and diverse benchmark of 57256 regex-heavy instances, almost 75%\nof which are derived from industrial applications or contributed by other\nsolver developers. Our solver outperforms five other state-of-the-art string\nsolvers, namely, CVC4, OSTRICH, Z3seq, Z3str3, and Z3-Trau, over this\nbenchmark, in particular achieving a 2.4x speedup over CVC4, 4.4x speedup over\nZ3seq, 6.4x speedup over Z3-Trau, 9.1x speedup over Z3str3, and 13x speedup\nover OSTRICH.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:18:02 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 02:58:35 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 16:23:26 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Berzish", "Murphy", ""], ["Kulczynski", "Mitja", ""], ["Mora", "Federico", ""], ["Manea", "Florin", ""], ["Day", "Joel D.", ""], ["Nowotka", "Dirk", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2010.07284", "submitter": "Vincenzo Ciancia", "authors": "Laura Bussi, Vincenzo Ciancia, Fabio Gadducci", "title": "A spatial model checker in GPU (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tool voxlogica merges the state-of-the-art library of computational\nimaging algorithms ITK with the combination of declarative specification and\noptimised execution provided by spatial logic model checking. The analysis of\nan existing benchmark for segmentation of brain tumours via a simple logical\nspecification reached state-of-the-art accuracy. We present a new, GPU-based\nversion of voxlogica and discuss its implementation, scalability, and\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:58:28 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bussi", "Laura", ""], ["Ciancia", "Vincenzo", ""], ["Gadducci", "Fabio", ""]]}, {"id": "2010.07416", "submitter": "Tom\\'a\\v{s} Gonda", "authors": "Tobias Fritz, Tom\\'a\\v{s} Gonda, Paolo Perrone, Eigil Fjeldgren\n  Rischel", "title": "Representable Markov Categories and Comparison of Statistical\n  Experiments in Categorical Probability", "comments": "69 pages, color used in text and diagrams. v2: Measure-theoretic\n  formulation of BSS Theorem added to the introduction plus minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LO math.CT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov categories are a recent categorical approach to the mathematical\nfoundations of probability and statistics. Here, this approach is advanced by\nstating and proving equivalent conditions for second-order stochastic\ndominance, a widely used way of comparing probability distributions by their\nspread. Furthermore, we lay foundation for the theory of comparing statistical\nexperiments within Markov categories by stating and proving the classical\nBlackwell-Sherman-Stein Theorem. Our version not only offers new insight into\nthe proof, but its abstract nature also makes the result more general,\nautomatically specializing to the standard Blackwell-Sherman-Stein Theorem in\nmeasure-theoretic probability as well as a Bayesian version that involves\nprior-dependent garbling. Along the way, we define and characterize\nrepresentable Markov categories, within which one can talk about Markov kernels\nto or from spaces of distributions. We do so by exploring the relation between\nMarkov categories and Kleisli categories of probability monads.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 21:54:57 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 03:05:33 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Fritz", "Tobias", ""], ["Gonda", "Tom\u00e1\u0161", ""], ["Perrone", "Paolo", ""], ["Rischel", "Eigil Fjeldgren", ""]]}, {"id": "2010.07650", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Grigorios Tsoumakas", "title": "Altruist: Argumentative Explanations through Local Interpretations of\n  Predictive Models", "comments": "9 Pages, 4 Figures, 3 Tables, Submitted to SDM21 by SIAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable machine learning is an emerging field providing solutions on\nacquiring insights into machine learning models' rationale. It has been put in\nthe map of machine learning by suggesting ways to tackle key ethical and\nsocietal issues. However, existing techniques of interpretable machine learning\nare far from being comprehensible and explainable to the end user. Another key\nissue in this field is the lack of evaluation and selection criteria, making it\ndifficult for the end user to choose the most appropriate interpretation\ntechnique for its use. In this study, we introduce a meta-explanation\nmethodology that will provide truthful interpretations, in terms of feature\nimportance, to the end user through argumentation. At the same time, this\nmethodology can be used as an evaluation or selection tool for multiple\ninterpretation techniques based on feature importance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 10:36:48 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2010.07763", "submitter": "Ranjit Jhala", "authors": "Ranjit Jhala, Niki Vazou", "title": "Refinement Types: A Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Refinement types enrich a language's type system with logical predicates that\ncircumscribe the set of values described by the type, thereby providing\nsoftware developers a tunable knob with which to inform the type system about\nwhat invariants and correctness properties should be checked on their code. In\nthis article, we distill the ideas developed in the substantial literature on\nrefinement types into a unified tutorial that explains the key ingredients of\nmodern refinement type systems. In particular, we show how to implement a\nrefinement type checker via a progression of languages that incrementally add\nfeatures to the language or type system.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:05:27 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Jhala", "Ranjit", ""], ["Vazou", "Niki", ""]]}, {"id": "2010.07800", "submitter": "Tobias Reinhard", "authors": "Tobias Reinhard, Amin Timany, Bart Jacobs", "title": "A Separation Logic to Verify Termination of Busy-Waiting for Abrupt\n  Program Exit", "comments": "7 pages, 11 figures, accepted at FTfJP 2020, corresponding technical\n  report: arXiv:2007.10215", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs for multiprocessor machines commonly perform busy-waiting for\nsynchronisation. In this paper, we make a first step towards proving\ntermination of such programs. We approximate (i) arbitrary waitable events by\nabrupt program termination and (ii) busy-waiting for events by busy-waiting to\nbe abruptly terminated.\n  We propose a separation logic for modularly verifying termination (under fair\nscheduling) of programs where some threads eventually abruptly terminate the\nprogram, and other threads busy-wait for this to happen.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 08:37:41 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 06:57:40 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Reinhard", "Tobias", ""], ["Timany", "Amin", ""], ["Jacobs", "Bart", ""]]}, {"id": "2010.07834", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Vojt\\v{e}ch Havlena and Ond\\v{r}ej Leng\\'al", "title": "Reducing (to) the Ranks: Efficient Rank-based B\\\"{u}chi Automata\n  Complementation (Technical Report)", "comments": "Accepted at CONCUR'21", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2021.9", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides several optimizations of the rank-based approach for\ncomplementing B\\\"{u}chi automata. We start with Schewe's theoretically optimal\nconstruction and develop a set of techniques for pruning its state space that\nare key to obtaining small complement automata in practice. In particular, the\nreductions (except one) have the property that they preserve (at least some)\nso-called super-tight runs, which are runs whose ranking is as tight as\npossible. Our evaluation on a large benchmark shows that the optimizations\nindeed significantly help the rank-based approach and that, in a large number\nof cases, the obtained complement is the smallest from those produced by a\nlarge number of state-of-the-art tools for B\\\"{u}chi complementation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 15:53:13 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 11:01:28 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 07:57:27 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Havlena", "Vojt\u011bch", ""], ["Leng\u00e1l", "Ond\u0159ej", ""]]}, {"id": "2010.07899", "submitter": "Stelios Tsampas", "authors": "Stelios Tsampas, Christian Williams, Andreas Nuyts, Dominique\n  Devriese, Frank Piessens", "title": "Abstract Congruence Criteria for Weak Bisimilarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce three general compositionality criteria over operational\nsemantics and prove that, when all three are satisfied together, they guarantee\nweak bisimulation being a congruence. Our work is founded upon Turi and\nPlotkin's mathematical operational semantics and the coalgebraic approach to\nweak bisimulation by Brengos. We demonstrate each criterion with various\nexamples of success and failure and establish a formal connection with the\nsimply WB cool rule format of Bloom and van Glabbeek. In addition, we show that\nthe three criteria induce lax models in the sense of Bonchi et al.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:25:45 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 23:40:42 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Tsampas", "Stelios", ""], ["Williams", "Christian", ""], ["Nuyts", "Andreas", ""], ["Devriese", "Dominique", ""], ["Piessens", "Frank", ""]]}, {"id": "2010.07912", "submitter": "Michael Blondin", "authors": "Michael Blondin, Christoph Haase, Philip Offtermatt", "title": "Directed Reachability for Infinite-State Systems", "comments": "29 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous tasks in program analysis and synthesis reduce to deciding\nreachability in possibly infinite graphs such as those induced by Petri nets.\nHowever, the Petri net reachability problem has recently been shown to require\nnon-elementary time, which raises questions about the practical applicability\nof Petri nets as target models. In this paper, we introduce a novel approach\nfor efficiently semi-deciding the reachability problem for Petri nets in\npractice. Our key insight is that computationally lightweight\nover-approximations of Petri nets can be used as distance oracles in classical\ngraph exploration algorithms such as A* and greedy best-first search. We\nprovide and evaluate a prototype implementation of our approach that\noutperforms existing state-of-the-art tools, sometimes by orders of magnitude,\nand which is also competitive with domain-specific tools on benchmarks coming\nfrom program synthesis and concurrent program analysis.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:46:12 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Blondin", "Michael", ""], ["Haase", "Christoph", ""], ["Offtermatt", "Philip", ""]]}, {"id": "2010.08003", "submitter": "Georgios Bakirtzis", "authors": "Georgios Bakirtzis, Cody H. Fleming, Christina Vasilakopoulou", "title": "Categorical Semantics of Cyber-Physical Systems Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems require the construction and management of various\nmodels to assure their correct, safe, and secure operation. These various\nmodels are necessary because of the coupled physical and computational dynamics\npresent in cyber-physical systems. However, to date the different model views\nof cyber-physical systems are largely related informally, which raises issues\nwith the degree of formal consistency between those various models of\nrequirements, system behavior, and system architecture. We present a\ncategory-theoretic framework to make different types of composition explicit in\nthe modeling and analysis of cyber-physical systems, which could assist in\nverifying the system as a whole. This compositional framework for\ncyber-physical systems gives rise to unified system models, where system\nbehavior is hierarchically decomposed and related to a system architecture\nusing the systems-as-algebras paradigm. As part of this paradigm, we show that\nan algebra of (safety) contracts generalizes over the state of the art,\nproviding more uniform mathematical tools for constraining the behavior over a\nricher set of composite cyber-physical system models, which has the potential\nof minimizing or eliminating hazardous behavior.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 20:04:59 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:30:00 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 13:07:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bakirtzis", "Georgios", ""], ["Fleming", "Cody H.", ""], ["Vasilakopoulou", "Christina", ""]]}, {"id": "2010.08230", "submitter": "Roy Overbeek", "authors": "Roy Overbeek, J\\\"org Endrullis, Alo\\\"is Rosset", "title": "Graph Rewriting and Relabeling with PBPO+", "comments": "20 pages, accepted to the International Conference on Graph\n  Transformation 2021 (ICGT 2021)", "journal-ref": "Proceedings of the Internatiol Conference on Graph Transformation\n  2021 (ICGT 2021), LNCS 12741, 2021, pp. 60-80", "doi": "10.1007/978-3-030-78946-6_4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the powerful Pullback-Pushout (PBPO) approach for graph rewriting\nwith strong matching. Our approach, called \\pbpostrong, exerts more control\nover the embedding of the pattern in the host graph, which is important for a\nlarge class of graph rewrite systems. In addition, we show that \\pbpostrong is\nwell-suited for rewriting labeled graphs and certain classes of attributed\ngraphs. For this purpose, we employ a lattice structure on the label set and\nuse order-preserving graph morphisms. We argue that our approach is simpler and\nmore general than related relabeling approaches in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:22:07 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 14:04:15 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 17:30:53 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Overbeek", "Roy", ""], ["Endrullis", "J\u00f6rg", ""], ["Rosset", "Alo\u00efs", ""]]}, {"id": "2010.08233", "submitter": "Chad Nester", "authors": "Chad Nester", "title": "The Structure of Concurrent Process Histories", "comments": "19 pages, many figures, in peer review", "journal-ref": null, "doi": "10.1007/978-3-030-78142-2_13", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify the algebraic structure of the material histories generated by\nconcurrent processes. Specifically, we extend existing categorical theories of\nresource convertibility to capture concurrent interaction. Our formalism admits\nan intuitive graphical presentation via string diagrams for proarrow\nequipments.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:29:19 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Nester", "Chad", ""]]}, {"id": "2010.08280", "submitter": "Satoshi Kura", "authors": "Satoshi Kura", "title": "General Semantic Construction of Dependent Refinement Type Systems,\n  Categorically", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refinement types are types equipped with predicates that specify\npreconditions and postconditions of underlying functional languages. We propose\na general semantic construction of dependent refinement type systems from\nunderlying type systems and predicate logic, that is, a construction of\nliftings of closed comprehension categories from given (underlying) closed\ncomprehension categories and posetal fibrations for predicate logic. We give\nsufficient conditions to lift structures such as dependent products, dependent\nsums, computational effects, and recursion from the underlying type systems to\nrefinement type systems. We demonstrate the usage of our construction by giving\nsemantics to a refinement type system and proving soundness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:04:44 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kura", "Satoshi", ""]]}, {"id": "2010.08288", "submitter": "Pierre Ohlmann", "authors": "Marcin Jurdzi\\'nski, R\\'emi Morvan, Pierre Ohlmann and K. S.\n  Thejaswini", "title": "A symmetric attractor-decomposition lifting algorithm for parity games", "comments": "30 pages, including 10 pages of appendix and 5 figures. Submitted to\n  FoSSaCS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress-measure lifting algorithms for solving parity games have the best\nworst-case asymptotic runtime, but are limited by their asymmetric nature, and\nknown from the work of Czerwi\\'nski et al. (2018) to be subject to a matching\nquasi-polynomial lower bound inherited from the combinatorics of universal\ntrees. Parys (2019) has developed an ingenious quasi-polynomial McNaughton-\nZielonka-style algorithm, and Lehtinen et al. (2019) have improved its\nworst-case runtime. Jurdzi\\'nski and Morvan (2020) have recently brought\nforward a generic attractor-based algorithm, formalizing a second class of\nquasi-polynomial solutions to solving parity games, which have runtime\nquadratic in the size of universal trees. First, we adapt the framework of\niterative lifting algorithms to computing attractor-based strategies. Second,\nwe design a symmetric lifting algorithm in this setting, in which two lifting\niterations, one for each player, accelerate each other in a recursive fashion.\nThe symmetric algorithm performs at least as well as progress-measure liftings\nin the worst-case, whilst bypassing their inherent asymmetric limitation.\nThirdly, we argue that the behaviour of the generic attractor-based algorithm\nof Jurdzinski and Morvan (2020) can be reproduced by a specific deceleration of\nour symmetric lifting algorithm, in which some of the information collected by\nthe algorithm is repeatedly discarded. This yields a novel interpretation of\nMcNaughton-Zielonka-style algorithms as progress-measure lifting iterations\n(with deliberate set-backs), further strengthening the ties between all known\nquasi-polynomial algorithms to date.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:27:39 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Jurdzi\u0144ski", "Marcin", ""], ["Morvan", "R\u00e9mi", ""], ["Ohlmann", "Pierre", ""], ["Thejaswini", "K. S.", ""]]}, {"id": "2010.08337", "submitter": "Chad Nester", "authors": "Chad Nester", "title": "A Foundation for Ledger Structures", "comments": "15 pages, many figures", "journal-ref": "2nd International Conference on Blockchain Economics, Security and\n  Protocols (Tokenomics 2020) OASIcs, Volume 82, pages 7:1-7:13", "doi": "10.4230/OASIcs.Tokenomics.2020.7", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an approach to constructing ledger structures for\ncryptocurrency systems with basic category theory. Compositional theories of\nresource convertibility allow us to express the material history of virtual\ngoods, and ownership is modelled by a free construction. Our notion of\nownership admits an intuitive graphical representation through string diagrams\nfor monoidal functors.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 12:08:49 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 14:21:50 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Nester", "Chad", ""]]}, {"id": "2010.08352", "submitter": "Alexander Gheorghiu", "authors": "Alexander Gheorghiu and Sonia Marin", "title": "Focused Proof-search in the Logic of Bunched Implications", "comments": "18 pages content", "journal-ref": "FoSSaCs 2020", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The logic of Bunched Implications (BI) freely combines additive and\nmultiplicative connectives, including implications; however, despite its\nwell-studied proof theory, proof-search in BI has always been a difficult\nproblem. The focusing principle is a restriction of the proof-search space that\ncan capture various goal-directed proof-search procedures. In this paper, we\nshow that focused proof-search is complete for BI by first reformulating the\ntraditional bunched sequent calculus using the simpler data-structure of nested\nsequents, following with a polarised and focused variant that we show is sound\nand complete via a cut-elimination argument. This establishes an operational\nsemantics for focused proof-search in the logic of Bunched Implications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 12:39:14 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 10:38:58 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Gheorghiu", "Alexander", ""], ["Marin", "Sonia", ""]]}, {"id": "2010.08382", "submitter": "Luc Segoufin", "authors": "Arnaud Durand, Nicole Schweikardt, Luc Segoufin", "title": "Enumerating Answers to First-Order Queries over Databases of Low Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of relational databases has low degree if for all $\\delta>0$, all but\nfinitely many databases in the class have degree at most $n^{\\delta}$, where\n$n$ is the size of the database. Typical examples are databases of bounded\ndegree or of degree bounded by $\\log n$.\n  It is known that over a class of databases having low degree, first-order\nboolean queries can be checked in pseudo-linear time, i.e. for all $\\epsilon>0$\nin time bounded by $n^{1+\\epsilon}$. We generalize this result by considering\nquery evaluation.\n  We show that counting the number of answers to a query can be done in\npseudo-linear time and that after a pseudo-linear time preprocessing we can\ntest in constant time whether a given tuple is a solution to a query or\nenumerate the answers to a query ith constant delay.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 13:33:34 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Durand", "Arnaud", ""], ["Schweikardt", "Nicole", ""], ["Segoufin", "Luc", ""]]}, {"id": "2010.08599", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling and Robert Harper", "title": "Logical Relations as Types: Proof-Relevant Parametricity for Program\n  Modules", "comments": "To appear, J.ACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of program modules is of interest to language designers not only\nfor its practical importance to programming, but also because it lies at the\nnexus of three fundamental concerns in language design: the phase distinction,\ncomputational effects, and type abstraction. We contribute a fresh \"synthetic\"\ntake on program modules that treats modules as the fundamental constructs, in\nwhich the usual suspects of prior module calculi (kinds, constructors, dynamic\nprograms) are rendered as derived notions in terms of a modal type-theoretic\naccount of the phase distinction. We simplify the account of type abstraction\n(embodied in the generativity of module functors) through a lax modality that\nencapsulates computational effects. Our main result is a (significant)\nproof-relevant and phase-sensitive generalization of the Reynolds abstraction\ntheorem for a calculus of program modules, based on a new kind of logical\nrelation called a parametricity structure. Parametricity structures generalize\nthe proof-irrelevant relations of classical parametricity to proof-relevant\nfamilies, where there may be non-trivial evidence witnessing the relatedness of\ntwo programs -- simplifying the metatheory of strong sums over the collection\nof types, for although there can be no \"relation classifying relations\", one\neasily accommodates a \"family classifying small families\". Using the insight\nthat logical relations/parametricity is itself a form of phase distinction\nbetween the syntactic and the semantic, we contribute a new synthetic approach\nto phase separated parametricity based on the slogan \"logical relations as\ntypes\", iterating our modal account of the phase distinction. Then, to\nconstruct a simulation between two implementations of an abstract type, one\nsimply programs a third implementation whose type component carries the\nrepresentation invariant.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:37:17 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 16:05:15 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 14:33:04 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Sterling", "Jonathan", ""], ["Harper", "Robert", ""]]}, {"id": "2010.08938", "submitter": "Xiaoshuang Chen", "authors": "Xiaoshuang Chen, Longbin Lai, Lu Qin, Xuemin Lin, and Boge Liu", "title": "A Framework to Quantify Approximate Simulation on Graph Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation and its variants (e.g., bisimulation and degree-preserving\nsimulation) are useful in a wide spectrum of applications. However, all\nsimulation variants are coarse \"yes-or-no\" indicators that simply confirm or\nrefute whether one node simulates another, which limits the scope and power of\ntheir utility. Therefore, it is meaningful to develop a fractional\n$\\chi$-simulation measure to quantify the degree to which one node simulates\nanother by the simulation variant $\\chi$. To this end, we first present several\nproperties necessary for a fractional $\\chi$-simulation measure. Then, we\npresent $FSim_\\chi$, a general fractional $\\chi$-simulation computation\nframework that can be configured to quantify the extent of all\n$\\chi$-simulations. Comprehensive experiments and real-world case studies show\nthe measure to be effective and the computation framework to be efficient.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 08:12:30 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Xiaoshuang", ""], ["Lai", "Longbin", ""], ["Qin", "Lu", ""], ["Lin", "Xuemin", ""], ["Liu", "Boge", ""]]}, {"id": "2010.09452", "submitter": "Joe Townsend Dr", "authors": "Joe Townsend, Theodoros Kasioumis and Hiroya Inakoshi", "title": "ERIC: Extracting Relations Inferred from Convolutions", "comments": "Accepted for poster presentation at ACCV (Asian Conference on\n  Computer Vision) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main contribution is to show that the behaviour of kernels across\nmultiple layers of a convolutional neural network can be approximated using a\nlogic program. The extracted logic programs yield accuracies that correlate\nwith those of the original model, though with some information loss in\nparticular as approximations of multiple layers are chained together or as\nlower layers are quantised. We also show that an extracted program can be used\nas a framework for further understanding the behaviour of CNNs. Specifically,\nit can be used to identify key kernels worthy of deeper inspection and also\nidentify relationships with other kernels in the form of the logical rules.\nFinally, we make a preliminary, qualitative assessment of rules we extract from\nthe last convolutional layer and show that kernels identified are symbolic in\nthat they react strongly to sets of similar images that effectively divide\noutput classes into sub-classes with distinct characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:04:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Townsend", "Joe", ""], ["Kasioumis", "Theodoros", ""], ["Inakoshi", "Hiroya", ""]]}, {"id": "2010.09471", "submitter": "Balasubramanian A.R", "authors": "A. R. Balasubramanian, Javier Esparza, Mikhail Raskin", "title": "Finding Cut-Offs in Leaderless Rendez-Vous Protocols is Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In rendez-vous protocols an arbitrarily large number of indistinguishable\nfinite-state agents interact in pairs. The cut-off problem asks if there exists\na number $B$ such that all initial configurations of the protocol with at least\n$B$ agents in a given initial state can reach a final configuration with all\nagents in a given final state. In a recent paper (Horn and Sangnier, CONCUR\n2020), Horn and Sangnier prove that the cut-off problem is equivalent to the\nPetri net reachability problem for protocols with a leader, and in EXPSPACE for\nleaderless protocols. Further, for the special class of symmetric protocols\nthey reduce these bounds to PSPACE and NP, respectively. The problem of\nlowering these upper bounds or finding matching lower bounds is left open. We\nshow that the cut-off problem is P-complete for leaderless protocols,\nNP-complete for symmetric protocols with a leader, and in NC for leaderless\nsymmetric protocols, thereby solving all the problems left open in (Horn and\nSangnier, CONCUR 2020).\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:10:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Balasubramanian", "A. R.", ""], ["Esparza", "Javier", ""], ["Raskin", "Mikhail", ""]]}, {"id": "2010.09645", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "On the Parallel Composition for True Concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For insight into the parallel composition for true concurrency, we recall the\naxiomatization of the parallel composition modulo truly concurrent behavioral\nequivalences as the sidelights of truly concurrent process algebra APTC. We\nprove that: (1) There is a finite sound and complete axiomatization of the\nparallel composition modulo pomset, step and hp-bisimulations, without any\nauxiliary operators. (2) There does not exist a finite sound and complete\naxiomatization of the parallel composition modulo hhp-bisimulation, without any\nauxiliary operator. (3) There is a finite sound and complete axiomatization of\nthe parallel composition modulo pomset, step, hp-. and hhp-bisimulations, with\nthe auxiliary left parallel composition and communication merge.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 15:20:07 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "2010.09646", "submitter": "Aritra Sarkar", "authors": "Aritra Sarkar", "title": "Quines are the fittest programs: Nesting algorithmic probability\n  converges to constructors", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article we explore the limiting behavior of the universal prior\ndistribution applied over multiple meta-level hierarchy of program and output\ndata of a Turing machine. We were motivated to reduce the effect of\nSolomonoff's assumption that all computable functions/hypothesis of the same\nlength are equally likely, by weighing each program in turn by the algorithmic\nprobability of their description number encoding. In the limiting case we\nconverge the set of all possible program strings of a fixed-length to a\ndistribution of self-replicating quines and quine-relays - having the structure\nof a constructor. We discuss how experimental algorithmic information theory\nprovides insights towards understanding the fundamental metrics proposed in\nthis work and reflect on the significance of these result in the constructor\ntheory of life.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 13:36:08 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sarkar", "Aritra", ""]]}, {"id": "2010.09821", "submitter": "Jason Parker", "authors": "Jason Parker", "title": "Isotropy and Combination Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper, the author and his collaborators studied the phenomenon\nof isotropy in the context of single-sorted equational theories, and showed\nthat the isotropy group of the category of models of any such theory encodes a\nnotion of inner automorphism for the theory.\n  Using results from the treatment of combination problems in term rewriting\ntheory, we show in this article that if $\\mathbb{T}_1$ and $\\mathbb{T}_2$ are\n(disjoint) equational theories satisfying minimal assumptions, then any free,\nfinitely generated model of the disjoint union theory $\\mathbb{T}_1 +\n\\mathbb{T}_2$ has trivial isotropy group, and hence the only inner\nautomorphisms of such models, i.e. the only automorphisms of such models that\nare coherently extendible, are the identity automorphisms.\n  As a corollary, we show that the global isotropy group of the category of\nmodels $(\\mathbb{T}_1 + \\mathbb{T}_2)\\mathsf{mod}$, i.e. the group of\ninvertible elements of the centre of this category, is the trivial group.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:59:45 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Parker", "Jason", ""]]}, {"id": "2010.09919", "submitter": "Alexey Ignatiev", "authors": "Jinqiang Yu, Alexey Ignatiev, Pierre Le Bodic, Peter J. Stuckey", "title": "Optimal Decision Lists using SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision lists are one of the most easily explainable machine learning\nmodels. Given the renewed emphasis on explainable machine learning decisions,\nthis machine learning model is increasingly attractive, combining small size\nand clear explainability. In this paper, we show for the first time how to\nconstruct optimal \"perfect\" decision lists which are perfectly accurate on the\ntraining data, and minimal in size, making use of modern SAT solving\ntechnology. We also give a new method for determining optimal sparse decision\nlists, which trade off size and accuracy. We contrast the size and test\naccuracy of optimal decisions lists versus optimal decision sets, as well as\nother state-of-the-art methods for determining optimal decision lists. We also\nexamine the size of average explanations generated by decision sets and\ndecision lists.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:33:42 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Yu", "Jinqiang", ""], ["Ignatiev", "Alexey", ""], ["Bodic", "Pierre Le", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2010.10069", "submitter": "Mario Rom\\'an", "authors": "Elena Di Lavore, Alessandro Gianola, Mario Rom\\'an, Nicoletta\n  Sabadini, Pawe{\\l} Soboci\\'nski", "title": "A canonical algebra of open transition systems", "comments": "18 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedback and state are closely interrelated concepts. Categories with\nfeedback, originally proposed by Katis, Sabadini and Walters, are a weakening\nof the notion of traced monoidal categories, with several pertinent\napplications in computer science. The construction of the free such categories\nhas appeared in several different contexts, and can be considered as state\nbootstrapping. We show that a categorical algebra for open transition systems,\n$\\mathbf{Span}(\\mathbf{Graph})_\\ast$, also due to Katis, Sabadini and Walters,\nis the free category with feedback over $\\mathbf{Span}(\\mathbf{Set})$.\n  Intuitively, this algebra of transition systems is obtained by adding state\nto an algebra of predicates, and therefore $\\mathbf{Span}(\\mathbf{Graph})_\\ast$\nis, in this sense, the canonical such algebra.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 06:57:40 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Di Lavore", "Elena", ""], ["Gianola", "Alessandro", ""], ["Rom\u00e1n", "Mario", ""], ["Sabadini", "Nicoletta", ""], ["Soboci\u0144ski", "Pawe\u0142", ""]]}, {"id": "2010.10129", "submitter": "Thomas Sturm", "authors": "Niclas Kruff, Christoph L\\\"uders, Ovidiu Radulescu, Thomas Sturm,\n  Sebastian Walcher", "title": "Algorithmic Reduction of Biological Networks With Multiple Time Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LO cs.SC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a symbolic algorithmic approach that allows to compute invariant\nmanifolds and corresponding reduced systems for differential equations modeling\nbiological networks which comprise chemical reaction networks for cellular\nbiochemistry, and compartmental models for pharmacology, epidemiology and\necology. Multiple time scales of a given network are obtained by scaling, based\non tropical geometry. Our reduction is mathematically justified within a\nsingular perturbation setting. The existence of invariant manifolds is subject\nto hyperbolicity conditions, for which we propose an algorithmic test based on\nHurwitz criteria. We finally obtain a sequence of nested invariant manifolds\nand respective reduced systems on those manifolds. Our theoretical results are\ngenerally accompanied by rigorous algorithmic descriptions suitable for direct\nimplementation based on existing off-the-shelf software systems, specifically\nsymbolic computation libraries and Satisfiability Modulo Theories solvers. We\npresent computational examples taken from the well-known BioModels database\nusing our own prototypical implementations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 08:48:09 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 17:47:20 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kruff", "Niclas", ""], ["L\u00fcders", "Christoph", ""], ["Radulescu", "Ovidiu", ""], ["Sturm", "Thomas", ""], ["Walcher", "Sebastian", ""]]}, {"id": "2010.10296", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "SeLFiE: Modular Semantic Reasoning for Induction in Isabelle/HOL", "comments": "under review at the 23rd International Symposium on Practical Aspects\n  of Declarative Languages (PADL) 2021. arXiv admin note: substantial text\n  overlap with arXiv:2009.09215", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof assistants offer tactics to apply proof by induction, but these tactics\nrely on inputs given by human engineers. We address this problem withSeLFiE, a\ndomain-specific language to encode experienced users' expertise on how to apply\nthe induct tactic in Isabelle/HOL: when we apply an induction heuristic written\nin SeLFiE to an inductive problem and arguments to the induct tactic, the\nSeLFiE interpreter examines both the syntactic structure of the problem and\nsemantics of the relevant constants to judge whether the arguments to the\ninduct tactic are plausible for that problem according to the heuristic. SeLFiE\nfacilitates the intricate interaction between syntactic and semantic analyses\nusing semantic constructs while maintaining the modularity of each analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:05:09 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2010.10724", "submitter": "Jeffrey M. Dudek", "authors": "Jeffrey M. Dudek, Dror Fried, Kuldeep S. Meel", "title": "Taming Discrete Integration via the Boon of Dimensionality", "comments": "To be published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete integration is a fundamental problem in computer science that\nconcerns the computation of discrete sums over exponentially large sets.\nDespite intense interest from researchers for over three decades, the design of\nscalable techniques for computing estimates with rigorous guarantees for\ndiscrete integration remains the holy grail. The key contribution of this work\naddresses this scalability challenge via an efficient reduction of discrete\nintegration to model counting. The proposed reduction is achieved via a\nsignificant increase in the dimensionality that, contrary to conventional\nwisdom, leads to solving an instance of the relatively simpler problem of model\ncounting.\n  Building on the promising approach proposed by Chakraborty et al, our work\novercomes the key weakness of their approach: a restriction to dyadic weights.\nWe augment our proposed reduction, called DeWeight, with a state of the art\nefficient approximate model counter and perform detailed empirical analysis\nover benchmarks arising from neural network verification domains, an emerging\napplication area of critical importance. DeWeight, to the best of our\nknowledge, is the first technique to compute estimates with provable guarantees\nfor this class of benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 02:32:51 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Fried", "Dror", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2010.10912", "submitter": "Daniel Hausmann", "authors": "Daniel Hausmann, Stefan Milius and Lutz Schr\\\"oder", "title": "Harnessing LTL With Freeze Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logics and automata models for languages over infinite alphabets, such as\nFreeze LTL and register automata, serve the verification of processes or\ndocuments with data. They relate tightly to formalisms over nominal sets, such\nas nondetermininistic orbit-finite automata (NOFAs), where names play the role\nof data. Reasoning problems in such formalisms tend to be computationally hard.\nName-binding nominal automata models such as regular nondeterministic automata\n(RNNAs) have been shown to be computationally more tractable. In the present\npaper, we introduce a linear-time logic Bar-muTL for finite words over an\ninfinite alphabet, which features full negation and freeze quantification via\nname binding. We show by reduction to extended regular nondeterministic nominal\nautomata that even though Bar-muTL allows liveness constraints, unrestricted\nnondeterminism, and unboundedly many registers, model checking Bar-muTL over\nRNNAs and satisfiability checking both have elementary complexity. E.g., model\nchecking is in ExpSpace, more precisely in parametrized PSpace, effectively\nwith the number of registers as the parameter.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 11:48:33 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 12:51:36 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 18:24:17 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hausmann", "Daniel", ""], ["Milius", "Stefan", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "2010.11342", "submitter": "David Darais", "authors": "Mat\\'ias Toro, David Darais, Chike Abuah, Joe Near, Federico Olmedo,\n  \\'Eric Tanter", "title": "Contextual Linear Types for Differential Privacy", "comments": "Journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language support for differentially-private programming is both crucial and\ndelicate. While elaborate program logics can be very expressive, type-system\nbased approaches using linear types tend to be more lightweight and amenable to\nautomatic checking and inference, and in particular in the presence of\nhigher-order programming. Since the seminal design of Fuzz, which is restricted\nto ${\\epsilon}$-differential privacy, a lot of effort has been made to support\nmore advanced variants of differential privacy, like\n$({\\epsilon},{\\delta})$-differential privacy. However, no existing type system\nsupports these advanced privacy variants while also supporting higher-order\nprogramming in full generality. We present Jazz, a language and type system\nwhich uses linear types and latent contextual effects to support both advanced\nvariants of differential privacy and higher order programming . Even when\navoiding advanced variants and higher order programming, our system achieves\nhigher precision than prior work for a large class of programming patterns. We\nformalize the core of the Jazz language, prove it sound for privacy via a\nlogical relation for metric preservation, and illustrate its expressive power\nthrough a number of case studies drawn from the recent differential privacy\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 23:01:50 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Toro", "Mat\u00edas", ""], ["Darais", "David", ""], ["Abuah", "Chike", ""], ["Near", "Joe", ""], ["Olmedo", "Federico", ""], ["Tanter", "\u00c9ric", ""]]}, {"id": "2010.11503", "submitter": "Jean Christoph Jung", "authors": "Thomas Gogacz, V\\'ictor Guti\\'errez-Basulto, Yazm\\'in\n  Ib\\'a\\~nez-Garc\\'ia, Jean Christoph Jung, Filip Murlak", "title": "On Finite and Unrestricted Query Entailment beyond SQ with Number\n  Restrictions on Transitive Roles", "comments": "Full version of a paper accepted at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the description logic SQ with number restrictions applicable to\ntransitive roles, extended with either nominals or inverse roles. We show tight\n2EXPTIME upper bounds for unrestricted entailment of regular path queries for\nboth extensions and finite entailment of positive existential queries for\nnominals. For inverses, we establish 2EXPTIME-completeness for unrestricted and\nfinite entailment of instance queries (the latter under restriction to a\nsingle, transitive role).\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 07:44:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gogacz", "Thomas", ""], ["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazm\u00edn", ""], ["Jung", "Jean Christoph", ""], ["Murlak", "Filip", ""]]}, {"id": "2010.11605", "submitter": "Jens Oliver Gutsfeld", "authors": "Jens Oliver Gutsfeld, Markus M\\\"uller-Olm and Christoph Ohrem", "title": "Automata and Fixpoints for Asynchronous Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties have received increasing attention in the last decade due to\ntheir importance e.g. for security analyses. Past approaches have focussed on\nsynchronous analyses, i.e. techniques in which different paths are compared\nlockstepwise. In this paper, we systematically study asynchronous analyses for\nhyperproperties by introducing both a novel automata model (Alternating\nAsynchronous Parity Automata) and the temporal fixpoint calculus $\\Hmu$, the\nfirst fixpoint calculus that can systematically express hyperproperties in an\nasynchronous manner and at the same time subsumes the existing logic HyperLTL.\nWe show that the expressive power of both models coincides over fixed path\nassignments. The high expressive power of both models is evidenced by the fact\nthat decision problems of interest are highly undecidable, i.e. not even\narithmetical. As a remedy, we propose approximative analyses for both models\nthat also induce natural decidable fragments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 11:06:16 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gutsfeld", "Jens Oliver", ""], ["M\u00fcller-Olm", "Markus", ""], ["Ohrem", "Christoph", ""]]}, {"id": "2010.11762", "submitter": "Tobias Reinhard", "authors": "Tobias Reinhard, Bart Jacobs", "title": "Ghost Signals: Verifying Termination of Busy-Waiting (Extended Version)", "comments": "68 pages; 42 figures; Simplified logic by removing permissions and\n  updated soundness proof in appendix. Simplified the logic's presentation.\n  Added case studies to appendix.; This is the extended version of a paper\n  which is to be published at CAV21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs for multiprocessor machines commonly perform busy waiting for\nsynchronization. We propose the first separation logic for modularly verifying\ntermination of such programs under fair scheduling. Our logic requires the\nproof author to associate a ghost signal with each busy-waiting loop and allows\nsuch loops to iterate while their corresponding signal $s$ is not set. The\nproof author further has to define a well-founded order on signals and to prove\nthat if the looping thread holds an obligation to set a signal $s^\\prime$, then\n$s^\\prime$ is ordered above $s$. By using conventional shared state invariants\nto associate the state of ghost signals with the state of data structures,\nprograms busy-waiting for arbitrary conditions over arbitrary data structures\ncan be verified.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:33:35 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 10:28:18 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Reinhard", "Tobias", ""], ["Jacobs", "Bart", ""]]}, {"id": "2010.11842", "submitter": "Carsten Lutz", "authors": "Pierre Bourhis and Carsten Lutz", "title": "Containment in Monadic Disjunctive Datalog, MMSNP, and Expressive\n  Description Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study query containment in three closely related formalisms: monadic\ndisjunctive Datalog (MDDLog), MMSNP (a logical generalization of constraint\nsatisfaction problems), and ontology-mediated queries (OMQs) based on\nexpressive description logics and unions of conjunctive queries. Containment in\nMMSNP was known to be decidable due to a result by Feder and Vardi, but its\nexact complexity has remained open. We prove 2NEXPTIME-completeness and extend\nthis result to monadic disjunctive Datalog and to OMQs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:25:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Bourhis", "Pierre", ""], ["Lutz", "Carsten", ""]]}, {"id": "2010.12182", "submitter": "Moritz Lichter", "authors": "Moritz Lichter and Pascal Schweitzer", "title": "Canonization for Bounded and Dihedral Color Classes in Choiceless\n  Polynomial Time", "comments": "To appear at CSL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest for a logic capturing PTime the next natural classes of\nstructures to consider are those with bounded color class size. We present a\ncanonization procedure for graphs with dihedral color classes of bounded size\nin the logic of Choiceless Polynomial Time (CPT), which then captures PTime on\nthis class of structures. This is the first result of this form for non-abelian\ncolor classes. The first step proposes a normal form which comprises a \"rigid\nassemblage\". This roughly means that the local automorphism groups form\n2-injective 3-factor subdirect products. Structures with color classes of\nbounded size can be reduced canonization preservingly to normal form in CPT. In\nthe second step, we show that for graphs in normal form with dihedral color\nclasses of bounded size, the canonization problem can be solved in CPT. We also\nshow the same statement for general ternary structures in normal form if the\ndihedral groups are defined over odd domains.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 06:27:00 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Lichter", "Moritz", ""], ["Schweitzer", "Pascal", ""]]}, {"id": "2010.12452", "submitter": "Sebastiaan Terwijn", "authors": "Paul Shafer and Sebastiaan A. Terwijn", "title": "Ordinal analysis of partial combinatory algebras", "comments": null, "journal-ref": null, "doi": "10.1017/jsl.2021.50", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For every partial combinatory algebra (pca), we define a hierarchy of\nextensionality relations using ordinals. We investigate the closure ordinals of\npca's, i.e.\\ the smallest ordinals where these relations become equal. We show\nthat the closure ordinal of Kleene's first model is $\\OCK$ and that the closure\nordinal of Kleene's second model is~$\\omega_1$. We calculate the exact\ncomplexities of the extensionality relations in Kleene's first model, showing\nthat they exhaust the hyperarithmetical hierarchy. We also discuss embeddings\nof pca's.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 14:46:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Shafer", "Paul", ""], ["Terwijn", "Sebastiaan A.", ""]]}, {"id": "2010.12504", "submitter": "Masahiro Sato", "authors": "Masahiro Sato and Jacques Garrigue", "title": "An Intuitionistic Set-theoretical Model of Fully Dependent CC{\\omega}", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Werner's set-theoretical model is one of the simplest models of CIC. It\ncombines a functional view of predicative universes with a collapsed view of\nthe impredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle holds. Following our previous work, we interpret\nProp into a topological space (a special case of Heyting algebra) to make the\nmodel more intuitionistic without sacrificing simplicity. We improve on that\nwork by providing a full interpretation of dependent product types, using\nAlexandroff spaces. We also extend our approach to inductive types by adding\nsupport for lists.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 16:11:48 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sato", "Masahiro", ""], ["Garrigue", "Jacques", ""]]}, {"id": "2010.12619", "submitter": "Alexander Rader", "authors": "Alexander Philipp Rader, Ionela G. Mocanu, Vaishak Belle and Brendan\n  Juba", "title": "Learning Implicitly with Noisy Data in Linear Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustly learning in expressive languages with real-world data continues to\nbe a challenging task. Numerous conventional methods appeal to heuristics\nwithout any assurances of robustness. While PAC-Semantics offers strong\nguarantees, learning explicit representations is not tractable even in a\npropositional setting. However, recent work on so-called \"implicit\" learning\nhas shown tremendous promise in terms of obtaining polynomial-time results for\nfragments of first-order logic. In this work, we extend implicit learning in\nPAC-Semantics to handle noisy data in the form of intervals and threshold\nuncertainty in the language of linear arithmetic. We prove that our extended\nframework keeps the existing polynomial-time complexity guarantees.\nFurthermore, we provide the first empirical investigation of this hitherto\npurely theoretical framework. Using benchmark problems, we show that our\nimplicit approach to learning optimal linear programming objective constraints\nsignificantly outperforms an explicit approach in practice.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:08:46 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Rader", "Alexander Philipp", ""], ["Mocanu", "Ionela G.", ""], ["Belle", "Vaishak", ""], ["Juba", "Brendan", ""]]}, {"id": "2010.12686", "submitter": "Frantisek Farka", "authors": "Franti\\v{s}ek Farka, Aleksandar Nanevski, Anindya Banerjee, Germ\\'an\n  Andr\\'es Delbianco, Ignacio F\\'abregas", "title": "On Algebraic Abstractions for Concurrent Separation Logics", "comments": "35 pages", "journal-ref": "Proc. ACM Program. Lang. 5, POPL, Article 5 (January 2021)", "doi": "10.1145/3434286", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent separation logic is distinguished by transfer of state ownership\nupon parallel composition and framing. The algebraic structure that underpins\nownership transfer is that of partial commutative monoids (PCMs). Extant\nresearch considers ownership transfer primarily from the logical perspective\nwhile comparatively less attention is drawn to the algebraic considerations.\nThis paper provides an algebraic formalization of ownership transfer in\nconcurrent separation logic by means of structure-preserving partial functions\n(i.e., morphisms) between PCMs, and an associated notion of separating\nrelations. Morphisms of structures are a standard concept in algebra and\ncategory theory, but haven't seen ubiquitous use in separation logic before.\nSeparating relations are binary relations that generalize disjointness and\ncharacterize the inputs on which morphisms preserve structure. The two\nabstractions facilitate verification by enabling concise ways of writing specs,\nby providing abstract views of threads' states that are preserved under\nownership transfer, and by enabling user-level construction of new PCMs out of\nexisting ones.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 22:06:12 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 11:06:02 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 19:37:31 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Farka", "Franti\u0161ek", ""], ["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""], ["Delbianco", "Germ\u00e1n Andr\u00e9s", ""], ["F\u00e1bregas", "Ignacio", ""]]}, {"id": "2010.12689", "submitter": "Claudia Faggian", "authors": "Ugo Dal Lago, Claudia Faggian, Simona Ronchi Della Rocca", "title": "Intersection Types and (Positive) Almost-Sure Termination", "comments": null, "journal-ref": "Proc. ACM Program. Lang. 5, POPL (2021)", "doi": "10.1145/3434313", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized higher-order computation can be seen as being captured by a lambda\ncalculus endowed with a single algebraic operation, namely a construct for\nbinary probabilistic choice. What matters about such computations is the\nprobability of obtaining any given result, rather than the possibility or the\nnecessity of obtaining it, like in (non)deterministic computation. Termination,\narguably the simplest kind of reachability problem, can be spelled out in at\nleast two ways, depending on whether it talks about the probability of\nconvergence or about the expected evaluation time, the second one providing a\nstronger guarantee. In this paper, we show that intersection types are capable\nof precisely characterizing both notions of termination inside a single system\nof types: the probability of convergence of any lambda-term can be\nunderapproximated by its type, while the underlying derivation's weight gives a\nlower bound to the term's expected number of steps to normal form. Noticeably,\nboth approximations are tight -- not only soundness but also completeness\nholds. The crucial ingredient is non-idempotency, without which it would be\nimpossible to reason on the expected number of reduction steps which are\nnecessary to completely evaluate any term. Besides, the kind of approximation\nwe obtain is proved to be optimal recursion theoretically: no recursively\nenumerable formal system can do better than that.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 22:17:08 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 11:22:50 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Faggian", "Claudia", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "2010.12892", "submitter": "Christoph Haase", "authors": "Christoph Haase and Jakub R\\'o\\.zycki", "title": "On the Expressiveness of B\\\"uchi Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the existential fragment of B\\\"uchi arithmetic is strictly less\nexpressive than full B\\\"uchi arithmetic of any base, and moreover establish\nthat its $\\Sigma_2$-fragment is already expressively complete. Furthermore, we\nshow that regular languages of polynomial growth are definable in the\nexistential fragment of B\\\"uchi arithmetic.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 12:39:27 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 15:02:07 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 23:49:48 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Haase", "Christoph", ""], ["R\u00f3\u017cycki", "Jakub", ""]]}, {"id": "2010.12896", "submitter": "Loizos Michael", "authors": "Antonis Kakas, Loizos Michael", "title": "Abduction and Argumentation for Explainable Machine Learning: A Position\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Abduction and Argumentation as two principled forms for\nreasoning, and fleshes out the fundamental role that they can play within\nMachine Learning. It reviews the state-of-the-art work over the past few\ndecades on the link of these two reasoning forms with machine learning work,\nand from this it elaborates on how the explanation-generating role of Abduction\nand Argumentation makes them naturally-fitting mechanisms for the development\nof Explainable Machine Learning and AI systems. Abduction contributes towards\nthis goal by facilitating learning through the transformation, preparation, and\nhomogenization of data. Argumentation, as a conservative extension of classical\ndeductive reasoning, offers a flexible prediction and coverage mechanism for\nlearning -- an associated target language for learned knowledge -- that\nexplicitly acknowledges the need to deal, in the context of learning, with\nuncertain, incomplete and inconsistent data that are incompatible with any\nclassically-represented logical theory.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 13:23:44 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kakas", "Antonis", ""], ["Michael", "Loizos", ""]]}, {"id": "2010.12988", "submitter": "Gabriele Vanoni", "authors": "Beniamino Accattoli and Ugo Dal Lago and Gabriele Vanoni", "title": "The (In)Efficiency of Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating higher-order functional programs through abstract machines\ninspired by the geometry of the interaction is known to induce $\\textit{space}$\nefficiencies, the price being $\\textit{time}$ performances often poorer than\nthose obtainable with traditional, environment-based, abstract machines.\nAlthough families of lambda-terms for which the former is exponentially less\nefficient than the latter do exist, it is currently unknown how \\emph{general}\nthis phenomenon is, and how far the inefficiencies can go, in the worst case.\nWe answer these questions formulating four different well-known abstract\nmachines inside a common definitional framework, this way being able to give\nsharp results about the relative time efficiencies. We also prove that\nnon-idempotent intersection type theories are able to precisely reflect the\ntime performances of the interactive abstract machine, this way showing that\nits time-inefficiency ultimately descends from the presence of higher-order\ntypes.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 21:11:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Lago", "Ugo Dal", ""], ["Vanoni", "Gabriele", ""]]}, {"id": "2010.13096", "submitter": "Yong Kiam Tan", "authors": "Yong Kiam Tan and Andr\\'e Platzer", "title": "Deductive Stability Proofs for Ordinary Differential Equations", "comments": "Long version of paper at TACAS 2021 (27th International Conference on\n  Tools and Algorithms for the Construction and Analysis of Systems, 27 Mar - 1\n  Apr 2021)", "journal-ref": null, "doi": "10.1007/978-3-030-72013-1_10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability is required for real world controlled systems as it ensures that\nthose systems can tolerate small, real world perturbations around their desired\noperating states. This paper shows how stability for continuous systems modeled\nby ordinary differential equations (ODEs) can be formally verified in\ndifferential dynamic logic (dL). The key insight is to specify ODE stability by\nsuitably nesting the dynamic modalities of dL with first-order logic\nquantifiers. Elucidating the logical structure of stability properties in this\nway has three key benefits: i) it provides a flexible means of formally\nspecifying various stability properties of interest, ii) it yields rigorous\nproofs of those stability properties from dL's axioms with dL's ODE safety and\nliveness proof principles, and iii) it enables formal analysis of the\nrelationships between various stability properties which, in turn, inform\nproofs of those properties. These benefits are put into practice through an\nimplementation of stability proofs for several examples in KeYmaera X, a hybrid\nsystems theorem prover based on dL.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 11:36:38 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 16:37:56 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 14:57:04 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Tan", "Yong Kiam", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2010.13163", "submitter": "Benjamin Moon", "authors": "Benjamin Moon, Harley Eades III, Dominic Orchard", "title": "Graded Modal Dependent Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graded type theories are an emerging paradigm for augmenting the reasoning\npower of types with parameterizable, fine-grained analyses of program\nproperties. There have been many such theories in recent years which equip a\ntype theory with quantitative dataflow tracking, usually via a semiring-like\nstructure which provides analysis on variables (often called `quantitative' or\n`coeffect' theories). We present Graded Modal Dependent Type Theory (GrTT for\nshort), which equips a dependent type theory with a general, parameterizable\nanalysis of the flow of data, both in and between computational terms and\ntypes. In this theory, it is possible to study, restrict, and reason about data\nuse in programs and types, enabling, for example, parametric quantifiers and\nlinearity to be captured in a dependent setting. We propose GrTT, study its\nmetatheory, and explore various case studies of its use in reasoning about\nprograms and studying other type theories. We have implemented the theory and\nhighlight the interesting details, including showing an application of grading\nto optimising the type checking procedure itself.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 17:01:16 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 14:15:09 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Moon", "Benjamin", ""], ["Eades", "Harley", "III"], ["Orchard", "Dominic", ""]]}, {"id": "2010.13326", "submitter": "Samson Abramsky", "authors": "Samson Abramsky", "title": "Classical logic, classical probability, and quantum mechanics", "comments": "15 pages. arXiv admin note: text overlap with arXiv:1705.07918", "journal-ref": "The Work and Influence of Itamar Pitowsky, ed. Meir Hemmo and Orly\n  Shenker, Springer Nature, pages 1--17, 2020", "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an overview and conceptual discussion of some of our results on\ncontextuality and non-locality. We focus in particular on connections with the\nwork of Itamar Pitowsky on correlation polytopes, Bell inequalities, and\nBoole's \"conditions of possible experience\".\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 16:20:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Abramsky", "Samson", ""]]}, {"id": "2010.13328", "submitter": "Samson Abramsky", "authors": "Samson Abramsky", "title": "Whither Semantics?", "comments": "Appeared in special issue of TCS in honour of Maurice Nivat. arXiv\n  admin note: text overlap with arXiv:1806.09031, arXiv:2010.06496", "journal-ref": "Theoretical Computer Science, vol. 807, pages 3--14, 2020", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how mathematical semantics has evolved, and suggest some new\ndirections for future work. As an example, we discuss some recent work on\nencapsulating model comparison games as comonads, in the context of finite\nmodel theory.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:13:36 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Abramsky", "Samson", ""]]}, {"id": "2010.13566", "submitter": "Tim Quatmann", "authors": "Tim Quatmann and Joost-Pieter Katoen", "title": "Multi-objective Optimization of Long-run Average and Total Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient procedure for multi-objective model checking\nof long-run average reward (aka: mean pay-off) and total reward objectives as\nwell as their combination. We consider this for Markov automata, a\ncompositional model that captures both traditional Markov decision processes\n(MDPs) as well as a continuous-time variant thereof. The crux of our procedure\nis a generalization of Forejt et al.'s approach for total rewards on MDPs to\narbitrary combinations of long-run and total reward objectives on Markov\nautomata. Experiments with a prototypical implementation on top of the Storm\nmodel checker show encouraging results for both model types and indicate a\nsubstantial improved performance over existing multi-objective long-run MDP\nmodel checking based on linear programming.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 13:17:47 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 08:45:10 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Quatmann", "Tim", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2010.13707", "submitter": "Dami\\'an Aparicio S\\'anchez", "authors": "Dami\\'an Aparicio-S\\'anchez, Santiago Escobar, Catherine Meadows, Jose\n  Meseguer, Julia Sapi\\~na", "title": "Protocol Analysis with Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework suited to the analysis of cryptographic protocols that\nmake use of time in their execution. We provide a process algebra syntax that\nmakes time information available to processes, and a transition semantics that\ntakes account of fundamental properties of time. Additional properties can be\nadded by the user if desirable. This timed protocol framework can be\nimplemented either as a simulation tool or as a symbolic analysis tool in which\ntime references are represented by logical variables, and in which the\nproperties of time are implemented as constraints on those time logical\nvariables. These constraints are carried along the symbolic execution of the\nprotocol. The satisfiability of these constraints can be evaluated as the\nanalysis proceeds, so attacks that violate the laws of physics can be rejected\nas impossible. We demonstrate the feasibility of our approach by using the\nMaude-NPA protocol analyzer together with an SMT solver that is used to\nevaluate the satisfiability of timing constraints. We provide a sound and\ncomplete protocol transformation from our timed process algebra to the\nMaude-NPA syntax and semantics, and we prove its soundness and completeness. We\nthen use the tool to analyze Mafia fraud and distance hijacking attacks on a\nsuite of distance-bounding protocols.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:48:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Aparicio-S\u00e1nchez", "Dami\u00e1n", ""], ["Escobar", "Santiago", ""], ["Meadows", "Catherine", ""], ["Meseguer", "Jose", ""], ["Sapi\u00f1a", "Julia", ""]]}, {"id": "2010.13925", "submitter": "Alceste Scalas", "authors": "Silvia Ghilezan, Jovanka Pantovi\\'c, Ivan Proki\\'c, Alceste Scalas,\n  Nobuko Yoshida", "title": "Precise Subtyping for Asynchronous Multiparty Sessions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents the first formalisation of the precise subtyping relation\nfor asynchronous multiparty sessions. We show that our subtyping relation is\nsound (i.e., guarantees safe process replacement) and also complete: any\nextension of the relation is unsound. To achieve our results, we develop a\nnovel session decomposition technique, from full session types (including\ninternal/external choices) into single input/output session trees (without\nchoices). Previous work studies precise subtyping for binary sessions (with\njust two participants), or multiparty sessions (with any number of\nparticipants) and synchronous interaction. Here, we cover multiparty sessions\nwith asynchronous interaction, where messages are transmitted via FIFO queues\n(as in the TCP/IP protocol), and prove that our subtyping is both operationally\nand denotationally precise. In the asynchronous multiparty setting, finding the\nprecise subtyping relation is a highly complex task: this is because, under\nsome conditions, participants can permute the order of their inputs and\noutputs, by sending some messages earlier or receiving some later, without\ncausing errors; the precise subtyping relation must capture all such valid\npermutations -- and consequently, its formalisation, reasoning and proofs\nbecome challenging. Our session decomposition technique overcomes this\ncomplexity, expressing the subtyping relation as a composition of refinement\nrelations between single input/output trees, and providing a simple reasoning\nprinciple for asynchronous message optimisations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 22:08:46 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ghilezan", "Silvia", ""], ["Pantovi\u0107", "Jovanka", ""], ["Proki\u0107", "Ivan", ""], ["Scalas", "Alceste", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "2010.13926", "submitter": "Zesen Qian", "authors": "Zesen Qian, G. A. Kavvos, Lars Birkedal", "title": "Client-Server Sessions in Linear Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce coexponentials, a new set of modalities for Classical Linear\nLogic. As duals to exponentials, the coexponentials codify a distributed form\nof the structural rules of weakening and contraction. This makes them a\nsuitable logical device for encapsulating the pattern of a server receiving\nrequests from an arbitrary number of clients on a single channel. Guided by\nthis intuition we formulate a system of session types based on Classical Linear\nLogic with coexponentials, which is suited to modelling client-server\ninteractions. We also present a session-typed functional programming language\nfor server-client programming, which we translate to our system of\ncoexponentials.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 22:12:53 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 19:37:00 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Qian", "Zesen", ""], ["Kavvos", "G. A.", ""], ["Birkedal", "Lars", ""]]}, {"id": "2010.14032", "submitter": "Robert Sison", "authors": "Robert Sison (1 and 2 and 3), Toby Murray (1) ((1) University of\n  Melbourne, (2) CSIRO's Data61, (3) UNSW Sydney)", "title": "Verified Secure Compilation for Mixed-Sensitivity Concurrent Programs", "comments": "Submitted to the Journal of Functional Programming Special Issue on\n  Secure Compilation. Some errors in the submitted manuscript's description of\n  Lemma 5.25 have been corrected. This paper expands on its conference version\n  arXiv:1907.00713. For supplement material, see http://covern.org/jfpsc.html", "journal-ref": null, "doi": "10.1017/S0956796821000162", "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proving only over source code that programs do not leak sensitive data leaves\na gap between reasoning and reality that can only be filled by accounting for\nthe behaviour of the compiler. Furthermore, software does not always have the\nluxury of limiting itself to single-threaded computation with resources\nstatically dedicated to each user to ensure the confidentiality of their data.\nThis results in mixed-sensitivity concurrent programs, which might reuse memory\nshared between their threads to hold data of different sensitivity levels at\ndifferent times; for such programs, a compiler must preserve the\nvalue-dependent coordination of such mixed-sensitivity reuse despite the impact\nof concurrency.\n  Here we demonstrate, using Isabelle/HOL, that it is feasible to verify that a\ncompiler preserves noninterference, the strictest kind of confidentiality\nproperty, for mixed-sensitivity concurrent programs. First, we present notions\nof refinement that preserve a concurrent value-dependent notion of\nnoninterference that we have designed to support such programs. As proving\nnoninterference-preserving refinement can be considerably more complex than the\nstandard refinements typically used to verify semantics -- preserving\ncompilation, our notions include a decomposition principle that separates the\nsemantics -- from the security-preservation concerns. Second, we demonstrate\nthat these refinement notions are applicable to verified secure compilation, by\nexercising them on a single-pass compiler for mixed-sensitivity concurrent\nprograms that synchronise using mutex locks, from a generic imperative language\nto a generic RISC-style assembly language. Finally, we execute our compiler on\na nontrivial mixed-sensitivity concurrent program modelling a real-world use\ncase, thus preserving its source-level noninterference properties down to an\nassembly-level model automatically.\n  (See paper for complete abstract.)\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 03:24:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Sison", "Robert", "", "1 and 2 and 3"], ["Murray", "Toby", ""]]}, {"id": "2010.14166", "submitter": "Rafa\\\"el Bocquet", "authors": "Rafa\\\"el Bocquet", "title": "Coherence of strict equalities in dependent type theories", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the coherence and conservativity of extensions of dependent type\ntheories by additional strict equalities. By considering notions of congruences\nand quotients of models of type theory, we reconstruct Hofmann's proof of the\nconservativity of Extensional Type Theory over Intensional Type Theory. We\ngeneralize these methods to type theories without the Uniqueness of Identity\nProofs principle, such as variants of Homotopy Type Theory, by introducing a\nnotion of higher congruence over models of type theory. Our definition of\nhigher congruence is inspired by Brunerie's type-theoretic definition of weak\n$\\infty$-groupoid. For a large class of type theories, we reduce the problem of\nthe conservativity of equational extensions to more tractable acyclicity\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 09:51:30 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Bocquet", "Rafa\u00ebl", ""]]}, {"id": "2010.14299", "submitter": "Laurent Bartholdi", "authors": "Laurent Bartholdi, Ville Salo", "title": "Simulations and the Lamplighter group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO math.GR math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of \"simulation\" for labelled graphs, in which edges of\nthe simulated graph are realized by regular expressions in the simulating\ngraph, and prove that the tiling problem (aka \"domino problem\") for the\nsimulating graph is at least as difficult as that for the simulated graph.\n  We apply this to the Cayley graph of the \"lamplighter group\" $L=\\mathbb\nZ/2\\wr\\mathbb Z$, and more generally to \"Diestel-Leader graphs\". We prove that\nthese graphs simulate the plane, and thus deduce that the seeded tiling problem\nis unsolvable on the group $L$.\n  We note that $L$ does not contain any plane in its Cayley graph, so our\nundecidability criterion by simulation covers cases not covered by Jeandel's\ncriterion based on translation-like action of a product of finitely generated\ninfinite groups.\n  Our approach to tiling problems is strongly based on categorical\nconstructions in graph theory.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:00:56 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Bartholdi", "Laurent", ""], ["Salo", "Ville", ""]]}, {"id": "2010.14430", "submitter": "Clemens Kupke", "authors": "Clemens Kupke and Johannes Marti and Yde Venema", "title": "Size matters in the modal $\\mu$-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss and compare complexity measures for the modal $\\mu$-calculus,\nfocusing on size and alternation depth. As a yardstick we take Wilke's\nalternating tree automata, which we shall call parity formulas in the text.\nBuilding on work by Bruse, Friedmann & Lange, we compare two size measures for\n$\\mu$-calculus formulas: subformula-size,i.e. , the number of subformulas of\nthe given formula, and closure-size. These notions correspond to the\nrepresentation of a formula as a parity formula based on, respectively, its\nsubformula dag, and its closure graph. What distinguishes our approach is that\nwe are explicit about the role of alpha-equivalence, as naively renaming bound\nvariables can lead to an exponential blow-up. In addition, we match the\nformula's alternation depth with the index of the parity formula. We start in a\nsetting without alpha-equivalence. We define subformula-size and closure-size\nand recall that a $\\mu$-calculus formula can be transformed into a parity\nformula of size linear wrt subformula size, and give a construction that\ntransforms a $\\mu$-calculus formula into an equivalent parity formula linear\nwrt closure-size. Conversely, there is a standard transformation producing a\n$\\mu$-calculus formula of exponential subformula -- but linear closure-size in\nterms of the size of the original parity formula. We identify so-called\nuntwisted parity formulas for which a transformation linear in subformula-size\nexists. We then introduce size notions that are completely invariant under\nalpha equivalence. We transfer the result of Bruse et alii, showing that also\nin our setting closure-size can be exponentially smaller than subformula-size.\nWe also show how to rename bound variables so that alpha-equivalence becomes\nsyntactic identity on the closure set. Finally, we review the complexity of\nguarded transformations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 16:43:52 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kupke", "Clemens", ""], ["Marti", "Johannes", ""], ["Venema", "Yde", ""]]}, {"id": "2010.14432", "submitter": "Edon Kelmendi", "authors": "Shaull Almagor, Toghrul Karimov, Edon Kelmendi, J\\\"oel Ouaknine, James\n  Worrell", "title": "Deciding $\\omega$-Regular Properties on Linear Recurrence Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of deciding $\\omega$-regular properties on infinite\ntraces produced by linear loops. Here we think of a given loop as producing a\nsingle infinite trace that encodes information about the signs of program\nvariables at each time step. Formally, our main result is a procedure that\ninputs a prefix-independent $\\omega$-regular property and a sequence of numbers\nsatisfying a linear recurrence, and determines whether the sign description of\nthe sequence (obtained by replacing each positive entry with \"$+$\", each\nnegative entry with \"$-$\", and each zero entry with \"$0$\") satisfies the given\nproperty. Our procedure requires that the recurrence be simple, \\ie, that the\nupdate matrix of the underlying loop be diagonalisable. This assumption is\ninstrumental in proving our key technical lemma: namely that the sign\ndescription of a simple linear recurrence sequence is almost periodic in the\nsense of Muchnik, Sem\\\"enov, and Ushakov. To complement this lemma, we give an\nexample of a linear recurrence sequence whose sign description fails to be\nalmost periodic. Generalising from sign descriptions, we also consider the\nverification of properties involving semi-algebraic predicates on program\nvariables.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 16:49:14 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Almagor", "Shaull", ""], ["Karimov", "Toghrul", ""], ["Kelmendi", "Edon", ""], ["Ouaknine", "J\u00f6el", ""], ["Worrell", "James", ""]]}, {"id": "2010.14548", "submitter": "Kevin Batz", "authors": "Kevin Batz, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph\n  Matheja", "title": "Relatively Complete Verification of Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a syntax for specifying quantitative \"assertions\" - functions\nmapping program states to numbers - for probabilistic program verification. We\nprove that our syntax is expressive in the following sense: Given any\nprobabilistic program $C$, if a function $f$ is expressible in our syntax, then\nthe function mapping each initial state $\\sigma$ to the expected value of $f$\nevaluated in the final states reached after termination of $C$ on $\\sigma$\n(also called the weakest preexpectation $\\textit{wp} [C](f)$) is also\nexpressible in our syntax.\n  As a consequence, we obtain a relatively complete verification system for\nreasoning about expected values and probabilities in the sense of Cook: Apart\nfrom proving a single inequality between two functions given by syntactic\nexpressions in our language, given $f$, $g$, and $C$, we can check whether $g\n\\preceq \\textit{wp} [C] (f)$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 18:37:46 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Batz", "Kevin", ""], ["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Matheja", "Christoph", ""]]}, {"id": "2010.14549", "submitter": "Gia Wulandari", "authors": "Gia Wulandari, Detlef Plump", "title": "Verifying Graph Programs with First-Order Logic (Extended Version)", "comments": "Extended version of a paper to appear at GCM 2020 post-proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Hoare-style verification for the graph programming language GP 2.\nIn previous work, graph properties were specified by so-called E-conditions\nwhich extend nested graph conditions. However, this type of assertions is not\neasy to comprehend by programmers that are used to formal specifications in\nstandard first-order logic. In this paper, we present an approach to verify GP\n2 programs with a standard first-order logic. We show how to construct a\nstrongest liberal postcondition with respect to a rule schema and a\nprecondition. We then extend this construction to obtain strongest liberal\npostconditions for arbitrary loop-free programs. Compared with previous work,\nthis allows to reason about a vastly generalised class of graph programs. In\nparticular, many programs with nested loops can be verified with the new\ncalculus.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 18:38:50 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:27:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wulandari", "Gia", ""], ["Plump", "Detlef", ""]]}, {"id": "2010.14648", "submitter": "Mohammad Abdulaziz", "authors": "Mohammad Abdulaziz and Friedrich Kurz", "title": "Formally Verified SAT-Based AI Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an executable formally verified SAT encoding of classical AI\nplanning. We use the theorem prover Isabelle/HOL to perform the verification.\nWe experimentally test the verified encoding and show that it can be used for\nreasonably sized standard planning benchmarks. We also use it as a reference to\ntest a state-of-the-art SAT-based planner, showing that it sometimes falsely\nclaims that problems have no solutions of certain lengths.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:23:04 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 12:19:38 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 09:43:28 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 18:21:00 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Abdulaziz", "Mohammad", ""], ["Kurz", "Friedrich", ""]]}, {"id": "2010.14814", "submitter": "Jan Dreier", "authors": "Jan Dreier and Peter Rossmanith", "title": "Approximate Evaluation of First-Order Counting Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kuske and Schweikardt introduced the very expressive first-order counting\nlogic FOC(P) to model database queries with counting operations. They showed\nthat there is an efficient model-checking algorithm on graphs with bounded\ndegree, while Grohe and Schweikardt showed that probably no such algorithm\nexists for trees of bounded depth.\n  We analyze the fragment FO({>0}) of this logic. While we remove for example\nsubtraction and comparison between two non-atomic counting terms, this logic\nremains quite expressive: We allow nested counting and comparison between\ncounting terms and arbitrarily large numbers. Our main result is an\napproximation scheme of the model-checking problem for FO({>0}) that runs in\nlinear fpt time on structures with bounded expansion. This scheme either gives\nthe correct answer or says \"I do not know.\" The latter answer may only be given\nif small perturbations in the number-symbols of the formula could make it both\nsatisfied and unsatisfied. This is complemented by showing that exactly solving\nthe model-checking problem for FO({>0}) is already hard on trees of bounded\ndepth and just slightly increasing the expressiveness of FO({>0}) makes even\napproximation hard on trees.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 08:42:03 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Dreier", "Jan", ""], ["Rossmanith", "Peter", ""]]}, {"id": "2010.14891", "submitter": "Mayuko Kori", "authors": "Mayuko Kori, Takeshi Tsukada and Naoki Kobayashi", "title": "A Cyclic Proof System for HFLN", "comments": "27 pages", "journal-ref": null, "doi": "10.4230/LIPIcs.CSL.2021.29", "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cyclic proof system allows us to perform inductive reasoning without\nexplicit inductions. We propose a cyclic proof system for HFLN, which is a\nhigher-order predicate logic with natural numbers and alternating fixed-points.\nOurs is the first cyclic proof system for a higher-order logic, to our\nknowledge. Due to the presence of higher-order predicates and alternating\nfixed-points, our cyclic proof system requires a more delicate global condition\non cyclic proofs than the original system of Brotherston and Simpson. We prove\nthe decidability of checking the global condition and soundness of this system,\nand also prove a restricted form of standard completeness for an infinitary\nvariant of our cyclic proof system. A potential application of our cyclic proof\nsystem is semi-automated verification of higher-order programs, based on\nKobayashi et al.'s recent work on reductions from program verification to HFLN\nvalidity checking.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 11:19:53 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 02:17:08 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kori", "Mayuko", ""], ["Tsukada", "Takeshi", ""], ["Kobayashi", "Naoki", ""]]}, {"id": "2010.14949", "submitter": "Zuhair Al-Johar Dr.", "authors": "Zuhair Al-Johar, M. Randall Holmes (University of Baghdad, Baghdad,\n  Iraq, Boise State University, Boise-Idaho, USA)", "title": "Acyclic Comprehension is equal to Stratified Comprehension", "comments": "4 pages. This is a copy of the original proof, written in LaTeX, of\n  that result before another proof of it was published in Notre Dame Journal of\n  Formal Logic by the same authors together with Nathan Bowler", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new criterion of comprehension is defined, initially termed by myself as\n\"connected\" and finally as \"Acyclic\" by Mr. Randall Holmes. Acyclic\ncomprehension simply asserts that for any acyclic formula phi, the set {x:phi}\nexists. I first presented this criterion semi-formally to Mr. Randall Holmes,\nwho further made the first rigorous definition of it, a definition that I\nfinally simplified to the one presented here. Later Mr. Holmes made another\npresentation of the definition which is also mentioned here. He pointed to me\nthat acyclic comprehension is implied by stratification, and posed the question\nas to whether it is equivalent to full stratification or strictly weaker. He\nand initially I myself thought that it was strictly weaker; Mr. Randall Holmes\nactually conjectured that it is very weak. Surprisingly it turned to be\nequivalent to full stratification as I proved here\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:07:21 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Al-Johar", "Zuhair", "", "University of Baghdad, Baghdad,\n  Iraq, Boise State University, Boise-Idaho, USA"], ["Holmes", "M. Randall", "", "University of Baghdad, Baghdad,\n  Iraq, Boise State University, Boise-Idaho, USA"]]}, {"id": "2010.15030", "submitter": "Jonas Kastberg Hinrichsen", "authors": "Jonas Kastberg Hinrichsen, Jesper Bengtson and Robbert Krebbers", "title": "Actris 2.0: Asynchronous Session-Type Based Reasoning in Separation\n  Logic", "comments": "52 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Message passing is a useful abstraction for implementing concurrent programs.\nFor real-world systems, however, it is often combined with other programming\nand concurrency paradigms, such as higher-order functions, mutable state,\nshared-memory concurrency, and locks. We present Actris: a logic for proving\nfunctional correctness of programs that use a combination of the aforementioned\nfeatures. Actris combines the power of modern concurrent separation logics with\na first-class protocol mechanism---based on session types---for reasoning about\nmessage passing in the presence of other concurrency paradigms. We show that\nActris provides a suitable level of abstraction by proving functional\ncorrectness of a variety of examples, including a distributed merge sort, a\ndistributed load-balancing mapper, and a variant of the map-reduce model, using\nconcise specifications. While Actris was already presented in a conference\npaper (POPL'20), this paper expands the prior presentation significantly.\nMoreover, it extends Actris to Actris 2.0 with a notion of subprotocols---based\non session-type subtyping---that permits additional flexibility when composing\nchannel endpoints, and that takes full advantage of the asynchronous semantics\nof message passing in Actris. Soundness of Actris 2.0 is proved using a model\nof its protocol mechanism in the Iris framework. We have mechanised the theory\nof Actris, together with custom tactics, as well as all examples in the paper,\nin the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 15:06:50 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Hinrichsen", "Jonas Kastberg", ""], ["Bengtson", "Jesper", ""], ["Krebbers", "Robbert", ""]]}, {"id": "2010.15490", "submitter": "Jean-Simon Lemay", "authors": "Robin Cockett and Jean-Simon Pacaud Lemay", "title": "Linearizing Combinators", "comments": "V2 - Fixed some typos. Again, a big thanks to Kristine Bauer for\n  reading over our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2017, Bauer, Johnson, Osborne, Riehl, and Tebbe (BJORT) showed that the\nAbelian functor calculus provides an example of a Cartesian differential\ncategory. The definition of a Cartesian differential category is based on a\ndifferential combinator which directly formalizes the total derivative from\nmultivariable calculus. However, in the aforementioned work the authors used\ntechniques from Goodwillie's functor calculus to establish a linearization\nprocess from which they then derived a differential combinator. This raised the\nquestion of what the precise relationship between linearization and having a\ndifferential combinator might be.\n  In this paper, we introduce the notion of a linearizing combinator which\nabstracts linearization in the Abelian functor calculus. We then use it to\nprovide an alternative axiomatization of a Cartesian differential category.\nEvery Cartesian differential category comes equipped with a canonical\nlinearizing combinator obtained by differentiation at zero. Conversely, a\ndifferential combinator can be constructed \\`a la BJORT when one has a system\nof partial linearizing combinators in each context. Thus, while linearizing\ncombinators do provide an alternative axiomatization of Cartesian differential\ncategories, an explicit notion of partial linearization is required. This is in\ncontrast to the situation for differential combinators where partial\ndifferentiation is automatic in the presence of total differentiation. The\nability to form a system of partial linearizing combinators from a total\nlinearizing combinator, while not being possible in general, is possible when\nthe setting is Cartesian closed.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 11:17:10 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 22:04:04 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Cockett", "Robin", ""], ["Lemay", "Jean-Simon Pacaud", ""]]}, {"id": "2010.15596", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Verification of Patterns", "comments": "189 pages, 100 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software patterns provide building blocks to the design and\nimplementation of a software system, and try to make the software engineering\nto progress from experience to science. The software patterns were made famous\nbecause of the introduction as the design patterns. After that, patterns have\nbeen researched and developed widely and rapidly. The series of books of\npattern-oriented software architecture should be marked in the development of\nsoftware patterns. As mentioned in these books, formalization of patterns and\nan intermediate pattern language are needed and should be developed in the\nfuture of patterns. So, in this book, we formalize software patterns according\nto the categories of the series of books of pattern-oriented software\narchitecture, and verify the correctness of patterns based on truly concurrent\nprocess algebra. In one aspect, patterns are formalized and verified; in the\nother aspect, truly concurrent process algebra can play a role of an\nintermediate pattern language for its rigorous theory.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 14:39:33 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 17:35:50 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "2010.15600", "submitter": "Ciro Garcia Mr", "authors": "Ciro Ivan Garcia Lopez", "title": "Three computational models and its equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.CL cs.GL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of computability has its origin in Hilbert's conference of 1900,\nwhere an adjacent question, to the ones he asked, is to give a precise\ndescription of the notion of algorithm. In the search for a good definition\narose three independent theories: Turing and the Turing machines, G\\\"odel and\nthe recursive functions, Church and the Lambda Calculus.\n  Later there were established by Kleene that the classic models of computation\nare equivalent. This fact is widely accepted by many textbooks and the proof is\nomitted since the proof is tedious and unreadable. We intend to fill this gap\npresenting the proof in a modern way, without forgetting the mathematical\ndetails.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 05:55:19 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Lopez", "Ciro Ivan Garcia", ""]]}, {"id": "2010.15975", "submitter": "Anthony Widjaja Lin", "authors": "Lukas Holik, Petr Janku, Anthony W. Lin, Philipp R\\\"ummer, Tomas\n  Vojnar", "title": "String Constraints with Concatenation and Transducers Solved Efficiently\n  (Technical Report)", "comments": "Full version of POPL'18 published paper with all proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String analysis is the problem of reasoning about how strings are manipulated\nby a program. It has numerous applications including automatic detection of\ncross-site scripting (XSS). A popular string analysis technique includes\nsymbolic executions, which at their core use string (constraint) solvers. Such\nsolvers typically reason about constraints expressed in theories over strings\nwith the concatenation operator as an atomic constraint. In recent years,\nresearchers started to recognise the importance of incorporating the\nreplace-all operator and finite transductions in the theories of strings with\nconcatenation. Such string operations are typically crucial for reasoning about\nXSS vulnerabilities in web applications, especially for modelling sanitisation\nfunctions and implicit browser transductions (e.g. innerHTML).\n  In this paper, we provide the first string solver that can reason about\nconstraints involving both concatenation and finite transductions. Moreover, it\nhas a completeness and termination guarantee for several important fragments\n(e.g. straight-line fragment). The main challenge addressed in the paper is the\nprohibitive worst-case complexity of the theory. To this end, we propose a\nmethod that exploits succinct alternating finite automata as concise symbolic\nrepresentations of string constraints. Alternation offers not only exponential\nsavings in space when representing Boolean combinations of transducers, but\nalso a possibility of succinct representation of otherwise costly combinations\nof transducers and concatenation. Reasoning about the emptiness of the AFA\nlanguage requires a state-space exploration in an exponential-sized graph, for\nwhich we use model checking algorithms (e.g. IC3). We have implemented our\nalgorithm and demonstrated its efficacy on benchmarks that are derived from XSS\nand other examples in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 22:33:34 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Holik", "Lukas", ""], ["Janku", "Petr", ""], ["Lin", "Anthony W.", ""], ["R\u00fcmmer", "Philipp", ""], ["Vojnar", "Tomas", ""]]}, {"id": "2010.16013", "submitter": "EPTCS", "authors": "Mauricio Ayala-Rinc\\'on (Universidade de Bras\\'ilia), Thaynara Arielly\n  de Lima (Universidade Federal de Goi\\'as)", "title": "Teaching Interactive Proofs to Mathematicians", "comments": "In Proceedings ThEdu'20, arXiv:2010.15832", "journal-ref": "EPTCS 328, 2020, pp. 1-17", "doi": "10.4204/EPTCS.328.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work discusses an approach to teach to mathematicians the importance and\neffectiveness of the application of Interactive Theorem Proving tools in their\nspecific fields of interest. The approach aims to motivate the use of such\ntools through short courses. In particular, it is discussed how, using as\ncase-of-study algebraic notions and properties, the use of the proof assistant\nPrototype Verification System PVS is promoted to interest mathematicians in the\ndevelopment of their mechanized proofs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 01:14:44 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ayala-Rinc\u00f3n", "Mauricio", "", "Universidade de Bras\u00edlia"], ["de Lima", "Thaynara Arielly", "", "Universidade Federal de Goi\u00e1s"]]}, {"id": "2010.16014", "submitter": "EPTCS", "authors": "Asta Halkj{\\ae}r From (Technical University of Denmark), J{\\o}rgen\n  Villadsen (Technical University of Denmark), Patrick Blackburn (Roskilde\n  University)", "title": "Isabelle/HOL as a Meta-Language for Teaching Logic", "comments": "In Proceedings ThEdu'20, arXiv:2010.15832", "journal-ref": "EPTCS 328, 2020, pp. 18-34", "doi": "10.4204/EPTCS.328.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof assistants are important tools for teaching logic. We support this\nclaim by discussing three formalizations in Isabelle/HOL used in a recent\ncourse on automated reasoning. The first is a formalization of System W (a\nsystem of classical propositional logic with only two primitive symbols), the\nsecond is the Natural Deduction Assistant (NaDeA), and the third is a one-sided\nsequent calculus that uses our Sequent Calculus Verifier (SeCaV). We describe\neach formalization in turn, concentrating on how we used them in our teaching,\nand commenting on features that are interesting or useful from a logic\neducation perspective. In the conclusion, we reflect on the lessons learned and\nwhere they might lead us next.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 01:15:00 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["From", "Asta Halkj\u00e6r", "", "Technical University of Denmark"], ["Villadsen", "J\u00f8rgen", "", "Technical University of Denmark"], ["Blackburn", "Patrick", "", "Roskilde\n  University"]]}, {"id": "2010.16015", "submitter": "EPTCS", "authors": "Filip Mari\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Sana Stojanovi\\'c-{\\Dj}ur{\\dj}evi\\'c (Faculty of Mathematics,\n  University of Belgrade, Serbia)", "title": "Formalizing IMO Problems and Solutions in Isabelle/HOL", "comments": "In Proceedings ThEdu'20, arXiv:2010.15832", "journal-ref": "EPTCS 328, 2020, pp. 35-55", "doi": "10.4204/EPTCS.328.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The International Mathematical Olympiad (IMO) is perhaps the most celebrated\nmental competition in the world and as such is among the greatest grand\nchallenges for Artificial Intelligence (AI). The IMO Grand Challenge, recently\nformulated, requires to build an AI that can win a gold medal in the\ncompetition. We present some initial steps that could help to tackle this goal\nby creating a public repository of mechanically checked solutions of IMO\nProblems in the interactive theorem prover Isabelle/HOL. This repository is\nactively maintained by students of the Faculty of Mathematics, University of\nBelgrade, Serbia within the course \"Introduction to Interactive Theorem\nProving\".\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 01:15:19 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Mari\u0107", "Filip", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Stojanovi\u0107-{\\Dj}ur\u0111evi\u0107", "Sana", "", "Faculty of Mathematics,\n  University of Belgrade, Serbia"]]}, {"id": "2010.16111", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (LSV,ENS Paris Saclay)", "title": "Type safety of rewrite rules in dependent types", "comments": null, "journal-ref": "5th International Conference on Formal Structures for Computation\n  and Deduction (FSCD 2020), Jun 2020, Paris, France. pp.14", "doi": "10.4230/LIPIcs.FSCD.2020.13", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressiveness of dependent type theory can be extended by identifying\ntypes modulo some additional computation rules. But, for preserving the\ndecidability of type-checking or the logical consistency of the system, one\nmust make sure that those user-defined rewriting rules preserve typing. In this\npaper, we give a new method to check that property using Knuth-Bendix\ncompletion.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 08:06:21 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "LSV,ENS Paris Saclay"]]}, {"id": "2010.16217", "submitter": "Katrin Schulz", "authors": "Fausto Barbero and Katrin Schulz and Sonja Smets and Fernando R.\n  Vel\\'azquez-Quesada and Kaibo Xie", "title": "Thinking About Causation: A Causal Language with Epistemic Operators", "comments": "This is the long version of a paper that is to be published in the\n  post-proceedings of the 3rd Dali Workshop on Dynamic Logic: New Trends and\n  Applications. The post-proceedings will be published by Springer as a Lecture\n  Notes in Computer Science volume", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a formal framework for modeling the interaction of causal\nand (qualitative) epistemic reasoning. To this purpose, we extend the notion of\na causal model with a representation of the epistemic state of an agent. On the\nside of the object language, we add operators to express knowledge and the act\nof observing new information. We provide a sound and complete axiomatization of\nthe logic, and discuss the relation of this framework to causal team semantics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:16:45 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Barbero", "Fausto", ""], ["Schulz", "Katrin", ""], ["Smets", "Sonja", ""], ["Vel\u00e1zquez-Quesada", "Fernando R.", ""], ["Xie", "Kaibo", ""]]}, {"id": "2010.16345", "submitter": "Alastair Reid", "authors": "Alastair Reid, Luke Church, Shaked Flur, Sarah de Haas, Maritza\n  Johnson, Ben Laurie", "title": "Towards making formal methods normal: meeting developers where they are", "comments": "To be presented at HATRA 2020: Human Aspects of Types and Reasoning\n  Assistants, 15-20 November, 2020, Chicago, IL. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Formal verification of software is a bit of a niche activity: it is only\napplied to the most safety-critical or security-critical software and it is\ntypically only performed by specialized verification engineers. This paper\nconsiders whether it would be possible to increase adoption of formal methods\nby integrating formal methods with developers' existing practices and\nworkflows.\n  We do not believe that widespread adoption will follow from making the\nprevailing formal methods argument that correctness is more important than\nengineering teams realize. Instead, our focus is on what we would need to do to\nenable programmers to make effective use of formal verification tools and\ntechniques. We do this by considering how we might make verification tooling\nthat both serves developers' needs and fits into their existing development\nlifecycle. We propose a target of two orders of magnitude increase in adoption\nwithin a decade driven by ensuring a positive `weekly cost-benefit' ratio for\ndeveloper time invested.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 16:05:00 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Reid", "Alastair", ""], ["Church", "Luke", ""], ["Flur", "Shaked", ""], ["de Haas", "Sarah", ""], ["Johnson", "Maritza", ""], ["Laurie", "Ben", ""]]}]