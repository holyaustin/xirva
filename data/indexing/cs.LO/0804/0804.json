[{"id": "0804.0066", "submitter": "Peter Schachte", "authors": "Kevin Henshall, Peter Schachte, Harald S{\\o}ndergaard and Leigh\n  Whiting", "title": "Binary Decision Diagrams for Affine Approximation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selman and Kautz's work on ``knowledge compilation'' established how\napproximation (strengthening and/or weakening) of a propositional\nknowledge-base can be used to speed up query processing, at the expense of\ncompleteness. In this classical approach, querying uses Horn over- and\nunder-approximations of a given knowledge-base, which is represented as a\npropositional formula in conjunctive normal form (CNF). Along with the class of\nHorn functions, one could imagine other Boolean function classes that might\nserve the same purpose, owing to attractive deduction-computational properties\nsimilar to those of the Horn functions. Indeed, Zanuttini has suggested that\nthe class of affine Boolean functions could be useful in knowledge compilation\nand has presented an affine approximation algorithm. Since CNF is awkward for\npresenting affine functions, Zanuttini considers both a sets-of-models\nrepresentation and the use of modulo 2 congruence equations. In this paper, we\npropose an algorithm based on reduced ordered binary decision diagrams\n(ROBDDs). This leads to a representation which is more compact than the sets of\nmodels and, once we have established some useful properties of affine Boolean\nfunctions, a more efficient algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2008 05:08:44 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["Henshall", "Kevin", ""], ["Schachte", "Peter", ""], ["S\u00f8ndergaard", "Harald", ""], ["Whiting", "Leigh", ""]]}, {"id": "0804.0273", "submitter": "Alwen Tiu", "authors": "Alwen Tiu and Rajeev Gore", "title": "A proof theoretic analysis of intruder theories", "comments": "This is an extended version of a conference paper accepted to RTA\n  2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of intruder deduction in security protocol analysis:\nthat is, deciding whether a given message $M$ can be deduced from a set of\nmessages $\\Gamma$ under the theory of blind signatures and arbitrary convergent\nequational theories modulo associativity and commutativity (AC) of certain\nbinary operators. The traditional formulations of intruder deduction are\nusually given in natural-deduction-like systems and proving decidability\nrequires significant effort in showing that the rules are \"local\" in some\nsense. By using the well-known translation between natural deduction and\nsequent calculus, we recast the intruder deduction problem as proof search in\nsequent calculus, in which locality is immediate. Using standard proof\ntheoretic methods, such as permutability of rules and cut elimination, we show\nthat the intruder deduction problem can be reduced, in polynomial time, to the\nelementary deduction problems, which amounts to solving certain equations in\nthe underlying individual equational theories. We further show that this result\nextends to combinations of disjoint AC-convergent theories whereby the\ndecidability of intruder deduction under the combined theory reduces to the\ndecidability of elementary deduction in each constituent theory. Although\nvarious researchers have reported similar results for individual cases, our\nwork shows that these results can be obtained using a systematic and uniform\nmethodology based on the sequent calculus.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2008 00:21:27 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2009 06:52:58 GMT"}], "update_date": "2009-04-06", "authors_parsed": [["Tiu", "Alwen", ""], ["Gore", "Rajeev", ""]]}, {"id": "0804.0599", "submitter": "Joao Marques-Silva", "authors": "Joao Marques-Silva, Ines Lynce and Vasco Manquinho", "title": "Symmetry Breaking for Maximum Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": "RT/039/08-CDIL", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetries are intrinsic to many combinatorial problems including Boolean\nSatisfiability (SAT) and Constraint Programming (CP). In SAT, the\nidentification of symmetry breaking predicates (SBPs) is a well-known, often\neffective, technique for solving hard problems. The identification of SBPs in\nSAT has been the subject of significant improvements in recent years, resulting\nin more compact SBPs and more effective algorithms. The identification of SBPs\nhas also been applied to pseudo-Boolean (PB) constraints, showing that symmetry\nbreaking can also be an effective technique for PB constraints. This paper\nextends further the application of SBPs, and shows that SBPs can be identified\nand used in Maximum Satisfiability (MaxSAT), as well as in its most well-known\nvariants, including partial MaxSAT, weighted MaxSAT and weighted partial\nMaxSAT. As with SAT and PB, symmetry breaking predicates for MaxSAT and\nvariants are shown to be effective for a representative number of problem\ndomains, allowing solving problem instances that current state of the art\nMaxSAT solvers could not otherwise solve.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2008 18:19:43 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Lynce", "Ines", ""], ["Manquinho", "Vasco", ""]]}, {"id": "0804.0660", "submitter": "Luca Roversi", "authors": "Luca Roversi", "title": "Weak Affine Light Typing is complete with respect to Safe Recursion on\n  Notation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Weak affine light typing (WALT) assigns light affine linear formulae as types\nto a subset of lambda-terms of System F. WALT is poly-time sound: if a\nlambda-term M has type in WALT, M can be evaluated with a polynomial cost in\nthe dimension of the derivation that gives it a type. The evaluation proceeds\nunder any strategy of a rewriting relation which is a mix of both call-by-name\nand call-by-value beta-reductions. WALT weakens, namely generalizes, the notion\nof \"stratification of deductions\", common to some Light Systems -- those\nlogical systems, derived from Linear logic, to characterize the set of\nPolynomial functions -- . A weaker stratification allows to define a\ncompositional embedding of Safe recursion on notation (SRN) into WALT. It turns\nout that the expressivity of WALT is strictly stronger than the one of the\nknown Light Systems. The embedding passes through the representation of a\nsubsystem of SRN. It is obtained by restricting the composition scheme of SRN\nto one that can only use its safe variables linearly. On one side, this\nsuggests that SRN, in fact, can be redefined in terms of more primitive\nconstructs. On the other, the embedding of SRN into WALT enjoys the two\nfollowing remarkable aspects. Every datatype, required by the embedding, is\nrepresented from scratch, showing the strong structural proof-theoretical roots\nof WALT. Moreover, the embedding highlights a stratification structure of the\nnormal and safe arguments, normally hidden inside the world of SRN-normal/safe\nvariables: the less an argument is \"polyomially impredicative\", the deeper, in\na formal, proof-theoretical sense, it is represented inside WALT. Finally,\nsince WALT is SRN-complete it is also polynomial-time complete since SRN is.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 08:14:22 GMT"}], "update_date": "2008-04-07", "authors_parsed": [["Roversi", "Luca", ""]]}, {"id": "0804.0876", "submitter": "Andreas Abel", "authors": "Andreas Abel", "title": "Semi-continuous Sized Types and Termination", "comments": "33 pages, extended version of CSL'06", "journal-ref": "Logical Methods in Computer Science, Volume 4, Issue 2 (April 10,\n  2008) lmcs:1236", "doi": "10.2168/LMCS-4(2:3)2008", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some type-based approaches to termination use sized types: an ordinal bound\nfor the size of a data structure is stored in its type. A recursive function\nover a sized type is accepted if it is visible in the type system that\nrecursive calls occur just at a smaller size. This approach is only sound if\nthe type of the recursive function is admissible, i.e., depends on the size\nindex in a certain way. To explore the space of admissible functions in the\npresence of higher-kinded data types and impredicative polymorphism, a\nsemantics is developed where sized types are interpreted as functions from\nordinals into sets of strongly normalizing terms. It is shown that upper\nsemi-continuity of such functions is a sufficient semantic criterion for\nadmissibility. To provide a syntactical criterion, a calculus for\nsemi-continuous functions is developed.\n", "versions": [{"version": "v1", "created": "Sat, 5 Apr 2008 22:27:29 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2008 15:26:49 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Abel", "Andreas", ""]]}, {"id": "0804.1033", "submitter": "Christoph Schommer", "authors": "Sviatlana Danilava, Christoph Schommer", "title": "A Semi-Automatic Framework to Discover Epistemic Modalities in\n  Scientific Articles", "comments": "18 pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Documents in scientific newspapers are often marked by attitudes and opinions\nof the author and/or other persons, who contribute with objective and\nsubjective statements and arguments as well. In this respect, the attitude is\noften accomplished by a linguistic modality. As in languages like english,\nfrench and german, the modality is expressed by special verbs like can, must,\nmay, etc. and the subjunctive mood, an occurrence of modalities often induces\nthat these verbs take over the role of modality. This is not correct as it is\nproven that modality is the instrument of the whole sentence where both the\nadverbs, modal particles, punctuation marks, and the intonation of a sentence\ncontribute. Often, a combination of all these instruments are necessary to\nexpress a modality. In this work, we concern with the finding of modal verbs in\nscientific texts as a pre-step towards the discovery of the attitude of an\nauthor. Whereas the input will be an arbitrary text, the output consists of\nzones representing modalities.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 14:13:27 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Danilava", "Sviatlana", ""], ["Schommer", "Christoph", ""]]}, {"id": "0804.1435", "submitter": "Marc de Falco", "authors": "Marc de Falco", "title": "The Geometry of Interaction of Differential Interaction Nets", "comments": "20 pagee, to be published in the proceedings of LICS08", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Geometry of Interaction purpose is to give a semantic of proofs or\nprograms accounting for their dynamics. The initial presentation, translated as\nan algebraic weighting of paths in proofnets, led to a better characterization\nof the lambda-calculus optimal reduction. Recently Ehrhard and Regnier have\nintroduced an extension of the Multiplicative Exponential fragment of Linear\nLogic (MELL) that is able to express non-deterministic behaviour of programs\nand a proofnet-like calculus: Differential Interaction Nets. This paper\nconstructs a proper Geometry of Interaction (GoI) for this extension. We\nconsider it both as an algebraic theory and as a concrete reversible\ncomputation. We draw links between this GoI and the one of MELL. As a\nby-product we give for the first time an equational theory suitable for the GoI\nof the Multiplicative Additive fragment of Linear Logic.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2008 08:57:47 GMT"}], "update_date": "2008-04-10", "authors_parsed": [["de Falco", "Marc", ""]]}, {"id": "0804.1667", "submitter": "James Cheney", "authors": "Christian Urban, James Cheney and Stefan Berghofer", "title": "Mechanizing the Metatheory of LF", "comments": "Accepted to ACM Transactions on Computational Logic. Preprint.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LF is a dependent type theory in which many other formal systems can be\nconveniently embedded. However, correct use of LF relies on nontrivial\nmetatheoretic developments such as proofs of correctness of decision procedures\nfor LF's judgments. Although detailed informal proofs of these properties have\nbeen published, they have not been formally verified in a theorem prover. We\nhave formalized these properties within Isabelle/HOL using the Nominal Datatype\nPackage, closely following a recent article by Harper and Pfenning. In the\nprocess, we identified and resolved a gap in one of the proofs and a small\nnumber of minor lacunae in others. We also formally derive a version of the\ntype checking algorithm from which Isabelle/HOL can generate executable code.\nBesides its intrinsic interest, our formalization provides a foundation for\nstudying the adequacy of LF encodings, the correctness of Twelf-style\nmetatheoretic reasoning, and the metatheory of extensions to LF.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 11:10:26 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2009 14:43:37 GMT"}, {"version": "v3", "created": "Mon, 3 May 2010 10:06:14 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Urban", "Christian", ""], ["Cheney", "James", ""], ["Berghofer", "Stefan", ""]]}, {"id": "0804.1729", "submitter": "Roberto Amadio", "authors": "Roberto Amadio (PPS), Mehdi Dogguy (PPS)", "title": "On affine usages in signal-based communication", "comments": null, "journal-ref": "Programming Languages and Systems, 6th Asian Symposium, APLAS\n  2008, France (2008)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a type system for a synchronous pi-calculus formalising the\nnotion of affine usage in signal-based communication. In particular, we\nidentify a limited number of usages that preserve affinity and that can be\ncomposed. As a main application of the resulting system, we show that typable\nprograms are deterministic.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 15:16:06 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2008 10:06:36 GMT"}, {"version": "v3", "created": "Wed, 3 Sep 2008 11:13:12 GMT"}], "update_date": "2010-07-01", "authors_parsed": [["Amadio", "Roberto", "", "PPS"], ["Dogguy", "Mehdi", "", "PPS"]]}, {"id": "0804.1879", "submitter": "Robin Adams", "authors": "Robin Adams", "title": "Lambda-Free Logical Frameworks", "comments": "v2: Mistakes were found in several proofs in v1. Several results have\n  been weakened. v3: Minor mistakes corrected and line lengths fixed. This\n  version submitted to APAL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the definition of the logical framework TF, the Type Framework. TF\nis a lambda-free logical framework; it does not include lambda-abstraction or\nproduct kinds. We give formal proofs of several results in the metatheory of\nTF, and show how it can be conservatively embedded in the logical framework LF:\nits judgements can be seen as the judgements of LF that are in beta-normal,\neta-long normal form. We show how several properties, such as adequacy theorems\nfor object theories and the injectivity of constants, can be proven more easily\nin TF, and then `lifted' to LF.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2008 11:32:51 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2008 15:55:56 GMT"}], "update_date": "2008-11-18", "authors_parsed": [["Adams", "Robin", ""]]}, {"id": "0804.2095", "submitter": "Paul Tarau", "authors": "Paul Tarau and Brenda Luderman", "title": "A Logic Programming Framework for Combinational Circuit Synthesis", "comments": null, "journal-ref": "23rd International Conference on Logic Programming (ICLP), LNCS\n  4670, 2007, pages 180-194", "doi": null, "report-no": null, "categories": "cs.LO cs.CE cs.DM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic Programming languages and combinational circuit synthesis tools share a\ncommon \"combinatorial search over logic formulae\" background. This paper\nattempts to reconnect the two fields with a fresh look at Prolog encodings for\nthe combinatorial objects involved in circuit synthesis. While benefiting from\nProlog's fast unification algorithm and built-in backtracking mechanism,\nefficiency of our search algorithm is ensured by using parallel bitstring\noperations together with logic variable equality propagation, as a mapping\nmechanism from primary inputs to the leaves of candidate Leaf-DAGs implementing\na combinational circuit specification. After an exhaustive expressiveness\ncomparison of various minimal libraries, a surprising first-runner, Strict\nBoolean Inequality \"<\" together with constant function \"1\" also turns out to\nhave small transistor-count implementations, competitive to NAND-only or\nNOR-only libraries. As a practical outcome, a more realistic circuit\nsynthesizer is implemented that combines rewriting-based simplification of\n(<,1) circuits with exhaustive Leaf-DAG circuit search.\n  Keywords: logic programming and circuit design, combinatorial object\ngeneration, exact combinational circuit synthesis, universal boolean logic\nlibraries, symbolic rewriting, minimal transistor-count circuit synthesis\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 02:40:31 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Tarau", "Paul", ""], ["Luderman", "Brenda", ""]]}, {"id": "0804.2155", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern", "title": "From Qualitative to Quantitative Proofs of Security Properties Using\n  First-Order Conditional Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A first-order conditional logic is considered, with semantics given by a\nvariant of epsilon-semantics, where p -> q means that Pr(q | p) approaches 1\nsuper-polynomially --faster than any inverse polynomial. This type of\nconvergence is needed for reasoning about security protocols. A complete\naxiomatization is provided for this semantics, and it is shown how a\nqualitative proof of the correctness of a security protocol can be\nautomatically converted to a quantitative proof appropriate for reasoning about\nconcrete security.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 12:06:04 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Halpern", "Joseph Y.", ""]]}, {"id": "0804.2401", "submitter": "Sanjiang Li", "authors": "Sanjiang Li", "title": "Causal models have no complete axiomatic characterization", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov networks and Bayesian networks are effective graphic representations\nof the dependencies embedded in probabilistic models. It is well known that\nindependencies captured by Markov networks (called graph-isomorphs) have a\nfinite axiomatic characterization. This paper, however, shows that\nindependencies captured by Bayesian networks (called causal models) have no\naxiomatization by using even countably many Horn or disjunctive clauses. This\nis because a sub-independency model of a causal model may be not causal, while\ngraph-isomorphs are closed under sub-models.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2008 14:28:34 GMT"}], "update_date": "2008-04-16", "authors_parsed": [["Li", "Sanjiang", ""]]}, {"id": "0804.2435", "submitter": "Nicolas Markey", "authors": "Francois Laroussinie, Nicolas Markey, and Ghassan Oreiby", "title": "On the Expressiveness and Complexity of ATL", "comments": "25 pages", "journal-ref": "Logical Methods in Computer Science, Volume 4, Issue 2 (May 15,\n  2008) lmcs:826", "doi": "10.2168/LMCS-4(2:7)2008", "report-no": null, "categories": "cs.LO cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ATL is a temporal logic geared towards the specification and verification of\nproperties in multi-agents systems. It allows to reason on the existence of\nstrategies for coalitions of agents in order to enforce a given property. In\nthis paper, we first precisely characterize the complexity of ATL\nmodel-checking over Alternating Transition Systems and Concurrent Game\nStructures when the number of agents is not fixed. We prove that it is\n\\Delta^P_2 - and \\Delta^P_?_3-complete, depending on the underlying multi-agent\nmodel (ATS and CGS resp.). We also consider the same problems for some\nextensions of ATL. We then consider expressiveness issues. We show how ATS and\nCGS are related and provide translations between these models w.r.t.\nalternating bisimulation. We also prove that the standard definition of ATL\n(built on modalities \"Next\", \"Always\" and \"Until\") cannot express the duals of\nits modalities: it is necessary to explicitely add the modality \"Release\".\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2008 17:18:46 GMT"}, {"version": "v2", "created": "Thu, 15 May 2008 13:13:15 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 12:50:23 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Laroussinie", "Francois", ""], ["Markey", "Nicolas", ""], ["Oreiby", "Ghassan", ""]]}, {"id": "0804.2535", "submitter": "Aleksander Wojdyga", "authors": "Aleksander Wojdyga", "title": "Short proofs of strong normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents simple, syntactic strong normalization proofs for the\nsimply-typed lambda-calculus and the polymorphic lambda-calculus (system F)\nwith the full set of logical connectives, and all the permutative reductions.\nThe normalization proofs use translations of terms and types to systems, for\nwhich strong normalization property is known.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2008 07:09:59 GMT"}], "update_date": "2008-04-17", "authors_parsed": [["Wojdyga", "Aleksander", ""]]}, {"id": "0804.2729", "submitter": "Henning Schnoor", "authors": "Edith Hemaspaandra, Henning Schnoor, Ilka Schnoor", "title": "Generalized Modal Satisfiability", "comments": "32 pages, 3 figures. Some of the results appeared in STACS 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that modal satisfiability is PSPACE-complete (Ladner 1977).\nHowever, the complexity may decrease if we restrict the set of propositional\noperators used. Note that there exist an infinite number of propositional\noperators, since a propositional operator is simply a Boolean function. We\ncompletely classify the complexity of modal satisfiability for every finite set\nof propositional operators, i.e., in contrast to previous work, we classify an\ninfinite number of problems. We show that, depending on the set of\npropositional operators, modal satisfiability is PSPACE-complete,\ncoNP-complete, or in P. We obtain this trichotomy not only for modal formulas,\nbut also for their more succinct representation using modal circuits. We\nconsider both the uni-modal and the multi-modal case, and study the dual\nproblem of validity as well.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2008 06:57:50 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Schnoor", "Henning", ""], ["Schnoor", "Ilka", ""]]}, {"id": "0804.3023", "submitter": "Abdessamad Imine", "authors": "Hanifa Boucheneb (VeriForm), Abdessamad Imine (INRIA Lorraine - LORIA\n  / LIFC)", "title": "Experiments in Model-Checking Optimistic Replication Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6510", "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a series of model-checking experiments to verify\noptimistic replication algorithms based on Operational Transformation (OT)\napproach used for supporting collaborative edition. We formally define, using\ntool UPPAAL, the behavior and the main consistency requirement (i.e.\nconvergence property) of the collaborative editing systems, as well as the\nabstract behavior of the environment where these systems are supposed to\noperate. Due to data replication and the unpredictable nature of user\ninteractions, such systems have infinitely many states. So, we show how to\nexploit some features of the UPPAAL specification language to attenuate the\nsevere state explosion problem. Two models are proposed. The first one, called\nconcrete model, is very close to the system implementation but runs up against\na severe explosion of states. The second model, called symbolic model, aims to\novercome the limitation of the concrete model by delaying the effective\nselection and execution of editing operations until the construction of\nsymbolic execution traces of all sites is completed. Experimental results have\nshown that the symbolic model allows a significant gain in both space and time.\nUsing the symbolic model, we have been able to show that if the number of sites\nexceeds 2 then the convergence property is not satisfied for all OT algorithms\nconsidered here. A counterexample is provided for every algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 14:04:38 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2008 08:51:52 GMT"}], "update_date": "2009-04-20", "authors_parsed": [["Boucheneb", "Hanifa", "", "VeriForm"], ["Imine", "Abdessamad", "", "INRIA Lorraine - LORIA\n  / LIFC"]]}, {"id": "0804.3065", "submitter": "Florent Jacquemard", "authors": "Hubert Comon-Lundh, Florent Jacquemard, Nicolas Perrin", "title": "Visibly Tree Automata with Memory and Constraints", "comments": "36 pages including an appendix", "journal-ref": "Logical Methods in Computer Science, Volume 4, Issue 2 (June 18,\n  2008) lmcs:827", "doi": "10.2168/LMCS-4(2:8)2008", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree automata with one memory have been introduced in 2001. They generalize\nboth pushdown (word) automata and the tree automata with constraints of\nequality between brothers of Bogaert and Tison. Though it has a decidable\nemptiness problem, the main weakness of this model is its lack of good closure\nproperties.\n  We propose a generalization of the visibly pushdown automata of Alur and\nMadhusudan to a family of tree recognizers which carry along their (bottom-up)\ncomputation an auxiliary unbounded memory with a tree structure (instead of a\nsymbol stack). In other words, these recognizers, called Visibly Tree Automata\nwith Memory (VTAM) define a subclass of tree automata with one memory enjoying\nBoolean closure properties. We show in particular that they can be determinized\nand the problems like emptiness, membership, inclusion and universality are\ndecidable for VTAM. Moreover, we propose several extensions of VTAM whose\ntransitions may be constrained by different kinds of tests between memories and\nalso constraints a la Bogaert and Tison comparing brother subtrees in the tree\nin input. We show that some of these classes of constrained VTAM keep the good\nclosure and decidability properties, and we demonstrate their expressiveness\nwith relevant examples of tree languages.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 16:27:34 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2008 23:32:44 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Comon-Lundh", "Hubert", ""], ["Jacquemard", "Florent", ""], ["Perrin", "Nicolas", ""]]}, {"id": "0804.3105", "submitter": "Igor Walukiewicz", "authors": "Anca Muscholl, Igor Walukiewicz", "title": "A lower bound on web services composition", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 4, Issue 2 (May 15,\n  2008) lmcs:824", "doi": "10.2168/LMCS-4(2:5)2008", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A web service is modeled here as a finite state machine. A composition\nproblem for web services is to decide if a given web service can be constructed\nfrom a given set of web services; where the construction is understood as a\nsimulation of the specification by a fully asynchronous product of the given\nservices. We show an EXPTIME-lower bound for this problem, thus matching the\nknown upper bound. Our result also applies to richer models of web services,\nsuch as the Roman model.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 21:15:47 GMT"}, {"version": "v2", "created": "Thu, 15 May 2008 13:14:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Muscholl", "Anca", ""], ["Walukiewicz", "Igor", ""]]}, {"id": "0804.3266", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (LIP)", "title": "Wadge Degrees of Infinitary Rational Relations", "comments": "to appear in the journal Mathematics in Computer Science, in a\n  Special Issue on Intensional Programming & Semantics, in honour of Bill Wadge\n  on the occasion of his 60th cycle", "journal-ref": "Mathematics in Computer Science 1, 2 (2008) 85-102", "doi": "10.1007/s11786-008-0045-7", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, from the topological point of view, 2-tape B\\\"uchi automata\nhave the same accepting power as Turing machines equipped with a B\\\"uchi\nacceptance condition. The Borel and the Wadge hierarchies of the class\nRAT_omega of infinitary rational relations accepted by 2-tape B\\\"uchi automata\nare equal to the Borel and the Wadge hierarchies of omega-languages accepted by\nreal-time B\\\"uchi 1-counter automata or by B\\\"uchi Turing machines. In\nparticular, for every non-null recursive ordinal $\\alpha$, there exist some\n$\\Sigma^0_\\alpha$-complete and some $\\Pi^0_\\alpha$-complete infinitary rational\nrelations. And the supremum of the set of Borel ranks of infinitary rational\nrelations is an ordinal $\\gamma^1_2$ which is strictly greater than the first\nnon-recursive ordinal $\\omega_1^{CK}$. This very surprising result gives\nanswers to questions of Simonnet (1992) and of Lescow and Thomas (1988,1994).\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2008 19:12:44 GMT"}], "update_date": "2009-01-04", "authors_parsed": [["Finkel", "Olivier", "", "LIP"]]}, {"id": "0804.3336", "submitter": "Alban Ponse", "authors": "Jan A. Bergstra and Alban Ponse", "title": "Differential Meadows", "comments": "8 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.LO math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A meadow is a zero totalised field (0^{-1}=0), and a cancellation meadow is a\nmeadow without proper zero divisors. In this paper we consider differential\nmeadows, i.e., meadows equipped with differentiation operators. We give an\nequational axiomatization of these operators and thus obtain a finite basis for\ndifferential cancellation meadows. Using the Zariski topology we prove the\nexistence of a differential cancellation meadow.\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2008 15:29:40 GMT"}], "update_date": "2009-02-07", "authors_parsed": [["Bergstra", "Jan A.", ""], ["Ponse", "Alban", ""]]}, {"id": "0804.3351", "submitter": "Cinzia Di Giusto", "authors": "Cinzia Di Giusto, Maurizio Gabbrielli, Maria Chiara Meo", "title": "On the Expressive Power of Multiple Heads in CHR", "comments": "v.6 Minor changes, new formulation of definitions, changed some\n  details in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Constraint Handling Rules (CHR) is a committed-choice declarative language\nwhich has been originally designed for writing constraint solvers and which is\nnowadays a general purpose language. CHR programs consist of multi-headed\nguarded rules which allow to rewrite constraints into simpler ones until a\nsolved form is reached. Many empirical evidences suggest that multiple heads\naugment the expressive power of the language, however no formal result in this\ndirection has been proved, so far.\n  In the first part of this paper we analyze the Turing completeness of CHR\nwith respect to the underneath constraint theory. We prove that if the\nconstraint theory is powerful enough then restricting to single head rules does\nnot affect the Turing completeness of the language. On the other hand,\ndifferently from the case of the multi-headed language, the single head CHR\nlanguage is not Turing powerful when the underlying signature (for the\nconstraint theory) does not contain function symbols.\n  In the second part we prove that, no matter which constraint theory is\nconsidered, under some reasonable assumptions it is not possible to encode the\nCHR language (with multi-headed rules) into a single headed language while\npreserving the semantics of the programs. We also show that, under some\nstronger assumptions, considering an increasing number of atoms in the head of\na rule augments the expressive power of the language.\n  These results provide a formal proof for the claim that multiple heads\naugment the expressive power of the CHR language.\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2008 16:21:43 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2009 19:49:25 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2009 16:29:03 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2010 18:22:39 GMT"}, {"version": "v5", "created": "Fri, 5 Nov 2010 21:19:52 GMT"}, {"version": "v6", "created": "Tue, 18 Jan 2011 11:03:53 GMT"}], "update_date": "2011-01-19", "authors_parsed": [["Di Giusto", "Cinzia", ""], ["Gabbrielli", "Maurizio", ""], ["Meo", "Maria Chiara", ""]]}, {"id": "0804.3434", "submitter": "Peter Selinger", "authors": "Peter Selinger", "title": "Lecture notes on the lambda calculus", "comments": "120 pages. Added in v2: section on polymorphism", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a set of lecture notes that developed out of courses on the lambda\ncalculus that I taught at the University of Ottawa in 2001 and at Dalhousie\nUniversity in 2007 and 2013. Topics covered in these notes include the untyped\nlambda calculus, the Church-Rosser theorem, combinatory algebras, the\nsimply-typed lambda calculus, the Curry-Howard isomorphism, weak and strong\nnormalization, polymorphism, type inference, denotational semantics, complete\npartial orders, and the language PCF.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2008 03:16:03 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2013 03:58:30 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Selinger", "Peter", ""]]}, {"id": "0804.3762", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (INRIA Lorraine - LORIA), Jean-Pierre Jouannaud\n  (LIX, INRIA Saclay Ile de France), Pierre-Yves Strub (LIX, INRIA Saclay Ile\n  de France)", "title": "From formal proofs to mathematical proofs: a safe, incremental way for\n  building in first-order decision procedures", "comments": null, "journal-ref": "Dans TCS 2008 5th IFIP International Conference on Theoretical\n  Computer Science (2008)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate here a new version of the Calculus of Inductive Constructions\n(CIC) on which the proof assistant Coq is based: the Calculus of Congruent\nInductive Constructions, which truly extends CIC by building in arbitrary\nfirst-order decision procedures: deduction is still in charge of the CIC\nkernel, while computation is outsourced to dedicated first-order decision\nprocedures that can be taken from the shelves provided they deliver a proof\ncertificate. The soundness of the whole system becomes an incremental property\nfollowing from the soundness of the certificate checkers and that of the\nkernel. A detailed example shows that the resulting style of proofs becomes\ncloser to that of the working mathematician.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2008 16:56:46 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "INRIA Lorraine - LORIA"], ["Jouannaud", "Jean-Pierre", "", "LIX, INRIA Saclay Ile de France"], ["Strub", "Pierre-Yves", "", "LIX, INRIA Saclay Ile\n  de France"]]}, {"id": "0804.3914", "submitter": "Andrew Gacek", "authors": "Andrew Gacek, Dale Miller, Gopalan Nadathur", "title": "Reasoning in Abella about Structural Operational Semantics\n  Specifications", "comments": "15 pages. To appear in LFMTP'08", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approach to reasoning about structural operational semantics style\nspecifications supported by the Abella system is discussed. This approach uses\nlambda tree syntax to treat object language binding and encodes binding related\nproperties in generic judgments. Further, object language specifications are\nembedded directly into the reasoning framework through recursive definitions.\nThe treatment of binding via generic judgments implicitly enforces distinctness\nand atomicity in the names used for bound variables. These properties must,\nhowever, be made explicit in reasoning tasks. This objective can be achieved by\nallowing recursive definitions to also specify generic properties of atomic\npredicates. The utility of these various logical features in the Abella system\nis demonstrated through actual reasoning tasks. Brief comparisons with a few\nother logic based approaches are also made.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2008 15:22:02 GMT"}, {"version": "v2", "created": "Tue, 3 Jun 2008 01:09:16 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Gacek", "Andrew", ""], ["Miller", "Dale", ""], ["Nadathur", "Gopalan", ""]]}, {"id": "0804.4071", "submitter": "Wan Ahmad Tajuddin Wan Abdullah", "authors": "Saratha Sathasivam (USM), Wan Ahmad Tajuddin Wan Abdullah (Univ\n  Malaya)", "title": "Logic Mining Using Neural Networks", "comments": "Proceedings of the International Conference on Intelligent Systems\n  2005 (ICIS 2005), Kuala Lumpur, 1-3 December 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge could be gained from experts, specialists in the area of interest,\nor it can be gained by induction from sets of data. Automatic induction of\nknowledge from data sets, usually stored in large databases, is called data\nmining. Data mining methods are important in the management of complex systems.\nThere are many technologies available to data mining practitioners, including\nArtificial Neural Networks, Regression, and Decision Trees. Neural networks\nhave been successfully applied in wide range of supervised and unsupervised\nlearning applications. Neural network methods are not commonly used for data\nmining tasks, because they often produce incomprehensible models, and require\nlong training times. One way in which the collective properties of a neural\nnetwork may be used to implement a computational task is by way of the concept\nof energy minimization. The Hopfield network is well-known example of such an\napproach. The Hopfield network is useful as content addressable memory or an\nanalog computer for solving combinatorial-type optimization problems. Wan\nAbdullah [1] proposed a method of doing logic programming on a Hopfield neural\nnetwork. Optimization of logical inconsistency is carried out by the network\nafter the connection strengths are defined from the logic program; the network\nrelaxes to neural states corresponding to a valid interpretation. In this\narticle, we describe how Hopfield network is able to induce logical rules from\nlarge database by using reverse analysis method: given the values of the\nconnections of a network, we can hope to know what logical rules are entrenched\nin the database.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2008 09:30:28 GMT"}], "update_date": "2008-04-28", "authors_parsed": [["Sathasivam", "Saratha", "", "USM"], ["Abdullah", "Wan Ahmad Tajuddin Wan", "", "Univ\n  Malaya"]]}, {"id": "0804.4073", "submitter": "Gilles Champenois", "authors": "Gilles Champenois", "title": "Grainy Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grainy numbers are defined as tuples of bits. They form a lattice where the\nmeet and the join operations are an addition and a multiplication. They may be\nsubstituted for the real numbers in the definition of fuzzy sets. The aim is to\npropose an alternative negation for the complement that we'll call supplement.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2008 09:36:17 GMT"}, {"version": "v2", "created": "Thu, 8 May 2008 09:07:18 GMT"}, {"version": "v3", "created": "Thu, 12 Jun 2008 22:10:31 GMT"}, {"version": "v4", "created": "Wed, 9 Jul 2008 11:01:54 GMT"}, {"version": "v5", "created": "Thu, 10 Jul 2008 09:23:47 GMT"}, {"version": "v6", "created": "Sun, 17 May 2009 13:45:46 GMT"}], "update_date": "2009-05-17", "authors_parsed": [["Champenois", "Gilles", ""]]}, {"id": "0804.4075", "submitter": "Wan Ahmad Tajuddin Wan Abdullah", "authors": "Saratha Sathasivam (USM), Wan Ahmad Tajuddin Wan Abdullah (Univ\n  Malaya)", "title": "Logic Learning in Hopfield Networks", "comments": "To appear in Mod. Appl. Sci", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic weights for neurons in logic programming can be calculated either by\nusing Hebbian learning or by Wan Abdullah's method. In other words, Hebbian\nlearning for governing events corresponding to some respective program clauses\nis equivalent with learning using Wan Abdullah's method for the same respective\nprogram clauses. In this paper we will evaluate experimentally the equivalence\nbetween these two types of learning through computer simulations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2008 09:46:46 GMT"}], "update_date": "2008-04-28", "authors_parsed": [["Sathasivam", "Saratha", "", "USM"], ["Abdullah", "Wan Ahmad Tajuddin Wan", "", "Univ\n  Malaya"]]}, {"id": "0804.4383", "submitter": "Carlo Alberto Furia", "authors": "Carlo A. Furia, Matteo Pradella, Matteo Rossi", "title": "Practical Automated Partial Verification of Multi-Paradigm Real-Time\n  Models", "comments": "33 pages; fixed a few typos and added data to Table 2", "journal-ref": "Proceedings of the 10th International Conference on Formal\n  Engineering Methods (ICFEM'08). Lecture Notes in Computer Science,\n  5256:298--317, Springer-Verlag, October 2008", "doi": "10.1007/978-3-540-88194-0_19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a fully automated verification technique that permits\nto analyze real-time systems described using a continuous notion of time and a\nmixture of operational (i.e., automata-based) and descriptive (i.e.,\nlogic-based) formalisms. The technique relies on the reduction, under\nreasonable assumptions, of the continuous-time verification problem to its\ndiscrete-time counterpart. This reconciles in a viable and effective way the\ndense/discrete and operational/descriptive dichotomies that are often\nencountered in practice when it comes to specifying and analyzing complex\ncritical systems. The article investigates the applicability of the technique\nthrough a significant example centered on a communication protocol. More\nprecisely, concurrent runs of the protocol are formalized by parallel instances\nof a Timed Automaton, while the synchronization rules between these instances\nare specified through Metric Temporal Logic formulas, thus creating a\nmulti-paradigm model. Verification tests run on this model using a bounded\nvalidity checker implementing the technique show consistent results and\ninteresting performances.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2008 12:04:12 GMT"}, {"version": "v2", "created": "Fri, 4 Jul 2008 14:42:17 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Furia", "Carlo A.", ""], ["Pradella", "Matteo", ""], ["Rossi", "Matteo", ""]]}, {"id": "0804.4530", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee, Luca de Alfaro and Thomas A. Henzinger", "title": "Strategy Improvement for Concurrent Safety Games", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider concurrent games played on graphs. At every round of the game,\neach player simultaneously and independently selects a move; the moves jointly\ndetermine the transition to a successor state. Two basic objectives are the\nsafety objective: ``stay forever in a set F of states'', and its dual, the\nreachability objective, ``reach a set R of states''. We present in this paper a\nstrategy improvement algorithm for computing the value of a concurrent safety\ngame, that is, the maximal probability with which player 1 can enforce the\nsafety objective. The algorithm yields a sequence of player-1 strategies which\nensure probabilities of winning that converge monotonically to the value of the\nsafety game.\n  The significance of the result is twofold. First, while strategy improvement\nalgorithms were known for Markov decision processes and turn-based games, as\nwell as for concurrent reachability games, this is the first strategy\nimprovement algorithm for concurrent safety games. Second, and most\nimportantly, the improvement algorithm provides a way to approximate the value\nof a concurrent safety game from below (the known value-iteration algorithms\napproximate the value from above). Thus, when used together with\nvalue-iteration algorithms, or with strategy improvement algorithms for\nreachability games, our algorithm leads to the first practical algorithm for\ncomputing converging upper and lower bounds for the value of reachability and\nsafety games.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2008 05:09:45 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["de Alfaro", "Luca", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "0804.4565", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Data linkage algebra, data linkage dynamics, and priority rewriting", "comments": "48 pages, typos corrected, phrasing improved, definition of services\n  replaced; presentation improved; presentation improved and appendix added", "journal-ref": "Fundamenta Informaticae, 128(4):367--412, 2013", "doi": "10.3233/FI-2013-950", "report-no": "PRG0806", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algebra of data linkages. Data linkages are intended for\nmodelling the states of computations in which dynamic data structures are\ninvolved. We present a simple model of computation in which states of\ncomputations are modelled as data linkages and state changes take place by\nmeans of certain actions. We describe the state changes and replies that result\nfrom performing those actions by means of a term rewriting system with rule\npriorities. The model in question is an upgrade of molecular dynamics. The\nupgrading is mainly concerned with the features to deal with values and the\nfeatures to reclaim garbage.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2008 09:55:33 GMT"}, {"version": "v2", "created": "Wed, 18 Jun 2008 05:48:10 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2012 11:31:42 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2013 09:46:25 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}]