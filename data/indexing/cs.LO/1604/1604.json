[{"id": "1604.00162", "submitter": "Christian Stra{\\ss}er", "authors": "Jesse Heyninck and Christian Stra{\\ss}er", "title": "Relations between assumption-based approaches in nonmonotonic logic and\n  formal argumentation", "comments": "Contribution to the 16th International Workshop on Non-Monotonic\n  Reasoning (NMR'16), Cape Town", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we make a contribution to the unification of formal models of\ndefeasible reasoning. We present several translations between formal\nargumentation frameworks and nonmonotonic logics for reasoning with plausible\nassumptions. More specifically, we translate adaptive logics into\nassumption-based argumentation and ASPIC+, ASPIC+ into assumption-based\nargumentation and a fragment of assumption-based argumentation into adaptive\nlogics. Adaptive logics are closely related to Makinson's default assumptions\nand to a significant class of systems within the tradition of preferential\nsemantics in the vein of KLM and Shoham. Thus, our results also provide close\nlinks between formal argumentation and the latter approaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 08:14:30 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Heyninck", "Jesse", ""], ["Stra\u00dfer", "Christian", ""]]}, {"id": "1604.00258", "submitter": "Arno Pauly", "authors": "Arno Pauly and Hideki Tsuiki", "title": "Computable dyadic subbases and $\\mathbf{T}^\\omega$-representations of\n  compact sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore representing the compact subsets of a given represented space by\ninfinite sequences over Plotkin's $\\mathbb{T}$. We show that computably compact\ncomputable metric spaces admit representations of their compact subsets in such\na way that compact sets are essentially underspecified points. We can even\nensure that a name of an $n$-element compact set contains $n$ occurrences of\n$\\bot$. We undergo this study effectively and show that such a\n$\\mathbb{T}^\\omega$-representation is effectively obtained from structures of\ncomputably compact computable metric spaces. As an application, we prove some\nstatements about the Weihrauch degree of closed choice for finite subsets of\ncomputably compact computable metric spaces.\n  Along the way, we introduce the notion of a computable dyadic subbase, and\nprove that every computably compact computable metric space admits a proper\ncomputable dyadic subbase.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 14:24:02 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 13:07:43 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 17:52:08 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Pauly", "Arno", ""], ["Tsuiki", "Hideki", ""]]}, {"id": "1604.00266", "submitter": "Elnaser Abdelwahab", "authors": "Elnaserledinellah Mahmood Abdelwahab, Karim Daghbouche, Nadra Ahmad\n  Shannan", "title": "The Algorithm of Islamic Jurisprudence (Fiqh) with Validation of an\n  Entscheidungsproblem", "comments": "36 pages, 6 Figures. J.Acad.(N.Y.)4,2:52-87, published May 16 2014", "journal-ref": "J.Acad.(N.Y.)4,2:52-87 May 16 2014", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The historic background of algorithmic processing with regard to etymology\nand methodology is translated into terms of mathematical logic and Computer\nScience. A formal logic structure is introduced by exemplaryquestions posed to\nFiqh-chapters to define alogic query language. As a foundation, ageneric\nalgorithm for deciding Fiqh-rulings is designed to enable and further leverage\nrule of law (vs. rule by law) with full transparency and complete algorithmic\ncoverage of Islamic law eventually providing legal security, legal equality,\nand full legal accountability.This is implemented by disentangling and\nreinstating classic Fiqh-methodology (usul al-Fiqh) with the expressive power\nof subsets of First Order Logic (FOL)sustainably substituting ad hoc reasoning\nwith falsifiable rational argumentation. The results are discussed in formal\nterms of completeness, decidability and complexity of formal Fiqh-systems.\nAnEntscheidungsproblem for formal Fiqh-Systems is formulated and validated.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 20:56:15 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Abdelwahab", "Elnaserledinellah Mahmood", ""], ["Daghbouche", "Karim", ""], ["Shannan", "Nadra Ahmad", ""]]}, {"id": "1604.00346", "submitter": "EPTCS", "authors": "Ferruccio Damiani (University of Torino, Italy), Michael Lienhardt\n  (University of Torino, Italy)", "title": "Refactoring Delta-Oriented Product Lines to achieve Monotonicity", "comments": "In Proceedings FMSPLE 2016, arXiv:1603.08577", "journal-ref": "EPTCS 206, 2016, pp. 2-16", "doi": "10.4204/EPTCS.206.2", "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delta-oriented programming (DOP) is a flexible transformational approach to\nimplement software product lines. In delta-oriented product lines, variants are\ngenerated by applying operations contained in delta modules to a (possibly\nempty) base program. These operations can add, remove or modify named elements\nin a program (e.g., classes, methods and fields in a Java program). This paper\npresents algorithms for refactoring a delta-oriented product line into\nmonotonic form, i.e., either to contain add and modify operations only\n(monotonic increasing) or to contain remove and modify operations only\n(monotonic decreasing). Because of their simpler structure, monotonic\ndelta-oriented product lines are easier to analyze. The algorithms are\nformalized by means of a core calculus for DOP of product lines of Java\nprograms and their correctness and complexity are given.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 18:25:58 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Damiani", "Ferruccio", "", "University of Torino, Italy"], ["Lienhardt", "Michael", "", "University of Torino, Italy"]]}, {"id": "1604.00350", "submitter": "EPTCS", "authors": "Maurice H. ter Beek (ISTI-CNR, Pisa, Italy), Erik P. de Vink (TU/e,\n  Eindhoven, The Netherlands), Tim A. C. Willemse (TU/e, Eindhoven, The\n  Netherlands)", "title": "Towards a Feature mu-Calculus Targeting SPL Verification", "comments": "In Proceedings FMSPLE 2016, arXiv:1603.08577", "journal-ref": "EPTCS 206, 2016, pp. 61-75", "doi": "10.4204/EPTCS.206.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modal mu-calculus mu-L is a well-known fixpoint logic to express and\nmodel check properties interpreted over labeled transition systems. In this\npaper, we propose two variants of the mu-calculus, mu-Lf and mu-Lf', for\nfeature transition systems. For this, we explicitly incorporate feature\nexpressions into the logics, allowing operators to select transitions and\nbehavior restricted to specific products and subfamilies. We provide semantics\nfor mu-Lf and mu-Lf' and relate the two new mu-calculi and mu-L to each other.\nNext, we focus on the analysis of SPL behavior and show how our formalism can\nbe applied for product-based verification with mu-Lf as well as family-based\nverification with mu-Lf'. We illustrate by means of a toy example how\nproperties can be model checked, exploiting an embedding of mu-Lf' into the\nmu-calculus with data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 18:26:46 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["ter Beek", "Maurice H.", "", "ISTI-CNR, Pisa, Italy"], ["de Vink", "Erik P.", "", "TU/e,\n  Eindhoven, The Netherlands"], ["Willemse", "Tim A. C.", "", "TU/e, Eindhoven, The\n  Netherlands"]]}, {"id": "1604.00384", "submitter": "EPTCS", "authors": "Robert Atkey (University of Strathclyde), Neelakantan Krishnaswami\n  (University of Birmingham)", "title": "Proceedings 6th Workshop on Mathematically Structured Functional\n  Programming", "comments": null, "journal-ref": "EPTCS 207, 2016", "doi": "10.4204/EPTCS.207", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sixth workshop on Mathematically Structured Functional Programming is\ndevoted to the derivation of functionality from structure. It is a celebration\nof the direct impact of Theoretical Computer Science on programs as we write\nthem today. Modern programming languages, and in particular functional\nlanguages, support the direct expression of mathematical structures, equipping\nprogrammers with tools of remarkable power and abstraction. Where would Haskell\nbe without monads? Functional reactive programming without arrows?\nCall-by-push-value without adjunctions? The list goes on. This workshop is a\nforum for researchers who seek to reflect mathematical phenomena in data and\ncontrol.\n  The sixth workshop on Mathematically Structured Functional Programming was\nheld on 8th April 2016 as a part of ETAPS 2016 in Eindhoven, the Netherlands.\nThere were five contributed talks and one invited talk.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 19:52:28 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Atkey", "Robert", "", "University of Strathclyde"], ["Krishnaswami", "Neelakantan", "", "University of Birmingham"]]}, {"id": "1604.00536", "submitter": "Jingchao Chen", "authors": "Jingchao Chen", "title": "Improving SAT Solvers via Blocked Clause Decomposition", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision variable selection policy used by the most competitive CDCL\n(Conflict-Driven Clause Learning) SAT solvers is either VSIDS (Variable State\nIndependent Decaying Sum) or its variants such as exponential version EVSIDS.\nThe common characteristic of VSIDS and its variants is to make use of\nstatistical information in the solving process, but ignore structure\ninformation of the problem. For this reason, this paper modifies the decision\nvariable selection policy, and presents a SAT solving technique based on BCD\n(Blocked Clause Decomposition). Its basic idea is that a part of decision\nvariables are selected by VSIDS heuristic, while another part of decision\nvariables are selected by blocked sets that are obtained by BCD. Compared with\nthe existing BCD-based technique, our technique is simple, and need not to\nreencode CNF formulas. SAT solvers for certified UNSAT track can apply also our\nBCD-based technique. Our experiments on application benchmarks demonstrate that\nthe new variables selection policy based on BCD can increase the performance of\nSAT solvers such as abcdSAT. The solver with BCD solved an instance from the\nSAT Race 2015 that was not solved by any solver so far. This shows that in some\ncases, the heuristic based on structure information is more efficient than that\nbased on statistical information.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 17:50:32 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Chen", "Jingchao", ""]]}, {"id": "1604.00936", "submitter": "Giuseppe Greco", "authors": "Sabine Frittella and Giuseppe Greco and Alessandra Palmigiano and Fan\n  Yang", "title": "Structural Multi-type Sequent Calculus for Inquisitive Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define a multi-type calculus for inquisitive logic, which\nis sound, complete and enjoys Belnap-style cut-elimination and subformula\nproperty. Inquisitive logic is the logic of inquisitive semantics, a semantic\nframework developed by Groenendijk, Roelofsen and Ciardelli which captures both\nassertions and questions in natural language. Inquisitive logic is sound and\ncomplete w.r.t. the so-called state semantics (also known as team semantics).\nThe Hilbert-style presentation of inquisitive logic is not closed under uniform\nsubstitution; indeed, some occurrences of formulas are restricted to a certain\nsubclass of formulas, called flat formulas. This and other features make the\nquest for analytic calculi for this logic not straightforward. We develop a\ncertain algebraic and order-theoretic analysis of the team semantics, which\nprovides the guidelines for the design of a multi-type environment which\naccounts for two domains of interpretation, for flat and for general formulas,\nas well as for their interaction. This multi-type environment in its turn\nprovides the semantic environment for the multi-type calculus for inquisitive\nlogic we introduce in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 16:29:14 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Frittella", "Sabine", ""], ["Greco", "Giuseppe", ""], ["Palmigiano", "Alessandra", ""], ["Yang", "Fan", ""]]}, {"id": "1604.01185", "submitter": "EPTCS", "authors": "Bartek Klin (University of Warsaw), Micha{\\l} Szynwelski (University\n  of Warsaw)", "title": "SMT Solving for Functional Programming over Infinite Structures", "comments": "In Proceedings MSFP 2016, arXiv:1604.00384", "journal-ref": "EPTCS 207, 2016, pp. 57-75", "doi": "10.4204/EPTCS.207.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a simple functional programming language aimed at manipulating\ninfinite, but first-order definable structures, such as the countably infinite\nclique graph or the set of all intervals with rational endpoints. Internally,\nsuch sets are represented by logical formulas that define them, and an external\nsatisfiability modulo theories (SMT) solver is regularly run by the interpreter\nto check their basic properties.\n  The language is implemented as a Haskell module.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 09:04:03 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Klin", "Bartek", "", "University of Warsaw"], ["Szynwelski", "Micha\u0142", "", "University\n  of Warsaw"]]}, {"id": "1604.01186", "submitter": "EPTCS", "authors": "Denis Firsov, Tarmo Uustalu, Niccol\\`o Veltri", "title": "Variations on Noetherianness", "comments": "In Proceedings MSFP 2016, arXiv:1604.00384", "journal-ref": "EPTCS 207, 2016, pp. 76-88", "doi": "10.4204/EPTCS.207.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In constructive mathematics, several nonequivalent notions of finiteness\nexist. In this paper, we continue the study of Noetherian sets in the\ndependently typed setting of the Agda programming language. We want to say that\na set is Noetherian, if, when we are shown elements from it one after another,\nwe will sooner or later have seen some element twice. This idea can be made\nprecise in a number of ways. We explore the properties and connections of some\nof the possible encodings. In particular, we show that certain implementations\nimply decidable equality while others do not, and we construct counterexamples\nin the latter case. Additionally, we explore the relation between\nNoetherianness and other notions of finiteness.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 09:04:13 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Firsov", "Denis", ""], ["Uustalu", "Tarmo", ""], ["Veltri", "Niccol\u00f2", ""]]}, {"id": "1604.01187", "submitter": "EPTCS", "authors": "Danel Ahman, Tarmo Uustalu", "title": "Directed Containers as Categories", "comments": "In Proceedings MSFP 2016, arXiv:1604.00384", "journal-ref": "EPTCS 207, 2016, pp. 89-98", "doi": "10.4204/EPTCS.207.5", "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed containers make explicit the additional structure of those\ncontainers whose set functor interpretation carries a comonad structure. The\ndata and laws of a directed container resemble those of a monoid, while the\ndata and laws of a directed container morphism those of a monoid morphism in\nthe reverse direction. With some reorganization, a directed container is the\nsame as a small category, but a directed container morphism is opcleavage-like.\nWe draw some conclusions for comonads from this observation, considering in\nparticular basic constructions and concepts like the opposite category and a\ngroupoid.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 09:04:22 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Ahman", "Danel", ""], ["Uustalu", "Tarmo", ""]]}, {"id": "1604.01288", "submitter": "Oliver Kullmann", "authors": "Oliver Kullmann and Xishun Zhao", "title": "Unsatisfiable hitting clause-sets with three more clauses than variables", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of this paper is the Finiteness Conjecture for minimally\nunsatisfiable clause-sets (MUs), stating that for each fixed deficiency (number\nof clauses minus number of variables) there are only finitely many patterns,\ngiven a certain basic reduction (generalising unit-clause propagation). We\nfocus our attention on hitting clause-sets (every two clauses have at least one\nclash), where the conjecture says that there are only finitely many isomorphism\ntypes. The Finiteness Conjecture is here known to hold for deficiency at most\n2, and we now prove it for deficiency 3. An important tool is the notion of\n\"(ir)reducible clause-sets\": we show how to reduce the general question to the\nirreducible case, and then solve this case (for deficiency 3). This notion\ncomes from number theory (Korec 1984, Berger et al 1990), and we rediscovered\nit in our studies.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 15:06:36 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Kullmann", "Oliver", ""], ["Zhao", "Xishun", ""]]}, {"id": "1604.01673", "submitter": "Antti Kuusisto", "authors": "Antti Kuusisto", "title": "On the uniform one-dimensional fragment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uniform one-dimensional fragment of first-order logic, U1, is a recently\nintroduced formalism that extends two-variable logic in a natural way to\ncontexts with relations of all arities. We survey properties of U1 and\ninvestigate its relationship to description logics designed to accommodate\nhigher arity relations, with particular attention given to DLR_reg. We also\ndefine a description logic version of a variant of U1 and prove a range of new\nresults concerning the expressivity of U1 and related logics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 16:03:42 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 15:09:02 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Kuusisto", "Antti", ""]]}, {"id": "1604.01942", "submitter": "Mahsa Shirmohammadi", "authors": "Laurent Doyen, Thierry Massart, Mahsa Shirmohammadi", "title": "The Complexity of Synchronizing Markov Decision Processes", "comments": "arXiv admin note: substantial text overlap with arXiv:1402.2840,\n  arXiv:1310.2935", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov decision processes (MDP) as generators of sequences of\nprobability distributions over states. A probability distribution is\np-synchronizing if the probability mass is at least p in a single state, or in\na given set of states. We consider four temporal synchronizing modes: a\nsequence of probability distributions is always p-synchronizing, eventually\np-synchronizing, weakly p-synchronizing, or strongly p-synchronizing if,\nrespectively, all, some, infinitely many, or all but finitely many\ndistributions in the sequence are p-synchronizing.\n  For each synchronizing mode, an MDP can be (i) sure winning if there is a\nstrategy that produces a 1-synchronizing sequence; (ii) almost-sure winning if\nthere is a strategy that produces a sequence that is, for all epsilon > 0, a\n(1-epsilon)-synchronizing sequence; (iii) limit-sure winning if for all epsilon\n> 0, there is a strategy that produces a (1-epsilon)-synchronizing sequence.\n  We provide fundamental results on the expressiveness, decidability, and\ncomplexity of synchronizing properties for MDPs. For each synchronizing mode,\nwe consider the problem of deciding whether an MDP is sure, almost-sure, or\nlimit-sure winning, and we establish matching upper and lower complexity bounds\nof the problems: for all winning modes, we show that the problems are\nPSPACE-complete for eventually and weakly synchronizing, and PTIME-complete for\nalways and strongly synchronizing. We establish the memory requirement for\nwinning strategies, and we show that all winning modes coincide for always\nsynchronizing, and that the almost-sure and limit-sure winning modes coincide\nfor weakly and strongly synchronizing.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 10:01:51 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 08:19:16 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Doyen", "Laurent", ""], ["Massart", "Thierry", ""], ["Shirmohammadi", "Mahsa", ""]]}, {"id": "1604.01990", "submitter": "Christophe Raffalli", "authors": "Rodolphe Lepigre (1), Christophe Raffalli (1) ((1) LAMA)", "title": "Practical Subtyping for System F with Sized (Co-)Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a rich type system with subtyping for an extension of System F.\nOur type constructors include sum and product types, universal and existential\nquantifiers, inductive and coinductive types. The latter two size annotations\nallowing the preservation of size invariants. For example it is possible to\nderive the termination of the quicksort by showing that partitioning a list\ndoes not increase its size. The system deals with complex programs involving\nmixed induction and coinduction, or even mixed (co-)induction and polymorphism\n(as for Scott-encoded datatypes). One of the key ideas is to completely\nseparate the induction on sizes from the notion of recursive programs. We use\nthe size change principle to check that the proof is well-founded, not that the\nprogram terminates. Termination is obtained by a strong normalization proof.\nAnother key idea is the use symbolic witnesses to handle quantifiers of all\nsorts. To demonstrate the practicality of our system, we provide an\nimplementation that accepts all the examples discussed in the paper and much\nmore.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 13:32:13 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 13:23:40 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 07:41:46 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Lepigre", "Rodolphe", "", "LAMA"], ["Raffalli", "Christophe", "", "LAMA"]]}, {"id": "1604.02086", "submitter": "Ralph Matthes", "authors": "Jos\\'e Esp\\'irito Santo, Ralph Matthes, Lu\\'is Pinto", "title": "Inhabitation in Simply-Typed Lambda-Calculus through a Lambda-Calculus\n  for Proof Search", "comments": "16 pages + 3 pages appendix (an error in the original version was\n  detected, the proofs are very different and are based on new definitions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new, comprehensive approach to inhabitation problems in simply-typed\nlambda-calculus is shown, dealing with both decision and counting problems.\nThis approach works by exploiting a representation of the search space\ngenerated by a given inhabitation problem, which is in terms of a\nlambda-calculus for proof search that the authors developed recently. The\nrepresentation may be seen as extending the Curry-Howard representation of\nproofs by lambda-terms, staying within the methods of lambda-calculus and type\nsystems. Our methodology reveals inductive descriptions of the decision\nproblems, driven by the syntax of the proof-search expressions, and the end\nproducts are simple, recursive decision procedures and counting functions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 17:42:39 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 22:51:22 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Santo", "Jos\u00e9 Esp\u00edrito", ""], ["Matthes", "Ralph", ""], ["Pinto", "Lu\u00eds", ""]]}, {"id": "1604.02284", "submitter": "EPTCS", "authors": "Swen Jacobs (Saarland University), Felix Klein (Saarland University),\n  Sebastian Schirmer (Saarland University)", "title": "A High-Level LTL Synthesis Format: TLSF v1.1", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178. arXiv admin note:\n  substantial text overlap with arXiv:1601.05228", "journal-ref": "EPTCS 229, 2016, pp. 112-132", "doi": "10.4204/EPTCS.229.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Temporal Logic Synthesis Format (TLSF), a high-level format to\ndescribe synthesis problems via Linear Temporal Logic (LTL). The format builds\nupon standard LTL, but additionally allows to use high-level constructs, such\nas sets and functions, to provide a compact and human-readable representation.\nFurthermore, the format allows to identify parameters of a specification such\nthat a single description can be used to define a family of problems.\nAdditionally, we present a tool to automatically translate the format into\nplain LTL, which then can be used for synthesis by a solver. The tool also\nallows to adjust parameters of the specification and to apply standard\ntransformations on the resulting formula.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 09:27:43 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2016 12:00:20 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 03:38:08 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Jacobs", "Swen", "", "Saarland University"], ["Klein", "Felix", "", "Saarland University"], ["Schirmer", "Sebastian", "", "Saarland University"]]}, {"id": "1604.02386", "submitter": "Zamira Daw", "authors": "Zamira Daw and Rance Cleaveland", "title": "An extensible formal semantics for UML activity diagrams", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an operational semantics for UML activity diagrams. The\npurpose of this semantics is three-fold: to give a robust basis for verifying\nmodel correctness; to help validate model transformations; and to provide a\nwell-formed basis for assessing whether a proposed extension/interpretation of\nthe modeling language is consistent with the standard. The challenges of a\ngeneral formal framework for UML models include the semi-formality of the\nsemantics specification, the extensibility of the language, and (sometimes\ndeliberate, sometimes accidental) under-specification of model behavior in the\nstandard. Our approach is based on structural operational semantics, which can\nbe extended according to domain-specific needs. The presented semantics has\nbeen implemented and tested.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 15:59:27 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Daw", "Zamira", ""], ["Cleaveland", "Rance", ""]]}, {"id": "1604.02603", "submitter": "Samson Abramsky", "authors": "Samson Abramsky", "title": "Information, Processes and Games", "comments": "Appeared in Philosophy of Information, vol. 8 of Handbook of the\n  Philosophy of Science, edited by Dov Gabbay and John Woods. arXiv admin note:\n  substantial text overlap with arXiv:quant-ph/0312044 by other authors", "journal-ref": "Philosophy of Information, Johan van Benthem and Pieter Adriaans,\n  eds., pages 483--549, 2008", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the prospects for an Information Dynamics which can serve as the\nbasis for a fundamental theory of information, incorporating qualitative and\nstructural as well as quantitative aspects. We motivate our discussion with\nsome basic conceptual puzzles: how can information increase in computation, and\nwhat is it that we are actually computing in general? Then we survey a number\nof the theories which have been developed within Computer Science, as partial\nexemplifications of the kind of fundamental theory which we seek: including\nDomain Theory, Dynamic Logic, and Process Algebra. We look at recent work\nshowing new ways of combining quantitative and qualitative theories of\ninformation, as embodied respectively by Domain Theory and Shannon Information\nTheory. Then we look at Game Semantics and Geometry of Interaction, as examples\nof dynamic models of logic and computation in which information flow and\ninteraction are made central and explicit. We conclude by looking briefly at\nsome key issues for future progress.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 19:49:51 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Abramsky", "Samson", ""]]}, {"id": "1604.02784", "submitter": "Carlos Leandro", "authors": "Carlos Leandro and Lu\\'is Monteiro", "title": "Multi-diagrams of relations between fuzzy sets: weighted limits,\n  colimits and commutativity", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limits and colimits of diagrams, defined by maps between sets, are universal\nconstructions fundamental in different mathematical domains and key concepts in\ntheoretical computer science. Its importance in semantic modeling is described\nby M. Makkai and R. Par\\'e, where it is formally shown that every axiomatizable\ntheory in classical infinitary logic can be specified using diagrams defined by\nmaps between sets, and its models are structures characterized by the\ncommutativity, limit and colimit of those diagrams. Z. Diskin taking a more\npractical perspective, presented an algebraic graphic-based framework for data\nmodeling and database design. The aim of our work is to study the possibility\nof extending these algebraic frameworks to the specification of fuzzy\nstructures and to the description of fuzzy patterns on data. For that purpose,\nin this paper we describe a conservative extension for the notions of diagram\ncommutativity, limit and colimit, when diagrams are constructed using relations\nbetween fuzzy sets, evaluated in a multi-valued logic. These are used to\nformalize what we mean by \"a relation $R$ is similar to a limit of diagram\n$D$,\" \"a similarity relation $S$ is identical to a colimit of diagram $D$\ncolimit,\" and \"a diagram $D$ is almost commutative.\"\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 03:56:19 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Leandro", "Carlos", ""], ["Monteiro", "Lu\u00eds", ""]]}, {"id": "1604.02790", "submitter": "Carlos Leandro", "authors": "Carlos Leandro", "title": "Categorical semiotics", "comments": "76 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of knowledge extracted from different models described by\ndomain experts or from models generated by machine learning algorithms is\nstrongly conditioned by the lack of an appropriated framework to specify and\nintegrate structures, learning processes, data transformations and data models\nor data rules. In this work we extended algebraic specification methods to be\nused in this type of framework. This methodology uses graphic structures\nsimilar to Ehresmann's sketches interpreted on a fuzzy set universe. This\napproach takes advantages of the sketches ability to integrate data\ndeterministic and nondeterministic structures. Selecting this strategy we also\ntry to take advantage on how the graphic languages, used in Category theory in\ngeneral and used for sketch definition in particular, are suited to reasoning\nabout problems, to structural description and to task specification and task\ndecomposition.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 04:47:42 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Leandro", "Carlos", ""]]}, {"id": "1604.02887", "submitter": "J\\\"urgen Koslowski", "authors": "Stephane Demri and Diego Figueira and M Praveen", "title": "Reasoning about Data Repetitions with Counter Systems", "comments": "54 pages", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 3 (August 4,\n  2016) lmcs:1645", "doi": "10.2168/LMCS-12(3:1)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study linear-time temporal logics interpreted over data words with\nmultiple attributes. We restrict the atomic formulas to equalities of attribute\nvalues in successive positions and to repetitions of attribute values in the\nfuture or past. We demonstrate correspondences between satisfiability problems\nfor logics and reachability-like decision problems for counter systems. We show\nthat allowing/disallowing atomic formulas expressing repetitions of values in\nthe past corresponds to the reachability/coverability problem in Petri nets.\nThis gives us 2EXPSPACE upper bounds for several satisfiability problems. We\nprove matching lower bounds by reduction from a reachability problem for a\nnewly introduced class of counter systems. This new class is a succinct version\nof vector addition systems with states in which counters are accessed via\npointers, a potentially useful feature in other contexts. We strengthen further\nthe correspondences between data logics and counter systems by characterizing\nthe complexity of fragments, extensions and variants of the logic. For\ninstance, we precisely characterize the relationship between the number of\nattributes allowed in the logic and the number of counters needed in the\ncounter system.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 11:19:28 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 07:31:27 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Demri", "Stephane", ""], ["Figueira", "Diego", ""], ["Praveen", "M", ""]]}, {"id": "1604.03098", "submitter": "Carlos Leandro", "authors": "Carlos Leandro and Lu\\'is Monteiro", "title": "Patterns on data described by vague limits, vague colimits and vague\n  commutativity", "comments": "35 pages. arXiv admin note: text overlap with arXiv:1604.02784", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of machine learning in particular and artificial intelligent\nin general has been strongly conditioned by the lack of an appropriated\nframework to specify and integrate learning processes, data transformation\nprocesses and data models. In this work we extend traditional algebraic\nspecification methods to this type of framework. Limits and colimits of\ndiagrams are universal constructions fundamental in different mathematical\ndomains importance in semantic modeling. The aim of our work is to study the\npossibility of extending these algebraic frameworks to the specification of\nvague structures and to the description of vague patterns on data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 04:57:34 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Leandro", "Carlos", ""], ["Monteiro", "Lu\u00eds", ""]]}, {"id": "1604.03413", "submitter": "Othmane Rezine", "authors": "Parosh Aziz Abdulla and C. Aiswarya and Mohamed Faouzi Atig and Marco\n  Montali and Othmane Rezine", "title": "Recency-Bounded Verification of Dynamic Database-Driven Systems\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalism to model database-driven systems, called database\nmanipulating systems (DMS). The actions of a DMS modify the current instance of\na relational database by adding new elements into the database, deleting tuples\nfrom the relations and adding tuples to the relations. The elements which are\nmodified by an action are chosen by (full) first-order queries. DMS is a highly\nexpressive model and can be thought of as a succinct representation of an\ninfinite state relational transition system, in line with similar models\nproposed in the literature. We propose monadic second order logic (MSO-FO) to\nreason about sequences of database instances appearing along a run.\nUnsurprisingly, the linear-time model checking problem of DMS against MSO-FO is\nundecidable. Towards decidability, we propose under-approximate model checking\nof DMS, where the under-approximation parameter is the \"bound on recency\". In a\n$k$-recency-bounded run, only the most recent $k$ elements in the current\nactive domain may be modified by an action. More runs can be verified by\nincreasing the bound on recency. Our main result shows that recency-bounded\nmodel checking of DMS against MSO-FO is decidable, by a reduction to the\nsatisfiability problem of MSO over nested words.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 14:01:21 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Aiswarya", "C.", ""], ["Atig", "Mohamed Faouzi", ""], ["Montali", "Marco", ""], ["Rezine", "Othmane", ""]]}, {"id": "1604.03471", "submitter": "Romain Brenguier", "authors": "Romain Brenguier", "title": "Optimal Assumptions for Synthesis", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controller synthesis is the process of constructing a correct system\nautomatically from its specification. This often requires assumptions about the\nbehaviour of the environment. It is difficult for the designer to identify the\nassumptions that ensures the existence of a correct controller, and doing so\nmanually can lead to assumptions that are stronger than necessary. As a\nconsequence the generated controllers are suboptimal in terms of generality and\nrobustness. In this work, given a specification, we identify the weakest\nassumptions that ensures the existence of a controller. We also consider two\nimportant classes of assumptions: the ones that can be ensured by the\nenvironment and assumptions that speaks only about inputs of the systems. We\nshow that optimal assumptions correspond to strongly winning strategies,\nadmissible strategies and remorsefree strategies respectively. Based on this\ncorrespondence, we propose an algorithm for computing optimal assumptions that\ncan be ensured by the environment.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 16:27:31 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Brenguier", "Romain", ""]]}, {"id": "1604.03515", "submitter": "Vladislav Ryzhikov Dr", "authors": "Davide Bresolin, Agi Kurucz, Emilio Mu\\~noz-Velasco, Vladislav\n  Ryzhikov, Guido Sciavicco, Michael Zakharyaschev", "title": "Horn Fragments of the Halpern-Shoham Interval Temporal Logic (Technical\n  Report)", "comments": null, "journal-ref": "ACM Trans. Comput. Logic 18, 3, Article 22 (August 2017), 39 pages", "doi": "10.1145/3105909", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the satisfiability problem for Horn fragments of the\nHalpern-Shoham interval temporal logic depending on the type (box or diamond)\nof the interval modal operators, the type of the underlying linear order\n(discrete or dense), and the type of semantics for the interval relations\n(reflexive or irreflexive). For example, we show that satisfiability of Horn\nformulas with diamonds is undecidable for any type of linear orders and\nsemantics. On the contrary, satisfiability of Horn formulas with boxes is\ntractable over both discrete and dense orders under the reflexive semantics and\nover dense orders under the irreflexive semantics, but becomes undecidable over\ndiscrete orders under the irreflexive semantics. Satisfiability of binary Horn\nformulas with both boxes and diamonds is always undecidable under the\nirreflexive semantics.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 18:43:02 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 15:07:04 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 10:16:50 GMT"}, {"version": "v4", "created": "Sun, 28 May 2017 13:35:38 GMT"}, {"version": "v5", "created": "Mon, 28 Aug 2017 14:11:39 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Bresolin", "Davide", ""], ["Kurucz", "Agi", ""], ["Mu\u00f1oz-Velasco", "Emilio", ""], ["Ryzhikov", "Vladislav", ""], ["Sciavicco", "Guido", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1604.03687", "submitter": "Robert Brijder", "authors": "Robert Brijder and David Doty and David Soloveichik", "title": "Democratic, Existential, and Consensus-Based Output Conventions in\n  Stable Computation by Chemical Reaction Networks", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.DC cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that some natural output conventions for error-free computation in\nchemical reaction networks (CRN) lead to a common level of computational\nexpressivity. Our main results are that the standard consensus-based output\nconvention have equivalent computational power to (1) existence-based and (2)\ndemocracy-based output conventions. The CRNs using the former output convention\nhave only \"yes\" voters, with the interpretation that the CRN's output is yes if\nany voters are present and no otherwise. The CRNs using the latter output\nconvention define output by majority vote among \"yes\" and \"no\" voters.\n  Both results are proven via a generalized framework that simultaneously\ncaptures several definitions, directly inspired by a Petri net result of\nEsparza, Ganty, Leroux, and Majumder [CONCUR 2015]. These results support the\nthesis that the computational expressivity of error-free CRNs is intrinsic, not\nsensitive to arbitrary definitional choices.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 08:28:42 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 12:11:14 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Brijder", "Robert", ""], ["Doty", "David", ""], ["Soloveichik", "David", ""]]}, {"id": "1604.03773", "submitter": "EPTCS", "authors": "Youssouf Oualhadj (LACL, U-PEC, Paris, France), Nicolas Troquard\n  (LACL, U-PEC, Paris, France)", "title": "Rational Verification in Iterated Electric Boolean Games", "comments": "In Proceedings SR 2016, arXiv:1607.02694", "journal-ref": "EPTCS 218, 2016, pp. 41-51", "doi": "10.4204/EPTCS.218.4", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric boolean games are compact representations of games where the players\nhave qualitative objectives described by LTL formulae and have limited\nresources. We study the complexity of several decision problems related to the\nanalysis of rationality in electric boolean games with LTL objectives. In\nparticular, we report that the problem of deciding whether a profile is a Nash\nequilibrium in an iterated electric boolean game is no harder than in iterated\nboolean games without resource bounds. We show that it is a PSPACE-complete\nproblem. As a corollary, we obtain that both rational elimination and rational\nconstruction of Nash equilibria by a supervising authority are PSPACE-complete\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 13:51:59 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 13:47:18 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Oualhadj", "Youssouf", "", "LACL, U-PEC, Paris, France"], ["Troquard", "Nicolas", "", "LACL, U-PEC, Paris, France"]]}, {"id": "1604.03793", "submitter": "Florian Lonsing", "authors": "Tomas Balyo and Florian Lonsing", "title": "HordeQBF: A Modular and Massively Parallel QBF Solver", "comments": "camera-ready version, 6-page tool paper, to appear in the proceedings\n  of SAT 2016, LNCS, Springer", "journal-ref": null, "doi": "10.1007/978-3-319-40970-2_33", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently developed massively parallel satisfiability (SAT) solver\nHordeSAT was designed in a modular way to allow the integration of any\nsequential CDCL-based SAT solver in its core. We integrated the QCDCL-based\nquantified Boolean formula (QBF) solver DepQBF in HordeSAT to obtain a\nmassively parallel QBF solver---HordeQBF. In this paper we describe the details\nof this integration and report on results of the experimental evaluation of\nHordeQBF's performance. HordeQBF achieves superlinear average and median\nspeedup on the hard application instances of the 2014 QBF Gallery.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 14:21:34 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Balyo", "Tomas", ""], ["Lonsing", "Florian", ""]]}, {"id": "1604.03799", "submitter": "Nicolai Kraus", "authors": "Thorsten Altenkirch, Paolo Capriotti, Nicolai Kraus", "title": "Extending Homotopy Type Theory with Strict Equality", "comments": "16 pages", "journal-ref": "25th EACSL Annual Conference on Computer Science Logic (CSL 2016),\n  Leibniz International Proceedings in Informatics (LIPIcs), volume 62, pages\n  21:1-21:17, 2016", "doi": "10.4230/LIPIcs.CSL.2016.21", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In homotopy type theory (HoTT), all constructions are necessarily stable\nunder homotopy equivalence. This has shortcomings: for example, it is believed\nthat it is impossible to define a type of semi-simplicial types. More\ngenerally, it is difficult and often impossible to handle towers of coherences.\nTo address this, we propose a 2-level theory which features both strict and\nweak equality. This can essentially be represented as two type theories: an\n\"outer\" one, containing a strict equality type former, and an \"inner\" one,\nwhich is some version of HoTT. Our type theory is inspired by Voevosky's\nsuggestion of a homotopy type system (HTS) which currently refers to a range of\nideas. A core insight of our proposal is that we no not need any form of\nequality reflection in order to achieve what HTS was suggested for. Instead,\nhaving unique identity proofs in the outer type theory is sufficient, and it\nalso has the meta-theoretical advantage of not breaking decidability of type\nchecking. The inner theory can be an easily justifiable extensions of HoTT,\nallowing the construction of \"infinite structures\" which are considered\nimpossible in plain HoTT. Alternatively, we can set the inner theory to be\nexactly the current standard formulation of HoTT, in which case our system can\nbe thought of as a type-theoretic framework for working with \"schematic\"\ndefinitions in HoTT. As demonstrations, we define semi-simplicial types and\nformalise constructions of Reedy fibrant diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 14:28:53 GMT"}, {"version": "v2", "created": "Sat, 29 Oct 2016 13:53:41 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Altenkirch", "Thorsten", ""], ["Capriotti", "Paolo", ""], ["Kraus", "Nicolai", ""]]}, {"id": "1604.03962", "submitter": "Mark Reynolds", "authors": "Mark Reynolds", "title": "A traditional tree-style tableau for LTL", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional linear time temporal logic (LTL) is the standard temporal logic\nfor computing applications and many reasoning techniques and tools have been\ndeveloped for it. Tableaux for deciding satisfiability have existed since the\n1980s. However, the tableaux for this logic do not look like traditional\ntree-shaped tableau systems and their processing is often quite complicated. We\npresent a new simple traditional-style tree-shaped tableau for LTL and prove\nthat it is sound and complete. As well as being simple to understand, to\nintroduce to students and to use manually, it also seems simple to implement\nand promises to be competitive in its automation. It is particularly suitable\nfor parallel implementations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 20:18:29 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Reynolds", "Mark", ""]]}, {"id": "1604.04114", "submitter": "Ekaterina Komendantskaya Dr", "authors": "Peng Fu and Ekaterina Komendantskaya", "title": "Operational Semantics of Resolution and Productivity in Horn Clause\n  Logic", "comments": "Journal Formal Aspect of Computing, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of operational and type-theoretic properties of\ndifferent resolution strategies in Horn clause logic. We distinguish four\ndifferent kinds of resolution: resolution by unification (SLD-resolution),\nresolution by term-matching, the recently introduced structural resolution, and\npartial (or lazy) resolution. We express them all uniformly as abstract\nreduction systems, which allows us to undertake a thorough comparative analysis\nof their properties. To match this small-step semantics, we propose to take\nHoward's System H as a type-theoretic semantic counterpart. Using System H, we\ninterpret Horn formulas as types, and a derivation for a given formula as the\nproof term inhabiting the type given by the formula. We prove soundness of\nthese abstract reduction systems relative to System H, and we show completeness\nof SLD-resolution and structural resolution relative to System H. We identify\nconditions under which structural resolution is operationally equivalent to\nSLD-resolution. We show correspondence between term-matching resolution for\nHorn clause programs without existential variables and term rewriting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 11:24:16 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 17:20:55 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Fu", "Peng", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1604.04139", "submitter": "Yassine Hachaichi", "authors": "Yassine Hacha\\\"ichi (LAMSIN)", "title": "Logic for Unambiguous Context-Free Languages", "comments": null, "journal-ref": "International Journal of Computer Science Theory and Application,\n  ORB Academic Publisher, 2016, 5 (1), pp.12-19", "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give in this paper a logical characterization for unambiguous Context Free\nLanguages, in the vein of descriptive complexity. A fragment of the logic\ncharacterizing context free languages given by Lautemann, Schwentick and\nTh\\'erien [18] based on implicit definability is used for this aim. We obtain a\nnew connection between two undecidable problems, a logical one and a language\ntheoretical one.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 09:40:14 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Hacha\u00efchi", "Yassine", "", "LAMSIN"]]}, {"id": "1604.04164", "submitter": "Elena Botoeva", "authors": "Elena Botoeva, Carsten Lutz, Vladislav Ryzhikov, Frank Wolter, Michael\n  Zakharyaschev", "title": "Query-Based Entailment and Inseparability for ALC Ontologies (Full\n  Version)", "comments": "The full version of the paper accepted at IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem whether two ALC knowledge bases are\nindistinguishable by queries over a given vocabulary. We give model-theoretic\ncriteria in terms of (partial) homomorphisms and products and prove that this\nproblem is undecidable for conjunctive queries (CQs) but 2EXPTIME-complete for\nUCQs (unions of CQs). The same results hold if CQs are replaced by rooted CQs.\nWe also consider the problem whether two ALC TBoxes give the same answers to\nany query in a given vocabulary over all ABoxes, and show that for CQs this\nproblem is undecidable, too, but becomes decidable and 2EXPTIME-complete in\nHorn-ALC, and even EXPTIME-complete in Horn-ALC when restricted to (unions of)\nrooted CQs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 14:16:39 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 21:34:19 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Botoeva", "Elena", ""], ["Lutz", "Carsten", ""], ["Ryzhikov", "Vladislav", ""], ["Wolter", "Frank", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1604.04197", "submitter": "Christina Rickmann", "authors": "Christina Rickmann", "title": "Topological Self-Stabilization with Name-Passing Process Calculi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological self-stabilization describes the ability of a distributed system\nto let the nodes themselves establish a meaningful overlay network. Independent\nfrom the initial network topology, the system converges to the desired topology\nvia forwarding, inserting, and deleting links to neighboring nodes.\nName-passing process calculi, like the pi-calculus, are a well-known and widely\nused method to model concurrent and distributed algorithms. The pi-calculus is\ndesigned to naturally express processes with a changing link infrastructure, as\nthe communication between processes may carry information that can be used for\na change in the linkage between the processes. We redesign a simple local\nlinearization algorithm with asynchronous message-passing that was originally\ndesigned for a shared memory model. We use an extended localized pi-calculus, a\nvariant of the pi-calculus, to model the algorithm. Subsequently, we formally\nprove the self-stabilizing properties closure, weak convergence for every\narbitrary initial configuration, and strong convergence for two special cases.\nIn our proofs we utilize rather an assertional reasoning than an action-based\nstyle. Furthermore, we describe the challenges in proving (strong) convergence\nin the general case. Additionally, we give strong arguments for strong\nconvergence, supported by further proven lemmata, and discuss different\napproaches for a formal proof.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 15:58:16 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Rickmann", "Christina", ""]]}, {"id": "1604.04240", "submitter": "Andrew Mironov", "authors": "Andrew M. Mironov", "title": "A New Method of Verification of Functional Programs", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper the problem of verification of functional programs (FPs) over\nstrings is considered, where specifications of properties of FPs are defined by\nother FPs, and a FP S1 meets a specification defined by another FP S2 iff a\ncomposition of functions defined by the FPs S1 and S2 is equal to the constant\n1. We introduce a concept of a state diagram of a FP, and reduce the\nverification problem to the problem of an analysis of the state diagrams of\nFPs. The proposed approach is illustrated by the example of verification of a\nsorting program.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 18:01:57 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Mironov", "Andrew M.", ""]]}, {"id": "1604.04295", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Nachum Dershowitz and Pierre N\\'eron", "title": "Axiomatizing Analog Algorithms", "comments": null, "journal-ref": "Computability in Europe 2016: Pursuit of the Universal (CiE),\n  Paris, France, Lecture Notes in Computer Science, vol. 9709, Springer-Verlag,\n  Switzerland, pp. 215-224 (2016)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalization of generic algorithms that includes analog\nalgorithms. This is achieved by reformulating and extending the framework of\nabstract state machines to include continuous-time models of computation. We\nprove that every hybrid algorithm satisfying some reasonable postulates may be\nexpressed precisely by a program in a simple and expressive language.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 20:13:44 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2016 19:57:51 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bournez", "Olivier", ""], ["Dershowitz", "Nachum", ""], ["N\u00e9ron", "Pierre", ""]]}, {"id": "1604.04344", "submitter": "Anna Mikhailovich", "authors": "Anna Mikhailovich", "title": "Some Closed Classes of Three-Valued Logic Generated by Periodic\n  Symmetric Functions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closed classes of three-valued logic generated by periodic symmetric funtions\nthat equal $1$ in tuples from $\\{1,2\\}^n$ and equal $0$ on the rest tuples are\nconsidered. Criteria for bases existence and finite bases existence for these\nclasses is obtained.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 03:27:16 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Mikhailovich", "Anna", ""]]}, {"id": "1604.04390", "submitter": "J\\\"urgen Koslowski", "authors": "Simon Castellan (LIP), Pierre Clairambault (LIP), Silvain Rideau,\n  Glynn Winskel", "title": "Games and Strategies as Event Structures", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  29, 2017) lmcs:3966", "doi": "10.23638/LMCS-13(3:35)2017", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2011, Rideau and Winskel introduced concurrent games and strategies as\nevent structures, generalizing prior work on causal formulations of games. In\nthis paper we give a detailed, self-contained and slightly-updated account of\nthe results of Rideau and Winskel: a notion of pre-strategy based on event\nstructures; a characterisation of those pre-strategies (deemed strategies)\nwhich are preserved by composition with a copycat strategy; and the\nconstruction of a bicategory of these strategies. Furthermore, we prove that\nthe corresponding category has a compact closed structure, and hence forms the\nbasis for the semantics of concurrent higher-order computation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 07:43:47 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 15:35:54 GMT"}, {"version": "v3", "created": "Tue, 10 Jan 2017 14:23:28 GMT"}, {"version": "v4", "created": "Tue, 16 May 2017 09:37:50 GMT"}, {"version": "v5", "created": "Wed, 27 Sep 2017 19:15:05 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Castellan", "Simon", "", "LIP"], ["Clairambault", "Pierre", "", "LIP"], ["Rideau", "Silvain", ""], ["Winskel", "Glynn", ""]]}, {"id": "1604.04435", "submitter": "Vojtech Forejt", "authors": "Vojt\\v{e}ch Forejt, Marta Kwiatkowska, Gethin Norman and Ashutosh\n  Trivedi", "title": "Expected Reachability-Time Games", "comments": "Manuscript accepted to Theoretical Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic timed automata are a suitable formalism to model systems with\nreal-time, nondeterministic and probabilistic behaviour. We study two-player\nzero-sum games on such automata where the objective of the game is specified as\nthe expected time to reach a target. The two players---called player Min and\nplayer Max---compete by proposing timed moves simultaneously and the move with\na shorter delay is performed. The first player attempts to minimise the given\nobjective while the second tries to maximise the objective. We observe that\nthese games are not determined, and study decision problems related to\ncomputing the upper and lower values, showing that the problems are decidable\nand lie in the complexity class NEXPTIME $\\cap$ co-NEXPTIME.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 11:31:04 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Forejt", "Vojt\u011bch", ""], ["Kwiatkowska", "Marta", ""], ["Norman", "Gethin", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1604.04575", "submitter": "Roly Perera", "authors": "Roly Perera, James Cheney", "title": "Proof-relevant $\\pi$-calculus: a constructive account of concurrency and\n  causality", "comments": "Under consideration for publication in Mathematical Structures in\n  Computer Science. arXiv admin note: text overlap with arXiv:1507.08054", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formalisation in Agda of the theory of concurrent transitions,\nresiduation, and causal equivalence of traces for the pi-calculus. Our\nformalisation employs de Bruijn indices and dependently-typed syntax, and\naligns the \"proved transitions\" proposed by Boudol and Castellani in the\ncontext of CCS with the proof terms naturally present in Agda's representation\nof the labelled transition relation. Our main contributions are proofs of the\n\"diamond lemma\" for the residuals of concurrent transitions and a formal\ndefinition of equivalence of traces up to permutation of transitions.\n  In the pi-calculus transitions represent propagating binders whenever their\nactions involve bound names. To accommodate these cases, we require a more\ngeneral diamond lemma where the target states of equivalent traces are no\nlonger identical, but are related by a braiding that rewires the bound and free\nnames to reflect the particular interleaving of events involving binders. Our\napproach may be useful for modelling concurrency in other languages where\ntransitions carry metadata sensitive to particular interleavings, such as\ndynamically allocated memory addresses.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 17:26:22 GMT"}, {"version": "v2", "created": "Sun, 5 Feb 2017 12:13:09 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Perera", "Roly", ""], ["Cheney", "James", ""]]}, {"id": "1604.04983", "submitter": "Tahiry  Rabehaja", "authors": "N. Bordenabe, A. McIver, C Morgan and T. Rabehaja", "title": "Compositional security and collateral leakage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantitative information flow we say that program $Q$ is \"at least as\nsecure as\" $P$ just when the amount of secret information flowing from $Q$ is\nnever more than flows from $P$, with of course a suitable quantification of\n\"flow\". This secure-refinement order $\\sqsubseteq$ is compositional just when\n$P{\\sqsubseteq}Q$ implies ${\\cal C}(P){\\sqsubseteq}{\\cal C}(Q)$ for any context\n${\\cal C}$, again with a suitable definition of \"context\".\n  Remarkable however is that leaks caused by executing $P,Q$ might not be\nlimited to their declared variables: they might impact correlated secrets in\nvariables declared and initialised in some broader context to which $P,Q$ do\nnot refer even implicitly. We call such leaks collateral because their effect\nis felt in domains of which (the programmers of) $P, Q$ might be wholly\nunaware: our inspiration is the \"Dalenius\" phenomenon for statistical\ndatabases.\n  We show that a proper treatment of these collateral leaks is necessary for a\ncompositional program semantics for read/write \"open\" programs. By adapting a\nrecent Hidden-Markov denotational model for non-interference security, so that\nit becomes \"collateral aware\", we give techniques and examples (e.g.\\\npublic-key encryption) to show how collateral leakage can be calculated and\nthen bounded in its severity.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 04:52:20 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Bordenabe", "N.", ""], ["McIver", "A.", ""], ["Morgan", "C", ""], ["Rabehaja", "T.", ""]]}, {"id": "1604.05006", "submitter": "Heng Zhang", "authors": "Heng Zhang, Yan Zhang, Jia-Huai You", "title": "Expressive Completeness of Existential Rule Languages for Ontology-based\n  Query Answering", "comments": "10 pages; the full version of a paper to appear in IJCAI 2016.\n  Changes (regarding to v1): a new reference has been added, and some typos\n  have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules, also known as data dependencies in Databases, have been\nrecently rediscovered as a promising family of languages for Ontology-based\nQuery Answering. In this paper, we prove that disjunctive embedded dependencies\nexactly capture the class of recursively enumerable ontologies in\nOntology-based Conjunctive Query Answering (OCQA). Our expressive completeness\nresult does not rely on any built-in linear order on the database. To establish\nthe expressive completeness, we introduce a novel semantic definition for OCQA\nontologies. We also show that neither the class of disjunctive tuple-generating\ndependencies nor the class of embedded dependencies is expressively complete\nfor recursively enumerable OCQA ontologies.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 06:16:49 GMT"}, {"version": "v2", "created": "Wed, 27 Apr 2016 13:22:52 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""], ["You", "Jia-Huai", ""]]}, {"id": "1604.05047", "submitter": "Thomas Seiller", "authors": "Thomas Seiller", "title": "From Dynamic to Static Semantics, Quantitatively", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit a new relationship between dynamic and static semantics. We define\nthe categorical outlay needed to define Interaction Graphs models, a\ngeneralisation of Girard's Geometry of Interaction models, which strongly\nrelate to game semantics. We then show how this category is mapped to weighted\nrelational models of linear logic. This brings into vision a new bridge between\nthe dynamic and static approaches, and provides formal grounds for considering\ninteraction graphs models as quantitative versions of GoI and game semantics\nmodels. We finally proceed to show how the interaction graphs models relate to\na very general notion of quantitative coherence spaces.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 09:09:48 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Seiller", "Thomas", ""]]}, {"id": "1604.05086", "submitter": "Ji Ruan", "authors": "Xiaowei Huang, Ji Ruan, Qingliang Chen and Kaile Su", "title": "Normative Multiagent Systems: A Dynamic Generalization", "comments": "26 pages. A conference version of this work is accepted by the 25th\n  International Joint Conference on Artificial Intelligence (IJCAI-16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social norms are powerful formalism in coordinating autonomous agents'\nbehaviour to achieve certain objectives. In this paper, we propose a dynamic\nnormative system to enable the reasoning of the changes of norms under\ndifferent circumstances, which cannot be done in the existing static normative\nsystems. We study two important problems (norm synthesis and norm recognition)\nrelated to the autonomy of the entire system and the agents, and characterise\nthe computational complexities of solving these problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 11:07:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Huang", "Xiaowei", ""], ["Ruan", "Ji", ""], ["Chen", "Qingliang", ""], ["Su", "Kaile", ""]]}, {"id": "1604.05258", "submitter": "Roman Kontchakov", "authors": "Meghyn Bienvenu, Stanislav Kikot, Roman Kontchakov, Vladimir V.\n  Podolskii and Michael Zakharyaschev", "title": "Theoretically Optimal Datalog Rewritings for OWL 2 QL Ontology-Mediated\n  Queries", "comments": "full version of the paper in the Proc. of the 29th Int. Workshop on\n  Description Logics (DL 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, for OWL 2 QL ontology-mediated queries with (i) ontologies of\nbounded depth and conjunctive queries of bounded treewidth, (ii) ontologies of\nbounded depth and bounded-leaf tree-shaped conjunctive queries, and (iii)\narbitrary ontologies and bounded-leaf tree-shaped conjunctive queries, one can\nconstruct and evaluate nonrecursive datalog rewritings by, respectively,\nLOGCFL, NL and LOGCFL algorithms, which matches the optimal combined\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 17:29:26 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Kikot", "Stanislav", ""], ["Kontchakov", "Roman", ""], ["Podolskii", "Vladimir V.", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1604.05543", "submitter": "Thorsten Wissmann", "authors": "Alexander Weinert and Martin Zimmermann", "title": "Easy to Win, Hard to Master: Optimal Strategies in Parity Games with\n  Costs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  19, 2017) lmcs:3938", "doi": "10.23638/LMCS-13(3:29)2017", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The winning condition of a parity game with costs requires an arbitrary, but\nfixed bound on the cost incurred between occurrences of odd colors and the next\noccurrence of a larger even one. Such games quantitatively extend parity games\nwhile retaining most of their attractive properties, i.e, determining the\nwinner is in NP and co-NP and one player has positional winning strategies.\n  We show that the characteristics of parity games with costs are vastly\ndifferent when asking for strategies realizing the minimal such bound: The\nsolution problem becomes PSPACE-complete and exponential memory is both\nnecessary in general and always sufficient. Thus, solving and playing parity\ngames with costs optimally is harder than just winning them. Moreover, we show\nthat the tradeoff between the memory size and the realized bound is gradual in\ngeneral. All these results hold true for both a unary and binary encoding of\ncosts.\n  Moreover, we investigate Streett games with costs. Here, playing optimally is\nas hard as winning, both in terms of complexity and memory.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 12:46:14 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 13:20:37 GMT"}, {"version": "v3", "created": "Thu, 10 Aug 2017 11:12:01 GMT"}, {"version": "v4", "created": "Mon, 18 Sep 2017 13:16:40 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Weinert", "Alexander", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1604.05555", "submitter": "Claudio Mezzina", "authors": "Claudio Antares Mezzina and Vasileios Koutavas", "title": "A Safety and Liveness Theory for Total Reversibility (Extended Abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the theory of safety and liveness in a reversible calculus where\nreductions are totally ordered and rollbacks lead the systems to past states.\nSimilar to previous work on communicating transactions, liveness and safety\nrespectively correspond to the should-testing and inverse may-testing\npreorders. We develop fully abstract models for these preorders in a reversible\ncalculus, which are based only on forward transitions, thus providing a simple\nproof technique for refinement of such systems. We show that with respect to\nsafety, total reversibility is a conservative extension to CCS. With respect to\nliveness, however, adding total reversibility to CCS distinguishes more\nsystems. To our knowledge, this work provides the first characterisations of\nsafety and liveness, and the first testing theory for a reversible calculus.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 13:23:57 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 14:57:43 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Mezzina", "Claudio Antares", ""], ["Koutavas", "Vasileios", ""]]}, {"id": "1604.05692", "submitter": "Florian Brandl", "authors": "Florian Brandl, Felix Brandt, Manuel Eberl and Christian Geist", "title": "Proving the Incompatibility of Efficiency and Strategyproofness via SMT\n  Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two important requirements when aggregating the preferences of multiple\nagents are that the outcome should be economically efficient and the\naggregation mechanism should not be manipulable. In this paper, we provide a\ncomputer-aided proof of a sweeping impossibility using these two conditions for\nrandomized aggregation mechanisms. More precisely, we show that every efficient\naggregation mechanism can be manipulated for all expected utility\nrepresentations of the agents' preferences. This settles an open problem and\nstrengthens a number of existing theorems, including statements that were shown\nwithin the special domain of assignment. Our proof is obtained by formulating\nthe claim as a satisfiability problem over predicates from real-valued\narithmetic, which is then checked using an SMT (satisfiability modulo theories)\nsolver. In order to verify the correctness of the result, a minimal\nunsatisfiable set of constraints returned by the SMT solver was translated back\ninto a proof in higher-order logic, which was automatically verified by an\ninteractive theorem prover. To the best of our knowledge, this is the first\napplication of SMT solvers in computational social choice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 19:01:55 GMT"}, {"version": "v2", "created": "Sat, 23 Apr 2016 10:21:50 GMT"}, {"version": "v3", "created": "Thu, 16 Jun 2016 12:19:30 GMT"}, {"version": "v4", "created": "Wed, 6 Sep 2017 16:03:25 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Brandl", "Florian", ""], ["Brandt", "Felix", ""], ["Eberl", "Manuel", ""], ["Geist", "Christian", ""]]}, {"id": "1604.05843", "submitter": "Thomas Zeume", "authors": "Thomas Zeume and Frederik Harwath", "title": "Order-Invariance of Two-Variable Logic is Decidable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that order-invariance of two-variable first-logic is decidable in\nthe finite. This is an immediate consequence of a decision procedure obtained\nfor the finite satisfiability problem for existential second-order logic with\ntwo first-order variables ($\\mathrm{ESO}^2$) on structures with two linear\norders and one induced successor. We also show that finite satisfiability is\ndecidable on structures with two successors and one induced linear order. In\nboth cases, so far only decidability for monadic $\\mathrm{ESO}^2$ has been\nknown. In addition, the finite satisfiability problem for $\\mathrm{ESO}^2$ on\nstructures with one linear order and its induced successor relation is shown to\nbe decidable in non-deterministic exponential time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 06:53:18 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Zeume", "Thomas", ""], ["Harwath", "Frederik", ""]]}, {"id": "1604.05948", "submitter": "Chris Heunen", "authors": "Chris Heunen and Aleks Kissinger", "title": "The CBH characterisation theorem beyond algebraic quantum theory", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CBH theorem characterises quantum theory within a C*-algebraic framework.\nNamely, mathematical properties of C*-algebras modelling quantum systems are\nequivalent to constraints that are information-theoretic in nature: (1)\nnoncommutativity of subalgebras is equivalent to impossibility of signalling;\n(2) noncommutativity of the whole algebra is equivalent to impossibility of\nbroadcasting; (3) the existence of entangled states is implied by the\nimpossibility of secure bit commitment (with the converse conjectured).\nHowever, the C*-algebraic framework has drawn criticism as it already contains\nmuch of themathematical structure of quantum theory such as complex linearity.\nWe address this issue by a generalising C*-algebras categorically. In this\nframework, equivalence (1) holds, equivalence (2) becomes a strict implication,\nand implication (3) fails in general. Thus we identify exactly what work is\nbeing done by the complex-linear structure of C*-algebras. In doing so, we\nuncover a richer hierarchy of notions of 'classicality' and 'quantumness' of\ninformation than visible in the concrete case.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 13:27:42 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2016 14:45:05 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 08:47:08 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 15:11:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Heunen", "Chris", ""], ["Kissinger", "Aleks", ""]]}, {"id": "1604.05994", "submitter": "Florian Lonsing", "authors": "Florian Lonsing, Uwe Egly, and Martina Seidl", "title": "Q-Resolution with Generalized Axioms", "comments": "(minor fixes) camera-ready version + appendix; to appear in the\n  proceedings of SAT 2016, LNCS, Springer", "journal-ref": null, "doi": "10.1007/978-3-319-40970-2_27", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-resolution is a proof system for quantified Boolean formulas (QBFs) in\nprenex conjunctive normal form (PCNF) which underlies search-based QBF solvers\nwith clause and cube learning (QCDCL). With the aim to derive and learn\nstronger clauses and cubes earlier in the search, we generalize the axioms of\nthe Q-resolution calculus resulting in an exponentially more powerful proof\nsystem. The generalized axioms introduce an interface of Q-resolution to any\nother QBF proof system allowing for the direct combination of orthogonal\nsolving techniques. We implemented a variant of the Q-resolution calculus with\ngeneralized axioms in the QBF solver DepQBF. As two case studies, we apply\nintegrated SAT solving and resource-bounded QBF preprocessing during the search\nto heuristically detect potential axiom applications. Experiments with\napplication benchmarks indicate a substantial performance improvement.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 15:07:24 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 12:17:47 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Lonsing", "Florian", ""], ["Egly", "Uwe", ""], ["Seidl", "Martina", ""]]}, {"id": "1604.06038", "submitter": "J\\\"urgen Koslowski", "authors": "Witold Charatonik and Piotr Witkowski", "title": "Two-variable Logic with Counting and a Linear Order", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 2 (June 23,\n  2016) lmcs:1640", "doi": "10.2168/LMCS-12(2:8)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the finite satisfiability problem for the two-variable fragment of\nfirst-order logic extended with counting quantifiers (C2) and interpreted over\nlinearly ordered structures. We show that the problem is undecidable in the\ncase of two linear orders (in the presence of two other binary symbols). In the\ncase of one linear order it is NEXPTIME-complete, even in the presence of the\nsuccessor relation. Surprisingly, the complexity of the problem explodes when\nwe add one binary symbol more: C2 with one linear order and in the presence of\nother binary predicate symbols is equivalent, under elementary reductions, to\nthe emptiness problem for multicounter automata.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 17:15:21 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 12:43:24 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Charatonik", "Witold", ""], ["Witkowski", "Piotr", ""]]}, {"id": "1604.06061", "submitter": "Viktor Winschel", "authors": "Jules Hedges, Evguenia Shprits, Viktor Winschel, Philipp Zahn", "title": "Compositionality and String Diagrams for Game Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce string diagrams as a formal mathematical, graphical language to\nrepresent, compose, program and reason about games. The language is well\nestablished in quantum physics, quantum computing and quantum linguistic with\nthe semantics given by category theory. We apply this language to the game\ntheoretical setting and show examples how to use it for some economic games\nwhere we highlight the compositional nature of our higher-order game theory.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 19:03:10 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Hedges", "Jules", ""], ["Shprits", "Evguenia", ""], ["Winschel", "Viktor", ""], ["Zahn", "Philipp", ""]]}, {"id": "1604.06118", "submitter": "Andrey Gorlin", "authors": "Andrey Gorlin and C. R. Ramakrishnan", "title": "XPL: An extended probabilistic logic for probabilistic transition\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Probabilistic Logic (GPL) is a temporal logic, based on the modal\nmu-calculus, for specifying properties of reactive probabilistic systems. We\nexplore XPL, an extension to GPL allowing the semantics of nondeterminism\npresent in Markov decision processes (MDPs). XPL is expressive enough that a\nnumber of independently studied problems--- such as termination of Recursive\nMDPs (RMDPs), PCTL* model checking of MDPs, and reachability for Branching\nMDPs--- can all be cast as model checking over XPL. Termination of multi-exit\nRMDPs is undecidable; thus, model checking in XPL is undecidable in general. We\ndefine a subclass, called separable XPL, for which model checking is decidable.\nDecidable problems such as termination of 1-exit RMDPs, PCTL* model checking of\nMDPs, and reachability for Branching MDPs can be reduced to model checking\nseparable XPL. Thus, XPL forms a uniform framework for studying problems\ninvolving systems with non-deterministic and probabilistic behaviors, while\nseparable XPL provides a way to solve decidable fragments of these problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 20:31:41 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 15:57:47 GMT"}, {"version": "v3", "created": "Sat, 22 Oct 2016 19:36:28 GMT"}, {"version": "v4", "created": "Thu, 12 Jan 2017 00:36:57 GMT"}, {"version": "v5", "created": "Tue, 9 May 2017 17:40:38 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Gorlin", "Andrey", ""], ["Ramakrishnan", "C. R.", ""]]}, {"id": "1604.06139", "submitter": "Daniel Hono", "authors": "Daniel S. Hono II, Namrata Galatage, Kimberly A. Gero, Paliath\n  Narendran, Ananya Subburathinam", "title": "Notes on Lynch-Morawska Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-SUNYA-CS-16-01", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate convergent term rewriting systems that conform\nto the criteria set out by Christopher Lynch and Barbara Morawska in their\nseminal paper \"Basic Syntactic Mutation.\" The equational unification problem\nmodulo such a rewrite system is solvable in polynomial-time. In this paper, we\nderive properties of such a system which we call an $LM$-system. We show, in\nparticular, that the rewrite rules in an $LM$-system have no left- or\nright-overlaps. We also show that despite the restricted nature of an\n$LM$-system, there are important undecidable problems, such as the deduction\nproblem in cryptographic protocol analysis (also called the the cap problem)\nthat remain undecidable for $LM$-systems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 22:56:59 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 02:20:32 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Hono", "Daniel S.", "II"], ["Galatage", "Namrata", ""], ["Gero", "Kimberly A.", ""], ["Narendran", "Paliath", ""], ["Subburathinam", "Ananya", ""]]}, {"id": "1604.06204", "submitter": "Robert Koenighofer", "authors": "Roderick Bloem and Uwe Egly and Patrick Klampfl and Robert\n  K\\\"onighofer and Florian Lonsing and Martina Seidl", "title": "Satisfiability-Based Methods for Reactive Synthesis from Safety\n  Specifications", "comments": "This is the manuscript of an article that has been submitted to the\n  Journal of Computer and System Sciences (JCSS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to synthesize reactive systems from declarative\nspecifications mostly rely on Binary Decision Diagrams (BDDs), inheriting their\nscalability issues. We present novel algorithms for safety specifications that\nuse decision procedures for propositional formulas (SAT solvers), Quantified\nBoolean Formulas (QBF solvers), or Effectively Propositional Logic (EPR). Our\nalgorithms are based on query learning, templates, reduction to EPR, QBF\ncertification, and interpolation. A parallelization combines multiple\nalgorithms. Our optimizations expand quantifiers and utilize unreachable states\nand variable independencies. Our approach outperforms a simple BDD-based tool\nand is competitive with a highly optimized one. It won two medals in the\nSyntComp competition.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 07:47:00 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Bloem", "Roderick", ""], ["Egly", "Uwe", ""], ["Klampfl", "Patrick", ""], ["K\u00f6nighofer", "Robert", ""], ["Lonsing", "Florian", ""], ["Seidl", "Martina", ""]]}, {"id": "1604.06376", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Laurent Doyen", "title": "Perfect-Information Stochastic Games with Generalized Mean-Payoff\n  Objectives", "comments": "A conference version will appear in LICS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph games provide the foundation for modeling and synthesizing reactive\nprocesses. In the synthesis of stochastic reactive processes, the traditional\nmodel is perfect-information stochastic games, where some transitions of the\ngame graph are controlled by two adversarial players, and the other transitions\nare executed probabilistically. We consider such games where the objective is\nthe conjunction of several quantitative objectives (specified as mean-payoff\nconditions), which we refer to as generalized mean-payoff objectives. The basic\ndecision problem asks for the existence of a finite-memory strategy for a\nplayer that ensures the generalized mean-payoff objective be satisfied with a\ndesired probability against all strategies of the opponent. A special case of\nthe decision problem is the almost-sure problem where the desired probability\nis 1. Previous results presented a semi-decision procedure for\nepsilon-approximations of the almost-sure problem. In this work, we show that\nboth the almost-sure problem as well as the general basic decision problem are\ncoNP-complete, significantly improving the previous results. Moreover, we show\nthat in the case of 1-player stochastic games, randomized memoryless strategies\nare sufficient and the problem can be solved in polynomial time. In contrast,\nin two-player stochastic games, we show that even with randomized strategies\nexponential memory is required in general, and present a matching exponential\nupper bound. We also study the basic decision problem with infinite-memory\nstrategies and present computational complexity results for the problem. Our\nresults are relevant in the synthesis of stochastic reactive systems with\nmultiple quantitative requirements.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 16:31:04 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""]]}, {"id": "1604.06384", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Laurent Doyen", "title": "Computation Tree Logic for Synchronization Properties", "comments": "A conference version will appear in ICALP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logic that extends CTL (Computation Tree Logic) with operators\nthat express synchronization properties. A property is synchronized in a system\nif it holds in all paths of a certain length. The new logic is obtained by\nusing the same path quantifiers and temporal operators as in CTL, but allowing\na different order of the quantifiers. This small syntactic variation induces a\nlogic that can express non-regular properties for which known extensions of MSO\nwith equality of path length are undecidable. We show that our variant of CTL\nis decidable and that the model-checking problem is in Delta_3^P = P^{NP^NP},\nand is DP-hard. We analogously consider quantifier exchange in extensions of\nCTL, and we present operators defined using basic operators of CTL* that\nexpress the occurrence of infinitely many synchronization points. We show that\nthe model-checking problem remains in Delta_3^P. The distinguishing power of\nCTL and of our new logic coincide if the Next operator is allowed in the\nlogics, thus the classical bisimulation quotient can be used for state-space\nreduction before model checking.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 16:53:48 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 14:54:05 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""]]}, {"id": "1604.06386", "submitter": "Vojtech Forejt", "authors": "Tom\\'a\\v{s} Br\\'azdil, Vojt\\v{e}ch Forejt, Anton\\'in Ku\\v{c}era and\n  Petr Novotn\\'y", "title": "Stability in Graphs and Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study graphs and two-player games in which rewards are assigned to states,\nand the goal of the players is to satisfy or dissatisfy certain property of the\ngenerated outcome, given as a mean payoff property. Since the notion of\nmean-payoff does not reflect possible fluctuations from the mean-payoff along a\nrun, we propose definitions and algorithms for capturing the stability of the\nsystem, and give algorithms for deciding if a given mean payoff and stability\nobjective can be ensured in the system\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 16:57:49 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Forejt", "Vojt\u011bch", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["Novotn\u00fd", "Petr", ""]]}, {"id": "1604.06483", "submitter": "Uwe Egly", "authors": "Uwe Egly", "title": "On Stronger Calculi for QBFs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantified Boolean formulas (QBFs) generalize propositional formulas by\nadmitting quantifications over propositional variables. QBFs can be viewed as\n(restricted) formulas of first-order predicate logic and easy translations of\nQBFs into first-order formulas exist. We analyze different translations and\nshow that first-order resolution combined with such translations can\npolynomially simulate well-known deduction concepts for QBFs. Furthermore, we\nextend QBF calculi by the possibility to instantiate a universal variable by an\nexistential variable of smaller level. Combining such an enhanced calculus with\nthe propositional extension rule results in a calculus with a universal\nquantifier rule which essentially introduces propositional formulas for\nuniversal variables. In this way, one can mimic a very general quantifier rule\nknown from sequent systems.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 20:37:53 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Egly", "Uwe", ""]]}, {"id": "1604.06503", "submitter": "Uli Fahrenberg", "authors": "Uli Fahrenberg, Axel Legay", "title": "A Linear-Time Branching-Time Spectrum for Behavioral Specification\n  Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose behavioral specification theories for most equivalences in the\nlinear-time--branching-time spectrum. Almost all previous work on specification\ntheories focuses on bisimilarity, but there is a clear interest in\nspecification theories for other preorders and equivalences. We show that\nspecification theories for preorders cannot exist and develop a general scheme\nwhich allows us to define behavioral specification theories, based on\ndisjunctive modal transition systems, for most equivalences in the\nlinear-time--branching-time spectrum.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 21:52:12 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 08:17:06 GMT"}, {"version": "v3", "created": "Mon, 10 Oct 2016 13:58:41 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 14:54:24 GMT"}, {"version": "v5", "created": "Fri, 18 Oct 2019 07:26:34 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Fahrenberg", "Uli", ""], ["Legay", "Axel", ""]]}, {"id": "1604.06509", "submitter": "Daniel Hono", "authors": "Daniel S. Hono II, Paliath Narendran, Rafael Veras", "title": "Lynch-Morawska Systems on Strings", "comments": "Revised based on reviewers' feedback", "journal-ref": null, "doi": null, "report-no": "TR-SUNYA-CS-16-02", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate properties of convergent and forward-closed string rewriting\nsystems in the context of the syntactic criteria introduced in\n\\cite{LynchMorawska} by Christopher Lynch and Barbara Morawska (we call these\n$LM$-Systems). Since a string rewriting system can be viewed as a\nterm-rewriting system over a signature of purely monadic function symbols, we\nadapt their definition to the string rewriting case. We prove that the\nsubterm-collapse problem for convergent and forward-closed string rewriting\nsystems is effectively solvable. Therefore, there exists a decision procedure\nthat verifies if such a system is an $LM$-System. We use the same construction\nto prove that the \\emph{cap problem} from the field of cryptographic protocol\nanalysis, which is undecidable for general $LM$-systems, is decidable when\nrestricted to the string rewriting case.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 22:21:13 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2016 02:39:30 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Hono", "Daniel S.", "II"], ["Narendran", "Paliath", ""], ["Veras", "Rafael", ""]]}, {"id": "1604.06617", "submitter": "Anselm Haak", "authors": "Arnaud Durand, Anselm Haak, Juha Kontinen and Heribert Vollmer", "title": "Descriptive Complexity of $\\#\\textrm{AC}^0$ Functions", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcss.2020.04.002", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new framework for a descriptive complexity approach to\narithmetic computations. We define a hierarchy of classes based on the idea of\ncounting assignments to free function variables in first-order formulae. We\ncompletely determine the inclusion structure and show that #P and #AC^0 appear\nas classes of this hierarchy. In this way, we unconditionally place #AC^0\nproperly in a strict hierarchy of arithmetic classes within #P. We compare our\nclasses with a hierarchy within #P defined in a model-theoretic way by Saluja\net al. We argue that our approach is better suited to study arithmetic circuit\nclasses such as #AC^0 which can be descriptively characterized as a class in\nour framework.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 12:04:54 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Durand", "Arnaud", ""], ["Haak", "Anselm", ""], ["Kontinen", "Juha", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1604.06747", "submitter": "Jonathan Hoyland", "authors": "Jonathan Hoyland, Matthew Hague", "title": "Generating Concurrency Checks Automatically", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces ATAB, a tool that automatically generates pairwise\nreachability checks for action trees. Action trees can be used to study the\nbehaviour of real-world concurrent programs. ATAB encodes pairwise reachability\nchecks into alternating tree automata that determine whether an action tree has\na schedule where any pair of given points in the program are simultaneously\nreachable. Because the pairwise reachability problem is undecidable in general\nATAB operates under a restricted form of lock-based concurrency. ATAB produces\nalternating tree automata that are more compact and more efficiently checkable\nthan those that have been previously used. The process is entirely automated,\nwhich simplifies the process of encoding checks for more complex action trees.\nThe alternating tree automata produced are easier to scale to large numbers of\nlocks than previous constructions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 16:52:58 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Hoyland", "Jonathan", ""], ["Hague", "Matthew", ""]]}, {"id": "1604.06752", "submitter": "EPTCS", "authors": "Jesko Hecking-Harbusch (Saarland University), Leander Tentrup\n  (Saarland University)", "title": "Solving QBF by Abstraction", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 88-102", "doi": "10.4204/EPTCS.277.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many verification and synthesis approaches rely on solving techniques for\nquantified Boolean formulas (QBF). Consequently, solution witnesses, in the\nform of Boolean functions, become more and more important as they represent\nimplementations or counterexamples. We present a recursive counterexample\nguided abstraction and refinement algorithm (CEGAR) for solving and certifying\nQBFs that exploits structural reasoning on the formula level. The algorithm\ndecomposes the given QBF into one propositional formula for every block of\nquantifiers that abstracts from assignments of variables not bound by this\nquantifier block. Further, we show how to derive an efficient certification\nextraction method on top of the algorithm. We report on experimental evaluation\nof this algorithm in the solver QuAbS (Quantified Abstraction Solver) which won\nthe most recent QBF competition (QBFEVAL'18). Further, we show the\neffectiveness of the certification approach using synthesis benchmarks and a\ncase study for synthesizing winning strategies in Petri Games.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 17:06:55 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 02:31:02 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Hecking-Harbusch", "Jesko", "", "Saarland University"], ["Tentrup", "Leander", "", "Saarland University"]]}, {"id": "1604.07030", "submitter": "Clemens Grabmayer", "authors": "Clemens Grabmayer", "title": "Linear Depth Increase of Lambda Terms along Leftmost-Outermost\n  Beta-Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing $n$ steps of $\\beta$-reduction to a given term in the\n$\\lambda$-calculus can lead to an increase in the size of the resulting term\nthat is exponential in $n$. The same is true for the possible depth increase of\nterms along a $\\beta$-reduction sequence. We explain that the situation is\ndifferent for the leftmost-outermost strategy for $\\beta$-reduction: while\nexponential size increase is still possible, depth increase is bounded linearly\nin the number of steps. For every $\\lambda$-term $M$ with depth $d$, in every\nstep of a leftmost-outermost $\\beta$-reduction rewrite sequence starting from\n$M$ the term depth increases by at most $d$. Hence the depth of the $n$-th\nreduct of $M$ in such a rewrite sequence is bounded by $d\\cdot (n+1)$.\n  We prove the lifting of this result to $\\lambda$-term representations as\northogonal first-order term rewriting systems, which can be obtained by the\nlambda-lifting transformation. For the transfer to lambda-calculus, we rely on\ncorrespondence statements via lambda-lifting. We argue that the\nlinear-depth-increase property can be a stepping stone for an alternative proof\nof, and so can shed new light on, a result by Accattoli and Dal Lago (2015)\nthat states: leftmost-outermost $\\beta$-reduction rewrite sequences of length\n$n$ in the lambda-calculus can be implemented on a reasonable machine with an\noverhead that is polynomial in $n$ and the size of the initial term.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 13:45:54 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 08:58:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Grabmayer", "Clemens", ""]]}, {"id": "1604.07064", "submitter": "Yaron Velner", "authors": "Shaull Almagor, Orna Kupferman, Yaron Velner", "title": "Minimizing Expected Cost Under Hard Boolean Constraints, with\n  Applications to Quantitative Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Boolean synthesis, we are given an LTL specification, and the goal is to\nconstruct a transducer that realizes it against an adversarial environment.\nOften, a specification contains both Boolean requirements that should be\nsatisfied against an adversarial environment, and multi-valued components that\nrefer to the quality of the satisfaction and whose expected cost we would like\nto minimize with respect to a probabilistic environment.\n  In this work we study, for the first time, mean-payoff games in which the\nsystem aims at minimizing the expected cost against a probabilistic\nenvironment, while surely satisfying an $\\omega$-regular condition against an\nadversarial environment. We consider the case the $\\omega$-regular condition is\ngiven as a parity objective or by an LTL formula. We show that in general,\noptimal strategies need not exist, and moreover, the limit value cannot be\napproximated by finite-memory strategies. We thus focus on computing the\nlimit-value, and give tight complexity bounds for synthesizing\n$\\epsilon$-optimal strategies for both finite-memory and infinite-memory\nstrategies.\n  We show that our game naturally arises in various contexts of synthesis with\nBoolean and multi-valued objectives. Beyond direct applications, in synthesis\nwith costs and rewards to certain behaviors, it allows us to compute the\nminimal sensing cost of $\\omega$-regular specifications -- a measure of quality\nin which we look for a transducer that minimizes the expected number of signals\nthat are read from the input.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 17:58:38 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Almagor", "Shaull", ""], ["Kupferman", "Orna", ""], ["Velner", "Yaron", ""]]}, {"id": "1604.07179", "submitter": "Fatemeh Ghassemi", "authors": "Behnaz Yousefi, Fatemeh Ghassemi, Ramtin Khosravi", "title": "Modeling and Efficient Verification of Wireless Ad hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wireless ad hoc networks, in particular mobile ad hoc networks (MANETs), are\ngrowing very fast as they make communication easier and more available.\nHowever, their protocols tend to be difficult to design due to topology\ndependent behavior of wireless communication, and their distributed and\nadaptive operations to topology dynamism. Therefore, it is desirable to have\nthem modeled and verified using formal methods. In this paper, we present an\nactor-based modeling language with the aim to model MANETs. We address main\nchallenges of modeling wireless ad hoc networks such as local broadcast,\nunderlying topology, and its changes, and discuss how they can be efficiently\nmodeled at the semantic level to make their verification amenable. The new\nframework abstracts the data link layer services by providing asynchronous\n(local) broadcast and unicast communication, while message delivery is in order\nand is guaranteed for connected receivers. We illustrate the applicability of\nour framework through two routing protocols, namely flooding and AODVv2-11, and\nshow how efficiently their state spaces can be reduced by the proposed\ntechniques. Furthermore, we demonstrate a loop formation scenario in AODV,\nfound by our analysis tool.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:38:14 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 07:45:56 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Yousefi", "Behnaz", ""], ["Ghassemi", "Fatemeh", ""], ["Khosravi", "Ramtin", ""]]}, {"id": "1604.07181", "submitter": "Thomas Studer", "authors": "Michel Marti and Thomas Studer", "title": "Modular Models for Intuitionistic Justification Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the logic iJT4, which is an explicit version of intuitionistic S4\nand establish soundness and completeness with respect to modular models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:42:06 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Marti", "Michel", ""], ["Studer", "Thomas", ""]]}, {"id": "1604.07201", "submitter": "Kohei Suenaga", "authors": "Kensuke Kojima and Minoru Kinoshita and Kohei Suenaga", "title": "Generalized Homogeneous Polynomials for Efficient Template-Based\n  Nonlinear Invariant Synthesis", "comments": "Presented in the 23rd Static Analysis Symposium (SAS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The template-based method is one of the most successful approaches to\nalgebraic invariant synthesis. In this method, an algorithm designates a\ntemplate polynomial p over program variables, generates constraints for p=0 to\nbe an invariant, and solves the generated constraints. However, this approach\noften suffers from an increasing template size if the degree of a template\npolynomial is too high.\n  We propose a technique to make template-based methods more efficient. Our\ntechnique is based on the following finding: If an algebraic invariant exists,\nthen there is a specific algebraic invariant that we call a generalized\nhomogeneous algebraic invariant that is often smaller. This finding justifies\nusing only a smaller template that corresponds to a generalized homogeneous\nalgebraic invariant.\n  Concretely, we state our finding above formally based on the abstract\nsemantics of an imperative program proposed by Cachera et al. Then, we modify\ntheir template-based invariant synthesis so that it generates only generalized\nhomogeneous algebraic invariants. This modification is proved to be sound.\nFurthermore, we also empirically demonstrate the merit of the restriction to\ngeneralized homogeneous algebraic invariants. Our implementation outperforms\nthat of Cachera et al. for programs that require a higher-degree template.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 11:07:05 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2016 00:50:35 GMT"}, {"version": "v3", "created": "Wed, 14 Sep 2016 00:06:16 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Kojima", "Kensuke", ""], ["Kinoshita", "Minoru", ""], ["Suenaga", "Kohei", ""]]}, {"id": "1604.07225", "submitter": "Miikka Vilander", "authors": "Lauri Hella and Miikka Vilander", "title": "The Succinctness of First-order Logic over Modal Logic via a Formula\n  Size Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new version of formula size game for modal logic. The game\ncharacterizes the equivalence of pointed Kripke-models up to formulas of given\nnumbers of modal operators and binary connectives. Our game is similar to the\nwell-known Adler-Immerman game. However, due to a crucial difference in the\ndefinition of positions of the game, its winning condition is simpler, and the\nsecond player (duplicator) does not have a trivial optimal strategy. Thus,\nunlike the Adler-Immerman game, our game is a genuine two-person game. We\nillustrate the use of the game by proving a nonelementary succinctness gap\nbetween bisimulation invariant first-order logic FO and (basic) modal logic ML.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 12:17:02 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Hella", "Lauri", ""], ["Vilander", "Miikka", ""]]}, {"id": "1604.07309", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Division by zero", "comments": "15 pages; fixed typos", "journal-ref": "Archive for Mathematical Logic 55 (2016), no. 7, pp. 997--1013", "doi": "10.1007/s00153-016-0508-5", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any sufficiently strong theory of arithmetic, the set of Diophantine\nequations provably unsolvable in the theory is algorithmically undecidable, as\na consequence of the MRDP theorem. In contrast, we show decidability of\nDiophantine equations provably unsolvable in Robinson's arithmetic Q. The\nargument hinges on an analysis of a particular class of equations, hitherto\nunexplored in Diophantine literature. We also axiomatize the universal fragment\nof Q in the process.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 15:25:44 GMT"}, {"version": "v2", "created": "Sat, 23 Jul 2016 20:10:19 GMT"}, {"version": "v3", "created": "Sat, 24 Sep 2016 18:43:09 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1604.07530", "submitter": "Rob van Glabbeek", "authors": "Wan Fokkink and Rob van Glabbeek", "title": "Divide and Congruence II: From Decomposition of Modal Formulas to\n  Preservation of Delay and Weak Bisimilarity", "comments": "An extended abstract of this paper appeared in Proc. LICS'16. With\n  Definition 20.4b(i) as formulated originally [v1], Proposition 5 does not\n  hold. A corrected Definition 20.4b appears in this revision [v2]", "journal-ref": "Information and Computation 257, 2017, pp. 79-113", "doi": "10.1016/j.ic.2017.10.003", "report-no": "Technical Report 9351, NICTA, 2016", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier we presented a method to decompose modal formulas for processes with\nthe internal action $\\tau$, and congruence formats for branching and\n$\\eta$-bisimilarity were derived on the basis of this decomposition method. The\nidea is that a congruence format for a semantics must ensure that the formulas\nin the modal characterisation of this semantics are always decomposed into\nformulas that are again in this modal characterisation. In this follow-up paper\nthe decomposition method is enhanced to deal with modal characterisations that\ncontain a modality $\\langle\\epsilon\\rangle\\langle a\\rangle\\phi$, to derive\ncongruence formats for delay and weak bisimilarity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 05:50:34 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 08:46:31 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Fokkink", "Wan", ""], ["van Glabbeek", "Rob", ""]]}, {"id": "1604.07564", "submitter": "Dietmar Berwanger", "authors": "Dietmar Berwanger, Anup Basil Mathew, R. Ramanujam", "title": "A Retraction Theorem for Distributed Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general theorem for distributed synthesis problems in\ncoordination games with $\\omega$-regular objectives of the form: If there\nexists a winning strategy for the coalition, then there exists an \"essential\"\nwinning strategy, that is obtained by a retraction of the given one. In\ngeneral, this does not lead to finite-state winning strategies, but when the\nknowledge of agents remains bounded, we can solve the synthesis problem. Our\nstudy is carried out in a setting where objectives are expressed in terms of\nevents that may \\emph{not} be observable. This is natural in games of imperfect\ninformation, rather than the common assumption that objectives are expressed in\nterms of events that are observable to all agents. We characterise decidable\ndistributed synthesis problems in terms of finiteness of knowledge states and\nfinite congruence classes induced by them.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 08:32:29 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Berwanger", "Dietmar", ""], ["Mathew", "Anup Basil", ""], ["Ramanujam", "R.", ""]]}, {"id": "1604.08040", "submitter": "Martin Suda", "authors": "Giles Reger, Martin Suda, Andrei Voronkov", "title": "Finding Finite Models in Multi-Sorted First Order Logic", "comments": "SAT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends the existing MACE-style finite model finding approach to\nmulti-sorted first order logic. This existing approach iteratively assumes\nincreasing domain sizes and encodes the related ground problem as a SAT\nproblem. When moving to the multi-sorted setting each sort may have a different\ndomain size, leading to an explosion in the search space. This paper focusses\non methods to tame that search space. The key approach adds additional\ninformation to the SAT encoding to suggest which domains should be grown.\nEvaluation of an implementation of techniques in the Vampire theorem prover\nshows that they dramatically reduce the search space and that this is an\neffective approach to find finite models in multi-sorted first order logic.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 12:34:36 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Reger", "Giles", ""], ["Suda", "Martin", ""], ["Voronkov", "Andrei", ""]]}, {"id": "1604.08058", "submitter": "Martin Suda", "authors": "Olaf Beyersdorff, Leroy Chew, Renate Schmidt, Martin Suda", "title": "Lifting QBF Resolution Calculi to DQBF", "comments": "SAT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the existing Resolution systems for quantified Boolean formulas\n(QBF) and answer the question which of these calculi can be lifted to the more\npowerful Dependency QBFs (DQBF). An interesting picture emerges: While for QBF\nwe have the strict chain of proof systems Q-Resolution < IR-calc < IRM-calc,\nthe situation is quite different in DQBF. Q-Resolution and likewise universal\nResolution are too weak: they are not complete. IR-calc has the right strength:\nit is sound and complete. IRM-calc is too strong: it is not sound any more, and\nthe same applies to long-distance Resolution. Conceptually, we use the relation\nof DQBF to EPR and explain our new DQBF calculus based on IR-calc as a\nsubsystem of FO-Resolution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 13:27:53 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Beyersdorff", "Olaf", ""], ["Chew", "Leroy", ""], ["Schmidt", "Renate", ""], ["Suda", "Martin", ""]]}, {"id": "1604.08080", "submitter": "Germ\\'an Andr\\'es Delbianco", "authors": "Germ\\'an Andr\\'es Delbianco, Ilya Sergey, Aleksandar Nanevski and\n  Anindya Banerjee", "title": "Concurrent Data Structures Linked in Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguments about correctness of a concurrent data structure are typically\ncarried out by using the notion of linearizability and specifying the\nlinearization points of the data structure's procedures. Such arguments are\noften cumbersome as the linearization points' position in time can be dynamic\n(depend on the interference, run-time values and events from the past, or even\nfuture), non-local (appear in procedures other than the one considered), and\nwhose position in the execution trace may only be determined after the\nconsidered procedure has already terminated.\n  In this paper we propose a new method, based on a separation-style logic, for\nreasoning about concurrent objects with such linearization points. We embrace\nthe dynamic nature of linearization points, and encode it as part of the data\nstructure's auxiliary state, so that it can be dynamically modified in place by\nauxiliary code, as needed when some appropriate run-time event occurs. We name\nthe idea linking-in-time, because it reduces temporal reasoning to spatial\nreasoning. For example, modifying a temporal position of a linearization point\ncan be modeled similarly to a pointer update in separation logic. Furthermore,\nthe auxiliary state provides a convenient way to concisely express the\nproperties essential for reasoning about clients of such concurrent objects. We\nillustrate the method by verifying (mechanically in Coq) an intricate optimal\nsnapshot algorithm due to Jayanti, as well as some clients.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 14:13:46 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 00:08:37 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 17:22:22 GMT"}, {"version": "v4", "created": "Wed, 18 Jan 2017 13:23:29 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Delbianco", "Germ\u00e1n Andr\u00e9s", ""], ["Sergey", "Ilya", ""], ["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""]]}, {"id": "1604.08155", "submitter": "John Backes", "authors": "John D. Backes and Michael W. Whalen and Andrew Gacek and John Komp", "title": "On Implementing Real-time Specification Patterns Using Observers", "comments": "In the proceedings of the NASA Formal Methods Symposium 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  English language requirements are often used to specify the behavior of\ncomplex cyber-physical systems. The process of transforming these requirements\nto a formal specification language is often challenging, especially if the\nspecification language does not contain constructs analogous to those used in\nthe original requirements. For example, requirements often contain real-time\nconstraints, but many specification languages for model checkers have discrete\ntime semantics. Work in specification patterns helps to bridge these gaps,\nallowing straightforward expression of common requirements patterns in formal\nlanguages. In this work we demonstrate how we support real-time specification\npatterns in the Assume Guarantee Reasoning Environment (AGREE) using observers.\nWe demonstrate that there are subtle challenges, not mentioned in previous\nliterature, to express real-time patterns accurately using observers. We then\ndemonstrate that these patterns are sufficient to model real-time requirements\nfor a real-world avionics system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 18:01:36 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Backes", "John D.", ""], ["Whalen", "Michael W.", ""], ["Gacek", "Andrew", ""], ["Komp", "John", ""]]}, {"id": "1604.08229", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Antonio Morgado and Joao Marques-Silva", "title": "Propositional Abduction with Implicit Hitting Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based abduction finds important applications in artificial intelligence\nand related areas. One application example is in finding explanations for\nobserved phenomena. Propositional abduction is a restriction of abduction to\nthe propositional domain, and complexity-wise is in the second level of the\npolynomial hierarchy. Recent work has shown that exploiting implicit hitting\nsets and propositional satisfiability (SAT) solvers provides an efficient\napproach for propositional abduction. This paper investigates this earlier work\nand proposes a number of algorithmic improvements. These improvements are shown\nto yield exponential reductions in the number of SAT solver calls. More\nimportantly, the experimental results show significant performance improvements\ncompared to the the best approaches for propositional abduction.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 20:29:01 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Morgado", "Antonio", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1604.08234", "submitter": "Sebastian Krinninger", "authors": "Krishnendu Chatterjee, Monika Henzinger, Sebastian Krinninger, Danupon\n  Nanongkai", "title": "Polynomial-Time Algorithms for Energy Games with Special Weight\n  Structures", "comments": "This paper appeared in the ESA 2012 special issue of Algorithmica. A\n  preliminary version was presented at the 20th Annual European Symposium on\n  Algorithms (ESA 2012)", "journal-ref": "Algorithmica 70(3): 457-492 (2014)", "doi": "10.1007/s00453-013-9843-7", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy games belong to a class of turn-based two-player infinite-duration\ngames}played on a weighted directed graph. It is one of the rare and intriguing\ncombinatorial problems that lie in ${\\sf NP} \\cap {\\sf co\\mbox{-}NP}$, but are\nnot known to be in ${\\sf P}$. The existence of polynomial-time algorithms has\nbeen a major open problem for decades and apart from pseudopolynomial\nalgorithms there is no algorithm that solves any non-trivial subclass in\npolynomial time.\n  In this paper, we give several results based on the weight structures of the\ngraph. First, we identify a notion of penalty and present a polynomial-time\nalgorithm when the penalty is large. Our algorithm is the first polynomial-time\nalgorithm on a large class of weighted graphs. It includes several worst-case\ninstances on which previous algorithms, such as value iteration and random\nfacet algorithms, require at least sub-exponential time. Our main technique is\ndeveloping the first non-trivial approximation algorithm and showing how to\nconvert it to an exact algorithm. Moreover, we show that in a practical case in\nverification where weights are clustered around a constant number of values,\nthe energy game problem can be solved in polynomial time. We also show that the\nproblem is still as hard as in general when the clique-width is bounded or the\ngraph is strongly ergodic, suggesting that restricting the graph structure does\nnot necessarily help.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 20:36:13 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 17:03:51 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Henzinger", "Monika", ""], ["Krinninger", "Sebastian", ""], ["Nanongkai", "Danupon", ""]]}, {"id": "1604.08248", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago", "title": "Infinitary $\\lambda$-Calculi from a Linear Perspective (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a linear infinitary $\\lambda$-calculus, called\n$\\ell\\Lambda_{\\infty}$, in which two exponential modalities are available, the\nfirst one being the usual, finitary one, the other being the only construct\ninterpreted coinductively. The obtained calculus embeds the infinitary\napplicative $\\lambda$-calculus and is universal for computations over infinite\nstrings. What is particularly interesting about $\\ell\\Lambda_{\\infty}$, is that\nthe refinement induced by linear logic allows to restrict both modalities so as\nto get calculi which are terminating inductively and productive coinductively.\nWe exemplify this idea by analysing a fragment of $\\ell\\Lambda$ built around\nthe principles of $\\mathsf{SLL}$ and $\\mathsf{4LL}$. Interestingly, it enjoys\nconfluence, contrarily to what happens in ordinary infinitary\n$\\lambda$-calculi.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 21:19:45 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Lago", "Ugo Dal", ""]]}, {"id": "1604.08345", "submitter": "James Cheney", "authors": "James Cheney and Alberto Momigliano and Matteo Pessina", "title": "Advances in Property-Based Testing for $\\alpha$Prolog", "comments": "To appear, Tests and Proofs 2016; includes appendix with details not\n  in the conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\alpha$Check is a light-weight property-based testing tool built on top of\n$\\alpha$Prolog, a logic programming language based on nominal logic.\n$\\alpha$Prolog is particularly suited to the validation of the meta-theory of\nformal systems, for example correctness of compiler translations involving\nname-binding, alpha-equivalence and capture-avoiding substitution. In this\npaper we describe an alternative to the negation elimination algorithm\nunderlying $\\alpha$Check that substantially improves its effectiveness. To\nsubstantiate this claim we compare the checker performances w.r.t. two of its\nmain competitors in the logical framework niche, namely the QuickCheck/Nitpick\ncombination offered by Isabelle/HOL and the random testing facility in\nPLT-Redex.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 08:43:17 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 14:45:01 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Cheney", "James", ""], ["Momigliano", "Alberto", ""], ["Pessina", "Matteo", ""]]}, {"id": "1604.08348", "submitter": "Thorsten Wissmann", "authors": "Vasco Brattka and Arno Pauly", "title": "On the algebraic structure of Weihrauch degrees", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4,\n  Computability and logic (October 25, 2018) lmcs:4918", "doi": "10.23638/LMCS-14(4:4)2018", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce two new operations (compositional products and implication) on\nWeihrauch degrees, and investigate the overall algebraic structure. The\nvalidity of the various distributivity laws is studied and forms the basis for\na comparison with similar structures such as residuated lattices and concurrent\nKleene algebras. Introducing the notion of an ideal with respect to the\ncompositional product, we can consider suitable quotients of the Weihrauch\ndegrees. We also prove some specific characterizations using the implication.\nIn order to introduce and study compositional products and implications, we\nintroduce and study a function space of multi-valued continuous functions. This\nspace turns out to be particularly well-behaved for effectively traceable\nspaces that are closely related to admissibly represented spaces.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 08:57:18 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2016 10:43:05 GMT"}, {"version": "v3", "created": "Tue, 1 Nov 2016 08:51:00 GMT"}, {"version": "v4", "created": "Wed, 9 Aug 2017 09:53:40 GMT"}, {"version": "v5", "created": "Mon, 19 Feb 2018 17:19:12 GMT"}, {"version": "v6", "created": "Fri, 9 Mar 2018 14:48:58 GMT"}, {"version": "v7", "created": "Fri, 4 May 2018 11:20:57 GMT"}, {"version": "v8", "created": "Wed, 24 Oct 2018 13:39:45 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Brattka", "Vasco", ""], ["Pauly", "Arno", ""]]}, {"id": "1604.08383", "submitter": "J\\\"urgen Koslowski", "authors": "\\'A. Garc\\'ia-P\\'erez and P. Nogueira", "title": "No solvable lambda-value term left behind", "comments": "43 pages", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 2 (June 30,\n  2016) lmcs:1644", "doi": "10.2168/LMCS-12(2:12)2016", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the lambda calculus a term is solvable iff it is operationally relevant.\nSolvable terms are a superset of the terms that convert to a final result\ncalled normal form. Unsolvable terms are operationally irrelevant and can be\nequated without loss of consistency. There is a definition of solvability for\nthe lambda-value calculus, called v-solvability, but it is not synonymous with\noperational relevance, some lambda-value normal forms are unsolvable, and\nunsolvables cannot be consistently equated. We provide a definition of\nsolvability for the lambda-value calculus that does capture operational\nrelevance and such that a consistent proof-theory can be constructed where\nunsolvables are equated attending to the number of arguments they take (their\n\"order\" in the jargon). The intuition is that in lambda-value the different\nsequentialisations of a computation can be distinguished operationally. We\nprove a version of the Genericity Lemma stating that unsolvable terms are\ngeneric and can be replaced by arbitrary terms of equal or greater order.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 11:58:11 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 12:38:07 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 12:01:08 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Garc\u00eda-P\u00e9rez", "\u00c1.", ""], ["Nogueira", "P.", ""]]}, {"id": "1604.08443", "submitter": "Christoph Rauch", "authors": "S. Akshay, Paul Gastin and Shankara Narayanan Krishna", "title": "Analyzing Timed Systems Using Tree Automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (May 9,\n  2018) lmcs:4489", "doi": "10.23638/LMCS-14(2:8)2018", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Timed systems, such as timed automata, are usually analyzed using their\noperational semantics on timed words. The classical region abstraction for\ntimed automata reduces them to (untimed) finite state automata with the same\ntime-abstract properties, such as state reachability. We propose a new\ntechnique to analyze such timed systems using finite tree automata instead of\nfinite word automata. The main idea is to consider timed behaviors as graphs\nwith matching edges capturing timing constraints. When a family of graphs has\nbounded tree-width, they can be interpreted in trees and MSO-definable\nproperties of such graphs can be checked using tree automata. The technique is\nquite general and applies to many timed systems. In this paper, as an example,\nwe develop the technique on timed pushdown systems, which have recently\nreceived considerable attention. Further, we also demonstrate how we can use it\non timed automata and timed multi-stack pushdown systems (with boundedness\nrestrictions).\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 14:52:27 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 14:37:55 GMT"}, {"version": "v3", "created": "Mon, 27 Nov 2017 04:25:52 GMT"}, {"version": "v4", "created": "Tue, 8 May 2018 09:21:22 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Akshay", "S.", ""], ["Gastin", "Paul", ""], ["Krishna", "Shankara Narayanan", ""]]}, {"id": "1604.08709", "submitter": "Yanjing Wang", "authors": "Tao Gu and Yanjing Wang", "title": "\"Knowing value\" logic as a normal modal logic", "comments": "21 pages, in Advances in Modal Logic Vol 11: 362-381 College\n  Publications. This is a draft with a more detailed proof of Prop. 3.5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years witness a growing interest in nonstandard epistemic logics of\n\"knowing whether\", \"knowing what\", \"knowing how\", and so on. These logics are\nusually not normal, i.e., the standard axioms and reasoning rules for modal\nlogic may be invalid. In this paper, we show that the conditional \"knowing\nvalue\" logic proposed by Wang and Fan \\cite{WF13} can be viewed as a disguised\nnormal modal logic by treating the negation of the Kv operator as a special\ndiamond. Under this perspective, it turns out that the original first-order\nKripke semantics can be greatly simplified by introducing a ternary relation\n$R_i^c$ in standard Kripke models, which associates one world with two\n$i$-accessible worlds that do not agree on the value of constant $c$. Under\nintuitive constraints, the modal logic based on such Kripke models is exactly\nthe one studied by Wang and Fan (2013,2014}. Moreover, there is a very natural\nbinary generalization of the \"knowing value\" diamond, which, surprisingly, does\nnot increase the expressive power of the logic. The resulting logic with the\nbinary diamond has a transparent normal modal system, which sharpens our\nunderstanding of the \"knowing value\" logic and simplifies some previously hard\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 07:22:27 GMT"}, {"version": "v2", "created": "Sun, 12 Jun 2016 16:48:41 GMT"}, {"version": "v3", "created": "Mon, 21 Nov 2016 05:34:15 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Gu", "Tao", ""], ["Wang", "Yanjing", ""]]}, {"id": "1604.08736", "submitter": "Alexander Maletzky", "authors": "Alexander Maletzky", "title": "Verifying Buchberger's Algorithm in Reduction Rings", "comments": "8 pages; appeared in the proceedings of PAS'2015 (Program\n  Verification, Automated Debugging, and Symbolic Computation, Beijing, China,\n  October 21--23, 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.LO math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the formal, computer-supported verification of a\nfunctional implementation of Buchberger's critical-pair/completion algorithm\nfor computing Gr\\\"obner bases in reduction rings. We describe how the algorithm\ncan be implemented and verified within one single software system, which in our\ncase is the Theorema system.\n  In contrast to existing formal correctness proofs of Buchberger's algorithm\nin other systems, e. g. Coq and ACL2, our work is not confined to the classical\nsetting of polynomial rings over fields, but considers the much more general\nsetting of reduction rings; this, naturally, makes the algorithm more\ncomplicated and the verification more difficult.\n  The correctness proof is essentially based on some non-trivial results from\nthe theory of reduction rings, which we formalized and formally proved as well.\nThis formalization already consists of more than 800 interactively proved\nlemmas and theorems, making the elaboration an extensive example of\nhigher-order theory exploration in Theorema.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 08:51:32 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Maletzky", "Alexander", ""]]}, {"id": "1604.08779", "submitter": "Reino Niskanen", "authors": "Reino Niskanen, Igor Potapov, Julien Reichert", "title": "Undecidability of Two-dimensional Robot Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot game is a two-player vector addition game played on the integer lattice\n$\\mathbb{Z}^n$. Both players have sets of vectors and in each turn the vector\nchosen by a player is added to the current configuration vector of the game.\nOne of the players, called Eve, tries to play the game from the initial\nconfiguration to the origin while the other player, Adam, tries to avoid the\norigin. The problem is to decide whether or not Eve has a winning strategy. In\nthis paper we prove undecidability of the robot game in dimension two answering\nthe question formulated by Doyen and Rabinovich in 2011 and closing the gap\nbetween undecidable and decidable cases.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 11:34:38 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Niskanen", "Reino", ""], ["Potapov", "Igor", ""], ["Reichert", "Julien", ""]]}, {"id": "1604.08873", "submitter": "Carlo Angiuli", "authors": "Carlo Angiuli, Robert Harper, Todd Wilson", "title": "Computational Higher Type Theory I: Abstract Cubical Realizability", "comments": "39 pages. v2: added abstract, minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brouwer's constructivist foundations of mathematics is based on an\nintuitively meaningful notion of computation shared by all mathematicians.\nMartin-L\\\"of's meaning explanations for constructive type theory define the\nconcept of a type in terms of computation. Briefly, a type is a complete\n(closed) program that evaluates to a canonical type whose members are complete\nprograms that evaluate to canonical elements of that type. The explanation is\nextended to incomplete (open) programs by functionality: types and elements\nmust respect equality in their free variables. Equality is evidence-free---two\ntypes or elements are at most equal---and equal things are implicitly\ninterchangeable in all contexts.\n  Higher-dimensional type theory extends type theory to account for\nidentifications of types and elements. An identification witnesses that two\ntypes or elements are explicitly interchangeable in all contexts by an explicit\ntransport, or coercion, operation. There must be sufficiently many\nidentifications, which is ensured by imposing a generalized form of the Kan\ncondition from homotopy theory. Here we provide a Martin-L\\\"of-style meaning\nexplanation of simple higher-dimensional type theory based on a programming\nlanguage that includes Kan-like constructs witnessing the computational meaning\nof the higher structure of types. The treatment includes an example of a higher\ninductive type (namely, the 1-dimensional sphere) and an example of Voevodsky's\nunivalence principle, which identifies equivalent types.\n  The main result is a computational canonicity theorem that validates the\ncomputational interpretation: a closed boolean expression must always evaluate\nto a boolean value, even in the presence of higher-dimensional structure. This\nprovides the first fully computational formulation of higher-dimensional type\ntheory.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 15:26:22 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 17:48:27 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Angiuli", "Carlo", ""], ["Harper", "Robert", ""], ["Wilson", "Todd", ""]]}]