[{"id": "1711.00113", "submitter": "Dariusz Biernacki", "authors": "Dariusz Biernacki, Serguei Lenglet, Piotr Polesiuk", "title": "Proving Soundness of Extensional Normal-Form Bisimilarities", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (March 29,\n  2019) lmcs:5323", "doi": "10.23638/LMCS-15(1:31)2019", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normal-form bisimilarity is a simple, easy-to-use behavioral equivalence that\nrelates terms in $\\lambda$-calculi by decomposing their normal forms into\nbisimilar subterms. Moreover, it typically allows for powerful up-to\ntechniques, such as bisimulation up to context, which simplify bisimulation\nproofs even further. However, proving soundness of these relations becomes\ncomplicated in the presence of $\\eta$-expansion and usually relies on ad hoc\nproof methods which depend on the language. In this paper we propose a more\nsystematic proof method to show that an extensional normal-form bisimilarity\nalong with its corresponding up to context technique are sound. We illustrate\nour technique with three calculi: the call-by-value $\\lambda$-calculus, the\ncall-by-value $\\lambda$-calculus with the delimited-control operators shift and\nreset, and the call-by-value $\\lambda$-calculus with the abortive control\noperators call/cc and abort. In the first two cases, there was previously no\nsound up to context technique validating the $\\eta$-law, whereas no theory of\nnormal-form bisimulations for a calculus with call/cc and abort has been\npresented before. Our results have been fully formalized in the Coq proof\nassistant.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 21:09:16 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 13:33:30 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 09:45:19 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 09:31:39 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Biernacki", "Dariusz", ""], ["Lenglet", "Serguei", ""], ["Polesiuk", "Piotr", ""]]}, {"id": "1711.00220", "submitter": "Ronny Tredup", "authors": "Christian Rosenke and Ronny Tredup", "title": "The Hardness of Synthesizing Elementary Net Systems from Highly\n  Restricted Inputs", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elementary net systems (ENS) are the most fundamental class of Petri nets.\nTheir synthesis problem has important applications in the design of digital\nhardware and commercial processes. Given a labeled transition system (TS) $A$,\nfeasibility is the NP-complete decision problem whether $A$ can be equivalently\nsynthesized into an ENS. It is well known that $A$ is feasible if and only if\nit has the event state separation property (ESSP) and the state separation\nproperty (SSP). Recently, these properties have also been studied individually\nfor their practical implications. A fast ESSP algorithm, for instance, would\nallow applications to at least validate the language equivalence of $A$ and a\nsynthesized ENS. Being able to efficiently decide SSP, on the other hand, could\nserve as a quick-fail preprocessing mechanism for synthesis. Although a few\ntractable subclasses have been found, this paper destroys much of the hope that\nmany practically meaningful input restrictions make feasibility or at least one\nof ESSP and SSP efficient. We show that all three problems remain NP-complete\neven if the input is restricted to linear TSs where every event occurs at most\nthree times or if the input is restricted to TSs where each event occurs at\nmost twice and each state has at most two successor and two predecessor states.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 06:28:52 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Rosenke", "Christian", ""], ["Tredup", "Ronny", ""]]}, {"id": "1711.00669", "submitter": "Antonio Bruto da Costa", "authors": "Antonio Anastasio Bruto da Costa, Goran Frehse, Pallab Dasgupta", "title": "Formal Feature Interpretation of Hybrid Systems", "comments": null, "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems ( Volume: 37 , Issue: 11 , Nov. 2018 )", "doi": "10.1109/TCAD.2018.2857361", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current practice a formal analysis of hybrid system models is\nassertion-based. The work presented here is based on features that look beyond\nfunctional correctness toward a quantitative evaluation of behavioral\nattributes. A feature defines a real-valued evaluation function over a specific\nset of traces. This paper describes an improved method for the interpretation\nof features over hybrid automata models. It further demonstrates how\nsatisfiability modulo theory solvers can be used for extracting behavioral\ntraces corresponding to corner cases of a feature. Results are demonstrated on\nexamples from the control and circuit domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 10:00:53 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 10:37:04 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["da Costa", "Antonio Anastasio Bruto", ""], ["Frehse", "Goran", ""], ["Dasgupta", "Pallab", ""]]}, {"id": "1711.00774", "submitter": "EPTCS", "authors": "Luca Paolini, Luca Roversi, Margherita Zorzi", "title": "Quantum Programming Made Easy", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 133-147", "doi": "10.4204/EPTCS.292.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present IQu, namely a quantum programming language that extends Reynold's\nIdealized Algol, the paradigmatic core of Algol-like languages. IQu combines\nimperative programming with high-order features, mediated by a simple type\ntheory. IQu mildly merges its quantum features with the classical programming\nstyle that we can experiment through Idealized Algol, the aim being to ease a\ntransition towards the quantum programming world. The proposed extension is\ndone along two main directions. First, IQu makes the access to quantum\nco-processors by means of quantum stores. Second, IQu includes some support for\nthe direct manipulation of quantum circuits, in accordance with recent trends\nin the development of quantum programming languages. Finally, we show that IQu\nis quite effective in expressing well-known quantum algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 15:02:38 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 18:48:10 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 05:17:58 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Paolini", "Luca", ""], ["Roversi", "Luca", ""], ["Zorzi", "Margherita", ""]]}, {"id": "1711.00878", "submitter": "Bernardo Toninho", "authors": "Bernardo Toninho and Nobuko Yoshida", "title": "On Polymorphic Sessions and Functions: A Tale of Two (Fully Abstract)\n  Encodings", "comments": "Extended version of ESOP'18 paper (includes appendix with proofs and\n  additional definitions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work exploits the logical foundation of session types to determine what\nkind of type discipline for the pi-calculus can exactly capture, and is\ncaptured by, lambda-calculus behaviours. Leveraging the proof theoretic content\nof the soundness and completeness of sequent calculus and natural deduction\npresentations of linear logic, we develop the first mutually inverse and fully\nabstract processes-as-functions and functions-as-processes encodings between a\npolymorphic session pi-calculus and a linear formulation of System F. We are\nthen able to derive results of the session calculus from the theory of the\nlambda-calculus: (1) we obtain a characterisation of inductive and coinductive\nsession types via their algebraic representations in System F; and (2) we\nextend our results to account for value and process passing, entailing strong\nnormalisation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 18:38:08 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 16:58:55 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Toninho", "Bernardo", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1711.01637", "submitter": "Alexander Weber", "authors": "Alexander Weber, Matthias Rungger, Gunther Reissig", "title": "Optimized State Space Grids for Abstractions", "comments": "This is the accepted version of a paper published in IEEE Trans.\n  Automat. Control", "journal-ref": "IEEE Trans. Automat. Control, vol. 62, no. 11, pp. 5816-5821, 2017", "doi": "10.1109/TAC.2016.2642794", "report-no": null, "categories": "math.OC cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical impact of abstraction-based controller synthesis methods is\ncurrently limited by the immense computational effort for obtaining\nabstractions. In this note we focus on a recently proposed method to compute\nabstractions whose state space is a cover of the state space of the plant by\ncongruent hyper-intervals. The problem of how to choose the size of the\nhyper-intervals so as to obtain computable and useful abstractions is unsolved.\nThis note provides a twofold contribution towards a solution. Firstly, we\npresent a functional to predict the computational effort for the abstraction to\nbe computed. Secondly, we propose a method for choosing the aspect ratio of the\nhyper-intervals when their volume is fixed. More precisely, we propose to\nchoose the aspect ratio so as to minimize a predicted number of transitions of\nthe abstraction to be computed, in order to reduce the computational effort. To\nthis end, we derive a functional to predict the number of transitions in\ndependence of the aspect ratio. The functional is to be minimized subject to\nsuitable constraints. We characterize the unique solvability of the respective\noptimization problem and prove that it transforms, under appropriate\nassumptions, into an equivalent convex problem with strictly convex objective.\nThe latter problem can then be globally solved using standard numerical\nmethods. We demonstrate our approach on an example.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 18:38:47 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Weber", "Alexander", ""], ["Rungger", "Matthias", ""], ["Reissig", "Gunther", ""]]}, {"id": "1711.01735", "submitter": "Amirhossein Akbar Tabatabai", "authors": "Amirhossein Akbar Tabatabai", "title": "Computational Flows in Arithmetic", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational flow is a pair consisting of a sequence of computational\nproblems of a certain sort and a sequence of computational reductions among\nthem. In this paper we will develop a theory for these computational flows and\nwe will use it to make a sound and complete interpretation for bounded theories\nof arithmetic. This property helps us to decompose a first order arithmetical\nproof to a sequence of computational reductions by which we can extract the\ncomputational content of low complexity statements in some bounded theories of\narithmetic such as $I\\Delta_0$, $T^k_n$, $I\\Delta_0+EXP$ and $PRA$. In the last\nsection, by generalizing term-length flows to ordinal-length flows, we will\nextend our investigation from bounded theories to strong unbounded ones such as\n$I\\Sigma_n$ and $PA+TI(\\alpha)$ and we will capture their total $NP$ search\nproblems as a consequence.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 05:33:59 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Tabatabai", "Amirhossein Akbar", ""]]}, {"id": "1711.01823", "submitter": "Paritosh Pandya", "authors": "Amol Wakankar, Paritosh K. Pandya and Raj Mohan Matteplackel", "title": "DCSYNTH: Guided Reactive Synthesis with Soft Requirements for Robust\n  Controller and Shield Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DCSYNTH is a tool for the synthesis of controllers from safety and bounded\nliveness requirements given in interval temporal logic QDDC. It investigates\nthe role of soft requirements (with priorities) in obtaining high quality\ncontrollers. A QDDC formula specifies past time properties. In DCSYNTH\nsynthesis, hard requirements must be invariantly satisfied whereas soft\nrequirements may be satisfied \"as much as possible\" in a best effort manner by\nthe controller. Soft requirements provide an invaluable ability to guide the\ncontroller synthesis. In the paper, using DCSYNTH, we show the application of\nsoft requirements in obtaining robust controllers with various specifiable\nnotions of robustness. We also show the use of soft requirements to specify and\nsynthesize efficient runtime enforcement shields which can correct burst\nerrors. Finally, we discuss the use of soft requirements in improving the\nlatency of controlled system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 10:40:20 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Wakankar", "Amol", ""], ["Pandya", "Paritosh K.", ""], ["Matteplackel", "Raj Mohan", ""]]}, {"id": "1711.01863", "submitter": "Dimitrios Milios", "authors": "Dimitrios Milios, Guido Sanguinetti, David Schnoerr", "title": "Probabilistic Model Checking for Continuous Time Markov Chains via\n  Sequential Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic model checking for systems with large or unbounded state space\nis a challenging computational problem in formal modelling and its\napplications. Numerical algorithms require an explicit representation of the\nstate space, while statistical approaches require a large number of samples to\nestimate the desired properties with high confidence. Here, we show how model\nchecking of time-bounded path properties can be recast exactly as a Bayesian\ninference problem. In this novel formulation the problem can be efficiently\napproximated using techniques from machine learning. Our approach is inspired\nby a recent result in statistical physics which derived closed form\ndifferential equations for the first-passage time distribution of stochastic\nprocesses. We show on a number of non-trivial case studies that our method\nachieves both high accuracy and significant computational gains compared to\nstatistical model checking.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 12:44:18 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 09:23:08 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Milios", "Dimitrios", ""], ["Sanguinetti", "Guido", ""], ["Schnoerr", "David", ""]]}, {"id": "1711.01947", "submitter": "Daniele Mundici", "authors": "Daniele Mundici", "title": "Word problems in Elliott monoids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic issues concerning Elliott local semigroups are seldom considered\nin the literature, although these combinatorial structures completely classify\nAF algebras. In general, the addition operation of an Elliott local semigroup\nis {\\it partial}, but for every AF algebra $\\mathfrak B$ whose Murray-von\nNeumann order of projections is a lattice, this operation is uniquely\nextendible to the addition of an involutive monoid $E(\\mathfrak B)$. Let\n$\\mathfrak M_1$ be the Farey AF algebra introduced by the present author in\n1988 and rediscovered by F. Boca in 2008. The freeness properties of the\ninvolutive monoid $E(\\mathfrak M_1)$ yield a natural word problem for every AF\nalgebra $\\mathfrak B$ with singly generated $E(\\mathfrak B)$, because\n$\\mathfrak B$ is automatically a quotient of $\\mathfrak M_1$. Given two\nformulas $\\phi$ and $\\psi$ in the language of involutive monoids, the problem\nasks to decide whether $\\phi$ and $\\psi$ code the same equivalence of\nprojections of $\\mathfrak B$. This mimics the classical definition of the word\nproblem of a group presented by generators and relations. We show that the word\nproblem of $\\mathfrak M_1$ is solvable in polynomial time, and so is the word\nproblem of the Behnke-Leptin algebras $\\mathcal A_{n,k}$, and of the\nEffros-Shen algebras $\\mathfrak F_{\\theta}$, for $\\theta\\in [0,1]\\setminus\n\\mathbb Q$ a real algebraic number, or $\\theta = 1/e$. We construct a quotient\nof $\\mathfrak M_1$ having a G\\\"odel incomplete word problem, and show that no\nprimitive quotient of $\\mathfrak M_1$ is G\\\"odel incomplete.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 08:11:38 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Mundici", "Daniele", ""]]}, {"id": "1711.02120", "submitter": "Robert Ganian", "authors": "Eduard Eiben, Robert Ganian, Sebastian Ordyniak", "title": "Small Resolution Proofs for QBF using Dependency Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the close connection between the evaluation of quantified Boolean\nformulas (QBF) and propositional satisfiability (SAT), tools and techniques\nwhich exploit structural properties of SAT instances are known to fail for QBF.\nThis is especially true for the structural parameter treewidth, which has\nallowed the design of successful algorithms for SAT but cannot be\nstraightforwardly applied to QBF since it does not take into account the\ninterdependencies between quantified variables.\n  In this work we introduce and develop dependency treewidth, a new structural\nparameter based on treewidth which allows the efficient solution of QBF\ninstances. Dependency treewidth pushes the frontiers of tractability for QBF by\novercoming the limitations of previously introduced variants of treewidth for\nQBF. We augment our results by developing algorithms for computing the\ndecompositions that are required to use the parameter.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:14:43 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Eiben", "Eduard", ""], ["Ganian", "Robert", ""], ["Ordyniak", "Sebastian", ""]]}, {"id": "1711.02456", "submitter": "Mikhail Prokopenko", "authors": "Mikhail Prokopenko, Michael Harr\\'e, Joseph Lizier, Fabio Boschetti,\n  Pavlos Peppas, Stuart Kauffman", "title": "Self-referential basis of undecidable dynamics: from The Liar Paradox\n  and The Halting Problem to The Edge of Chaos", "comments": "25 pages", "journal-ref": null, "doi": "10.1016/j.plrev.2018.12.003", "report-no": null, "categories": "cs.LO cs.FL nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore several fundamental relations between formal\nsystems, algorithms, and dynamical systems, focussing on the roles of\nundecidability, universality, diagonalization, and self-reference in each of\nthese computational frameworks. Some of these interconnections are well-known,\nwhile some are clarified in this study as a result of a fine-grained comparison\nbetween recursive formal systems, Turing machines, and Cellular Automata (CAs).\nIn particular, we elaborate on the diagonalization argument applied to\ndistributed computation carried out by CAs, illustrating the key elements of\nG\\\"odel's proof for CAs. The comparative analysis emphasizes three factors\nwhich underlie the capacity to generate undecidable dynamics within the\nexamined computational frameworks: (i) the program-data duality; (ii) the\npotential to access an infinite computational medium; and (iii) the ability to\nimplement negation. The considered adaptations of G\\\"odel's proof distinguish\nbetween computational universality and undecidability, and show how the\ndiagonalization argument exploits, on several levels, the self-referential\nbasis of undecidability.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 13:37:38 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 03:33:19 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Prokopenko", "Mikhail", ""], ["Harr\u00e9", "Michael", ""], ["Lizier", "Joseph", ""], ["Boschetti", "Fabio", ""], ["Peppas", "Pavlos", ""], ["Kauffman", "Stuart", ""]]}, {"id": "1711.02503", "submitter": "Bernhard Gleiss", "authors": "Bernhard Gleiss, Laura Kovacs, Martin Suda", "title": "Splitting Proofs for Interpolation", "comments": "26th Conference on Automated Deduction, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study interpolant extraction from local first-order refutations. We\npresent a new theoretical perspective on interpolation based on clearly\nseparating the condition on logical strength of the formula from the\nrequirement on the com- mon signature. This allows us to highlight the space of\nall interpolants that can be extracted from a refutation as a space of simple\nchoices on how to split the refuta- tion into two parts. We use this new\ninsight to develop an algorithm for extracting interpolants which are linear in\nthe size of the input refutation and can be further optimized using metrics\nsuch as number of non-logical symbols or quantifiers. We implemented the new\nalgorithm in first-order theorem prover VAMPIRE and evaluated it on a large\nnumber of examples coming from the first-order proving community. Our\nexperiments give practical evidence that our work improves the state-of-the-art\nin first-order interpolation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 14:49:10 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Gleiss", "Bernhard", ""], ["Kovacs", "Laura", ""], ["Suda", "Martin", ""]]}, {"id": "1711.02843", "submitter": "Fengkui Ju", "authors": "Fengkui Ju and Gianluca Grilletti", "title": "A Dynamic Solution to the Puzzle of Sea Battle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The puzzle of sea battle involves an argument that is an instantiation of\nreasoning by cases. Its premises include the conditionals \"if there is a/no sea\nbattle tomorrow, it is necessarily so\". It has a fatalistic conclusion. Two\nreadings of necessity can be distinguished: absolute and relative necessity.\nThe conditionals are valid for the latter reading. By the restrictor view of\n\"if\" in linguistics, the conditionals are not material implication. Instead,\nthe if-clauses in them are devices for restricting the discourse domain that\nconsists of possible futures. As a consequence, the argument is not sound. We\npresent a dynamic temporal logic to formalize this idea. The base of this logic\nis CTL* without the operator until. The logic has a dynamic operator that\nshrinks models. The completeness of the logic is shown by reducing the dynamic\noperator.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 05:56:50 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Ju", "Fengkui", ""], ["Grilletti", "Gianluca", ""]]}, {"id": "1711.02889", "submitter": "Harshita Kona", "authors": "Kona Harshita, Sounaka Mishra, Renjith. P, and N. Sadagopan", "title": "FO and MSO approach to Some Graph Problems: Approximation and Poly time\n  Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is two fold. Firstly, we present a logical approach\nto graph modification problems such as minimum node deletion, edge deletion,\nedge augmentation problems by expressing them as an expression in first order\n(FO) logic. As a consequence, it follows that these problems have constant\nfactor polynomial-time approximation algorithms. In particular, node\ndeletion/edge deletion on a graph $G$ whose resultant is cograph, split,\nthreshold, comparable, interval and permutation are $O(1)$ approximable.\nSecondly, we present a monadic second order (MSO) logic to minimum graph\nmodification problems, minimum dominating set problem and minimum coloring\nproblem and their variants. As a consequence, it follows that these problems\nhave linear-time algorithms on bounded tree-width graphs. In particular, we\nshow the existance of linear-time algorithms on bounded tree-width graphs for\nstar coloring, cd-coloring, rainbow coloring, equitable coloring, total\ndominating set, connected dominating set. In a nut shell, this paper presents a\nunified framework and an algorithmic scheme through logical expressions for\nsome graph problems through FO and MSO.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 09:48:55 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Harshita", "Kona", ""], ["Mishra", "Sounaka", ""], ["P", "Renjith.", ""], ["Sadagopan", "N.", ""]]}, {"id": "1711.03269", "submitter": "Juling Zhang", "authors": "Juling Zhang, Guowu Yang, William N. N. Hung, and Jinzhao Wu", "title": "A Canonical-based NPN Boolean Matching Algorithm Utilizing Boolean\n  Difference and Cofactor Signature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new compact canonical-based algorithm to solve the\nproblem of single-output completely specified NPN Boolean matching. We propose\na new signature vector Boolean difference and cofactor (DC) signature vector.\nOur algorithm utilizes the Boolean difference, cofactor signature and symmetry\nproperties to search for canonical transformations. The use of symmetry and\nBoolean difference notably reduces the search space and speeds up the Boolean\nmatching process compared to the algorithm proposed in [1]. We tested our\nalgorithm on a large number of circuits. The experimental results showed that\nthe average runtime of our algorithm 37% higher and its average search space\n67% smaller compared to [1] when tested on general circuits.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 06:19:24 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Zhang", "Juling", ""], ["Yang", "Guowu", ""], ["Hung", "William N. N.", ""], ["Wu", "Jinzhao", ""]]}, {"id": "1711.03272", "submitter": "Siddharth Krishna", "authors": "Siddharth Krishna, Dennis Shasha, Thomas Wies", "title": "Go with the Flow: Compositional Abstractions for Concurrent Data\n  Structures (Extended Version)", "comments": "This is an extended version of a POPL 2018 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent separation logics have helped to significantly simplify\ncorrectness proofs for concurrent data structures. However, a recurring problem\nin such proofs is that data structure abstractions that work well in the\nsequential setting are much harder to reason about in a concurrent setting due\nto complex sharing and overlays. To solve this problem, we propose a novel\napproach to abstracting regions in the heap by encoding the data structure\ninvariant into a local condition on each individual node. This condition may\ndepend on a quantity associated with the node that is computed as a fixpoint\nover the entire heap graph. We refer to this quantity as a flow. Flows can\nencode both structural properties of the heap (e.g. the reachable nodes from\nthe root form a tree) as well as data invariants (e.g. sortedness). We then\nintroduce the notion of a flow interface, which expresses the relies and\nguarantees that a heap region imposes on its context to maintain the local flow\ninvariant with respect to the global heap. Our main technical result is that\nthis notion leads to a new semantic model of separation logic. In this model,\nflow interfaces provide a general abstraction mechanism for describing complex\ndata structures. This abstraction mechanism admits proof rules that generalize\nover a wide variety of data structures. To demonstrate the versatility of our\napproach, we show how to extend the logic RGSep with flow interfaces. We have\nused this new logic to prove linearizability and memory safety of nontrivial\nconcurrent data structures. In particular, we obtain parametric linearizability\nproofs for concurrent dictionary algorithms that abstract from the details of\nthe underlying data structure representation. These proofs cannot be easily\nexpressed using the abstraction mechanisms provided by existing separation\nlogics.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 06:45:24 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Krishna", "Siddharth", ""], ["Shasha", "Dennis", ""], ["Wies", "Thomas", ""]]}, {"id": "1711.03363", "submitter": "Matthew Hague", "authors": "Taolue Chen, Yan Chen, Matthew Hague, Anthony W. Lin, and Zhilin Wu", "title": "What Is Decidable about String Constraints with the ReplaceAll Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it was shown that any theory of strings containing the\nstring-replace function (even the most restricted version where\npattern/replacement strings are both constant strings) becomes undecidable if\nwe do not impose some kind of straight-line (aka acyclicity) restriction on the\nformulas. Despite this, the straight-line restriction is still practically\nsensible since this condition is typically met by string constraints that are\ngenerated by symbolic execution. In this paper, we provide the first systematic\nstudy of straight-line string constraints with the string-replace function and\nthe regular constraints as the basic operations. We show that a large class of\nsuch constraints (i.e. when only a constant string or a regular expression is\npermitted in the pattern) is decidable. We note that the string-replace\nfunction, even under this restriction, is sufficiently powerful for expressing\nthe concatenation operator and much more (e.g. extensions of regular\nexpressions with string variables). This gives us the most expressive decidable\nlogic containing concatenation, replace, and regular constraints under the same\numbrella. Our decision procedure for the straight-line fragment follows an\nautomata-theoretic approach, and is modular in the sense that the\nstring-replace terms are removed one by one to generate more and more regular\nconstraints, which can then be discharged by the state-of-the-art string\nconstraint solvers. We also show that this fragment is, in a way, a maximal\ndecidable subclass of the straight-line fragment with string-replace and\nregular constraints. To this end, we show undecidability results for the\nfollowing two extensions: (1) variables are permitted in the pattern parameter\nof the replace function, (2) length constraints are permitted.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 13:25:03 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Chen", "Taolue", ""], ["Chen", "Yan", ""], ["Hague", "Matthew", ""], ["Lin", "Anthony W.", ""], ["Wu", "Zhilin", ""]]}, {"id": "1711.03399", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "On First-order Cons-free Term Rewriting and PTIME", "comments": "workshop proceedings for DICE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that (first-order) cons-free term rewriting with a\ncall-by-value reduction strategy exactly characterises the class of\nPTIME-computable functions. We use this to give an alternative proof of the\nresult by Carvalho and Simonsen which states that cons-free term rewriting with\nlinearity constraints characterises this class.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:53:16 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 10:14:01 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1711.03407", "submitter": "Cynthia Kop", "authors": "Cynthia Kop, Jakob Grue Simonsen", "title": "Higher-order Cons-free Interpreters", "comments": "workshop proceedings for HOR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructor rewriting systems are said to be cons-free if any constructor\nterm occurring in the rhs of a rule must be a subterm of the lhs of the rule.\nRoughly, such systems cannot build new data structures during their evaluation.\nIn earlier work by several authors, (typed) cons-free systems have been used to\ncharacterise complexity classes such as polynomial or exponential time or space\nby varying the type orders, and the recursion forms allowed. This paper\nconcerns the construction of interpreters for cons-free term rewriting. Due to\ntheir connection with proofs by diagonalisation, interpreters may be of use\nwhen studying separation results between complexity classes in implicit\ncomputational complexity theory. We are interested in interpreters of type\norder $k > 1$ that can interpret any term of strictly lower type order; while\nthis gives us a well-known separation result E$^k$TIME $\\subseteq$\nE$^{k+1}$TIME, the hope is that more refined interpreters with syntactically\nlimited constraints can be used to obtain a notion of faux diagonalisation and\nbe used to attack open problems in complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:01:55 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kop", "Cynthia", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "1711.03415", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "Non-deterministic Characterisations", "comments": "workshop proceedings for WST 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend Jones' result -- that cons-free programming with\n$k^{th}$-order data and a call-by-value strategy characterises EXP$^k$TIME --\nto a more general setting, including pattern-matching and non-deterministic\nchoice. We show that the addition of non-determinism is unexpectedly powerful\nin the higher-order setting. Nevertheless, we can obtain a non-deterministic\nparallel to Jones' hierarchy result by appropriate restricting rule formation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:12:27 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1711.03424", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "Cons-free Programming with Immutable Functions", "comments": "workshop proceedings for DICE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of non-determinism in purely functional programming\nlanguages with higher-order types. Specifically, we set out to characterise the\nhierarchy NP $\\subseteq$ NEXP $\\subseteq$ NEXP$^{(2)}$ $\\subseteq \\cdots\n\\subseteq$ NEXP$^{(k)}$ $\\subseteq \\cdots$ solely in terms of higher-typed,\npurely functional programs. Although the work is incomplete, we present an\ninitial approach using cons-free programs with immutable functions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:28:39 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1711.03433", "submitter": "Cynthia Kop", "authors": "Cynthia Kop, Kristoffer Rose", "title": "h: A Plank for Higher-order Attribute Contraction Schemes", "comments": "workshop proceedings for HOR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and formalize h, a core (or \"plank\") calculus that can serve as\nthe foundation for several compiler specification languages, notably CRSX\n(Combinatory Reductions Systems with eXtensions), HACS (Higher-order Attribute\nContraction Schemes), and TransScript. We discuss how the h typing and\nformation rules introduce the necessary restrictions to ensure that rewriting\nis well-defined, even in the presence of h's powerful extensions for\nmanipulating free variables and environments as first class elements (including\nin pattern matching).\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:52:18 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kop", "Cynthia", ""], ["Rose", "Kristoffer", ""]]}, {"id": "1711.03499", "submitter": "David Wolpert", "authors": "David Wolpert", "title": "Constraints on physical reality arising from a formalization of\n  knowledge", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.hist-ph cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are (at least) four ways that an agent can acquire information\nconcerning the state of the universe: via observation, control, prediction, or\nvia retrodiction, i.e., memory. Each of these four ways of acquiring\ninformation seems to rely on a different kind of physical device (resp., an\nobservation device, a control device, etc.). However it turns out that certain\nmathematical structure is common to those four types of device. Any device that\npossesses a certain subset of that structure is known as an \"inference device\"\n(ID).\n  Here I review some of the properties of IDs, including their relation with\nTuring machines, and (more loosely) quantum mechanics. I also review the bounds\nof the joint abilities of any set of IDs to know facts about the physical\nuniverse that contains them. These bounds constrain the possible properties of\nany universe that contains agents who can acquire information concerning that\nuniverse.\n  I then extend this previous work on IDs, by adding to the definition of IDs\nsome of the other mathematical structure that is common to the four ways of\nacquiring information about the universe but is not captured in the (minimal)\ndefinition of IDs. I discuss these extensions of IDs in the context of\nepistemic logic (especially possible worlds formalisms like Kripke structures\nand Aumann structures). In particular, I show that these extensions of IDs are\nnot subject to the problem of logical omniscience that plagues many previously\nstudied forms of epistemic logic.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 17:53:28 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 17:59:06 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 01:35:52 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Wolpert", "David", ""]]}, {"id": "1711.03588", "submitter": "Carroll Morgan", "authors": "Annabelle McIver, Carroll Morgan, Benjamin Lucien Kaminski,\n  Joost-Pieter Katoen", "title": "A New Proof Rule for Almost-Sure Termination", "comments": "V1 to appear in PoPL18. This version collects some existing text into\n  new example subsection 5.5 and adds a new example 5.6 and makes further\n  remarks about uncountable branching. The new example 5.6 relates to work on\n  lexicographic termination methods, also to appear in PoPL18 [Agrawal et al,\n  2018]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important question for a probabilistic program is whether the probability\nmass of all its diverging runs is zero, that is that it terminates \"almost\nsurely\". Proving that can be hard, and this paper presents a new method for\ndoing so; it is expressed in a program logic, and so applies directly to source\ncode. The programs may contain both probabilistic- and demonic choice, and the\nprobabilistic choices may depend on the current state.\n  As do other researchers, we use variant functions (a.k.a.\n\"super-martingales\") that are real-valued and probabilistically might decrease\non each loop iteration; but our key innovation is that the amount as well as\nthe probability of the decrease are parametric.\n  We prove the soundness of the new rule, indicate where its applicability goes\nbeyond existing rules, and explain its connection to classical results on\ndenumerable (non-demonic) Markov chains.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 20:29:00 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 01:09:43 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["McIver", "Annabelle", ""], ["Morgan", "Carroll", ""], ["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1711.03742", "submitter": "Daniele Porello", "authors": "Daniele Porello", "title": "Judgment aggregation in non-classical logics", "comments": "To appear in Journal of Applied Non-Classical Logics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work contributes to the theory of judgment aggregation by discussing a\nnumber of significant non-classical logics. After adapting the standard\nframework of judgment aggregation to cope with non-classical logics, we discuss\nin particular results for the case of Intuitionistic Logic, the Lambek\ncalculus, Linear Logic and Relevant Logics. The motivation for studying\njudgment aggregation in non-classical logics is that they offer a number of\nmodelling choices to represent agents' reasoning in aggregation problems. By\nstudying judgment aggregation in logics that are weaker than classical logic,\nwe investigate whether some well-known impossibility results, that were\ntailored for classical logic, still apply to those weak systems.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 09:40:16 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Porello", "Daniele", ""]]}, {"id": "1711.03745", "submitter": "Daniele Porello", "authors": "Daniele Porello", "title": "Logics for modelling collective attitudes", "comments": "To appear in Fundamenta Informaticae", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a number of logics to reason about collective propositional\nattitudes that are defined by means of the majority rule. It is well known that\nmajoritarian aggregation is subject to irrationality, as the results in social\nchoice theory and judgment aggregation show. The proposed logics for modelling\ncollective attitudes are based on a substructural propositional logic that\nallows for circumventing inconsistent outcomes. Individual and collective\npropositional attitudes, such as beliefs, desires, obligations, are then\nmodelled by means of minimal modalities to ensure a number of basic principles.\nIn this way, a viable consistent modelling of collective attitudes is obtained.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 09:53:31 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Porello", "Daniele", ""]]}, {"id": "1711.03752", "submitter": "Gabriel Navarro", "authors": "F. J. Lobillo and Luis Merino and Gabriel Navarro and Evangelina\n  Santos", "title": "Lattice embeddings between types of fuzzy sets. Closed-valued fuzzy sets", "comments": null, "journal-ref": null, "doi": "10.1016/j.fss.2018.04.014", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the problem of extending Zadeh's operators on\nfuzzy sets (FSs) to interval-valued (IVFSs), set-valued (SVFSs) and type-2\n(T2FSs) fuzzy sets. Namely, it is known that seeing FSs as SVFSs, or T2FSs,\nwhose membership degrees are singletons is not order-preserving. We then\ndescribe a family of lattice embeddings from FSs to SVFSs. Alternatively, if\nthe former singleton viewpoint is required, we reformulate the intersection on\nhesitant fuzzy sets and introduce what we have called closed-valued fuzzy sets.\nThis new type of fuzzy sets extends standard union and intersection on FSs. In\naddition, it allows handling together membership degrees of different nature\nas, for instance, closed intervals and finite sets. Finally, all these\nconstructions are viewed as T2FSs forming a chain of lattices.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 10:06:51 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Lobillo", "F. J.", ""], ["Merino", "Luis", ""], ["Navarro", "Gabriel", ""], ["Santos", "Evangelina", ""]]}, {"id": "1711.03826", "submitter": "Luca Bortolussi", "authors": "Luca Bortolussi, Roberta Lanciani and Laura Nenzi", "title": "Model Checking Markov Population Models by Stochastic Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex systems can be described by population models, in which a pool\nof agents interacts and produces complex collective behaviours. We consider the\nproblem of verifying formal properties of the underlying mathematical\nrepresentation of these models, which is a Continuous Time Markov Chain, often\nwith a huge state space. To circumvent the state space explosion, we rely on\nstochastic approximation techniques, which replace the large model by a simpler\none, guaranteed to be probabilistically consistent. We show how to efficiently\nand accurately verify properties of random individual agents, specified by\nContinuous Stochastic Logic extended with Timed Automata (CSL-TA), and how to\nlift these specifications to the collective level, approximating the number of\nagents satisfying them using second or higher order stochastic approximation\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 14:11:04 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Bortolussi", "Luca", ""], ["Lanciani", "Roberta", ""], ["Nenzi", "Laura", ""]]}, {"id": "1711.03829", "submitter": "Maximilian Schwenger", "authors": "Peter Faymonville (1), Bernd Finkbeiner (1), Maximilian Schwenger (1),\n  Hazem Torfah (1) ((1) Saarland University)", "title": "Real-time Stream-based Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce RTLola, a new stream-based specification language for the\ndescription of real-time properties of reactive systems. The key feature is the\nintegration of sliding windows over real-time intervals with aggregation\nfunctions into the language. Using sliding windows we can detach fixed-rate\noutput streams from the varying rate input streams. We provide an efficient\nevaluation algorithm of the sliding windows by partitioning the windows into\nintervals according to a given monitor frequency. For useful aggregation\nfunctions, the intervals allow a more efficient way to compute the aggregation\nvalue by dynamically reusing interval summaries. In general, the number of\ninput values within a single window instance can grow arbitrarily large\ndisallowing any guarantees on the expected memory consumption. Assuming a fixed\nmonitor output rate, we can provide memory guarantees which can be computed\na-priori. Additionally, for specifications using certain classes of aggregation\nfunctions, we can perform a more precise, better memory analysis. We\ndemonstrate the applicability of the new language on practical examples.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 14:27:19 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 11:52:34 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 08:17:13 GMT"}, {"version": "v4", "created": "Wed, 12 Jun 2019 09:37:17 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Faymonville", "Peter", "", "Saarland University"], ["Finkbeiner", "Bernd", "", "Saarland University"], ["Schwenger", "Maximilian", "", "Saarland University"], ["Torfah", "Hazem", "", "Saarland University"]]}, {"id": "1711.03842", "submitter": "Anish Tondwalkar", "authors": "Niki Vazou, Anish Tondwalkar, Vikraman Choudhury, Ryan G. Scott, Ryan\n  R. Newton, Philip Wadler, Ranjit Jhala", "title": "Refinement Reflection: Complete Verification with SMT", "comments": "29 pages plus appendices, to appear in POPL 2018. arXiv admin note:\n  text overlap with arXiv:1610.04641", "journal-ref": null, "doi": "10.1145/3158141", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce Refinement Reflection, a new framework for building SMT-based\ndeductive verifiers. The key idea is to reflect the code implementing a\nuser-defined function into the function's (output) refinement type. As a\nconsequence, at uses of the function, the function definition is instantiated\nin the SMT logic in a precise fashion that permits decidable verification.\nReflection allows the user to write equational proofs of programs just by\nwriting other programs using pattern-matching and recursion to perform\ncase-splitting and induction. Thus, via the propositions-as-types principle, we\nshow that reflection permits the specification of arbitrary functional\ncorrectness properties. Finally, we introduce a proof-search algorithm called\nProof by Logical Evaluation that uses techniques from model checking and\nabstract interpretation, to completely automate equational reasoning. We have\nimplemented reflection in Liquid Haskell and used it to verify that the widely\nused instances of the Monoid, Applicative, Functor, and Monad typeclasses\nactually satisfy key algebraic laws required to make the clients safe, and have\nused reflection to build the first library that actually verifies assumptions\nabout associativity and ordering that are crucial for safe deterministic\nparallelism.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 17:51:16 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Vazou", "Niki", ""], ["Tondwalkar", "Anish", ""], ["Choudhury", "Vikraman", ""], ["Scott", "Ryan G.", ""], ["Newton", "Ryan R.", ""], ["Wadler", "Philip", ""], ["Jhala", "Ranjit", ""]]}, {"id": "1711.03876", "submitter": "Ale\\v{s} Bizjak", "authors": "Alexander Rabinovich", "title": "A Proof of Stavi's Theorem", "comments": "arXiv admin note: text overlap with arXiv:1401.2580", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (March 6,\n  2018) lmcs:4346", "doi": "10.23638/LMCS-14(1:20)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kamp's theorem established the expressive equivalence of the temporal logic\nwith Until and Since and the First-Order Monadic Logic of Order (FOMLO) over\nthe Dedekind-complete time flows. However, this temporal logic is not\nexpressively complete for FOMLO over the rationals. Stavi introduced two\nadditional modalities and proved that the temporal logic with Until, Since and\nStavi's modalities is expressively equivalent to FOMLO over all linear orders.\nWe present a simple proof of Stavi's theorem.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 16:14:46 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 09:09:08 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Rabinovich", "Alexander", ""]]}, {"id": "1711.04184", "submitter": "Ma{\\l}gorzata Moczurad", "authors": "Ma{\\l}gorzata Moczurad, Piotr Zgliczy\\'nski", "title": "Real-number Computability from the Perspective of Computer Assisted\n  Proofs in Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by computer assisted proofs in analysis, we present an interval\napproach to real-number computations.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 19:25:36 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 17:33:07 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 18:55:09 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Moczurad", "Ma\u0142gorzata", ""], ["Zgliczy\u0144ski", "Piotr", ""]]}, {"id": "1711.04240", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Ensuring Liveness Properties of Distributed Systems (A Research Agenda)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Often fairness assumptions need to be made in order to establish liveness\nproperties of distributed systems, but in many situations these lead to false\nconclusions.\n  This document presents a research agenda aiming at laying the foundations of\na theory of concurrency that is equipped to ensure liveness properties of\ndistributed systems without making fairness assumptions. This theory will\nencompass process algebra, temporal logic and semantic models, as well as\ntreatments of real-time. The agenda also includes developing a methodology that\nallows successful application of this theory to the specification, analysis and\nverification of realistic distributed systems, including routing protocols for\nwireless networks.\n  Contemporary process algebras and temporal logics fail to make distinctions\nbetween systems of which one has a crucial liveness property and the other does\nnot, at least when assuming justness, a strong progress property, but not\nassuming fairness. Setting up an alternative framework involves giving up on\nidentifying strongly bisimilar systems, inventing new induction principles,\ndeveloping new axiomatic bases for process algebras and new congruence formats\nfor operational semantics, and creating new treatments of time and probability.\n  Even simple systems like fair schedulers or mutual exclusion protocols cannot\nbe accurately specified in standard process algebras (or Petri nets) in the\nabsence of fairness assumptions. Hence the work involves the study of adequate\nlanguage or model extensions, and their expressive power.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 05:37:55 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1711.04718", "submitter": "Peng Fu", "authors": "Peng Fu", "title": "A Type Checking Algorithm for Higher-rank, Impredicative and\n  Second-order Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a type checking algorithm that is able to type check a nontrivial\nsubclass of functional programs that use features such as higher-rank,\nimpredicative and second-order types. The only place the algorithm requires\ntype annotation is before each function declaration. We prove the soundness of\nthe type checking algorithm with respect to System $\\mathbf{F}_{\\omega}$, i.e.\nif the program is type checked, then the type checker will produce a well-typed\nannotated System $\\mathbf{F}_{\\omega}$ term. We extend the basic algorithm to\nhandle pattern matching and let-bindings. We implement a prototype type checker\nand test it on a variety of functional programs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 17:30:12 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Fu", "Peng", ""]]}, {"id": "1711.05159", "submitter": "Mathys Rennela", "authors": "Mathys Rennela and Sam Staton", "title": "Classical Control, Quantum Circuits and Linear Logic in Enriched\n  Category Theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (March 10,\n  2020) lmcs:6192", "doi": "10.23638/LMCS-16(1:30)2020", "report-no": null, "categories": "cs.LO cs.PL math.CT math.OA quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe categorical models of a circuit-based (quantum) functional\nprogramming language. We show that enriched categories play a crucial role.\nFollowing earlier work on QWire by Paykin et al., we consider both a simple\nfirst-order linear language for circuits, and a more powerful host language,\nsuch that the circuit language is embedded inside the host language. Our\ncategorical semantics for the host language is standard, and involves cartesian\nclosed categories and monads. We interpret the circuit language not in an\nordinary category, but in a category that is enriched in the host category. We\nshow that this structure is also related to linear/non-linear models. As an\nextended example, we recall an earlier result that the category of W*-algebras\nis dcpo-enriched, and we use this model to extend the circuit language with\nsome recursive types.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 15:59:21 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 17:49:53 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 13:19:22 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 21:38:22 GMT"}, {"version": "v5", "created": "Mon, 9 Mar 2020 16:39:50 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Rennela", "Mathys", ""], ["Staton", "Sam", ""]]}, {"id": "1711.05497", "submitter": "Thorsten Wissmann", "authors": "Bram Westerbaan, Bas Westerbaan, Rutger Kuyper, Carst Tankink, Remy\n  Viehoff, Henk Barendregt", "title": "Statman's Hierarchy Theorem", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (November\n  27, 2017) lmcs:4089", "doi": "10.23638/LMCS-13(4:19)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Simply Typed $\\lambda$-calculus Statman investigates the reducibility\nrelation $\\leq_{\\beta\\eta}$ between types: for $A,B \\in \\mathbb{T}^0$, types\nfreely generated using $\\rightarrow$ and a single ground type $0$, define $A\n\\leq_{\\beta\\eta} B$ if there exists a $\\lambda$-definable injection from the\nclosed terms of type $A$ into those of type $B$. Unexpectedly, the induced\npartial order is the (linear) well-ordering (of order type) $\\omega + 4$.\n  In the proof a finer relation $\\leq_{h}$ is used, where the above injection\nis required to be a B\\\"ohm transformation, and an (a posteriori) coarser\nrelation $\\leq_{h^+}$, requiring a finite family of B\\\"ohm transformations that\nis jointly injective.\n  We present this result in a self-contained, syntactic, constructive and\nsimplified manner. En route similar results for $\\leq_h$ (order type $\\omega +\n5$) and $\\leq_{h^+}$ (order type $8$) are obtained. Five of the equivalence\nclasses of $\\leq_{h^+}$ correspond to canonical term models of Statman, one to\nthe trivial term model collapsing all elements of the same type, and one does\nnot even form a model by the lack of closed terms of many types.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 10:56:30 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 13:14:20 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Westerbaan", "Bram", ""], ["Westerbaan", "Bas", ""], ["Kuyper", "Rutger", ""], ["Tankink", "Carst", ""], ["Viehoff", "Remy", ""], ["Barendregt", "Henk", ""]]}, {"id": "1711.05698", "submitter": "Rajdeep Mukherjee", "authors": "Eugene Goldberg, Matthias Gudemann, Daniel Kroening, Rajdeep Mukherjee", "title": "Efficient Verification of Multi-Property Designs (The Benefit of Wrong\n  Assumptions) (Extended Version)", "comments": "6 pages, Design Automation and Test in Europe conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficiently checking a set of safety properties\nP1,....,Pk of one design. We introduce a new approach called JA-verification\nwhere JA stands for \"Just-Assume\" (as opposed to \"assume-guarantee\"). In this\napproach, when proving property Pi, one assumes that every property Pj for j!=i\nholds. The process of proving properties either results in showing that\nP1,....,Pk hold without any assumptions or finding a \"debugging set\" of\nproperties. The latter identifies a subset of failed properties that cause\nfailure of other properties. The design behaviors that cause the properties in\nthe debugging set to fail must be fixed first. Importantly, in our approach,\nthere is no need to prove the assumptions used. We describe the theory behind\nour approach and report experimental results that demonstrate substantial gains\nin performance, especially in the cases where a small debugging set exists.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 17:50:34 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 00:55:36 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Goldberg", "Eugene", ""], ["Gudemann", "Matthias", ""], ["Kroening", "Daniel", ""], ["Mukherjee", "Rajdeep", ""]]}, {"id": "1711.05816", "submitter": "Francis Jeffry Pelletier", "authors": "Allen P. Hazen and Francis Jeffry Pelletier", "title": "K3, L3, LP, RM3, A3, FDE: How to Make Many-Valued Logics Work for You", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate some well-known (and a few not-so-well-known) many-valued\nlogics that have a small number (3 or 4) of truth values. For some of them we\ncomplain that they do not have any \\emph{logical} use (despite their perhaps\nhaving some intuitive semantic interest) and we look at ways to add features so\nas to make them useful, while retaining their intuitive appeal. At the end, we\nshow some surprising results in the system FDE, and its relationships with\nfeatures of other logics. We close with some new examples of \"synonymous\nlogics.\" An Appendix contains a natural deduction system for our augmented FDE,\nand proofs of soundness and completeness.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 21:40:01 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Hazen", "Allen P.", ""], ["Pelletier", "Francis Jeffry", ""]]}, {"id": "1711.06120", "submitter": "Ale\\v{s} Bizjak", "authors": "Vojt\\v{e}ch Forejt, Petr Jan\\v{c}ar, Stefan Kiefer, James Worrell", "title": "Game Characterization of Probabilistic Bisimilarity, and Applications to\n  Pushdown Automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (November\n  15, 2018) lmcs:4972", "doi": "10.23638/LMCS-14(4:13)2018", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the bisimilarity problem for probabilistic pushdown automata (pPDA)\nand subclasses thereof. Our definition of pPDA allows both probabilistic and\nnon-deterministic branching, generalising the classical notion of pushdown\nautomata (without epsilon-transitions). We first show a general\ncharacterization of probabilistic bisimilarity in terms of two-player games,\nwhich naturally reduces checking bisimilarity of probabilistic labelled\ntransition systems to checking bisimilarity of standard (non-deterministic)\nlabelled transition systems. This reduction can be easily implemented in the\nframework of pPDA, allowing to use known results for standard\n(non-probabilistic) PDA and their subclasses. A direct use of the reduction\nincurs an exponential increase of complexity, which does not matter in deriving\ndecidability of bisimilarity for pPDA due to the non-elementary complexity of\nthe problem. In the cases of probabilistic one-counter automata (pOCA), of\nprobabilistic visibly pushdown automata (pvPDA), and of probabilistic basic\nprocess algebras (i.e., single-state pPDA) we show that an implicit use of the\nreduction can avoid the complexity increase; we thus get PSPACE, EXPTIME, and\n2-EXPTIME upper bounds, respectively, like for the respective non-probabilistic\nversions. The bisimilarity problems for OCA and vPDA are known to have matching\nlower bounds (thus being PSPACE-complete and EXPTIME-complete, respectively);\nwe show that these lower bounds also hold for fully probabilistic versions that\ndo not use non-determinism.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 14:52:22 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 17:41:37 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 09:26:29 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Forejt", "Vojt\u011bch", ""], ["Jan\u010dar", "Petr", ""], ["Kiefer", "Stefan", ""], ["Worrell", "James", ""]]}, {"id": "1711.06128", "submitter": "Ho-Pun Lam", "authors": "Ho-Pun Lam and Mustafa Hashmi", "title": "Enabling Reasoning with LegalRuleML", "comments": "25 pages. Under consideration for publication in Theory and Practice\n  of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In order to automate verification process, regulatory rules written in\nnatural language need to be translated into a format that machines can\nunderstand. However, none of the existing formalisms can fully represent the\nelements that appear in legal norms. For instance, most of these formalisms do\nnot provide features to capture the behavior of deontic effects, which is an\nimportant aspect in automated compliance checking. This paper presents an\napproach for transforming legal norms represented using LegalRuleML to a\nvariant of Modal Defeasible Logic (and vice versa) such that a legal statement\nrepresented using LegalRuleML can be transformed into a machine-readable format\nthat can be understood and reasoned about depending upon the client's\npreferences.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 05:00:58 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 05:15:32 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Lam", "Ho-Pun", ""], ["Hashmi", "Mustafa", ""]]}, {"id": "1711.06202", "submitter": "Simone Silvetti", "authors": "Laura Nenzi, Simone Silvetti, Ezio Bartocci and Luca Bortolussi", "title": "A Robust Genetic Algorithm for Learning Temporal Specifications from\n  Data", "comments": "16 pages, 3 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of mining signal temporal logical requirements from a\ndataset of regular (good) and anomalous (bad) trajectories of a dynamical\nsystem. We assume the training set to be labeled by human experts and that we\nhave access only to a limited amount of data, typically noisy. We provide a\nsystematic approach to synthesize both the syntactical structure and the\nparameters of the temporal logic formula using a two-steps procedure: first, we\nleverage a novel evolutionary algorithm for learning the structure of the\nformula; second, we perform the parameter synthesis operating on the\nstatistical emulation of the average robustness for a candidate formula w.r.t.\nits parameters. We compare our results with our previous work [{BufoBSBLB14]\nand with a recently proposed decision-tree [bombara_decision_2016] based\nmethod. We present experimental results on two case studies: an anomalous\ntrajectory detection problem of a naval surveillance system and the\ncharacterization of an Ineffective Respiratory effort, showing the usefulness\nof our work.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 17:31:08 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 15:46:56 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 10:19:24 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Nenzi", "Laura", ""], ["Silvetti", "Simone", ""], ["Bartocci", "Ezio", ""], ["Bortolussi", "Luca", ""]]}, {"id": "1711.06361", "submitter": "Stepan Kuznetsov", "authors": "Stepan Kuznetsov", "title": "Eliminating the unit constant in the Lambek calculus with brackets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a translation of the Lambek calculus with brackets and the unit\nconstant, $\\mathbf{Lb}^{\\boldsymbol{*}}_{\\mathbf{1}}$, into the Lambek calculus\nwith brackets allowing empty antecedents, but without the unit constant,\n$\\mathbf{Lb}^{\\boldsymbol{*}}$. Using this translation, we extend previously\nknown results for $\\mathbf{Lb}^{\\boldsymbol{*}}$ to\n$\\mathbf{Lb}^{\\boldsymbol{*}}_{\\mathbf{1}}$: (1) languages generated by\ncategorial grammars based on the Lambek calculus with brackets are context-free\n(Kanazawa 2017); (2) the polynomial-time algorithm for deciding derivability of\nbounded depth sequents (Kanovich et al. 2017).\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 00:46:35 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Kuznetsov", "Stepan", ""]]}, {"id": "1711.06501", "submitter": "Jonatan Kilhamn", "authors": "Koen Claessen, Jonatan Kilhamn, Laura Kov\\'acs, Bengt Lennartson", "title": "A Supervisory Control Algorithm Based on Property-Directed Reachability", "comments": "16 pages; presented at Haifa Verification Conference 2017, the final\n  publication is available at Springer via\n  https://doi.org/10.1007/978-3-319-70389-3_8", "journal-ref": "Strichman O., Tzoref-Brill R. (eds) Hardware and Software:\n  Verification and Testing. HVC 2017. Lecture Notes in Computer Science, vol\n  10629. Springer, Cham", "doi": "10.1007/978-3-319-70389-3_8", "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for synthesising a controller (supervisor) for a\ndiscrete event system (DES) based on the property-directed reachability (PDR)\nmodel checking algorithm. The discrete event systems framework is useful in\nboth software, automation and manufacturing, as problems from those domains can\nbe modelled as discrete supervisory control problems. As a formal framework,\nDES is also similar to domains for which the field of formal methods for\ncomputer science has developed techniques and tools. In this paper, we attempt\nto marry the two by adapting PDR to the problem of controller synthesis. The\nresulting algorithm takes as input a transition system with forbidden states\nand uncontrollable transitions, and synthesises a safe and\nminimally-restrictive controller, correct-by-design. We also present an\nimplementation along with experimental results, showing that the algorithm has\npotential as a part of the solution to the greater effort of formal supervisory\ncontroller synthesis and verification.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 11:36:01 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Claessen", "Koen", ""], ["Kilhamn", "Jonatan", ""], ["Kov\u00e1cs", "Laura", ""], ["Lennartson", "Bengt", ""]]}, {"id": "1711.06541", "submitter": "Eshan Singh", "authors": "Eshan Singh, David Lin, Clark Barrett, and Subhasish Mitra", "title": "Logic Bug Detection and Localization Using Symbolic Quick Error\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Symbolic Quick Error Detection (Symbolic QED), a structured\napproach for logic bug detection and localization which can be used both during\npre-silicon design verification as well as post-silicon validation and debug.\nThis new methodology leverages prior work on Quick Error Detection (QED) which\nhas been demonstrated to drastically reduce the latency, in terms of the number\nof clock cycles, of error detection following the activation of a logic (or\nelectrical) bug. QED works through software transformations, including\nredundant execution and control flow checking, of the applied tests. Symbolic\nQED combines these error-detecting QED transformations with bounded model\nchecking-based formal analysis to generate minimal-length bug activation traces\nthat detect and localize any logic bugs in the design. We demonstrate the\npracticality and effectiveness of Symbolic QED using the OpenSPARC T2, a\n500-million-transistor open-source multicore System-on-Chip (SoC) design, and\nusing \"difficult\" logic bug scenarios observed in various state-of-the-art\ncommercial multicore SoCs. Our results show that Symbolic QED: (i) is fully\nautomatic, unlike manual techniques in use today that can be extremely\ntime-consuming and expensive; (ii) requires only a few hours in contrast to\nmanual approaches that might take days (or even months) or formal techniques\nthat often take days or fail completely for large designs; and (iii) generates\ncounter-examples (for activating and detecting logic bugs) that are up to 6\norders of magnitude shorter than those produced by traditional techniques.\nSignificantly, this new approach does not require any additional hardware.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:03:25 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Singh", "Eshan", ""], ["Lin", "David", ""], ["Barrett", "Clark", ""], ["Mitra", "Subhasish", ""]]}, {"id": "1711.06542", "submitter": "Christoph Benzm\\\"uller", "authors": "Daniel Kirchner, Christoph Benzm\\\"uller, Edward N. Zalta", "title": "Mechanizing Principia Logico-Metaphysica in Functional Type Theory", "comments": "14 pages, 6 figures; preprint of article with same title to appear in\n  The Review of Symbolic Logic", "journal-ref": null, "doi": "10.1017/S1755020319000297", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principia Logico-Metaphysica contains a foundational logical theory for\nmetaphysics, mathematics, and the sciences. It includes a canonical development\nof Abstract Object Theory [AOT], a metaphysical theory (inspired by ideas of\nErnst Mally, formalized by Zalta) that distinguishes between ordinary and\nabstract objects.\n  This article reports on recent work in which AOT has been successfully\nrepresented and partly automated in the proof assistant system Isabelle/HOL.\nInitial experiments within this framework reveal a crucial but overlooked fact:\na deeply-rooted and known paradox is reintroduced in AOT when the logic of\ncomplex terms is simply adjoined to AOT's specially-formulated comprehension\nprinciple for relations. This result constitutes a new and important paradox,\ngiven how much expressive and analytic power is contributed by having the two\nkinds of complex terms in the system. Its discovery is the highlight of our\njoint project and provides strong evidence for a new kind of scientific\npractice in philosophy, namely, computational metaphysics.\n  Our results were made technically possible by a suitable adaptation of\nBenzm\\\"uller's metalogical approach to universal reasoning by semantically\nembedding theories in classical higher-order logic. This approach enables one\nto reuse state-of-the-art higher-order proof assistants, such as Isabelle/HOL,\nfor mechanizing and experimentally exploring challenging logics and theories\nsuch as AOT. Our results also provide a fresh perspective on the question of\nwhether relational type theory or functional type theory better serves as a\nfoundation for logic and metaphysics.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 09:15:25 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 07:27:15 GMT"}, {"version": "v3", "created": "Sat, 6 Jul 2019 11:11:07 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2019 12:45:35 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Kirchner", "Daniel", ""], ["Benzm\u00fcller", "Christoph", ""], ["Zalta", "Edward N.", ""]]}, {"id": "1711.07023", "submitter": "Yannick Forster", "authors": "Yannick Forster, Edith Heiter, Gert Smolka", "title": "Verification of PCP-Related Computational Reductions in Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally verify several computational reductions concerning the Post\ncorrespondence problem (PCP) using the proof assistant Coq. Our verifications\ninclude a reduction of a string rewriting problem generalising the halting\nproblem for Turing machines to PCP, and reductions of PCP to the intersection\nproblem and the palindrome problem for context-free grammars. Interestingly,\nrigorous correctness proofs for some of the reductions are missing in the\nliterature.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 14:15:45 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 15:19:29 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Forster", "Yannick", ""], ["Heiter", "Edith", ""], ["Smolka", "Gert", ""]]}, {"id": "1711.07320", "submitter": "Albert Atserias", "authors": "Albert Atserias and Joanna Ochremiak", "title": "Proof Complexity Meets Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse how the standard reductions between constraint satisfaction\nproblems affect their proof complexity. We show that, for the most studied\npropositional, algebraic, and semi-algebraic proof systems, the classical\nconstructions of pp-interpretability, homomorphic equivalence and addition of\nconstants to a core preserve the proof complexity of the CSP. As a result, for\nthose proof systems, the classes of constraint languages for which small\nunsatisfiability certificates exist can be characterised algebraically. We\nillustrate our results by a gap theorem saying that a constraint language\neither has resolution refutations of constant width, or does not have\nbounded-depth Frege refutations of subexponential size. The former holds\nexactly for the widely studied class of constraint languages of bounded width.\nThis class is also known to coincide with the class of languages with\nrefutations of sublinear degree in Sums-of-Squares and Polynomial Calculus over\nthe real-field, for which we provide alternative proofs. We then ask for the\nexistence of a natural proof system with good behaviour with respect to\nreductions and simultaneously small size refutations beyond bounded width. We\ngive an example of such a proof system by showing that bounded-degree\nLov\\'asz-Schrijver satisfies both requirements. Finally, building on the known\nlower bounds, we demonstrate the applicability of the method of reducibilities\nand construct new explicit hard instances of the graph 3-coloring problem for\nall studied proof systems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 14:37:34 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 08:49:54 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Atserias", "Albert", ""], ["Ochremiak", "Joanna", ""]]}, {"id": "1711.07358", "submitter": "Kevin H. Knuth", "authors": "Kevin H. Knuth", "title": "Lattices and Their Consistent Quantification", "comments": "33 pages, 8 figures", "journal-ref": "K. H. Knuth, 2018. Lattices and their consistent quantification,\n  Annalen der Physik, 1700370", "doi": "10.1002/andp.201700370", "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the order-theoretic concept of lattices along with the\nconcept of consistent quantification where lattice elements are mapped to real\nnumbers in such a way that preserves some aspect of the order-theoretic\nstructure. Symmetries, such as associativity, constrain consistent\nquantification and lead to a constraint equation known as the sum rule.\nDistributivity in distributive lattices also constrains consistent\nquantification and leads to a product rule. The sum and product rules, which\nare familiar from, but not unique to, probability theory, arise from the fact\nthat logical statements form a distributive (Boolean) lattice, which exhibits\nthe requisite symmetries.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 06:21:22 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 03:23:12 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Knuth", "Kevin H.", ""]]}, {"id": "1711.07786", "submitter": "Ale\\v{s} Bizjak", "authors": "Nadia Creignou, Reinhard Pichler, Stefan Woltran", "title": "Do Hard SAT-Related Reasoning Tasks Become Easier in the Krom Fragment?", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (October\n  31, 2018) lmcs:4941", "doi": "10.23638/LMCS-14(4:10)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many reasoning problems are based on the problem of satisfiability (SAT).\nWhile SAT itself becomes easy when restricting the structure of the formulas in\na certain way, the situation is more opaque for more involved decision\nproblems. We consider here the CardMinSat problem which asks, given a\npropositional formula $\\phi$ and an atom $x$, whether $x$ is true in some\ncardinality-minimal model of $\\phi$. This problem is easy for the Horn\nfragment, but, as we will show in this paper, remains $\\Theta_2$-complete (and\nthus $\\mathrm{NP}$-hard) for the Krom fragment (which is given by formulas in\nCNF where clauses have at most two literals). We will make use of this fact to\nstudy the complexity of reasoning tasks in belief revision and logic-based\nabduction and show that, while in some cases the restriction to Krom formulas\nleads to a decrease of complexity, in others it does not. We thus also consider\nthe CardMinSat problem with respect to additional restrictions to Krom formulas\ntowards a better understanding of the tractability frontier of such problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 13:55:13 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 15:02:19 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 09:32:17 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Creignou", "Nadia", ""], ["Pichler", "Reinhard", ""], ["Woltran", "Stefan", ""]]}, {"id": "1711.08076", "submitter": "Marijn Heule", "authors": "Marijn J.H. Heule", "title": "Schur Number Five", "comments": "accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the solution of a century-old problem known as Schur Number Five:\nWhat is the largest (natural) number $n$ such that there exists a five-coloring\nof the positive numbers up to $n$ without a monochromatic solution of the\nequation $a + b = c$? We obtained the solution, $n = 160$, by encoding the\nproblem into propositional logic and applying massively parallel satisfiability\nsolving techniques on the resulting formula. We constructed and validated a\nproof of the solution to increase trust in the correctness of the\nmulti-CPU-year computations. The proof is two petabytes in size and was\ncertified using a formally verified proof checker, demonstrating that any\nresult by satisfiability solvers---no matter how large---can now be validated\nusing highly trustworthy systems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 22:54:59 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Heule", "Marijn J. H.", ""]]}, {"id": "1711.08191", "submitter": "Alberto Molinari", "authors": "Laura Bozzelli, Alberto Molinari, Angelo Montanari, Adriano Peron,\n  Pietro Sala", "title": "Interval vs. Point Temporal Logic Model Checking: an Expressiveness\n  Comparison", "comments": null, "journal-ref": "ACM Trans. Comput. Logic 20 (2018) 4:1-4:31", "doi": "10.1145/3281028", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, model checking with interval temporal logics is emerging\nas a viable alternative to model checking with standard point-based temporal\nlogics, such as LTL, CTL, CTL*, and the like. The behavior of the system is\nmodeled by means of (finite) Kripke structures, as usual. However, while\ntemporal logics which are interpreted \"point-wise\" describe how the system\nevolves state-by-state, and predicate properties of system states, those which\nare interpreted \"interval-wise\" express properties of computation stretches,\nspanning a sequence of states. A proposition letter is assumed to hold over a\ncomputation stretch (interval) if and only if it holds over each component\nstate (homogeneity assumption). A natural question arises: is there any\nadvantage in replacing points by intervals as the primary temporal entities, or\nis it just a matter of taste?\n  In this paper, we study the expressiveness of Halpern and Shoham's interval\ntemporal logic (HS) in model checking, in comparison with those of LTL, CTL,\nand CTL*. To this end, we consider three semantic variants of HS: the\nstate-based one, introduced by Montanari et al., that allows time to branch\nboth in the past and in the future, the computation-tree-based one, that allows\ntime to branch in the future only, and the trace-based variant, that disallows\ntime to branch. These variants are compared among themselves and to the\naforementioned standard logics, getting a complete picture. In particular, we\nshow that HS with trace-based semantics is equivalent to LTL (but at least\nexponentially more succinct), HS with computation-tree-based semantics is\nequivalent to finitary CTL*, and HS with state-based semantics is incomparable\nwith all of them (LTL, CTL, and CTL*).\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 09:33:35 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 14:50:28 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Bozzelli", "Laura", ""], ["Molinari", "Alberto", ""], ["Montanari", "Angelo", ""], ["Peron", "Adriano", ""], ["Sala", "Pietro", ""]]}, {"id": "1711.08699", "submitter": "Pawel Sobocinski", "authors": "Filippo Bonchi and Dusko Pavlovic and Pawel Sobocinski", "title": "Functorial Semantics for Relational Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of Frobenius theory as a generalisation of Lawvere's\nfunctorial semantics approach to categorical universal algebra. Whereas the\nuniverse for models of Lawvere theories is the category of sets and functions,\nor more generally cartesian categories, Frobenius theories take their models in\nthe category of sets and relations, or more generally in cartesian\nbicategories.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 14:15:58 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Bonchi", "Filippo", ""], ["Pavlovic", "Dusko", ""], ["Sobocinski", "Pawel", ""]]}, {"id": "1711.08859", "submitter": "Aleksandar Zelji\\'c", "authors": "Aleksandar Zeljic, Peter Backeman, Christoph M. Wintersteiger, Philipp\n  Ruemmer", "title": "Exploring Approximations for Floating-Point Arithmetic using UppSAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of solving floating-point constraints obtained from\nsoftware verification. We present UppSAT --- a new implementation of a\nsystematic approximation refinement framework [ZWR17] as an abstract SMT\nsolver. Provided with an approximation and a decision procedure (implemented in\nan off-the-shelf SMT solver), UppSAT yields an approximating SMT solver.\nAdditionally, UppSAT includes a library of predefined approximation components\nwhich can be combined and extended to define new encodings, orderings and\nsolving strategies. We propose that UppSAT can be used as a sandbox for easy\nand flexible exploration of new approximations. To substantiate this, we\nexplore several approximations of floating-point arithmetic. Approximations can\nbe viewed as a composition of an encoding into a target theory, a precision\nordering, and a number of strategies for model reconstruction and precision (or\napproximation) refinement. We present encodings of floating-point arithmetic\ninto reduced precision floating-point arithmetic, real-arithmetic, and\nfixed-point arithmetic (encoded in the theory of bit-vectors). In an\nexperimental evaluation, we compare the advantages and disadvantages of\napproximating solvers obtained by combining various encodings and decision\nprocedures (based on existing state-of-the-art SMT solvers for floating-point,\nreal, and bit-vector arithmetic).\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 02:23:41 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 14:54:19 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Zeljic", "Aleksandar", ""], ["Backeman", "Peter", ""], ["Wintersteiger", "Christoph M.", ""], ["Ruemmer", "Philipp", ""]]}, {"id": "1711.09084", "submitter": "Martin Jon\\'a\\v{s}", "authors": "Jan Mr\\'azek, Martin Jon\\'a\\v{s}, Ji\\v{r}\\'i Barnat", "title": "SMT Queries Decomposition and Caching in Semi-Symbolic Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-symbolic (control-explicit data-symbolic) model checking the\nstate-space explosion problem is fought by representing sets of states by\nfirst-order formulas over the bit-vector theory. In this model checking\napproach, most of the verification time is spent in an SMT solver on deciding\nsatisfiability of quantified queries, which represent equality of symbolic\nstates. In this paper, we introduce a new scheme for decomposition of symbolic\nstates, which can be used to significantly improve the performance of any\nsemi-symbolic model checker. Using the decomposition, a model checker can issue\nmuch simpler and smaller queries to the solver when compared to the original\ncase. Some SMT calls may be even avoided completely, as the satisfaction of\nsome of the simplified formulas can be decided syntactically. Moreover, the\ndecomposition allows for an efficient caching scheme for quantified formulas.\nTo support our theoretical contribution, we show the performance gain of our\nmodel checker SymDIVINE on a set of examples from the Software Verification\nCompetition.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 22:56:00 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Mr\u00e1zek", "Jan", ""], ["Jon\u00e1\u0161", "Martin", ""], ["Barnat", "Ji\u0159\u00ed", ""]]}, {"id": "1711.09184", "submitter": "Muaz Niazi", "authors": "Waseem Akram, Muaz A. Niazi", "title": "A Formal Specification Framework for Smart Grid Components", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid can be considered as the next step in the evolution of power\nsystems. It comprises of different entities and objects ranging from smart\nappliances, smart meters, generators, smart storages, and more. One key problem\nin modeling smart grid is that while currently there is a considerable focus on\nthe practical aspects of smart grid, there are very few modeling attempts and\neven lesser attempts at formalization. To the best of our knowledge, among\nother formal methods, formal specification has previously not been applied in\nthe domain of smart grid. In this paper, we attempt to bridge this gap by\npresenting a novel approach to modeling smart grid components using a formal\nspecification approach. We use a state-based formal specification language\nnamely Z (pronounced as `Zed') since we believe Z is particularly suited for\nmodeling smart grid components.We demonstrate the application of Z on key smart\ngrid components. The presented formal specification can be considered as first\nsteps towards modeling of smart grid using a Software Engineering formalism. It\nalso demonstrates how complex systems, such as the smart grid, can be modeled\nelegantly using formal specification.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 04:06:24 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Akram", "Waseem", ""], ["Niazi", "Muaz A.", ""]]}, {"id": "1711.09326", "submitter": "Ale\\v{s} Bizjak", "authors": "Matthew de Brecht", "title": "A generalization of a theorem of Hurewicz for quasi-Polish spaces", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (February\n  6, 2018) lmcs:4260", "doi": "10.23638/LMCS-14(1:13)2018", "report-no": null, "categories": "math.GN cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify four countable topological spaces $S_2$, $S_1$, $S_D$, and $S_0$\nwhich serve as canonical examples of topological spaces which fail to be\nquasi-Polish. These four spaces respectively correspond to the $T_2$, $T_1$,\n$T_D$, and $T_0$-separation axioms. $S_2$ is the space of rationals, $S_1$ is\nthe natural numbers with the cofinite topology, $S_D$ is an infinite chain\nwithout a top element, and $S_0$ is the set of finite sequences of natural\nnumbers with the lower topology induced by the prefix ordering. Our main result\nis a generalization of Hurewicz's theorem showing that a co-analytic subset of\na quasi-Polish space is either quasi-Polish or else contains a countable\n$\\Pi^0_2$-subset homeomorphic to one of these four spaces.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 03:00:04 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 10:24:48 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["de Brecht", "Matthew", ""]]}, {"id": "1711.09640", "submitter": "Michele Pagani", "authors": "Thomas Ehrhard (IRIF), Michele Pagani (IRIF), Christine Tasson (IRIF)", "title": "Measurable Cones and Stable, Measurable Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3158147", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a notion of stable and measurable map between cones endowed with\nmeasurability tests and show that it forms a cpo-enriched cartesian closed\ncategory. This category gives a denotational model of an extension of PCF\nsupporting the main primitives of probabilistic functional programming, like\ncontinuous and discrete probabilistic distributions, sampling, conditioning and\nfull recursion. We prove the soundness and adequacy of this model with respect\nto a call-by-name operational semantics and give some examples of its\ndenotations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 12:08:37 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"], ["Pagani", "Michele", "", "IRIF"], ["Tasson", "Christine", "", "IRIF"]]}, {"id": "1711.09740", "submitter": "Thorsten Wissmann", "authors": "Bart Jacobs and Abraham Westerbaan", "title": "Distances between States and between Predicates", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  25, 2020) lmcs:6154", "doi": "10.23638/LMCS-16(1:26)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper gives a systematic account of various metrics on probability\ndistributions (states) and on predicates. These metrics are described in a\nuniform manner using the validity relation between states and predicates. The\nstandard adjunction between convex sets (of states) and effect modules (of\npredicates) is restricted to convex complete metric spaces and directed\ncomplete effect modules. This adjunction is used in two state-and-effect\ntriangles, for classical (discrete) probability and for quantum probability.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 15:10:19 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 18:06:56 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 19:57:20 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 08:54:13 GMT"}, {"version": "v5", "created": "Mon, 24 Feb 2020 16:27:07 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Jacobs", "Bart", ""], ["Westerbaan", "Abraham", ""]]}, {"id": "1711.09762", "submitter": "Yehia Abd Alrahman", "authors": "Yehia Abd Alrahman and Rocco De Nicola and Michele Loreti", "title": "A Behavioural Theory for Interactions in Collective-Adaptive Systems", "comments": "30 pages, preprint submitted to Elsevier. arXiv admin note: text\n  overlap with arXiv:1711.06092 and arXiv:1602.05635", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a process calculus, named AbC, to study the behavioural theory of\ninteractions in collective-adaptive systems by relying on attribute-based\ncommunication. An AbC system consists of a set of parallel components each of\nwhich is equipped with a set of attributes. Communication takes place in an\nimplicit multicast fashion, and interaction among components is dynamically\nestablished by taking into account \"connections\" as determined by predicates\nover their attributes. The structural operational semantics of AbC is based on\nLabeled Transition Systems that are also used to define bisimilarity between\ncomponents. Labeled bisimilarity is in full agreement with a barbed congruence,\ndefined by simple basic observables and context closure. The introduced\nequivalence is used to study the expressiveness of AbC in terms of encoding\nbroadcast channel-based interactions and to establish formal relationships\nbetween system descriptions at different levels of abstraction.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 14:32:07 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 12:42:39 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Alrahman", "Yehia Abd", ""], ["De Nicola", "Rocco", ""], ["Loreti", "Michele", ""]]}, {"id": "1711.09946", "submitter": "Christoph Rauch", "authors": "Lorenzo Clemente and Richard Mayr", "title": "Efficient reduction of nondeterministic automata with application to\n  language inclusion testing", "comments": "69 pages. arXiv admin note: text overlap with arXiv:1210.6624", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  13, 2019) lmcs:5189", "doi": "10.23638/LMCS-15(1:12)2019", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present efficient algorithms to reduce the size of nondeterministic\nB\\\"uchi word automata (NBA) and nondeterministic finite word automata (NFA),\nwhile retaining their languages. Additionally, we describe methods to solve\nPSPACE-complete automata problems like language universality, equivalence, and\ninclusion for much larger instances than was previously possible ($\\ge 1000$\nstates instead of 10-100). This can be used to scale up applications of\nautomata in formal verification tools and decision procedures for logical\ntheories. The algorithms are based on new techniques for removing transitions\n(pruning) and adding transitions (saturation), as well as extensions of classic\nquotienting of the state space. These techniques use criteria based on\ncombinations of backward and forward trace inclusions and simulation relations.\nSince trace inclusion relations are themselves PSPACE-complete, we introduce\nlookahead simulations as good polynomial time computable approximations\nthereof. Extensive experiments show that the average-case time complexity of\nour algorithms scales slightly above quadratically. (The space complexity is\nworst-case quadratic.) The size reduction of the automata depends very much on\nthe class of instances, but our algorithm consistently reduces the size far\nmore than all previous techniques. We tested our algorithms on NBA derived from\nLTL-formulae, NBA derived from mutual exclusion protocols and many classes of\nrandom NBA and NFA, and compared their performance to the well-known automata\ntool GOAL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 19:33:12 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 19:42:12 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 17:53:30 GMT"}, {"version": "v4", "created": "Tue, 12 Feb 2019 12:45:26 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Clemente", "Lorenzo", ""], ["Mayr", "Richard", ""]]}, {"id": "1711.10078", "submitter": "Beniamino Accattoli", "authors": "Ugo Dal Lago, Beniamino Accattoli", "title": "Encoding Turing Machines into the Deterministic Lambda-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is about encoding Turing machines into the lambda-calculus.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 01:19:59 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Accattoli", "Beniamino", ""]]}, {"id": "1711.10224", "submitter": "EPTCS", "authors": "Dana Fisman (Ben-Gurion University), Swen Jacobs (Saarland University)", "title": "Proceedings Sixth Workshop on Synthesis", "comments": null, "journal-ref": "EPTCS 260, 2017", "doi": "10.4204/EPTCS.260", "report-no": null, "categories": "cs.LO cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SYNT workshop aims to bring together researchers interested in the broad\narea of synthesis of computing systems. The goal is to foster the development\nof frontier techniques in automating the development of computing system.\nContributions of interest include algorithms, complexity and decidability\nanalysis, as well as reproducible heuristics, implemented tools, and\nexperimental evaluation. Application domains include software, hardware,\nembedded, and cyber-physical systems. Computation models include functional,\nreactive, hybrid and timed systems. Identifying, formalizing, and evaluating\nsynthesis in particular application domains is encouraged.\n  The sixth iteration of the workshop took place in Heidelberg, Germany. It was\nco-located with the 29th International Conference on Computer Aided\nVerification. The workshop included four contributed talks, four invited talks,\nand reports on the Syntax-Guided Synthesis Competition (SyGuS) and the Reactive\nSynthesis Competition (SYNTCOMP).\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 11:05:51 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Fisman", "Dana", "", "Ben-Gurion University"], ["Jacobs", "Swen", "", "Saarland University"]]}, {"id": "1711.10233", "submitter": "Christoph Rauch", "authors": "Tomasz Brengos, Marco Peressotti", "title": "Behavioural equivalences for timed systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  28, 2019) lmcs:5220", "doi": "10.23638/LMCS-15(1:17)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Timed transition systems are behavioural models that include an explicit\ntreatment of time flow and are used to formalise the semantics of several\nfoundational process calculi and automata. Despite their relevance, a general\nmathematical characterisation of timed transition systems and their behavioural\ntheory is still missing. We introduce the first uniform framework for timed\nbehavioural models that encompasses known behavioural equivalences such as\ntimed bisimulations, timed language equivalences as well as their weak and\ntime-abstract counterparts. All these notions of equivalences are naturally\norganised by their discriminating power in a spectrum. We prove that this\nresult does not depend on the type of the systems under scrutiny: it holds for\nany generalisation of timed transition system. We instantiate our framework to\ntimed transition systems and their quantitative extensions such as timed\nprobabilistic systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 11:33:11 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 11:23:33 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 02:07:34 GMT"}, {"version": "v4", "created": "Tue, 12 Feb 2019 22:18:41 GMT"}, {"version": "v5", "created": "Wed, 27 Feb 2019 09:56:35 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Brengos", "Tomasz", ""], ["Peressotti", "Marco", ""]]}, {"id": "1711.10301", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli", "title": "The Maximal MAM, a Reasonable Implementation of the Maximal Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is about a reasonable abstract machine, called Maximal MAM,\nimplementing the maximal strategy of the lambda-calculus, that is, the strategy\nthat always produces a longest evaluation sequence.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 14:19:15 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Accattoli", "Beniamino", ""]]}, {"id": "1711.10636", "submitter": "EPTCS", "authors": "Roderick Bloem, Sven Schewe, Ayrat Khalimov", "title": "CTL* synthesis via LTL synthesis", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224", "journal-ref": "EPTCS 260, 2017, pp. 4-22", "doi": "10.4204/EPTCS.260.4", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce synthesis for CTL* properties to synthesis for LTL. In the context\nof model checking this is impossible - CTL* is more expressive than LTL. Yet,\nin synthesis we have knowledge of the system structure and we can add new\noutputs. These outputs can be used to encode witnesses of the satisfaction of\nCTL* subformulas directly into the system. This way, we construct an LTL\nformula, over old and new outputs and original inputs, which is realisable if,\nand only if, the original CTL* formula is realisable. The CTL*-via-LTL\nsynthesis approach preserves the problem complexity, although it might increase\nthe minimal system size. We implemented the reduction, and evaluated the\nCTL*-via-LTL synthesiser on several examples.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 01:23:10 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bloem", "Roderick", ""], ["Schewe", "Sven", ""], ["Khalimov", "Ayrat", ""]]}, {"id": "1711.10637", "submitter": "EPTCS", "authors": "Bernd Finkbeiner (1), Manuel Gieseking (2), Jesko Hecking-Harbusch\n  (1), Ernst-R\\\"udiger Olderog (2) ((1) Saarland University, (2) University of\n  Oldenburg)", "title": "Symbolic vs. Bounded Synthesis for Petri Games", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224", "journal-ref": "EPTCS 260, 2017, pp. 23-43", "doi": "10.4204/EPTCS.260.5", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petri games are a multiplayer game model for the automatic synthesis of\ndistributed systems. We compare two fundamentally different approaches for\nsolving Petri games. The symbolic approach decides the existence of a winning\nstrategy via a reduction to a two-player game over a finite graph, which in\nturn is solved by a fixed point iteration based on binary decision diagrams\n(BDDs). The bounded synthesis approach encodes the existence of a winning\nstrategy, up to a given bound on the size of the strategy, as a quantified\nBoolean formula (QBF). In this paper, we report on initial experience with a\nprototype implementation of the bounded synthesis approach. We compare bounded\nsynthesis to the existing implementation of the symbolic approach in the\nsynthesis tool ADAM. We present experimental results on a collection of\nbenchmarks, including one new benchmark family, modeling manufacturing and\nworkflow scenarios with multiple concurrent processes.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 01:24:15 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Gieseking", "Manuel", ""], ["Hecking-Harbusch", "Jesko", ""], ["Olderog", "Ernst-R\u00fcdiger", ""]]}, {"id": "1711.10639", "submitter": "EPTCS", "authors": "Hadi Ravanbakhsh (1), Sriram Sankaranarayanan (1) ((1) University of\n  Colorado, Boulder)", "title": "A Class of Control Certificates to Ensure Reach-While-Stay for Switched\n  Systems", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224", "journal-ref": "EPTCS 260, 2017, pp. 44-61", "doi": "10.4204/EPTCS.260.6", "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the problem of synthesizing switching\ncontrollers for temporal properties through the composition of simple primitive\nreach-while-stay (RWS) properties. Reach-while-stay properties specify that the\nsystem states starting from an initial set I, must reach a goal (target) set G\nin finite time, while remaining inside a safe set S. Our approach synthesizes\nswitched controllers that select between finitely many modes to satisfy the\ngiven RWS specification. To do so, we consider control certificates, which are\nLyapunov-like functions that represent control strategies to achieve the\ndesired specification. However, for RWS problems, a control Lyapunov-like\nfunction is often hard to synthesize in a simple polynomial form. Therefore, we\ncombine control barrier and Lyapunov functions with an additional compatibility\ncondition between them. Using this approach, the controller synthesis problem\nreduces to one of solving quantified nonlinear constrained problems that are\nhandled using a combination of SMT solvers. The synthesis of controllers is\ndemonstrated through a set of interesting numerical examples drawn from the\nrelated work, and compared with the state-of-the-art tool SCOTS. Our evaluation\nsuggests that our approach is computationally feasible, and adds to the growing\nbody of formal approaches to controller synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 01:26:09 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Ravanbakhsh", "Hadi", ""], ["Sankaranarayanan", "Sriram", ""]]}, {"id": "1711.10641", "submitter": "EPTCS", "authors": "Andrew Reynolds (1), Cesare Tinelli (2) ((1) University of Iowa, (2)\n  University of Iowa)", "title": "SyGuS Techniques in the Core of an SMT Solver", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224", "journal-ref": "EPTCS 260, 2017, pp. 81-96", "doi": "10.4204/EPTCS.260.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an overview of recent techniques for implementing syntax-guided\nsynthesis (SyGuS) algorithms in the core of Satisfiability Modulo Theories\n(SMT) solvers. We define several classes of synthesis conjectures and\ncorresponding techniques that can be used when dealing with each class of\nconjecture.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 01:29:26 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Reynolds", "Andrew", ""], ["Tinelli", "Cesare", ""]]}, {"id": "1711.10708", "submitter": "EPTCS", "authors": "Massimo Bartoletti (University of Cagliari, IT), Laura Bocchi\n  (University of Kent, UK), Ludovic Henrio (CNRS, Sophia Antipolis, FR), Sophia\n  Knight (Uppsala University, SE)", "title": "Proceedings 10th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 261, 2017", "doi": "10.4204/EPTCS.261", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE 2017, the 10th Interaction and\nConcurrency Experience, which was held in Neuch\\^atel, Switzerland on the 21st\nand 22nd of June 2017 as a satellite event of DisCoTec'17.\n  The ICE procedure for paper selection allows PC members to interact,\nanonymously, with authors. During the review phase, each submitted paper is\npublished on a discussion forum whose access is restricted to the authors and\nto all the PC members not declaring a conflict of interest. The PC members post\ncomments and questions that the authors reply to. For the first time, the 2017\nedition of ICE included a double blind reviewing of original research papers,\nin order to increase fairness and avoid bias in reviewing. The gender balance\nof accepted papers was also more even than in past years.\n  Each paper was reviewed by three PC members, and altogether five papers were\naccepted for publication (the workshop also featured five brief announcements\nwhich are not part of this volume). We were proud to host three invited talks,\nby Christian Cachin, Marieke Huismann, and Pawe{\\l} Sobocinski. The abstracts\nof these talks are included in this volume together with the regular papers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 07:14:40 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bartoletti", "Massimo", "", "University of Cagliari, IT"], ["Bocchi", "Laura", "", "University of Kent, UK"], ["Henrio", "Ludovic", "", "CNRS, Sophia Antipolis, FR"], ["Knight", "Sophia", "", "Uppsala University, SE"]]}, {"id": "1711.10860", "submitter": "Tom Hirschowitz", "authors": "Clovis Eberhart and Tom Hirschowitz", "title": "What's in a game? A theory of game models", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game semantics is a rich and successful class of denotational models for\nprogramming languages. Most game models feature a rather intuitive setup, yet\nsurprisingly difficult proofs of such basic results as associativity of\ncomposition of strategies. We set out to unify these models into a basic\nabstract framework for game semantics, game settings. Our main contribution is\nthe generic construction, for any game setting, of a category of games and\nstrategies. Furthermore, we extend the framework to deal with innocence, and\nprove that innocent strategies form a subcategory. We finally show that our\nconstructions cover many concrete cases, mainly among the early models and the\nvery recent sheaf-based ones.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 14:07:56 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Eberhart", "Clovis", ""], ["Hirschowitz", "Tom", ""]]}, {"id": "1711.11157", "submitter": "Yitao Liang", "authors": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van den Broeck", "title": "A Semantic Loss Function for Deep Learning with Symbolic Knowledge", "comments": "This version appears in the Proceedings of the 35th International\n  Conference on Machine Learning (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel methodology for using symbolic knowledge in deep\nlearning. From first principles, we derive a semantic loss function that\nbridges between neural output vectors and logical constraints. This loss\nfunction captures how close the neural network is to satisfying the constraints\non its output. An experimental evaluation shows that it effectively guides the\nlearner to achieve (near-)state-of-the-art results on semi-supervised\nmulti-class classification. Moreover, it significantly increases the ability of\nthe neural network to predict structured objects, such as rankings and paths.\nThese discrete concepts are tremendously difficult to learn, and benefit from a\ntight integration of deep learning and symbolic reasoning methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 23:49:55 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 00:05:58 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Xu", "Jingyi", ""], ["Zhang", "Zilu", ""], ["Friedman", "Tal", ""], ["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1711.11208", "submitter": "EPTCS", "authors": "Tobias Prehn (TU Berlin, Germany), Stephan Mennicke (TU Braunschweig,\n  Germany)", "title": "Keep it Fair: Equivalences", "comments": "In Proceedings ICE 2017, arXiv:1711.10708", "journal-ref": "EPTCS 261, 2017, pp. 5-16", "doi": "10.4204/EPTCS.261.4", "report-no": null, "categories": "cs.LO cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For models of concurrent and distributed systems, it is important and also\nchallenging to establish correctness in terms of safety and/or liveness\nproperties. Theories of distributed systems consider equivalences fundamental,\nsince they (1) preserve desirable correctness characteristics and (2) often\nallow for component substitution making compositional reasoning feasible.\nModeling distributed systems often requires abstraction utilizing\nnondeterminism which induces unintended behaviors in terms of infinite\nexecutions with one nondeterministic choice being recurrently resolved, each\ntime neglecting a single alternative. These situations are considered\nunrealistic or highly improbable. Fairness assumptions are commonly used to\nfilter system behaviors, thereby distinguishing between realistic and\nunrealistic executions. This allows for key arguments in correctness proofs of\ndistributed systems, which would not be possible otherwise. Our contribution is\nan equivalence spectrum in which fairness assumptions are preserved. The\nidentified equivalences allow for (compositional) reasoning about correctness\nincorporating fairness assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 03:45:30 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Prehn", "Tobias", "", "TU Berlin, Germany"], ["Mennicke", "Stephan", "", "TU Braunschweig,\n  Germany"]]}, {"id": "1711.11209", "submitter": "EPTCS", "authors": "Franco Barbanera, Ugo de'Liguoro", "title": "Session Types for Orchestrated Interactions", "comments": "In Proceedings ICE 2017, arXiv:1711.10708", "journal-ref": "EPTCS 261, 2017, pp. 17-36", "doi": "10.4204/EPTCS.261.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of the pi-calculus with binary sessions, we aim at relaxing\nthe notion of duality of session types by the concept of retractable compliance\ndeveloped in contract theory. This leads to extending session types with a new\ntype operator of \"speculative selection\" including choices not necessarily\noffered by a compliant partner. We address the problem of selecting successful\ncommunicating branches by means of an operational semantics based on\norchestrators, which has been shown to be equivalent to the retractable\nsemantics of contracts, but clearly more feasible. A type system, sound with\nrespect to such a semantics, is hence provided.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 03:45:49 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Barbanera", "Franco", ""], ["de'Liguoro", "Ugo", ""]]}, {"id": "1711.11210", "submitter": "EPTCS", "authors": "Chiara Bodei (Dipartimento di Informatica, Universit\\`a di Pisa),\n  Pierpaolo Degano (Dipartimento di Informatica, Universit\\`a di Pisa),\n  Letterio Galletta (Dipartimento di Informatica, Universit\\`a di Pisa), Emilio\n  Tuosto (Department of Informatics, University of Leicester)", "title": "Tool Supported Analysis of IoT", "comments": "In Proceedings ICE 2017, arXiv:1711.10708", "journal-ref": "EPTCS 261, 2017, pp. 37-56", "doi": "10.4204/EPTCS.261.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of IoT systems could benefit from the combination of two different\nanalyses. We perform a first analysis to approximate how data flow across the\nsystem components, while the second analysis checks their communication\nsoundness. We show how the combination of these two analyses yields further\nbenefits hardly achievable by separately using each of them. We exploit two\nindependently developed tools for the analyses.\n  Firstly, we specify IoT systems in IoT-LySa, a simple specification language\nfeaturing asynchronous multicast communication of tuples. The values carried by\nthe tuples are drawn from a term-algebra obtained by a parametric signature.\nThe analysis of communication soundness is supported by ChorGram, a tool\ndeveloped to verify the compatibility of communicating finite-state machines.\nIn order to combine the analyses we implement an encoding of IoT-LySa processes\ninto communicating machines. This encoding is not completely straightforward\nbecause IoT-LySa has multicast communications with data, while communication\nmachines are based on point-to-point communications where only finitely many\nsymbols can be exchanged. To highlight the benefits of our approach we appeal\nto a simple yet illustrative example.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 03:46:09 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Bodei", "Chiara", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"], ["Degano", "Pierpaolo", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"], ["Galletta", "Letterio", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"], ["Tuosto", "Emilio", "", "Department of Informatics, University of Leicester"]]}, {"id": "1711.11439", "submitter": "EPTCS", "authors": "Swen Jacobs (1), Nicolas Basset (2), Roderick Bloem (3), Romain\n  Brenguier (4), Maximilien Colange (5), Peter Faymonville (1), Bernd\n  Finkbeiner (1), Ayrat Khalimov (3), Felix Klein (1), Thibaud Michaud (5),\n  Guillermo A. P\\'erez (2), Jean-Fran\\c{c}ois Raskin (2), Ocan Sankur (6),\n  Leander Tentrup (1) ((1) Saarland University, (2) Universit\\'e Libre de\n  Bruxelles, (3) Graz University of Technology, (4) University of Oxford, (5)\n  LRDE, EPITA, (6) CNRS, Irisa)", "title": "The 4th Reactive Synthesis Competition (SYNTCOMP 2017): Benchmarks,\n  Participants & Results", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224. arXiv admin note: text\n  overlap with arXiv:1609.00507", "journal-ref": "EPTCS 260, 2017, pp. 116-143", "doi": "10.4204/EPTCS.260.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the fourth reactive synthesis competition (SYNTCOMP 2017). We\nintroduce two new benchmark classes that have been added to the SYNTCOMP\nlibrary, and briefly describe the benchmark selection, evaluation scheme and\nthe experimental setup of SYNTCOMP 2017. We present the participants of\nSYNTCOMP 2017, with a focus on changes with respect to the previous years and\non the two completely new tools that have entered the competition. Finally, we\npresent and analyze the results of our experimental evaluation, including a\nranking of tools with respect to quantity and quality of solutions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 04:02:14 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Jacobs", "Swen", ""], ["Basset", "Nicolas", ""], ["Bloem", "Roderick", ""], ["Brenguier", "Romain", ""], ["Colange", "Maximilien", ""], ["Faymonville", "Peter", ""], ["Finkbeiner", "Bernd", ""], ["Khalimov", "Ayrat", ""], ["Klein", "Felix", ""], ["Michaud", "Thibaud", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""], ["Tentrup", "Leander", ""]]}]