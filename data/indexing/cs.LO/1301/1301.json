[{"id": "1301.0038", "submitter": "EPTCS", "authors": "Kyungmin Bae (University of Illinois at Urbana-Champaign), Joshua\n  Krisiloff (University of Illinois at Urbana-Champaign), Jos\\'e Meseguer\n  (University of Illinois at Urbana-Champaign), Peter Csaba \\\"Olveczky\n  (University of Oslo)", "title": "PALS-Based Analysis of an Airplane Multirate Control System in Real-Time\n  Maude", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 5-21", "doi": "10.4204/EPTCS.105.2", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed cyber-physical systems (DCPS) are pervasive in areas such as\naeronautics and ground transportation systems, including the case of\ndistributed hybrid systems. DCPS design and verification is quite challenging\nbecause of asynchronous communication, network delays, and clock skews.\nFurthermore, their model checking verification typically becomes unfeasible due\nto the huge state space explosion caused by the system's concurrency. The PALS\n(\"physically asynchronous, logically synchronous\") methodology has been\nproposed to reduce the design and verification of a DCPS to the much simpler\ntask of designing and verifying its underlying synchronous version. The\noriginal PALS methodology assumes a single logical period, but Multirate PALS\nextends it to deal with multirate DCPS in which components may operate with\ndifferent logical periods. This paper shows how Multirate PALS can be applied\nto formally verify a nontrivial multirate DCPS. We use Real-Time Maude to\nformally specify a multirate distributed hybrid system consisting of an\nairplane maneuvered by a pilot who turns the airplane according to a specified\nangle through a distributed control system. Our formal analysis revealed that\nthe original design was ineffective in achieving a smooth turning maneuver, and\nled to a redesign of the system that satisfies the desired correctness\nproperties. This shows that the Multirate PALS methodology is not only\neffective for formal DCPS verification, but can also be used effectively in the\nDCPS design process, even before properties are verified.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:54:14 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Bae", "Kyungmin", "", "University of Illinois at Urbana-Champaign"], ["Krisiloff", "Joshua", "", "University of Illinois at Urbana-Champaign"], ["Meseguer", "Jos\u00e9", "", "University of Illinois at Urbana-Champaign"], ["\u00d6lveczky", "Peter Csaba", "", "University of Oslo"]]}, {"id": "1301.0039", "submitter": "EPTCS", "authors": "Adrien Champion (Onera / Rockwell Collins France), R\\'emi Delmas\n  (Onera), Michael Dierkes (Rockwell Collins France)", "title": "Generating Property-Directed Potential Invariants By Backward Analysis", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 22-38", "doi": "10.4204/EPTCS.105.3", "report-no": null, "categories": "cs.LO cs.CE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the issue of lemma generation in a k-induction-based\nformal analysis of transition systems, in the linear real/integer arithmetic\nfragment. A backward analysis, powered by quantifier elimination, is used to\noutput preimages of the negation of the proof objective, viewed as unauthorized\nstates, or gray states. Two heuristics are proposed to take advantage of this\nsource of information. First, a thorough exploration of the possible\npartitionings of the gray state space discovers new relations between state\nvariables, representing potential invariants. Second, an inexact exploration\nregroups and over-approximates disjoint areas of the gray state space, also to\ndiscover new relations between state variables. k-induction is used to isolate\nthe invariants and check if they strengthen the proof objective. These\nheuristics can be used on the first preimage of the backward exploration, and\neach time a new one is output, refining the information on the gray states. In\nour context of critical avionics embedded systems, we show that our approach is\nable to outperform other academic or commercial tools on examples of interest\nin our application field. The method is introduced and motivated through two\nmain examples, one of which was provided by Rockwell Collins, in a\ncollaborative formal verification framework.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:54:21 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Champion", "Adrien", "", "Onera / Rockwell Collins France"], ["Delmas", "R\u00e9mi", "", "Onera"], ["Dierkes", "Michael", "", "Rockwell Collins France"]]}, {"id": "1301.0040", "submitter": "EPTCS", "authors": "Peter Hui (Pacific Northwest National Laboratory), Satish Chikkagoudar\n  (Pacific Northwest National Laboratory)", "title": "A Formal Model For Real-Time Parallel Computation", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 39-55", "doi": "10.4204/EPTCS.105.4", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imposition of real-time constraints on a parallel computing environment-\nspecifically high-performance, cluster-computing systems- introduces a variety\nof challenges with respect to the formal verification of the system's timing\nproperties. In this paper, we briefly motivate the need for such a system, and\nwe introduce an automaton-based method for performing such formal verification.\nWe define the concept of a consistent parallel timing system: a hybrid system\nconsisting of a set of timed automata (specifically, timed Buchi automata as\nwell as a timed variant of standard finite automata), intended to model the\ntiming properties of a well-behaved real-time parallel system. Finally, we give\na brief case study to demonstrate the concepts in the paper: a parallel matrix\nmultiplication kernel which operates within provable upper time bounds. We give\nthe algorithm used, a corresponding consistent parallel timing system, and\nempirical results showing that the system operates under the specified timing\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:54:28 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Hui", "Peter", "", "Pacific Northwest National Laboratory"], ["Chikkagoudar", "Satish", "", "Pacific Northwest National Laboratory"]]}, {"id": "1301.0041", "submitter": "EPTCS", "authors": "Masahiro Matsubara (Hitachi, Ltd.), Kohei Sakurai (Hitachi, Ltd.),\n  Fumio Narisawa (Hitachi, Ltd.), Masushi Enshoiwa (Hitachi Advanced Digital,\n  Inc.), Yoshio Yamane (Hitachi Advanced Digital, Inc.), Hisamitsu Yamanaka\n  (Hitachi Automotive Systems, Ltd.)", "title": "Model Checking with Program Slicing Based on Variable Dependence Graphs", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 56-68", "doi": "10.4204/EPTCS.105.5", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In embedded control systems, the potential risks of software defects have\nbeen increasing because of software complexity which leads to, for example,\ntiming related problems. These defects are rarely found by tests or\nsimulations. To detect such defects, we propose a modeling method which can\ngenerate software models for model checking with a program slicing technique\nbased on a variable dependence graph. We have applied the proposed method to\none case in automotive control software and demonstrated the effectiveness of\nthe method. Furthermore, we developed a software tool to automate model\ngeneration and achieved a 35% decrease in total verification time on model\nchecking.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:54:35 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Matsubara", "Masahiro", "", "Hitachi, Ltd."], ["Sakurai", "Kohei", "", "Hitachi, Ltd."], ["Narisawa", "Fumio", "", "Hitachi, Ltd."], ["Enshoiwa", "Masushi", "", "Hitachi Advanced Digital,\n  Inc."], ["Yamane", "Yoshio", "", "Hitachi Advanced Digital, Inc."], ["Yamanaka", "Hisamitsu", "", "Hitachi Automotive Systems, Ltd."]]}, {"id": "1301.0044", "submitter": "EPTCS", "authors": "Chen-Wei Wang (McMaster Centre for Software Certification, McMaster\n  University), Jim Davies (Department of Computer Science, University of\n  Oxford)", "title": "Formal Model-Driven Engineering: Generating Data and Behavioural\n  Components", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 100-117", "doi": "10.4204/EPTCS.105.8", "report-no": null, "categories": "cs.SE cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-driven engineering is the automatic production of software artefacts\nfrom abstract models of structure and functionality. By targeting a specific\nclass of system, it is possible to automate aspects of the development process,\nusing model transformations and code generators that encode domain knowledge\nand implementation strategies. Using this approach, questions of correctness\nfor a complex, software system may be answered through analysis of abstract\nmodels of lower complexity, under the assumption that the transformations and\ngenerators employed are themselves correct. This paper shows how formal\ntechniques can be used to establish the correctness of model transformations\nused in the generation of software components from precise object models. The\nsource language is based upon existing, formal techniques; the target language\nis the widely-used SQL notation for database programming. Correctness is\nestablished by giving comparable, relational semantics to both languages, and\nchecking that the transformations are semantics-preserving.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:54:57 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Wang", "Chen-Wei", "", "McMaster Centre for Software Certification, McMaster\n  University"], ["Davies", "Jim", "", "Department of Computer Science, University of\n  Oxford"]]}, {"id": "1301.0045", "submitter": "EPTCS", "authors": "Mengying Wang (ECNU), Yang Lu (SJTU)", "title": "A Timed Calculus for Mobile Ad Hoc Networks", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 118-134", "doi": "10.4204/EPTCS.105.9", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a timed calculus for Mobile Ad Hoc Networks embodying the\npeculiarities of local broadcast, node mobility and communication interference.\nWe present a Reduction Semantics and a Labelled Transition Semantics and prove\nthe equivalence between them. We then apply our calculus to model and study\nsome MAC-layer protocols with special emphasis on node mobility and\ncommunication interference.\n  A main purpose of the semantics is to describe the various forms of\ninterference while nodes change their locations in the network. Such\ninterference only occurs when a node is simultaneously reached by more than one\nongoing transmission over the same channel.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:55:04 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Wang", "Mengying", "", "ECNU"], ["Lu", "Yang", "", "SJTU"]]}, {"id": "1301.0046", "submitter": "EPTCS", "authors": "Zheng Wang (East China Normal University), Geguang Pu (East China\n  Normal University), Jianwen Li (East China Normal University), Jifeng He\n  (East China Normal University), Shengchao Qin (University of Teesside), Kim\n  G. Larsen (Aalborg University of Denmark), Jan Madsen (Technical University\n  of Denmark), Bin Gu (Beijing Institute of Control Engineering)", "title": "MDM: A Mode Diagram Modeling Framework", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 135-149", "doi": "10.4204/EPTCS.105.10", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Periodic control systems used in spacecrafts and automotives are usually\nperiod-driven and can be decomposed into different modes with each mode\nrepresenting a system state observed from outside. Such systems may also\ninvolve intensive computing in their modes. Despite the fact that such control\nsystems are widely used in the above-mentioned safety-critical embedded\ndomains, there is lack of domain-specific formal modelling languages for such\nsystems in the relevant industry. To address this problem, we propose a formal\nvisual modeling framework called mode diagram as a concise and precise way to\nspecify and analyze such systems. To capture the temporal properties of\nperiodic control systems, we provide, along with mode diagram, a property\nspecification language based on interval logic for the description of concrete\ntemporal requirements the engineers are concerned with. The statistical model\nchecking technique can then be used to verify the mode diagram models against\ndesired properties. To demonstrate the viability of our approach, we have\napplied our modelling framework to some real life case studies from industry\nand helped detect two design defects for some spacecraft control systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:55:16 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Wang", "Zheng", "", "East China Normal University"], ["Pu", "Geguang", "", "East China\n  Normal University"], ["Li", "Jianwen", "", "East China Normal University"], ["He", "Jifeng", "", "East China Normal University"], ["Qin", "Shengchao", "", "University of Teesside"], ["Larsen", "Kim G.", "", "Aalborg University of Denmark"], ["Madsen", "Jan", "", "Technical University\n  of Denmark"], ["Gu", "Bin", "", "Beijing Institute of Control Engineering"]]}, {"id": "1301.0302", "submitter": "Paulo Shakarian", "authors": "Paulo Shakarian, Gerardo I. Simari, Robert Schroeder", "title": "MANCaLog: A Logic for Multi-Attribute Network Cascades (Technical\n  Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The modeling of cascade processes in multi-agent systems in the form of\ncomplex networks has in recent years become an important topic of study due to\nits many applications: the adoption of commercial products, spread of disease,\nthe diffusion of an idea, etc. In this paper, we begin by identifying a\ndesiderata of seven properties that a framework for modeling such processes\nshould satisfy: the ability to represent attributes of both nodes and edges, an\nexplicit representation of time, the ability to represent non-Markovian\ntemporal relationships, representation of uncertain information, the ability to\nrepresent competing cascades, allowance of non-monotonic diffusion, and\ncomputational tractability. We then present the MANCaLog language, a formalism\nbased on logic programming that satisfies all these desiderata, and focus on\nalgorithms for finding minimal models (from which the outcome of cascades can\nbe obtained) as well as how this formalism can be applied in real world\nscenarios. We are not aware of any other formalism in the literature that meets\nall of the above requirements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 20:01:04 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2013 01:54:12 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Shakarian", "Paulo", ""], ["Simari", "Gerardo I.", ""], ["Schroeder", "Robert", ""]]}, {"id": "1301.0647", "submitter": "Mani A", "authors": "A. Mani", "title": "Algebraic Semantics of Similarity-Based Bitten Rough Set Theory", "comments": "Almost the same as my published paper in FI", "journal-ref": "Mani, A.: Algebraic semantics of similarity-based bitten rough set\n  theory. Fundamenta Informaticae 97 (2009) 177--197", "doi": null, "report-no": null, "categories": "math.LO cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two algebraic semantics for bitten rough set theory (\\cite{SW})\nover similarity spaces and their abstract granular versions. Connections with\nchoice based generalized rough semantics developed in \\cite{AM69} by the\npresent author and general cover based rough set theories are also considered.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 22:59:49 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1301.0667", "submitter": "Zhaohua Luo", "authors": "Zhaohua Luo", "title": "Algebraic Logic, I Quantifier Theories and Completeness Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic logic studies algebraic theories related to proposition and\nfirst-order logic. A new algebraic approach to first-order logic is sketched in\nthis paper. We introduce the notion of a quantifier theory, which is a functor\nfrom the category of a monad of sets to the category of Boolean algebras,\ntogether with a uniquely determined system of quantifiers. A striking feature\nof this approach is that Cayley's Completeness Theorem and Godel's Completeness\nTheorem can be stated and proved in a much simpler fashion for quantifier\ntheories. Both theorems are due to Halmos for polyadic algebras. We also\npresent a simple transparent treatment of ultraproducts of models of a\nquantifier theory.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 03:40:58 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Luo", "Zhaohua", ""]]}, {"id": "1301.0999", "submitter": "Paul Poncet", "authors": "Paul Poncet", "title": "Transporting continuity properties from a poset to its subposets", "comments": "34 pages. Changes: new title, new abstract, major changes with\n  additional sections and results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify two key conditions that a subset $A$ of a poset $P$ may satisfy\nto guarantee the transfer of continuity properties from $P$ to $A$. We then\nhighlight practical cases where these key conditions are fulfilled. Along the\nway we are led to consider subsets of a given poset $P$ whose way-below\nrelation is the restriction of the way-below relation of $P$, which we call\nway-below preserving subposets. As an application, we show that every\nconditionally complete poset $P$ with the interpolation property contains a\nlargest continuous way-below preserving subposet. Most of our results are\nexpressed in the general setting of $Z$ theory, where $Z$ is a subset system.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 12:10:40 GMT"}, {"version": "v2", "created": "Fri, 26 Sep 2014 13:57:00 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 11:00:01 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Poncet", "Paul", ""]]}, {"id": "1301.1003", "submitter": "Jef Wijsen", "authors": "Jef Wijsen", "title": "Charting the Tractability Frontier of Certain Conjunctive Query\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An uncertain database is defined as a relational database in which primary\nkeys need not be satisfied. A repair (or possible world) of such database is\nobtained by selecting a maximal number of tuples without ever selecting two\ndistinct tuples with the same primary key value. For a Boolean query q, the\ndecision problem CERTAINTY(q) takes as input an uncertain database db and asks\nwhether q is satisfied by every repair of db. Our main focus is on acyclic\nBoolean conjunctive queries without self-join. Previous work has introduced the\nnotion of (directed) attack graph of such queries, and has proved that\nCERTAINTY(q) is first-order expressible if and only if the attack graph of q is\nacyclic. The current paper investigates the boundary between tractability and\nintractability of CERTAINTY(q). We first classify cycles in attack graphs as\neither weak or strong, and then prove among others the following. If the attack\ngraph of a query q contains a strong cycle, then CERTAINTY(q) is coNP-complete.\nIf the attack graph of q contains no strong cycle and every weak cycle of it is\nterminal (i.e., no edge leads from a vertex in the cycle to a vertex outside\nthe cycle), then CERTAINTY(q) is in P. We then partially address the only\nremaining open case, i.e., when the attack graph contains some nonterminal\ncycle and no strong cycle. Finally, we establish a relationship between the\ncomplexities of CERTAINTY(q) and evaluating q on probabilistic databases.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 13:08:21 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Wijsen", "Jef", ""]]}, {"id": "1301.1390", "submitter": "Michael Fink", "authors": "Thomas Eiter, Michael Fink, Thomas Krennwallner, Christoph Redl, and\n  Peter Sch\\\"uller", "title": "Eliminating Unfounded Set Checking for HEX-Programs", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEX-programs are an extension of the Answer Set Programming (ASP) paradigm\nincorporating external means of computation into the declarative programming\nlanguage through so-called external atoms. Their semantics is defined in terms\nof minimal models of the Faber-Leone-Pfeifer (FLP) reduct. Developing native\nsolvers for HEX-programs based on an appropriate notion of unfounded sets has\nbeen subject to recent research for reasons of efficiency. Although this has\nlead to an improvement over naive minimality checking using the FLP reduct,\ntesting for foundedness remains a computationally expensive task. In this work\nwe improve on HEX-program evaluation in this respect by identifying a syntactic\nclass of programs, that can be efficiently recognized and allows to entirely\nskip the foundedness check. Moreover, we develop criteria for decomposing a\nprogram into components, such that the search for unfounded sets can be\nrestricted. Observing that our results apply to many HEX-program applications\nprovides analytic evidence for the significance and effectiveness of our\napproach, which is complemented by a brief discussion of preliminary\nexperimental validation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:22 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Eiter", "Thomas", ""], ["Fink", "Michael", ""], ["Krennwallner", "Thomas", ""], ["Redl", "Christoph", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1301.1391", "submitter": "Johannes Klaus Fichte", "authors": "Johannes Klaus Fichte and Stefan Szeider", "title": "Backdoors to Normality for Disjunctive Logic Programs", "comments": "A short version will appear in the Proceedings of the Proceedings of\n  the 27th AAAI Conference on Artificial Intelligence (AAAI'13). A preliminary\n  version of the paper was presented on the workshop Answer Set Programming and\n  Other Computing Paradigms (ASPOCP 2012), 5th International Workshop,\n  September 4, 2012, Budapest, Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, propositional satisfiability (SAT) has become one\nof the most successful and widely applied techniques for the solution of\nNP-complete problems. The aim of this paper is to investigate theoretically how\nSat can be utilized for the efficient solution of problems that are harder than\nNP or co-NP. In particular, we consider the fundamental reasoning problems in\npropositional disjunctive answer set programming (ASP), Brave Reasoning and\nSkeptical Reasoning, which ask whether a given atom is contained in at least\none or in all answer sets, respectively. Both problems are located at the\nsecond level of the Polynomial Hierarchy and thus assumed to be harder than NP\nor co-NP. One cannot transform these two reasoning problems into SAT in\npolynomial time, unless the Polynomial Hierarchy collapses. We show that\ncertain structural aspects of disjunctive logic programs can be utilized to\nbreak through this complexity barrier, using new techniques from Parameterized\nComplexity. In particular, we exhibit transformations from Brave and Skeptical\nReasoning to SAT that run in time O(2^k n^2) where k is a structural parameter\nof the instance and n the input size. In other words, the reduction is\nfixed-parameter tractable for parameter k. As the parameter k we take the size\nof a smallest backdoor with respect to the class of normal (i.e.,\ndisjunction-free) programs. Such a backdoor is a set of atoms that when deleted\nmakes the program normal. In consequence, the combinatorial explosion, which is\nexpected when transforming a problem from the second level of the Polynomial\nHierarchy to the first level, can now be confined to the parameter k, while the\nrunning time of the reduction is polynomial in the input size n, where the\norder of the polynomial is independent of k.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:37 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 17:17:43 GMT"}], "update_date": "2013-05-06", "authors_parsed": [["Fichte", "Johannes Klaus", ""], ["Szeider", "Stefan", ""]]}, {"id": "1301.1393", "submitter": "Michael Fink", "authors": "Joohyung Lee and Yunsong Meng", "title": "Two New Definitions of Stable Models of Logic Programs with Generalized\n  Quantifiers", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present alternative definitions of the first-order stable model semantics\nand its extension to incorporate generalized quantifiers by referring to the\nfamiliar notion of a reduct instead of referring to the SM operator in the\noriginal definitions. Also, we extend the FLP stable model semantics to allow\ngeneralized quantifiers by referring to an operator that is similar to the\n$\\sm$ operator. For a reasonable syntactic class of logic programs, we show\nthat the two stable model semantics of generalized quantifiers are\ninterchangeable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:49 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Lee", "Joohyung", ""], ["Meng", "Yunsong", ""]]}, {"id": "1301.1394", "submitter": "Michael Fink", "authors": "Vladimir Lifschitz and Fangkai Yang", "title": "Lloyd-Topor Completion and General Stable Models", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between the generalization of program\ncompletion defined in 1984 by Lloyd and Topor and the generalization of the\nstable model semantics introduced recently by Ferraris et al. The main theorem\ncan be used to characterize, in some cases, the general stable models of a\nlogic program by a first-order formula. The proof uses Truszczynski's stable\nmodel semantics of infinitary propositional formulas.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:55 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Lifschitz", "Vladimir", ""], ["Yang", "Fangkai", ""]]}, {"id": "1301.1395", "submitter": "Michael Fink", "authors": "Joost Vennekens and Marc Denecker", "title": "Extending FO(ID) with Knowledge Producing Definitions: Preliminary\n  Results", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research into the relation between ASP and classical logic has\nidentified at least two different ways in which the former extends the latter.\nFirst, ASP program typically contain sets of rules that can be naturally\ninterpreted as inductive definitions, and the language FO(ID) has shown that\nsuch inductive definitions can elegantly be added to classical logic in a\nmodular way. Second, there is of course also the well-known epistemic component\nof ASP, which was mainly emphasized in the early papers on stable model\nsemantics. To investigate whether this kind of knowledge can also, and in a\nsimilarly modular way, be added to classical logic, the language of Ordered\nEpistemic Logic was presented in recent work. However, this logic views the\nepistemic component as entirely separate from the inductive definition\ncomponent, thus ignoring any possible interplay between the two. In this paper,\nwe present a language that extends the inductive definition construct found in\nFO(ID) with an epistemic component, making such interplay possible. The\neventual goal of this work is to discover whether it is really appropriate to\nview the epistemic component and the inductive definition component of ASP as\ntwo separate extensions of classical logic, or whether there is also something\nof importance in the combination of the two.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:30:01 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Vennekens", "Joost", ""], ["Denecker", "Marc", ""]]}, {"id": "1301.1629", "submitter": "Michael Tautschnig", "authors": "Jade Alglave and Daniel Kroening and Michael Tautschnig", "title": "Partial Orders for Efficient BMC of Concurrent Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast number of interleavings that a concurrent program can have is\ntypically identified as the root cause of the difficulty of automatic analysis\nof concurrent software. Weak memory is generally believed to make this problem\neven harder. We address both issues by modelling programs' executions with\npartial orders rather than the interleaving semantics (SC). We implemented a\nsoftware analysis tool based on these ideas. It scales to programs of\nsufficient size to achieve first-time formal verification of non-trivial\nconcurrent systems code over a wide range of models, including SC, Intel x86\nand IBM Power.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 18:41:11 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Alglave", "Jade", ""], ["Kroening", "Daniel", ""], ["Tautschnig", "Michael", ""]]}, {"id": "1301.1702", "submitter": "Alexey Solovyev", "authors": "Alexey Solovyev, Thomas C. Hales", "title": "Formal Verification of Nonlinear Inequalities with Taylor Interval\n  Approximations", "comments": "15 pages", "journal-ref": null, "doi": "10.1007/978-3-642-38088-4_26", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal tool for verification of multivariate nonlinear\ninequalities. Our verification method is based on interval arithmetic with\nTaylor approximations. Our tool is implemented in the HOL Light proof assistant\nand it is capable to verify multivariate nonlinear polynomial and\nnon-polynomial inequalities on rectangular domains. One of the main features of\nour work is an efficient implementation of the verification procedure which can\nprove non-trivial high-dimensional inequalities in several seconds. We\ndeveloped the verification tool as a part of the Flyspeck project (a formal\nproof of the Kepler conjecture). The Flyspeck project includes about 1000\nnonlinear inequalities. We successfully tested our method on more than 100\nFlyspeck inequalities and estimated that the formal verification procedure is\nabout 3000 times slower than an informal verification method implemented in\nC++. We also describe future work and prospective optimizations for our method.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 21:46:46 GMT"}], "update_date": "2013-05-22", "authors_parsed": [["Solovyev", "Alexey", ""], ["Hales", "Thomas C.", ""]]}, {"id": "1301.1818", "submitter": "Michael Ummels", "authors": "Michael Ummels and Christel Baier", "title": "Computing Quantiles in Markov Reward Models", "comments": "17 pages, 1 figure; typo in example corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic model checking mainly concentrates on techniques for reasoning\nabout the probabilities of certain path properties or expected values of\ncertain random variables. For the quantitative system analysis, however, there\nis also another type of interesting performance measure, namely quantiles. A\ntypical quantile query takes as input a lower probability bound p and a\nreachability property. The task is then to compute the minimal reward bound r\nsuch that with probability at least p the target set will be reached before the\naccumulated reward exceeds r. Quantiles are well-known from mathematical\nstatistics, but to the best of our knowledge they have not been addressed by\nthe model checking community so far.\n  In this paper, we study the complexity of quantile queries for until\nproperties in discrete-time finite-state Markov decision processes with\nnon-negative rewards on states. We show that qualitative quantile queries can\nbe evaluated in polynomial time and present an exponential algorithm for the\nevaluation of quantitative quantile queries. For the special case of Markov\nchains, we show that quantitative quantile queries can be evaluated in time\npolynomial in the size of the chain and the maximum reward.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 11:41:43 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 10:00:10 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Ummels", "Michael", ""], ["Baier", "Christel", ""]]}, {"id": "1301.2678", "submitter": "Fabio Patrizi", "authors": "Francesco Belardinelli, Alessio Lomuscio, Fabio Patrizi", "title": "Verification of Agent-Based Artifact Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artifact systems are a novel paradigm for specifying and implementing\nbusiness processes described in terms of interacting modules called artifacts.\nArtifacts consist of data and lifecycles, accounting respectively for the\nrelational structure of the artifacts' states and their possible evolutions\nover time. In this paper we put forward artifact-centric multi-agent systems, a\nnovel formalisation of artifact systems in the context of multi-agent systems\noperating on them. Differently from the usual process-based models of services,\nthe semantics we give explicitly accounts for the data structures on which\nartifact systems are defined. We study the model checking problem for\nartifact-centric multi-agent systems against specifications written in a\nquantified version of temporal-epistemic logic expressing the knowledge of the\nagents in the exchange. We begin by noting that the problem is undecidable in\ngeneral. We then identify two noteworthy restrictions, one syntactical and one\nsemantical, that enable us to find bisimilar finite abstractions and therefore\nreduce the model checking problem to the instance on finite models. Under these\nassumptions we show that the model checking problem for these systems is\nEXPSPACE-complete. We then introduce artifact-centric programs, compact and\ndeclarative representations of the programs governing both the artifact system\nand the agents. We show that, while these in principle generate infinite-state\nsystems, under natural conditions their verification problem can be solved on\nfinite abstractions that can be effectively computed from the programs. Finally\nwe exemplify the theoretical results of the paper through a mainstream\nprocurement scenario from the artifact systems literature.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 11:45:54 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 09:22:30 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Belardinelli", "Francesco", ""], ["Lomuscio", "Alessio", ""], ["Patrizi", "Fabio", ""]]}, {"id": "1301.2683", "submitter": "Josef Urban", "authors": "Josef Urban", "title": "BliStr: The Blind Strategymaker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BliStr is a system that automatically develops strategies for E prover on a\nlarge set of problems. The main idea is to interleave (i) iterated\nlow-timelimit local search for new strategies on small sets of similar easy\nproblems with (ii) higher-timelimit evaluation of the new strategies on all\nproblems. The accumulated results of the global higher-timelimit runs are used\nto define and evolve the notion of \"similar easy problems\", and to control the\nselection of the next strategy to be improved. The technique was used to\nsignificantly strengthen the set of E strategies used by the MaLARea, PS-E,\nE-MaLeS, and E systems in the CASC@Turing 2012 competition, particularly in the\nMizar division. Similar improvement was obtained on the problems created from\nthe Flyspeck corpus.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 13:02:21 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 12:54:41 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Urban", "Josef", ""]]}, {"id": "1301.2763", "submitter": "Satoshi Matsuoka", "authors": "Satoshi Matsuoka", "title": "A New Proof of P-time Completeness of Linear Lambda Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new proof of P-time completeness of Linear Lambda Calculus, which\nwas originally given by H. Mairson in 2003. Our proof uses an essentially\ndifferent Boolean type from the type Mairson used. Moreover the correctness of\nour proof can be machined-checked using an implementation of Standard ML.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2013 10:47:32 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Matsuoka", "Satoshi", ""]]}, {"id": "1301.3127", "submitter": "Frederic Herbreteau", "authors": "Fr\\'ed\\'eric Herbreteau (LaBRI), B. Srivathsan (RWTH), Igor\n  Walukiewicz (LaBRI)", "title": "Lazy abstractions for timed automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the reachability problem for timed automata. A standard solution\nto this problem involves computing a search tree whose nodes are abstractions\nof zones. For efficiency reasons, they are parametrized by the maximal lower\nand upper bounds (LU-bounds) occurring in the guards of the automaton. We\npropose an algorithm that is updating LU-bounds during exploration of the\nsearch tree. In order to keep them as small as possible, the bounds are refined\nonly when they enable a transition that is impossible in the unabstracted\nsystem. So our algorithm can be seen as a kind of lazy CEGAR algorithm for\ntimed automata. We show that on several standard benchmarks, the algorithm is\ncapable of keeping very small LU-bounds, and in consequence reduce the search\nspace substantially.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 20:56:20 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 07:42:48 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Herbreteau", "Fr\u00e9d\u00e9ric", "", "LaBRI"], ["Srivathsan", "B.", "", "RWTH"], ["Walukiewicz", "Igor", "", "LaBRI"]]}, {"id": "1301.3189", "submitter": "Cl\\'ement Aubert", "authors": "Cl\\'ement Aubert and Thomas Seiller", "title": "Logarithmic Space and Permutations", "comments": null, "journal-ref": "Information and Computation, Volume 248: 2-21 (2016)", "doi": "10.1016/j.ic.2014.01.018", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a recent work, Girard proposed a new and innovative approach to\ncomputational complexity based on the proofs-as-programs correspondence. In a\nprevious paper, the authors showed how Girard proposal succeeds in obtaining a\nnew characterization of co-NL languages as a set of operators acting on a\nHilbert Space. In this paper, we extend this work by showing that it is also\npossible to define a set of operators characterizing the class L of logarithmic\nspace languages.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 00:31:00 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2013 18:53:39 GMT"}, {"version": "v3", "created": "Mon, 16 Feb 2015 08:31:28 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 14:13:01 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Aubert", "Cl\u00e9ment", ""], ["Seiller", "Thomas", ""]]}, {"id": "1301.3297", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Instruction sequence based non-uniform complexity classes", "comments": "33 pages, supersedes arXiv:0809.0352 [cs.CC] in many respects (see\n  end of introduction); remarks added", "journal-ref": "Scientific Annals of Computer Science 24(1):47--89, 2014", "doi": "10.7561/SACS.2014.1.47", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to non-uniform complexity in which single-pass\ninstruction sequences play a key part, and answer various questions that arise\nfrom this approach. We introduce several kinds of non-uniform complexity\nclasses. One kind includes a counterpart of the well-known non-uniform\ncomplexity class P/poly and another kind includes a counterpart of the\nwell-known non-uniform complexity class NP/poly. Moreover, we introduce a\ngeneral notion of completeness for the non-uniform complexity classes of the\nlatter kind. We also formulate a counterpart of the well-known complexity\ntheoretic conjecture that NP is not included in P/poly. We think that the\npresented approach opens up an additional way of investigating issues\nconcerning non-uniform complexity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 10:32:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2013 11:52:23 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1301.3299", "submitter": "Wanwei Liu", "authors": "Wanwei Liu and Rui Wang and Xianjin Fu and Ji Wang and Wei Dong and\n  Xiaoguang Mao", "title": "Counterexample-Preserving Reduction for Symbolic Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost of LTL model checking is highly sensitive to the length of the\nformula under verification. We observe that, under some specific conditions,\nthe input LTL formula can be reduced to an easier-to-handle one before model\nchecking. In our reduction, these two formulae need not to be logically\nequivalent, but they share the same counterexample set w.r.t the model. In the\ncase that the model is symbolically represented, the condition enabling such\nreduction can be detected with a lightweight effort (e.g., with SAT-solving).\nIn this paper, we tentatively name such technique \"Counterexample-Preserving\nReduction\" (CePRe for short), and finally the proposed technquie is\nexperimentally evaluated by adapting NuSMV.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 10:53:51 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Liu", "Wanwei", ""], ["Wang", "Rui", ""], ["Fu", "Xianjin", ""], ["Wang", "Ji", ""], ["Dong", "Wei", ""], ["Mao", "Xiaoguang", ""]]}, {"id": "1301.3350", "submitter": "Yan Zhang", "authors": "Yan Zhang, Zhaohui Zhu, Jinjin Zhang", "title": "On Recursive Operations Over Logic LTS", "comments": "66 pages", "journal-ref": "Math. Struct. Comp. Sci. 25 (2015) 1382-1431", "doi": "10.1017/S0960129514000073", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in order to mix algebraic and logic styles of specification in a\nuniform framework, the notion of a logic labelled transition system (Logic LTS\nor LLTS for short) has been introduced and explored. A variety of constructors\nover LLTS, including usual process-algebraic operators, logic connectives\n(conjunction and disjunction) and standard temporal operators (always and\nunless), have been given. However, no attempt has made so far to develop\ngeneral theory concerning (nested) recursive operations over LLTSs and a few\nfundamental problems are still open. This paper intends to study this issue in\npure process-algebraic style. A few fundamental properties, including\nprecongruence and the uniqueness of consistent solutions for equations, will be\nestablished.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 14:08:54 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 02:42:03 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2013 06:03:38 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Zhang", "Yan", ""], ["Zhu", "Zhaohui", ""], ["Zhang", "Jinjin", ""]]}, {"id": "1301.3393", "submitter": "Jamie Vicary", "authors": "Mike Stay and Jamie Vicary", "title": "Bicategorical Semantics for Nondeterministic Computation", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a bicategorical syntax for the interaction between public and\nprivate information in classical information theory. We use this to give\nhigh-level graphical definitions of encrypted communication and secret sharing\nprotocols, including a characterization of their security properties.\nRemarkably, this makes it clear that the protocols have an identical abstract\nform to the quantum teleportation and dense coding procedures, yielding\nevidence of a deep connection between classical and quantum information\nprocessing. We also formulate public-key cryptography using our scheme.\nSpecific implementations of these protocols as nondeterministic classical\nprocedures are recovered by applying our formalism in a symmetric monoidal\nbicategory of matrices of relations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 16:09:06 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Stay", "Mike", ""], ["Vicary", "Jamie", ""]]}, {"id": "1301.4372", "submitter": "Alejandro Sanchez", "authors": "C\\'esar S\\'anchez and Alejandro S\\'anchez", "title": "A Decidable Theory of Skiplists of Unbounded Size and Arbitrary Height", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a theory of skiplists of arbitrary height, and shows\ndecidability of the satisfiability problem for quantifier-free formulas.\n  A skiplist is an imperative software data structure that implements sets by\nmaintaining several levels of ordered singly-linked lists in memory, where each\nlevel is a sublist of its lower levels. Skiplists are widely used in practice\nbecause they offer a performance comparable to balanced binary trees, and can\nbe implemented more efficiently. To achieve this performance, most\nimplementations dynamically increment the height (the number of levels).\nSkiplists are difficult to reason about because of the dynamic size (number of\nnodes) and the sharing between the different layers. Furthermore, reasoning\nabout dynamic height adds the challenge of dealing with arbitrary many levels.\n  The first contribution of this paper is the theory TSL that allows to express\nthe heap memory layout of a skiplist of arbitrary height. The second\ncontribution is a decision procedure for the satisfiability prob- lem of\nquantifier-free TSL formulas. The last contribution is to illustrate the formal\nverification of a practical skiplist implementation using this decision\nprocedure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 13:08:00 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["S\u00e1nchez", "C\u00e9sar", ""], ["S\u00e1nchez", "Alejandro", ""]]}, {"id": "1301.4816", "submitter": "Oriol Valent\\'in", "authors": "Oriol Valent\\'in", "title": "The Hidden Structural Rules of the Discontinuous Lambek Calculus", "comments": "Submitted to Lambek Festschrift volume", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequent calculus sL for the Lambek calculus L (lambek 58) has no\nstructural rules. Interestingly, sL is equivalent to a multimodal calculus mL,\nwhich consists of the nonassociative Lambek calculus with the structural rule\nof associativity. This paper proves that the sequent calculus or hypersequent\ncalculus hD of the discontinuous Lambek calculus (Morrill and Valent\\'in),\nwhich like sL has no structural rules, is also equivalent to an omega-sorted\nmultimodal calculus mD. More concretely, we present a faithful embedding\ntranslation between mD and hD in such a way that it can be said that hD absorbs\nthe structural rules of mD.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 11:02:29 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2013 08:23:37 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Valent\u00edn", "Oriol", ""]]}, {"id": "1301.4845", "submitter": "Julian Hedges", "authors": "Julian Hedges", "title": "A generalisation of Nash's theorem with higher-order functionals", "comments": null, "journal-ref": null, "doi": "10.1098/rspa.2013.0041", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent theory of sequential games and selection functions by Mar- tin\nEscardo and Paulo Oliva is extended to games in which players move\nsimultaneously. The Nash existence theorem for mixed-strategy equilibria of\nfinite games is generalised to games defined by selection functions. A normal\nform construction is given which generalises the game-theoretic normal form,\nand its soundness is proven. Minimax strategies also gener- alise to the new\nclass of games and are computed by the Berardi-Bezem- Coquand functional,\nstudied in proof theory as an interpretation of the axiom of countable choice.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 12:40:33 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Hedges", "Julian", ""]]}, {"id": "1301.4874", "submitter": "leroux J", "authors": "J\\'er\\^ome Leroux (LABRI, CNRS)", "title": "Vector Addition System Reversible Reachability Problem", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 1 (February\n  27, 2013) lmcs:881", "doi": "10.2168/LMCS-9(1:5)2013", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reachability problem for vector addition systems is a central problem of\nnet theory. This problem is known to be decidable but the complexity is still\nunknown. Whereas the problem is EXPSPACE-hard, no elementary upper bounds\ncomplexity are known. In this paper we consider the reversible reachability\nproblem. This problem consists to decide if two configurations are reachable\none from each other, or equivalently if they are in the same strongly connected\ncomponent of the reachability graph. We show that this problem is\nEXPSPACE-complete. As an application of the introduced materials we\ncharacterize the reversibility domains of a vector addition system.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 14:25:00 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2013 12:12:03 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Leroux", "J\u00e9r\u00f4me", "", "LABRI, CNRS"]]}, {"id": "1301.4910", "submitter": "M\\'ario S. Alvim", "authors": "M\\'ario S. Alvim", "title": "Computational Aspects of the Calculus of Structure", "comments": "Thesis presented by M\\'ario S. Alvim as part of the requirements for\n  the degree or Master of Science in Computer Science granted by the\n  Universidade Federal de Minas Gerais. April, 04th, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic is the science of correct inferences and a logical system is a tool to\nprove assertions in a certain logic in a correct way. There are many logical\nsystems, and many ways of formalizing them, e.g., using natural deduction or\nsequent calculus. Calculus of structures (CoS) is a new formalism proposed by\nAlessio Guglielmi in 2004 that generalizes sequent calculus in the sense that\ninference rules can be applied at any depth inside a formula, rather than only\nto the main connective. With this feature, proofs in CoS are shorter than in\nany other formalism supporting analytical proofs. Although it is great to have\nthe freedom and expressiveness of CoS, under the point of view of proof search\nmore freedom means a larger search space. And that should be restricted when\nlooking for complete automation of deductive systems. Some efforts were made to\nreduce this non-determinism, but they are all basically operational approaches,\nand no solid theoretical result regarding the computational behaviour of CoS\nhas been achieved so far. The main focus of this thesis is to discuss ways to\npropose a proof search strategy for CoS suitable to implementation. This\nstrategy should be theoretical instead of purely operational. We introduce the\nconcept of incoherence number of substructures inside structures and we use\nthis concept to achieve our main result: there is an algorithm that, according\nto our conjecture, corresponds to a proof search strategy to every provable\nstructure in the subsystem of FBV (the multiplicative linear logic MLL plus the\nrule mix) containing only pairwise distinct atoms. Our algorithm is implemented\nand we believe our strategy is a good starting point to exploit the\ncomputational aspects of CoS in more general systems, like BV itself.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 16:19:00 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Alvim", "M\u00e1rio S.", ""]]}, {"id": "1301.4938", "submitter": "Christian Retore", "authors": "Christian Retor\\'e (LaBRI, IRIT)", "title": "A type theoretical framework for natural language semantics: the\n  Montagovian generative lexicon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework, named the Montagovian generative lexicon, for\ncomputing the semantics of natural language sentences, expressed in many sorted\nhigher order logic. Word meaning is depicted by lambda terms of second order\nlambda calculus (Girard's system F) with base types including a type for\npropositions and many types for sorts of a many sorted logic. This framework is\nable to integrate a proper treatment of lexical phenomena into a Montagovian\ncompositional semantics, including the restriction of selection which imposes\nthe nature of the arguments of a predicate, and the possible adaptation of a\nword meaning to some contexts. Among these adaptations of a word's sense to the\ncontext, ontological inclusions are handled by an extension of system F with\ncoercive subtyping that is introduced in the present paper. The benefits of\nthis framework for lexical pragmatics are illustrated on meaning transfers and\ncoercions, on possible and impossible copredication over different senses, on\ndeverbal ambiguities, and on \"fictive motion\". Next we show that the\ncompositional treatment of determiners, quantifiers, plurals,... are finer\ngrained in our framework. We then conclude with the linguistic, logical and\ncomputational perspectives opened by the Montagovian generative lexicon.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 17:42:19 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2014 23:58:30 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2014 15:43:25 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Retor\u00e9", "Christian", "", "LaBRI, IRIT"]]}, {"id": "1301.4973", "submitter": "Philipp Ruemmer", "authors": "Philipp R\\\"ummer (Uppsala University), Hossein Hojjat (EPFL Lausanne),\n  Viktor Kuncak (EPFL Lausanne)", "title": "Disjunctive Interpolants for Horn-Clause Verification (Extended\n  Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in software verification is efficient and precise\ncompositional analysis of programs with procedures and loops. Interpolation\nmethods remain one of the most promising techniques for such verification, and\nare closely related to solving Horn clause constraints. We introduce a new\nnotion of interpolation, disjunctive interpolation, which solve a more general\nclass of problems in one step compared to previous notions of interpolants,\nsuch as tree interpolants or inductive sequences of interpolants. We present\nalgorithms and complexity for construction of disjunctive interpolants, as well\nas their use within an abstraction-refinement loop. We have implemented Horn\nclause verification algorithms that use disjunctive interpolants and evaluate\nthem on benchmarks expressed as Horn clauses over the theory of integer linear\narithmetic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 20:13:32 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["R\u00fcmmer", "Philipp", "", "Uppsala University"], ["Hojjat", "Hossein", "", "EPFL Lausanne"], ["Kuncak", "Viktor", "", "EPFL Lausanne"]]}, {"id": "1301.5089", "submitter": "Danko Ilik", "authors": "Danko Ilik", "title": "An interpretation of the Sigma-2 fragment of classical Analysis in\n  System T", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is possible to define a realizability interpretation for the\n$\\Sigma_2$-fragment of classical Analysis using G\\\"odel's System T only. This\nsupplements a previous result of Schwichtenberg regarding bar recursion at\ntypes 0 and 1 by showing how to avoid using bar recursion altogether. Our\nresult is proved via a conservative extension of System T with an operator for\ncomposable continuations from the theory of programming languages due to Danvy\nand Filinski. The fragment of Analysis is therefore essentially constructive,\neven in presence of the full Axiom of Choice schema: Weak Church's Rule holds\nof it in spite of the fact that it is strong enough to refute the formal\narithmetical version of Church's Thesis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 07:15:00 GMT"}, {"version": "v2", "created": "Mon, 8 Dec 2014 15:12:22 GMT"}, {"version": "v3", "created": "Thu, 29 Jan 2015 10:35:28 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Ilik", "Danko", ""]]}, {"id": "1301.5139", "submitter": "Radu Iosif", "authors": "Radu Iosif and Adam Rogalewicz and Jiri Simacek", "title": "The Tree Width of Separation Logic with Recursive Definitions", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation Logic is a widely used formalism for describing dynamically\nallocated linked data structures, such as lists, trees, etc. The decidability\nstatus of various fragments of the logic constitutes a long standing open\nproblem. Current results report on techniques to decide satisfiability and\nvalidity of entailments for Separation Logic(s) over lists (possibly with\ndata). In this paper we establish a more general decidability result. We prove\nthat any Separation Logic formula using rather general recursively defined\npredicates is decidable for satisfiability, and moreover, entailments between\nsuch formulae are decidable for validity. These predicates are general enough\nto define (doubly-) linked lists, trees, and structures more general than\ntrees, such as trees whose leaves are chained in a list. The decidability\nproofs are by reduction to decidability of Monadic Second Order Logic on graphs\nwith bounded tree width.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 11:05:35 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2013 16:07:27 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Iosif", "Radu", ""], ["Rogalewicz", "Adam", ""], ["Simacek", "Jiri", ""]]}, {"id": "1301.5154", "submitter": "Radhakrishnan Delhibabu", "authors": "Radhakrishnan Delhibabu, Gerhard Lakemeyer", "title": "A Rational and Efficient Algorithm for View Revision in Databases", "comments": null, "journal-ref": "Applied Mathematics & Information Sciences, Volume 7, No. 3\n  (2013), PP:843-856", "doi": "10.12785/amis/070302", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of belief and knowledge is one of the major components of any\nautonomous system that should be able to incorporate new pieces of information.\nIn this paper, we argue that to apply rationality result of belief dynamics\ntheory to various practical problems, it should be generalized in two respects:\nfirst of all, it should allow a certain part of belief to be declared as\nimmutable; and second, the belief state need not be deductively closed. Such a\ngeneralization of belief dynamics, referred to as base dynamics, is presented,\nalong with the concept of a generalized revision algorithm for Horn knowledge\nbases. We show that Horn knowledge base dynamics has interesting connection\nwith kernel change and abduction. Finally, we also show that both variants are\nrational in the sense that they satisfy certain rationality postulates stemming\nfrom philosophical works on belief dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 11:30:37 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Delhibabu", "Radhakrishnan", ""], ["Lakemeyer", "Gerhard", ""]]}, {"id": "1301.5197", "submitter": "Fr\\'ed\\'eric Servais", "authors": "Emmanuel Filiot and Olivier Gauwin and Pierre-Alain Reynier and\n  Fr\\'ed\\'eric Servais", "title": "From Two-Way to One-Way Finite State Transducers", "comments": "18 pages, published in LICS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any two-way finite state automaton is equivalent to some one-way finite state\nautomaton. This well-known result, shown by Rabin and Scott and independently\nby Shepherdson, states that two-way finite state automata (even\nnon-deterministic) characterize the class of regular languages. It is also\nknown that this result does not extend to finite string transductions:\n(deterministic) two-way finite state transducers strictly extend the expressive\npower of (functional) one-way transducers. In particular deterministic two-way\ntransducers capture exactly the class of MSO-transductions of finite strings.\nIn this paper, we address the following definability problem: given a function\ndefined by a two-way finite state transducer, is it definable by a one-way\nfinite state transducer? By extending Rabin and Scott's proof to transductions,\nwe show that this problem is decidable. Our procedure builds a one-way\ntransducer, which is equivalent to the two-way transducer, whenever one exists.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 14:43:15 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 12:04:37 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Filiot", "Emmanuel", ""], ["Gauwin", "Olivier", ""], ["Reynier", "Pierre-Alain", ""], ["Servais", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1301.5304", "submitter": "Christian Retore", "authors": "Michele Abrusci, Christian Retor\\'e (LaBRI, IRIT)", "title": "Some proof theoretical remarks on quantification in ordinary language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the common approach to quantification and generalised\nquantification in formal linguistics and philosophy of language. We point out\nhow this general setting departs from empirical linguistic data, and give some\nhints for a different view based on proof theory, which on many aspects gets\ncloser to the language itself. We stress the importance of Hilbert's oper- ator\nepsilon and tau for, respectively, existential and universal quantifications.\nIndeed, these operators help a lot to construct semantic representation close\nto natural language, in particular with quantified noun phrases as individual\nterms. We also define guidelines for the design of the proof rules\ncorresponding to generalised quantifiers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 20:22:20 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Abrusci", "Michele", "", "LaBRI, IRIT"], ["Retor\u00e9", "Christian", "", "LaBRI, IRIT"]]}, {"id": "1301.5500", "submitter": "Sylvain Schmitz", "authors": "Christoph Haase (CNRS & ENS Cachan), Sylvain Schmitz (ENS Cachan &\n  INRIA), Philippe Schnoebelen (CNRS & ENS Cachan)", "title": "The Power of Priority Channel Systems", "comments": "Extended version of an article presented at CONCUR 2013, LNCS 8052,\n  pp. 319--333, Springer, doi:10.1007/978-3-642-40184-8_23", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  3, 2014) lmcs:1049", "doi": "10.2168/LMCS-10(4:4)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Priority Channel Systems, a new class of channel systems where\nmessages carry a numeric priority and where higher-priority messages can\nsupersede lower-priority messages preceding them in the fifo communication\nbuffers. The decidability of safety and inevitability properties is shown via\nthe introduction of a priority embedding, a well-quasi-ordering that has not\npreviously been used in well-structured systems. We then show how Priority\nChannel Systems can compute Fast-Growing functions and prove that the\naforementioned verification problems are\n$\\mathbf{F}_{\\varepsilon_{0}}$-complete.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 13:46:20 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 20:16:46 GMT"}, {"version": "v3", "created": "Tue, 8 Apr 2014 07:30:56 GMT"}, {"version": "v4", "created": "Sat, 6 Sep 2014 14:10:38 GMT"}, {"version": "v5", "created": "Tue, 2 Dec 2014 09:13:22 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Haase", "Christoph", "", "CNRS & ENS Cachan"], ["Schmitz", "Sylvain", "", "ENS Cachan &\n  INRIA"], ["Schnoebelen", "Philippe", "", "CNRS & ENS Cachan"]]}, {"id": "1301.5588", "submitter": "Matthew Moore", "authors": "Matthew Moore", "title": "The Undecidability of the Definability of Principal Subcongruences", "comments": null, "journal-ref": "The Journal of Symbolic Logic. 80 (2015), no. 2, 384--432", "doi": "10.1017/jsl.2014.51", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For each Turing machine T, we construct an algebra A'(T) such that the\nvariety generated by A'(T) has definable principal subcongruences if and only\nif T halts, thus proving that the property of having definable principal\nsubcongruences is undecidable for a finite algebra. A consequence of this is\nthat there is no algorithm that takes as input a finite algebra a decides\nwhether that algebra is finitely based.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 13:33:53 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2013 20:40:41 GMT"}, {"version": "v3", "created": "Thu, 24 Jul 2014 20:29:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Moore", "Matthew", ""]]}, {"id": "1301.6039", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya", "title": "Recycling Proof Patterns in Coq: Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of Interactive Theorem Provers has led to the creation of big\nlibraries and varied infrastructures for formal proofs. However, despite (or\nperhaps due to) their sophistication, the re-use of libraries by non-experts or\nacross domains is a challenge. In this paper, we provide detailed case studies\nand evaluate the machine-learning tool ML4PG built to interactively data-mine\nthe electronic libraries of proofs, and to provide user guidance on the basis\nof proof patterns found in the existing libraries.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 13:29:29 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2013 14:04:45 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 10:39:54 GMT"}, {"version": "v4", "created": "Fri, 7 Mar 2014 12:30:49 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1301.6431", "submitter": "Panagiotis Kouvaros", "authors": "Panagiotis Kouvaros, Alessio Lomuscio", "title": "Automatic Verification of Parameterised Interleaved Multi-Agent Systems", "comments": "8 pages with 1 figure; Published in the Proceedings of the 12th\n  International Conference on Autonomous Agents and Multi-Agent systems\n  (AAMAS13). Saint Paul, MN, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in verification of multi-agent systems by model checking\nconcerns the fact that the state-space of the system grows exponentially with\nthe number of agents present. This makes practical model checking unfeasible\nwhenever the system contains more than a few agents. In this paper we put\nforward a technique to establish a cutoff result, thereby showing that all\nsystems of arbitrary number of agents can be verified by model checking a\nsingle system containing a number of agents equal to the cutoff of the system.\nWhile this problem is undecidable in general, we here define a class of\nparameterised interpreted systems and a parameterised temporal-epistemic logic\nfor which the result can be shown. We exemplify the theoretical results on a\nrobotic example and present an implementation of the technique on top of mcmas,\nan open-source model checker for multi-agent systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 02:57:35 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 16:36:55 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Kouvaros", "Panagiotis", ""], ["Lomuscio", "Alessio", ""]]}, {"id": "1301.6572", "submitter": "Gilles Geeraerts", "authors": "Gilles Geeraerts and Alexander Heu{\\ss}ner and M. Praveen and\n  Jean-Fran\\c{c}ois Raskin", "title": "{\\omega}-Petri nets", "comments": "37 pages, 6 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce {\\omega}-Petri nets ({\\omega}PN), an extension of plain Petri\nnets with {\\omega}-labeled input and output arcs, that is well-suited to\nanalyse parametric concurrent systems with dynamic thread creation. Most\ntechniques (such as the Karp and Miller tree or the Rackoff technique) that\nhave been proposed in the setting of plain Petri nets do not apply directly to\n{\\omega}PN because {\\omega}PN define transition systems that have infinite\nbranching. This motivates a thorough analysis of the computational aspects of\n{\\omega}PN. We show that an {\\omega}PN can be turned into an plain Petri net\nthat allows to recover the reachability set of the {\\omega}PN, but that does\nnot preserve termination. This yields complexity bounds for the reachability,\n(place) boundedness and coverability problems on {\\omega}PN. We provide a\npractical algorithm to compute a coverability set of the {\\omega}PN and to\ndecide termination by adapting the classical Karp and Miller tree construction.\nWe also adapt the Rackoff technique to {\\omega}PN, to obtain the exact\ncomplexity of the termination problem. Finally, we consider the extension of\n{\\omega}PN with reset and transfer arcs, and show how this extension impacts\nthe decidability and complexity of the aforementioned problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 15:14:42 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Geeraerts", "Gilles", ""], ["Heu\u00dfner", "Alexander", ""], ["Praveen", "M.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1301.6698", "submitter": "Dan Geiger", "authors": "Dan Geiger, Christopher Meek", "title": "Quantifier Elimination for Statistical Problems", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-226-235", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent improvement on Tarski's procedure for quantifier elimination in the\nfirst order theory of real numbers makes it feasible to solve small instances\nof the following problems completely automatically: 1. listing all equality and\ninequality constraints implied by a graphical model with hidden variables. 2.\nComparing graphyical models with hidden variables (i.e., model equivalence,\ninclusion, and overlap). 3. Answering questions about the identification of a\nmodel or portion of a model, and about bounds on quantities derived from a\nmodel. 4. Determing whether a given set of independence assertions. We discuss\nthe foundation of quantifier elimination and demonstrate its application to\nthese problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Geiger", "Dan", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.6743", "submitter": "Leendert van der Torre", "authors": "Leendert van der Torre, Yao-Hua Tan", "title": "An Update Semantics for Defeasible Obligations", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-631-638", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deontic logic DUS is a Deontic Update Semantics for prescriptive\nobligations based on the update semantics of Veltman. In DUS the definition of\nlogical validity of obligations is not based on static truth values but on\ndynamic action transitions. In this paper prescriptive defeasible obligations\nare formalized in update semantics and the diagnostic problem of defeasible\ndeontic logic is discussed. Assume a defeasible obligation `normally A ought to\nbe (done)' together withthe fact `A is not (done).' Is this an exception of the\nnormality claim, or is it a violation of the obligation? In this paper we\nformalize the heuristic principle that it is a violation, unless there is a\nmore specific overriding obligation. The underlying motivation from legal\nreasoning is that criminals should have as little opportunities as possible to\nexcuse themselves by claiming that their behavior was exceptional rather than\ncriminal.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["van der Torre", "Leendert", ""], ["Tan", "Yao-Hua", ""]]}, {"id": "1301.6905", "submitter": "Robert Kowalski", "authors": "Robert Kowalski, Fariba Sadri", "title": "Towards a Logic-Based Unifying Framework for Computing", "comments": "An improved version of this paper will be published in the journal,\n  New Generation Computing, with the title \"Reactive Computing as Model\n  Generation\". In the meanwhile, a copy of the revised paper can be found on\n  http://www.doc.ic.ac.uk/~rak/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a logic-based, framework inspired by artificial\nintelligence, but scaled down for practical database and programming\napplications. Computation in the framework is viewed as the task of generating\na sequence of state transitions, with the purpose of making an agent's goals\nall true. States are represented by sets of atomic sentences (or facts),\nrepresenting the values of program variables, tuples in a coordination\nlanguage, facts in relational databases, or Herbrand models.\n  In the model-theoretic semantics, the entire sequence of states and events\nare combined into a single model-theoretic structure, by associating timestamps\nwith facts and events. But in the operational semantics, facts are updated\ndestructively, without timestamps. We show that the model generated by\ndestructive updates is identical to the model generated by reasoning with facts\ncontaining timestamps. We also extend the model with intentional predicates and\ncomposite event predicates defined by logic programs containing conditions in\nfirst-order logic, which query the current state.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 12:23:26 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 07:25:29 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Kowalski", "Robert", ""], ["Sadri", "Fariba", ""]]}, {"id": "1301.7112", "submitter": "Egor Ianovski", "authors": "Egor Ianovski", "title": "Computable Component-wise Reducibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider equivalence relations and preorders complete for various levels\nof the arithmetical hierarchy under computable, component-wise reducibility. We\nshow that implication in first order logic is a complete preorder for $\\SI 1$,\nthe $\\le^P_m$ relation on EXPTIME sets for $\\SI 2$ and the embeddability of\ncomputable subgroups of $(\\QQ,+)$ for $\\SI 3$. In all cases, the symmetric\nfragment of the preorder is complete for equivalence relations on the same\nlevel. We present a characterisation of $\\PI 1$ equivalence relations which\nallows us to establish that equality of polynomial time functions and inclusion\nof polynomial time sets are complete for $\\PI 1$ equivalence relations and\npreorders respectively. We also show that this is the limit of the enquiry: for\n$n\\geq 2$ there are no $\\PI n$ nor $\\DE n$-complete equivalence relations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 00:42:49 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Ianovski", "Egor", ""]]}, {"id": "1301.7321", "submitter": "Johannes Kloos", "authors": "Johannes Kloos, Rupak Majumdar, Filip Niksic and Ruzica Piskac", "title": "Incremental, Inductive Coverability", "comments": "Non-reviewed version, original version submitted to CAV 2013; this is\n  a revised version, containing more experimental results and some corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an incremental, inductive (IC3) procedure to check coverability of\nwell-structured transition systems. Our procedure generalizes the IC3 procedure\nfor safety verification that has been successfully applied in finite-state\nhardware verification to infinite-state well-structured transition systems. We\nshow that our procedure is sound, complete, and terminating for downward-finite\nwell-structured transition systems---where each state has a finite number of\nstates below it---a class that contains extensions of Petri nets, broadcast\nprotocols, and lossy channel systems.\n  We have implemented our algorithm for checking coverability of Petri nets. We\ndescribe how the algorithm can be efficiently implemented without the use of\nSMT solvers. Our experiments on standard Petri net benchmarks show that IC3 is\ncompetitive with state-of-the-art implementations for coverability based on\nsymbolic backward analysis or expand-enlarge-and-check algorithms both in time\ntaken and space usage.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 18:37:03 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 16:25:09 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Kloos", "Johannes", ""], ["Majumdar", "Rupak", ""], ["Niksic", "Filip", ""], ["Piskac", "Ruzica", ""]]}, {"id": "1301.7462", "submitter": "Christine Rizkallah", "authors": "Eyad Alkassar and Sascha B\\\"ohme and Kurt Mehlhorn and Christine\n  Rizkallah", "title": "A Framework for the Verification of Certifying Computations", "comments": "A preliminary version appeared under the title \"Verification of\n  Certifying Computations\" in CAV 2011, LCNS Vol 6806, pages 67 - 82. This\n  paper is currently under review in the Journal of Automated Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification of complex algorithms is challenging. Verifying their\nimplementations goes beyond the state of the art of current automatic\nverification tools and usually involves intricate mathematical theorems.\nCertifying algorithms compute in addition to each output a witness certifying\nthat the output is correct. A checker for such a witness is usually much\nsimpler than the original algorithm - yet it is all the user has to trust. The\nverification of checkers is feasible with current tools and leads to\ncomputations that can be completely trusted. We describe a framework to\nseamlessly verify certifying computations. We use the automatic verifier VCC\nfor establishing the correctness of the checker and the interactive theorem\nprover Isabelle/HOL for high-level mathematical properties of algorithms. We\ndemonstrate the effectiveness of our approach by presenting the verification of\ntypical examples of the industrial-level and widespread algorithmic library\nLEDA.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 23:02:36 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Alkassar", "Eyad", ""], ["B\u00f6hme", "Sascha", ""], ["Mehlhorn", "Kurt", ""], ["Rizkallah", "Christine", ""]]}, {"id": "1301.7465", "submitter": "Ron Peretz", "authors": "Ron Peretz", "title": "Effective Martingales with Restricted Wagers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic model of computable randomness considers martingales that take\nreal or rational values. Recent work by Bienvenu et al. (2012) and Teutsch\n(2014) shows that fundamental features of the classic model change when the\nmartingales take integer values.\n  We compare the prediction power of martingales whose wagers belong to three\ndifferent subsets of rational numbers: (a) all rational numbers, (b) rational\nnumbers excluding a punctured neighbourhood of 0, and (c) integers. We also\nconsider three different success criteria: (i) accumulating an infinite amount\nof money, (ii) consuming an infinite amount of money, and (iii) making the\naccumulated capital oscillate.\n  The nine combinations of (a)--(c) and (i)--(iii) define nine notions of\ncomputable randomness. We provide a complete characterization of the relations\nbetween these notions, and show that they form five linearly ordered classes.\n  Our results solve outstanding questions raised in Bienvenu et al. (2012),\nTeutsch (2014), and Chalcraft et al. (2012), and strengthen existing results.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 23:12:45 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2013 17:01:32 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2015 16:13:56 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Peretz", "Ron", ""]]}, {"id": "1301.7521", "submitter": "Ahmet Husainov A.", "authors": "Ahmet A. Husainov, E.S. Bushmeleva, T.A. Trishina", "title": "Homology Groups of Pipeline Petri Nets", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.AT", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study homology groups of elementary Petri nets for the pipeline systems.\nWe show that the integral homology groups of these nets in dimensions 0 and 1\nequal the group of integers, and they are zero in other dimensions. We prove\nthat directed homology groups of elementary Petri nets are zero in all\ndimensions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 06:23:16 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 10:25:22 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2013 23:57:17 GMT"}, {"version": "v4", "created": "Fri, 1 Mar 2013 08:03:17 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Husainov", "Ahmet A.", ""], ["Bushmeleva", "E. S.", ""], ["Trishina", "T. A.", ""]]}, {"id": "1301.7531", "submitter": "Silvano Dal Zilio", "authors": "Nouha Abid (LAAS), Silvano Dal Zilio (LAAS), Didier Le Botlan (LAAS)", "title": "A Verified Approach for Checking Real-Time Specification Patterns", "comments": "An extended version of this paper appears as Research Report LAAS No.\n  11365, June 2011. VECoS 2012, 6th International Workshop on Verification and\n  Evaluation of Computer and Communication Systems, France (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a verified approach to the formal verification of timed properties\nusing model-checking techniques. We focus on properties expressed using\nreal-time specification patterns, which can be viewed as a subset of timed\ntemporal logics that includes properties commonly found during the analysis of\nreactive systems. Our model-checking approach is based on the use of observers\nin order to transform the verification of timed patterns into the verification\nof simpler LTL formulas. While the use of observers for model-checking is quite\ncommon, our contribution is original in several ways. First, we define a formal\nframework to verify that our observers are correct and non-intrusive. Second,\nwe define different classes of observers for each pattern and use a pragmatic\napproach in order to select the most efficient candidate in practice. This\napproach is implemented in an integrated verification tool chain for the Fiacre\nlanguage.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 07:50:52 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Abid", "Nouha", "", "LAAS"], ["Zilio", "Silvano Dal", "", "LAAS"], ["Botlan", "Didier Le", "", "LAAS"]]}, {"id": "1301.7533", "submitter": "Silvano Dal Zilio", "authors": "Rodrigo Tacla Saad (LAAS), Silvano Dal Zilio (LAAS), Bernard\n  Berthomieu (LAAS)", "title": "An Experiment on Parallel Model Checking of a CTL Fragment", "comments": "10th International Symposium, ATVA 2012, Automated Technology for\n  Verification and Analysis, Thiruvananthapuram : India (2012)", "journal-ref": null, "doi": "10.1007/978-3-642-33386-6_23", "report-no": "Rapport LAAS n&deg; 12400", "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a parallel algorithm for local, on the fly, model checking of a\nfragment of CTL that is well-suited for modern, multi-core architectures. This\nmodel-checking algorithm takes bene t from a parallel state space construction\nalgorithm, which we described in a previous work, and shares the same basic set\nof principles: there are no assumptions on the models that can be analyzed; no\nrestrictions on the way states are distributed; and no restrictions on the way\nwork is shared among processors. We evaluate the performance of diff erent\nversions of our algorithm and compare our results with those obtained using\nother parallel model checking tools. One of the most novel contributions of\nthis work is to study a space-e fficient variant for CTL model-checking that\ndoes not require to store the whole transition graph but that operates on a\nreverse spanning tree.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 07:56:11 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Saad", "Rodrigo Tacla", "", "LAAS"], ["Zilio", "Silvano Dal", "", "LAAS"], ["Berthomieu", "Bernard", "", "LAAS"]]}, {"id": "1301.7676", "submitter": "Nicos Angelopoulos", "authors": "Anthony Monnet and Roger Villemaire", "title": "Efficient Partial Order CDCL Using Assertion Level Choice Heuristics", "comments": "Appeared in CICLOPS 2012. 15 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We previously designed Partial Order Conflict Driven Clause Learning\n(PO-CDCL), a variation of the satisfiability solving CDCL algorithm with a\npartial order on decision levels, and showed that it can speed up the solving\non problems with a high independence between decision levels. In this paper, we\nmore thoroughly analyze the reasons of the efficiency of PO-CDCL. Of particular\nimportance is that the partial order introduces several candidates for the\nassertion level. By evaluating different heuristics for this choice, we show\nthat the assertion level selection has an important impact on solving and that\na carefully designed heuristic can significantly improve performances on\nrelevant benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 16:45:01 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Monnet", "Anthony", ""], ["Villemaire", "Roger", ""]]}, {"id": "1301.7700", "submitter": "Julien Reichert", "authors": "Arjun Arul, Julien Reichert", "title": "The Complexity of Robot Games on the Integer Line", "comments": "In Proceedings QAPL 2013, arXiv:1306.2413", "journal-ref": "EPTCS 117, 2013, pp. 132-148", "doi": "10.4204/EPTCS.117.9", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In robot games on Z, two players add integers to a counter. Each player has a\nfinite set from which he picks the integer to add, and the objective of the\nfirst player is to let the counter reach 0. We present an exponential-time\nalgorithm for deciding the winner of a robot game given the initial counter\nvalue, and prove a matching lower bound.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 17:46:22 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2013 10:30:07 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2013 08:07:51 GMT"}, {"version": "v4", "created": "Fri, 2 Aug 2013 06:40:29 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Arul", "Arjun", ""], ["Reichert", "Julien", ""]]}]