[{"id": "1311.0330", "submitter": "Ver\\'onica  Becher", "authors": "Ver\\'onica Becher and Serge Grigorieff", "title": "Borel and Hausdorff Hierarchies in Topological Spaces of Choquet Games\n  and Their Effectivization", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 25 (2015) 1490-1519", "doi": "10.1017/S096012951300025X", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What parts of classical descriptive set theory done in Polish spaces still\nhold for more general topological spaces, possibly T0 or T1, but not T2 (i.e.\nnot Hausdorff)? This question has been addressed by Victor Selivanov in a\nseries of papers centered on algebraic domains. And recently it has been\nconsidered by Matthew de Brecht for quasi-Polish spaces, a framework that\ncontains both countably based continuous domains and Polish spaces. In this\npaper we present alternative unifying topological spaces, that we call\napproximation spaces. They are exactly the spaces for which player Nonempty has\na stationary strategy in the Choquet game. A natural proper subclass of\napproximation spaces coincides with the class of quasi-Polish spaces. We study\nthe Borel and Hausdorff difference hierarchies in approximation spaces,\nrevisiting the work done for the other topological spaces. We also consider the\nproblem of effectivization of these results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2013 02:44:42 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Becher", "Ver\u00f3nica", ""], ["Grigorieff", "Serge", ""]]}, {"id": "1311.0331", "submitter": "Ver\\'onica  Becher", "authors": "Ver\\'onica Becher and Serge Grigorieff", "title": "Wadge Hardness in Scott Spaces and Its Effectivization", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 25 (2015) 1520-1545", "doi": "10.1017/S0960129513000248", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove some results on the Wadge order on the space of sets of natural\nnumbers endowed with Scott topology, and more generally, on omega-continuous\ndomains. Using alternating decreasing chains we characterize the property of\nWadge hardness for the classes of the Hausdorff difference hierarchy (iterated\ndifferences of open sets). A similar characterization holds for Wadge\none-to-one and finite-to-one completeness. We consider the same questions for\nthe effectivization of the Wadge relation. We also show that for the space of\nsets of natural numbers endowed with the Scott topology, in each class of the\nHausdorff difference hierarchy there are two strictly increasing chains of\nWadge degrees of sets properly in that class. The length of these chains is the\nrank of the considered class, and each element in one chain is incomparable\nwith all the elements in the other chain.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2013 02:50:14 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Becher", "Ver\u00f3nica", ""], ["Grigorieff", "Serge", ""]]}, {"id": "1311.0335", "submitter": "Ver\\'onica  Becher", "authors": "Ver\\'onica Becher and Pablo Ariel Heiber and Theodore A. Slaman", "title": "Normal Numbers and the Borel Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the set of absolutely normal numbers is $\\mathbf\n\\Pi^0_3$-complete in the Borel hierarchy of subsets of real numbers. Similarly,\nthe set of absolutely normal numbers is $\\Pi^0_3$-complete in the effective\nBorel hierarchy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2013 03:32:56 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Becher", "Ver\u00f3nica", ""], ["Heiber", "Pablo Ariel", ""], ["Slaman", "Theodore A.", ""]]}, {"id": "1311.0363", "submitter": "Karim Nour", "authors": "Ren\\'e David and Karim Nour (LAMA - Equipe LIMD - Universit\\'e de\n  Savoie, Le Bourget du Lac)", "title": "About the range property for H", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (January\n  21, 2014) lmcs:849", "doi": "10.2168/LMCS-10(1:3)2014", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, A. Polonsky has shown that the range property fails for H. We give\nhere some conditions on a closed term that imply that its range has an infinite\ncardinality.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2013 10:05:35 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2014 19:26:17 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2014 22:54:41 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["David", "Ren\u00e9", "", "LAMA - Equipe LIMD - Universit\u00e9 de\n  Savoie, Le Bourget du Lac"], ["Nour", "Karim", "", "LAMA - Equipe LIMD - Universit\u00e9 de\n  Savoie, Le Bourget du Lac"]]}, {"id": "1311.0710", "submitter": "Andrew Craig", "authors": "L.M. Cabrer, A.P.K. Craig, H.A. Priestley", "title": "Product representation for default bilattices: an application of natural\n  duality theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilattices (that is, sets with two lattice structures) provide an algebraic\ntool to model simultaneously the validity of, and knowledge about, sentences in\nan appropriate language. In particular, certain bilattices have been used to\nmodel situations in which information is prioritised and so can be viewed\nhierarchically. These default bilattices are not interlaced: the lattice\noperations of one lattice structure do not preserve the order of the other one.\nThe well-known product representation theorem for interlaced bilattices does\nnot extend to bilattices which fail to be interlaced and the lack of a product\nrepresentation has been a handicap to understanding the structure of default\nbilattices. In this paper we study, from an algebraic perspective, a hierarchy\nof varieties of default bilattices, allowing for different levels of default.\nWe develop natural dualities for these varieties and thereby obtain a concrete\nrepresentation for the algebras in each variety. This leads on to a form of\nproduct representation that generalises the product representation as this\napplies to distributive bilattices.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 14:26:47 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Cabrer", "L. M.", ""], ["Craig", "A. P. K.", ""], ["Priestley", "H. A.", ""]]}, {"id": "1311.1029", "submitter": "Pascal Michel", "authors": "Pascal Michel", "title": "Problems in number theory from busy beaver competition", "comments": "35 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  14, 2015) lmcs:1611", "doi": "10.2168/LMCS-11(4:10)2015", "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By introducing the busy beaver competition of Turing machines, in 1962, Rado\ndefined noncomputable functions on positive integers. The study of these\nfunctions and variants leads to many mathematical challenges. This article\ntakes up the following one: How can a small Turing machine manage to produce\nvery big numbers? It provides the following answer: mostly by simulating\nCollatz-like functions, that are generalizations of the famous 3x+1 function.\nThese functions, like the 3x+1 function, lead to new unsolved problems in\nnumber theory.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 12:22:32 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2015 07:00:18 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2015 17:58:24 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Michel", "Pascal", ""]]}, {"id": "1311.1043", "submitter": "Martin Lang", "authors": "Martin Lang (RWTH Aachen University), Christof L\\\"oding (RWTH Aachen\n  University)", "title": "Modeling and Verification of Infinite Systems with Resources", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (December\n  17, 2013) lmcs:1162", "doi": "10.2168/LMCS-9(4:22)2013", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider formal verification of recursive programs with resource\nconsumption. We introduce prefix replacement systems with non-negative integer\ncounters which can be incremented and reset to zero as a formal model for such\nprograms. In these systems, we investigate bounds on the resource consumption\nfor reachability questions. Motivated by this question, we introduce relational\nstructures with resources and a quantitative first-order logic over these\nstructures. We define resource automatic structures as a subclass of these\nstructures and provide an effective method to compute the semantics of the\nlogic on this subclass. Subsequently, we use this framework to solve the\nbounded reachability problem for resource prefix replacement systems. We\nachieve this result by extending the well-known saturation method to annotated\nprefix replacement systems. Finally, we provide a connection to the study of\nthe logic cost-WMSO.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 13:11:54 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2013 00:34:28 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Lang", "Martin", "", "RWTH Aachen University"], ["L\u00f6ding", "Christof", "", "RWTH Aachen\n  University"]]}, {"id": "1311.1395", "submitter": "Alexander Kurz", "authors": "Alexander Kurz (University of Leicester), Daniela Luan Petri\\c{s}an\n  (University of Leicester), Paula Severi (University of Leicester), Fer-Jan de\n  Vries (University of Leicester)", "title": "Nominal Coalgebraic Data Types with Applications to Lambda Calculus", "comments": "52 pages, accepted for publication in LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (December\n  11, 2013) lmcs:865", "doi": "10.2168/LMCS-9(4:20)2013", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate final coalgebras in nominal sets. This allows us to define\ntypes of infinite data with binding for which all constructions automatically\nrespect alpha equivalence. We give applications to the infinitary lambda\ncalculus.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 13:57:02 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 22:07:48 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kurz", "Alexander", "", "University of Leicester"], ["Petri\u015fan", "Daniela Luan", "", "University of Leicester"], ["Severi", "Paula", "", "University of Leicester"], ["de Vries", "Fer-Jan", "", "University of Leicester"]]}, {"id": "1311.1602", "submitter": "Jianwen Li", "authors": "Jianwen Li, Geguang Pu, Lijun Zhang, Yinbo Yao, Moshe Y. Vardi, Jifeng\n  he", "title": "Polsat: A Portfolio LTL Satisfiability Solver", "comments": "11 pages, 1 table, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a portfolio LTL-satisfiability solver, called\nPolsat. To achieve fast satisfiability checking for LTL formulas, the tool\nintegrates four representative LTL solvers: pltl, TRP++, NuSMV, and Aalta. The\nidea of Polsat is to run the component solvers in parallel to get best overall\nperformance; once one of the solvers terminates, it stops all other solvers.\nRemarkably, the Polsat solver utilizes the power of modern multi-core compute\nclusters. The empirical experiments show that Polsat takes advantages of it.\nFurther, Polsat is also a testing plat- form for all LTL solvers.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 08:31:05 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Li", "Jianwen", ""], ["Pu", "Geguang", ""], ["Zhang", "Lijun", ""], ["Yao", "Yinbo", ""], ["Vardi", "Moshe Y.", ""], ["he", "Jifeng", ""]]}, {"id": "1311.1721", "submitter": "Jiri Velebil", "authors": "Jiri Adamek, Lurdes Sousa, Jiri Velebil", "title": "Kan injectivity in order-enriched categories", "comments": "23 pages", "journal-ref": "Math. Struct. Comp. Sci. 25 (2015) 6-45", "doi": "10.1017/S0960129514000024", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous lattices were characterised by Martin Escardo as precisely the\nobjects that are Kan-injective w.r.t. a certain class of morphisms. We study\nKan-injectivity in general categories enriched in posets. For every class H of\nmorphisms we study the subcategory of all objects Kan-injective w.r.t. H and\nall morphisms preserving Kan-extensions. For categories such as Top_0 and Pos\nwe prove that whenever H is a set of morphisms, the above subcategory is\nmonadic, and the monad it creates is a Kock-Zoeberlein monad. However, this\ndoes not generalise to proper classes: we present a class of continuous\nmappings in Top_0 for which Kan-injectivity does not yield a monadic category.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 15:56:20 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Adamek", "Jiri", ""], ["Sousa", "Lurdes", ""], ["Velebil", "Jiri", ""]]}, {"id": "1311.1722", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Davide Sangiorgi, Michele Alberti", "title": "On Coinductive Equivalences for Higher-Order Probabilistic Functional\n  Programs (Long Version)", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study bisimulation and context equivalence in a probabilistic\n$\\lambda$-calculus. The contributions of this paper are threefold. Firstly we\nshow a technique for proving congruence of probabilistic applicative\nbisimilarity. While the technique follows Howe's method, some of the\ntechnicalities are quite different, relying on non-trivial \"disentangling\"\nproperties for sets of real numbers. Secondly we show that, while bisimilarity\nis in general strictly finer than context equivalence, coincidence between the\ntwo relations is attained on pure $\\lambda$-terms. The resulting equality is\nthat induced by Levy-Longo trees, generally accepted as the finest extensional\nequivalence on pure $\\lambda$-terms under a lazy regime. Finally, we derive a\ncoinductive characterisation of context equivalence on the whole probabilistic\nlanguage, via an extension in which terms akin to distributions may appear in\nredex position. Another motivation for the extension is that its operational\nsemantics allows us to experiment with a different congruence technique, namely\nthat of logical bisimilarity.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 15:58:59 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Sangiorgi", "Davide", ""], ["Alberti", "Michele", ""]]}, {"id": "1311.1912", "submitter": "Jesse Alama", "authors": "Jesse Alama", "title": "Complete independence of an axiom system for central translations", "comments": "10 pages. Submitted to Note di Matematica", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed axiom system for Andr\\'e's central translation structures\nis improved upon. First, one of its axioms turns out to be dependent (derivable\nfrom the other axioms). Without this axiom, the axiom system is indeed\nindependent. Second, whereas most of the original independence models were\ninfinite, finite independence models are available. Moreover, the independence\nproof for one of the axioms employed proof-theoretic techniques rather than\nindependence models; for this axiom, too, a finite independence model exists.\nFor every axiom, then, there is a finite independence model. Finally, the axiom\nsystem (without its single dependent axiom) is not only independent, but\ncompletely independent.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 09:34:44 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Alama", "Jesse", ""]]}, {"id": "1311.1915", "submitter": "Jesse Alama", "authors": "Jesse Alama", "title": "Sentence complexity of theorems in Mizar", "comments": "11 pages. Submitted to the Journal of Automated Reasoning special\n  issue on the 40th anniversary of the Mizar system", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the longest-running computer-assisted formal mathematics projects,\nlarge tracts of mathematical knowledge have been formalized with the help of\nthe Mizar system. Because Mizar is based on first-order classical logic and set\ntheory, and because of its emphasis on pure mathematics, the Mizar library\noffers a cornucopia for the researcher interested in foundations of\nmathematics. With Mizar, one can adopt an experimental approach and take on\nproblems in foundations, at least those which are amenable to such\nexperimentation. Addressing a question posed by H. Friedman, we use Mizar to\ntake on the question of surveying the sentence complexity (measured by\nquantifier alternation) of mathematical theorems. We find, as Friedman\nsuggests, that the sentence complexity of most Mizar theorems is universal\n($\\Pi_{1}$, or $\\forall$), and as one goes higher in the sentence complexity\nhierarchy the number of Mizar theorems having these complexities decreases\nrapidly. The results support the intuitive idea that mathematical statements,\neven when carried out an abstract set-theoretical style, are usually quite low\nin the sentence complexity hierarchy (not more complex than\n$\\forall\\exists\\forall$ or $\\exists\\forall$).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 09:49:33 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Alama", "Jesse", ""]]}, {"id": "1311.1916", "submitter": "Antonino Salibra", "authors": "Antonino Salibra (Universit\\`a Ca'Foscari Venezia), Alberto Carraro\n  (Laboratoire PPS, Universit\\'e Paris Diderot)", "title": "Ordered Models of the Lambda Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (December\n  12, 2013) lmcs:726", "doi": "10.2168/LMCS-9(4:21)2013", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering a question by Honsell and Plotkin, we show that there are two\nequations between lambda terms, the so-called subtractive equations, consistent\nwith lambda calculus but not simultaneously satisfied in any partially ordered\nmodel with bottom element. We also relate the subtractive equations to the open\nproblem of the order-incompleteness of lambda calculus, by studying the\nconnection between the notion of absolute unorderability in a specific point\nand a weaker notion of subtractivity (namely n-subtractivity) for partially\nordered algebras. Finally we study the relation between n-subtractivity and\nrelativized separation conditions in topological algebras, obtaining an\nincompleteness theorem for a general topological semantics of lambda calculus.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 09:55:52 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2013 22:46:50 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Salibra", "Antonino", "", "Universit\u00e0 Ca'Foscari Venezia"], ["Carraro", "Alberto", "", "Laboratoire PPS, Universit\u00e9 Paris Diderot"]]}, {"id": "1311.1917", "submitter": "Jesse Alama", "authors": "Jesse Alama", "title": "Toward a structure theory for Lorenzen dialogue games", "comments": "20 pages. Expanded version of an informal presentation given at CiE\n  2010 (Computability in Europe)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lorenzen dialogues provide a two-player game formalism that can characterize\na variety of logics: each set $S$ of rules for such a game determines a set\n$\\mathcal{D}(S)$ of formulas for which one of the players (the so-called\nProponent) has a winning strategy, and the set $\\mathcal{D}(S)$ can coincide\nwith various logics, such as intuitionistic, classical, modal, connexive, and\nrelevance logics. But the standard sets of rules employed for these games are\noften logically opaque and can involve subtle interactions among each other.\nMoreover, $\\mathcal{D}(S)$ can vary in unexpected ways with $S$; small changes\nin $S$, even logically well-motivated ones, can make $\\mathcal{D}(S)$ logically\nunusual. We pose the problem of providing a structure theory that could explain\nhow $\\mathcal{D}(S)$ varies with $S$, and in particular, when $\\mathcal{D}(S)$\nis closed under modus ponens (and thus constitutes at least a minimal kind of\nlogic).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 09:57:48 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 11:10:52 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Alama", "Jesse", ""]]}, {"id": "1311.2290", "submitter": "Peter Selinger", "authors": "Michele Pagani, Peter Selinger, Beno\\^it Valiron", "title": "Applying quantitative semantics to higher-order quantum computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a denotational semantics for higher order quantum computation is a\nlong-standing problem in the semantics of quantum programming languages. Most\npast approaches to this problem fell short in one way or another, either\nlimiting the language to an unusably small finitary fragment, or giving up\nimportant features of quantum physics such as entanglement. In this paper, we\npropose a denotational semantics for a quantum lambda calculus with recursion\nand an infinite data type, using constructions from quantitative semantics of\nlinear logic.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 17:56:21 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Pagani", "Michele", ""], ["Selinger", "Peter", ""], ["Valiron", "Beno\u00eet", ""]]}, {"id": "1311.2362", "submitter": "Alwen Tiu", "authors": "Hendra Gunadi and Alwen Tiu", "title": "Efficient Runtime Monitoring with Metric Temporal Logic: A Case Study in\n  the Android Operating System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a design and an implementation of a security policy specification\nlanguage based on metric linear-time temporal logic (MTL). MTL features\ntemporal operators that are indexed by time intervals, allowing one to specify\ntiming-dependent security policies. The design of the language is driven by the\nproblem of runtime monitoring of applications in mobile devices. A main case\nthe study is the privilege escalation attack in the Android operating system,\nwhere an app gains access to certain resource or functionalities that are not\nexplicitly granted to it by the user, through indirect control flow. To capture\nthese attacks, we extend MTL with recursive definitions, that are used to\nexpress call chains betwen apps. We then show how the metric operators of MTL,\nin combination with recursive definitions, can be used to specify policies to\ndetect privilege escalation, under various fine grained constraints. We present\na new algorithm, extending that of linear time temporal logic, for monitoring\nsafety policies written in our specification language. The monitor does not\nneed to store the entire history of events generated by the apps, something\nthat is crucial for practical implementations. We modified the Android OS\nkernel to allow us to insert our generated monitors modularly. We have tested\nthe modified OS on an actual device, and show that it is effective in detecting\npolicy violations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 06:21:29 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Gunadi", "Hendra", ""], ["Tiu", "Alwen", ""]]}, {"id": "1311.2702", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn, Alexandre Bergel", "title": "Verifiable Source Code Documentation in Controlled Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing documentation about software internals is rarely considered a\nrewarding activity. It is highly time-consuming and the resulting documentation\nis fragile when the software is continuously evolving in a multi-developer\nsetting. Unfortunately, traditional programming environments poorly support the\nwriting and maintenance of documentation. Consequences are severe as the lack\nof documentation on software structure negatively impacts the overall quality\nof the software product. We show that using a controlled natural language with\na reasoner and a query engine is a viable technique for verifying the\nconsistency and accuracy of documentation and source code. Using ACE, a\nstate-of-the-art controlled natural language, we present positive results on\nthe comprehensibility and the general feasibility of creating and verifying\ndocumentation. As a case study, we used automatic documentation verification to\nidentify and fix severe flaws in the architecture of a non-trivial piece of\nsoftware. Moreover, a user experiment shows that our language is faster and\neasier to learn and understand than other formal languages for software\ndocumentation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 07:44:10 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Kuhn", "Tobias", ""], ["Bergel", "Alexandre", ""]]}, {"id": "1311.2928", "submitter": "Andrea Turrini", "authors": "Ernst Moritz Hahn and Guangyuan Li and Sven Schewe and Andrea Turrini\n  and Lijun Zhang", "title": "Lazy Probabilistic Model Checking without Determinisation", "comments": "38 pages. Updated version for introducing the following changes: -\n  general improvement on paper presentation; - extension of the approach to\n  avoid full determinisation; - added proofs for such an extension; - added\n  case studies; - updated old case studies to reflect the added extension", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bottleneck in the quantitative analysis of Markov chains and Markov\ndecision processes against specifications given in LTL or as some form of\nnondeterministic B\\\"uchi automata is the inclusion of a determinisation step of\nthe automaton under consideration. In this paper, we show that full\ndeterminisation can be avoided: subset and breakpoint constructions suffice. We\nhave implemented our approach---both explicit and symbolic versions---in a\nprototype tool. Our experiments show that our prototype can compete with mature\ntools like PRISM.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 05:29:39 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2015 08:11:29 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Li", "Guangyuan", ""], ["Schewe", "Sven", ""], ["Turrini", "Andrea", ""], ["Zhang", "Lijun", ""]]}, {"id": "1311.2959", "submitter": "David Monniaux", "authors": "Thomas Braibant (Gallium), Jacques-Henri Jourdan (Gallium), David\n  Monniaux", "title": "Implementing and reasoning about hash-consed data structures in Coq", "comments": null, "journal-ref": "Journal of Automated Reasoning, Springer Verlag (Germany), 2014,\n  53 (3), pp.271-304", "doi": "10.1007/s10817-014-9306-0", "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on four different approaches to implementing hash-consing in Coq\nprograms. The use cases include execution inside Coq, or execution of the\nextracted OCaml code. We explore the different trade-offs between faithful use\nof pristine extracted code, and code that is fine-tuned to make use of OCaml\nprogramming constructs not available in Coq. We discuss the possible\nconsequences in terms of performances and guarantees. We use the running\nexample of binary decision diagrams and then demonstrate the generality of our\nsolutions by applying them to other examples of hash-consed data structures.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 19:49:43 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2014 16:28:37 GMT"}, {"version": "v3", "created": "Mon, 15 Dec 2014 14:57:17 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2015 17:39:37 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Braibant", "Thomas", "", "Gallium"], ["Jourdan", "Jacques-Henri", "", "Gallium"], ["Monniaux", "David", ""]]}, {"id": "1311.2960", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "An Axiomatization for Quantum Processes to Unifying Quantum and\n  Classical Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish an axiomatization for quantum processes, which is a quantum\ngeneralization of process algebra ACP (Algebra of Communicating Processes). We\nuse the framework of a quantum process configuration $\\langle p,\n\\varrho\\rangle$, but we treat it as two relative independent part: the\nstructural part $p$ and the quantum part $\\varrho$, because the establishment\nof a sound and complete theory is dependent on the structural properties of the\nstructural part $p$. We let the quantum part $\\varrho$ be the outcomes of\nexecution of $p$ to examine and observe the function of the basic theory of\nquantum mechanics. We establish not only a strong bisimularity for quantum\nprocesses, but also a weak bisimularity to model the silent step and abstract\ninternal computations in quantum processes. The relationship between quantum\nbisimularity and classical bisimularity is established, which makes an\naxiomatization of quantum processes possible. An axiomatization for quantum\nprocesses called qACP is designed, which involves not only quantum information,\nbut also classical information and unifies quantum computing and classical\ncomputing. qACP can be used easily and widely for verification of most quantum\ncommunication protocols.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 03:34:18 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1311.2973", "submitter": "Viorica  Sofronie-Stokkermans", "authors": "Viorica Sofronie-Stokkermans", "title": "Locality and applications to subsumption testing and interpolation in\n  $\\mathcal{EL}$ and some of its extensions", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that subsumption problems in lightweight description\nlogics (such as $\\mathcal{EL}$ and $\\mathcal{EL}^+$) can be expressed as\nuniform word problems in classes of semilattices with monotone operators. We\nuse possibilities of efficient local reasoning in such classes of algebras, to\nobtain uniform PTIME decision procedures for CBox subsumption in\n$\\mathcal{EL}$, $\\mathcal{EL}^+$ and extensions thereof. These locality\nconsiderations allow us to present a new family of (possibly many-sorted)\nlogics which extend $\\mathcal{EL}$ and $\\mathcal{EL}^+$ with $n$-ary roles\nand/or numerical domains. As a by-product, this allows us to show that the\nalgebraic models of ${\\cal EL}$ and ${\\cal EL}^+$ have ground interpolation and\nthus that ${\\cal EL}$, ${\\cal EL}^+$, and their extensions studied in this\npaper have interpolation. We also show how these ideas can be used for the\ndescription logic $\\mathcal{EL}^{++}$.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 22:27:26 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Sofronie-Stokkermans", "Viorica", ""]]}, {"id": "1311.3198", "submitter": "Marie-Laure Mugnier", "authors": "M\\'elanie K\\\"onig and Michel Lecl\\`ere and Marie-Laure Mugnier and\n  Micha\\\"el Thomazo", "title": "Sound, Complete and Minimal UCQ-Rewriting for Existential Rules", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": "Report-no: LIRMM-RR-13034", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of Ontology-Based Data Access, with ontologies\nrepresented in the framework of existential rules, also known as Datalog+/-. A\nwell-known approach involves rewriting the query using ontological knowledge.\nWe focus here on the basic rewriting technique which consists of rewriting the\ninitial query into a union of conjunctive queries. First, we study a generic\nbreadth-first rewriting algorithm, which takes as input any rewriting operator,\nand define properties of rewriting operators that ensure the correctness of the\nalgorithm. Then, we focus on piece-unifiers, which provide a rewriting operator\nwith the desired properties. Finally, we propose an implementation of this\nframework and report some experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 16:36:35 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["K\u00f6nig", "M\u00e9lanie", ""], ["Lecl\u00e8re", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Thomazo", "Micha\u00ebl", ""]]}, {"id": "1311.3396", "submitter": "Yuan Feng", "authors": "Yuan Feng and Lijun Zhang", "title": "When Equivalence and Bisimulation Join Forces in Probabilistic Automata", "comments": "21 pages, 1 figure. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic automata were introduced by Rabin in 1963 as language\nacceptors. Two automata are equivalent if and only if they accept each word\nwith the same probability. On the other side, in the process algebra community,\nprobabilistic automata were re-proposed by Segala in 1995 which are more\ngeneral than Rabin's automata. Bisimulations have been proposed for Segala's\nautomata to characterize the equivalence between them. So far the two notions\nof equivalences and their characteristics have been studied most independently.\nIn this paper, we consider Segala's automata, and propose a novel notion of\ndistribution based bisimulation by joining the existing equivalence and\nbisimilarities. Our bisimulation bridges the two closely related concepts in\nthe community, and provides a uniform way of studying their characteristics. We\ndemonstrate the utility of our definition by studying distribution based\nbisimulation metrics, which gives rise to a robust notion of equivalence for\nRabin's automata.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 07:15:43 GMT"}, {"version": "v2", "created": "Sat, 8 Mar 2014 01:55:21 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Feng", "Yuan", ""], ["Zhang", "Lijun", ""]]}, {"id": "1311.3530", "submitter": "Robert Koenighofer", "authors": "Roderick Bloem, Robert Koenighofer, Martina Seidl", "title": "SAT-Based Synthesis Methods for Safety Specs", "comments": "Extended version of a paper at VMCAI'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic synthesis of hardware components from declarative specifications is\nan ambitious endeavor in computer aided design. Existing synthesis algorithms\nare often implemented with Binary Decision Diagrams (BDDs), inheriting their\nscalability limitations. Instead of BDDs, we propose several new methods to\nsynthesize finite-state systems from safety specifications using decision\nprocedures for the satisfiability of quantified and unquantified Boolean\nformulas (SAT-, QBF- and EPR-solvers). The presented approaches are based on\ncomputational learning, templates, or reduction to first-order logic. We also\npresent an efficient parallelization, and optimizations to utilize reachability\ninformation and incremental solving. Finally, we compare all methods in an\nextensive case study. Our new methods outperform BDDs and other existing work\non some classes of benchmarks, and our parallelization achieves a super-linear\nspeedup. This is an extended version of [5], featuring an additional appendix.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 15:11:12 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Bloem", "Roderick", ""], ["Koenighofer", "Robert", ""], ["Seidl", "Martina", ""]]}, {"id": "1311.3687", "submitter": "Jose Oliveira Prof", "authors": "Daniel Murta and Jose Nuno Oliveira", "title": "Calculating risk in functional programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the trend towards tolerating hardware unreliability, accuracy is exchanged\nfor cost savings. Running on less reliable machines, \"functionally correct\"\ncode becomes risky and one needs to know how risk propagates so as to mitigate\nit. Risk estimation, however, seems to live outside the average programmer's\ntechnical competence and core practice. In this paper we propose that risk be\nconstructively handled in functional programming by (a) writing programs which\nmay choose between expected and faulty behaviour, and by (b) reasoning about\nthem in a linear algebra extension to standard, a la Bird-Moor algebra of\nprogramming. In particular, the propagation of faults across standard program\ntransformation techniques known as tupling and fusion is calculated, enabling\nthe fault of the whole to be expressed in terms of the faults of its parts.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 22:14:33 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Murta", "Daniel", ""], ["Oliveira", "Jose Nuno", ""]]}, {"id": "1311.3899", "submitter": "Sebastian Siebertz", "authors": "Martin Grohe, Stephan Kreutzer, Sebastian Siebertz", "title": "Deciding first-order properties of nowhere dense graphs", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowhere dense graph classes, introduced by Nesetril and Ossona de Mendez,\nform a large variety of classes of \"sparse graphs\" including the class of\nplanar graphs, actually all classes with excluded minors, and also bounded\ndegree graphs and graph classes of bounded expansion.\n  We show that deciding properties of graphs definable in first-order logic is\nfixed-parameter tractable on nowhere dense graph classes. At least for graph\nclasses closed under taking subgraphs, this result is optimal: it was known\nbefore that for all classes C of graphs closed under taking subgraphs, if\ndeciding first-order properties of graphs in C is fixed-parameter tractable,\nthen C must be nowhere dense (under a reasonable complexity theoretic\nassumption).\n  As a by-product, we give an algorithmic construction of sparse neighbourhood\ncovers for nowhere dense graphs. This extends and improves previous\nconstructions of neighbourhood covers for graph classes with excluded minors.\nAt the same time, our construction is considerably simpler than those. Our\nproofs are based on a new game-theoretic characterisation of nowhere dense\ngraphs that allows for a recursive version of locality-based algorithms on\nthese classes. On the logical side, we prove a \"rank-preserving\" version of\nGaifman's locality theorem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 16:08:13 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2014 14:01:14 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Grohe", "Martin", ""], ["Kreutzer", "Stephan", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1311.3903", "submitter": "Samuel Mimram", "authors": "Samuel Mimram (LIST), Cinzia Di Giusto (LIST)", "title": "A Categorical Theory of Patches", "comments": null, "journal-ref": "MFPS - Mathematical Foundations of Programming Semantics 298\n  (2013) 283-307", "doi": "10.1016/j.entcs.2013.09.018", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working with distant collaborators on the same documents, one often uses\na version control system, which is a program tracking the history of files and\nhelping importing modifications brought by others as patches. The\nimplementation of such a system requires to handle lots of situations depending\non the operations performed by users on files, and it is thus difficult to\nensure that all the corner cases have been correctly addressed. Here, instead\nof verifying the implementation of such a system, we adopt a complementary\napproach: we introduce a theoretical model, which is defined abstractly by the\nuniversal property that it should satisfy, and work out a concrete description\nof it. We begin by defining a category of files and patches, where the\noperation of merging the effect of two coinitial patches is defined by pushout.\nSince two patches can be incompatible, such a pushout does not necessarily\nexist in the category, which raises the question of which is the correct\ncategory to represent and manipulate files in conflicting state. We provide an\nanswer by investigating the free completion of the category of files under\nfinite colimits, and give an explicit description of this category: its objects\nare finite sets labeled by lines equipped with a transitive relation and\nmorphisms are partial functions respecting labeling and relations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 20:19:47 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Mimram", "Samuel", "", "LIST"], ["Di Giusto", "Cinzia", "", "LIST"]]}, {"id": "1311.4002", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus and Christian Sattler", "title": "Higher Homotopies in a Hierarchy of Univalent Universes", "comments": "v1: 30 pages, main results and a connectedness construction; v2: 14\n  pages, only main results, improved presentation, final journal version,\n  ancillary files with electronic appendix; v3: content unchanged, different\n  documentclass reduced the number of pages to 12", "journal-ref": "ACM Transactions on Computational Logic (TOCL), Volume 16 Issue 2,\n  Article No. 18, March 2015", "doi": "10.1145/2729979", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Martin-Lof type theory with a hierarchy U(0): U(1): U(2): ... of\nunivalent universes, we show that U(n) is not an n-type. Our construction also\nsolves the problem of finding a type that strictly has some high truncation\nlevel without using higher inductive types. In particular, U(n) is such a type\nif we restrict it to n-types. We have fully formalized and verified our results\nwithin the dependently typed language and proof assistant Agda.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 23:34:16 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2015 20:30:26 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2015 12:48:30 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Kraus", "Nicolai", ""], ["Sattler", "Christian", ""]]}, {"id": "1311.4046", "submitter": "Jan Leike", "authors": "Jan Leike, Ashish Tiwari", "title": "Synthesis for Polynomial Lasso Programs", "comments": "Paper at VMCAI'14, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for the synthesis of polynomial lasso programs. These\nprograms consist of a program stem, a set of transitions, and an exit\ncondition, all in the form of algebraic assertions (conjunctions of polynomial\nequalities). Central to this approach is the discovery of non-linear\n(algebraic) loop invariants. We extend Sankaranarayanan, Sipma, and Manna's\ntemplate-based approach and prove a completeness criterion. We perform program\nsynthesis by generating a constraint whose solution is a synthesized program\ntogether with a loop invariant that proves the program's correctness. This\nconstraint is non-linear and is passed to an SMT solver. Moreover, we can\nenforce the termination of the synthesized program with the support of test\ncases.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2013 10:20:48 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Leike", "Jan", ""], ["Tiwari", "Ashish", ""]]}, {"id": "1311.4289", "submitter": "Tero Laitinen", "authors": "Tero Laitinen and Tommi Junttila and Ilkka Niemel\\\"a", "title": "Simulating Parity Reasoning (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional satisfiability (SAT) solvers, which typically operate using\nconjunctive normal form (CNF), have been successfully applied in many domains.\nHowever, in some application areas such as circuit verification, bounded model\nchecking, and logical cryptanalysis, instances can have many parity (xor)\nconstraints which may not be handled efficiently if translated to CNF. Thus,\nextensions to the CNF-driven search with various parity reasoning engines\nranging from equivalence reasoning to incremental Gaussian elimination have\nbeen proposed. This paper studies how stronger parity reasoning techniques in\nthe DPLL(XOR) framework can be simulated by simpler systems: resolution, unit\npropagation, and parity explanations. Such simulations are interesting, for\nexample, for developing the next generation SAT solvers capable of handling\nparity constraints efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 08:05:16 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Laitinen", "Tero", ""], ["Junttila", "Tommi", ""], ["Niemel\u00e4", "Ilkka", ""]]}, {"id": "1311.4376", "submitter": "Paul Vickers", "authors": "Paul Vickers and Joe Faith and Nick Rossiter", "title": "Understanding Visualization: A Formal Approach using Category Theory and\n  Semiotics", "comments": "15 pages, 14 figures", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, vol. 19,\n  pp. 1048-1061, 2013", "doi": "10.1109/TVCG.2012.294", "report-no": null, "categories": "cs.LO cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article combines the vocabulary of semiotics and category theory to\nprovide a formal analysis of visualization. It shows how familiar processes of\nvisualization fit the semiotic frameworks of both Saussure and Peirce, and\nextends these structures using the tools of category theory to provide a\ngeneral framework for understanding visualization in practice, including:\nrelationships between systems, data collected from those systems, renderings of\nthose data in the form of representations, the reading of those representations\nto create visualizations, and the use of those visualizations to create\nknowledge and understanding of the system under inspection. The resulting\nframework is validated by demonstrating how familiar information visualization\nconcepts (such as literalness, sensitivity, redundancy, ambiguity,\ngeneralizability, and chart junk) arise naturally from it and can be defined\nformally and precisely. This article generalizes previous work on the formal\ncharacterization of visualization by, inter alia, Ziemkiewicz and Kosara and\nallows us to formally distinguish properties of the visualization process that\nprevious work does not.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 13:51:27 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Vickers", "Paul", ""], ["Faith", "Joe", ""], ["Rossiter", "Nick", ""]]}, {"id": "1311.4425", "submitter": "Ayrat Khalimov", "authors": "Benjamin Aminof, Swen Jacobs, Ayrat Khalimov, Sasha Rubin", "title": "Parameterized Model Checking of Token-Passing Systems", "comments": "We had to remove an appendix until the proofs and notations there is\n  cleared", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the parameterized model checking problem for token-passing systems\nand specifications in indexed $\\textsf{CTL}^\\ast \\backslash \\textsf{X}$.\nEmerson and Namjoshi (1995, 2003) have shown that parameterized model checking\nof indexed $\\textsf{CTL}^\\ast \\backslash \\textsf{X}$ in uni-directional token\nrings can be reduced to checking rings up to some \\emph{cutoff} size. Clarke et\nal. (2004) have shown a similar result for general topologies and indexed\n$\\textsf{LTL} \\backslash \\textsf{X}$, provided processes cannot choose the\ndirections for sending or receiving the token.\n  We unify and substantially extend these results by systematically exploring\nfragments of indexed $\\textsf{CTL}^\\ast \\backslash \\textsf{X}$ with respect to\ngeneral topologies. For each fragment we establish whether a cutoff exists, and\nfor some concrete topologies, such as rings, cliques and stars, we infer small\ncutoffs. Finally, we show that the problem becomes undecidable, and thus no\ncutoffs exist, if processes are allowed to choose the directions in which they\nsend or from which they receive the token.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 15:40:11 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2013 10:04:51 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2013 19:44:40 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Aminof", "Benjamin", ""], ["Jacobs", "Swen", ""], ["Khalimov", "Ayrat", ""], ["Rubin", "Sasha", ""]]}, {"id": "1311.4617", "submitter": "Zhaowei Xu", "authors": "Zhaowei Xu", "title": "A New Perspective for Hoare's Logic and Peano's Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Hoare's logic is an axiomatic system of proving programs correct, which has\nbeen extended to be a separation logic to reason about mutable heap structure.\nWe develop the most fundamental logical structure of strongest postcondition of\nHoare's logic in Peano's arithmetic $PA$. Let $p\\in L$ and $S$ be any\nwhile-program. The arithmetical definability of $\\textbf{N}$-computable\nfunction $f_S^{\\textbf{N}}$ leads to separate $S$ from $SP(p,S)$, which defines\nthe strongest postcondition of $p$ and $S$ over $\\textbf{N}$, achieving an\nequivalent but more meaningful form in $PA$. From the reduction of Hoare's\nlogic to PA, together with well-defined underlying semantics, it follows that\nHoare's logic is sound and complete relative to the theory of $PA$, which is\ndifferent from the relative completeness in the sense of Cook. Finally, we\ndiscuss two ways to extend computability from the standard structure to\nnonstandard models of $PA$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 03:59:26 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Xu", "Zhaowei", ""]]}, {"id": "1311.4639", "submitter": "Katsumi Inoue", "authors": "Katsumi Inoue and Chiaki Sakama (Editors)", "title": "Post-Proceedings of the First International Workshop on Learning and\n  Nonmonotonic Reasoning", "comments": "67 pages, 5 papers, 1 abstract, 1 cover", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Representation and Reasoning and Machine Learning are two important\nfields in AI. Nonmonotonic logic programming (NMLP) and Answer Set Programming\n(ASP) provide formal languages for representing and reasoning with commonsense\nknowledge and realize declarative problem solving in AI. On the other side,\nInductive Logic Programming (ILP) realizes Machine Learning in logic\nprogramming, which provides a formal background to inductive learning and the\ntechniques have been applied to the fields of relational learning and data\nmining. Generally speaking, NMLP and ASP realize nonmonotonic reasoning while\nlack the ability of learning. By contrast, ILP realizes inductive learning\nwhile most techniques have been developed under the classical monotonic logic.\nWith this background, some researchers attempt to combine techniques in the\ncontext of nonmonotonic ILP. Such combination will introduce a learning\nmechanism to programs and would exploit new applications on the NMLP side,\nwhile on the ILP side it will extend the representation language and enable us\nto use existing solvers. Cross-fertilization between learning and nonmonotonic\nreasoning can also occur in such as the use of answer set solvers for ILP,\nspeed-up learning while running answer set solvers, learning action theories,\nlearning transition rules in dynamical systems, abductive learning, learning\nbiological networks with inhibition, and applications involving default and\nnegation. This workshop is the first attempt to provide an open forum for the\nidentification of problems and discussion of possible collaborations among\nresearchers with complementary expertise. The workshop was held on September\n15th of 2013 in Corunna, Spain. This post-proceedings contains five technical\npapers (out of six accepted papers) and the abstract of the invited talk by Luc\nDe Raedt.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 07:39:58 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Inoue", "Katsumi", "", "Editors"], ["Sakama", "Chiaki", "", "Editors"]]}, {"id": "1311.4915", "submitter": "Matthew Hague", "authors": "Matthew Hague", "title": "Senescent Ground Tree Rewrite Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ground Tree Rewrite Systems with State are known to have an undecidable\ncontrol state reachability problem. Taking inspiration from the recent\nintroduction of scope-bounded multi-stack pushdown systems, we define Senescent\nGround Tree Rewrite Systems. These are a restriction of ground tree rewrite\nsystems with state such that nodes of the tree may no longer be rewritten after\nhaving witnessed an a priori fixed number of control state changes. As well as\ngeneralising scope-bounded multi-stack pushdown systems, we show --- via\nreductions to and from reset Petri-nets --- that these systems have an\nAckermann-complete control state reachability problem. However, reachability of\na regular set of trees remains undecidable.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 23:03:10 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Hague", "Matthew", ""]]}, {"id": "1311.5006", "submitter": "Andrea Simonetto", "authors": "Andrea Simonetto", "title": "Indagini in Deep Inference", "comments": "in Italian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Italian master's thesis in Computer Science. It is an overview of the\nstandard tecniques developed in the field of Proof Theory, ending with some\nresults in the new field of Deep Inference, plus an original contribution\ntrying to relate Deep Inference and Process Algebras.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 10:46:35 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Simonetto", "Andrea", ""]]}, {"id": "1311.5058", "submitter": "EPTCS", "authors": "Sebastian Maneth (University of Edinburgh)", "title": "Proceedings Second International Workshop on Trends in Tree Automata and\n  Tree Transducers", "comments": null, "journal-ref": "EPTCS 134, 2013", "doi": "10.4204/EPTCS.134", "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers that were presented at the second\ninternational workshop on Trends in Tree Automata and Transducers (TTATT 2013)\nwhich took place on October 19th, 2013 in Hanoi/Vietnam. The workshop was\ncolocated with the verification conference ATVA. The first edition of the\nworkshop was colocated with RTA and took place in Nagoya/Japan. The interest of\nthe workshop lies at the intersection of programming languages, verification,\nand database theory, which are areas to which tree automata and transducers are\napplied recently.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 14:11:27 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Maneth", "Sebastian", "", "University of Edinburgh"]]}, {"id": "1311.5567", "submitter": "EPTCS", "authors": "Naoki Nishida (Nagoya University), Masahiko Sakai (Nagoya University),\n  Yasuhiro Nakano (Nagoya University)", "title": "On Constructing Constrained Tree Automata Recognizing Ground Instances\n  of Constrained Terms", "comments": "In Proceedings TTATT 2013, arXiv:1311.5058", "journal-ref": "EPTCS 134, 2013, pp. 1-10", "doi": "10.4204/EPTCS.134.1", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inductive theorem proving method for constrained term rewriting systems,\nwhich is based on rewriting induction, needs a decision procedure for\nreduction-completeness of constrained terms. In addition, the sufficient\ncomplete property of constrained term rewriting systems enables us to relax the\nside conditions of some inference rules in the proving method. These two\nproperties can be reduced to intersection emptiness problems related to sets of\nground instances for constrained terms. This paper proposes a method to\nconstruct deterministic, complete, and constraint-complete constrained tree\nautomata recognizing ground instances of constrained terms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 21:00:22 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Nishida", "Naoki", "", "Nagoya University"], ["Sakai", "Masahiko", "", "Nagoya University"], ["Nakano", "Yasuhiro", "", "Nagoya University"]]}, {"id": "1311.5802", "submitter": "EPTCS", "authors": "Franco Barbanera (Dipartimento di Matematica e Informatica, Univ.\n  Catania), Ugo de' Liguoro (Dipartimento di Informatica, Univ. Torino)", "title": "Loosening the notions of compliance and sub-behaviour in client/server\n  systems", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 94-110", "doi": "10.4204/EPTCS.166.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of \"session behaviors\" for client/server systems, we propose a\nweakening of the compliance and sub-behaviour relations where the bias toward\nthe client (whose \"requests\" must be satisfied) is pushed further with respect\nto the usual definitions, by admitting that \"not needed\" output actions from\nthe server side can be \"skipped\" by the client. Both compliance and\nsub-behaviour relations resulting from this weakening remain decidable, though\nthe proof of the duals-as-minima property for servers, on which the\ndecidability of the sub-behaviour relation relies, requires a tighter analysis\nof client/server interactions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 16:34:44 GMT"}, {"version": "v2", "created": "Tue, 28 Oct 2014 00:41:59 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Barbanera", "Franco", "", "Dipartimento di Matematica e Informatica, Univ.\n  Catania"], ["Liguoro", "Ugo de'", "", "Dipartimento di Informatica, Univ. Torino"]]}, {"id": "1311.6057", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Radha Jagadeesan", "title": "Games and Full Completeness for Multiplicative Linear Logic", "comments": "45 pages, 5 figures", "journal-ref": "Journal of Symbolic Logic (1994), volume 59 no. 2, pages 543-574", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a game semantics for Linear Logic, in which formulas denote games\nand proofs denote winning strategies. We show that our semantics yields a\ncategorical model of Linear Logic and prove full completeness for\nMultiplicative Linear Logic with the MIX rule: every winning strategy is the\ndenotation of a unique cut-free proof net. A key role is played by the notion\nof {\\em history-free} strategy; strong connections are made between\nhistory-free strategies and the Geometry of Interaction. Our semantics\nincorporates a natural notion of polarity, leading to a refined treatment of\nthe additives. We make comparisons with related work by Joyal, Blass et al.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2013 21:45:25 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Abramsky", "Samson", ""], ["Jagadeesan", "Radha", ""]]}, {"id": "1311.6125", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Radha Jagadeesan and Pasquale Malacaria", "title": "Full Abstraction for PCF", "comments": "50 pages", "journal-ref": "Information and Computation vol. 163 no. 2 (2000), pages 409-470", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intensional model for the programming language PCF is described, in which\nthe types of PCF are interpreted by games, and the terms by certain\n\"history-free\" strategies. This model is shown to capture definability in PCF.\nMore precisely, every compact strategy in the model is definable in a certain\nsimple extension of PCF. We then introduce an intrinsic preorder on strategies,\nand show that it satisfies some striking properties, such that the intrinsic\npreorder on function types coincides with the pointwise preorder. We then\nobtain an order-extensional fully abstract model of PCF by quotienting the\nintensional model by the intrinsic preorder. This is the first\nsyntax-independent description of the fully abstract model for PCF. (Hyland and\nOng have obtained very similar results by a somewhat different route,\nindependently and at the same time).\n  We then consider the effective version of our model, and prove a Universality\nTheorem: every element of the effective extensional model is definable in PCF.\nEquivalently, every recursive strategy is definable up to observational\nequivalence.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2013 14:05:33 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2014 12:14:30 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Abramsky", "Samson", ""], ["Jagadeesan", "Radha", ""], ["Malacaria", "Pasquale", ""]]}, {"id": "1311.6250", "submitter": "EPTCS", "authors": "Claudia Carapelle (Leipzig University), Shiguang Feng (Leipzig\n  University), Oliver Fern\\'andez Gil (Leipzig University), Karin Quaas\n  (Leipzig University)", "title": "On the Expressiveness of TPTL and MTL over \\omega-Data Words", "comments": "In Proceedings AFL 2014, arXiv:1405.5272", "journal-ref": "EPTCS 151, 2014, pp. 174-187", "doi": "10.4204/EPTCS.151.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are\nprominent extensions of Linear Temporal Logic to specify properties about data\nlanguages. In this paper, we consider the class of data languages of\nnon-monotonic data words over the natural numbers. We prove that, in this\nsetting, TPTL is strictly more expressive than MTL. To this end, we introduce\nEhrenfeucht-Fraisse (EF) games for MTL. Using EF games for MTL, we also prove\nthat the MTL definability decision problem (\"Given a TPTL-formula, is the\nlanguage defined by this formula definable in MTL?\") is undecidable. We also\ndefine EF games for TPTL, and we show the effect of various syntactic\nrestrictions on the expressiveness of MTL and TPTL.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 10:27:10 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 02:13:19 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Carapelle", "Claudia", "", "Leipzig University"], ["Feng", "Shiguang", "", "Leipzig\n  University"], ["Gil", "Oliver Fern\u00e1ndez", "", "Leipzig University"], ["Quaas", "Karin", "", "Leipzig University"]]}, {"id": "1311.6542", "submitter": "Meixia Qu", "authors": "Meixia Qu, Ke Chen, Daming Zhu, Junfeng Luan", "title": "Implementing program extraction from CL1-proofs", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (CoL) is a formal theory of interactive computation. It\nunderstands computational problems as games played by two players: a machine\nand its environment, uses logical formalism to describe valid principles of\ncomputability and formulas to represent computational problems. Logic CL1 is a\ndeductive system for a fragment of CoL. The logical vocabulary contains all of\nthe operators of classical logic and choice operators, the atoms represent\nelementary games i.e. predicates of classical logic. In this paper, we present\na program that takes a CL1-proof of an arbitrary formula $F$, and extract a\nwinning strategy for $F$ from that proof then play $F$ using that strategy. We\nhope this paper would provide a starting point for further work in program\nextraction of the CoL-based arithmetic and other CoL-based applied systems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 02:09:41 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Qu", "Meixia", ""], ["Chen", "Ke", ""], ["Zhu", "Daming", ""], ["Luan", "Junfeng", ""]]}, {"id": "1311.6563", "submitter": "Philip Atzemoglou", "authors": "Philip Atzemoglou", "title": "Higher-order semantics for quantum programming languages with classical\n  control", "comments": "DPhil Thesis. See full text for unabridged abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis studies the categorical formalisation of quantum computing,\nthrough the prism of type theory, in a three-tier process. The first stage of\nour investigation involves the creation of the dagger lambda calculus, a lambda\ncalculus for dagger compact categories. Our second contribution lifts the\nexpressive power of the dagger lambda calculus, to that of a quantum\nprogramming language, by adding classical control in the form of complementary\nclassical structures and dualisers. Finally, our third contribution\ndemonstrates how our lambda calculus can be applied to various well known\nproblems in quantum computation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 06:08:34 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Atzemoglou", "Philip", ""]]}, {"id": "1311.6605", "submitter": "Pierre-Cyrille Heam", "authors": "Alois Dreyfus (INRIA Nancy - Grand Est / LORIA / LIFC, UMR 6174),\n  Pierre-Cyrille Heam (INRIA Nancy - Grand Est / LORIA / LIFC, FEMTO-ST), Olga\n  Kouchnarenko (INRIA Nancy - Grand Est / LORIA / LIFC, FEMTO-ST)", "title": "Enhancing Approximations for Regular Reachability Analysis", "comments": null, "journal-ref": "Implementation and Application of Automata 7982 (2013) 331-339", "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces two mechanisms for computing over-approximations of\nsets of reachable states, with the aim of ensuring termination of state-space\nexploration. The first mechanism consists in over-approximating the automata\nrepresenting reachable sets by merging some of their states with respect to\nsimple syntactic criteria, or a combination of such criteria. The second\napproximation mechanism consists in manipulating an auxiliary automaton when\napplying a transducer representing the transition relation to an automaton\nencoding the initial states. In addition, for the second mechanism we propose a\nnew approach to refine the approximations depending on a property of interest.\nThe proposals are evaluated on examples of mutual exclusion protocols.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 09:57:16 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Dreyfus", "Alois", "", "INRIA Nancy - Grand Est / LORIA / LIFC, UMR 6174"], ["Heam", "Pierre-Cyrille", "", "INRIA Nancy - Grand Est / LORIA / LIFC, FEMTO-ST"], ["Kouchnarenko", "Olga", "", "INRIA Nancy - Grand Est / LORIA / LIFC, FEMTO-ST"]]}, {"id": "1311.7090", "submitter": "J\\\"urgen Koslowski", "authors": "Manuel A. Martins (University of Aveiro), Alexandre Madeira (CCTC,\n  Minho University & Dep. Mathematics, Aveiro University & Critical Software),\n  Luis S. Barbosa (Dep. Informatics & CCTC, Minho University, Braga, Portugal)", "title": "The role of logical interpretations in program development", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (January\n  3, 2014) lmcs:706", "doi": "10.2168/LMCS-10(1:1)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stepwise refinement of algebraic specifications is a well known formal\nmethodology for program development. However, traditional notions of refinement\nbased on signature morphisms are often too rigid to capture a number of\nrelevant transformations in the context of software design, reuse, and\nadaptation. This paper proposes a new approach to refinement in which signature\nmorphisms are replaced by logical interpretations as a means to witness\nrefinements. The approach is first presented in the context of equational\nlogic, and later generalised to deductive systems of arbitrary dimension. This\nallows, for example, refining sentential into equational specifications and the\nlatter into modal ones.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 19:44:37 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 13:20:26 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2014 09:23:08 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Martins", "Manuel A.", "", "University of Aveiro"], ["Madeira", "Alexandre", "", "CCTC,\n  Minho University & Dep. Mathematics, Aveiro University & Critical Software"], ["Barbosa", "Luis S.", "", "Dep. Informatics & CCTC, Minho University, Braga, Portugal"]]}, {"id": "1311.7181", "submitter": "Jianhua Zhao", "authors": "Jianhua Zhao and Xuandong LI", "title": "Formal Verification of `Programming to Interfaces' Programs", "comments": "40Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a formal approach to specify and verify object-oriented\nprograms written in the `programming to interfaces' paradigm. Besides the\nmethods to be invoked by its clients, an interface also declares a set of\nabstract function/predicate symbols, together with a set of constraints on\nthese symbols. For each method declared in this interface, a specification\ntemplate is given using these abstract symbols. A class implementing this\ninterface can give its own definitions to the abstract symbols, as long as all\nthe constraints are satisfied. This class implements all the methods declared\nin the interface such that the method specification templates declared in the\ninterface are satisfied w.r.t. the definitions of the abstract function symbols\nin this class. Based on the constraints on the abstract symbols, the client\ncode using interfaces can be specified and verified precisely without knowing\nwhat classes implement these interfaces. Given more information about the\nimplementing classes, the specifications of the client code can be specialized\ninto more precise ones without re-verifying the client code.\n  Several commonly used interfaces and their implementations (including\nIterator, Observer, Comparable, and Comparator) are used to demonstrate that\nthe approach in this paper is both precise and flexible.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 00:39:01 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Zhao", "Jianhua", ""], ["LI", "Xuandong", ""]]}, {"id": "1311.7635", "submitter": "Konrad Kulakowski", "authors": "Konrad Ku{\\l}akowski", "title": "Concurrent bisimulation algorithm", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coarsest bisimulation-finding problem plays an important role in the\nformal analysis of concurrent systems. For example, solving this problem allows\nthe behavior of different processes to be compared or specifications to be\nverified. Hence, in this paper an efficient concurrent bisimulation algorithm\nis presented. It is based on the sequential Paige and Tarjan algorithm and the\nconcept of the state signatures. The original solution follows Hopcroft's\nprinciple \"process the smaller half\". The presented algorithm uses its\ngeneralized version \"process all but the largest one\" better suited for\nconcurrent and parallel applications. The running time achieved is comparable\nwith the best known sequential and concurrent solutions. At the end of the\nwork, the results of tests carried out are presented. The question of the lower\nbound for the running time of the optimal algorithm is also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 19:14:21 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2014 23:36:48 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Ku\u0142akowski", "Konrad", ""]]}]