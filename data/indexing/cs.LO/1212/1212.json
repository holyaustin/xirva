[{"id": "1212.0020", "submitter": "Trifon Trifonov", "authors": "Dan Hernest and Trifon Trifonov", "title": "Modal Functional (`Dialectica') Interpretation", "comments": "31 pages, three Appendix sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt our light Dialectica interpretation to usual and light modal\nformulas (with universal quantification on boolean and natural variables) and\nprove it sound for a non-standard modal arithmetic based on Goedel's T and\nclassical S_4. The range of this light modal Dialectica is the usual\n(non-modal) classical Arithmetic in all finite types (with booleans); the\npropositional kernel of its domain is Boolean and not S_4. The `heavy' modal\nDialectica interpretation is a new technique; it cannot be simulated within our\nprevious light Dialectica. The synthesized functionals are at least as good as\nbefore; the translation process is much improved and could be more suitable for\nthe human operators.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 21:32:52 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2013 08:58:08 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2015 02:21:54 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2015 16:37:30 GMT"}, {"version": "v5", "created": "Wed, 20 Jan 2021 19:08:12 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Hernest", "Dan", ""], ["Trifonov", "Trifon", ""]]}, {"id": "1212.0079", "submitter": "Guido Governatori", "authors": "Guido Governatori, Francesco Olivieri, Antonino Rotolo and Simone\n  Scannapieco", "title": "Computing Strong and Weak Permissions in Defeasible Logic", "comments": null, "journal-ref": "Journal of Philosophical Logic (2013) 42:799-829", "doi": "10.1007/s10992-013-9295-1", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an extension of Defeasible Logic to represent and\ncompute three concepts of defeasible permission. In particular, we discuss\ndifferent types of explicit permissive norms that work as exceptions to\nopposite obligations. Moreover, we show how strong permissions can be\nrepresented both with, and without introducing a new consequence relation for\ninferring conclusions from explicit permissive norms. Finally, we illustrate\nhow a preference operator applicable to contrary-to-duty obligations can be\ncombined with a new operator representing ordered sequences of strong\npermissions which derogate from prohibitions. The logical system is studied\nfrom a computational standpoint and is shown to have liner computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 07:36:46 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Governatori", "Guido", ""], ["Olivieri", "Francesco", ""], ["Rotolo", "Antonino", ""], ["Scannapieco", "Simone", ""]]}, {"id": "1212.0253", "submitter": "Emmanuel Polonowski", "authors": "Emmanuel Polonowski", "title": "DBGen User Manual", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR--LACL--2012--4", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DBGen is a tool for Coq developers. It takes as input the definition of a\nterm structure with bindings annotations and generates definitions and\nproperties for lifting and substitution in the De Bruijn setting, up to the\nsubstitution lemma. It provides also a named syntax and a translation function\nto the De Bruijn syntax.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 22:28:14 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Polonowski", "Emmanuel", ""]]}, {"id": "1212.0401", "submitter": "Dimitri Hendriks", "authors": "Joerg Endrullis (Vrije Universiteit Amsterdam), Dimitri Hendriks\n  (Vrije Universiteit Amsterdam), Jan Willem Klop (Vrije Universiteit\n  Amsterdam), Andrew Polonsky (Vrije Universiteit Amsterdam)", "title": "Discriminating Lambda-Terms Using Clocked Boehm Trees", "comments": "arXiv admin note: substantial text overlap with arXiv:1002.2578", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 2 (May 28,\n  2014) lmcs:880", "doi": "10.2168/LMCS-10(2:4)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As observed by Intrigila, there are hardly techniques available in the\nlambda-calculus to prove that two lambda-terms are not beta-convertible.\nTechniques employing the usual Boehm Trees are inadequate when we deal with\nterms having the same Boehm Tree (BT). This is the case in particular for fixed\npoint combinators, as they all have the same BT. Another interesting equation,\nwhose consideration was suggested by Scott, is BY = BYS, an equation valid in\nthe classical model P-omega of lambda-calculus, and hence valid with respect to\nBT-equality but nevertheless the terms are beta-inconvertible. To prove such\nbeta-inconvertibilities, we employ `clocked' BT's, with annotations that convey\ninformation of the tempo in which the data in the BT are produced. Boehm Trees\nare thus enriched with an intrinsic clock behaviour, leading to a refined\ndiscrimination method for lambda-terms. The corresponding equality is strictly\nintermediate between beta-convertibility and Boehm Tree equality, the equality\nin the model P-omega. An analogous approach pertains to Levy-Longo and\nBerarducci Trees. Our refined Boehm Trees find in particular an application in\nbeta-discriminating fixed point combinators (fpc's). It turns out that Scott's\nequation BY = BYS is the key to unlocking a plethora of fpc's, generated by a\nvariety of production schemes of which the simplest was found by Boehm, stating\nthat new fpc's are obtained by postfixing the term SI, also known as Smullyan's\nOwl. We prove that all these newly generated fpc's are indeed new, by\nconsidering their clocked BT's. Even so, not all pairs of new fpc's can be\ndiscriminated this way. For that purpose we increase the discrimination power\nby a precision of the clock notion that we call `atomic clock'.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 14:32:15 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 08:34:52 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Endrullis", "Joerg", "", "Vrije Universiteit Amsterdam"], ["Hendriks", "Dimitri", "", "Vrije Universiteit Amsterdam"], ["Klop", "Jan Willem", "", "Vrije Universiteit\n  Amsterdam"], ["Polonsky", "Andrew", "", "Vrije Universiteit Amsterdam"]]}, {"id": "1212.0966", "submitter": "Giuseppe Rosolini", "authors": "Maria Emilia Maietti and Giuseppe Rosolini", "title": "Unifying exact completions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the notion of exact completion with respect to an existential\nelementary doctrine. We observe that the forgetful functor from the 2-category\nexact categories to existential elementary doctrines has a left biadjoint that\ncan be obtained as a composite of two others. Finally, we conclude how this\nnotion encompasses both that of the exact completion of a regular category as\nwell as that of the exact completion of a cartesian category with weak\npullbacks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 08:40:29 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Maietti", "Maria Emilia", ""], ["Rosolini", "Giuseppe", ""]]}, {"id": "1212.1089", "submitter": "Francesco Ranzato", "authors": "Francesco Ranzato", "title": "An Efficient Simulation Algorithm on Kripke Structures", "comments": "Conference version appeared in Proceedings of the 38th International\n  Symposium on Mathematical Foundations of Computer Science (MFCS'13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of algorithms for computing the simulation preorder (and\nequivalence) on Kripke structures are available. Let Sigma denote the state\nspace, -> the transition relation and Psim the partition of Sigma induced by\nsimulation equivalence. While some algorithms are designed to reach the best\nspace bounds, whose dominating additive term is |Psim|^2, other algorithms are\ndevised to attain the best time complexity O(|Psim||->|). We present a novel\nsimulation algorithm which is both space and time efficient: it runs in\nO(|Psim|^2 log|Psim| + |Sigma|log|Sigma|) space and O(|Psim||->|log|Sigma|)\ntime. Our simulation algorithm thus reaches the best space bounds while closely\napproaching the best time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 16:27:16 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2012 11:08:13 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2013 13:51:00 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Ranzato", "Francesco", ""]]}, {"id": "1212.1251", "submitter": "Ralf Wimmer", "authors": "Ernst Moritz Hahn and Holger Hermanns and Ralf Wimmer and Bernd Becker", "title": "Transient Reward Approximation for Continuous-Time Markov Chains", "comments": "Accepted for publication in IEEE Transactions on Reliability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the analysis of very large continuous-time Markov chains\n(CTMCs) with many distinct rates. Such models arise naturally in the context of\nreliability analysis, e.g., of computer network performability analysis, of\npower grids, of computer virus vulnerability, and in the study of crowd\ndynamics. We use abstraction techniques together with novel algorithms for the\ncomputation of bounds on the expected final and accumulated rewards in\ncontinuous-time Markov decision processes (CTMDPs). These ingredients are\ncombined in a partly symbolic and partly explicit (symblicit) analysis\napproach. In particular, we circumvent the use of multi-terminal decision\ndiagrams, because the latter do not work well if facing a large number of\ndifferent rates. We demonstrate the practical applicability and efficiency of\nthe approach on two case studies.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 07:27:29 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2015 11:06:26 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Hermanns", "Holger", ""], ["Wimmer", "Ralf", ""], ["Becker", "Bernd", ""]]}, {"id": "1212.1485", "submitter": "Kshitij Bansal", "authors": "Kshitij Bansal (1) and St\\'ephane Demri (1 and 2) ((1) New York\n  University, USA, (2) LSV, CNRS, France)", "title": "A Note on the Complexity of Model-Checking Bounded Multi-Pushdown\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "NYU TR2012-949", "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we provide complexity characterizations of model checking\nmulti-pushdown systems. Multi-pushdown systems model recursive concurrent\nprograms in which any sequential process has a finite control. We consider\nthree standard notions for boundedness: context boundedness, phase boundedness\nand stack ordering. The logical formalism is a linear-time temporal logic\nextending well-known logic CaRet but dedicated to multi-pushdown systems in\nwhich abstract operators (related to calls and returns) such as those for\nnext-time and until are parameterized by stacks. We show that the problem is\nEXPTIME-complete for context-bounded runs and unary encoding of the number of\ncontext switches; we also prove that the problem is 2EXPTIME-complete for\nphase-bounded runs and unary encoding of the number of phase switches. In both\ncases, the value k is given as an input (whence it is not a constant of the\nmodel-checking problem), which makes a substantial difference in the\ncomplexity. In certain cases, our results improve previous complexity results.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 22:02:22 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Bansal", "Kshitij", "", "1 and 2"], ["Demri", "St\u00e9phane", "", "1 and 2"]]}, {"id": "1212.1548", "submitter": "Frank D. Valencia", "authors": "Andr\\'es Aristiz\\'abal (INRIA Saclay - Ile de France, LIX), Filippo\n  Bonchi (LIP), Luis Pino (INRIA Saclay - Ile de France), Frank D. Valencia\n  (INRIA Saclay - Ile de France, LIX)", "title": "Partition Refinement for Bisimilarity in CCP", "comments": "27th ACM Symposium On Applied Computing, Trento : Italy (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saraswat's concurrent constraint programming (ccp) is a mature formalism for\nmodeling processes (or programs) that interact by telling and asking\nconstraints in a global medium, called the store. Bisimilarity is a standard\nbehavioural equivalence in concurrency theory, but a well-behaved notion of\nbisimilarity for ccp has been proposed only recently. When the state space of a\nsystem is finite, the ordinary notion of bisimilarity can be computed via the\nwell-known partition refinement algorithm, but unfortunately, this algorithm\ndoes not work for ccp bisimilarity. In this paper, we propose a variation of\nthe partition refinement algorithm for verifying ccp bisimilarity. To the best\nof our knowledge this is the first work providing for the automatic\nverification of program equivalence for ccp\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 07:28:30 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Aristiz\u00e1bal", "Andr\u00e9s", "", "INRIA Saclay - Ile de France, LIX"], ["Bonchi", "Filippo", "", "LIP"], ["Pino", "Luis", "", "INRIA Saclay - Ile de France"], ["Valencia", "Frank D.", "", "INRIA Saclay - Ile de France, LIX"]]}, {"id": "1212.1734", "submitter": "Baltasar Tranc\\'on y Widemann", "authors": "Baltasar Tranc\\'on y Widemann", "title": "Systematic Construction of Temporal Logics for Dynamical Systems via\n  Coalgebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal logics are an obvious high-level descriptive companion formalism to\ndynamical systems which model behavior as deterministic evolution of state over\ntime. A wide variety of distinct temporal logics applicable to dynamical\nsystems exists, and each candidate has its own pragmatic justification. Here, a\nsystematic approach to the construction of temporal logics for dynamical\nsystems is proposed: Firstly, it is noted that dynamical systems can be seen as\ncoalgebras in various ways. Secondly, a straightforward standard construction\nof modal logics out of coalgebras, namely Moss's coalgebraic logic, is applied.\nLastly, the resulting systems are characterized with respect to the temporal\nproperties they express.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 22:47:24 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Widemann", "Baltasar Tranc\u00f3n y", ""]]}, {"id": "1212.2154", "submitter": "Yongming Li", "authors": "Yongming Li, Manfred Droste and Lihui Lei", "title": "Model-Checking of Linear-Time Properties in Multi-Valued Systems", "comments": "50 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study model-checking of linear-time properties in\nmulti-valued systems. Safety property, invariant property, liveness property,\npersistence and dual-persistence properties in multi-valued logic systems are\nintroduced. Some algorithms related to the above multi-valued linear-time\nproperties are discussed. The verification of multi-valued regular safety\nproperties and multi-valued $\\omega$-regular properties using lattice-valued\nautomata are thoroughly studied. Since the law of non-contradiction (i.e.,\n$a\\wedge \\neg a=0$) and the law of excluded-middle (i.e., $a\\vee \\neg a=1$) do\nnot hold in multi-valued logic, the linear-time properties introduced in this\npaper have the new forms compared to those in classical logic. Compared to\nthose classical model checking methods, our methods to multi-valued model\nchecking are more directly accordingly. A new form of multi-valued model\nchecking with membership degree is also introduced. In particular, we show that\nmulti-valued model-checking can be reduced to the classical model checking. The\nrelated verification algorithms are also presented. Some illustrative examples\nand case study are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2012 08:26:11 GMT"}, {"version": "v2", "created": "Sun, 25 Sep 2016 02:59:13 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Li", "Yongming", ""], ["Droste", "Manfred", ""], ["Lei", "Lihui", ""]]}, {"id": "1212.2257", "submitter": "Yan Zhang", "authors": "Yan Zhang, Zhaohui Zhu, Jinjin Zhang, Yong Zhou", "title": "A Process Calculus with Logical Operators", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to combine operational and logical styles of specifications in one\nunified framework, the notion of logic labelled transition systems (Logic LTS,\nfor short) has been presented and explored by L\\\"{u}ttgen and Vogler in [TCS\n373(1-2):19-40; Inform. & Comput. 208:845-867]. In contrast with usual LTS, two\nlogical constructors $\\wedge$ and $\\vee$ over Logic LTSs are introduced to\ndescribe logical combinations of specifications. Hitherto such framework has\nbeen dealt with in considerable depth, however, process algebraic style way has\nnot yet been involved and the axiomatization of constructors over Logic LTSs is\nabsent. This paper tries to develop L\\\"{u}ttgen and Vogler's work along this\ndirection. We will present a process calculus for Logic LTSs (CLL, for short).\nThe language CLL is explored in detail from two different but equivalent views.\nBased on behavioral view, the notion of ready simulation is adopted to\nformalize the refinement relation, and the behavioral theory is developed.\nBased on proof-theoretic view, a sound and ground-complete axiomatic system for\nCLL is provided, which captures operators in CLL through (in)equational laws.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 00:21:51 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Zhang", "Yan", ""], ["Zhu", "Zhaohui", ""], ["Zhang", "Jinjin", ""], ["Zhou", "Yong", ""]]}, {"id": "1212.2350", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (LIAMA, LCS), Kim Quyen Ly (LIAMA, LCS)", "title": "Automated verification of termination certificates", "comments": null, "journal-ref": "15th National Symposium of Selected ICT Problems (2012)", "doi": null, "report-no": null, "categories": "cs.LO cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to increase user confidence, many automated theorem provers provide\ncertificates that can be independently verified. In this paper, we report on\nour progress in developing a standalone tool for checking the correctness of\ncertificates for the termination of term rewrite systems, and formally proving\nits correctness in the proof assistant Coq. To this end, we use the extraction\nmechanism of Coq and the library on rewriting theory and termination called\nCoLoR.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 09:24:46 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA, LCS"], ["Ly", "Kim Quyen", "", "LIAMA, LCS"]]}, {"id": "1212.2747", "submitter": "Oleg Verbitsky", "authors": "Christoph Berkholz, Andreas Krebs, and Oleg Verbitsky", "title": "Bounds for the quantifier depth in finite-variable logics: Alternation\n  hierarchy", "comments": "28 pages, 7 figures. Section 7 is expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two structures $G$ and $H$ distinguishable in $\\fo k$ (first-order\nlogic with $k$ variables), let $A^k(G,H)$ denote the minimum alternation depth\nof a $\\fo k$ formula distinguishing $G$ from $H$. Let $A^k(n)$ be the maximum\nvalue of $A^k(G,H)$ over $n$-element structures. We prove the strictness of the\nquantifier alternation hierarchy of $\\fo 2$ in a strong quantitative form,\nnamely $A^2(n)\\ge n/8-2$, which is tight up to a constant factor. For each\n$k\\ge2$, it holds that $A^k(n)>\\log_{k+1}n-2$ even over colored trees, which is\nalso tight up to a constant factor if $k\\ge3$. For $k\\ge 3$ the last lower\nbound holds also over uncolored trees, while the alternation hierarchy of $\\fo\n2$ collapses even over all uncolored graphs.\n  We also show examples of colored graphs $G$ and $H$ on $n$ vertices that can\nbe distinguished in $\\fo 2$ much more succinctly if the alternation number is\nincreased just by one: while in $\\Sigma_{i}$ it is possible to distinguish $G$\nfrom $H$ with bounded quantifier depth, in $\\Pi_{i}$ this requires quantifier\ndepth $\\Omega(n^2)$. The quadratic lower bound is best possible here because,\nif $G$ and $H$ can be distinguished in $\\fo k$ with $i$ quantifier\nalternations, this can be done with quantifier depth $n^{2k-2}$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 09:43:17 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2013 14:48:31 GMT"}, {"version": "v3", "created": "Fri, 17 May 2013 09:38:25 GMT"}, {"version": "v4", "created": "Thu, 8 Aug 2013 09:20:54 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Berkholz", "Christoph", ""], ["Krebs", "Andreas", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1212.2789", "submitter": "Changil Choe", "authors": "Changil Choe, Hyejong Hong, Kukhwan Kim", "title": "Formal Design and Verification of N-M Switching Control System", "comments": null, "journal-ref": "Romanian Journal of Mathematics and Computer Science, Vol. 2, No.\n  2, 2012, 36-43", "doi": null, "report-no": "KISU-MATH-2012-E-R-008", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production factories in which stable voltage is critical, e.g.,\nelectro-plating factory, require constantly stable voltage to minimize loss by\nadjusting incoming voltage in real time, even if low-quality electricity is\nsupplied from outside. To solve such problem often being raised from the\nfactories located in the area with unstable electricity supply, we designed N-M\nswitching control system and verified its correctness using LTL model checking\ntechnique.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 12:26:25 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Choe", "Changil", ""], ["Hong", "Hyejong", ""], ["Kim", "Kukhwan", ""]]}, {"id": "1212.3217", "submitter": "Joost Joosten", "authors": "J. J. Joosten", "title": "Complexity fits the fittest", "comments": "arXiv admin note: substantial text overlap with arXiv:1211.1878", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we shall relate computational complexity to the principle of\nnatural selection. We shall do this by giving a philosophical account of\ncomplexity versus universality. It seems sustainable to equate universal\nsystems to complex systems or at least to potentially complex systems. Post's\nproblem on the existence of (natural) intermediate degrees (between decidable\nand universal RE) then finds its analog in the Principle of Computional\nEquivalence (PCE). In this paper we address possible driving forces --if any--\nbehind PCE. Both the natural aspects as well as the cognitive ones are\ninvestigated. We postulate a principle GNS that we call the Generalized Natural\nSelection principle that together with the Church-Turing thesis is seen to be\nin close correspondence to a weak version of PCE. Next, we view our cognitive\ntoolkit in an evolutionary light and postulate a principle in analogy with\nFodor's language principle. In the final part of the paper we reflect on ways\nto provide circumstantial evidence for GNS by means of theorems, experiments\nor, simulations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 11:49:44 GMT"}], "update_date": "2012-12-14", "authors_parsed": [["Joosten", "J. J.", ""]]}, {"id": "1212.3251", "submitter": "Tony Tan", "authors": "Tony Tan", "title": "Automata for two-variable logic over trees with ordered data values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data trees are trees in which each node, besides carrying a label from a\nfinite alphabet, also carries a data value from an infinite domain. They have\nbeen used as an abstraction model for reasoning tasks on {XML} and\nverification. However, most existing approaches consider the case where only\nequality test can be performed on the data values.\n  In this paper we study data trees in which the data values come from a\nlinearly ordered domain, and in addition to equality test, we can test whether\nthe data value in a node is greater than the one in another node. We introduce\nan automata model for them which we call ordered-data tree automata (ODTA),\nprovide its logical characterisation, and prove that its non-emptiness problem\nis decidable in 3-NEXPTIME. We also show that the two-variable logic on\nunranked trees, studied by Bojanczyk, Muscholl, Schwentick and Segoufin in\n2009, corresponds precisely to a special subclass of this automata model.\n  Then we define a slightly weaker version of ODTA, which we call weak ODTA,\nand provide its logical characterisation. The complexity of the non-emptiness\nproblem drops to NP. However, a number of existing formalisms and models\nstudied in the literature can be captured already by weak ODTA. We also show\nthat the definition of ODTA can be easily modified, to the case where the data\nvalues come from a tree-like partially ordered domain, such as strings.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 18:18:54 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2013 15:54:59 GMT"}], "update_date": "2013-10-07", "authors_parsed": [["Tan", "Tony", ""]]}, {"id": "1212.3357", "submitter": "Andrea Cal\\`i PhD", "authors": "Andrea Cali, Georg Gottlob and Michael Kifer", "title": "Taming the Infinite Chase: Query Answering under Expressive Integrity\n  Constraints", "comments": "Pre-print", "journal-ref": "Journal of Artificial Intelligence Research, vol. 48, pp. 115-174,\n  2013", "doi": "10.1613/jair.3873", "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chase algorithm is a fundamental tool for query evaluation and query\ncontainment under constraints, where the constraints are (sub-classes of)\ntuple-generating dependencies (TGDs) and equality generating depencies (EGDs).\nSo far, most of the research on this topic has focused on cases where the chase\nprocedure terminates, with some notable exceptions. In this paper we take a\ngeneral approach, and we propose large classes of TGDs under which the chase\ndoes not always terminate. Our languages, in particular, are inspired by\nguarded logic: we show that by enforcing syntactic properties on the form of\nthe TGDs, we are able to ensure decidability of the problem of answering\nconjunctive queries despite the non-terminating chase. We provide tight\ncomplexity bounds for the problem of conjunctive query evaluation for several\nclasses of TGDs. We then introduce EGDs, and provide a condition under which\nEGDs do not interact with TGDs, and therefore do not take part in query\nanswering. We show applications of our classes of constraints to the problem of\nanswering conjunctive queries under F-Logic Lite, a recently introduced\nontology language, and under prominent tractable Description Logics languages.\nAll the results in this paper immediately extend to the problem of conjunctive\nquery containment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 22:17:47 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 22:57:37 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Cali", "Andrea", ""], ["Gottlob", "Georg", ""], ["Kifer", "Michael", ""]]}, {"id": "1212.3454", "submitter": "EPTCS", "authors": "Uli Fahrenberg (Irisa / INRIA Rennes, France), Axel Legay (Irisa /\n  INRIA Rennes, France), Claus Thrane (Aalborg University, Denmark)", "title": "Proceedings Quantities in Formal Methods", "comments": null, "journal-ref": "EPTCS 103, 2012", "doi": "10.4204/EPTCS.103", "report-no": null, "categories": "cs.LO cs.FL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Workshop on Quantities in Formal\nMethods, QFM 2012, held in Paris, France on 28 August 2012. The workshop was\naffiliated with the 18th Symposium on Formal Methods, FM 2012. The focus of the\nworkshop was on quantities in modeling, verification, and synthesis. Modern\napplications of formal methods require to reason formally on quantities such as\ntime, resources, or probabilities. Standard formal methods and tools have\ngotten very good at modeling (and verifying) qualitative properties: whether or\nnot certain events will occur. During the last years, these methods and tools\nhave been extended to also cover quantitative aspects, notably leading to tools\nlike e.g. UPPAAL (for real-time systems), PRISM (for probabilistic systems),\nand PHAVer (for hybrid systems). A lot of work remains to be done however\nbefore these tools can be used in the industrial applications at which they are\naiming.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 12:38:37 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Fahrenberg", "Uli", "", "Irisa / INRIA Rennes, France"], ["Legay", "Axel", "", "Irisa /\n  INRIA Rennes, France"], ["Thrane", "Claus", "", "Aalborg University, Denmark"]]}, {"id": "1212.3458", "submitter": "EPTCS", "authors": "Marco Carbone, Ivan Lanese, Alexandra Silva, Ana Sokolova", "title": "Proceedings Fifth Interaction and Concurrency Experience", "comments": "EPTCS 104, 2012", "journal-ref": null, "doi": "10.4204/EPTCS.104", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE'12, the 5th Interaction and\nConcurrency Experience workshop, which was held in Stockholm, Sweden on the\n16th of June 2012 as a satellite event of DisCoTec'12. The topic of ICE'12 was\nDistributed Coordination, Execution Models, and Resilient Interaction. The ICE\nprocedure for paper selection allows for PC members to interact, anonymously,\nwith authors. During the review phase, each submitted paper is published on a\nWiki and associated with a discussion forum whose access is restricted to the\nauthors and to all the PC members not declaring a conflict of interests. The PC\nmembers post comments and questions that the authors reply to. Each paper was\nreviewed by four PC members, and altogether 8 papers were accepted for\npublication. We were proud to host two invited talks, Marcello Bonsangue and\nIchiro Hasuo, whose abstracts are included in this volume together with the\nregular papers.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 12:50:44 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Carbone", "Marco", ""], ["Lanese", "Ivan", ""], ["Silva", "Alexandra", ""], ["Sokolova", "Ana", ""]]}, {"id": "1212.3534", "submitter": "Balder ten Cate", "authors": "Balder ten Cate and V\\'ictor Dalmau", "title": "A note on the product homomorphism problem and CQ-definability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The product homomorphism problem (PHP) takes as input a finite collection of\nrelational structures A1, ..., An and another relational structure B, all over\nthe same schema, and asks whether there is a homomorphism from the direct\nproduct A1 x ... x An to B. This problem is clearly solvable in\nnon-deterministic exponential time. It follows from results in [1] that the\nproblem is NExpTime-complete. The proof, based on a reduction from an\nexponential tiling problem, uses structures of bounded domain size but with\nrelations of unbounded arity. In this note, we provide a self-contained proof\nof NExpTime-hardness of PHP, and we show that it holds already for directed\ngraphs, as well as for structures of bounded arity with a bounded domain size\n(but without a bound on the number of relations). We also present an\napplication to the CQ-definability problem (also known as the PP-definability\nproblem).\n  [1] Ross Willard. Testing expressibility is hard. In David Cohen, editor, CP,\nvolume 6308 of Lecture Notes in Computer Science, pages 9-23. Springer, 2010.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 17:24:34 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Cate", "Balder ten", ""], ["Dalmau", "V\u00edctor", ""]]}, {"id": "1212.3618", "submitter": "EPTCS", "authors": "Ekaterina Komendantskaya (School of Computing, University of Dundee),\n  J\\'onathan Heras (School of Computing, University of Dundee), Gudmund Grov\n  (School of Mathematical and Computer Sciences, Heriot-Watt University)", "title": "Machine Learning in Proof General: Interfacing Interfaces", "comments": "In Proceedings UITP 2012, arXiv:1307.1528", "journal-ref": "EPTCS 118, 2013, pp. 15-41", "doi": "10.4204/EPTCS.118.2", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ML4PG - a machine learning extension for Proof General. It allows\nusers to gather proof statistics related to shapes of goals, sequences of\napplied tactics, and proof tree structures from the libraries of interactive\nhigher-order proofs written in Coq and SSReflect. The gathered data is\nclustered using the state-of-the-art machine learning algorithms available in\nMATLAB and Weka. ML4PG provides automated interfacing between Proof General and\nMATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints\nin the process of interactive proof development.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 21:06:34 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2013 05:19:38 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Komendantskaya", "Ekaterina", "", "School of Computing, University of Dundee"], ["Heras", "J\u00f3nathan", "", "School of Computing, University of Dundee"], ["Grov", "Gudmund", "", "School of Mathematical and Computer Sciences, Heriot-Watt University"]]}, {"id": "1212.3838", "submitter": "Changil Choe", "authors": "Changil Choe, Dang Van Hung, and Song Han", "title": "Towards Approximate Model Checking DC and PDC Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DC has proved to be a promising tool for the specification and verification\nof functional requirements on the design of hard real-time systems. Many works\nwere devoted to develop effective techniques for checking the models of hard\nreal-time systems against DC specifications. DC model checking theory is still\nevolving and yet there is no available tools supporting practical verifications\ndue to the high undecidability of calculus and the great complexity of model\nchecking. Present situation of PDC model checking is much worse than the one of\nDC model checking. In view of the results so far achieved, it is desirable to\ndevelop approximate model checking techniques for DC and PDC specifications.\nThis work was motivated to develop approximate techniques checking automata\nmodels of hard real-time systems for DC and PDC specifications. Unlike previous\nworks which only deal with decidable formulas, we want to develop approximate\ntechniques covering whole DC and PDC formulas. The first results of our work,\nnamely, approximate techniques checking real-time automata models of systems\nfor LDI and PLDI specifications, are described in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 22:08:44 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Choe", "Changil", ""], ["Van Hung", "Dang", ""], ["Han", "Song", ""]]}, {"id": "1212.3870", "submitter": "EPTCS", "authors": "Johannes H\\\"olzl (Technische Universit\\\"at M\\\"unchen), Tobias Nipkow\n  (Technische Universit\\\"at M\\\"unchen)", "title": "Interactive verification of Markov chains: Two distributed protocol case\n  studies", "comments": "In Proceedings QFM 2012, arXiv:1212.3454", "journal-ref": "EPTCS 103, 2012, pp. 17-31", "doi": "10.4204/EPTCS.103.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic model checkers like PRISM only check probabilistic systems of a\nfixed size. To guarantee the desired properties for an arbitrary size,\nmathematical analysis is necessary. We show for two case studies how this can\nbe done in the interactive proof assistant Isabelle/HOL. The first case study\nis a detailed description of how we verified properties of the ZeroConf\nprotocol, a decentral address allocation protocol. The second case study shows\nthe more involved verification of anonymity properties of the Crowds protocol,\nan anonymizing protocol.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:40:35 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["H\u00f6lzl", "Johannes", "", "Technische Universit\u00e4t M\u00fcnchen"], ["Nipkow", "Tobias", "", "Technische Universit\u00e4t M\u00fcnchen"]]}, {"id": "1212.3871", "submitter": "EPTCS", "authors": "Parosh Aziz Abdulla (Uppsala University, Sweden), Mohamed Faouzi Atig\n  (Uppsala University, Sweden), Jari Stenman (Uppsala University, Sweden)", "title": "Adding Time to Pushdown Automata", "comments": "In Proceedings QFM 2012, arXiv:1212.3454", "journal-ref": "EPTCS 103, 2012, pp. 1-16", "doi": "10.4204/EPTCS.103.1", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial, we illustrate through examples how we can combine two\nclassical models, namely those of pushdown automata (PDA) and timed automata,\nin order to obtain timed pushdown automata (TPDA). Furthermore, we describe how\nthe reachability problem for TPDAs can be reduced to the reachability problem\nfor PDAs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:40:37 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Abdulla", "Parosh Aziz", "", "Uppsala University, Sweden"], ["Atig", "Mohamed Faouzi", "", "Uppsala University, Sweden"], ["Stenman", "Jari", "", "Uppsala University, Sweden"]]}, {"id": "1212.3872", "submitter": "EPTCS", "authors": "Kim G. Larsen (Department of Computer Science, Aalborg University),\n  Radu Mardare (Department of Computer Science, Aalborg University), Claus\n  Thrane (Department of Computer Science, Aalborg University)", "title": "Parameterized Metatheory for Continuous Markovian Logic", "comments": "In Proceedings QFM 2012, arXiv:1212.3454", "journal-ref": "EPTCS 103, 2012, pp. 33-47", "doi": "10.4204/EPTCS.103.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that a classic metalogical framework, including all Boolean\noperators, can be used to support the development of a metric behavioural\ntheory for Markov processes. Previously, only intuitionistic frameworks or\nframeworks without negation and logical implication have been developed to\nfulfill this task. The focus of this paper is on continuous Markovian logic\n(CML), a logic that characterizes stochastic bisimulation of Markov processes\nwith an arbitrary measurable state space and continuous-time transitions. For a\nparameter epsilon>0 interpreted as observational error, we introduce an\nepsilon-parameterized metatheory for CML: we define the concepts of\nepsilon-satisfiability and epsilon-provability related by a sound and complete\naxiomatization and prove a series of \"parameterized\" metatheorems including\ndecidability, weak completeness and finite model property. We also prove\nresults regarding the relations between metalogical concepts defined for\ndifferent parameters. Using this framework, we can characterize both the\nstochastic bisimulation relation and various observational preorders based on\nbehavioural pseudometrics. The main contribution of this paper is proving that\nall these analyses can actually be done using a unified complete Boolean\nframework. This extends the state of the art in this field, since the related\nworks only propose intuitionistic contexts that limit, for instance, the use of\nthe Boolean logical implication.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:40:40 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Larsen", "Kim G.", "", "Department of Computer Science, Aalborg University"], ["Mardare", "Radu", "", "Department of Computer Science, Aalborg University"], ["Thrane", "Claus", "", "Department of Computer Science, Aalborg University"]]}, {"id": "1212.3873", "submitter": "EPTCS", "authors": "Hua Mao (AAU), Yingke Chen (AAU), Manfred Jaeger (AAU), Thomas D.\n  Nielsen (AAU), Kim G. Larsen (AAU), Brian Nielsen (AAU)", "title": "Learning Markov Decision Processes for Model Checking", "comments": "In Proceedings QFM 2012, arXiv:1212.3454", "journal-ref": "EPTCS 103, 2012, pp. 49-63", "doi": "10.4204/EPTCS.103.6", "report-no": null, "categories": "cs.LG cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing an accurate system model for formal model verification can be\nboth resource demanding and time-consuming. To alleviate this shortcoming,\nalgorithms have been proposed for automatically learning system models based on\nobserved system behaviors. In this paper we extend the algorithm on learning\nprobabilistic automata to reactive systems, where the observed system behavior\nis in the form of alternating sequences of inputs and outputs. We propose an\nalgorithm for automatically learning a deterministic labeled Markov decision\nprocess model from the observed behavior of a reactive system. The proposed\nlearning algorithm is adapted from algorithms for learning deterministic\nprobabilistic finite automata, and extended to include both probabilistic and\nnondeterministic transitions. The algorithm is empirically analyzed and\nevaluated by learning system models of slot machines. The evaluation is\nperformed by analyzing the probabilistic linear temporal logic properties of\nthe system as well as by analyzing the schedulers, in particular the optimal\nschedulers, induced by the learned models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:40:47 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Mao", "Hua", "", "AAU"], ["Chen", "Yingke", "", "AAU"], ["Jaeger", "Manfred", "", "AAU"], ["Nielsen", "Thomas D.", "", "AAU"], ["Larsen", "Kim G.", "", "AAU"], ["Nielsen", "Brian", "", "AAU"]]}, {"id": "1212.3874", "submitter": "EPTCS", "authors": "Andr\\'es Aristiz\\'abal (CNRS/DGA and LIX \\'Ecole Polytechnique de\n  Paris), Filippo Bonchi (ENS Lyon, Universit\\'e de Lyon, LIP), Luis Pino\n  (INRIA/DGA and LIX \\'Ecole Polytechnique de Paris), Frank Valencia (CNRS and\n  LIX \\'Ecole Polytechnique de Paris)", "title": "Reducing Weak to Strong Bisimilarity in CCP", "comments": "In Proceedings ICE 2012, arXiv:1212.3458. arXiv admin note: text\n  overlap with arXiv:1212.1548", "journal-ref": "EPTCS 104, 2012, pp. 2-16", "doi": "10.4204/EPTCS.104.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent constraint programming (ccp) is a well-established model for\nconcurrency that singles out the fundamental aspects of asynchronous systems\nwhose agents (or processes) evolve by posting and querying (partial)\ninformation in a global medium. Bisimilarity is a standard behavioural\nequivalence in concurrency theory. However, only recently a well-behaved notion\nof bisimilarity for ccp, and a ccp partition refinement algorithm for deciding\nthe strong version of this equivalence have been proposed. Weak bisimiliarity\nis a central behavioural equivalence in process calculi and it is obtained from\nthe strong case by taking into account only the actions that are observable in\nthe system. Typically, the standard partition refinement can also be used for\ndeciding weak bisimilarity simply by using Milner's reduction from weak to\nstrong bisimilarity; a technique referred to as saturation. In this paper we\ndemonstrate that, because of its involved labeled transitions, the\nabove-mentioned saturation technique does not work for ccp. We give an\nalternative reduction from weak ccp bisimilarity to the strong one that allows\nus to use the ccp partition refinement algorithm for deciding this equivalence.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:42:03 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Aristiz\u00e1bal", "Andr\u00e9s", "", "CNRS/DGA and LIX \u00c9cole Polytechnique de\n  Paris"], ["Bonchi", "Filippo", "", "ENS Lyon, Universit\u00e9 de Lyon, LIP"], ["Pino", "Luis", "", "INRIA/DGA and LIX \u00c9cole Polytechnique de Paris"], ["Valencia", "Frank", "", "CNRS and\n  LIX \u00c9cole Polytechnique de Paris"]]}, {"id": "1212.3875", "submitter": "EPTCS", "authors": "\\'Etienne Lozes (Universit\\\"at Kassel, Germany), Jules Villard\n  (University College London, UK)", "title": "Shared Contract-Obedient Endpoints", "comments": "In Proceedings ICE 2012, arXiv:1212.3458", "journal-ref": "EPTCS 104, 2012, pp. 17-31", "doi": "10.4204/EPTCS.104.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing verification techniques for message-passing programs\nsuppose either that channel endpoints are used in a linear fashion, where at\nmost one thread may send or receive from an endpoint at any given time, or that\nendpoints may be used arbitrarily by any number of threads. The former approach\nusually forbids the sharing of channels while the latter limits what is\nprovable about programs. In this paper we propose a midpoint between these\ntechniques by extending a proof system based on separation logic to allow\nsharing of endpoints. We identify two independent mechanisms for supporting\nsharing: an extension of fractional shares to endpoints, and a new technique\nbased on what we call reflexive ownership transfer. We demonstrate on a number\nof examples that a linear treatment of sharing is possible.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:42:11 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Lozes", "\u00c9tienne", "", "Universit\u00e4t Kassel, Germany"], ["Villard", "Jules", "", "University College London, UK"]]}, {"id": "1212.3877", "submitter": "EPTCS", "authors": "Simon Bliudze (Ecole Polytechnique F\\'ed\\'erale de Lausanne)", "title": "Towards a Theory of Glue", "comments": "In Proceedings ICE 2012, arXiv:1212.3458", "journal-ref": "EPTCS 104, 2012, pp. 48-66", "doi": "10.4204/EPTCS.104.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study the notions of behaviour type and composition operator\nmaking a first step towards the definition of a formal framework for studying\nbehaviour composition in a setting sufficiently general to provide insight into\nhow the component-based systems should be modelled and compared. We illustrate\nthe proposed notions on classical examples (Traces, Labelled Transition Systems\nand Coalgebras). Finally, the definition of memoryless glue operators, takes us\none step closer to a formal understanding of the separation of concerns\nprinciple stipulating that computational aspects of a system should be\nlocalised within its atomic components, whereas coordination layer responsible\nfor managing concurrency should be realised by memoryless glue operators.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:42:23 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Bliudze", "Simon", "", "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne"]]}, {"id": "1212.3878", "submitter": "EPTCS", "authors": "Dan R. Ghica (University of Birmingham), Zaid Al-Zobaidi (University\n  of Birmingham)", "title": "Coherent Minimisation: Towards efficient tamper-proof compilation", "comments": "In Proceedings ICE 2012, arXiv:1212.3458", "journal-ref": "EPTCS 104, 2012, pp. 83-98", "doi": "10.4204/EPTCS.104.8", "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automata representing game-semantic models of programs are meant to operate\nin environments whose input-output behaviour is constrained by the rules of a\ngame. This can lead to a notion of equivalence between states which is weaker\nthan the conventional notion of bisimulation, since not all actions are\navailable to the environment. An environment which attempts to break the rules\nof the game is, effectively, mounting a low-level attack against a system. In\nthis paper we show how (and why) to enforce game rules in games-based hardware\nsynthesis and how to use this weaker notion of equivalence, called coherent\nequivalence, to aggressively minimise automata.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:42:40 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Ghica", "Dan R.", "", "University of Birmingham"], ["Al-Zobaidi", "Zaid", "", "University\n  of Birmingham"]]}, {"id": "1212.3879", "submitter": "EPTCS", "authors": "Jurriaan Rot (LIACS - Leiden University, The Netherlands), Irina\n  M\\u{a}riuca As\\u{a}voae (Alexandru Ioan Cuza University, Romania), Frank de\n  Boer (Centrum Wiskunde en Informatica (CWI), The Netherlands), Marcello M.\n  Bonsangue (LIACS - Leiden University, The Netherlands), Dorel Lucanu\n  (Alexandru Ioan Cuza University, Romania)", "title": "Interacting via the Heap in the Presence of Recursion", "comments": "In Proceedings ICE 2012, arXiv:1212.3458", "journal-ref": "EPTCS 104, 2012, pp. 99-113", "doi": "10.4204/EPTCS.104.9", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all modern imperative programming languages include operations for\ndynamically manipulating the heap, for example by allocating and deallocating\nobjects, and by updating reference fields. In the presence of recursive\nprocedures and local variables the interactions of a program with the heap can\nbecome rather complex, as an unbounded number of objects can be allocated\neither on the call stack using local variables, or, anonymously, on the heap\nusing reference fields. As such a static analysis is, in general, undecidable.\n  In this paper we study the verification of recursive programs with unbounded\nallocation of objects, in a simple imperative language for heap manipulation.\nWe present an improved semantics for this language, using an abstraction that\nis precise. For any program with a bounded visible heap, meaning that the\nnumber of objects reachable from variables at any point of execution is\nbounded, this abstraction is a finitary representation of its behaviour, even\nthough an unbounded number of objects can appear in the state. As a\nconsequence, for such programs model checking is decidable.\n  Finally we introduce a specification language for temporal properties of the\nheap, and discuss model checking these properties against heap-manipulating\nprograms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:42:47 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Rot", "Jurriaan", "", "LIACS - Leiden University, The Netherlands"], ["As\u0103voae", "Irina M\u0103riuca", "", "Alexandru Ioan Cuza University, Romania"], ["de Boer", "Frank", "", "Centrum Wiskunde en Informatica"], ["Bonsangue", "Marcello M.", "", "LIACS - Leiden University, The Netherlands"], ["Lucanu", "Dorel", "", "Alexandru Ioan Cuza University, Romania"]]}, {"id": "1212.3884", "submitter": "Viktor Schuppan", "authors": "Viktor Schuppan", "title": "Extracting Unsatisfiable Cores for LTL via Temporal Resolution", "comments": "Full version of an Acta Informatica paper", "journal-ref": null, "doi": "10.1007/s00236-015-0242-1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsatisfiable cores (UCs) are a well established means for debugging in a\ndeclarative setting. Still, there are few tools that perform automated\nextraction of UCs for LTL. Existing tools compute a UC as an unsatisfiable\nsubset of the set of top-level conjuncts of an LTL formula. Using resolution\ngraphs to extract UCs is common in other domains such as SAT. In this article\nwe construct and optimize resolution graphs for temporal resolution as\nimplemented in the temporal resolution-based solver TRP++, and we use them to\nextract UCs for propositional LTL. The resulting UCs are more fine-grained than\nthe UCs obtained from existing tools because UC extraction also simplifies\ntop-level conjuncts instead of treating them as atomic entities. For example,\ngiven an unsatisfiable LTL formula of the form $\\phi \\equiv ({\\bf G} \\psi)\n\\wedge {\\bf F} \\psi'$ existing tools return $\\phi$ as a UC irrespective of the\ncomplexity of $\\psi$ and $\\psi'$, whereas the approach presented in this\narticle continues to remove parts not required for unsatisfiability inside\n$\\psi$ and $\\psi'$. Our approach also identifies groups of occurrences of a\nproposition that do not interact in a proof of unsatisfiability. We implement\nour approach in TRP++. Our experimental evaluation demonstrates that our\napproach (i) extracts UCs that are often significantly smaller than the input\nformula with an acceptable overhead and (ii) produces more fine-grained UCs\nthan competing tools while remaining at least competitive in terms of run time\nand memory usage. The source code of our tool is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 04:47:46 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 00:56:05 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Schuppan", "Viktor", ""]]}, {"id": "1212.4179", "submitter": "Anya Yermakova", "authors": "Anya Yermakova and Alexandru Baltag", "title": "A Dynamic-Epistemic Logic for Mobile Structured Agents", "comments": "This paper was presented at ECAL'11 and later published in the book\n  Integral Biomathics: Tracing the Road to Reality: Results from the First Year\n  Project Activities of the INtegral BIOmathics Support Action (INBIOSA)", "journal-ref": "Integral Biomathics (2012) 129-141", "doi": null, "report-no": null, "categories": "cs.LO math.LO q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent systems have been studied in various contexts of both application\nand theory. We take Dynamic Epistemic Logic (DEL), one of the formalisms\ndesigned to reason about such systems, as the foundation of the language we\nwill build.\n  BioAmbient calculus is an extension of \\pi-calculus, developed largely for\napplications to biomolecular systems. It deals with ambients and their ability\nto communicate and to execute concurrent processes while moving.\n  In this paper we combine the formalism of Dynamic Epistemic Logic together\nwith the formalism of BioAmbient Calculus in order to reason about knowledge\nmaintained and gained upon process transitions. The motivation lies in\ndeveloping a language that captures locally available information through\nassignment of knowledge, with potential application to biological systems as\nwell as social, virtual, and others.\n  We replace the ambients of BioAmbient Calculus with agents, to which we\nattribute knowledge, and explore the parallels of this treatment. The resulting\nlogic describes the information flow governing mobile structured agents,\norganized hierarchically, whose architecture (and local information) may change\ndue to actions such as communication, merging (of two agents), entering (of an\nagent into the inner structure of another agent) and exiting (of an agent from\nthe structure of another). We show how the main axioms of DEL must be altered\nto accommodate the informational effects of the agents' dynamic architecture.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 22:15:44 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Yermakova", "Anya", ""], ["Baltag", "Alexandru", ""]]}, {"id": "1212.4288", "submitter": "Uli Fahrenberg", "authors": "Beno\\^it Delahaye (Universit\\'e de Nantes, France), Uli Fahrenberg\n  (Inria / IRISA Rennes, France), Kim G. Larsen (Aalborg University, Denmark),\n  Axel Legay (Inria / IRISA Rennes, France)", "title": "Refinement and Difference for Probabilistic Automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August\n  26, 2014) lmcs:942", "doi": "10.2168/LMCS-10(3:11)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a difference operator for stochastic systems whose\nspecifications are represented by Abstract Probabilistic Automata (APAs). In\nthe case refinement fails between two specifications, the target of this\noperator is to produce a specification APA that represents all witness PAs of\nthis failure. Our contribution is an algorithm that allows to approximate the\ndifference of two APAs with arbitrary precision. Our technique relies on new\nquantitative notions of distances between APAs used to assess convergence of\nthe approximations, as well as on an in-depth inspection of the refinement\nrelation for APAs. The procedure is effective and not more complex to implement\nthan refinement checking.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 10:11:25 GMT"}, {"version": "v2", "created": "Sat, 24 May 2014 10:28:04 GMT"}, {"version": "v3", "created": "Mon, 25 Aug 2014 11:00:38 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Delahaye", "Beno\u00eet", "", "Universit\u00e9 de Nantes, France"], ["Fahrenberg", "Uli", "", "Inria / IRISA Rennes, France"], ["Larsen", "Kim G.", "", "Aalborg University, Denmark"], ["Legay", "Axel", "", "Inria / IRISA Rennes, France"]]}, {"id": "1212.4444", "submitter": "EPTCS", "authors": "Kyriakos Poyias, Emilio Tuosto", "title": "Enforcing Architectural Styles in Presence of Unexpected Distributed\n  Reconfigurations", "comments": "In Proceedings ICE 2012, arXiv:1212.3458", "journal-ref": "EPTCS 104, 2012, pp. 67-82", "doi": "10.4204/EPTCS.104.7", "report-no": null, "categories": "cs.LO cs.DC cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectural Design Rewriting (ADR, for short) is a rule-based formal\nframework for modelling the evolution of architectures of distributed systems.\nRules allow ADR graphs to be refined. After equipping ADR with a simple logic,\nwe equip rules with pre- and post-conditions; the former constraints the\napplicability of the rules while the later specifies properties of the\nresulting graphs. We give an algorithm to compute the weakest pre-condition out\nof a rule and its post-condition. On top of this algorithm, we design a simple\nmethodology that allows us to select which rules can be applied at the\narchitectural level to reconfigure a system so to regain its architectural\nstyle when it becomes compromised by unexpected run-time reconfigurations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:42:30 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Poyias", "Kyriakos", ""], ["Tuosto", "Emilio", ""]]}, {"id": "1212.4483", "submitter": "Luca Roversi", "authors": "Luca Roversi", "title": "Extending a system in the calculus of structures with a self-dual\n  quantifier", "comments": "29 pages", "journal-ref": null, "doi": "10.1093/logcom/exu033", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recall that SBV, a proof system developed under the methodology of deep\ninference, extends multiplicative linear logic with the self-dual\nnon-commutative logical operator Seq. We introduce SBVQ that extends SBV by\nadding the self-dual quantifier Sdq. The system SBVQ is consistent because we\nprove that (the analogous of) cut elimination holds for it. Its new logical\noperator Sdq operationally behaves as a binder, in a way that the interplay\nbetween Seq, and Sdq can model {\\beta}-reduction of linear {\\lambda}-calculus\ninside the cut-free subsystem BVQ of SBVQ. The long term aim is to keep\ndeveloping a programme whose goal is to give pure logical accounts of\ncomputational primitives under the proof-search-as-computation analogy, by\nmeans of minimal, and incremental extensions of SBV.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 20:45:10 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Roversi", "Luca", ""]]}, {"id": "1212.4650", "submitter": "Simone Fulvio Rollini", "authors": "Arie Gurfinkel and Simone Fulvio Rollini and Natasha Sharygina", "title": "Interpolation Properties and SAT-based Model Checking", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-02444-8_19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Craig interpolation is a widespread method in verification, with important\napplications such as Predicate Abstraction, CounterExample Guided Abstraction\nRefinement and Lazy Abstraction With Interpolants. Most state-of-the-art model\nchecking techniques based on interpolation require collections of interpolants\nto satisfy particular properties, to which we refer as \"collectives\"; they do\nnot hold in general for all interpolation systems and have to be established\nfor each particular system and verification environment. Nevertheless, no\nsystematic approach exists that correlates the individual interpolation systems\nand compares the necessary collectives. This paper proposes a uniform\nframework, which encompasses (and generalizes) the most common collectives\nexploited in verification. We use it for a systematic study of the collectives\nand of the constraints they pose on propositional interpolation systems used in\nSAT-based model checking.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 13:10:18 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2013 07:45:57 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Gurfinkel", "Arie", ""], ["Rollini", "Simone Fulvio", ""], ["Sharygina", "Natasha", ""]]}, {"id": "1212.4669", "submitter": "Luca Roversi", "authors": "Luca Roversi", "title": "Communication, and concurrency with logic-based restriction inside a\n  calculus of structures", "comments": "32 pages. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that we can use structural proof theory to refine, or\ngeneralize, existing paradigmatic computational primitives, or to discover new\nones. Under such a point of view we keep developing a programme whose goal is\nestablishing a correspondence between proof-search of a logical system and\ncomputations in a process algebra. We give a purely logical account of a\nprocess algebra operation which strictly includes the behavior of restriction\non actions we find in Milner CCS. This is possible inside a logical system in\nthe Calculus of Structures of Deep Inference endowed with a self-dual\nquantifier. Using proof-search of cut-free proofs of such a logical system we\nshow how to solve reachability problems in a process algebra that subsumes a\nsignificant fragment of Milner CCS.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 14:31:22 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Roversi", "Luca", ""]]}, {"id": "1212.5094", "submitter": "Mohamed El-Zawawy Dr.", "authors": "Mohamed A. El-Zawawy", "title": "Recognition of Logically Related Regions Based Heap Abstraction", "comments": "15 pages", "journal-ref": "Journal of the Egyptian Mathematical Society,Volume 20, Issue 2,\n  July 2012, Pages 64-71", "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel set of algorithms for heap abstraction,\nidentifying logically related regions of the heap. The targeted regions include\nobjects that are part of the same component structure (recursive data\nstructure). The result of the technique outlined in this paper has the form of\na compact normal form (an abstract model) that boosts the efficiency of the\nstatic analysis via speeding its convergence. The result of heap abstraction,\ntogether with some properties of data structures, can be used to enable program\noptimizations like static deallocation, pool allocation, region-based garbage\ncollection, and object co-location.\n  More precisely, this paper proposes algorithms for abstracting heap\ncomponents with the layout of a singly linked list, a binary tree, a cycle, and\na directed acyclic graph. The termination and correctness of these algorithms\nare studied in the paper. Towards presenting the algorithms the paper also\npresents concrete and abstract models for heap representations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 15:46:59 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["El-Zawawy", "Mohamed A.", ""]]}, {"id": "1212.5108", "submitter": "Florent Jacquemard", "authors": "Florent Jacquemard (Inria Paris-Rocquencourt, STMS), Michael\n  Rusinowitch (INRIA Lorraine - LORIA / LIFC)", "title": "Rewrite Closure and CF Hedge Automata", "comments": null, "journal-ref": "7th International Conference on Language and Automata Theory and\n  Application (2013)", "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of hedge automata called bidimensional context-free\nhedge automata. The class of unranked ordered tree languages they recognize is\nshown to be preserved by rewrite closure with inverse-monadic rules. We also\nextend the parameterized rewriting rules used for modeling the W3C XQuery\nUpdate Facility in previous works, by the possibility to insert a new parent\nnode above a given node. We show that the rewrite closure of hedge automata\nlanguages with these extended rewriting systems are context-free hedge\nlanguages.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 16:01:21 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Jacquemard", "Florent", "", "Inria Paris-Rocquencourt, STMS"], ["Rusinowitch", "Michael", "", "INRIA Lorraine - LORIA / LIFC"]]}, {"id": "1212.5116", "submitter": "Brijesh Dongol", "authors": "Brijesh Dongol and John Derrick", "title": "Proving linearisability via coarse-grained abstraction", "comments": "37 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearisability has become the standard safety criterion for concurrent data\nstructures ensuring that the effect of a concrete operation takes place after\nthe execution some atomic statement (often referred to as the linearisation\npoint). Identification of linearisation points is a non-trivial task and it is\neven possible for an operation to be linearised by the execution of other\nconcurrent operations. This paper presents a method for verifying\nlinearisability that does not require identification of linearisation points in\nthe concrete code. Instead, we show that the concrete program is a refinement\nof some coarse-grained abstraction. The linearisation points in the abstraction\nare straightforward to identify and the linearisability proof itself is simpler\ndue to the coarse granularity of its atomic statements. The concrete\nfine-grained program is a refinement of the coarse-grained program, and hence\nis also linearisable because every behaviour of the concrete program is a\npossible behaviour its abstraction.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 16:08:36 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Dongol", "Brijesh", ""], ["Derrick", "John", ""]]}, {"id": "1212.5139", "submitter": "Jinjin Zhang", "authors": "Jinjin Zhang and Zhaohui Zhu", "title": "A Modal Characterization of Alternating Approximate Bisimilarity", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, alternating transition systems are adopted to describe control\nsystems with disturbances and their finite abstract systems. In order to\ncapture the equivalence relation between these systems, a notion of alternating\napproximate bisimilarity is introduced. This paper aims to establish a modal\ncharacterization for alternating approximate bisimilarity. Moreover, based on\nthis result, we provide a link between specifications satisfied by the samples\nof control systems with disturbances and their finite abstractions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 06:46:58 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Zhang", "Jinjin", ""], ["Zhu", "Zhaohui", ""]]}, {"id": "1212.5668", "submitter": "Thorsten Wissmann", "authors": "Benedikt Ahrens", "title": "Initial Semantics for Reduction Rules", "comments": "Extended version of arXiv:1206.4547, proves a variant of a result of\n  PhD thesis arXiv:1206.4556", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (March 21,\n  2019) lmcs:5299", "doi": "10.23638/LMCS-15(1:28)2019", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give an algebraic characterization of the syntax and operational semantics\nof a class of simply-typed languages, such as the language PCF: we characterize\nsimply-typed syntax with variable binding and equipped with reduction rules via\na universal property, namely as the initial object of some category of models.\nFor this purpose, we employ techniques developed in two previous works: in the\nfirst work we model syntactic translations between languages over different\nsets of types as initial morphisms in a category of models. In the second work\nwe characterize untyped syntax with reduction rules as initial object in a\ncategory of models. In the present work, we combine the techniques used earlier\nin order to characterize simply-typed syntax with reduction rules as initial\nobject in a category. The universal property yields an operator which allows to\nspecify translations---that are semantically faithful by construction---between\nlanguages over possibly different sets of types.\n  As an example, we upgrade a translation from PCF to the untyped lambda\ncalculus, given in previous work, to account for reduction in the source and\ntarget. Specifically, we specify a reduction semantics in the source and target\nlanguage through suitable rules. By equipping the untyped lambda calculus with\nthe structure of a model of PCF, initiality yields a translation from PCF to\nthe lambda calculus, that is faithful with respect to the reduction semantics\nspecified by the rules.\n  This paper is an extended version of an article published in the proceedings\nof WoLLIC 2012.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2012 08:48:22 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 13:32:12 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 15:26:47 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Ahrens", "Benedikt", ""]]}, {"id": "1212.5692", "submitter": "Vivek Nigam", "authors": "Nick Benton, Martin Hofmann, Vivek Nigam", "title": "Abstract Effects and Proof-Relevant Logical Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel variant of logical relations that maps types not merely\nto partial equivalence relations on values, as is commonly done, but rather to\na proof-relevant generalisation thereof, namely setoids. The objects of a\nsetoid establish that values inhabit semantic types, whilst its morphisms are\nunderstood as proofs of semantic equivalence. The transition to proof-relevance\nsolves two well-known problems caused by the use of existential quantification\nover future worlds in traditional Kripke logical relations: failure of\nadmissibility, and spurious functional dependencies. We illustrate the novel\nformat with two applications: a direct-style validation of Pitts and Stark's\nequivalences for \"new\" and a denotational semantics for a region-based effect\nsystem that supports type abstraction in the sense that only externally visible\neffects need to be tracked; non-observable internal modifications, such as the\nreorganisation of a search tree or lazy initialisation, can count as `pure' or\n`read only'. This `fictional purity' allows clients of a module soundly to\nvalidate more effect-based program equivalences than would be possible with\ntraditional effect systems.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2012 13:54:02 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Benton", "Nick", ""], ["Hofmann", "Martin", ""], ["Nigam", "Vivek", ""]]}, {"id": "1212.5895", "submitter": "Mario Alviano", "authors": "Mario Alviano, Wolfgang Faber, Stefan Woltran", "title": "Complexity of super-coherence problems in ASP", "comments": "22 pages, 1 figure, journal paper", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 339-361", "doi": "10.1017/S147106841300001X", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapting techniques from database theory in order to optimize Answer Set\nProgramming (ASP) systems, and in particular the grounding components of ASP\nsystems, is an important topic in ASP. In recent years, the Magic Set method\nhas received some interest in this setting, and a variant of it, called DMS,\nhas been proposed for ASP. However, this technique has a caveat, because it is\nnot correct (in the sense of being query-equivalent) for all ASP programs. In\nrecent work, a large fragment of ASP programs, referred to as super-coherent\nprograms, has been identified, for which DMS is correct. The fragment contains\nall programs which possess at least one answer set, no matter which set of\nfacts is added to them. Two open question remained: How complex is it to\ndetermine whether a given program is super-coherent? Does the restriction to\nsuper-coherent programs limit the problems that can be solved? Especially the\nfirst question turned out to be quite difficult to answer precisely. In this\npaper, we formally prove that deciding whether a propositional program is\nsuper-coherent is \\Pi^P_3-complete in the disjunctive case, while it is\n\\Pi^P_2-complete for normal programs. The hardness proofs are the difficult\npart in this endeavor: We proceed by characterizing the reductions by the\nmodels and reduct models which the ASP programs should have, and then provide\ninstantiations that meet the given specifications. Concerning the second\nquestion, we show that all relevant ASP reasoning tasks can be transformed into\ntasks over super-coherent programs, even though this transformation is more of\ntheoretical than practical interest.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 11:04:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Alviano", "Mario", ""], ["Faber", "Wolfgang", ""], ["Woltran", "Stefan", ""]]}, {"id": "1212.6183", "submitter": "Xiaojie Deng", "authors": "Xiaojie Deng, Yu Zhang, Yuxin Deng, and Farong Zhong", "title": "The Buffered \\pi-Calculus: A Model for Concurrent Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Message-passing based concurrent languages are widely used in developing\nlarge distributed and coordination systems. This paper presents the buffered\n$\\pi$-calculus --- a variant of the $\\pi$-calculus where channel names are\nclassified into buffered and unbuffered: communication along buffered channels\nis asynchronous, and remains synchronous along unbuffered channels. We show\nthat the buffered $\\pi$-calculus can be fully simulated in the polyadic\n$\\pi$-calculus with respect to strong bisimulation. In contrast to the\n$\\pi$-calculus which is hard to use in practice, the new language enables easy\nand clear modeling of practical concurrent languages. We encode two real-world\nconcurrent languages in the buffered $\\pi$-calculus: the (core) Go language and\nthe (Core) Erlang. Both encodings are fully abstract with respect to weak\nbisimulations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 14:12:03 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Deng", "Xiaojie", ""], ["Zhang", "Yu", ""], ["Deng", "Yuxin", ""], ["Zhong", "Farong", ""]]}, {"id": "1212.6500", "submitter": "Alexander Lauser", "authors": "Manfred Kufleitner and Alexander Lauser", "title": "Quantifier Alternation in Two-Variable First-Order Logic with Successor\n  Is Decidable", "comments": "Accepted at STACS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quantifier alternation hierarchy within two-variable\nfirst-order logic FO^2[<,suc] over finite words with linear order and binary\nsuccessor predicate. We give a single identity of omega-terms for each level of\nthis hierarchy. This shows that it is decidable for a given regular language\nand a non-negative integer m, whether the language is definable by a formula in\nFO^2[<,suc] which has at most m quantifier alternations. We also consider the\nalternation hierarchy of unary temporal logic TL[X,F,Y,P] defined by the\nmaximal number of nested negations. This hierarchy coincides with the\nFO^2[<,suc] alternation hierarchy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 09:56:00 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Kufleitner", "Manfred", ""], ["Lauser", "Alexander", ""]]}, {"id": "1212.6519", "submitter": "Mani A", "authors": "A. Mani", "title": "Dialectics of Knowledge Representation in a Granular Rough Set Theory", "comments": "Enlarged version of Refereed Conference Paper. 18 pp 1 figure. (An\n  extended version is to appear soon)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of rough and definite objects are relatively more determinate\nthan those of granules and granulation in general rough set theory (RST) [1].\nRepresentation of rough objects can however depend on the dialectical relation\nbetween granulation and definiteness. In this research, we make this exact in\nthe context of RST over proto-transitive approximation spaces. This approach\ncan be directly extended to many other types of RST. These are used for\nformulating an extended concept of knowledge interpretation (KI)(relative the\nsituation for classical RST) and the problem of knowledge representation (KR)\nis solved. These will be of direct interest in granular KR in RST as developed\nby the present author [2] and of rough objects in general. In [3], these have\nalready been used for five different semantics by the present author. This is\nan extended version of [4] with key examples and more results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 14:08:00 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2013 09:03:41 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1212.6567", "submitter": "Andr", "authors": "Martin Grohe (RWTH Aachen University, Germany), Berit Gru{\\ss}ien\n  (Humboldt-Universit\\\"at zu Berlin), Andr\\'e Hernich (Humboldt-Universit\\\"at\n  zu Berlin), Bastian Laubner (Humboldt-Universit\\\"at zu Berlin)", "title": "L-Recursion and a new Logic for Logarithmic Space", "comments": "44 pages, 10 figures. A preliminary version of this article appeared\n  in the Proceedings of the 25th International Workshop on Computer Science\n  Logic (CSL '11)", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 1 (March 13,\n  2013) lmcs:938", "doi": "10.2168/LMCS-9(1:11)2013", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend first-order logic with counting by a new operator that allows it to\nformalise a limited form of recursion which can be evaluated in logarithmic\nspace. The resulting logic LREC has a data complexity in LOGSPACE, and it\ndefines LOGSPACE-complete problems like deterministic reachability and Boolean\nformula evaluation. We prove that LREC is strictly more expressive than\ndeterministic transitive closure logic with counting and incomparable in\nexpressive power with symmetric transitive closure logic STC and transitive\nclosure logic (with or without counting). LREC is strictly contained in\nfixed-point logic with counting FPC. We also study an extension LREC= of LREC\nthat has nicer closure properties and is more expressive than both LREC and\nSTC, but is still contained in FPC and has a data complexity in LOGSPACE. Our\nmain results are that LREC captures LOGSPACE on the class of directed trees and\nthat LREC= captures LOGSPACE on the class of interval graphs.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 21:37:58 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2013 01:56:53 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2013 09:51:53 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Grohe", "Martin", "", "RWTH Aachen University, Germany"], ["Gru\u00dfien", "Berit", "", "Humboldt-Universit\u00e4t zu Berlin"], ["Hernich", "Andr\u00e9", "", "Humboldt-Universit\u00e4t\n  zu Berlin"], ["Laubner", "Bastian", "", "Humboldt-Universit\u00e4t zu Berlin"]]}, {"id": "1212.6574", "submitter": "EPTCS", "authors": "Peter Csaba \\\"Olveczky (University of Oslo), Cyrille Artho (AIST)", "title": "Proceedings First International Workshop on Formal Techniques for\n  Safety-Critical Systems", "comments": null, "journal-ref": "EPTCS 105, 2012", "doi": "10.4204/EPTCS.105", "report-no": null, "categories": "cs.LO cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the First International Workshop of\nFormal Techniques for Safety-Critical Systems (FTSCS 2012), held in Kyoto on\nNovember 12, 2012, as a satellite event of the ICFEM conference.\n  The aim of this workshop is to bring together researchers and engineers\ninterested in the application of (semi-)formal methods to improve the quality\nof safety-critical computer systems. FTSCS is particularly interested in\nindustrial applications of formal methods. Topics include:\n  - the use of formal methods for safety-critical and QoS-critical systems,\nincluding avionics, automotive, and medical systems; - methods, techniques and\ntools to support automated analysis, certification, debugging, etc.; - analysis\nmethods that address the limitations of formal methods in industry; - formal\nanalysis support for modeling languages used in industry, such as AADL,\nPtolemy, SysML, SCADE, Modelica, etc.; and - code generation from validated\nmodels.\n  The workshop received 25 submissions; 21 of these were regular papers and 4\nwere tool/work-in-progress/position papers. Each submission was reviewed by\nthree referees; based on the reviews and extensive discussions, the program\ncommittee selected nine regular papers, which are included in this volume. Our\nprogram also included an invited talk by Ralf Huuck.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2012 00:04:47 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["\u00d6lveczky", "Peter Csaba", "", "University of Oslo"], ["Artho", "Cyrille", "", "AIST"]]}, {"id": "1212.6576", "submitter": "Steffen Lewitzka", "authors": "Steffen Lewitzka", "title": "Denotational semantics for modal systems S3--S5 extended by axioms for\n  propositional quantifiers and identity", "comments": "32 pages. This version of the article has been accepted for\n  publication in STUDIA LOGICA. The final publication is available at Springer\n  via http://dx.doi.org/10.1007/s11225-014-9577-9", "journal-ref": null, "doi": "10.1007/s11225-014-9577-9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are logics where necessity is defined by means of a given identity\nconnective: $\\square\\varphi := \\varphi\\equiv\\top$ ($\\top$ is a tautology). On\nthe other hand, in many standard modal logics the concept of propositional\nidentity (PI) $\\varphi\\equiv\\psi$ can be defined by strict equivalence (SE)\n$\\square(\\varphi\\leftrightarrow\\psi)$. All these approaches to modality involve\na principle that we call the Collapse Axiom (CA): \"There is only one necessary\nproposition.\" In this paper, we consider a notion of PI which relies on the\nidentity axioms of Suszko's non-Fregean logic $\\mathit{SCI}$. Then $S3$ proves\nto be the smallest Lewis modal system where PI can be defined as SE. We extend\n$S3$ to a non-Fregean logic with propositional quantifiers such that necessity\nand PI are integrated as non-interdefinable concepts. CA is not valid and PI\nrefines SE. Models are expansions of $\\mathit{SCI}$-models. We show that\n$\\mathit{SCI}$-models are Boolean prealgebras, and vice-versa. This associates\nNon-Fregean Logic with research on Hyperintensional Semantics. PI equals SE iff\nmodels are Boolean algebras and CA holds. A representation result establishes a\nconnection to Fine's approach to propositional quantifiers and shows that our\ntheories are \\textit{conservative} extensions of $S3$--$S5$, respectively. If\nwe exclude the Barcan formula and a related axiom, then the resulting systems\nare still complete w.r.t. a simpler denotational semantics.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2012 00:30:29 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2013 19:10:17 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2013 19:39:16 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2014 00:44:13 GMT"}, {"version": "v5", "created": "Sun, 7 Sep 2014 00:53:40 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Lewitzka", "Steffen", ""]]}, {"id": "1212.6607", "submitter": "Jinjin Zhang", "authors": "Jinjin Zhang, Zhaohui Zhu, and Jianfei Yang", "title": "A control strategy algorithm for finite alternating transition systems", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an increasing interest in the formal analysis and\ndesign of control systems. In this area, in order to reduce the complexity and\nscale of control systems, finite abstractions of control systems are introduced\nand explored. Amongst, Pola and Tabuada construct finite alternating transition\nsystems as approximate finite abstractions for control systems with disturbance\ninputs [SIAM Journal on Control and Optimization, Vol. 48, 2009, 719-733].\nGiven linear temporal logical formulas as specifications, this paper provides a\ncontrol strategy algorithm to find control strategies of Pola and Tabuada's\nabstractions enforcing specifications.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2012 10:12:49 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Zhang", "Jinjin", ""], ["Zhu", "Zhaohui", ""], ["Yang", "Jianfei", ""]]}, {"id": "1212.6641", "submitter": "Francois Clement", "authors": "Sylvie Boldo (LRI, INRIA Saclay - \\^Ile-de-France), Fran\\c{c}ois\n  Cl\\'ement (Inria Paris-Rocquencourt), Jean-Christophe Filli\\^atre (LRI, INRIA\n  Saclay - \\^Ile-de-France), Micaela Mayero (LIPN), Guillaume Melquiond (LRI,\n  INRIA Saclay - \\^Ile-de-France), Pierre Weis (Inria Paris-Rocquencourt)", "title": "Trusting Computations: a Mechanized Proof from Partial Differential\n  Equations to Actual Program", "comments": "N&deg; RR-8197 (2012). arXiv admin note: text overlap with\n  arXiv:1112.1795", "journal-ref": null, "doi": null, "report-no": "RR-8197", "categories": "math.NA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer programs may go wrong due to exceptional behaviors, out-of-bound\narray accesses, or simply coding errors. Thus, they cannot be blindly trusted.\nScientific computing programs make no exception in that respect, and even bring\nspecific accuracy issues due to their massive use of floating-point\ncomputations. Yet, it is uncommon to guarantee their correctness. Indeed, we\nhad to extend existing methods and tools for proving the correct behavior of\nprograms to verify an existing numerical analysis program. This C program\nimplements the second-order centered finite difference explicit scheme for\nsolving the 1D wave equation. In fact, we have gone much further as we have\nmechanically verified the convergence of the numerical scheme in order to get a\ncomplete formal proof covering all aspects from partial differential equations\nto actual numerical results. To the best of our knowledge, this is the first\ntime such a comprehensive proof is achieved.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2012 15:51:10 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2014 10:51:29 GMT"}, {"version": "v3", "created": "Mon, 2 Jun 2014 18:49:48 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Boldo", "Sylvie", "", "LRI, INRIA Saclay - \u00cele-de-France"], ["Cl\u00e9ment", "Fran\u00e7ois", "", "Inria Paris-Rocquencourt"], ["Filli\u00e2tre", "Jean-Christophe", "", "LRI, INRIA\n  Saclay - \u00cele-de-France"], ["Mayero", "Micaela", "", "LIPN"], ["Melquiond", "Guillaume", "", "LRI,\n  INRIA Saclay - \u00cele-de-France"], ["Weis", "Pierre", "", "Inria Paris-Rocquencourt"]]}, {"id": "1212.6751", "submitter": "Russell Miller", "authors": "Russell Miller and Hans Schoutens", "title": "Computably Categorical Fields via Fermat's Last Theorem", "comments": "to appear in the journal Computability", "journal-ref": "Computability 2 (2013), 51-65", "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a computable, computably categorical field of infinite\ntranscendence degree over the rational numbers, using the Fermat polynomials\nand assorted results from algebraic geometry. We also show that this field has\nan intrinsically computable (infinite) transcendence basis.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2012 17:31:58 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Miller", "Russell", ""], ["Schoutens", "Hans", ""]]}, {"id": "1212.6813", "submitter": "Zhaohui Zhu", "authors": "Zhaohui Zhu, Yan Zhang, Jinjin Zhang", "title": "Merging Process Algebra and Action-based Computation Tree Logic", "comments": "64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process algebra and temporal logic are two popular paradigms for the\nspecification, verification and systematic development of reactive and\nconcurrent systems. These two approaches take different standpoint for looking\nat specifications and verifications, and offer complementary advantages. In\norder to mix algebraic and logic styles of specification in a uniform\nframework, the notion of a logic labelled transition system (LLTS) has been\npresented and explored by Luttgen and Vogler. This paper intends to propose a\nLLTS-oriented process calculus which, in addition to usual process-algebraic\noperators, involves logic connectives (conjunction and disjunction) and\nstandard temporal operators (always and unless). This calculus preserves usual\nproperties of these logic operators, allows one to freely mix operational and\nlogic operators, and supports compositional reasoning. Moreover, the links\nbetween this calculus and Action-based Computation Tree Logic (ACTL) including\ncharacteristic formulae of process terms, characteristic processes of ACTL\nformulae and Galois connection are explored.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 03:09:34 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Zhu", "Zhaohui", ""], ["Zhang", "Yan", ""], ["Zhang", "Jinjin", ""]]}]