[{"id": "1912.00010", "submitter": "Flavio Ferrarotti", "authors": "Flavio Ferrarotti, Senen Gonz\\'ales, Klaus-Dieter Schewe, Jos\\'e\n  Mar\\'ia Turull-Torres", "title": "A Restricted Second-Order Logic for Non-deterministic Poly-Logarithmic\n  Time", "comments": "Draft of Paper submitted to the Logic Journal of the IGPL. arXiv\n  admin note: substantial text overlap with arXiv:1806.07127", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a restricted second-order logic $\\mathrm{SO}^{\\mathit{plog}}$\nfor finite structures where second-order quantification ranges over relations\nof size at most poly-logarithmic in the size of the structure. We demonstrate\nthe relevance of this logic and complexity class by several problems in\ndatabase theory. We then prove a Fagin's style theorem showing that the Boolean\nqueries which can be expressed in the existential fragment of\n$\\mathrm{SO}^{\\mathit{plog}}$ corresponds exactly to the class of decision\nproblems that can be computed by a non-deterministic Turing machine with random\naccess to the input in time $O((\\log n)^k)$ for some $k \\ge 0$, i.e., to the\nclass of problems computable in non-deterministic poly-logarithmic time. It\nshould be noted that unlike Fagin's theorem which proves that the existential\nfragment of second-order logic captures NP over arbitrary finite structures,\nour result only holds over ordered finite structures, since\n$\\mathrm{SO}^{\\mathit{plog}}$ is too weak as to define a total order of the\ndomain. Nevertheless $\\mathrm{SO}^{\\mathit{plog}}$ provides natural levels of\nexpressibility within poly-logarithmic space in a way which is closely related\nto how second-order logic provides natural levels of expressibility within\npolynomial space. Indeed, we show an exact correspondence between the\nquantifier prefix classes of $\\mathrm{SO}^{\\mathit{plog}}$ and the levels of\nthe non-deterministic poly-logarithmic time hierarchy, analogous to the\ncorrespondence between the quantifier prefix classes of second-order logic and\nthe polynomial-time hierarchy. Our work closely relates to the constant depth\nquasipolynomial size AND/OR circuits and corresponding restricted second-order\nlogic defined by David A. Mix Barrington in 1992. We explore this relationship\nin detail.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 12:48:12 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ferrarotti", "Flavio", ""], ["Gonz\u00e1les", "Senen", ""], ["Schewe", "Klaus-Dieter", ""], ["Turull-Torres", "Jos\u00e9 Mar\u00eda", ""]]}, {"id": "1912.00012", "submitter": "Paulo Oliva", "authors": "Rob Arthan and Paulo Oliva", "title": "Negative Translations for Affine and Lukasiewicz Logic", "comments": "arXiv admin note: text overlap with arXiv:1404.0570", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate four well-known negative translations of classical logic into\nintuitionistic logic within a substructural setting. We find that in affine\nlogic the translation schemes due to Kolmogorov and G\\\"odel both satisfy\nTroelstra's criteria for a negative translation. On the other hand, the schemes\nof Glivenko and Gentzen both fail for affine logic, but for different reasons:\none can extend affine logic to make Glivenko work and Gentzen fail and vice\nversa. By contrast, in the setting of Lukasiewicz logic, we can prove a general\nresult asserting that a wide class of formula translations including those of\nKolmogorov, G\\\"odel, Gentzen and Glivenko not only satisfy Troelstra's criteria\nwith respect to a natural intuitionistic fragment of Lukasiewicz logic but are\nall equivalent.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:07:11 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Arthan", "Rob", ""], ["Oliva", "Paulo", ""]]}, {"id": "1912.00171", "submitter": "Nadia Labai", "authors": "Nadia Labai, Tomer Kotek, Magdalena Ortiz, and Helmut Veith", "title": "Pebble-Intervals Automata and FO2 with Two Orders (Extended Version)", "comments": "This extended version includes proofs omitted from the LATA 2020\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel automata model, called pebble-intervals automata (PIA),\nand study its power and closure properties. PIAs are tailored for a decidable\nfragment of FO that is important for reasoning about structures that use data\nvalues from infinite domains: the two-variable fragment with one total preorder\nand its induced successor relation, one linear order, and an arbitrary number\nof unary relations. We prove that the string projection of every language of\ndata words definable in the logic is accepted by a pebble-intervals automaton\nA, and obtain as a corollary an automata-theoretic proof of the EXPSPACE upper\nbound for finite satisfiability due to Schwentick and Zeume.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:07:36 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 15:54:46 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Labai", "Nadia", ""], ["Kotek", "Tomer", ""], ["Ortiz", "Magdalena", ""], ["Veith", "Helmut", ""]]}, {"id": "1912.00534", "submitter": "Kilian Risse", "authors": "Susanna F. de Rezende, Jakob Nordstr\\\"om, Kilian Risse, Dmitry Sokolov", "title": "Exponential Resolution Lower Bounds for Weak Pigeonhole Principle and\n  Perfect Matching Formulas over Sparse Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show exponential lower bounds on resolution proof length for pigeonhole\nprinciple (PHP) formulas and perfect matching formulas over highly unbalanced,\nsparse expander graphs, thus answering the challenge to establish strong lower\nbounds in the regime between balanced constant-degree expanders as in\n[Ben-Sasson and Wigderson '01] and highly unbalanced, dense graphs as in [Raz\n'04] and [Razborov '03, '04]. We obtain our results by revisiting Razborov's\npseudo-width method for PHP formulas over dense graphs and extending it to\nsparse graphs. This further demonstrates the power of the pseudo-width method,\nand we believe it could potentially be useful for attacking also other\nlongstanding open problems for resolution and other proof systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 01:04:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["de Rezende", "Susanna F.", ""], ["Nordstr\u00f6m", "Jakob", ""], ["Risse", "Kilian", ""], ["Sokolov", "Dmitry", ""]]}, {"id": "1912.00629", "submitter": "Ryu Hasegawa", "authors": "Ryu Hasegawa", "title": "A categorical reduction system for linear logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagram chasing is not an easy task. The coherence holds in a generalized\nsense if we have a mechanical method to judge whether given two morphisms are\nequal to each other. A simple way to this end is to reform a concerned category\ninto a calculus, where the instructions for the diagram chasing are given in\nthe form of rewriting rules. We apply this idea to the categorical semantics of\nthe linear logic. We build a calculus directly on the free category of the\nsemantics. It enables us to perform diagram chasing as essentially one-way\ncomputations led by the rewriting rules. We verify the weak termination\nproperty of this calculus. This gives the first step towards the mechanization\nof diagram chasing.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:32:59 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 00:53:44 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Hasegawa", "Ryu", ""]]}, {"id": "1912.00801", "submitter": "Adonai S. Sant'Anna", "authors": "Adonai Sant'Anna, Otavio Bueno, Marcio de Franca", "title": "Follow the Flow: sets, relations, and categories as special cases of\n  functions with no domain", "comments": "61 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce, develop, and apply a new approach for dealing with the\nintuitive notion of function, called Flow Theory. Within our framework all\nfunctions are monadic and none of them has any domain. Sets, proper classes,\ncategories, functors, and even relations are special cases of functions. In\nthis sense, functions in Flow are not equivalent to functions in ZFC.\nNevertheless, we prove both ZFC and Category Theory are naturally immersed\nwithin Flow. Besides, our framework provides major advantages as a language for\naxiomatization of standard mathematical and physical theories. Russell's\nparadox is avoided without any equivalent to the Separation Scheme. Hierarchies\nof sets are obtained without any equivalent to the Power Set Axiom. And a clear\nprinciple of duality emerges from Flow, in a way which was not anticipated\nneither by Category Theory nor by standard set theories. Besides, there seems\nto be within Flow an identification not only with the common practice of doing\nmathematics (which is usually quite different from the ways proposed by\nlogicians), but even with the common practice of teaching this formal science.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:53:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sant'Anna", "Adonai", ""], ["Bueno", "Otavio", ""], ["de Franca", "Marcio", ""]]}, {"id": "1912.00948", "submitter": "Grzegorz Fabia\\'nski", "authors": "Grzegorz Fabia\\'nski", "title": "Properties of nowhere dense graph classes related to independent set\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A set is called r-independent, if every two vertices of it are in distance\ngreater then r. In the r-independent set problem with parameter k, we ask\nwhether in a given graph G there exists an r-independent set of size k. In this\nwork we present an algorithm for this problem, which applied to a graph from\nany fixed nowhere dense class, works in time bounded by f(k, r)*G, for some\nfunction f. We also present alternative algorithm, with running time bounded by\ng(k, r)*G, working on slightly more general classes of graphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:46:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Fabia\u0144ski", "Grzegorz", ""]]}, {"id": "1912.01032", "submitter": "Zhiwei Zhang", "authors": "Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Y. Vardi, Zhiwei\n  Zhang", "title": "FourierSAT: A Fourier Expansion-Based Algebraic Framework for Solving\n  Hybrid Boolean Constraints", "comments": "The paper was accepted by Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI 2020). V2 (Feb 24): Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.IT cs.LG math.IT math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Boolean SATisfiability problem (SAT) is of central importance in computer\nscience. Although SAT is known to be NP-complete, progress on the engineering\nside, especially that of Conflict-Driven Clause Learning (CDCL) and Local\nSearch SAT solvers, has been remarkable. Yet, while SAT solvers aimed at\nsolving industrial-scale benchmarks in Conjunctive Normal Form (CNF) have\nbecome quite mature, SAT solvers that are effective on other types of\nconstraints, e.g., cardinality constraints and XORs, are less well studied; a\ngeneral approach to handling non-CNF constraints is still lacking. In addition,\nprevious work indicated that for specific classes of benchmarks, the running\ntime of extant SAT solvers depends heavily on properties of the formula and\ndetails of encoding, instead of the scale of the benchmarks, which adds\nuncertainty to expectations of running time.\n  To address the issues above, we design FourierSAT, an incomplete SAT solver\nbased on Fourier analysis of Boolean functions, a technique to represent\nBoolean functions by multilinear polynomials. By such a reduction to continuous\noptimization, we propose an algebraic framework for solving systems consisting\nof different types of constraints. The idea is to leverage gradient information\nto guide the search process in the direction of local improvements. Empirical\nresults demonstrate that FourierSAT is more robust than other solvers on\ncertain classes of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 19:01:29 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 17:51:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kyrillidis", "Anastasios", ""], ["Shrivastava", "Anshumali", ""], ["Vardi", "Moshe Y.", ""], ["Zhang", "Zhiwei", ""]]}, {"id": "1912.01107", "submitter": "Marco Peressotti", "authors": "Fabio Burco and Marino Miculan and Marco Peressotti", "title": "Towards a Formal Model for Composable Container Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern cloud-based architectures, containers play a central role: they\nprovide powerful isolation mechanisms such that developers can focus on the\nlogic and dependencies of applications while system administrators can focus on\ndeployment and management issue. In this work, we propose a formal model for\ncontainer-based systems, using the framework of Bigraphical Reactive Systems\n(BRSs). We first introduce local directed bigraphs, a graph-based formalism\nwhich allows us to deal with localized resources. Then, we define a signature\nfor modelling containers and provide some examples of bigraphs modelling\ncontainers. These graphs can be analysed and manipulated using techniques from\ngraph theory: properties about containers can be formalized as properties of\nthe corresponding bigraphic representations. Moreover, it turns out that the\ncomposition of containers as performed by e.g. docker-compose, corresponds\nprecisely to the composition of the corresponding bigraphs inside an\n``environment bigraph'' which in turn is obtained directly from the YAML file\nused to define the composition of containers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:46:05 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Burco", "Fabio", ""], ["Miculan", "Marino", ""], ["Peressotti", "Marco", ""]]}, {"id": "1912.01289", "submitter": "Francesco Tiezzi", "authors": "Rocco De Nicola, Gianluigi Ferrari, Rosario Pugliese, Francesco Tiezzi", "title": "A Formal Approach to the Engineering of Domain-Specific Distributed\n  Systems", "comments": "In Press", "journal-ref": "Journal of Logical and Algebraic Methods in Programming, Elsevier,\n  2019", "doi": "10.1016/j.jlamp.2019.100511", "report-no": null, "categories": "cs.PL cs.FL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some results regarding specification, programming and verification\nof different classes of distributed systems which stemmed from the research of\nthe Concurrency and Mobility Group at University of Firenze. More specifically,\nwe examine the distinguishing features of network-aware programming,\nservice-oriented computing, autonomic computing, and collective adaptive\nsystems programming. We then present an overview of four different languages,\nnamely Klaim, Cows, Scel and AbC. For each language, we discuss design choices,\npresent syntax and semantics, show how the different formalisms can be used to\nmodel and program a travel booking scenario, and describe programming\nenvironments and verification techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 10:45:53 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["De Nicola", "Rocco", ""], ["Ferrari", "Gianluigi", ""], ["Pugliese", "Rosario", ""], ["Tiezzi", "Francesco", ""]]}, {"id": "1912.01333", "submitter": "Paulo Oliva", "authors": "Paulo Oliva and Chuangjie Xu", "title": "On the Herbrand Functional Interpretation", "comments": "9 pages", "journal-ref": null, "doi": "10.1002/malq.201900067", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the types of the witnesses in the Herbrand functional\ninterpretation can be simplified, avoiding the use of \"sets of functionals\" in\nthe interpretation of implication and universal quantification. This is done by\npresenting an alternative formulation of the Herbrand functional\ninterpretation, which we show to be equivalent to the original presentation. As\na result of this investigation we also strengthen the monotonicity property of\nthe original presentation, and prove a monotonicity property for our\nalternative definition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 12:21:49 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Oliva", "Paulo", ""], ["Xu", "Chuangjie", ""]]}, {"id": "1912.01476", "submitter": "Patrick Trentin", "authors": "Francesco Contaldo, Patrick Trentin, Roberto Sebastiani", "title": "From MiniZinc to Optimization Modulo Theories, and Back (Extended\n  Version)", "comments": "Short Version published at CPAIOR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization Modulo Theories (OMT) is an extension of SMT that allows for\nfinding models that optimize objective functions. In this paper we aim at\nbridging the gap between Constraint Programming (CP) and OMT, in both\ndirections. First, we have extended the OMT solver OptiMathSAT with a FlatZinc\ninterface -- which can also be used as a FlatZinc-to-OMT encoder for other OMT\nsolvers. This allows OMT tools to be used in combination with mzn2fzn on the\nlarge amount of CP problems coming from the MiniZinc community. Second, we have\nintroduced a tool for translating SMT and OMT problems on the linear arithmetic\nand bit-vector theories into MiniZinc. This allows MiniZinc solvers to be used\non a large amount of SMT/OMT problems.\n  We have discussed the main issues we had to cope with in either directions.\nWe have performed an extensive empirical evaluation comparing three\nstate-of-the-art OMT-based tools with many state-of-the-art CP tools on (i) CP\nproblems coming from the MiniZinc challenge, and (ii) OMT problems coming\nmostly from formal verification. This analysis also allowed us to identify some\ncriticalities, in terms of efficiency and correctness, one has to cope with\nwhen addressing CP problems with OMT tools, and vice versa.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 15:42:26 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 09:59:24 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Contaldo", "Francesco", ""], ["Trentin", "Patrick", ""], ["Sebastiani", "Roberto", ""]]}, {"id": "1912.01525", "submitter": "Thibault Gauthier", "authors": "Chad E. Brown, Thibault Gauthier", "title": "Self-Learned Formula Synthesis in Set Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reinforcement learning algorithm accomplishes the task of synthesizing a\nset-theoretical formula that evaluates to given truth values for given\nassignments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:56:51 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Brown", "Chad E.", ""], ["Gauthier", "Thibault", ""]]}, {"id": "1912.01876", "submitter": "Munyque Mittelmann", "authors": "Munyque Mittelmann, Laurent Perrussel", "title": "Game Description Logic with Integers: A GDL Numerical Extension", "comments": "23 pages, extended version of the paper published at the conference\n  FoIKS 2020 (11th International Symposium on Foundations of Information and\n  Knowledge Systems)", "journal-ref": null, "doi": "10.1007/978-3-030-39951-1_12", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems can be viewed as games, where one or more agents try to ensure\nthat certain objectives hold no matter the behavior from the environment and\nother agents. In recent years, a number of logical formalisms have been\nproposed for specifying games among which the Game Description Language (GDL)\nwas established as the official language for General Game Playing. Although\nnumbers are recurring in games, the description of games with numerical\nfeatures in GDL requires the enumeration from all possible numeric values and\nthe relation among them. Thereby, in this paper, we introduce the Game\nDescription Logic with Integers (GDLZ) to describe games with numerical\nvariables, numerical parameters, as well as to perform numerical comparisons.\nWe compare our approach with GDL and show that when describing the same game,\nGDLZ is more compact.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 10:13:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mittelmann", "Munyque", ""], ["Perrussel", "Laurent", ""]]}, {"id": "1912.01914", "submitter": "Daniel Ventura", "authors": "Sandra Alves and Delia Kesner and Daniel Ventura", "title": "A Quantitative Understanding of Pattern Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows that the recent approach to quantitative typing systems for\nprogramming languages can be extended to pattern matching features. Indeed, we\ndefine two resource aware type systems, named U and E, for a lambda-calculus\nequipped with pairs for both patterns and terms. Our typing systems borrow some\nbasic ideas from [BKRDR15], which characterises (head) normalisation in a\nqualitative way, in the sense that typability and normalisation coincide. But\nin contrast to [BKRDR15], our (static) systems also provides quantitative\ninformation about the dynamics of the calculus. Indeed, system U provides upper\nbounds for the length of normalisation sequences plus the size of their\ncorresponding normal forms, while system E, which can be seen as a refinement\nof system U, produces exact bounds for each of them. This is achieved by means\nof a non-idempotent intersection type system equipped with different technical\ntools. First of all, we use product types to type pairs, instead of the\ndisjoint unions in [BKRDR15], thus avoiding an overlap between \"being a pair\"\nand \"being duplicable\", resulting in an essential tool to reason about\nquantitativity. Secondly, typing sequents in system E are decorated with tuples\nof integers, which provide quantitative information about normalisation\nsequences, notably time (c.f. length) and space (c.f. size). Another key tool\nof system E is that the type system distinguishes between consuming\n(contributing to time) and persistent (contributing to space) constructors.\nMoreover, the time resource information is remarkably refined, because it\ndiscriminates between different kinds of reduction steps performed during\nevaluation, so that beta reduction, substitution and matching steps are counted\nseparately.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 11:54:15 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Alves", "Sandra", ""], ["Kesner", "Delia", ""], ["Ventura", "Daniel", ""]]}, {"id": "1912.02150", "submitter": "Reazul Hasan Russel", "authors": "Reazul Hasan Russel", "title": "A Probabilistic Approach to Satisfiability of Propositional Logic\n  Formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a version of WalkSAT algorithm, named as BetaWalkSAT. This method\nuses probabilistic reasoning for biasing the starting state of the local search\nalgorithm. Beta distribution is used to model the belief over boolean values of\nthe literals. Our results suggest that, the proposed BetaWalkSAT algorithm can\noutperform other uninformed local search approaches for complex boolean\nsatisfiability problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:58:28 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Russel", "Reazul Hasan", ""]]}, {"id": "1912.02211", "submitter": "Abhishek Kr Singh", "authors": "Abhishek Kr Singh and Raja Natarajan", "title": "A Constructive Formalization of the Weak Perfect Graph Theorem", "comments": "The 9th ACM SIGPLAN International Conference on Certified Programs\n  and Proofs (CPP 2020)", "journal-ref": null, "doi": "10.1145/3372885.3373819", "report-no": null, "categories": "cs.LO cs.DM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Perfect Graph Theorems are important results in graph theory describing\nthe relationship between clique number $\\omega(G) $ and chromatic number\n$\\chi(G) $ of a graph $G$. A graph $G$ is called \\emph{perfect} if\n$\\chi(H)=\\omega(H)$ for every induced subgraph $H$ of $G$. The Strong Perfect\nGraph Theorem (SPGT) states that a graph is perfect if and only if it does not\ncontain an odd hole (or an odd anti-hole) as its induced subgraph. The Weak\nPerfect Graph Theorem (WPGT) states that a graph is perfect if and only if its\ncomplement is perfect. In this paper, we present a formal framework for working\nwith finite simple graphs. We model finite simple graphs in the Coq Proof\nAssistant by representing its vertices as a finite set over a countably\ninfinite domain. We argue that this approach provides a formal framework in\nwhich it is convenient to work with different types of graph constructions (or\nexpansions) involved in the proof of the Lov\\'{a}sz Replication Lemma (LRL),\nwhich is also the key result used in the proof of Weak Perfect Graph Theorem.\nFinally, we use this setting to develop a constructive formalization of the\nWeak Perfect Graph Theorem.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 19:03:53 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Singh", "Abhishek Kr", ""], ["Natarajan", "Raja", ""]]}, {"id": "1912.02250", "submitter": "Kesha Hietala", "authors": "Kesha Hietala, Robert Rand, Shih-Han Hung, Xiaodi Wu, Michael Hicks", "title": "A Verified Optimizer for Quantum Circuits", "comments": "This paper supercedes arXiv:1904.06319; version 2 includes additional\n  results and improved formatting; version 3 is the final draft with additional\n  formatting improvements and some restructuring", "journal-ref": null, "doi": "10.1145/3434318", "report-no": null, "categories": "cs.PL cs.ET cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VOQC, the first fully verified optimizer for quantum circuits,\nwritten using the Coq proof assistant. Quantum circuits are expressed as\nprograms in a simple, low-level language called SQIR, a simple quantum\nintermediate representation, which is deeply embedded in Coq. Optimizations and\nother transformations are expressed as Coq functions, which are proved correct\nwith respect to a semantics of SQIR programs. SQIR uses a semantics of matrices\nof complex numbers, which is the standard for quantum computation, but treats\nmatrices symbolically in order to reason about programs that use an arbitrary\nnumber of quantum bits. SQIR's careful design and our provided automation make\nit possible to write and verify a broad range of optimizations in VOQC,\nincluding full-circuit transformations from cutting-edge optimizers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:07:00 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 16:54:52 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 02:45:31 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Hietala", "Kesha", ""], ["Rand", "Robert", ""], ["Hung", "Shih-Han", ""], ["Wu", "Xiaodi", ""], ["Hicks", "Michael", ""]]}, {"id": "1912.02499", "submitter": "Caterina Urban", "authors": "Caterina Urban, Maria Christakis, Valentin W\\\"ustholz, Fuyuan Zhang", "title": "Perfectly Parallel Fairness Certification of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CY cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is growing concern that machine-learning models, which\ncurrently assist or even automate decision making, reproduce, and in the worst\ncase reinforce, bias of the training data. The development of tools and\ntechniques for certifying fairness of these models or describing their biased\nbehavior is, therefore, critical. In this paper, we propose a perfectly\nparallel static analysis for certifying causal fairness of feed-forward neural\nnetworks used for classification of tabular data. When certification succeeds,\nour approach provides definite guarantees, otherwise, it describes and\nquantifies the biased behavior. We design the analysis to be sound, in practice\nalso exact, and configurable in terms of scalability and precision, thereby\nenabling pay-as-you-go certification. We implement our approach in an\nopen-source tool and demonstrate its effectiveness on models trained with\npopular datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 10:59:28 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 13:31:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Urban", "Caterina", ""], ["Christakis", "Maria", ""], ["W\u00fcstholz", "Valentin", ""], ["Zhang", "Fuyuan", ""]]}, {"id": "1912.02636", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Chad Brown, Cezary Kaliszyk, Josef Urban", "title": "Exploration of Neural Machine Translation in Autoformalization of\n  Mathematics in Mizar", "comments": "The 9th ACM SIGPLAN International Conference on Certified Programs\n  and Proofs", "journal-ref": null, "doi": "10.1145/3372885.3373827", "report-no": null, "categories": "cs.LO cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we share several experiments trying to automatically translate\ninformal mathematics into formal mathematics. In our context informal\nmathematics refers to human-written mathematical sentences in the LaTeX format;\nand formal mathematics refers to statements in the Mizar language. We conducted\nour experiments against three established neural network-based machine\ntranslation models that are known to deliver competitive results on translating\nbetween natural languages. To train these models we also prepared four\ninformal-to-formal datasets. We compare and analyze our results according to\nwhether the model is supervised or unsupervised. In order to augment the data\navailable for auto-formalization and improve the results, we develop a custom\ntype-elaboration mechanism and integrate it in the supervised translation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:13:15 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:29:01 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Wang", "Qingxiang", ""], ["Brown", "Chad", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1912.02731", "submitter": "Denis Ponomaryov", "authors": "Sergey Goncharov, Sergey Ospichev, Denis Ponomaryov, and Dmitri\n  Sviridenko", "title": "The Expressiveness of Looping Terms in the Semantic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the language of $\\Delta_0$-formulas with list terms interpreted\nover hereditarily finite list superstructures. We study the complexity of\nreasoning in extensions of the language of $\\Delta_0$-formulas with\nnon-standard list terms, which represent bounded list search, bounded\niteration, and bounded recursion. We prove a number of results on the\ncomplexity of model checking and satisfiability for these formulas. In\nparticular, we show that the set of $\\Delta_0$-formulas with bounded recursive\nterms true in a given list superstructure $HW(\\mathcal{M})$ is non-elementary\n(it contains the class kEXPTIME, for all $k\\geqslant 1$). For\n$\\Delta_0$-formulas with restrictions on the usage of iterative and recursive\nterms, we show lower complexity.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:10:30 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 11:34:11 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Goncharov", "Sergey", ""], ["Ospichev", "Sergey", ""], ["Ponomaryov", "Denis", ""], ["Sviridenko", "Dmitri", ""]]}, {"id": "1912.02759", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Duty to Warn in Strategic Games", "comments": "Proc. of the 19th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2020) May 9--13, 2020, Auckland, New Zealand, B.\n  An, N. Yorke-Smith, A. El Fallah Seghrouchni, G.~Sukthankar (eds.). arXiv\n  admin note: substantial text overlap with arXiv:1811.02446", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates the second-order blameworthiness or duty to warn\nmodality \"one coalition knew how another coalition could have prevented an\noutcome\". The main technical result is a sound and complete logical system that\ndescribes the interplay between the distributed knowledge and the duty to warn\nmodalities.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:57:02 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:54:55 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1912.02885", "submitter": "David  McAllester", "authors": "David McAllester", "title": "Isomorphism Revisited", "comments": "This paper lacks adequate proofs of the claims", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isomorphism is central to the structure of mathematics and has been\nformalized in various ways within dependent type theory. All previous\ntreatments have done this by replacing quantification over sets with\nquantification over groupoids of some form --- categories in which every\nmorphism is an isomorphism. Quantification over sets is replaced by\nquantification over standard groupoids in the groupoid model, by quantification\nover infinity groupoid in Homotopy type theory, and by quantification over\nmorphoids in the morphoid model. Here we give a treatment of isomorphism based\non the intuitive notion of sets as collections without internal structure.\nQuantification over sets remains as quantification over sets. Isomorphism and\ngroupoid structure then emerge from simple but subtle syntactic restrictions on\nset-theoretic language. This approach more fully unifies the classical ZFC\nfoundations with a rigorous treatments of isomorphism, symmetry, canonicality,\nfunctors, and natural transformations. This is all done without reference to\ncategory theory.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:33:49 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 01:39:23 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["McAllester", "David", ""]]}, {"id": "1912.02898", "submitter": "Ghassen Hamdi", "authors": "Ghassen Hamdi and Abdelmoutia Telli and Mohamed Nazih Omri", "title": "Recursive algorithms to repair prioritized and inconsistent dl-lite\n  knowledge base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inconsistency in prioritized knowledge base is because the assertions\n(ABoxes) come from several sources with different levels of reliability. We\nintroduce the handling of this inconsistency problem to query inconsistent\n\\textit{DL-Lite} knowledge bases. In the literature, firstly, repair all the\ninconsistent assertions of the \\textit{DL-Lite}'s inconsistent knowledge base.\nThen, interrogate it. However, our algorithm, on proceeds directly with an\ninterrogation of the knowledge base in order to recover an exhaustive list of\nanswers to a given query. In a second time, to repair the answers of this list.\nThe novelty of our article is the proposition of a recurring function that\ncalculates the rank of coherence in order to manage the inconsistencies in the\nset of responses. This strategy allowed us to reduce execution time compared to\nexisting algorithms. The experimental study as well as the analysis of the\nresults, which we carried out, showed that our algorithm is much more\nproductive than the other algorithms since it gives the greatest number of\nanswers while remaining the best from the point of view of the execution time.\nFinally, as shown in our experimental studies, they allow an efficient handling\nof inconsistency. Such facts make all the repairs suitable for \\textit{DL-Lite\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:00:08 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Hamdi", "Ghassen", ""], ["Telli", "Abdelmoutia", ""], ["Omri", "Mohamed Nazih", ""]]}, {"id": "1912.03028", "submitter": "M. Saqib Nawaz", "authors": "M. Saqib Nawaz, Moin Malik, Yi Li, Meng Sun and M. Ikram Ullah Lali", "title": "A Survey on Theorem Provers in Formal Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanical reasoning is a key area of research that lies at the crossroads of\nmathematical logic and artificial intelligence. The main aim to develop\nmechanical reasoning systems (also known as theorem provers) was to enable\nmathematicians to prove theorems by computer programs. However, these tools\nevolved with time and now play vital role in the modeling and reasoning about\ncomplex and large-scale systems, especially safety-critical systems.\nTechnically, mathematical formalisms and automated reasoning based-approaches\nare employed to perform inferences and to generate proofs in theorem provers.\nIn literature, there is a shortage of comprehensive documents that can provide\nproper guidance about the preferences of theorem provers with respect to their\ndesigns, performances, logical frameworks, strengths, differences and their\napplication areas. In this work, more than 40 theorem provers are studied in\ndetail and compared to present a comprehensive analysis and evaluation of these\ntools. Theorem provers are investigated based on various parameters, which\nincludes: implementation architecture, logic and calculus used, library\nsupport, level of automation, programming paradigm, programming language,\ndifferences and application areas.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:05:38 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Nawaz", "M. Saqib", ""], ["Malik", "Moin", ""], ["Li", "Yi", ""], ["Sun", "Meng", ""], ["Lali", "M. Ikram Ullah", ""]]}, {"id": "1912.03252", "submitter": "Jouko Vaananen", "authors": "Pietro Galliani and Jouko Vaananen", "title": "Diversity, Dependence and Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concepts of dependence and independence in a very general\nframework. We use a concept of rank to study dependence and independence. By\nmeans of the rank we identify (total) dependence with inability to create more\ndiversity, and (total) independence with the presence of maximum diversity. We\nshow that our theory of dependence and independence covers a variety of\ndependence concepts, for example the seemingly unrelated concepts of linear\ndependence in algebra and dependence of variables in logic.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:49:56 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Galliani", "Pietro", ""], ["Vaananen", "Jouko", ""]]}, {"id": "1912.03434", "submitter": "Makoto Hamana", "authors": "Makoto Hamana", "title": "Modular Termination for Second-Order Computation Rules and Application\n  to Algebraic Effect Handlers", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a new modular proof method of termination for second-order\ncomputation, and report its implementation SOL. The proof method is useful for\nproving termination of higher-order foundational calculi. To establish the\nmethod, we use a variation of semantic labelling translation and Blanqui's\nGeneral Schema: a syntactic criterion of strong normalisation. As an\napplication, we apply this method to show termination of a variant of\ncall-by-push-value calculus with algebraic effects and effect handlers. We also\nshow that our tool SOL is effective to solve higher-order termination problems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 04:06:36 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 21:11:52 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 06:25:08 GMT"}, {"version": "v4", "created": "Sun, 15 Mar 2020 07:18:12 GMT"}, {"version": "v5", "created": "Wed, 24 Jun 2020 11:37:31 GMT"}, {"version": "v6", "created": "Thu, 25 Jun 2020 11:56:57 GMT"}, {"version": "v7", "created": "Wed, 6 Jan 2021 22:11:31 GMT"}, {"version": "v8", "created": "Mon, 12 Jul 2021 08:41:57 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hamana", "Makoto", ""]]}, {"id": "1912.03841", "submitter": "Xishun Zhao", "authors": "Kexu Wang and Xishun Zhao", "title": "A Logic that Captures $\\beta$P on Ordered Structures", "comments": "15 pages. This article was reported with a title \"Logarithmic-Bounded\n  Second-Order Quantifiers and Limited Nondeterminism\" in National Conference\n  on Modern Logic 2019, on November 9 in Beijing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the inflationary fixed-point logic, IFP, with a new kind of\nsecond-order quantifiers which have (poly-)logarithmic bounds. We prove that on\nordered structures the new logic $\\exists^{\\log^{\\omega}}\\text{IFP}$ captures\nthe limited nondeterminism class $\\beta\\text{P}$. In order to study its\nexpressive power, we also design a new version of Ehrenfeucht-Fra\\\"iss\\'e game\nfor this logic and show that our capturing result will not hold on the general\ncase, i.e. on all the finite structures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 04:26:59 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 14:39:29 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wang", "Kexu", ""], ["Zhao", "Xishun", ""]]}, {"id": "1912.04496", "submitter": "Longchun Wang", "authors": "Longchun Wang Lankun Guo and Qingguo Li", "title": "Continuous Domains in Formal Concept Analysis", "comments": null, "journal-ref": "Fundamenta Informaticae 179 (2021)", "doi": "10.3233/FI-2021-2025", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal Concept Analysis has proven to be an effective method of restructuring\ncomplete lattices and various algebraic domains. In this paper, the notions of\nattribute continuous formal context and continuous formal concept are\nintroduced by considering a selection F of fnite subsets of attributes. Our\ndecision of a selection F relies on a kind of generalized interior operators.\nIt is shown that the set of continuous formal concepts forms a continuous\ndomain, and every continuous domain can be obtained in this way. Moreover, an\nnotion of F-morphism is also identified to produce a category equivalent to\nthat of continuous domains with Scott-continuous functions. This paper also\nconsider the representations of various subclasses of continuous domains such\nas algebraic domains, bounded complete domains and stably continuous\nsemilattices. These results explore the fundamental idea of domain theory in\nFormal Concept Analysis from a categorical viewpoint.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 04:57:15 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Guo", "Longchun Wang Lankun", ""], ["Li", "Qingguo", ""]]}, {"id": "1912.04513", "submitter": "Pierre Tholoniat", "authors": "Rob van Glabbeek, Vincent Gramoli, Pierre Tholoniat", "title": "Cross-Chain Payment Protocols with Success Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of cross-chain payment whereby\ncustomers of different escrows -- implemented by a bank or a blockchain smart\ncontract -- successfully transfer digital assets without trusting each other.\nPrior to this work, cross-chain payment problems did not require this success\nor any form of progress. We introduce a new specification formalism called\nAsynchronous Networks of Timed Automata (ANTA) to formalise such protocols.\n  We present the first cross-chain payment protocol that ensures termination in\na bounded amount of time and works correctly in the presence of clock skew. We\nthen demonstrate that it is impossible to solve this problem without assuming\nsynchrony, in the sense that each message is guaranteed to arrive within a\nknown amount of time. We also offer a protocol that solves an eventually\nterminating variant of this cross-chain payment problem without synchrony, and\neven in the presence of Byzantine failures.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 05:56:55 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["van Glabbeek", "Rob", ""], ["Gramoli", "Vincent", ""], ["Tholoniat", "Pierre", ""]]}, {"id": "1912.05063", "submitter": "Aaron Eberhart", "authors": "Aaron Eberhart, Monireh Ebrahimi, Lu Zhou, Cogan Shimizu, and Pascal\n  Hitzler", "title": "Completion Reasoning Emulation for the Description Logic EL+", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to integrating deep learning with knowledge-based\nsystems that we believe shows promise. Our approach seeks to emulate reasoning\nstructure, which can be inspected part-way through, rather than simply learning\nreasoner answers, which is typical in many of the black-box systems currently\nin use. We demonstrate that this idea is feasible by training a long short-term\nmemory (LSTM) artificial neural network to learn EL+ reasoning patterns with\ntwo different data sets. We also show that this trained system is resistant to\nnoise by corrupting a percentage of the test data and comparing the reasoner's\nand LSTM's predictions on corrupt data with correct answers.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 00:29:18 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Eberhart", "Aaron", ""], ["Ebrahimi", "Monireh", ""], ["Zhou", "Lu", ""], ["Shimizu", "Cogan", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1912.05364", "submitter": "Clemens Dubslaff", "authors": "Clemens Dubslaff, Kai Ding, Andrey Morozov, Christel Baier, Klaus\n  Janschek", "title": "Breaking the Limits of Redundancy Systems Analysis", "comments": "This paper is a preprint of the corresponding ESREL'19 conference\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundancy mechanisms such as triple modular redundancy protect\nsafety-critical components by replication and thus improve systems fault\ntolerance. However, the gained fault tolerance comes along with costs to be\ninvested, e.g., increasing execution time, energy consumption, or packaging\nsize, for which constraints have to be obeyed during system design. This turns\nthe question of finding suitable combinations of components to be protected\ninto a challenging task as the number of possible protection combinations grows\nexponentially in the number of components. We propose family-based approaches\nto tackle the combinatorial blowup in redundancy systems modeling and analysis\nphases. Based on systems designed in SIMULINK we show how to obtain models that\ninclude all possible protection combinations and present a tool chain that,\ngiven a probabilistic error model, generates discrete Markov chain families.\nUsing symbolic techniques that enable concise family representation and\nanalysis, we show how SIMULINK models of realistic size can be protected and\nanalyzed with a single family-based analysis run while a one-by-one analysis of\neach protection combination would clearly exceed any realistic time\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 14:46:39 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Dubslaff", "Clemens", ""], ["Ding", "Kai", ""], ["Morozov", "Andrey", ""], ["Baier", "Christel", ""], ["Janschek", "Klaus", ""]]}, {"id": "1912.05616", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Ensuring Liveness Properties of Distributed Systems: Open Problems", "comments": "An earlier version of this paper appeared as arXiv:1711.04240", "journal-ref": null, "doi": "10.1016/j.jlamp.2019.100480", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often fairness assumptions need to be made in order to establish liveness\nproperties of distributed systems, but in many situations they lead to false\nconclusions. This document presents a research agenda aiming at laying the\nfoundations of a theory of concurrency that is equipped to ensure liveness\nproperties of distributed systems without making fairness assumptions. This\ntheory will encompass process algebra, temporal logic and semantic models. The\nagenda also includes the development of a methodology and tools that allow\nsuccessful application of this theory to the specification, analysis and\nverification of realistic distributed systems. Contemporary process algebras\nand temporal logics fail to make distinctions between systems of which one has\na crucial liveness property and the other does not, at least when assuming\njustness, a strong progress property, but not assuming fairness. Setting up an\nalternative framework involves giving up on identifying strongly bisimilar\nsystems, inventing new induction principles, developing new axiomatic bases for\nprocess algebras and new congruence formats for operational semantics, and\ncreating matching treatments of time and probability. Even simple systems like\nfair schedulers or mutual exclusion protocols cannot be accurately specified in\nstandard process algebras (or Petri nets) in the absence of fairness\nassumptions. Hence the work involves the study of adequate language or model\nextensions, and their expressive power.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 10:56:42 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1912.05793", "submitter": "Guillermo P\\'erez", "authors": "Guillermo A. Perez", "title": "The Extended HOA Format for Synthesis", "comments": "Updated the link to a cited tool and made it explicit that parity\n  automata can be assumed to be complete", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a small extension to the Hanoi Omega-Automata format to define\nreactive-synthesis problems. Namely, we add a \"controllable-AP\" header item\nspecifying the subset of atomic propositions which is controllable. We describe\nthe semantics of the new format and propose an output format for synthesized\nstrategies. Finally, we also comment on tool support meant to encourage fast\nadoption of the extended Hanoi Omega-Automata format for synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 06:46:47 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 13:35:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Perez", "Guillermo A.", ""]]}, {"id": "1912.05828", "submitter": "Francesco Belardinelli", "authors": "Ria Jha, Francesco Belardinelli, Francesca Toni", "title": "Formal Verification of Debates in Argumentation Theory", "comments": "Accepted for publication as full paper at the 35th ACM/SIGAPP\n  Symposium On Applied Computing (SAC2020), KRR track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans engage in informal debates on a daily basis. By expressing their\nopinions and ideas in an argumentative fashion, they are able to gain a deeper\nunderstanding of a given problem and in some cases, find the best possible\ncourse of actions towards resolving it. In this paper, we develop a methodology\nto verify debates formalised as abstract argumentation frameworks. We first\npresent a translation from debates to transition systems. Such transition\nsystems can model debates and represent their evolution over time using a\nfinite set of states. We then formalise relevant debate properties using\ntemporal and strategy logics. These formalisations, along with a debate\ntransition system, allow us to verify whether a given debate satisfies certain\nproperties. The verification process can be automated using model checkers.\nTherefore, we also measure their performance when verifying debates, and use\nthe results to discuss the feasibility of model checking debates.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:31:34 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Jha", "Ria", ""], ["Belardinelli", "Francesco", ""], ["Toni", "Francesca", ""]]}, {"id": "1912.05906", "submitter": "Felix Axel Gimeno Gil", "authors": "Xujie Si, Yujia Li, Vinod Nair, Felix Gimeno", "title": "Prioritized Unit Propagation with Periodic Resetting is (Almost) All You\n  Need for Random SAT Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose prioritized unit propagation with periodic resetting, which is a\nsimple but surprisingly effective algorithm for solving random SAT instances\nthat are meant to be hard. In particular, an evaluation on the Random Track of\nthe 2017 and 2018 SAT competitions shows that a basic prototype of this simple\nidea already ranks at second place in both years. We share this observation in\nthe hope that it helps the SAT community better understand the hardness of\nrandom instances used in competitions and inspire other interesting ideas on\nSAT solving.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:57:02 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Si", "Xujie", ""], ["Li", "Yujia", ""], ["Nair", "Vinod", ""], ["Gimeno", "Felix", ""]]}, {"id": "1912.06110", "submitter": "Dominik D. Freydenberger", "authors": "Dominik D. Freydenberger and Liat Peterfreund", "title": "The theory of concatenation over finite models", "comments": "Update to make this version consistent with conference version (ICALP\n  2021), which renamed Datasplog to FC-Datalog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose FC, a new logic on words that combines finite model theory with\nthe theory of concatenation - a first-order logic that is based on word\nequations. Like the theory of concatenation, FC is built around word equations;\nin contrast to it, its semantics are defined to only allow finite models, by\nlimiting the universe to a word and all its factors. As a consequence of this,\nFC has many of the desirable properties of FO on finite models, while being far\nmore expressive than FO[<]. Most noteworthy among these desirable properties\nare sufficient criteria for efficient model checking, and capturing various\ncomplexity classes by adding operators for transitive closures or fixed points.\n  Not only does FC allow us to obtain new insights and techniques for\nexpressive power and efficient evaluation of document spanners, but it also\nprovides a general framework for logic on words that also has potential\napplications in other areas.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 18:18:55 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 14:18:54 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 18:23:35 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 13:52:43 GMT"}, {"version": "v5", "created": "Thu, 11 Mar 2021 12:42:24 GMT"}, {"version": "v6", "created": "Thu, 13 May 2021 16:38:17 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Freydenberger", "Dominik D.", ""], ["Peterfreund", "Liat", ""]]}, {"id": "1912.06191", "submitter": "EPTCS", "authors": "Fabrizio Genovese (Statebox Team), Alex Gryzlov (Statebox Team), Jelle\n  Herold (Statebox Team), Andre Knispel (Statebox Team), Marco Perone (Statebox\n  Team), Erik Post (Statebox Team), Andr\\'e Videla (Statebox Team)", "title": "idris-ct: A Library to do Category Theory in Idris", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 246-254", "doi": "10.4204/EPTCS.323.16", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce idris-ct, a Idris library providing verified type definitions of\ncategorical concepts.idris-ct strives to be a bridge between academy and\nindustry, catering both to category theorists who want to implement and try\ntheir ideas in a practical environment and to businesses and engineers who care\nabout formalization with category theory: It is inspired by similar libraries\ndeveloped for theorem proving but remains very practical, being aimed at\nsoftware production in business. Nevertheless, the use of dependent types\nallows for a formally correct implementation of categorical concepts, so that\nguarantees can be made on software properties.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:25:20 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 02:17:56 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Genovese", "Fabrizio", "", "Statebox Team"], ["Gryzlov", "Alex", "", "Statebox Team"], ["Herold", "Jelle", "", "Statebox Team"], ["Knispel", "Andre", "", "Statebox Team"], ["Perone", "Marco", "", "Statebox\n  Team"], ["Post", "Erik", "", "Statebox Team"], ["Videla", "Andr\u00e9", "", "Statebox Team"]]}, {"id": "1912.06467", "submitter": "Jiri Adamek", "authors": "Ji\\v{r}\\'i Ad\\'amek", "title": "A farewell to Professor RNDr. V\\v{e}ra Trnkov\\'a}, DrSc", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is an introduction of the volume of the journal Commentationes\nMathematicae Universitatis Caroalinae dedicated to the memory of V\\v{e}ra\nTrnkov\\'a}.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 13:33:03 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 16:37:09 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ad\u00e1mek", "Ji\u0159\u00ed", ""]]}, {"id": "1912.06578", "submitter": "Chana Weil-Kennedy", "authors": "Javier Esparza, Stefan Jaax, Mikhail Raskin, Chana Weil-Kennedy", "title": "The Complexity of Verifying Population Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols [Angluin et al., PODC, 2004] are a model of distributed\ncomputation in which indistinguishable, finite-state agents interact in pairs\nto decide if their initial configuration, i.e., the initial number of agents in\neach state, satisfies a given property. In a seminal paper Angluin et al.\nclassified population protocols according to their communication mechanism, and\nconducted an exhaustive study of the expressive power of each class, that is,\nof the properties they can decide [Angluin et al., Distributed Computing,\n2007]. In this paper we study the correctness problem for population protocols,\ni.e., whether a given protocol decides a given property. A previous paper\n[Esparza et al., Acta Informatica, 2017] has shown that the problem is\ndecidable for the main population protocol model, but at least as hard as the\nreachability problem for Petri nets, which has recently been proved to have\nnon-elementary complexity. Motivated by this result, we study the computational\ncomplexity of the correctness problem for all other classes introduced by\nAngluin et al., some of which are less powerful than the main model. Our main\nresults show that for the class of observation models the complexity of the\nproblem is much lower, ranging from ${\\Pi}_2^p$ to PSPACE.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 16:06:33 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 15:30:18 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Esparza", "Javier", ""], ["Jaax", "Stefan", ""], ["Raskin", "Mikhail", ""], ["Weil-Kennedy", "Chana", ""]]}, {"id": "1912.06611", "submitter": "Antoine Amarilli", "authors": "Assia Mahboubi and Thomas Sibut-Pinote", "title": "A Formal Proof of the Irrationality of $\\zeta(3)$", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  18, 2021) lmcs:7193", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a complete formal verification of a proof that the\nevaluation of the Riemann zeta function at 3 is irrational, using the Coq proof\nassistant. This result was first presented by Ap\\'ery in 1978, and the proof we\nhave formalized essentially follows the path of his original presentation. The\ncrux of this proof is to establish that some sequences satisfy a common\nrecurrence. We formally prove this result by an a posteriori verification of\ncalculations performed by computer algebra algorithms in a Maple session. The\nrest of the proof combines arithmetical ingredients and asymptotic analysis,\nwhich we conduct by extending the Mathematical Components libraries.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 17:19:34 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 13:50:33 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 20:57:12 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 19:15:27 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 12:39:05 GMT"}, {"version": "v6", "created": "Wed, 17 Feb 2021 13:07:44 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Mahboubi", "Assia", ""], ["Sibut-Pinote", "Thomas", ""]]}, {"id": "1912.07042", "submitter": "Nathalie Bertrand", "authors": "Nathalie Bertrand and Patricia Bouyer and Anirban Majumdar", "title": "Reconfiguration and Message Losses in Parameterized Broadcast Networks", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (March 18,\n  2021) lmcs:7280", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Broadcast networks allow one to model networks of identical nodes\ncommunicating through message broadcasts. Their parameterized verification aims\nat proving a property holds for any number of nodes, under any communication\ntopology, and on all possible executions. We focus on the coverability problem\nwhich dually asks whether there exists an execution that visits a configuration\nexhibiting some given state of the broadcast protocol. Coverability is known to\nbe undecidable for static networks, i.e. when the number of nodes and\ncommunication topology is fixed along executions. In contrast, it is decidable\nin PTIME when the communication topology may change arbitrarily along\nexecutions, that is for reconfigurable networks. Surprisingly, no lower nor\nupper bounds on the minimal number of nodes, or the minimal length of covering\nexecution in reconfigurable networks, appear in the literature.\n  In this paper we show tight bounds for cutoff and length, which happen to be\nlinear and quadratic, respectively, in the number of states of the protocol. We\nalso introduce an intermediary model with static communication topology and\nnon-deterministic message losses upon sending. We show that the same tight\nbounds apply to lossy networks, although, reconfigurable executions may be\nlinearly more succinct than lossy executions. Finally, we show NP-completeness\nfor the natural optimisation problem associated with the cutoff.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 13:56:52 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 08:57:53 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 15:46:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bertrand", "Nathalie", ""], ["Bouyer", "Patricia", ""], ["Majumdar", "Anirban", ""]]}, {"id": "1912.07309", "submitter": "Tom\\'a\\v{s} Masopust", "authors": "Jan Komenda and Tom\\'a\\v{s} Masopust", "title": "Conditions for Hierarchical Supervisory Control under Partial\n  Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental problem in hierarchical supervisory control under partial\nobservation is to find conditions preserving observability between the original\n(low-level) and the abstracted (high-level) plants. Two conditions for\nobservable specifications were identified in the literature -- observation\nconsistency (OC) and local observation consistency (LOC). However, the\ndecidability of OC and LOC were left open. We show that both OC and LOC are\ndecidable for regular systems. We further show that these conditions do not\nguarantee that supremal (normal or relatively observable) sublanguages computed\non the low level and on the high level always coincide. To solve the issue, we\nsuggest a new condition -- modified observation consistency -- and show that\nunder this condition, the supremal normal sublanguages are preserved between\nthe levels, while the supremal relatively observable high-level sublanguage is\nat least as good as the supremal relatively observable low-level sublanguage,\ni.e., the high-level solution may be even better than the low-level solution.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 12:01:55 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Komenda", "Jan", ""], ["Masopust", "Tom\u00e1\u0161", ""]]}, {"id": "1912.07339", "submitter": "Martin E. Bidlingmaier", "authors": "Martin E. Bidlingmaier, Florian Faissole, Bas Spitters", "title": "Synthetic topology in Homotopy Type Theory for probabilistic programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ALEA Coq library formalizes measure theory based on a variant of the Giry\nmonad on the category of sets. This enables the interpretation of a\nprobabilistic programming language with primitives for sampling from discrete\ndistributions. However, continuous distributions have to be discretized because\nthe corresponding measures cannot be defined on all subsets of their carriers.\n  This paper proposes the use of synthetic topology to model continuous\ndistributions for probabilistic computations in type theory. We study the\ninitial $\\sigma$-frame and the corresponding induced topology on arbitrary\nsets. Based on these intrinsic topologies we define valuations and lower\nintegrals on sets, and prove versions of the Riesz and Fubini theorems. We then\nshow how the Lebesgue valuation, and hence continuous distributions, can be\nconstructed.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 13:25:19 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 12:36:41 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Bidlingmaier", "Martin E.", ""], ["Faissole", "Florian", ""], ["Spitters", "Bas", ""]]}, {"id": "1912.07340", "submitter": "Adnan Rashid", "authors": "Sa'ed Abed, Adnan Rashid and Osman Hasan", "title": "Formal Analysis of the Biological Circuits using Higher-order-logic\n  Theorem Proving", "comments": "6 Pages", "journal-ref": "Symposium on Applied Computing (SAC-2020)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic Biology is an interdisciplinary field that utilizes\nwell-established engineering principles, ranging from electrical, control and\ncomputer systems, for analyzing the biological systems, such as biological\ncircuits, enzymes, pathways and controllers. Traditionally, these biological\nsystems, i.e., the genetic circuits are analyzed using paper-and-pencil proofs\nand computer-based simulations techniques. However, these methods cannot\nprovide accurate results due to their inherent limitations such as human\nerror-proneness, round-off errors and the unverified algorithms present in the\ncore of the tools, providing such analyses. In this paper, we propose to use\nhigher-order-logic theorem proving as a complementary technique for analyzing\nthese systems and thus overcome the above-mentioned issues. In particular, we\npropose a higher-order-logic theorem proving based framework to formally reason\nabout the genetic circuits used in synthetic biology. The main idea is to,\nfirst, model the continuous dynamics of the genetic circuits using differential\nequations. The next step is to obtain the systems' transfer function from their\ncorresponding block diagram representations. Finally, the transfer function\nbased analysis of these differential equation based models is performed using\nthe Laplace transform. To illustrate the practical utilization of our proposed\nframework, we formally analyze the genetic circuits of activated and repressed\nexpressions of protein.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 13:25:56 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 04:26:02 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Abed", "Sa'ed", ""], ["Rashid", "Adnan", ""], ["Hasan", "Osman", ""]]}, {"id": "1912.07462", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "On the Unity of Logic: a Sequential, Unpolarized Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work aims to give a unity of logic via standard sequential,\nunpolarized games. Specifically, our vision is that there must be\nmathematically precise concepts of linear refinement and intuitionistic\nrestriction of logic such that the linear refinement of classical logic (CL)\ncoincides with (classical) linear logic (LL), and its intuitionistic\nrestriction with the linear refinement of intuitionistic logic (IL) into\nintuitionistic LL (ILL). However, LL is, in contradiction to the name, cannot\nbe the linear refinement of CL at least from the game-semantic point of view\ndue to its concurrency and polarization. In fact, existing game semantics of LL\nemploys concurrency, which is rather exotic to game semantics of ILL, IL or CL.\nAlso, linear negation in LL is never true in (game semantics of) ILL, IL or CL.\nIn search for the truly linear refinement of CL, we carve out (a sequent\ncalculus of) linear logic negative ($LL^-$) from (the two-sided sequent\ncalculus of) LL, and introducing a new distribution axiom $! ? A \\vdash ? ! A$\n(for a translation of sequents $\\Delta \\vdash \\Gamma$ for CL into the sequents\n$! \\Delta \\vdash ? \\Gamma$ for $LL^-$). We then give a categorical semantics of\n$LL^-$, for which we introduce why not monad ?, dual to the well-known of\ncourse comonad !, giving a categorical translation $\\Delta \\rightarrow \\Gamma =\n? (\\Delta \\multimap \\Gamma) \\cong ! \\Delta \\multimap ? \\Gamma$ of CL into\n$LL^-$, which is the Kleisli extension of the standard translation $\\Delta\n\\rightarrow \\Gamma = ! \\Delta \\multimap \\Gamma$ of IL into ILL. Moreover, we\ninstantiate the categorical semantics by fully complete (sequential,\nunpolarized) game semantics of $LL^-$ (without atoms), for which we introduce\nlinearity of strategies.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:54:27 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1912.07475", "submitter": "Shqiponja Ahmetaj", "authors": "Shqiponja Ahmetaj, Magdalena Ortiz, and Mantas Simkus", "title": "Polynomial Rewritings from Expressive Description Logics with Closed\n  Predicates to Variants of Datalog", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2019.103220", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, complete and incomplete information coexist. For this\nreason, the knowledge representation and database communities have long shown\ninterest in simultaneously supporting the closed- and the open-world views when\nreasoning about logic theories. Here we consider the setting of querying\npossibly incomplete data using logic theories, formalized as the evaluation of\nan ontology-mediated query (OMQ) that pairs a query with a theory, sometimes\ncalled an ontology, expressing background knowledge. This can be further\nenriched by specifying a set of closed predicates from the theory that are to\nbe interpreted under the closed-world assumption, while the rest are\ninterpreted with the open-world view. In this way we can retrieve more precise\nanswers to queries by leveraging the partial completeness of the data.\n  The central goal of this paper is to understand the relative expressiveness\nof OMQ languages in which the ontology is written in the expressive Description\nLogic (DL) ALCHOI and includes a set of closed predicates. We consider a\nrestricted class of conjunctive queries. Our main result is to show that every\nquery in this non-monotonic query language can be translated in polynomial time\ninto Datalog with negation under the stable model semantics. To overcome the\nchallenge that Datalog has no direct means to express the existential\nquantification present in ALCHOI, we define a two-player game that\ncharacterizes the satisfaction of the ontology, and design a Datalog query that\ncan decide the existence of a winning strategy for the game. If there are no\nclosed predicates, that is in the case of querying a plain ALCHOI knowledge\nbase, our translation yields a positive disjunctive Datalog program of\npolynomial size. To the best of our knowledge, unlike previous translations for\nrelated fragments with expressive (non-Horn) DLs, these are the first\npolynomial time translations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 16:15:06 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Ahmetaj", "Shqiponja", ""], ["Ortiz", "Magdalena", ""], ["Simkus", "Mantas", ""]]}, {"id": "1912.07804", "submitter": "Shufang Zhu", "authors": "Shufang Zhu, Giuseppe De Giacomo, Geguang Pu, Moshe Vardi", "title": "LTLf Synthesis with Fairness and Stability Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In synthesis, assumptions are constraints on the environment that rule out\ncertain environment behaviors. A key observation here is that even if we\nconsider systems with LTLf goals on finite traces, environment assumptions need\nto be expressed over infinite traces, since accomplishing the agent goals may\nrequire an unbounded number of environment action. To solve synthesis with\nrespect to finite-trace LTLf goals under infinite-trace assumptions, we could\nreduce the problem to LTL synthesis. Unfortunately, while synthesis in LTLf and\nin LTL have the same worst-case complexity (both 2EXPTIME-complete), the\nalgorithms available for LTL synthesis are much more difficult in practice than\nthose for LTLf synthesis. In this work we show that in interesting cases we can\navoid such a detour to LTL synthesis and keep the simplicity of LTLf synthesis.\nSpecifically, we develop a BDD-based fixpoint-based technique for handling\nbasic forms of fairness and of stability assumptions. We show, empirically,\nthat this technique performs much better than standard LTL synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 03:44:39 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhu", "Shufang", ""], ["De Giacomo", "Giuseppe", ""], ["Pu", "Geguang", ""], ["Vardi", "Moshe", ""]]}, {"id": "1912.07834", "submitter": "Michiaki Tatsubori", "authors": "Michiaki Tatsubori, Asim Munawar, Takao Moriyama", "title": "Design and Implementation of Linked Planning Domain Definition Language", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a critical component of any artificial intelligence system that\nconcerns the realization of strategies or action sequences typically for\nintelligent agents and autonomous robots. Given predefined parameterized\nactions, a planning service should accept a query with the goal and initial\nstate to give a solution with a sequence of actions applied to environmental\nobjects. This paper addresses the problem by providing a repository of actions\ngenerically applicable to various environmental objects based on Semantic Web\ntechnologies. Ontologies are used for asserting constraints in common sense as\nwell as for resolving compatibilities between actions and states. Constraints\nare defined using Web standards such as SPARQL and SHACL to allow conditional\npredicates. We demonstrate the usefulness of the proposed planning domain\ndescription language with our robotics applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 06:05:49 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Tatsubori", "Michiaki", ""], ["Munawar", "Asim", ""], ["Moriyama", "Takao", ""]]}, {"id": "1912.08277", "submitter": "Michel de Rougemont", "authors": "Richard Lassaigne and Michel de Rougemont", "title": "Testing Membership for Timed Automata", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a timed automata which admits thick components and a timed word $x$, we\npresent a tester which decides if $x$ is in the language of the automaton or if\n$x$ is $\\epsilon$-far from the language, using finitely many samples taken from\nthe weighted time distribution $\\mu$ associated with an input $x$. We introduce\na distance between timed words, the {\\em timed edit distance}, which\ngeneralizes the classical edit distance. A timed word $x$ is $\\epsilon$-far\nfrom a timed language if its relative distance to the language is greater than\n$\\epsilon$.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:24:41 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:55:15 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Lassaigne", "Richard", ""], ["de Rougemont", "Michel", ""]]}, {"id": "1912.08418", "submitter": "Alexander Kurz", "authors": "Alexander Kurz, Andrew Moshier, Achim Jung", "title": "Stone Duality for Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how Stone duality can be extended from maps to relations. This is\nachieved by working order enriched and defining a relation from A to B as both\nan order-preserving function from the opposite of A times B to the 2-element\nchain and as a subobject of A times B. We show that dual adjunctions and\nequivalences between regular categories, taken in a suitably order enriched\nsense, extend to (framed bi)categories of relations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 07:28:16 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 11:23:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kurz", "Alexander", ""], ["Moshier", "Andrew", ""], ["Jung", "Achim", ""]]}, {"id": "1912.08482", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky and Simon Kn\\\"auer", "title": "Hardness of Network Satisfaction for Relation Algebras with Normal\n  Representations", "comments": "11 pages. Accepted for publication in the proceedings of RAMICS 2020\n  published by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the general network satisfaction\nproblem for a finite relation algebra $A$ with a normal representation $B$. If\n$B$ contains a non-trivial equivalence relation with a finite number of\nequivalence classes, then the network satisfaction problem for $A$ is NP-hard.\nAs a second result, we prove hardness if $B$ has domain size at least three and\ncontains no non-trivial equivalence relations but a symmetric atom $a$ with a\nforbidden triple $(a,a,a)$, that is, $a \\not\\leq a \\circ a$. We illustrate how\nto apply our conditions on two small relation algebras.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:38:32 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:59:51 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""]]}, {"id": "1912.08715", "submitter": "Miikka Vilander", "authors": "Lauri Hella, Miikka Vilander", "title": "Formula size games for modal logic and $\\mu$-calculus", "comments": "This is a preprint of an article published in Journal of Logic and\n  Computation Published by Oxford University Press. arXiv admin note:\n  substantial text overlap with arXiv:1604.07225", "journal-ref": "Journal of Logic and Computation, exz025, Oxford University Press,\n  2019", "doi": "10.1093/logcom/exz025", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new version of formula size game for modal logic. The game\ncharacterizes the equivalence of pointed Kripke-models up to formulas of given\nnumbers of modal operators and binary connectives. Our game is similar to the\nwell-known Adler-Immerman game. However, due to a crucial difference in the\ndefinition of positions of the game, its winning condition is simpler, and the\nsecond player does not have a trivial optimal strategy. Thus, unlike the\nAdler-Immerman game, our game is a genuine two-person game. We illustrate the\nuse of the game by proving a non-elementary succinctness gap between\nbisimulation invariant first-order logic $\\mathrm{FO}$ and (basic) modal logic\n$\\mathrm{ML}$. We also present a version of the game for the modal\n$\\mu$-calculus $\\mathrm{L}_\\mu$ and show that $\\mathrm{FO}$ is also\nnon-elementarily more succinct than $\\mathrm{L}_\\mu$.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 06:39:49 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Hella", "Lauri", ""], ["Vilander", "Miikka", ""]]}, {"id": "1912.08966", "submitter": "EPTCS", "authors": "Rachid Echahed, Detlef Plump", "title": "Proceedings Tenth International Workshop on Graph Computation Models", "comments": null, "journal-ref": "EPTCS 309, 2019", "doi": "10.4204/EPTCS.309", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the post-proceedings of the Tenth International Workshop\non Graph Computation Models (GCM 2019: http://gcm2019.imag.fr). The workshop\nwas held in Eindhoven, The Netherlands, on July 17th, 2019, as part of STAF\n2019 (Software Technologies: Applications and Foundations).\n  Graphs are common mathematical structures that are visual and intuitive. They\nconstitute a natural and seamless way for system modelling in science,\nengineering and beyond, including computer science, biology, business process\nmodelling, etc. Graph computation models constitute a class of very high-level\nmodels where graphs are first-class citizens. The aim of the International GCM\nWorkshop series is to bring together researchers interested in all aspects of\ncomputation models based on graphs and graph transformation. It promotes the\ncross-fertilizing exchange of ideas and experiences among senior and young\nresearchers from the different communities interested in the foundations,\napplications, and implementations of graph computation models and related\nareas.\n  These post-proceedings contain four selected papers from GCM2019 proceedings\nand an invited presentation that gives an account of the very successful panel\ndiscussion dedicated to the Analysis of Graph Transformation Systems, which\ntook place during the workshop and was animated by Reiko Heckel, Leen Lambers\nand Maryam Ghaffari Saadat.\n  All submissions were subject to careful refereeing. The topics of accepted\npapers include theoretical aspects of graph transformation and parsing\ntechniques as well as an application to model-driven engineering.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 00:44:10 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Echahed", "Rachid", ""], ["Plump", "Detlef", ""]]}, {"id": "1912.09298", "submitter": "Caterina Viola", "authors": "Manuel Bodirsky, Marcello Mamino, Caterina Viola", "title": "Piecewise Linear Valued CSPs Solvable by Linear Programming Relaxation", "comments": "45 pages. arXiv admin note: substantial text overlap with\n  arXiv:1804.01710", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valued constraint satisfaction problems (VCSPs) are a large class of\ncombinatorial optimisation problems. The computational complexity of VCSPs\ndepends on the set of allowed cost functions in the input. Recently, the\ncomputational complexity of all VCSPs for finite sets of cost functions over\nfinite domains has been classified. Many natural optimisation problems,\nhowever, cannot be formulated as VCSPs over a finite domain. We initiate the\nsystematic investigation of infinite-domain VCSPs by studying the complexity of\nVCSPs for piecewise linear homogeneous cost functions. Such VCSPs can be solved\nin polynomial time if the cost functions are improved by fully symmetric\nfractional operations of all arities. We show this by reducing the problem to a\nfinite-domain VCSP which can be solved using the basic linear program\nrelaxation. It follows that VCSPs for submodular PLH cost functions can be\nsolved in polynomial time; in fact, we show that submodular PLH functions form\na maximally tractable class of PLH cost functions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 10:56:45 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""], ["Viola", "Caterina", ""]]}, {"id": "1912.09571", "submitter": "Samuel Alexander", "authors": "Samuel Allen Alexander", "title": "Measuring the intelligence of an idealized mechanical knowing agent", "comments": "17 pages, CIFMA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a notion of the intelligence level of an idealized mechanical\nknowing agent. This is motivated by efforts within artificial intelligence\nresearch to define real-number intelligence levels of complicated intelligent\nsystems. Our agents are more idealized, which allows us to define a much\nsimpler measure of intelligence level for them. In short, we define the\nintelligence level of a mechanical knowing agent to be the supremum of the\ncomputable ordinals that have codes the agent knows to be codes of computable\nordinals. We prove that if one agent knows certain things about another agent,\nthen the former necessarily has a higher intelligence level than the latter.\nThis allows our intelligence notion to serve as a stepping stone to obtain\nresults which, by themselves, are not stated in terms of our intelligence\nnotion (results of potential interest even to readers totally skeptical that\nour notion correctly captures intelligence). As an application, we argue that\nthese results comprise evidence against the possibility of intelligence\nexplosion (that is, the notion that sufficiently intelligent machines will\neventually be capable of designing even more intelligent machines, which can\nthen design even more intelligent machines, and so on).\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:03:00 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Alexander", "Samuel Allen", ""]]}, {"id": "1912.09607", "submitter": "EPTCS", "authors": "Reiko Heckel, Leen Lambers, Maryam Ghaffari Saadat", "title": "Analysis of Graph Transformation Systems: Native vs Translation-based\n  Techniques", "comments": "In Proceedings GCM 2019, arXiv:1912.08966", "journal-ref": "EPTCS 309, 2019, pp. 1-22", "doi": "10.4204/EPTCS.309.1", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper summarises the contributions in a session at GCM 2019 presenting\nand discussing the use of native and translation-based solutions to common\nanalysis problems for Graph Transformation Systems (GTSs). In addition to a\ncomparison of native and translation-based techniques in this area, we explore\ndesign choices for the latter, s.a. choice of logic and encoding method, which\nhave a considerable impact on the overall quality and complexity of the\nanalysis. We substantiate our arguments by citing literature on application of\ntheorem provers, model checkers, and SAT/SMT solver in GTSs, and conclude with\na general discussion from a software engineering perspective, including\ncomments from the workshop participants, and recommendations on how to\ninvestigate important design choices in the future.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:39:27 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Heckel", "Reiko", ""], ["Lambers", "Leen", ""], ["Saadat", "Maryam Ghaffari", ""]]}, {"id": "1912.09611", "submitter": "EPTCS", "authors": "Rosemary Monahan (Maynooth University, Ireland), Virgile Prevosto\n  (Universit\\'e Paris-Saclay, France), Jose Proen\\c{c}a (HASLab/INESC-TEC &\n  CISTER/ISEP, Portugal)", "title": "Proceedings Fifth Workshop on Formal Integrated Development Environment", "comments": null, "journal-ref": "EPTCS 310, 2019", "doi": "10.4204/EPTCS.310", "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of F-IDE 2019, the fifth international\nworkshop on Formal Integrated Development Environment, which was held on\nOctober 7, 2019 in Porto, Portugal, as part of FM'19, the 3rd World Congress on\nFormal Methods. High levels of safety, security and privacy standards require\nthe use of formal methods to specify and develop compliant software\n(sub)systems. Any standard comes with an assessment process, which requires a\ncomplete documentation of the application in order to ease the justification of\ndesign choices and the review of code and proofs. Thus tools are needed for\nhandling specifications, program constructs and verification artifacts. The aim\nof the F-IDE workshop is to provide a forum for presenting and discussing\nresearch efforts as well as experience returns on design, development and usage\nof formal IDE aiming at making formal methods \"easier\" for both specialists and\nnon-specialists.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:49:53 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Monahan", "Rosemary", "", "Maynooth University, Ireland"], ["Prevosto", "Virgile", "", "Universit\u00e9 Paris-Saclay, France"], ["Proen\u00e7a", "Jose", "", "HASLab/INESC-TEC &\n  CISTER/ISEP, Portugal"]]}, {"id": "1912.09715", "submitter": "Andrzej Szalas", "authors": "Andrzej Szalas", "title": "A Paraconsistent ASP-like Language with Tractable Model Generation", "comments": null, "journal-ref": "Journal of Applied Logic - IfColog Journal of Logic and their\n  Applications, vol. 7, No. 3, 2020, 361-389,\n  http://www.collegepublications.co.uk/downloads/ifcolog00039.pdf", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is nowadays a dominant rule-based knowledge\nrepresentation tool. Though existing ASP variants enjoy efficient\nimplementations, generating an answer set remains intractable. The goal of this\nresearch is to define a new \\asp-like rule language, 4SP, with tractable model\ngeneration. The language combines ideas of ASP and a paraconsistent rule\nlanguage 4QL. Though 4SP shares the syntax of \\asp and for each program all its\nanswer sets are among 4SP models, the new language differs from ASP in its\nlogical foundations, the intended methodology of its use and complexity of\ncomputing models.\n  As we show in the paper, 4QL can be seen as a paraconsistent counterpart of\nASP programs stratified with respect to default negation. Although model\ngeneration of well-supported models for 4QL programs is tractable, dropping\nstratification makes both 4QL and ASP intractable. To retain tractability while\nallowing non-stratified programs, in 4SP we introduce trial expressions\ninterlacing programs with hypotheses as to the truth values of default\nnegations. This allows us to develop a~model generation algorithm with\ndeterministic polynomial time complexity.\n  We also show relationships among 4SP, ASP and 4QL.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:35:29 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Szalas", "Andrzej", ""]]}, {"id": "1912.09741", "submitter": "Roy Overbeek", "authors": "Roy Overbeek", "title": "Formalizing Determinacy of Concurrent Revisions", "comments": "To appear in: Proceedings of the 9th ACM SIGPLAN International\n  Conference on Certified Programs and Proofs (CPP '20), January 20--21, 2020,\n  New Orleans, LA, USA. ACM, New York, NY, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent revisions is a concurrency control model designed to guarantee\ndeterminacy, meaning that the outcomes of programs are uniquely determined.\nThis paper describes an Isabelle/HOL formalization of the model's operational\nsemantics and proof of determinacy. We discuss and resolve subtle ambiguities\nin the operational semantics and simplify the proof of determinacy. Although\nour findings do not appear to correspond to bugs in implementations, the\nformalization highlights some of the challenges involved in the design and\nverification of concurrency control models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 10:24:10 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Overbeek", "Roy", ""]]}, {"id": "1912.09797", "submitter": "Eryk Kopczy\\'nski", "authors": "Eryk Kopczynski", "title": "Axiomatizing rectangular grids with no extra non-unary relations", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a formula $\\phi$ which axiomatizes non-narrow rectangular grids\nwithout using any binary relations other than the grid neighborship relations.\nAs a corollary, we prove that a set $A \\subseteq \\mathbb{N}$ is a spectrum of a\nformula which has only planar models if numbers $n \\in A$ can be recognized by\na non-deterministic Turing machine (or a one-dimensional cellular automaton) in\ntime $t(n)$ and space $s(n)$, where $t(n)s(n) \\leq n$ and $t(n),s(n) =\n\\Omega(\\log(n))$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 13:02:33 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kopczynski", "Eryk", ""]]}, {"id": "1912.09875", "submitter": "Frederik Meyer B{\\o}nneland", "authors": "Frederik Meyer B{\\o}nneland, Peter Gj{\\o}l Jensen, Kim Guldstrand\n  Larsen, Marco Mu\\~niz, Ji\\v{r}\\'i Srba", "title": "Stubborn Set Reduction for Two-Player Reachability Games", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (March 18,\n  2021) lmcs:7278", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partial order reductions have been successfully applied to model checking of\nconcurrent systems and practical applications of the technique show nontrivial\nreduction in the size of the explored state space. We present a theory of\npartial order reduction based on stubborn sets in the game-theoretical setting\nof 2-player games with reachability objectives. Our stubborn reduction allows\nus to prune the interleaving behaviour of both players in the game, and we\nformally prove its correctness on the class of games played on general labelled\ntransition systems. We then instantiate the framework to the class of weighted\nPetri net games with inhibitor arcs and provide its efficient implementation in\nthe model checker TAPAAL. Finally, we evaluate our stubborn reduction on\nseveral case studies and demonstrate its efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:19:00 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 12:06:15 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 13:53:12 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 09:25:06 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 16:36:19 GMT"}, {"version": "v6", "created": "Fri, 19 Feb 2021 17:48:37 GMT"}, {"version": "v7", "created": "Wed, 17 Mar 2021 13:57:25 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["B\u00f8nneland", "Frederik Meyer", ""], ["Jensen", "Peter Gj\u00f8l", ""], ["Larsen", "Kim Guldstrand", ""], ["Mu\u00f1iz", "Marco", ""], ["Srba", "Ji\u0159\u00ed", ""]]}, {"id": "1912.10040", "submitter": "John van de Wetering", "authors": "Abraham Westerbaan and Bas Westerbaan and John van de Wetering", "title": "A characterisation of ordered abstract probabilities", "comments": "12 pages. V2: Minor changes", "journal-ref": "Proceedings of LICS2020 (35th Annual ACM/IEEE Symposium on Logic\n  in Computer Science)", "doi": "10.1145/3373718.3394742", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer science, especially when dealing with quantum computing or other\nnon-standard models of computation, basic notions in probability theory like \"a\npredicate\" vary wildly. There seems to be one constant: the only useful example\nof an algebra of probabilities is the real unit interval. In this paper we try\nto explain this phenomenon. We will show that the structure of the real unit\ninterval naturally arises from a few reasonable assumptions. We do this by\nstudying effect monoids, an abstraction of the algebraic structure of the real\nunit interval: it has an addition $x+y$ which is only defined when $x+y\\leq 1$\nand an involution $x\\mapsto 1-x$ which make it an effect algebra, in\ncombination with an associative (possibly non-commutative) multiplication.\nExamples include the unit intervals of ordered rings and Boolean algebras.\n  We present a structure theory for effect monoids that are $\\omega$-complete,\ni.e. where every increasing sequence has a supremum. We show that any\n$\\omega$-complete effect monoid embeds into the direct sum of a Boolean algebra\nand the unit interval of a commutative unital C$^*$-algebra. This gives us from\nfirst principles a dichotomy between sharp logic, represented by the Boolean\nalgebra part of the effect monoid, and probabilistic logic, represented by the\ncommutative C$^*$-algebra. Some consequences of this characterisation are that\nthe multiplication must always be commutative, and that the unique\n$\\omega$-complete effect monoid without zero divisors and more than 2 elements\nmust be the real unit interval. Our results give an algebraic characterisation\nand motivation for why any physical or logical theory would represent\nprobabilities by real numbers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:21:41 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:13:19 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Westerbaan", "Abraham", ""], ["Westerbaan", "Bas", ""], ["van de Wetering", "John", ""]]}, {"id": "1912.10041", "submitter": "Kees Middelburg", "authors": "C. A. Middelburg", "title": "Probabilistic process algebra and strategic interleaving", "comments": "30 pages, major revision with adaptation of example from\n  arXiv:2003.00473 incorporated (also text overlap with arXiv:1703.06822)", "journal-ref": "Scientific Annals of Computer Science 30(2):205--243 (2020)", "doi": "10.7561/SACS.2020.2.205", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first present a probabilistic version of ACP that rests on the principle\nthat probabilistic choices are always resolved before choices involved in\nalternative composition and parallel composition are resolved and then extend\nthis probabilistic version of ACP with a form of interleaving in which parallel\nprocesses are interleaved according to what is known as a process-scheduling\npolicy in the field of operating systems. We use the term strategic\ninterleaving for this more constrained form of interleaving. The extension\ncovers probabilistic process-scheduling policies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:54:45 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 09:38:57 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 13:12:43 GMT"}, {"version": "v4", "created": "Sun, 15 Mar 2020 15:09:22 GMT"}, {"version": "v5", "created": "Tue, 21 Apr 2020 13:42:04 GMT"}, {"version": "v6", "created": "Tue, 8 Sep 2020 14:17:35 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Middelburg", "C. A.", ""]]}, {"id": "1912.10240", "submitter": "Amazigh Amrane", "authors": "Amazigh Amrane and Nicolas Bedon", "title": "Logic and Rational Languages of Scattered and Countable Series-Parallel\n  Posets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $A$ be an alphabet and $SP^\\diamond(A)$ denote the class of all countable\nN-free partially ordered sets labeled by $A$, in which chains are scattered\nlinear orderings and antichains are finite. We characterize the rational\nlanguages of $SP^\\diamond(A)$ by means of logic. We define an extension of\nmonadic second-order logic by Presburger arithmetic, named P-MSO, such that a\nlanguage $L$ of $SP^\\diamond(A)$ is rational if and only if $L$ is the language\nof a sentence of P-MSO, with effective constructions from one formalism to the\nother. As a corollary, the P-MSO theory of $SP^\\diamond(A)$ is decidable.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 10:27:40 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Amrane", "Amazigh", ""], ["Bedon", "Nicolas", ""]]}, {"id": "1912.10277", "submitter": "Marcelo Coniglio", "authors": "Marcelo E. Coniglio, Aldo Figallo-Orellano and Ana C. Golzio", "title": "First-order swap structures semantics for some Logics of Formal\n  Inconsistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logics of formal inconsistency (LFIs, for short) are paraconsistent\nlogics (that is, logics containing contradictory but non-trivial theories)\nhaving a consistency connective which allows to recover the ex falso quodlibet\nprinciple in a controlled way. The aim of this paper is considering a novel\nsemantical approach to first-order LFIs based on Tarskian structures defined\nover swap structures, a special class of multialgebras. The proposed semantical\nframework generalizes previous aproaches to quantified LFIs presented in the\nliterature. The case of QmbC, the simpler quantified LFI expanding classical\nlogic, will be analyzed in detail. An axiomatic extension of QmbC called QLFI1o\nis also studied, which is equivalent to the quantified version of da Costa and\nD'Ottaviano 3-valued logic J3. The semantical structures for this logic turn\nout to be Tarkian structures based on twist structures. The expansion of QmbC\nand QLFI1o with a standard equality predicate is also considered.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 15:16:13 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Coniglio", "Marcelo E.", ""], ["Figallo-Orellano", "Aldo", ""], ["Golzio", "Ana C.", ""]]}, {"id": "1912.10285", "submitter": "Shilpi Goel", "authors": "Shilpi Goel, Anna Slobodova, Rob Sumners, and Sol Swords", "title": "Verifying x86 Instruction Implementations", "comments": "Pre-Print of CPP2020 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of modern microprocessors is a complex task that requires a\nsubstantial allocation of resources. Despite significant progress in formal\nverification, the goal of complete verification of an industrial design has not\nbeen achieved. In this paper, we describe a current contribution of formal\nmethods to the validation of modern x86 microprocessors at Centaur Technology.\nWe focus on proving correctness of instruction implementations, which includes\nthe decoding of an instruction, its translation into a sequence of\nmicro-operations, any subsequent execution of traps to microcode ROM, and the\nimplementation of these micro-operations in execution units. All these tasks\nare performed within one verification framework, which includes a theorem\nprover, a verified symbolic simulator, and SAT solvers. We describe the work of\ndefining the needed formal models for both the architecture and\nmicro-architecture in this framework, as well as tools for decomposing the\nrequisite properties into smaller lemmas which can be automatically checked. We\nadditionally cover the advantages and limitations of our approach. To our\nknowledge, there are no similar results in the verification of implementations\nof an x86 microprocessor.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 15:58:33 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Goel", "Shilpi", ""], ["Slobodova", "Anna", ""], ["Sumners", "Rob", ""], ["Swords", "Sol", ""]]}, {"id": "1912.10515", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira", "title": "Bringing Belief Base Change into Dynamic Epistemic Logic", "comments": "Published at DaLI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AGM's belief revision is one of the main paradigms in the study of belief\nchange operations. In this context, belief bases (prioritised bases) have been\nprimarily used to specify the agent's belief state. While the connection of\niterated AGM-like operations and their encoding in dynamic epistemic logics\nhave been studied before, few works considered how well-known postulates from\niterated belief revision theory can be characterised by means of belief bases\nand their counterpart in dynamic epistemic logic. Particularly, it has been\nshown that some postulates can be characterised through transformations in\npriority graphs, while others may not be represented that way. This work\ninvestigates changes in the semantics of Dynamic Preference Logic that give\nrise to an appropriate syntactic representation for its models that allow us to\nrepresent and reason about iterated belief base change in this logic.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 19:21:05 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""]]}, {"id": "1912.10606", "submitter": "L\\^e Th\\`anh D\\~ung Nguy\\^en", "authors": "L\\^e Th\\`anh D\\~ung Nguy\\^en", "title": "Complexity of correctness for pomset logic proof nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that it is coNP-complete to decide whether a given proof structure of\npomset logic is a correct proof net, using the graph-theoretic used in a\nprevious paper of ours (arXiv:1901.10247).\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:41:32 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 17:58:41 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 16:48:35 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Nguy\u00ean", "L\u00ea Th\u00e0nh D\u0169ng", ""]]}, {"id": "1912.10629", "submitter": "EPTCS", "authors": "Denis Cousineau (Mitsubishi Electric R&D Centre Europe (MERCE) Rennes,\n  France), David Mentr\\'e (Mitsubishi Electric R&D Centre Europe (MERCE)\n  Rennes, France), Hiroaki Inoue (Mitsubishi Electric Corporation Amagasaki,\n  Japan)", "title": "Automated Deductive Verification for Ladder Programming", "comments": "In Proceedings F-IDE 2019, arXiv:1912.09611", "journal-ref": "EPTCS 310, 2019, pp. 7-12", "doi": "10.4204/EPTCS.310.2", "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ladder Logics is a programming language standardized in IEC 61131-3 and\nwidely used for programming industrial Programmable Logic Controllers (PLC). A\nPLC program consists of inputs (whose values are given at runtime by factory\nsensors), outputs (whose values are given at runtime to factory actuators), and\nthe logical expressions computing output values from input values. Due to the\ngraphical form of Ladder programs, and the amount of inputs and outputs in\ntypical industrial programs, debugging such programs is time-consuming and\nerror-prone. We present, in this paper, a Why3-based tool prototype we have\nimplemented for automating the use of deductive verification in order to\nprovide an easy-to-use and robust debugging tool for Ladder programmers.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 05:40:01 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Cousineau", "Denis", "", "Mitsubishi Electric R&D Centre Europe"], ["Mentr\u00e9", "David", "", "Mitsubishi Electric R&D Centre Europe"], ["Inoue", "Hiroaki", "", "Mitsubishi Electric Corporation Amagasaki,\n  Japan"]]}, {"id": "1912.10630", "submitter": "EPTCS", "authors": "Fr\\'ed\\'eric Tuong (LRI, Universit\\'e Paris-Saclay), Burkhart Wolff\n  (LRI, Universit\\'e Paris-Saclay)", "title": "Deeply Integrating C11 Code Support into Isabelle/PIDE", "comments": "In Proceedings F-IDE 2019, arXiv:1912.09611", "journal-ref": "EPTCS 310, 2019, pp. 13-28", "doi": "10.4204/EPTCS.310.3", "report-no": null, "categories": "cs.PL cs.LO cs.SC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for C code in C11 syntax deeply integrated into the\nIsabelle/PIDE development environment. Our framework provides an abstract\ninterface for verification back-ends to be plugged-in independently. Thus,\nvarious techniques such as deductive program verification or white-box testing\ncan be applied to the same source, which is part of an integrated PIDE document\nmodel. Semantic back-ends are free to choose the supported C fragment and its\nsemantics. In particular, they can differ on the chosen memory model or the\nspecification mechanism for framing conditions.\n  Our framework supports semantic annotations of C sources in the form of\ncomments. Annotations serve to locally control back-end settings, and can\nexpress the term focus to which an annotation refers. Both the logical and the\nsyntactic context are available when semantic annotations are evaluated. As a\nconsequence, a formula in an annotation can refer both to HOL or C variables.\n  Our approach demonstrates the degree of maturity and expressive power the\nIsabelle/PIDE subsystem has achieved in recent years. Our integration technique\nemploys Lex and Yacc style grammars to ensure efficient deterministic parsing.\nWe present two case studies for the integration of (known) semantic back-ends\nin order to validate the design decisions for our back-end interface.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 05:40:20 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Tuong", "Fr\u00e9d\u00e9ric", "", "LRI, Universit\u00e9 Paris-Saclay"], ["Wolff", "Burkhart", "", "LRI, Universit\u00e9 Paris-Saclay"]]}, {"id": "1912.10633", "submitter": "EPTCS", "authors": "Markus Alexander Kuppe (Microsoft Research), Leslie Lamport (Microsoft\n  Research), Daniel Ricketts (Oracle Corporation)", "title": "The TLA+ Toolbox", "comments": "In Proceedings F-IDE 2019, arXiv:1912.09611", "journal-ref": "EPTCS 310, 2019, pp. 50-62", "doi": "10.4204/EPTCS.310.6", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the workflows supported by the TLA+ Toolbox to write and verify\nspecifications. We focus on features that are useful in industry because its\nusers are primarily engineers. Two features are novel in the scope of formal\nIDEs: CloudTLC connects the Toolbox with cloud computing to scale up model\nchecking. A Profiler helps to debug inefficient expressions and to pinpoint the\nsource of state space explosion. For those who wish to contribute to the\nToolbox or learn from its flaws, we present its technical architecture.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 05:41:30 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kuppe", "Markus Alexander", "", "Microsoft Research"], ["Lamport", "Leslie", "", "Microsoft\n  Research"], ["Ricketts", "Daniel", "", "Oracle Corporation"]]}, {"id": "1912.10634", "submitter": "EPTCS", "authors": "Julien Brunel (ONERA DTIS and Universit\\'e f\\'ed\\'erale de Toulouse,\n  France), David Chemouil (ONERA DTIS and Universit\\'e f\\'ed\\'erale de\n  Toulouse, France), Alcino Cunha (INESC TEC and Universidade do Minho,\n  Portugal), Nuno Macedo (INESC TEC and Universidade do Minho, Portugal)", "title": "Simulation under Arbitrary Temporal Logic Constraints", "comments": "In Proceedings F-IDE 2019, arXiv:1912.09611", "journal-ref": "EPTCS 310, 2019, pp. 63-69", "doi": "10.4204/EPTCS.310.7", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most model checkers provide a useful simulation mode, that allows users to\nexplore the set of possible behaviours by interactively picking at each state\nwhich event to execute next. Traditionally this simulation mode cannot take\ninto consideration additional temporal logic constraints, such as arbitrary\nfairness restrictions, substantially reducing its usability for debugging the\nmodelled system behaviour. Similarly, when a specification is false, even if\nall its counter-examples combined also form a set of behaviours, most model\ncheckers only present one of them to the user, providing little or no mechanism\nto explore alternatives. In this paper, we present a simple on-the-fly\nverification technique to allow the user to explore the behaviours that satisfy\nan arbitrary temporal logic specification, with an interactive process akin to\nsimulation. This technique enables a unified interface for simulating the\nmodelled system and exploring its counter-examples. The technique is formalised\nin the framework of state/event linear temporal logic and a proof of concept\nwas implemented in an event-based variant of the Electrum framework.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 05:41:51 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Brunel", "Julien", "", "ONERA DTIS and Universit\u00e9 f\u00e9d\u00e9rale de Toulouse,\n  France"], ["Chemouil", "David", "", "ONERA DTIS and Universit\u00e9 f\u00e9d\u00e9rale de\n  Toulouse, France"], ["Cunha", "Alcino", "", "INESC TEC and Universidade do Minho,\n  Portugal"], ["Macedo", "Nuno", "", "INESC TEC and Universidade do Minho, Portugal"]]}, {"id": "1912.10642", "submitter": "Paolo Perrone", "authors": "Paolo Perrone", "title": "Notes on Category Theory with examples from basic mathematics", "comments": "Lecture notes, 181 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes were originally developed as lecture notes for a category theory\ncourse. They should be well-suited to anyone that wants to learn category\ntheory from scratch and has a scientific mind. There is no need to know\nadvanced mathematics, nor any of the disciplines where category theory is\ntraditionally applied, such as algebraic geometry or theoretical computer\nscience. The only knowledge that is assumed from the reader is linear algebra.\nAll concepts are explained by giving concrete examples from different,\nnon-specialized areas of mathematics (such as basic group theory, graph theory,\nand probability). Not every example is helpful for every reader, but hopefully\nevery reader can find at least one helpful example per concept. The reader is\nencouraged to read all the examples, this way they may even learn something new\nabout a different field.\n  Particular emphasis is given to the Yoneda lemma and its significance, with\nboth intuitive explanations, detailed proofs, and specific examples. Another\ncommon theme in these notes is the relationship between categories and directed\nmultigraphs, which is treated in detail. From the applied point of view, this\nshows why categorical thinking can help whenever some process is taking place\non a graph. From the pure math point of view, this can be seen as the\n1-dimensional first step into the theory of simplicial sets. Finally, monads\nand comonads are treated on an equal footing, differently to most literature in\nwhich comonads are often overlooked as \"just the dual to monads\". Theorems,\ninterpretations and concrete examples are given for monads as well as for\ncomonads.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 06:38:45 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 02:26:10 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 16:27:21 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 15:53:30 GMT"}, {"version": "v5", "created": "Tue, 25 Aug 2020 13:46:09 GMT"}, {"version": "v6", "created": "Tue, 9 Feb 2021 16:39:48 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Perrone", "Paolo", ""]]}, {"id": "1912.10717", "submitter": "Malvin Gattinger", "authors": "Malvin Gattinger", "title": "Towards Symbolic Factual Change in DEL", "comments": "11 pages, original proceedings available at\n  http://www2.sfs.uni-tuebingen.de/esslli-stus-2017/#proceedings", "journal-ref": "Karoliina Lohiniva, Johannes Wahle (Eds.): Proceedings of the\n  ESSLLI 2017 Student Session, pp. 14-24, 2017", "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We extend symbolic model checking for Dynamic Epistemic Logic (DEL) with\nfactual change. Our transformers provide a compact representation of action\nmodels with pre- and postconditions, for both S5 and the general case. The\nmethod can be implemented using binary decision diagrams and we expect it to\nimprove model checking performance. As an example we give a symbolic\nrepresentation of the Sally-Anne false belief task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 10:26:34 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Gattinger", "Malvin", ""]]}, {"id": "1912.10816", "submitter": "Rene Haberland", "authors": "Ren\\'e Haberland", "title": "Narrowing Down XML Template Expansion and Schema Validation", "comments": "46 pages, 12 figures, 2 appendices", "journal-ref": "Master Thesis, 2007", "doi": null, "report-no": null, "categories": "cs.LO cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines how much template instantiation can narrow down schema\nvalidation for XML-documents. First, instantiation and validation are\nformalised. Properties towards their practical meaning are probed, an\nimplementation is developed. Requirements for an unification are elaborated and\na comparison is taken out. The semantics are formulated in terms of\ndenotational semantics as well as rule-based referring to the data models\nchosen. Formalisation makes it clearer instantiation is adequately represented.\nBoth semantics show, that the rules set for both, instantiation and validation,\ncannot totally be unified. However, reuse of simplified code also simplifies\nunification. Implementation allows unification of both processes on\ndocument-level. The validity of all implementations is guaranteed by a\ncomprehensive test suite. Analysis shows the minimal XML template language has\ngot regular grammar properties, except macros. An explanation was given, why\nfilters and arrows are not best, especially towards a unified language to be\nvariable and extensive. Recommendations for future language design are\nprovided. Instantiation shows a universal gap in applications, for instance, as\nseen by XSLT. Lack of expressibility of arbitrary functions in a schema is one\nsuch example, expressibility of the command language is another basic\nrestriction. Useful unification constraints are found out to be handy, such as\ntyping each slot. In order to obtain most flexibility out of command languages\nadaptations are required. An alternative to introducing constraints is the\neffective construction of special NFAs. Comparison criteria are introduced\nregarding mainly syntax and semantics. Comparisons is done accordingly. Despite\nits huge syntax definitions XSD was found weaker than RelaxNG or XML template\nlanguage. As template language the latter is considered universal.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:28:57 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 19:26:25 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Haberland", "Ren\u00e9", ""]]}, {"id": "1912.10824", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Matko Bo\\v{s}njak, Tim Rockt\\\"aschel, Sebastian\n  Riedel, Edward Grefenstette", "title": "Differentiable Reasoning on Large Knowledge Bases and Natural Language", "comments": "Accepted at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning with knowledge expressed in natural language and Knowledge Bases\n(KBs) is a major challenge for Artificial Intelligence, with applications in\nmachine reading, dialogue, and question answering. General neural architectures\nthat jointly learn representations and transformations of text are very\ndata-inefficient, and it is hard to analyse their reasoning process. These\nissues are addressed by end-to-end differentiable reasoning systems such as\nNeural Theorem Provers (NTPs), although they can only be used with small-scale\nsymbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension\nto NTPs addressing their complexity and scalability limitations, thus making\nthem applicable to real-world datasets. This result is achieved by dynamically\nconstructing the computation graph of NTPs and including only the most\npromising proof paths during inference, thus obtaining orders of magnitude more\nefficient models. Then, we propose a novel approach for jointly reasoning over\nKBs and textual mentions, by embedding logic facts and natural language\nsentences in a shared embedding space. We show that GNTPs perform on par with\nNTPs at a fraction of their cost while achieving competitive link prediction\nresults on large datasets, providing explanations for predictions, and inducing\ninterpretable models. Source code, datasets, and supplementary material are\navailable online at https://github.com/uclnlp/gntp.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:01:54 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Minervini", "Pasquale", ""], ["Bo\u0161njak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1912.10961", "submitter": "Juan Meleiro", "authors": "Juan Ferrer Meleiro and Hugo Luiz Mariano", "title": "Formalizing the Curry-Howard Correspondence", "comments": "26 pages. For the full source, see\n  https://gitlab.com/juanmeleiro/ic.git or contact Juan Meleiro", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Curry-Howard Correspondence has a long history, and still is a topic of\nactive research. Though there are extensive investigations into the subject,\nthere doesn't seem to be a definitive formulation of this result in the level\nof generality that it deserves. In the current work, we introduce the formalism\nof p-institutions that could unify previous aproaches. We restate the\ntradicional correspondence between typed $\\lambda$-calculi and propositional\nlogics inside this formalism, and indicate possible directions in which it\ncould foster new and more structured generalizations.\n  Furthermore, we indicate part of a formalization of the subject in the\nprogramming-language Idris, as a demonstration of how such theorem-proving\nenviroments could serve mathematical research.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 16:40:00 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Meleiro", "Juan Ferrer", ""], ["Mariano", "Hugo Luiz", ""]]}, {"id": "1912.11223", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen,\n  Ufuk Topcu", "title": "Scenario-Based Verification of Uncertain MDPs", "comments": "Accepted to TACAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov decision processes (MDPs) in which the transition\nprobabilities and rewards belong to an uncertainty set parametrized by a\ncollection of random variables. The probability distributions for these random\nparameters are unknown. The problem is to compute the probability to satisfy a\ntemporal logic specification within any MDP that corresponds to a sample from\nthese unknown distributions. In general, this problem is undecidable, and we\nresort to techniques from so-called scenario optimization. Based on a finite\nnumber of samples of the uncertain parameters, each of which induces an MDP,\nthe proposed method estimates the probability of satisfying the specification\nby solving a finite-dimensional convex optimization problem. The number of\nsamples required to obtain a high confidence on this estimate is independent\nfrom the number of states and the number of random parameters. Experiments on a\nlarge set of benchmarks show that a few thousand samples suffice to obtain\nhigh-quality confidence bounds with a high probability.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 06:41:48 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:32:44 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1912.11273", "submitter": "Stepan Kuznetsov", "authors": "Stepan Kuznetsov", "title": "Action Logic is Undecidable", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action logic is the algebraic logic (inequational theory) of residuated\nKleene lattices. This logic involves Kleene star, axiomatized by an induction\nscheme. For a stronger system which uses an $\\omega$-rule instead (infinitary\naction logic) Buszkowski and Palka (2007) have proved $\\Pi_1^0$-completeness\n(thus, undecidability). Decidability of action logic itself was an open\nquestion, raised by D. Kozen in 1994. In this article, we show that it is\nundecidable, more precisely, $\\Sigma_1^0$-complete. We also prove the same\ncomplexity results for all recursively enumerable logics between action logic\nand infinitary action logic; for fragments of those only one of the two lattice\n(additive) connectives; for action logic extended with the law of\ndistributivity.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 10:09:12 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Kuznetsov", "Stepan", ""]]}, {"id": "1912.11786", "submitter": "EPTCS", "authors": "Martin Suda (CTU, Prague, Czech Republic), Sarah Winkler (University\n  of Verona, Italy)", "title": "Proceedings of the Second International Workshop on Automated Reasoning:\n  Challenges, Applications, Directions, Exemplary Achievements", "comments": null, "journal-ref": "EPTCS 311, 2019", "doi": "10.4204/EPTCS.311", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the post-proceedings of the second ARCADE workshop, which took\nplace on the 26th August 2019 in Natal, Brazil, colocated with CADE-27. ARCADE\nstands for Automated Reasoning: Challenges, Applications, Directions, Exemplary\nachievements. The goal of this workshop was to bring together key people from\nvarious sub-communities of automated reasoning--such as SAT/SMT, resolution,\ntableaux, theory-specific calculi (e.g. for description logic, arithmetic, set\ntheory), interactive theorem proving---to discuss the present, past, and future\nof the field.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 07:00:29 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Suda", "Martin", "", "CTU, Prague, Czech Republic"], ["Winkler", "Sarah", "", "University\n  of Verona, Italy"]]}, {"id": "1912.12189", "submitter": "Utpal Bora", "authors": "Utpal Bora, Santanu Das, Pankaj Kukreja, Saurabh Joshi, Ramakrishna\n  Upadrasta, Sanjay Rajopadhye", "title": "LLOV: A Fast Static Data-Race Checker for OpenMP Programs", "comments": "Accepted in ACM TACO, August 2020", "journal-ref": null, "doi": "10.1145/3418597", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of Exascale computing, writing efficient parallel programs is\nindispensable and at the same time, writing sound parallel programs is very\ndifficult. Specifying parallelism with frameworks such as OpenMP is relatively\neasy, but data races in these programs are an important source of bugs. In this\npaper, we propose LLOV, a fast, lightweight, language agnostic, and static data\nrace checker for OpenMP programs based on the LLVM compiler framework. We\ncompare LLOV with other state-of-the-art data race checkers on a variety of\nwell-established benchmarks. We show that the precision, accuracy, and the F1\nscore of LLOV is comparable to other checkers while being orders of magnitude\nfaster. To the best of our knowledge, LLOV is the only tool among the\nstate-of-the-art data race checkers that can verify a C/C++ or FORTRAN program\nto be data race free.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 15:53:53 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 17:34:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bora", "Utpal", ""], ["Das", "Santanu", ""], ["Kukreja", "Pankaj", ""], ["Joshi", "Saurabh", ""], ["Upadrasta", "Ramakrishna", ""], ["Rajopadhye", "Sanjay", ""]]}, {"id": "1912.12223", "submitter": "Kumar Sankar Ray", "authors": "Litan Kumar Das and Kumar Sankar Ray", "title": "Bitopological Duality for Algebras of Fittings logic and Natural Duality\n  extension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a bitopological duality for algebras of\nFitting's multi-valued logic. We also extend the natural duality theory for\n$\\mathbb{ISP_I}(\\mathcal{L})$ by developing a duality for\n$\\mathbb{ISP}(\\mathcal{L})$, where $\\mathcal{L}$ is a finite algebra in which\nunderlying lattice is bounded distributive.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:38:19 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Das", "Litan Kumar", ""], ["Ray", "Kumar Sankar", ""]]}, {"id": "1912.12338", "submitter": "Szymon Toru\\'nczyk", "authors": "Szymon Toru\\'nczyk", "title": "Aggregate Queries on Sparse Databases", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algebraic framework for studying efficient algorithms for query\nevaluation, aggregation, enumeration, and maintenance under updates, on sparse\ndatabases. Our framework allows to treat those problems in a unified way, by\nconsidering various semirings, depending on the considered problem. As a\nconcrete application, we propose a powerful query language extending\nfirst-order logic by aggregation in multiple semirings. We obtain an optimal\nalgorithm for computing the answers of such queries on sparse databases. More\nprecisely, given a database from a fixed class with bounded expansion, the\nalgorithm computes in linear time a data structure which allows to enumerate\nthe set of answers to the query, with constant delay between two outputs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 21:15:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Toru\u0144czyk", "Szymon", ""]]}, {"id": "1912.12442", "submitter": "Andreas Pieris", "authors": "Pablo Barcelo, Victor Dalmau, Cristina Feier, Carsten Lutz, Andreas\n  Pieris", "title": "The Limits of Efficiency for Open- and Closed-World Query Evaluation\n  Under Guarded TGDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-mediated querying and querying in the presence of constraints are\ntwo key database problems where tuple-generating dependencies (TGDs) play a\ncentral role. In ontology-mediated querying, TGDs can formalize the ontology\nand thus derive additional facts from the given data, while in querying in the\npresence of constraints, they restrict the set of admissible databases. In this\nwork, we study the limits of efficient query evaluation in the context of the\nabove two problems, focussing on guarded and frontier-guarded TGDs and on UCQs\nas the actual queries. We show that a class of ontology-mediated queries (OMQs)\nbased on guarded TGDs can be evaluated in FPT iff the OMQs in the class are\nequivalent to OMQs in which the actual query has bounded treewidth, up to some\nreasonable assumptions. For querying in the presence of constraints, we\nconsider classes of constraint-query specifications (CQSs) that bundle a set of\nconstraints with an actual query. We show a dichotomy result for CQSs based on\nguarded TGDs that parallels the one for OMQs except that, additionally, FPT\ncoincides with PTime combined complexity. The proof is based on a novel\nconnection between OMQ and CQS evaluation. Using a direct proof, we also show a\nsimilar dichotomy result, again up to some reasonable assumptions, for CQSs\nbased on frontier-guarded TGDs with a bounded number of atoms in TGD heads. Our\nresults on CQSs can be viewed as extensions of Grohe's well-known\ncharacterization of the tractable classes of CQs (without constraints). Like\nGrohe's characterization, all the above results assume that the arity of\nrelation symbols is bounded by a constant. We also study the associated meta\nproblems, i.e., whether a given OMQ or CQS is equivalent to one in which the\nactual query has bounded treewidth.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 11:08:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Barcelo", "Pablo", ""], ["Dalmau", "Victor", ""], ["Feier", "Cristina", ""], ["Lutz", "Carsten", ""], ["Pieris", "Andreas", ""]]}, {"id": "1912.12837", "submitter": "Luca Roversi", "authors": "Gianluca Curzi and Luca Roversi", "title": "A type-assignment of linear erasure and duplication", "comments": "43 pages (10 pages of technical appendix). The final version will\n  appear on Theoretical Computer Science\n  https://doi.org/10.1016/j.tcs.2020.05.001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce $\\mathsf{LEM}$, a type-assignment system for the linear $\n\\lambda $-calculus that extends second-order $\\mathsf{IMLL}_2$, i.e.,\nintuitionistic multiplicative Linear Logic, by means of logical rules that\nweaken and contract assumptions, but in a purely linear setting. $\\mathsf{LEM}$\nenjoys both a mildly weakened cut-elimination, whose computational cost is\ncubic, and Subject reduction. A translation of $\\mathsf{LEM}$ into\n$\\mathsf{IMLL}_2$ exists such that the derivations of the former can\nexponentially compress the dimension of the derivations in the latter.\n$\\mathsf{LEM}$ allows for a modular and compact representation of boolean\ncircuits, directly encoding the fan-out nodes, by contraction, and disposing\ngarbage, by weakening. It can also represent natural numbers with terms very\nclose to standard Church numerals which, moreover, apply to Hereditarily Finite\nPermutations, i.e. a group structure that exists inside the linear $ \\lambda\n$-calculus.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:47:14 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 09:48:57 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Curzi", "Gianluca", ""], ["Roversi", "Luca", ""]]}, {"id": "1912.12893", "submitter": "Martin Dieguez", "authors": "Philippe Balbiani and Joseph Boudou and Mart\\'in Di\\'eguez and David\n  Fern\\'andez-Duque", "title": "Intuitionistic Linear Temporal Logics", "comments": "arXiv admin note: text overlap with arXiv:1704.02847,\n  arXiv:1803.05078", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider intuitionistic variants of linear temporal logic with `next',\n`until' and `release' based on expanding posets: partial orders equipped with\nan order-preserving transition function. This class of structures gives rise to\na logic which we denote $\\iltl$, and by imposing additional constraints we\nobtain the logics $\\itlb$ of persistent posets and $\\itlht$ of here-and-there\ntemporal logic, both of which have been considered in the literature. We prove\nthat $\\iltl$ has the effective finite model property and hence is decidable,\nwhile $\\itlb$ does not have the finite model property. We also introduce\nnotions of bounded bisimulations for these logics and use them to show that the\n`until' and `release' operators are not definable in terms of each other, even\nover the class of persistent posets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 11:49:31 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Balbiani", "Philippe", ""], ["Boudou", "Joseph", ""], ["Di\u00e9guez", "Mart\u00edn", ""], ["Fern\u00e1ndez-Duque", "David", ""]]}, {"id": "1912.12895", "submitter": "David Fern\\'andez-Duque", "authors": "Joseph Boudou and Mart\\'in Di\\'eguez and David Fern\\'andez-Duque and\n  Philip Kremer", "title": "Exploring the Jungle of Intuitionistic Temporal Logics", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). arXiv admin note: text overlap with arXiv:1803.05077", "journal-ref": null, "doi": "10.1017/S1471068421000089", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of intuitionistic temporal logics in Computer Science and\nArtificial Intelligence has become increasingly clear in the last few years.\nFrom the proof-theory point of view, intuitionistic temporal logics have made\nit possible to extend functional languages with new features via type theory,\nwhile from its semantical perspective several logics for reasoning about\ndynamical systems and several semantics for logic programming have their roots\nin this framework. In this paper we consider several axiomatic systems for\nintuitionistic linear temporal logic and show that each of these systems is\nsound for a class of structures based either on Kripke frames or on dynamic\ntopological systems. Our topological semantics features a new interpretation\nfor the `henceforth' modality that is a natural intuitionistic variant of the\nclassical one. Using the soundness results, we show that the seven logics\nobtained from the axiomatic systems are distinct.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 11:55:20 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 15:45:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Boudou", "Joseph", ""], ["Di\u00e9guez", "Mart\u00edn", ""], ["Fern\u00e1ndez-Duque", "David", ""], ["Kremer", "Philip", ""]]}, {"id": "1912.12958", "submitter": "EPTCS", "authors": "Giles Reger (University of Manchester)", "title": "Boldly Going Where No Prover Has Gone Before", "comments": "In Proceedings ARCADE 2019, arXiv:1912.11786", "journal-ref": "EPTCS 311, 2019, pp. 37-41", "doi": "10.4204/EPTCS.311.6", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I argue that the most interesting goal facing researchers in automated\nreasoning is being able to solve problems that cannot currently be solved by\nexisting tools and methods. This may appear obvious, and is clearly not an\noriginal thought, but focusing on this as a primary goal allows us to examine\nother goals in a new light. Many successful theorem provers employ a portfolio\nof different methods for solving problems. This changes the landscape on which\nwe perform our research: solving problems that can already be solved may not\nimprove the state of the art and a method that can solve a handful of problems\nunsolvable by current methods, but generally performs poorly on most problems,\ncan be very useful. We acknowledge that forcing new methods to compete against\nportfolio solvers can stifle innovation. However, this is only the case when\ncomparisons are made at the level of total problems solved. We propose a\nmovement towards focussing on unique solutions in evaluation and competitions\ni.e. measuring the potential contribution to a portfolio solver. This state of\naffairs is particularly prominent in first-order logic, which is undecidable.\nWhen reasoning in a decidable logic there can be a focus on optimising a\ndecision procedure and measuring average solving times. But in a setting where\nsolutions are difficult to find, average solving times lose meaning, and whilst\nimproving the efficiency of a technique can move potential solutions within\nacceptable time limits, in general, complementary strategies may be more\nsuccessful.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:14:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Reger", "Giles", "", "University of Manchester"]]}, {"id": "1912.12959", "submitter": "EPTCS", "authors": "Naveen Sundar Govindarajulu (Rensselaer AI and Reasoning Lab), Selmer\n  Bringsjord (Rensselaer Polytechnic Institute), Matthew Peveler (Rensselaer\n  Polytechnic Institute)", "title": "On Quantified Modal Theorem Proving for Modeling Ethics", "comments": "In Proceedings ARCADE 2019, arXiv:1912.11786", "journal-ref": "EPTCS 311, 2019, pp. 43-49", "doi": "10.4204/EPTCS.311.7", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, formal logics have been used to model a wide range of\nethical theories and principles with the goal of using these models within\nautonomous systems. Logics for modeling ethical theories, and their automated\nreasoners, have requirements that are different from modal logics used for\nother purposes, e.g. for temporal reasoning. Meeting these requirements\nnecessitates investigation of new approaches for proof automation.\nParticularly, a quantified modal logic, the deontic cognitive event calculus\n(DCEC), has been used to model various versions of the doctrine of double\neffect, akrasia, and virtue ethics. Using a fragment of DCEC, we outline these\ndistinct characteristics and present a sketches of an algorithm that can help\nwith some aspects proof automation for DCEC.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:14:21 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Govindarajulu", "Naveen Sundar", "", "Rensselaer AI and Reasoning Lab"], ["Bringsjord", "Selmer", "", "Rensselaer Polytechnic Institute"], ["Peveler", "Matthew", "", "Rensselaer\n  Polytechnic Institute"]]}, {"id": "1912.12966", "submitter": "EPTCS", "authors": "Christoph Weidenbach (Max Planck Institute for Informatics)", "title": "The Challenge of Unifying Semantic and Syntactic Inference Restrictions", "comments": "In Proceedings ARCADE 2019, arXiv:1912.11786", "journal-ref": "EPTCS 311, 2019, pp. 5-10", "doi": "10.4204/EPTCS.311.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While syntactic inference restrictions don't play an important role for SAT,\nthey are an essential reasoning technique for more expressive logics, such as\nfirst-order logic, or fragments thereof. In particular, they can result in\nshort proofs or model representations. On the other hand, semantically guided\ninference systems enjoy important properties, such as the generation of solely\nnon-redundant clauses. I discuss to what extend the two paradigms may be\nunifiable.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:28:38 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Weidenbach", "Christoph", "", "Max Planck Institute for Informatics"]]}, {"id": "1912.13122", "submitter": "Andres Garcia-Camino", "authors": "Andr\\'es Garc\\'ia-Camino", "title": "Declarative Mechanism Design", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report-no: 01", "categories": "cs.AI cs.LG cs.LO cs.MA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agentswas Electronic\nInstitutions.However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide sI, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 00:10:50 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 22:36:52 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 17:19:26 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Garc\u00eda-Camino", "Andr\u00e9s", ""]]}, {"id": "1912.13430", "submitter": "Alberto Camacho", "authors": "Alberto Camacho, Sheila A. McIlraith", "title": "Towards Neural-Guided Program Synthesis for Linear Temporal Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.GT cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing a program that realizes a logical specification is a classical\nproblem in computer science. We examine a particular type of program synthesis,\nwhere the objective is to synthesize a strategy that reacts to a potentially\nadversarial environment while ensuring that all executions satisfy a Linear\nTemporal Logic (LTL) specification. Unfortunately, exact methods to solve\nso-called LTL synthesis via logical inference do not scale. In this work, we\ncast LTL synthesis as an optimization problem. We employ a neural network to\nlearn a Q-function that is then used to guide search, and to construct programs\nthat are subsequently verified for correctness. Our method is unique in\ncombining search with deep learning to realize LTL synthesis. In our\nexperiments the learned Q-function provides effective guidance for synthesis\nproblems with relatively small specifications.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 17:09:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Camacho", "Alberto", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "1912.13477", "submitter": "Tarmo Uustalu", "authors": "Shin-ya Katsumata, Exequiel Rivas and Tarmo Uustalu", "title": "Interaction laws of monads and comonads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study functor-functor and monad-comonad interaction laws as\nmathematical objects to describe interaction of effectful computations with\nbehaviors of effect-performing machines. Monad-comonad interaction laws are\nmonoid objects of the monoidal category of functor-functor interaction laws. We\nshow that, for suitable generalizations of the concepts of dual and Sweedler\ndual, the greatest functor resp. monad interacting with a given functor or\ncomonad is its dual while the greatest comonad interacting with a given monad\nis its Sweedler dual. We relate monad-comonad interaction laws to stateful\nrunners. We show that functor-functor interaction laws are Chu spaces over the\ncategory of endofunctors taken with the Day convolution monoidal structure.\nHasegawa's glueing endows the category of these Chu spaces with a monoidal\nstructure whose monoid objects are monad-comonad interaction laws.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:27:22 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Katsumata", "Shin-ya", ""], ["Rivas", "Exequiel", ""], ["Uustalu", "Tarmo", ""]]}]