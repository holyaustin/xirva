[{"id": "1105.0354", "submitter": "Robert Rothenberg", "authors": "Robert Rothenberg", "title": "Modality for Free: Notes on Adding the Tarskian M\\\"{o}glichkeit to\n  Substructural Logics", "comments": "8 pages, work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We briefly examine the modal formulae that can be derived in Multiplicative\nAdditive Linear Logic (MALL) and some extensions by using Tarksi's extensional\nmodal operators. We also breifly compare this with a substructural form of the\nmodal logic K.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 15:22:14 GMT"}, {"version": "v2", "created": "Sun, 8 May 2011 14:01:20 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Rothenberg", "Robert", ""]]}, {"id": "1105.0548", "submitter": "Florian Rabe", "authors": "Florian Rabe, Michael Kohlhase", "title": "A Scalable Module System", "comments": "This is a preprint of the main paper on the MMT language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic and logic computation systems ranging from computer algebra systems\nto theorem provers are finding their way into science, technology, mathematics\nand engineering. But such systems rely on explicitly or implicitly represented\nmathematical knowledge that needs to be managed to use such systems\neffectively.\n  While mathematical knowledge management (MKM) \"in the small\" is well-studied,\nscaling up to large, highly interconnected corpora remains difficult. We hold\nthat in order to realize MKM \"in the large\", we need representation languages\nand software architectures that are designed systematically with large-scale\nprocessing in mind.\n  Therefore, we have designed and implemented the MMT language -- a module\nsystem for mathematical theories. MMT is designed as the simplest possible\nlanguage that combines a module system, a foundationally uncommitted formal\nsemantics, and web-scalable implementations. Due to a careful choice of\nrepresentational primitives, MMT allows us to integrate existing representation\nlanguages for formal mathematical knowledge in a simple, scalable formalism. In\nparticular, MMT abstracts from the underlying mathematical and logical\nfoundations so that it can serve as a standardized representation format for a\nformal digital library. Moreover, MMT systematically separates logic-dependent\nand logic-independent concerns so that it can serve as an interface layer\nbetween computation systems and MKM systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 11:05:34 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Rabe", "Florian", ""], ["Kohlhase", "Michael", ""]]}, {"id": "1105.0653", "submitter": "Joachim Wehler", "authors": "Christoph Schneider, Joachim Wehler", "title": "Model Checking of Boolean Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of Business Process Management formal models for the control\nflow of business processes have been designed since more than 15 years. Which\nmethods are best suited to verify the bulk of these models? The first step is\nto select a formal language which fixes the semantics of the models. We adopt\nthe language of Boolean systems as reference language for Boolean process\nmodels. Boolean systems form a simple subclass of coloured Petri nets. Their\ncharacteristics are low tokens to model explicitly states with a subsequent\nskipping of activations and arbitrary logical rules of type AND, XOR, OR etc.\nto model the split and join of the control flow. We apply model checking as a\nverification method for the safeness and liveness of Boolean systems. Model\nchecking of Boolean systems uses the elementary theory of propositional logic,\nno modal operators are needed. Our verification builds on a finite complete\nprefix of a certain T-system attached to the Boolean system. It splits the\nprocesses of the Boolean system into a finite set of base processes of bounded\nlength. Their behaviour translates to formulas from propositional logic. Our\nverification task consists in checking the satisfiability of these formulas. In\naddition we have implemented our model checking algorithm as a java program.\nThe time needed to verify a given Boolean system depends critically on the\nnumber of initial tokens. Because the algorithm has to solve certain\nSAT-problems, polynomial complexity cannot be expected. The paper closes with\nthe model checking of some Boolean process models which have been designed as\nEvent-driven Process Chains.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 18:49:18 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Schneider", "Christoph", ""], ["Wehler", "Joachim", ""]]}, {"id": "1105.0845", "submitter": "Henning Schnoor", "authors": "Edith Hemaspaandra and Henning Schnoor", "title": "A Simplest Undecidable Modal Logic", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modal logics are widely used in computer science. The complexity of their\nsatisfiability problems has been an active field of research since the 1970s.\nWe prove that even very \"simple\" modal logics can be undecidable: We show that\nthere is an undecidable modal logic that can be obtained by restricting the\nallowed models with a first-order formula in which only universal quantifiers\nappear.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 15:01:33 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Schnoor", "Henning", ""]]}, {"id": "1105.1256", "submitter": "George Metcalfe", "authors": "George Metcalfe (University of Bern), Nicola Olivetti (Paul Cezanne\n  University)", "title": "Towards a Proof Theory of G\\\"odel Modal Logics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,\n  2011) lmcs:972", "doi": "10.2168/LMCS-7(2:10)2011", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analytic proof calculi are introduced for box and diamond fragments of basic\nmodal fuzzy logics that combine the Kripke semantics of modal logic K with the\nmany-valued semantics of G\\\"odel logic. The calculi are used to establish\ncompleteness and complexity results for these fragments.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 10:07:14 GMT"}, {"version": "v2", "created": "Sat, 14 May 2011 09:57:42 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Metcalfe", "George", "", "University of Bern"], ["Olivetti", "Nicola", "", "Paul Cezanne\n  University"]]}, {"id": "1105.1364", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Lechen Li", "title": "Achieving Data Privacy through Secrecy Views and Null-Based Virtual\n  Updates", "comments": "Minor revisions of journal resubmission, 2012", "journal-ref": "IEEE Transaction on Knowledge and Data Engineering, 2013,\n  25(5):987-1000", "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There may be sensitive information in a relational database, and we might\nwant to keep it hidden from a user or group thereof. In this work, sensitive\ndata is characterized as the contents of a set of secrecy views. For a user\nwithout permission to access that sensitive data, the database instance he\nqueries is updated to make the contents of the views empty or contain only\ntuples with null values. In particular, if this user poses a query about any of\nthese views, no meaningful information is returned. Since the database is not\nexpected to be physically changed to produce this result, the updates are only\nvirtual. And also minimal in a precise way. These minimal updates are reflected\nin the secrecy view contents, and also in the fact that query answers, while\nbeing privacy preserving, are also maximally informative. Virtual updates are\nbased on the use of null values as used in the SQL standard. We provide the\nsemantics of secrecy views and the virtual updates. The different ways in which\nthe underlying database is virtually updated are specified as the models of a\nlogic program with stable model semantics. The program becomes the basis for\nthe computation of the \"secret answers\" to queries, i.e. those that do not\nreveal the sensitive information.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 19:34:23 GMT"}, {"version": "v2", "created": "Tue, 27 Dec 2011 02:53:11 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2012 18:33:40 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Li", "Lechen", ""]]}, {"id": "1105.1369", "submitter": "Massimo Callisto De Donato", "authors": "Federico Buti (1), Massimo Callisto De Donato (1), Flavio Corradini\n  (1), Maria Rita Di Berardini (1) and Walter Vogler (2) ((1) School of Science\n  and Technology University of Camerino, (2) Institut f\\\"ur Informatik\n  Universit\\\"at Augsburg)", "title": "Evaluating the Efficiency of Asynchronous Systems with FASE", "comments": "14 pages, 5 figures. A preliminary version has been presented as\n  extended abstract in Pre-Proc. of The 1st Int. Workshop on Quantitative\n  Formal Methods, pp.101-106, Technische Universiteit Eindhoven, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present FASE (Faster Asynchronous Systems Evaluation), a\ntool for evaluating the worst-case efficiency of asynchronous systems. The tool\nis based on some well-established results in the setting of a timed process\nalgebra (PAFAS: a Process Algebra for Faster Asynchronous Systems). To show the\napplicability of FASE to concrete meaningful examples, we consider three\nimplementations of a bounded buffer and use FASE to automatically evaluate\ntheir worst-case efficiency. We finally contrast our results with previous ones\nwhere the efficiency of the same implementations has already been considered.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 10:16:36 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Buti", "Federico", ""], ["De Donato", "Massimo Callisto", ""], ["Corradini", "Flavio", ""], ["Di Berardini", "Maria Rita", ""], ["Vogler", "Walter", ""]]}, {"id": "1105.1370", "submitter": "Massimo Callisto De Donato", "authors": "Massimo Callisto De Donato (1) and Maria Rita Di Berardini (1) ((1)\n  Scuola di Scienze e Tecnologie, Sezione Informatica. Universit\\`a di\n  Camerino)", "title": "A Framework for the Evaluation of Worst-Case System Efficiency", "comments": "5 Pages. In ICTCS 2010: 12th Italian Conference on Theoretical\n  Computer Science, University of Camerino, Camerino, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present FASE (Fast Asynchronous Systems Evaluation), a tool\nfor evaluating worst-case efficiency of asynchronous systems. This tool\nimplements some well-established results in the setting of a timed CCS-like\nprocess algebra: PAFAS (a Process Algebra for Faster Asynchronous Systems).\nMoreover, we discuss some new solutions that are useful to improve the\napplicability of FASE to concrete meaningful examples. We finally use fase to\nevaluate the efficiency of three different implementations of a bounded buffer\nand compare our results with previous ones obtained when the same\nimplementations have been contrasted according to an efficiency preorder.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 10:56:23 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["De Donato", "Massimo Callisto", ""], ["Di Berardini", "Maria Rita", ""]]}, {"id": "1105.1376", "submitter": "Yannick Chevalier", "authors": "Yannick Chevalier (IRIT)", "title": "Finitary Deduction Systems", "comments": "30 pages. Work begun while in the CASSIS Project, INRIA Nancy Grand\n  Est", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptographic protocols are the cornerstone of security in distributed\nsystems. The formal analysis of their properties is accordingly one of the\nfocus points of the security community, and is usually split among two groups.\nIn the first group, one focuses on trace-based security properties such as\nconfidentiality and authentication, and provides decision procedures for the\nexistence of attacks for an on-line attackers. In the second group, one focuses\non equivalence properties such as privacy and guessing attacks, and provides\ndecision procedures for the existence of attacks for an offline attacker. In\nall cases the attacker is modeled by a deduction system in which his possible\nactions are expressed. We present in this paper a notion of finitary deduction\nsystems that aims at relating both approaches. We prove that for such deduction\nsystems, deciding equivalence properties for on-line attackers can be reduced\nto deciding reachability properties in the same setting.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 20:01:26 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Chevalier", "Yannick", "", "IRIT"]]}, {"id": "1105.1380", "submitter": "Russell Miller", "authors": "Wesley Calvert (Southern Illinois University), Ken Kramer (Queens\n  College & Graduate Center, CUNY), Russell Miller (Queens College & Graduate\n  Center, CUNY)", "title": "Noncomputable functions in the Blum-Shub-Smale model", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (May 24,\n  2011) lmcs:1226", "doi": "10.2168/LMCS-7(2:15)2011", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working in the Blum-Shub-Smale model of computation on the real numbers, we\nanswer several questions of Meer and Ziegler. First, we show that, for each\nnatural number d, an oracle for the set of algebraic real numbers of degree at\nmost d is insufficient to allow an oracle BSS-machine to decide membership in\nthe set of algebraic numbers of degree d + 1. We add a number of further\nresults on relative computability of these sets and their unions. Then we show\nthat the halting problem for BSS-computation is not decidable below any\ncountable oracle set, and give a more specific condition, related to the\ncardinalities of the sets, necessary for relative BSS-computability. Most of\nour results involve the technique of using as input a tuple of real numbers\nwhich is algebraically independent over both the parameters and the oracle of\nthe machine.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 20:13:24 GMT"}, {"version": "v2", "created": "Sat, 21 May 2011 20:00:17 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Calvert", "Wesley", "", "Southern Illinois University"], ["Kramer", "Ken", "", "Queens\n  College & Graduate Center, CUNY"], ["Miller", "Russell", "", "Queens College & Graduate\n  Center, CUNY"]]}, {"id": "1105.1657", "submitter": "Pierre Ganty", "authors": "Mohamed Faouzi Atig and Pierre Ganty", "title": "Approximating Petri Net Reachability Along Context-free Traces", "comments": "16 pages", "journal-ref": null, "doi": "10.4230/LIPIcs.FSTTCS.2011.152", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem asking whether the intersection of a context-free\nlanguage (CFL) and a Petri net language (PNL) is empty. Our contribution to\nsolve this long-standing problem which relates, for instance, to the\nreachability analysis of recursive programs over unbounded data domain, is to\nidentify a class of CFLs called the finite-index CFLs for which the problem is\ndecidable. The k-index approximation of a CFL can be obtained by discarding all\nthe words that cannot be derived within a budget k on the number of occurrences\nof non-terminals. A finite-index CFL is thus a CFL which coincides with its\nk-index approximation for some k. We decide whether the intersection of a\nfinite-index CFL and a PNL is empty by reducing it to the reachability problem\nof Petri nets with weak inhibitor arcs, a class of systems with infinitely many\nstates for which reachability is known to be decidable. Conversely, we show\nthat the reachability problem for a Petri net with weak inhibitor arcs reduces\nto the emptiness problem of a finite-index CFL intersected with a PNL.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 12:44:49 GMT"}, {"version": "v2", "created": "Sat, 4 Jun 2011 21:58:47 GMT"}, {"version": "v3", "created": "Mon, 16 Jan 2012 10:27:08 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Atig", "Mohamed Faouzi", ""], ["Ganty", "Pierre", ""]]}, {"id": "1105.2246", "submitter": "Clemens Kupke", "authors": "Corina Cirstea (University of Southampton), Clemens Kupke (Imperial\n  College London), Dirk Pattinson (Imperial College London)", "title": "EXPTIME Tableaux for the Coalgebraic mu-Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (August 11,\n  2011) lmcs:784", "doi": "10.2168/LMCS-7(3:3)2011", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coalgebraic approach to modal logic provides a uniform framework that\ncaptures the semantics of a large class of structurally different modal logics,\nincluding e.g. graded and probabilistic modal logics and coalition logic. In\nthis paper, we introduce the coalgebraic mu-calculus, an extension of the\ngeneral (coalgebraic) framework with fixpoint operators. Our main results are\ncompleteness of the associated tableau calculus and EXPTIME decidability for\nguarded formulas. Technically, this is achieved by reducing satisfiability to\nthe existence of non-wellfounded tableaux, which is in turn equivalent to the\nexistence of winning strategies in parity games. Our results are parametric in\nthe underlying class of models and yield, as concrete applications, previously\nunknown complexity bounds for the probabilistic mu-calculus and for an\nextension of coalition logic with fixpoints.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 16:36:39 GMT"}, {"version": "v2", "created": "Tue, 9 Aug 2011 20:20:50 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Cirstea", "Corina", "", "University of Southampton"], ["Kupke", "Clemens", "", "Imperial\n  College London"], ["Pattinson", "Dirk", "", "Imperial College London"]]}, {"id": "1105.2576", "submitter": "Adam Koprowski", "authors": "Adam Koprowski (MLstate, Paris, France), Henri Binsztok (MLstate,\n  Paris, France)", "title": "TRX: A Formally Verified Parser Interpreter", "comments": "26 pages, LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (June 24,\n  2011) lmcs:686", "doi": "10.2168/LMCS-7(2:18)2011", "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing is an important problem in computer science and yet surprisingly\nlittle attention has been devoted to its formal verification. In this paper, we\npresent TRX: a parser interpreter formally developed in the proof assistant\nCoq, capable of producing formally correct parsers. We are using parsing\nexpression grammars (PEGs), a formalism essentially representing recursive\ndescent parsing, which we consider an attractive alternative to context-free\ngrammars (CFGs). From this formalization we can extract a parser for an\narbitrary PEG grammar with the warranty of total correctness, i.e., the\nresulting parser is terminating and correct with respect to its grammar and the\nsemantics of PEGs; both properties formally proven in Coq.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 20:43:38 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 20:51:51 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Koprowski", "Adam", "", "MLstate, Paris, France"], ["Binsztok", "Henri", "", "MLstate,\n  Paris, France"]]}, {"id": "1105.2665", "submitter": "Daniel Romero", "authors": "Mar\\'ia Alpuente (1), Demis Ballis (2), Javier Espert (1), and Daniel\n  Romero (1) ((1) Universidad Polit\\'ecnica de Valencia --- DSIC-ELP, (2)\n  University of Udine --- DIMI)", "title": "Dynamic Backward Slicing of Rewriting Logic Computations", "comments": "17 pages, 1 figure, 5 extra pages for Appendix; Extended version of\n  the CADE 23 paper Backward Trace Slicing for Rewriting Logic Theories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trace slicing is a widely used technique for execution trace analysis that is\neffectively used in program debugging, analysis and comprehension. In this\npaper, we present a backward trace slicing technique that can be used for the\nanalysis of Rewriting Logic theories. Our trace slicing technique allows us to\nsystematically trace back rewrite sequences modulo equational axioms (such as\nassociativity and commutativity) by means of an algorithm that dynamically\nsimplifies the traces by detecting control and data dependencies, and dropping\nuseless data that do not influence the final result. Our methodology is\nparticularly suitable for analyzing complex, textually-large system\ncomputations such as those delivered as counter-example traces by Maude\nmodel-checkers.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 09:12:20 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2011 08:17:11 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Alpuente", "Mar\u00eda", ""], ["Ballis", "Demis", ""], ["Espert", "Javier", ""], ["Romero", "Daniel", ""]]}, {"id": "1105.2725", "submitter": "Florian Rabe", "authors": "Florian Rabe and Michael Kohlhase and Claudio Sacerdoti Coen", "title": "A Foundational View on Integration Problems", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-22673-1_8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of reasoning and computation services across system and\nlanguage boundaries is a challenging problem of computer science. In this\npaper, we use integration for the scenario where we have two systems that we\nintegrate by moving problems and solutions between them. While this scenario is\noften approached from an engineering perspective, we take a foundational view.\nBased on the generic declarative language MMT, we develop a theoretical\nframework for system integration using theories and partial theory morphisms.\nBecause MMT permits representations of the meta-logical foundations themselves,\nthis includes integration across logics. We discuss safe and unsafe integration\nschemes and devise a general form of safe integration.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 13:38:08 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Rabe", "Florian", ""], ["Kohlhase", "Michael", ""], ["Coen", "Claudio Sacerdoti", ""]]}, {"id": "1105.2751", "submitter": "Bas Spitters", "authors": "Robbert Krebbers and Bas Spitters", "title": "Computer certified efficient exact reals in Coq", "comments": "Proceedings of CICM11, Springer LNAI, 2011", "journal-ref": "Proceedings of CICM11, vol 6824, Springer LNAI, 90-106, 2011", "doi": "10.1007/978-3-642-22673-1_7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating point operations are fast, but require continuous effort on the part\nof the user in order to ensure that the results are correct. This burden can be\nshifted away from the user by providing a library of exact analysis in which\nthe computer handles the error estimates. We provide an implementation of the\nexact real numbers in the Coq proof assistant. This improves on the earlier\nCoq-implementation by O'Connor in two ways: we use dyadic rationals built from\nthe machine integers and we optimize computation of power series by using\napproximate division. Moreover, we use type classes for clean mathematical\ninterfaces. This appears to be the first time that type classes are used in\nheavy computation. We obtain over a 100 times speed up of the basic operations\nand indications for improving the Coq system.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 15:13:57 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Krebbers", "Robbert", ""], ["Spitters", "Bas", ""]]}, {"id": "1105.2813", "submitter": "Wolfgang Gatterbauer", "authors": "Wolfgang Gatterbauer, Dan Suciu", "title": "Optimal Upper and Lower Bounds for Boolean Expressions by Dissociation", "comments": "7 pages, 2 figures; for details see the project page:\n  http://LaPushDB.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops upper and lower bounds for the probability of Boolean\nexpressions by treating multiple occurrences of variables as independent and\nassigning them new individual probabilities. Our technique generalizes and\nextends the underlying idea of a number of recent approaches which are\nvaryingly called node splitting, variable renaming, variable splitting, or\ndissociation for probabilistic databases. We prove that the probabilities we\nassign to new variables are the best possible in some sense.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 19:41:45 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Gatterbauer", "Wolfgang", ""], ["Suciu", "Dan", ""]]}, {"id": "1105.3324", "submitter": "Juha Kontinen", "authors": "Arnaud Durand, Juha Kontinen", "title": "Hierarchies in Dependence Logic", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fragments of dependence logic defined either by restricting the\nnumber k of universal quantifiers or the width of dependence atoms in formulas.\nWe find the sublogics of existential second-order logic corresponding to these\nfragments of dependence logic. We also show that these both ways of defining\nfragments of dependence logic give rise to a hierarchy in expressive power with\nrespect to k.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2011 09:51:16 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Durand", "Arnaud", ""], ["Kontinen", "Juha", ""]]}, {"id": "1105.3414", "submitter": "Jia-Huai  You", "authors": "Guohua Liu and Jia-Huai You", "title": "Relating Weight Constraint and Aggregate Programs: Semantics and\n  Representation", "comments": "To appear in Theory and Practice of Logic Programming (TPLP), 2011.\n  30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight constraint and aggregate programs are among the most widely used logic\nprograms with constraints. In this paper, we relate the semantics of these two\nclasses of programs, namely the stable model semantics for weight constraint\nprograms and the answer set semantics based on conditional satisfaction for\naggregate programs. Both classes of programs are instances of logic programs\nwith constraints, and in particular, the answer set semantics for aggregate\nprograms can be applied to weight constraint programs. We show that the two\nsemantics are closely related. First, we show that for a broad class of weight\nconstraint programs, called strongly satisfiable programs, the two semantics\ncoincide. When they disagree, a stable model admitted by the stable model\nsemantics may be circularly justified. We show that the gap between the two\nsemantics can be closed by transforming a weight constraint program to a\nstrongly satisfiable one, so that no circular models may be generated under the\ncurrent implementation of the stable model semantics. We further demonstrate\nthe close relationship between the two semantics by formulating a\ntransformation from weight constraint programs to logic programs with nested\nexpressions which preserves the answer set semantics. Our study on the\nsemantics leads to an investigation of a methodological issue, namely the\npossibility of compact representation of aggregate programs by weight\nconstraint programs. We show that almost all standard aggregates can be encoded\nby weight constraints compactly. This makes it possible to compute the answer\nsets of aggregate programs using the ASP solvers for weight constraint\nprograms. This approach is compared experimentally with the ones where\naggregates are handled more explicitly, which show that the weight constraint\nencoding of aggregates enables a competitive approach to answer set computation\nfor aggregate programs.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2011 05:36:39 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Liu", "Guohua", ""], ["You", "Jia-Huai", ""]]}, {"id": "1105.3583", "submitter": "Wojciech Kazana", "authors": "Wojciech Kazana (INRIA), Luc Segoufin (INRIA)", "title": "First-order query evaluation on structures of bounded degree", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (June 29,\n  2011) lmcs:903", "doi": "10.2168/LMCS-7(2:20)2011", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the enumeration problem of first-order queries over structures of\nbounded degree. It was shown that this problem is in the Constant-Delaylin\nclass. An enumeration problem belongs to Constant-Delaylin if for an input of\nsize n it can be solved by: - an O(n) precomputation phase building an index\nstructure, - followed by a phase enumerating the answers with no repetition and\na constant delay between two consecutive outputs. In this article we give a\ndifferent proof of this result based on Gaifman's locality theorem for\nfirst-order logic. Moreover, the constants we obtain yield a total evaluation\ntime that is triply exponential in the size of the input formula, matching the\ncomplexity of the best known evaluation algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 10:17:11 GMT"}, {"version": "v2", "created": "Mon, 30 May 2011 09:59:34 GMT"}, {"version": "v3", "created": "Wed, 1 Jun 2011 15:37:38 GMT"}, {"version": "v4", "created": "Tue, 28 Jun 2011 00:04:03 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kazana", "Wojciech", "", "INRIA"], ["Segoufin", "Luc", "", "INRIA"]]}, {"id": "1105.3853", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "The taming of recurrences in computability logic through cirquent\n  calculus, Part I", "comments": null, "journal-ref": "Archive for Mathematical Logic 52 (2013), pp. 173-212", "doi": "10.1007/s00153-012-0313-8", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper constructs a cirquent calculus system and proves its soundness and\ncompleteness with respect to the semantics of computability logic (see\nhttp://www.cis.upenn.edu/~giorgi/cl.html). The logical vocabulary of the system\nconsists of negation, parallel conjunction, parallel disjunction, branching\nrecurrence, and branching corecurrence. The article is published in two parts,\nwith (the present) Part I containing preliminaries and a soundness proof, and\n(the forthcoming) Part II containing a completeness proof.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 12:44:51 GMT"}, {"version": "v2", "created": "Sun, 29 May 2011 14:38:29 GMT"}, {"version": "v3", "created": "Fri, 3 Jun 2011 12:37:44 GMT"}, {"version": "v4", "created": "Thu, 23 Jun 2011 03:13:08 GMT"}, {"version": "v5", "created": "Wed, 19 Sep 2012 18:12:46 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1105.4060", "submitter": "Andrew Adamatzky", "authors": "Andrew Schumann and Andrew Adamatzky", "title": "Logical Modelling of Physarum Polycephalum", "comments": null, "journal-ref": "Analele Universitatii de Vest, Timisoara, Seria Matematica -\n  Informatica XLVIII, 3, (2010), 175-190", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model of unconventional computing where a structural part\nof computation is presented by dynamics of plasmodium of Physarum polycephalum,\na large single cell. We sketch a new logical approach combining conventional\nlogic with process calculus to demonstrate how to employ formal methods in\ndesign of unconventional computing media presented by Physarum polycephalum.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 11:18:13 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Schumann", "Andrew", ""], ["Adamatzky", "Andrew", ""]]}, {"id": "1105.4224", "submitter": "Sanjiang Li", "authors": "Weiming Liu and Sanjiang Li", "title": "On A Semi-Automatic Method for Generating Composition Tables", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Originating from Allen's Interval Algebra, composition-based reasoning has\nbeen widely acknowledged as the most popular reasoning technique in qualitative\nspatial and temporal reasoning. Given a qualitative calculus (i.e. a relation\nmodel), the first thing we should do is to establish its composition table\n(CT). In the past three decades, such work is usually done manually. This is\nundesirable and error-prone, given that the calculus may contain tens or\nhundreds of basic relations. Computing the correct CT has been identified by\nTony Cohn as a challenge for computer scientists in 1995. This paper addresses\nthis problem and introduces a semi-automatic method to compute the CT by\nrandomly generating triples of elements. For several important qualitative\ncalculi, our method can establish the correct CT in a reasonable short time.\nThis is illustrated by applications to the Interval Algebra, the Region\nConnection Calculus RCC-8, the INDU calculus, and the Oriented Point Relation\nAlgebras. Our method can also be used to generate CTs for customised\nqualitative calculi defined on restricted domains.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 07:37:47 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Liu", "Weiming", ""], ["Li", "Sanjiang", ""]]}, {"id": "1105.4394", "submitter": "EPTCS", "authors": "Harsh Raju Chamarthi (Northeastern University), Peter C. Dillinger\n  (Northeastern University), Matt Kaufmann (University of Texas at Austin),\n  Panagiotis Manolios (Northeastern University)", "title": "Integrating Testing and Interactive Theorem Proving", "comments": "In Proceedings ACL2 2011, arXiv:1110.4473", "journal-ref": "EPTCS 70, 2011, pp. 4-19", "doi": "10.4204/EPTCS.70.1", "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using an interactive theorem prover to reason about programs involves a\nsequence of interactions where the user challenges the theorem prover with\nconjectures. Invariably, many of the conjectures posed are in fact false, and\nusers often spend considerable effort examining the theorem prover's output\nbefore realizing this. We present a synergistic integration of testing with\ntheorem proving, implemented in the ACL2 Sedan (ACL2s), for automatically\ngenerating concrete counterexamples. Our method uses the full power of the\ntheorem prover and associated libraries to simplify conjectures; this\nsimplification can transform conjectures for which finding counterexamples is\nhard into conjectures where finding counterexamples is trivial. In fact, our\napproach even leads to better theorem proving, e.g. if testing shows that a\ngeneralization step leads to a false conjecture, we force the theorem prover to\nbacktrack, allowing it to pursue more fruitful options that may yield a proof.\nThe focus of the paper is on the engineering of a synergistic integration of\ntesting with interactive theorem proving; this includes extending ACL2 with new\nfunctionality that we expect to be of general interest. We also discuss our\nexperience in using ACL2s to teach freshman students how to reason about their\nprograms.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 03:05:44 GMT"}, {"version": "v2", "created": "Fri, 21 Oct 2011 02:09:20 GMT"}], "update_date": "2011-10-24", "authors_parsed": [["Chamarthi", "Harsh Raju", "", "Northeastern University"], ["Dillinger", "Peter C.", "", "Northeastern University"], ["Kaufmann", "Matt", "", "University of Texas at Austin"], ["Manolios", "Panagiotis", "", "Northeastern University"]]}, {"id": "1105.4537", "submitter": "Damien Pous", "authors": "Thomas Braibant (Universit\\'e de Grenoble, LIG, UMR 5217), Damien Pous\n  (CNRS, LIG, UMR 5217)", "title": "Deciding Kleene Algebras in Coq", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 2,\n  2012) lmcs:1043", "doi": "10.2168/LMCS-8(1:16)2012", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reflexive tactic for deciding the equational theory of Kleene\nalgebras in the Coq proof assistant. This tactic relies on a careful\nimplementation of efficient finite automata algorithms, so that it solves\ncasual equations instantaneously and properly scales to larger expressions. The\ndecision procedure is proved correct and complete: correctness is established\nw.r.t. any model by formalising Kozen's initiality theorem; a counter-example\nis returned when the given equation does not hold. The correctness proof is\nchallenging: it involves both a precise analysis of the underlying automata\nalgorithms and a lot of algebraic reasoning. In particular, we have to\nformalise the theory of matrices over a Kleene algebra. We build on the recent\naddition of firstorder typeclasses in Coq in order to work efficiently with the\ninvolved algebraic structures.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 13:27:27 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2012 21:40:51 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2012 20:34:11 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Braibant", "Thomas", "", "Universit\u00e9 de Grenoble, LIG, UMR 5217"], ["Pous", "Damien", "", "CNRS, LIG, UMR 5217"]]}, {"id": "1105.5282", "submitter": "Santiago Escobar", "authors": "Santiago Escobar and Catherine Meadows and Jose Meseguer", "title": "State Space Reduction in the Maude-NRL Protocol Analyzer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maude-NRL Protocol Analyzer (Maude-NPA) is a tool and inference system\nfor reasoning about the security of cryptographic protocols in which the\ncryptosystems satisfy different equational properties. It both extends and\nprovides a formal framework for the original NRL Protocol Analyzer, which\nsupported equational reasoning in a more limited way. Maude-NPA supports a wide\nvariety of algebraic properties that includes many crypto-systems of interest\nsuch as, for example, one-time pads and Diffie-Hellman. Maude-NPA, like the\noriginal NPA, looks for attacks by searching backwards from an insecure attack\nstate, and assumes an unbounded number of sessions. Because of the unbounded\nnumber of sessions and the support for different equational theories, it is\nnecessary to develop ways of reducing the search space and avoiding infinite\nsearch paths. In order for the techniques to prove useful, they need not only\nto speed up the search, but should not violate completeness, so that failure to\nfind attacks still guarantees security. In this paper we describe some state\nspace reduction techniques that we have implemented in Maude-NPA. We also\nprovide completeness proofs, and experimental evaluations of their effect on\nthe performance of Maude-NPA.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 13:22:19 GMT"}], "update_date": "2011-05-30", "authors_parsed": [["Escobar", "Santiago", ""], ["Meadows", "Catherine", ""], ["Meseguer", "Jose", ""]]}, {"id": "1105.5487", "submitter": "Dietrich Kuske", "authors": "Benedikt Bollig and Dietrich Kuske", "title": "An optimal construction of Hanf sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first elementary construction of equivalent formulas in Hanf\nnormal form. The triply exponential upper bound is complemented by a matching\nlower bound.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 07:22:30 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2011 10:59:55 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Bollig", "Benedikt", ""], ["Kuske", "Dietrich", ""]]}, {"id": "1105.6210", "submitter": "Pierre Deransart", "authors": "Pierre Deransart (INRIA Rocquencourt)", "title": "Generic Traces and Constraints, GenTra4CP revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generic trace format GenTra4CP has been defined in 2004 with the goal of\nbecoming a standard trace format for the observation of constraint solvers over\nfinite domains. It has not been used since. This paper defines the concept of\ngeneric trace formally, based on simple transformations of traces. It then\nanalyzes, and occasionally corrects, shortcomings of the proposed initial\nformat and shows the interest that a generic tracer may bring to develop\nportable applications or to standardization efforts, in particular in the field\nof constraints.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 09:12:29 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Deransart", "Pierre", "", "INRIA Rocquencourt"]]}, {"id": "1105.6317", "submitter": "Amir M. Ben-Amram", "authors": "Amir M. Ben-Amram (Tel-Aviv Academic College)", "title": "Monotonicity Constraints for Termination in the Integer Domain", "comments": "43 pages", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (August 24,\n  2011) lmcs:1002", "doi": "10.2168/LMCS-7(3:4)2011", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Size-Change Termination (SCT) is a method of proving program termination\nbased on the impossibility of infinite descent. To this end we use a program\nabstraction in which transitions are described by Monotonicity Constraints over\n(abstract) variables. When only constraints of the form x>y' and x\\geq y' are\nallowed, we have size-change graphs. In the last decade, both theory and\npractice have evolved significantly in this restricted framework. The crucial\nunderlying assumption of most of the past work is that the domain of the\nvariables is well-founded. In a recent paper I showed how to extend and adapt\nsome theory from the domain of size-change graphs to general monotonicity\nconstraints, thus complementing previous work, but remaining in the realm of\nwell-founded domains. However, monotonicity constraints are, interestingly,\ncapable of proving termination also in the integer domain, which is not\nwell-founded. The purpose of this paper is to explore the application of\nmonotonicity constraints in this domain. We lay the necessary theoretical\nfoundation, and present precise decision procedures for termination; finally,\nwe provide a procedure to construct explicit global ranking functions from\nmonotonicity constraints in singly-exponential time, and of optimal worst-case\nsize and dimension (ordinal).\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 15:42:03 GMT"}, {"version": "v2", "created": "Mon, 22 Aug 2011 20:11:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ben-Amram", "Amir M.", "", "Tel-Aviv Academic College"]]}]