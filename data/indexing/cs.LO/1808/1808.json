[{"id": "1808.00248", "submitter": "Rafael Pe\\~naloza", "authors": "Franz Baader, Francesco Kriegel, Adrian Nuradiansyah, and Rafael\n  Pe\\~naloza", "title": "Repairing Description Logic Ontologies by Weakening Axioms", "comments": "Extended version of the paper \"Making Repairs in Description Logics\n  More Gentle\" accepted at KR 2018", "journal-ref": null, "doi": null, "report-no": "18-01", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical approach for repairing a Description Logic ontology O in the\nsense of removing an unwanted consequence $\\alpha$ is to delete a minimal\nnumber of axioms from O such that the resulting ontology O' does not have the\nconsequence $\\alpha$. However, the complete deletion of axioms may be too\nrough, in the sense that it may also remove consequences that are actually\nwanted. To alleviate this problem, we propose a more gentle way of repair in\nwhich axioms are not necessarily deleted, but only weakened. On the one hand,\nwe investigate general properties of this gentle repair method. On the other\nhand, we propose and analyze concrete approaches for weakening axioms expressed\nin the Description Logic EL.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 09:53:05 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Baader", "Franz", ""], ["Kriegel", "Francesco", ""], ["Nuradiansyah", "Adrian", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1808.00329", "submitter": "Sabina Marchetti", "authors": "Sabina Marchetti, Alessandro Antonucci", "title": "Imaginary Kinematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel class of adjustment rules for a collection of beliefs.\nThis is an extension of Lewis' imaging to absorb probabilistic evidence in\ngeneralized settings. Unlike standard tools for belief revision, our proposal\nmay be used when information is inconsistent with an agent's belief base. We\nshow that the functionals we introduce are based on the imaginary counterpart\nof probability kinematics for standard belief revision, and prove that, under\ncertain conditions, all standard postulates for belief revision are satisfied.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 14:13:59 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Marchetti", "Sabina", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "1808.00486", "submitter": "Wilmer Ricciotti", "authors": "Wilmer Ricciotti and James Cheney", "title": "Explicit Auditing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Calculus of Audited Units (CAU) is a typed lambda calculus resulting from\na computational interpretation of Artemov's Justification Logic under the\nCurry-Howard isomorphism; it extends the simply typed lambda calculus by\nproviding audited types, inhabited by expressions carrying a trail of their\npast computation history. Unlike most other auditing techniques, CAU allows the\ninspection of trails at runtime as a first-class operation, with applications\nin security, debugging, and transparency of scientific computation.\n  An efficient implementation of CAU is challenging: not only do the sizes of\ntrails grow rapidly, but they also need to be normalized after every beta\nreduction. In this paper, we study how to reduce terms more efficiently in an\nuntyped variant of CAU by means of explicit substitutions and explicit auditing\noperations, finally deriving a call-by-value abstract machine.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 18:03:02 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Ricciotti", "Wilmer", ""], ["Cheney", "James", ""]]}, {"id": "1808.00710", "submitter": "EPTCS", "authors": "Pietro Galliani (Free University of Bozen-Bolzano)", "title": "Safe Dependency Atoms and Possibility Operators in Team Semantics", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 58-72", "doi": "10.4204/EPTCS.277.5", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I consider the question of which dependencies are safe for a Team\nSemantics-based logic FO(D), in the sense that they do not increase its\nexpressive power over sentences when added to it. I show that some\ndependencies, like totality, non-constancy and non-emptiness, are safe for all\nlogics FO(D), and that other dependencies, like constancy, are not safe for\nFO(D) for some choices of D despite being strongly first order. I furthermore\nshow that the possibility operator, which holds in a team if and only if its\nargument holds in some nonempty subteam, can be added to any logic FO(D)\nwithout increasing its expressive power over sentences.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 08:47:46 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 00:57:49 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Galliani", "Pietro", "", "Free University of Bozen-Bolzano"]]}, {"id": "1808.00727", "submitter": "Christoph Redl", "authors": "Christoph Redl", "title": "Inlining External Sources in Answer Set Programs", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 360-411", "doi": "10.1017/S147106841800056X", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEX-programs are an extension of answer set programs (ASP) with external\nsources. To this end, external atoms provide a bidirectional interface between\nthe program and an external source. The traditional evaluation algorithm for\nHEX-programs is based on guessing truth values of external atoms and verifying\nthem by explicit calls of the external source. The approach was optimized by\ntechniques that reduce the number of necessary verification calls or speed them\nup, but the remaining external calls are still expensive. In this paper we\npresent an alternative evaluation approach based on inlining of external atoms,\nmotivated by existing but less general approaches for specialized formalisms\nsuch as DL-programs. External atoms are then compiled away such that no\nverification calls are necessary. The approach is implemented in the dlvhex\nreasoner. Experiments show a significant performance gain. Besides performance\nimprovements, we further exploit inlining for extending previous (semantic)\ncharacterizations of program equivalence from ASP to HEX-programs, including\nthose of strong equivalence, uniform equivalence and H, B -equivalence.\nFinally, based on these equivalence criteria, we characterize also\ninconsistency of programs wrt. extensions. Since well-known ASP extensions\n(such as constraint ASP) are special cases of HEX, the results are interesting\nbeyond the particular formalism. Under consideration in Theory and Practice of\nLogic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:32:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Redl", "Christoph", ""]]}, {"id": "1808.00843", "submitter": "Tuan Phong Ngo", "authors": "Parosh Aziz Abdulla and Mohamed Faouzi Atig and Bengt Jonsson and Tuan\n  Phong Ngo", "title": "Optimal Stateless Model Checking under the Release-Acquire Semantics", "comments": "Accepted paper in OOPSLA'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for the efficient application of stateless model\nchecking (SMC) to concurrent programs running under the Release-Acquire (RA)\nfragment of the C/C++11 memory model. Our approach is based on exploring the\npossible program orders, which define the order in which instructions of a\nthread are executed, and read-from relations, which specify how reads obtain\ntheir values from writes. This is in contrast to previous approaches, which\nalso explore the possible coherence orders, i.e., orderings between conflicting\nwrites. Since unexpected test results such as program crashes or assertion\nviolations depend only on the read-from relation, we avoid a potentially\nsignificant source of redundancy. Our framework is based on a novel technique\nfor determining whether a particular read-from relation is feasible under the\nRA semantics. We define an SMC algorithm which is provably optimal in the sense\nthat it explores each program order and read-from relation exactly once. This\noptimality result is strictly stronger than previous analogous optimality\nresults, which also take coherence order into account. We have implemented our\nframework in the tool Tracer. Experiments show that Tracer can be significantly\nfaster than state-of-the-art tools that can handle the RA semantics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 14:55:27 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 21:26:47 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Jonsson", "Bengt", ""], ["Ngo", "Tuan Phong", ""]]}, {"id": "1808.00923", "submitter": "Ana Sokolova", "authors": "Filippo Bonchi, Ana Sokolova, Valeria Vignudelli", "title": "The Theory of Traces for Systems with Nondeterminism, Probability, and\n  Termination", "comments": "This paper is an extended version of a LICS 2019 paper \"The Theory of\n  Traces for Systems with Nondeterminism and Probability\". It contains all the\n  proofs, additional explanations, material, and examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies trace-based equivalences for systems combining\nnondeterministic and probabilistic choices. We show how trace semantics for\nsuch processes can be recovered by instantiating a coalgebraic construction\nknown as the generalised powerset construction. We characterise and compare the\nresulting semantics to known definitions of trace equivalences appearing in the\nliterature. Most of our results are based on the exciting interplay between\nmonads and their presentations via algebraic theories.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 17:19:29 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 14:01:53 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 11:44:53 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 11:07:38 GMT"}, {"version": "v5", "created": "Mon, 8 Mar 2021 17:55:46 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Bonchi", "Filippo", ""], ["Sokolova", "Ana", ""], ["Vignudelli", "Valeria", ""]]}, {"id": "1808.01239", "submitter": "Karl Schlechta", "authors": "Karl Schlechta", "title": "Remarks on an article by Rabern et al", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that conjecture 15 in the article by Rabern et al. is wrong, comment\non theorem 24 there, and conclude with some remarks on structures similar to\nthe Yablo construction.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 16:00:16 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2018 10:44:43 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 13:50:19 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Schlechta", "Karl", ""]]}, {"id": "1808.01599", "submitter": "Kirstin Peters", "authors": "Kirstin Peters and Uwe Nestmann", "title": "On the Distributability of Mobile Ambients (Technical Report)", "comments": "This paper is an extended version of the paper 'On the\n  Distributability of Mobile Ambients' presented at the workshop EXPRESS/SOS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern society is dependent on distributed software systems and to verify\nthem different modelling languages such as mobile ambients were developed. To\nanalyse the quality of mobile ambients as a good foundational model for\ndistributed computation, we analyse the level of synchronisation between\ndistributed components that they can express. Therefore, we rely on earlier\nestablished synchronisation patterns. It turns out that mobile ambients are not\nfully distributed, because they can express enough synchronisation to express a\nsynchronisation pattern called M. However, they can express strictly less\nsynchronisation than the standard pi-calculus. For this reason, we can show\nthat there is no good and distributability-preserving encoding from the\nstandard pi-calculus into mobile ambients and also no such encoding from mobile\nambients into the join-calculus, i.e., the expressive power of mobile ambients\nis in between these languages. Finally, we discuss how these results can be\nused to obtain a fully distributed variant of mobile ambients.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 11:52:40 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Peters", "Kirstin", ""], ["Nestmann", "Uwe", ""]]}, {"id": "1808.01874", "submitter": "Loris Bozzato", "authors": "Loris Bozzato, Luciano Serafini, Thomas Eiter", "title": "Reasoning with Justifiable Exceptions in Contextual Hierarchies\n  (Appendix)", "comments": "Appendix to the paper \"Reasoning with Justifiable Exceptions in\n  Contextual Hierarchies\", accepted to the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an appendix to the paper \"Reasoning with Justifiable Exceptions\nin Contextual Hierarchies\" by Bozzato, Serafini and Eiter, 2018. It provides\nfurther details on the language, the complexity results and the datalog\ntranslation introduced in the main paper.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 13:15:24 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Bozzato", "Loris", ""], ["Serafini", "Luciano", ""], ["Eiter", "Thomas", ""]]}, {"id": "1808.01877", "submitter": "Rafael Pe\\~naloza", "authors": "Rafael Pe\\~naloza, Veronika Thost, Anni-Yasmin Turhan", "title": "Query Answering for Rough EL Ontologies (Extended Technical Report)", "comments": "Extended version of a paper accepted at KR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Querying large datasets with incomplete and vague data is still a challenge.\nOntology-based query answering extends standard database query answering by\nbackground knowledge from an ontology to augment incomplete data. We focus on\nontologies written in rough description logics (DLs), which allow to represent\nvague knowledge by partitioning the domain of discourse into classes of\nindiscernible elements.\n  In this paper, we extend the combined approach for ontology-based query\nanswering to a variant of the DL EL augmented with rough concept constructors.\nWe show that this extension preserves the good computational properties of\nclassical EL and can be implemented by standard database systems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 13:18:32 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Pe\u00f1aloza", "Rafael", ""], ["Thost", "Veronika", ""], ["Turhan", "Anni-Yasmin", ""]]}, {"id": "1808.02010", "submitter": "Colin Gordon", "authors": "Colin S. Gordon", "title": "Polymorphic Iterable Sequential Effect Systems", "comments": "Extended journal version of ECOOP 2017 paper (preprint at\n  arXiv:1705.02264) generalizing the iteration operator for behavioral effect\n  systems, strengthening existence results, strengthening proof, and adding to\n  examples and comparison to related work (more details in paper). Final author\n  version", "journal-ref": "ACM Transactions on Programming Languages and Systems (TOPLAS),\n  2021", "doi": "10.1145/3450272", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effect systems are lightweight extensions to type systems that can verify a\nwide range of important properties with modest developer burden. But our\ngeneral understanding of effect systems is limited primarily to systems where\nthe order of effects is irrelevant. Understanding such systems in terms of a\nsemilattice of effects grounds understanding of the essential issues, and\nprovides guidance when designing new effect systems. By contrast, sequential\neffect systems -- where the order of effects is important -- lack an\nestablished algebraic structure on effects.\n  We present an abstract polymorphic effect system parameterized by an effect\nquantale -- an algebraic structure with well-defined properties that can model\nthe effects of a range of existing sequential effect systems. We define effect\nquantales, derive useful properties, and show how they cleanly model a variety\nof known sequential effect systems.\n  We show that for most effect quantales, there is an induced notion of\niterating a sequential effect; that for systems we consider the derived\niteration agrees with the manually designed iteration operators in prior work;\nand that this induced notion of iteration is as precise as possible when\ndefined. We also position effect quantales with respect to work on categorical\nsemantics for sequential effect systems, clarifying the distinctions between\nthese systems and our own in the course of giving a thorough survey of these\nframeworks. Our derived iteration construct should generalize to these semantic\nstructures, addressing limitations of that work. Finally, we consider the\nrelationship between sequential effects and Kleene Algebras, where the latter\nmay be used as instances of the former.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 17:57:13 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:37:43 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 16:53:54 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 19:13:56 GMT"}, {"version": "v5", "created": "Fri, 2 Oct 2020 18:04:40 GMT"}, {"version": "v6", "created": "Thu, 15 Jul 2021 15:26:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gordon", "Colin S.", ""]]}, {"id": "1808.02055", "submitter": "Veronika Thost", "authors": "Veronika Thost", "title": "Metric Temporal Extensions of DL-Lite and Interval-Rigid Names", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DL-Lite description logics allow for modeling domain knowledge on top of\ndatabases and for efficient reasoning. We focus on metric temporal extensions\nof DL-Lite_bool and its fragments, and study the complexity of satisfiability.\nIn particular, we investigate the influence of rigid and interval-rigid\nsymbols, which allow for modeling knowledge that remains valid over (some)\ntime. We show that especially the latter add considerable expressive power in\nmany logics, but they do not always increase complexity.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 18:20:48 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Thost", "Veronika", ""]]}, {"id": "1808.02291", "submitter": "Alessandro Ronca", "authors": "Alessandro Ronca, Mark Kaminski, Bernardo Cuenca Grau, Ian Horrocks", "title": "The Window Validity Problem in Rule-Based Stream Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based temporal query languages provide the expressive power and\nflexibility required to capture in a natural way complex analysis tasks over\nstreaming data. Stream processing applications, however, typically require near\nreal-time response using limited resources. In particular, it becomes essential\nthat the underpinning query language has favourable computational properties\nand that stream processing algorithms are able to keep only a small number of\npreviously received facts in memory at any point in time without sacrificing\ncorrectness. In this paper, we propose a recursive fragment of temporal Datalog\nwith tractable data complexity and study the properties of a generic stream\nreasoning algorithm for this fragment. We focus on the window validity problem\nas a way to minimise the number of time points for which the stream reasoning\nalgorithm needs to keep data in memory at any point in time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 10:17:11 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 12:04:03 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 17:53:44 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Ronca", "Alessandro", ""], ["Kaminski", "Mark", ""], ["Grau", "Bernardo Cuenca", ""], ["Horrocks", "Ian", ""]]}, {"id": "1808.02777", "submitter": "Ra\\'ul E. Monti", "authors": "Pedro R. D'Argenio and Ra\\'ul E. Monti", "title": "Input/Output Stochastic Automata with Urgency: Confluence and weak\n  determinism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous work, we introduced an input/output variant of stochastic\nautomata (IOSA) that, once the model is closed (i.e., all synchronizations are\nresolved), the resulting automaton is fully stochastic, that is, it does not\ncontain non-deterministic choices. However, such variant is not sufficiently\nversatile for compositional modelling. In this article, we extend IOSA with\nurgent actions. This extension greatly increases the modularization of the\nmodels, allowing to take better advantage on compositionality than its\npredecessor. However, this extension introduces non-determinism even in closed\nmodels. We first show that confluent models are weakly deterministic in the\nsense that, regardless the resolution of the non-determinism, the stochastic\nbehaviour is the same. In addition, we provide sufficient conditions to ensure\nthat a network of interacting IOSAs is confluent without the need to obtain the\ncomposed IOSA.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 13:37:20 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 19:21:45 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["D'Argenio", "Pedro R.", ""], ["Monti", "Ra\u00fal E.", ""]]}, {"id": "1808.02850", "submitter": "Medina Andresel", "authors": "Medina Andre\\c{s}el, Yazmin Ib\\'a\\~nez-Garc\\'ia, Magdalena Ortiz and\n  Mantas \\v{S}imkus", "title": "Relaxing and Restraining Queries for OBDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ontology-based data access (OBDA), ontologies have been successfully\nemployed for querying possibly unstructured and incomplete data. In this paper,\nwe advocate using ontologies not only to formulate queries and compute their\nanswers, but also for modifying queries by relaxing or restraining them, so\nthat they can retrieve either more or less answers over a given dataset.\nTowards this goal, we first illustrate that some domain knowledge that could be\nnaturally leveraged in OBDA can be expressed using complex role inclusions\n(CRI). Queries over ontologies with CRI are not first-order (FO) rewritable in\ngeneral. We propose an extension of DL-Lite with CRI, and show that conjunctive\nqueries over ontologies in this extension are FO rewritable. Our main\ncontribution is a set of rules to relax and restrain conjunctive queries (CQs).\nFirstly, we define rules that use the ontology to produce CQs that are\nrelaxations/restrictions over any dataset. Secondly, we introduce a set of\ndata-driven rules, that leverage patterns in the current dataset, to obtain\nmore fine-grained relaxations and restrictions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 16:27:52 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Andre\u015fel", "Medina", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazmin", ""], ["Ortiz", "Magdalena", ""], ["\u0160imkus", "Mantas", ""]]}, {"id": "1808.02943", "submitter": "Thorsten Wissmann", "authors": "Francesco Dagnino", "title": "Coaxioms: flexible coinductive definitions by inference systems", "comments": "This is a corrected version of the paper (arXiv:1808.02943v4)\n  published originally on 12 March 2019", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  20, 2020) lmcs:5277", "doi": "10.23638/LMCS-15(1:26)2019", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a generalized notion of inference system to support more\nflexible interpretations of recursive definitions. Besides axioms and inference\nrules with the usual meaning, we allow also coaxioms, which are, intuitively,\naxioms which can only be applied \"at infinite depth\" in a proof tree. Coaxioms\nallow us to interpret recursive definitions as fixed points which are not\nnecessarily the least, nor the greatest one, whose existence is guaranteed by a\nsmooth extension of classical results. This notion nicely subsumes standard\ninference systems and their inductive and coinductive interpretation, thus\nallowing formal reasoning in cases where the inductive and coinductive\ninterpretation do not provide the intended meaning, but are rather mixed\ntogether.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 21:15:11 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 16:08:42 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 14:16:17 GMT"}, {"version": "v4", "created": "Mon, 11 Mar 2019 17:36:37 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2020 13:36:53 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Dagnino", "Francesco", ""]]}, {"id": "1808.03043", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Hunting for Tractable Languages for Judgment Aggregation", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment aggregation is a general framework for collective decision making\nthat can be used to model many different settings. Due to its general nature,\nthe worst case complexity of essentially all relevant problems in this\nframework is very high. However, these intractability results are mainly due to\nthe fact that the language to represent the aggregation domain is overly\nexpressive. We initiate an investigation of representation languages for\njudgment aggregation that strike a balance between (1) being limited enough to\nyield computational tractability results and (2) being expressive enough to\nmodel relevant applications. In particular, we consider the languages of Krom\nformulas, (definite) Horn formulas, and Boolean circuits in decomposable\nnegation normal form (DNNF). We illustrate the use of the positive complexity\nresults that we obtain for these languages with a concrete application: voting\non how to spend a budget (i.e., participatory budgeting).\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 07:16:56 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1808.03161", "submitter": "Rachid Echahed", "authors": "Thierry Boy de la Tour and Rachid Echahed", "title": "A Set-Theoretic Framework for Parallel Graph Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of attributed graph transformations and propose a new\nalgorithmic approach for defining parallel graph transformations allowing\noverlaps. We start by introducing some abstract operations over graph\nstructures. Then, we define the notion of rewrite rules as three inclusions of\nthe form $L \\supseteq K \\supseteq M \\subseteq R$. We provide six conditions\nthat parallel graph rewrite relations should ideally satisfy, which lead us to\ndefine two distinct full parallel graph rewrite relations. A central notion of\nregularity of matchings is proved to be equivalent to these six conditions, and\nto the equality of these two relations. Furthermore, we take advantage of the\nsymmetries that may occur in $L$, $K$, $M$ and $R$ and define another pair of\nrewrite relations that factor out possibly many equivalent matchings up to\ntheir common symmetries. These definitions and the corresponding proofs combine\noperations on graphs with group-theoretic notions, thus illustrating the\nrelevance of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 13:49:33 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["de la Tour", "Thierry Boy", ""], ["Echahed", "Rachid", ""]]}, {"id": "1808.03315", "submitter": "Curtis Madsen", "authors": "Curtis Madsen, Prashant Vaidyanathan, Sadra Sadraddini, Cristian-Ioan\n  Vasile, Nicholas A. DeLateur, Ron Weiss, Douglas Densmore, Calin Belta", "title": "Metrics for Signal Temporal Logic Formulae", "comments": "This paper has been accepted for presentation at, and publication in\n  the proceedings of, the 2018 IEEE Conference on Decision and Control (CDC),\n  to be held in Fontainebleau, Miami Beach, FL, USA on Dec. 17-19, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal Temporal Logic (STL) is a formal language for describing a broad range\nof real-valued, temporal properties in cyber-physical systems. While there has\nbeen extensive research on verification and control synthesis from STL\nrequirements, there is no formal framework for comparing two STL formulae. In\nthis paper, we show that under mild assumptions, STL formulae admit a metric\nspace. We propose two metrics over this space based on i) the Pompeiu-Hausdorff\ndistance and ii) the symmetric difference measure, and present algorithms to\ncompute them. Alongside illustrative examples, we present applications of these\nmetrics for two fundamental problems: a) design quality measures: to compare\nall the temporal behaviors of a designed system, such as a synthetic genetic\ncircuit, with the \"desired\" specification, and b) loss functions: to quantify\nerrors in Temporal Logic Inference (TLI) as a first step to establish formal\nperformance guarantees of TLI algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 07:27:30 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Madsen", "Curtis", ""], ["Vaidyanathan", "Prashant", ""], ["Sadraddini", "Sadra", ""], ["Vasile", "Cristian-Ioan", ""], ["DeLateur", "Nicholas A.", ""], ["Weiss", "Ron", ""], ["Densmore", "Douglas", ""], ["Belta", "Calin", ""]]}, {"id": "1808.03326", "submitter": "Frederic Mesnard", "authors": "Fred Mesnard and Peter J. Stuckey", "title": "Pre-proceedings of the 28th International Symposium on Logic-Based\n  Program Synthesis and Transformation (LOPSTR 2018)", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume constitutes the pre-proceedings of the 28th International\nSymposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2018),\nheld on 4-6th September 2018 in Frankfurt am Main, Germany and co-located with\nthe 20th International Symposium on Principles and Practice of Declarative\nProgramming (PPDP 2018) and the 26th International Workshop on Functional and\nLogic Programming (WFLP 2018).\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 15:44:29 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 12:32:29 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2018 14:20:34 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Mesnard", "Fred", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "1808.03395", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli", "title": "Proof Nets and the Linear Substitution Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the very beginning of the theory of linear logic it is known how to\nrepresent the $\\lambda$-calculus as linear logic proof nets. The two systems\nhowever have different granularities, in particular proof nets have an explicit\nnotion of sharing---the exponentials---and a micro-step operational semantics,\nwhile the $\\lambda$-calculus has no sharing and a small-step operational\nsemantics. Here we show that the \\emph{linear substitution calculus}, a simple\nrefinement of the $\\lambda$-calculus with sharing, is isomorphic to proof nets\nat the operational level.\n  Nonetheless, two different terms with sharing can still have the same proof\nnets representation---a further result is the characterisation of the equality\ninduced by proof nets over terms with sharing. Finally, such a detailed\nanalysis of the relationship between terms and proof nets, suggests a new,\nabstract notion of proof net, based on rewriting considerations and not\nnecessarily of a graphical nature.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 02:29:01 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Accattoli", "Beniamino", ""]]}, {"id": "1808.03810", "submitter": "Petros Papapanagiotou", "authors": "Petros Papapanagiotou, Jacques Fleuriot", "title": "The Boyer-Moore Waterfall Model Revisited", "comments": "Originally written: September 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the potential of the Boyer-Moore waterfall\nmodel for the automation of inductive proofs within a modern proof assistant.\nWe analyze the basic concepts and methodology underlying this 30-year-old model\nand implement a new, fully integrated tool in the theorem prover HOL Light that\ncan be invoked as a tactic. We also describe several extensions and\nenhancements to the model. These include the integration of existing HOL Light\nproof procedures and the addition of state-of-the-art generalization techniques\ninto the waterfall. Various features, such as proof feedback and heuristics\ndealing with non-termination, that are needed to make this automated tool\nuseful within our interactive setting are also discussed. Finally, we present a\nthorough evaluation of the approach using a set of 150 theorems, and discuss\nthe effectiveness of our additions and relevance of the model in light of our\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 14:28:28 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Papapanagiotou", "Petros", ""], ["Fleuriot", "Jacques", ""]]}, {"id": "1808.03852", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "A Parameterized Complexity View on Description Logic Reasoning", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics are knowledge representation languages that have been\ndesigned to strike a balance between expressivity and computational\ntractability. Many different description logics have been developed, and\nnumerous computational problems for these logics have been studied for their\ncomputational complexity. However, essentially all complexity analyses of\nreasoning problems for description logics use the one-dimensional framework of\nclassical complexity theory. The multi-dimensional framework of parameterized\ncomplexity theory is able to provide a much more detailed image of the\ncomplexity of reasoning problems.\n  In this paper we argue that the framework of parameterized complexity has a\nlot to offer for the complexity analysis of description logic reasoning\nproblems---when one takes a progressive and forward-looking view on\nparameterized complexity tools. We substantiate our argument by means of three\ncase studies. The first case study is about the problem of concept\nsatisfiability for the logic ALC with respect to nearly acyclic TBoxes. The\nsecond case study concerns concept satisfiability for ALC concepts\nparameterized by the number of occurrences of union operators and the number of\noccurrences of full existential quantification. The third case study offers a\ncritical look at data complexity results from a parameterized complexity point\nof view. These three case studies are representative for the wide range of uses\nfor parameterized complexity methods for description logic problems.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 19:25:04 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1808.04111", "submitter": "Salvador Lucas", "authors": "Salvador Lucas", "title": "Proving Program Properties as First-Order Satisfiability", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/6", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program semantics can often be expressed as a (many-sorted) first-order\ntheory S, and program properties as sentences $\\varphi$ which are intended to\nhold in the canonical model of such a theory, which is often incomputable.\nRecently, we have shown that properties $\\varphi$ expressed as the existential\nclosure of a boolean combination of atoms can be disproved by just finding a\nmodel of S and the negation $\\neg\\varphi$ of $\\varphi$. Furthermore, this idea\nworks quite well in practice due to the existence of powerful tools for the\nautomatic generation of models for (many-sorted) first-order theories. In this\npaper we extend our previous result to arbitrary properties, expressed as\nsentences without any special restriction. Consequently, one can prove a\nprogram property $\\varphi$ by just finding a model of an appropriate theory\n(including S and possibly something else) and an appropriate first-order\nformula related to $\\varphi$. Beyond its possible theoretical interest, we show\nthat our results can also be of practical use in several respects.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 09:01:44 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 07:32:21 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Lucas", "Salvador", ""]]}, {"id": "1808.04149", "submitter": "Cl\\'emence Frioux", "authors": "Cl\\'emence Frioux, Torsten Schaub, Sebastian Schellhorn, Anne Siegel,\n  Philipp Wanko", "title": "Hybrid Metabolic Network Completion", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metabolic networks play a crucial role in biology since they capture all\nchemical reactions in an organism. While there are networks of high quality for\nmany model organisms, networks for less studied organisms are often of poor\nquality and suffer from incompleteness. To this end, we introduced in previous\nwork an ASP-based approach to metabolic network completion. Although this\nqualitative approach allows for restoring moderately degraded networks, it\nfails to restore highly degraded ones. This is because it ignores quantitative\nconstraints capturing reaction rates. To address this problem, we propose a\nhybrid approach to metabolic network completion that integrates our qualitative\nASP approach with quantitative means for capturing reaction rates. We begin by\nformally reconciling existing stoichiometric and topological approaches to\nnetwork completion in a unified formalism. With it, we develop a hybrid ASP\nencoding and rely upon the theory reasoning capacities of the ASP system clingo\nfor solving the resulting logic program with linear constraints over reals. We\nempirically evaluate our approach by means of the metabolic network of\nEscherichia coli. Our analysis shows that our novel approach yields greatly\nsuperior results than obtainable from purely qualitative or quantitative\napproaches. Under consideration in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 11:09:20 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Frioux", "Cl\u00e9mence", ""], ["Schaub", "Torsten", ""], ["Schellhorn", "Sebastian", ""], ["Siegel", "Anne", ""], ["Wanko", "Philipp", ""]]}, {"id": "1808.04176", "submitter": "Angelos Charalambidis", "authors": "Antonis Troumpoukis, Angelos Charalambidis", "title": "Predicate Specialization for Definitional Higher-order Logic Programs", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/11", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order logic programming is an interesting extension of traditional\nlogic programming that allows predicates to appear as arguments and variables\nto be used where predicates typically occur. Higher-order characteristics are\nindeed desirable but on the other hand they are also usually more expensive to\nsupport. In this paper we propose a program specialization technique based on\npartial evaluation that can be applied to a modest but useful class of\nhigher-order logic programs and can transform them into first-order programs\nwithout introducing additional data structures. The resulting first-order\nprograms can be executed by conventional logic programming interpreters and\nbenefit from other optimizations that might be available. We provide an\nimplementation and experimental results that suggest the efficiency of the\ntransformation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 12:38:48 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 20:42:46 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Troumpoukis", "Antonis", ""], ["Charalambidis", "Angelos", ""]]}, {"id": "1808.04193", "submitter": "Luigi Liquori", "authors": "Furio Honsell, Luigi Liquori, Claude Stolze, Ivan Scagnetto", "title": "The Delta-framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Delta-framework, LF-Delta, a dependent type theory based on\nthe Edinburgh Logical Framework LF, extended with the strong proof-functional\nconnectives, i.e. strong intersection, minimal relevant implication and strong\nunion. Strong proof-functional connectives take into account the shape of\nlogical proofs, thus reflecting polymorphic features of proofs in formulae.\nThis is in contrast to classical or intuitionistic connectives where the\nmeaning of a compound formula depends only on the truth value or the\nprovability of its subformulae. Our framework encompasses a wide range of type\ndisciplines. Moreover, since relevant implication permits to express subtyping,\nLF-Delta subsumes also Pfenning's refinement types. We discuss the design\ndecisions which have led us to the formulation of LF-Delta, study its\nmetatheory, and provide various examples of applications. Our strong\nproof-functional type theory can be plugged in existing common proof\nassistants.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 13:21:53 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Honsell", "Furio", ""], ["Liquori", "Luigi", ""], ["Stolze", "Claude", ""], ["Scagnetto", "Ivan", ""]]}, {"id": "1808.04239", "submitter": "Chen-Kai Lin", "authors": "Chen-Kai Lin, Ching-Chun (Jim) Huang, Bow-Yaw Wang", "title": "A Spin-based model checking for the simple concurrent program on a\n  preemptive RTOS", "comments": "7 pages, 5 figures, The 24th Workshop on Compiler Techniques and\n  System Software for High-Performance and Embedded Computing, 2018, Chiayi,\n  Taiwan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We adapt an existing preemptive scheduling model of RTOS kernel by eChronos\nfrom machine-assisted proof to Spin-based model checker. The model we\nconstructed can be automatically verified rather than formulating proofs by\nhand. Moreover, we look into the designs of a Linux-like real-time\nkernel--Piko/RT and the specification of ARMv7-M architecture to reconstruct\nthe model, and use LTL to specify a simple concurrent\nprograms--consumer/producer problem during the development stage of the kernel.\nWe show that under the preemptive scheduling and the mechanism of ARMv7-M, the\nprogram will not suffer from race condition, starvation, and deadlock.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 08:21:58 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Lin", "Chen-Kai", "", "Jim"], ["Ching-Chun", "", "", "Jim"], ["Huang", "", ""], ["Wang", "Bow-Yaw", ""]]}, {"id": "1808.04251", "submitter": "Michael Kinyon", "authors": "Michael Kinyon", "title": "Proof Simplification and Automated Theorem Proving", "comments": null, "journal-ref": "Philosophical Transactions of the Royal Society A, 377 (2018)", "doi": "10.1098/rsta.2018.0034", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proofs first generated by automated theorem provers are far from optimal\nby any measure of simplicity. In this paper I describe a technique for\nsimplifying automated proofs. Hopefully this discussion will stimulate interest\nin the larger, still open, question of what reasonable measures of proof\nsimplicity might be.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 22:50:07 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kinyon", "Michael", ""]]}, {"id": "1808.04264", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "A short introduction to program algebra with instructions for Boolean\n  registers", "comments": "21 pages, this paper is to a large extent a compilation of material\n  from several earlier publications; 23 pages, presentation improved and\n  section on uses for the theory added. arXiv admin note: text overlap with\n  arXiv:1702.03511", "journal-ref": "Computer Science Journal of Moldova, 26(3):199--232, 2018", "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parameterized algebraic theory of instruction sequences, objects that\nrepresent the behaviours produced by instruction sequences under execution, and\nobjects that represent the behaviours exhibited by the components of the\nexecution environment of instruction sequences is the basis of a line of\nresearch in which issues relating to a wide variety of subjects from computer\nscience have been rigorously investigated thinking in terms of instruction\nsequences. In various papers that belong to this line of research, use is made\nof an instantiation of this theory in which the basic instructions are\ninstructions to read out and alter the content of Boolean registers and the\ncomponents of the execution environment are Boolean registers. In this paper,\nwe give a simplified presentation of the most general such instantiated theory.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 14:24:35 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 09:01:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1808.04271", "submitter": "Adriano Peron", "authors": "Laura Bozzelli, Aniello Murano, Adriano Peron", "title": "Timed context-free temporal logics (extended version)", "comments": "arXiv admin note: text overlap with arXiv:1711.08314", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is focused on temporal logics for the description of the behaviour\nof real-time pushdown reactive systems. The paper is motivated to bridge\ntractable logics specialized for expressing separately dense-time real-time\nproperties and context-free properties by ensuring decidability and\ntractability in the combined setting. To this end we introduce two real-time\nlinear temporal logics for specifying quantitative timing context-free\nrequirements in a pointwise semantics setting: Event-Clock Nested Temporal\nLogic (ECNTL) and Nested Metric Temporal Logic (NMTL). The logic ECNTL is an\nextension of both the logic CARET (a context-free extension of standard LTL)\nand Event-Clock Temporal Logic (a tractable real-time logical framework related\nto the class of Event-Clock automata). We prove that satisfiability of ECNTL\nand visibly model-checking of Visibly Pushdown Timed Automata VPTA against\nECNTL are decidable and EXPTIME-complete. The other proposed logic NMTL is a\ncontext-free extension of standard Metric Temporal Logic (MTL). It is well\nknown that satisfiability of future MTL is undecidable when interpreted over\ninfinite timed words but decidable over finite timed words. On the other hand,\nwe show that by augmenting future MTL with future context-free temporal\noperators, the satisfiability problem turns out to be undecidable also for\nfinite timed words. On the positive side, we devise a meaningful and decidable\nfragment of the logic NMTL which is expressively equivalent to ECNTL and for\nwhich satisfiability and visibly model-checking of VPTA are EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 14:35:26 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 14:29:00 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Bozzelli", "Laura", ""], ["Murano", "Aniello", ""], ["Peron", "Adriano", ""]]}, {"id": "1808.04289", "submitter": "Laura Titolo", "authors": "Laura Titolo and Cesar A. Mu\\~noz and Marco A. Feliu and Mariano M.\n  Moscato", "title": "Eliminating Unstable Tests in Floating-Point Programs", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/1", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Round-off errors arising from the difference between real numbers and their\nfloating-point representation cause the control flow of conditional\nfloating-point statements to deviate from the ideal flow of the real-number\ncomputation. This problem, which is called test instability, may result in a\nsignificant difference between the computation of a floating-point program and\nthe expected output in real arithmetic. In this paper, a formally proven\nprogram transformation is proposed to detect and correct the effects of\nunstable tests. The output of this transformation is a floating-point program\nthat is guaranteed to return either the result of the original floating-point\nprogram when it can be assured that both its real and its floating-point flows\nagree or a warning when these flows may diverge. The proposed approach is\nillustrated with the transformation of the core computation of a polygon\ncontainment algorithm developed at NASA that is used in a geofencing system for\nunmanned aircraft systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 15:25:12 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 04:10:44 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Titolo", "Laura", ""], ["Mu\u00f1oz", "Cesar A.", ""], ["Feliu", "Marco A.", ""], ["Moscato", "Mariano M.", ""]]}, {"id": "1808.04738", "submitter": "Gulay Unel", "authors": "Gulay Unel", "title": "Stream Reasoning on Expressive Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data streams occur widely in various real world applications. The research on\nstreaming data mainly focuses on the data management, query evaluation and\noptimization on these data, however the work on reasoning procedures for\nstreaming knowledge bases on both the assertional and terminological levels is\nvery limited. Typically reasoning services on large knowledge bases are very\nexpensive, and need to be applied continuously when the data is received as a\nstream. Hence new techniques for optimizing this continuous process is needed\nfor developing efficient reasoners on streaming data. In this paper, we survey\nthe related research on reasoning on expressive logics that can be applied to\nthis setting, and point to further research directions in this area.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:18:02 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 13:35:20 GMT"}], "update_date": "2018-08-19", "authors_parsed": [["Unel", "Gulay", ""]]}, {"id": "1808.04867", "submitter": "Carlos Olarte", "authors": "Moreno Falaschi and Carlos Olarte", "title": "An Assertion language for slicing Constraint Logic Languages", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/12", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Logic Programming (CLP) is a language scheme for combining two\ndeclarative paradigms: constraint solving and logic programming. Concurrent\nConstraint Programming (CCP) is a declarative model for concurrency where\nagents interact by telling and asking constraints in a shared store. In a\nprevious paper, we developed a framework for dynamic slicing of CCP where the\nuser first identifies that a (partial) computation is wrong. Then, she marks\n(selects) some parts of the final state corresponding to the data (constraints)\nand processes that she wants to study more deeply. An automatic process of\nslicing begins, and the partial computation is \"depurated\" by removing\nirrelevant information. In this paper we give two major contributions. First,\nwe extend the framework to CLP, thus generalizing the previous work. Second, we\nprovide an assertion language suitable for both, CCP and CLP, which allows the\nuser to specify some properties of the computations in her program. If a state\nin a computation does not satisfy an assertion then some \"wrong\" information is\nidentified and an automatic slicing process can start. This way we make one\nstep further towards automatizing the slicing process. We show that our\nframework can be integrated with the previous semi-automatic one, giving the\nuser more choices and flexibility. We show by means of examples and experiments\nthe usefulness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 19:20:37 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 15:13:56 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 08:02:45 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Falaschi", "Moreno", ""], ["Olarte", "Carlos", ""]]}, {"id": "1808.04882", "submitter": "Guy Avni", "authors": "Guy Avni and Shibashis Guha and Orna Kupferman", "title": "Timed Network Games with Clocks", "comments": "A full version of a paper published in MFCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network games are widely used as a model for selfish resource-allocation\nproblems. In the classical model, each player selects a path connecting her\nsource and target vertices. The cost of traversing an edge depends on the {\\em\nload}; namely, number of players that traverse it. Thus, it abstracts the fact\nthat different users may use a resource at different times and for different\ndurations, which plays an important role in determining the costs of the users\nin reality. For example, when transmitting packets in a communication network,\nrouting traffic in a road network, or processing a task in a production system,\nactual sharing and congestion of resources crucially depends on time.\n  In \\cite{AGK17}, we introduced {\\em timed network games}, which add a time\ncomponent to network games. Each vertex $v$ in the network is associated with a\ncost function, mapping the load on $v$ to the price that a player pays for\nstaying in $v$ for one time unit with this load. Each edge in the network is\nguarded by the time intervals in which it can be traversed, which forces the\nplayers to spend time in the vertices. In this work we significantly extend the\nway time can be referred to in timed network games. In the model we study, the\nnetwork is equipped with {\\em clocks}, and, as in timed automata, edges are\nguarded by constraints on the values of the clocks, and their traversal may\ninvolve a reset of some clocks. We argue that the stronger model captures many\nrealistic networks. The addition of clocks breaks the techniques we developed\nin \\cite{AGK17} and we develop new techniques in order to show that positive\nresults on classic network games carry over to the stronger timed setting.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 20:10:33 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Avni", "Guy", ""], ["Guha", "Shibashis", ""], ["Kupferman", "Orna", ""]]}, {"id": "1808.04949", "submitter": "Daniel Leivant", "authors": "Daniel Leivant", "title": "A theory of finite structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel formal theory of finite structures, based on a view of\nfinite structures as a fundamental artifact of computing and programming,\nforming a common platform for computing both within particular finite\nstructures, and in the aggregate for computing over infinite data-types\nconstrued as families of finite structures. A \"finite structure\" is here a\nfinite collection of finite partial-functions, over a common universe of atoms.\nThe theory is second-order, as it uses quantification over finite functions.\n  Our formal theory FS uses a small number of fundamental axiom-schemas, with\nfiniteness enforced by a schema of induction on finite partial-functions. We\nshow that computability is definable in the theory by existential formulas,\ngeneralizing Kleene's Theorem on the Sigma-1 definability of RE sets, and use\nthat result to prove that FS is mutually interpretable with Peano Arithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 02:26:40 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Leivant", "Daniel", ""]]}, {"id": "1808.05051", "submitter": "David Fern\\'andez-Duque", "authors": "Philippe Balbiani, David Fern\\'andez-Duque, Andreas Herzig and Petar\n  Iliev", "title": "Frame-validity games and lower bounds on the complexity of modal axioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce frame-equivalence games tailored for reasoning about the size,\nmodal depth, number of occurrences of symbols and number of different\npropositional variables of modal formulae defining a given frame-property.\nUsing these games, we prove lower bounds on the above measures for a number of\nwell-known modal axioms; what is more, for some of the axioms, we show that\nthey are optimal among the formulae defining the respective class of frames.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 12:16:44 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Balbiani", "Philippe", ""], ["Fern\u00e1ndez-Duque", "David", ""], ["Herzig", "Andreas", ""], ["Iliev", "Petar", ""]]}, {"id": "1808.05059", "submitter": "Lukasz Czajka", "authors": "{\\L}ukasz Czajka", "title": "An operational interpretation of coinductive types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  13, 2020) lmcs:6097", "doi": "10.23638/LMCS-16(1:11)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an operational rewriting-based semantics for strictly positive\nnested higher-order (co)inductive types. The semantics takes into account the\n\"limits\" of infinite reduction sequences. This may be seen as a refinement and\ngeneralization of the notion of productivity in term rewriting to a setting\nwith higher-order functions and with data specified by nested higher-order\ninductive and coinductive definitions. Intuitively, we interpret lazy data\nstructures in a higher-order functional language by potentially infinite terms\ncorresponding to their complete unfoldings.\n  We prove an approximation theorem which essentially states that if a term\nreduces to an arbitrarily large finite approximation of an infinite object in\nthe interpretation of a coinductive type, then it infinitarily (i.e. in the\n\"limit\") reduces to an infinite object in the interpretation of this type. We\nintroduce a sufficient syntactic correctness criterion, in the form of a type\nsystem, for finite terms decorated with type information. Using the\napproximation theorem, we show that each well-typed term has a well-defined\ninterpretation in our semantics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 13:05:08 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 18:30:06 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 15:54:57 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 09:24:45 GMT"}, {"version": "v5", "created": "Wed, 12 Feb 2020 13:30:24 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Czajka", "\u0141ukasz", ""]]}, {"id": "1808.05065", "submitter": "Etienne Payet", "authors": "Etienne Payet", "title": "Guided Unfoldings for Finding Loops in Standard Term Rewriting", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/19", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reconsider the unfolding-based technique that we have\nintroduced previously for detecting loops in standard term rewriting. We\nimprove it by guiding the unfolding process, using distinguished positions in\nthe rewrite rules. This results in a depth-first computation of the unfoldings,\nwhereas the original technique was breadth-first. We have implemented this new\napproach in our tool NTI and compared it to the previous one on a bunch of\nrewrite systems. The results we get are promising (better times, more\nsuccessful proofs).\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 13:13:37 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 06:45:55 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Payet", "Etienne", ""]]}, {"id": "1808.05088", "submitter": "Marco Carbone", "authors": "Marco Carbone, Luis Cruz-Filipe, Fabrizio Montesi, Agata Murawska", "title": "Multiparty Classical Choreographies", "comments": "Post-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326) The paper was\n  improved and extended (+2 pages). Now more details are provided on the work", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/24", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Multiparty Classical Choreographies (MCC), a language model where\nglobal descriptions of communicating systems (choreographies) implement typed\nmultiparty sessions. Typing is achieved by generalising classical linear logic\nto judgements that explicitly record parallelism by means of hypersequents. Our\napproach unifies different lines of work on choreographies and processes with\nmultiparty sessions, as well as their connection to linear logic. Thus, results\ndeveloped in one context are carried over to the others. Key novelties of MCC\ninclude support for server invocation in choreographies, as well as\nlogic-driven compilation of choreographies with replicated processes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 14:11:41 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 06:09:12 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 10:04:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Carbone", "Marco", ""], ["Cruz-Filipe", "Luis", ""], ["Montesi", "Fabrizio", ""], ["Murawska", "Agata", ""]]}, {"id": "1808.05197", "submitter": "Isabel Garcia-Contreras", "authors": "Isabel Garcia-Contreras, Jose F. Morales, Manuel V. Hermenegildo", "title": "Multivariant Assertion-based Guidance in Abstract Interpretation", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/29", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximations during program analysis are a necessary evil, as they ensure\nessential properties, such as soundness and termination of the analysis, but\nthey also imply not always producing useful results. Automatic techniques have\nbeen studied to prevent precision loss, typically at the expense of larger\nresource consumption. In both cases (i.e., when analysis produces inaccurate\nresults and when resource consumption is too high), it is necessary to have\nsome means for users to provide information to guide analysis and thus improve\nprecision and/or performance. We present techniques for supporting within an\nabstract interpretation framework a rich set of assertions that can deal with\nmultivariance/context-sensitivity, and can handle different run-time semantics\nfor those assertions that cannot be discharged at compile time. We show how the\nproposed approach can be applied to both improving precision and accelerating\nanalysis. We also provide some formal results on the effects of such assertions\non the analysis results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 17:44:16 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 20:24:09 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 17:16:53 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Garcia-Contreras", "Isabel", ""], ["Morales", "Jose F.", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1808.05342", "submitter": "Jacek Chrz\\k{a}szcz", "authors": "Aleksy Schubert and Jacek Chrz\\k{a}szcz", "title": "Formalisation of a frame stack semantics for a Java-like language", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/25", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Coq formalisation of the small-step operational semantics of\nJafun, a small Java-like language with classes. This format of semantics makes\nit possible to naturally specify and prove invariants that should hold at each\ncomputation step. In contrast to the Featherweight Java approach the semantics\nexplicitly manipulates frame stack of method calls. Thanks to that one can\nexpress properties of computation that depend on execution of particular\nmethods.\n  On the basis of the semantics, we developed a type system that makes it\npossible to delineate a notion of a compound value and classify certain methods\nas extensional functions operating on them. In our formalisation we make a\nmechanised proof that the operational semantics for the untyped version of the\nsemantics agrees with the one for the typed one. We discuss different methods\nto make such formalisation effort and provide experiments that substantiate it.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 04:16:51 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Schubert", "Aleksy", ""], ["Chrz\u0105szcz", "Jacek", ""]]}, {"id": "1808.05360", "submitter": "Vincent Nys", "authors": "Vincent Nys and Danny De Schreye", "title": "Compiling Control as Offline Partial Deduction", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/7", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to a technique known as compiling control, whose\naim is to compile away special mechanisms for non-standard atom selection in\nlogic programs. It has previously been conjectured that compiling control could\nbe implemented as an instance of the first Futamura projection, in which an\ninterpreter is specialized for an input program. However, the exact nature of\nsuch an interpreter and of the required technique for specialization were never\nspecified. In this work, we propose a Prolog meta-interpreter which applies the\ndesired non-standard selection rule and which is amenable to specialization\nusing offline partial deduction. After the initial analysis phase of compiling\ncontrol, we collect annotations to specialize the interpreter using the Logen\nsystem for offline partial deduction. We also show that the result of the\nspecialization is equivalent to the program obtained using the traditional\napproach to compiling control. In this way, we simplify the synthesis step.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 07:09:58 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 17:22:12 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Nys", "Vincent", ""], ["De Schreye", "Danny", ""]]}, {"id": "1808.05415", "submitter": "John Baez", "authors": "John C. Baez and Jade Master", "title": "Open Petri Nets", "comments": "30 pages, TikZ figures", "journal-ref": "Math. Struct. Comp. Sci. 30 (2020) 314-341", "doi": "10.1017/S0960129520000043", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reachability semantics for Petri nets can be studied using open Petri\nnets. For us an \"open\" Petri net is one with certain places designated as\ninputs and outputs via a cospan of sets. We can compose open Petri nets by\ngluing the outputs of one to the inputs of another. Open Petri nets can be\ntreated as morphisms of a category $\\mathsf{Open}(\\mathsf{Petri})$, which\nbecomes symmetric monoidal under disjoint union. However, since the composite\nof open Petri nets is defined only up to isomorphism, it is better to treat\nthem as morphisms of a symmetric monoidal double category\n$\\mathbb{O}\\mathbf{pen}(\\mathsf{Petri})$. We describe two forms of semantics\nfor open Petri nets using symmetric monoidal double functors out of\n$\\mathbb{O}\\mathbf{pen}(\\mathsf{Petri})$. The first, an operational semantics,\ngives for each open Petri net a category whose morphisms are the processes that\nthis net can carry out. This is done in a compositional way, so that these\ncategories can be computed on smaller subnets and then glued together. The\nsecond, a reachability semantics, simply says which markings of the outputs can\nbe reached from a given marking of the inputs.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 11:04:45 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 06:01:18 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 17:52:35 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 00:43:01 GMT"}, {"version": "v5", "created": "Mon, 30 Sep 2019 00:06:18 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Baez", "John C.", ""], ["Master", "Jade", ""]]}, {"id": "1808.05481", "submitter": "Thorsten Wissmann", "authors": "{\\L}ukasz Czajka", "title": "A new coinductive confluence proof for infinitary lambda calculus", "comments": "arXiv admin note: text overlap with arXiv:1501.04354", "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (March 11,\n  2020) lmcs:6194", "doi": "10.23638/LMCS-16(1:31)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new and formal coinductive proof of confluence and normalisation\nof B\\\"ohm reduction in infinitary lambda calculus. The proof is simpler than\nprevious proofs of this result. The technique of the proof is new, i.e., it is\nnot merely a coinductive reformulation of any earlier proofs. We formalised the\nproof in the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 10:48:52 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 13:57:47 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:01:51 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 15:59:48 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Czajka", "\u0141ukasz", ""]]}, {"id": "1808.05490", "submitter": "Petros Papapanagiotou", "authors": "Petros Papapanagiotou and Jacques Fleuriot", "title": "A Pragmatic, Scalable Approach to Correct-by-construction Process\n  Composition Using Classical Linear Logic Inference", "comments": "Post-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326). arXiv admin note:\n  substantial text overlap with arXiv:1803.02613", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/13", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for rigorous process composition is encountered in many situations\npertaining to the development and analysis of complex systems. We discuss the\nuse of Classical Linear Logic (CLL) for correct-by-construction resource-based\nprocess composition, with guaranteed deadlock freedom, systematic resource\naccounting, and concurrent execution. We introduce algorithms to automate the\nnecessary inference steps for binary compositions of processes in parallel,\nconditionally, and in sequence. We combine decision procedures and heuristics\nto achieve intuitive and practically useful compositions in an applied setting.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 16:24:38 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 10:02:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Papapanagiotou", "Petros", ""], ["Fleuriot", "Jacques", ""]]}, {"id": "1808.05545", "submitter": "Jules Hedges", "authors": "Jules Hedges", "title": "Limits of bimorphic lenses", "comments": "Important: I now believe that the main result, proposition 6 (and by\n  extension theorem 1) is false. I am not formally withdrawing the paper from\n  arXiv because I think it's salvageable with some changes, but in the meantime\n  the main results should not be relied on", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bimorphic lenses are a simplification of polymorphic lenses that (like\npolymorphic lenses) have a type defined by 4 parameters, but which are defined\nin a monomorphic type system (i.e. an ordinary category with finite products).\nWe show that the category of bimorphic lenses is complete when the base\ncategory is complete, cocomplete and cartesian closed, and so symmetric\nbimorphic lenses can be defined as spans of ordinary bimorphic lenses. This is\nin contrast to monomorphic lenses, which do not have pullbacks, and for which\nthe category of spans can be defined in an ad-hoc way only when the lenses\nsatisfy a certain axiom (the put-get law). This is a step towards a theory of\nsymmetric polymorphic lenses. Bimorphic lenses additionally play an essential\nrole in compositional game theory, and spans of bimorphic lenses are a step\ntowards a compact closed category of open games.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 15:43:24 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 14:05:19 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hedges", "Jules", ""]]}, {"id": "1808.05750", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Complete Test Sets And Their Approximations", "comments": "arXiv admin note: text overlap with arXiv:1804.00073", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use testing to check if a combinational circuit $N$ always evaluates to 0\n(written as $N \\equiv 0$). We call a set of tests proving $N \\equiv 0$ a\ncomplete test set (CTS). The conventional point of view is that to prove $N\n\\equiv 0$ one has to generate a trivial CTS. It consists of all $2^{|X|}$ input\nassignments where $X$ is the set of input variables of $N$. We use the notion\nof a Stable Set of Assignments (SSA) to show that one can build a non-trivial\nCTS consisting of less than $2^{|X|}$ tests. Given an unsatisfiable CNF formula\n$H(W)$, an SSA of $H$ is a set of assignments to $W$ that proves\nunsatisfiability of $H$. A trivial SSA is the set of all $2^{|W|}$ assignments\nto $W$. Importantly, real-life formulas can have non-trivial SSAs that are much\nsmaller than $2^{|W|}$. In general, construction of even non-trivial CTSs is\ninefficient. We describe a much more efficient approach where tests are\nextracted from an SSA built for a `projection' of $N$ on a subset of variables\nof $N$. These tests can be viewed as an approximation of a CTS for $N$. We give\nexperimental results and describe potential applications of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 05:12:06 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "1808.05791", "submitter": "Mickael Randour", "authors": "St\\'ephane Le Roux, Arno Pauly, Mickael Randour", "title": "Extending finite-memory determinacy by Boolean combination of winning\n  conditions", "comments": "Conference version appeared in FSTTCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite-memory (FM) determinacy in games on finite graphs, a central\nquestion for applications in controller synthesis, as FM strategies correspond\nto implementable controllers. We establish general conditions under which FM\nstrategies suffice to play optimally, even in a broad multi-objective setting.\nWe show that our framework encompasses important classes of games from the\nliterature, and permits to go further, using a unified approach. While such an\napproach cannot match ad-hoc proofs with regard to tightness of memory bounds,\nit has two advantages: first, it gives a widely-applicable criterion for FM\ndeterminacy; second, it helps to understand the cornerstones of FM determinacy,\nwhich are often hidden but common in proofs for specific (combinations of)\nwinning conditions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 08:25:42 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 18:26:00 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Roux", "St\u00e9phane Le", ""], ["Pauly", "Arno", ""], ["Randour", "Mickael", ""]]}, {"id": "1808.06255", "submitter": "Yuri Gurevich", "authors": "Yuri Gurevich", "title": "Evolving Algebras 1993: Lipari Guide", "comments": "The paper is published in arXiv because the Oxford University Press\n  book is not available, Specification and Validation Methods, editor Egon\n  Boerger, Oxford University Press, 1995", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation models and specification methods seem to be worlds apart. The\nproject on abstract state machines (in short ASMs, also known as evolving\nalgebras) started as an attempt to bridge the gap by improving on Turing's\nthesis. We sought more versatile machines which would be able to step-for-step\nsimulate arbitrary algorithms on their natural abstraction levels. The ASM\nthesis asserts that ASMs are such versatile machines. The guide provides the\ndefinitions of sequential, parallel and distributed ASMs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 20:49:31 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Gurevich", "Yuri", ""]]}, {"id": "1808.06256", "submitter": "Raheleh Jalali", "authors": "Amirhossein Akbar Tabatabai, Raheleh Jalali", "title": "Universal Proof Theory: Semi-analytic Rules and Craig Interpolation", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [6], Iemhoff introduced the notion of a focused axiom and a focused rule\nas the building blocks for a certain form of sequent calculus which she calls a\nfocused proof system. She then showed how the existence of a terminating\nfocused system implies the uniform interpolation property for the logic that\nthe calculus captures. In this paper we first generalize her focused rules to\nsemi-analytic rules, a dramatically powerful generalization, and then we will\nshow how the semi-analytic calculi consisting of these rules together with our\ngeneralization of her focused axioms, lead to the feasible Craig interpolation\nproperty. Using this relationship, we first present a uniform method to prove\ninterpolation for different logics from sub-structural logics $\\mathbf{FL_e}$,\n$\\mathbf{FL_{ec}}$, $\\mathbf{FL_{ew}}$ and $\\mathbf{IPC}$ to their appropriate\nclassical and modal extensions, including the intuitionistic and classical\nlinear logics. Then we will use our theorem negatively, first to show that so\nmany sub-structural logics including $\\L_n$, $G_n$, $BL$, $R$ and $RM^e$ and\nalmost all super-intutionistic logics (except at most seven of them) do not\nhave a semi-analytic calculus. To investigate the case that the logic actually\nhas the Craig interpolation property, we will first define a certain specific\ntype of semi-analytic calculus which we call PPF systems and we will then\npresent a sound and complete PPF calculus for classical logic. However, we will\nshow that all such PPF calculi are exponentially slower than the classical\nHilbert-style proof system (or equivalently $\\mathbf{LK+Cut}$). We will then\npresent a similar exponential lower bound for a certain form of complete PPF\ncalculi, this time for any super-intuitionistic logic.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 20:52:24 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Tabatabai", "Amirhossein Akbar", ""], ["Jalali", "Raheleh", ""]]}, {"id": "1808.06258", "submitter": "Raheleh Jalali", "authors": "Amirhossein Akbar Tabatabai, Raheleh Jalali", "title": "Universal Proof Theory: Semi-analytic Rules and Uniform Interpolation", "comments": "54 pages. arXiv admin note: text overlap with arXiv:1808.06256", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [7] and [8], Iemhoff introduced a connection between the existence of a\nterminating sequent calculi of a certain kind and the uniform interpolation\nproperty of the super-intuitionistic logic that the calculus captures. In this\npaper, we will generalize this relationship to also cover the substructural\nsetting on the one hand and a much more powerful class of rules on the other.\nThe resulted relationship then provides a uniform method to establish uniform\ninterpolation property for the logics $\\mathbf{FL_e}$, $\\mathbf{FL_{ew}}$,\n$\\mathbf{CFL_e}$, $\\mathbf{CFL_{ew}}$, $\\mathbf{IPC}$, $\\mathbf{CPC}$ and their\n$\\mathbf{K}$ and $\\mathbf{KD}$-type modal extensions. More interestingly\nthough, on the negative side, we will show that no extension of $\\mathbf{FL_e}$\ncan enjoy a certain natural type of terminating sequent calculus unless it has\nthe uniform interpolation property. It excludes almost all super-intutionistic\nlogics and the logics $\\mathbf{K4}$ and $\\mathbf{S4}$ from having such a\nreasonable calculus.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 20:56:34 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Tabatabai", "Amirhossein Akbar", ""], ["Jalali", "Raheleh", ""]]}, {"id": "1808.06284", "submitter": "Tadeusz Litak", "authors": "Tadeusz Litak", "title": "A continuum of incomplete intermediate logics", "comments": "A corrected version of my 2002 paper", "journal-ref": "Reports on Mathematical Logic 36, pp. 131-141, 2002", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper generalizes the 1977 paper of V.B. Shehtman, which constructed the\nfirst Kripke incomplete intermediate logic, by presenting a continuum of such\nlogics. This version fixes an error in my simplified proof of incompleteness of\nShehtman's original logic.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 02:25:06 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Litak", "Tadeusz", ""]]}, {"id": "1808.06351", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "Lambda Calculus with Explicit Read-back", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new term rewriting system that is similar to the\nembedded read-back mechanism for interaction nets presented in our previous\nwork, but is easier to follow than in the original setting and thus to analyze\nits properties. Namely, we verify that it correctly represents the lambda\ncalculus. Further, we show that there is exactly one reduction sequence that\nstarts with any term in our term rewriting system. Finally, we represent the\nleftmost strategy which is known to be normalizing.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 09:00:15 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1808.06393", "submitter": "Tadeusz Litak", "authors": "Tadeusz Litak", "title": "Some notes on the superintuitionistic logic of chequered subsets of\n  $\\mathbb{R}^\\infty$", "comments": "Extended and annotated version of my 2004 paper", "journal-ref": "Bulletin of the Section of Logic, vol. 33(2), pp. 81-86, 2004", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I investigate the superintuitionistic analogue of the modal logic of\nchequered subsets of $\\mathbb{R}^\\infty$ introduced by van Benthem et al. It is\nobserved that this logic possesses the disjunction property, contains the Scott\naxiom, fails to contain the Kreisel-Putnam axiom and it is a sublogic of the\nMedvedev logic.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 11:24:41 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Litak", "Tadeusz", ""]]}, {"id": "1808.06413", "submitter": "{\\L}ukasz Czajka", "authors": "{\\L}ukasz Czajka, Burak Ekici, Cezary Kaliszyk", "title": "Concrete Semantics with Coq and CoqHammer", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-96812-4_5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"Concrete Semantics\" book gives an introduction to imperative programming\nlanguages accompanied by an Isabelle/HOL formalization. In this paper we\ndiscuss a re-formalization of the book using the Coq proof assistant. In order\nto achieve a similar brevity of the formal text we extensively use CoqHammer,\nas well as Coq Ltac-level automation. We compare the formalization efficiency,\ncompactness, and the readability of the proof scripts originating from a Coq\nre-formalization of two chapters from the book.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 12:15:09 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Czajka", "\u0141ukasz", ""], ["Ekici", "Burak", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1808.07725", "submitter": "Philipp K\\\"orner", "authors": "Alexandros Efremidis, Joshua Schmidt, Sebastian Krings, Philipp\n  K\\\"orner", "title": "Measuring Coverage of Prolog Programs Using Mutation Testing", "comments": "16 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing is an important aspect in professional software development, both to\navoid and identify bugs as well as to increase maintainability. However,\nincreasing the number of tests beyond a reasonable amount hinders development\nprogress. To decide on the completeness of a test suite, many approaches to\nassert test coverage have been suggested. Yet, frameworks for logic programs\nremain scarce.\n  In this paper, we introduce a framework for Prolog programs measuring test\ncoverage using mutations. We elaborate the main ideas of mutation testing and\ntransfer them to logic programs. To do so, we discuss the usefulness of\ndifferent mutations in the context of Prolog and empirically evaluate them in a\nnew mutation testing framework on different examples.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 12:47:52 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Efremidis", "Alexandros", ""], ["Schmidt", "Joshua", ""], ["Krings", "Sebastian", ""], ["K\u00f6rner", "Philipp", ""]]}, {"id": "1808.07826", "submitter": "Matthew Hammer", "authors": "Matthew A. Hammer, Jana Dunfield, Kyle Headley, Monal Narasimhamurthy,\n  Dimitrios J. Economou", "title": "Fungi: Typed incremental computation with names", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental computations attempt to exploit input similarities over time,\nreusing work that is unaffected by input changes. To maximize this reuse in a\ngeneral-purpose programming setting, programmers need a mechanism to identify\ndynamic allocations (of data and subcomputations) that correspond over time. We\npresent Fungi, a typed functional language for incremental computation with\nnames. Unlike prior general-purpose languages for incremental computing,\nFungi's notion of names is formal, general, and statically verifiable. Fungi's\ntype-and-effect system permits the programmer to encode (program-specific)\nlocal invariants about names, and to use these invariants to establish global\nuniqueness for their composed programs, the property of using names correctly.\nWe prove that well-typed Fungi programs respect global uniqueness. We derive a\nbidirectional version of the type and effect system, and we have implemented a\nprototype of Fungi in Rust. We apply Fungi to a library of incremental\ncollections, showing that it is expressive in practice.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:55:24 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Hammer", "Matthew A.", ""], ["Dunfield", "Jana", ""], ["Headley", "Kyle", ""], ["Narasimhamurthy", "Monal", ""], ["Economou", "Dimitrios J.", ""]]}, {"id": "1808.07832", "submitter": "Devangi Parikh", "authors": "Devangi N. Parikh, Margaret E. Myers, Richard Vuduc, Robert A. van de\n  Geijn", "title": "A Simple Methodology for Computing Families of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": "FLAME Working Note #87, The University of Texas at Austin,\n  Department of Computer Science, Technical Report TR-18-06", "categories": "cs.PL cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering \"good\" algorithms for an operation is often considered an art\nbest left to experts. What if there is a simple methodology, an algorithm, for\nsystematically deriving a family of algorithms as well as their cost analyses,\nso that the best algorithm can be chosen? We discuss such an approach for\nderiving loop-based algorithms. The example used to illustrate this\nmethodology, evaluation of a polynomial, is itself simple yet the best\nalgorithm that results is surprising to a non-expert: Horner's rule. We finish\nby discussing recent advances that make this approach highly practical for the\ndomain of high-performance linear algebra software libraries.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 23:17:06 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Parikh", "Devangi N.", ""], ["Myers", "Margaret E.", ""], ["Vuduc", "Richard", ""], ["van de Geijn", "Robert A.", ""]]}, {"id": "1808.08071", "submitter": "EPTCS", "authors": "Jorge A. P\\'erez (University of Groningen, The Netherlands), Simone\n  Tini (University of Insubria, Italy)", "title": "Proceedings Combined 25th International Workshop on Expressiveness in\n  Concurrency and 15th Workshop on Structural Operational Semantics", "comments": null, "journal-ref": "EPTCS 276, 2018", "doi": "10.4204/EPTCS.276", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Combined 25th International\nWorkshop on Expressiveness in Concurrency and the 15th Workshop on Structural\nOperational Semantics (EXPRESS/SOS 2018), which was held on September 3, 2018,\nin Beijing, China, as an affiliated workshop of CONCUR 2018, the 29th\nInternational Conference on Concurrency Theory. The EXPRESS workshops aim at\nbringing together researchers interested in the expressiveness of various\nformal systems and semantic notions, particularly in the field of concurrency.\nTheir focus has traditionally been on the comparison between programming\nconcepts (such as concurrent, functional, imperative, logic and object-oriented\nprogramming) and between mathematical models of computation (such as process\nalgebras, Petri nets, event structures, modal logics, and rewrite systems) on\nthe basis of their relative expressive power. The SOS workshops aim at being a\nforum for researchers, students and practitioners interested in new\ndevelopments, and directions for future investigation, in the field of\nstructural operational semantics. One of the specific goals of the SOS workshop\nseries is to establish synergies between the concurrency and programming\nlanguage communities working on the theory and practice of SOS. Since 2012, the\nEXPRESS and SOS communities have organized an annual combined EXPRESS/SOS\nworkshop on the expressiveness of mathematical models of computation and the\nformal semantics of systems and programming concepts.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 10:08:05 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["P\u00e9rez", "Jorge A.", "", "University of Groningen, The Netherlands"], ["Tini", "Simone", "", "University of Insubria, Italy"]]}, {"id": "1808.08190", "submitter": "Lucas Martinelli Tabajara", "authors": "Supratik Chakraborty, Dror Fried, Lucas M. Tabajara, Moshe Y. Vardi", "title": "Functional Synthesis via Input-Output Separation", "comments": "13 pages, 3 figures, extended version of publication in FMCAD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functional synthesis is the process of constructing a Boolean\nfunction from a Boolean specification that relates input and output variables.\nDespite significant recent developments in synthesis algorithms, Boolean\nfunctional synthesis remains a challenging problem even when state-of-the-art\nmethods are used for decomposing the specification. In this work we bring a\nfresh decomposition approach, orthogonal to existing methods, that explores the\ndecomposition of the specification into separate input and output components.\nWe make use of an input-output decomposition of a given specification described\nas a CNF formula, by alternatingly analyzing the separate input and output\ncomponents. We exploit well-defined properties of these components to\nultimately synthesize a solution for the entire specification. We first provide\na theoretical result that, for input components with specific structures,\nsynthesis for CNF formulas via this framework can be performed more efficiently\nthan in the general case. We then show by experimental evaluations that our\nalgorithm performs well also in practice on instances which are challenging for\nexisting state-of-the-art tools, serving as a good complement to modern\nsynthesis techniques.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 16:02:40 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Chakraborty", "Supratik", ""], ["Fried", "Dror", ""], ["Tabajara", "Lucas M.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1808.08648", "submitter": "EPTCS", "authors": "Jens Aagaard (Department of Computer Science, Aalborg University),\n  Hans H\\\"uttel (Department of Computer Science, Aalborg University), Mathias\n  Jakobsen (Department of Computer Science, Aalborg University), Mikkel\n  Kettunen (Department of Computer Science, Aalborg University)", "title": "Context-Free Session Types for Applied Pi-Calculus", "comments": "In Proceedings EXPRESS/SOS 2018, arXiv:1808.08071", "journal-ref": "EPTCS 276, 2018, pp. 3-18", "doi": "10.4204/EPTCS.276.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a binary session type system using context-free session types to a\nversion of the applied pi-calculus of Abadi et. al. where only base terms,\nconstants and channels can be sent. Session types resemble process terms from\nBPA and we use a version of bisimulation equivalence to characterize type\nequivalence. We present a quotiented type system defined on type equivalence\nclasses for which type equivalence is built into the type system. Both type\nsystems satisfy general soundness properties; this is established by an appeal\nto a generic session type system for psi-calculi.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 01:18:46 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Aagaard", "Jens", "", "Department of Computer Science, Aalborg University"], ["H\u00fcttel", "Hans", "", "Department of Computer Science, Aalborg University"], ["Jakobsen", "Mathias", "", "Department of Computer Science, Aalborg University"], ["Kettunen", "Mikkel", "", "Department of Computer Science, Aalborg University"]]}, {"id": "1808.08649", "submitter": "EPTCS", "authors": "Valentina Castiglioni (INRIA Saclay - Ile de France)", "title": "Trace and Testing Metrics on Nondeterministic Probabilistic Processes", "comments": "In Proceedings EXPRESS/SOS 2018, arXiv:1808.08071", "journal-ref": "EPTCS 276, 2018, pp. 19-36", "doi": "10.4204/EPTCS.276.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of nondeterminism and probability in concurrent systems lead\nto the development of several interpretations of process behavior. If we\nrestrict our attention to linear properties only, we can identify three main\napproaches to trace and testing semantics: the trace distributions, the\ntrace-by-trace and the extremal probabilities approaches. In this paper, we\npropose novel notions of behavioral metrics that are based on the three classic\napproaches above, and that can be used to measure the disparities in the linear\nbehavior of processes wrt trace and testing semantics. We study the properties\nof these metrics, like non-expansiveness, and we compare their expressive\npowers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 01:19:03 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Castiglioni", "Valentina", "", "INRIA Saclay - Ile de France"]]}, {"id": "1808.08652", "submitter": "EPTCS", "authors": "Chun Tian (Fondazione Bruno Kessler, Italy), Davide Sangiorgi\n  (Universit\\`a di Bologna and INRIA, Italy)", "title": "Unique Solutions of Contractions, CCS, and their HOL Formalisation", "comments": "In Proceedings EXPRESS/SOS 2018, arXiv:1808.08071", "journal-ref": "EPTCS 276, 2018, pp. 122-139", "doi": "10.4204/EPTCS.276.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unique solution of contractions is a proof technique for bisimilarity\nthat overcomes certain syntactic constraints of Milner's \"unique solution of\nequations\" technique. The paper presents an overview of a rather comprehensive\nformalisation of the core of the theory of CCS in the HOL theorem prover\n(HOL4), with a focus towards the theory of unique solutions of contractions.\n(The formalisation consists of about 20,000 lines of proof scripts in Standard\nML.) Some refinements of the theory itself are obtained. In particular we\nremove the constraints on summation, which must be weakly-guarded, by moving to\nrooted contraction, that is, the coarsest precongruence contained in the\ncontraction preorder.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 01:20:45 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Tian", "Chun", "", "Fondazione Bruno Kessler, Italy"], ["Sangiorgi", "Davide", "", "Universit\u00e0 di Bologna and INRIA, Italy"]]}, {"id": "1808.08759", "submitter": "Leander Tentrup", "authors": "Leander Tentrup and Markus N. Rabe", "title": "Clausal Abstraction for DQBF (full version)", "comments": "Full version of SAT 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency quantified Boolean formulas (DQBF) is a logic admitting\nexistential quantification over Boolean functions, which allows us to elegantly\nstate synthesis problems in verification such as the search for invariants,\nprograms, or winning regions of games. In this paper, we lift the clausal\nabstraction algorithm for quantified Boolean formulas (QBF) to DQBF. Clausal\nabstraction for QBF is an abstraction refinement algorithm that operates on a\nsequence of abstractions that represent the different quantifier levels. For\nDQBF we need to generalize this principle to partial orders of abstractions.\nThe two challenges to overcome are: (1) Clauses may contain literals with\nincomparable dependencies, which we address by the recently proposed proof rule\ncalled Fork Extension, and (2) existential variables may have spurious\ndependencies, which we prevent by tracking consistency requirements during the\nexecution. Our implementation dCAQE solves significantly more formulas than the\nexisting DQBF algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:48:32 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 10:57:49 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 10:08:00 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Tentrup", "Leander", ""], ["Rabe", "Markus N.", ""]]}, {"id": "1808.09028", "submitter": "Alexander Weinert", "authors": "Daniel Neider and Alexander Weinert and Martin Zimmermann", "title": "Robust, Expressive, and Quantitative Linear Temporal Logics: Pick any\n  Two for Free (full version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Temporal Logic (LTL) is the standard specification language for\nreactive systems and is successfully applied in industrial settings. However,\nmany shortcomings of LTL have been identified in the literature, among them the\nlimited expressiveness, the lack of quantitative features, and the inability to\nexpress robustness. There is work on overcoming these shortcomings, but each of\nthese is typically addressed in isolation. This is insufficient for\napplications where all shortcomings manifest themselves simultaneously.\n  Here, we tackle this issue by introducing logics that address more than one\nshortcoming. To this end, we combine the logics Linear Dynamic Logic,\nPrompt-LTL, and robust LTL, each addressing one aspect, to new logics. For all\ncombinations of two aspects, the resulting logic has the same desirable\nalgorithmic properties as plain LTL. In particular, the highly efficient\nalgorithmic backends that have been developed for LTL are also applicable to\nthese new logics. Finally, we discuss how to address all three aspects\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 20:30:42 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 08:34:22 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 08:22:33 GMT"}, {"version": "v4", "created": "Sun, 14 Jul 2019 09:16:05 GMT"}, {"version": "v5", "created": "Fri, 19 Jul 2019 20:18:51 GMT"}, {"version": "v6", "created": "Fri, 20 Sep 2019 09:49:57 GMT"}, {"version": "v7", "created": "Thu, 29 Apr 2021 09:21:24 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Neider", "Daniel", ""], ["Weinert", "Alexander", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1808.09213", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez, Paul Harrenstein, Giuseppe Perelli, Michael\n  Wooldridge", "title": "Nash Equilibrium and Bisimulation Invariance", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (September\n  20, 2019) lmcs:5776", "doi": "10.23638/LMCS-15(3:32)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Game theory provides a well-established framework for the analysis of\nconcurrent and multi-agent systems. The basic idea is that concurrent processes\n(agents) can be understood as corresponding to players in a game; plays\nrepresent the possible computation runs of the system; and strategies define\nthe behaviour of agents. Typically, strategies are modelled as functions from\nsequences of system states to player actions. Analysing a system in such a\nsetting involves computing the set of (Nash) equilibria in the concurrent game.\nHowever, we show that, with respect to the above model of strategies (arguably,\nthe \"standard\" model in the computer science literature), bisimilarity does not\npreserve the existence of Nash equilibria. Thus, two concurrent games which are\nbehaviourally equivalent from a semantic perspective, and which from a logical\nperspective satisfy the same temporal logic formulae, may nevertheless have\nfundamentally different properties (solutions) from a game theoretic\nperspective. Our aim in this paper is to explore the issues raised by this\ndiscovery. After illustrating the issue by way of a motivating example, we\npresent three models of strategies with respect to which the existence of Nash\nequilibria is preserved under bisimilarity. We use some of these models of\nstrategies to provide new semantic foundations for logics for strategic\nreasoning, and investigate restricted scenarios where bisimilarity can be shown\nto preserve the existence of Nash equilibria with respect to the conventional\nmodel of strategies in the computer science literature.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 10:40:56 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 11:54:27 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 10:17:03 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 08:21:26 GMT"}, {"version": "v5", "created": "Thu, 19 Sep 2019 09:59:49 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gutierrez", "Julian", ""], ["Harrenstein", "Paul", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "1808.09361", "submitter": "EPTCS", "authors": "Kirstin Peters (TU Berlin), Uwe Nestmann (TU Berlin)", "title": "On the Distributability of Mobile Ambients", "comments": "In Proceedings EXPRESS/SOS 2018, arXiv:1808.08071. Conference version\n  of arXiv:1808.01599", "journal-ref": "EPTCS 276, 2018, pp. 104-121", "doi": "10.4204/EPTCS.276.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern society is dependent on distributed software systems and to verify\nthem different modelling languages such as mobile ambients were developed. To\nanalyse the quality of mobile ambients as a good foundational model for\ndistributed computation, we analyse the level of synchronisation between\ndistributed components that they can express. Therefore, we rely on earlier\nestablished synchronisation patterns. It turns out that mobile ambients are not\nfully distributed, because they can express enough synchronisation to express a\nsynchronisation pattern called M. However, they can express strictly less\nsynchronisation than the standard pi-calculus. For this reason, we can show\nthat there is no good and distributability-preserving encoding from the\nstandard pi-calculus into mobile ambients and also no such encoding from mobile\nambients into the join-calculus, i.e., the expressive power of mobile ambients\nis in between these languages. Finally, we discuss how these results can be\nused to obtain a fully distributed variant of mobile ambients.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 01:20:26 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Peters", "Kirstin", "", "TU Berlin"], ["Nestmann", "Uwe", "", "TU Berlin"]]}, {"id": "1808.09430", "submitter": "Ayrat Khalimov", "authors": "Ayrat Khalimov", "title": "Reactive Synthesis: Branching Logics and Parameterized Systems", "comments": "phd thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive synthesis is an automatic way to translate a human intention\nexpressed in some logic into a system of some kind. This thesis has two parts,\ndevoted to logic and to systems.\n  In Part I, we develop two new approaches to CTL* synthesis. The first\napproach consists of two extensions of the SMT-based bounded synthesis: one\nfollows bottom-up CTL* model checking, another one follows the automata\nframework. The second approach reduces CTL* synthesis to LTL synthesis. The\nreduction turns any LTL synthesiser into a CTL* synthesiser. The two approaches\nwere implemented and are available online.\n  In Part II, we study parameterized synthesis for two system architectures.\nThe first architecture is guarded systems and is inspired by cache coherence\nprotocols. In guarded systems, processes transitions are enabled or disabled\ndepending on the existence of other processes in certain local states. The\nexisting cutoff results for guarded protocols are restricted to closed systems,\nand are of limited use for liveness properties. We close these gaps and prove\ntight cutoffs for open systems with liveness properties, and also cutoffs for\ndetecting deadlocks. The second architecture is token-ring systems, where the\nsingle token circulates processes arranged in a ring. The experiments with the\nexisting parameterized synthesis method showed that it does not scale to large\nspecifications. First, we optimize the method by refining the cutoff reduction,\nusing modularity and abstraction. The evaluation show several orders of\nmagnitude speed-ups. Second, we perform parameterized synthesis case study on\nthe industrial arbiter protocol AMBA. We describe new tricks ---a new cutoff\nextension and decompositional synthesis--- that, together with the previously\ndescribed optimizations, allowed us to synthesize AMBA in a parameterized\nsetting, for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:43:14 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Khalimov", "Ayrat", ""]]}, {"id": "1808.09701", "submitter": "Artem Yushkovskiy", "authors": "Artem Yushkovskiy", "title": "Comparison of Two Theorem Provers: Isabelle/HOL and Coq", "comments": "The seminar paper for the course CS-E4000 -- Seminar in Computer\n  Science held in autumn 2017 at Aalto University (Espoo, Finland), tutor:\n  Prof. Stavros Tripakis", "journal-ref": "In proceedings of the Seminar in Computer Science (CS-E4000),\n  Aalto Univeristy, Autumn 2017", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The need for formal definition of the very basis of mathematics arose in the\nlast century. The scale and complexity of mathematics, along with discovered\nparadoxes, revealed the danger of accumulating errors across theories.\nAlthough, according to G\\\"odel's incompleteness theorems, it is not possible to\nconstruct a single formal system which will describe all phenomena in the\nworld, being complete and consistent at the same time, it gave rise to rather\npractical areas of logic, such as the theory of automated theorem proving. This\nis a set of techniques used to verify mathematical statements mechanically\nusing logical reasoning. Moreover, it can be used to solve complex engineering\nproblems as well, for instance, to prove the security properties of a software\nsystem or an algorithm. This paper compares two widespread tools for automated\ntheorem proving, Isabelle/HOL and Coq, with respect to expressiveness,\nlimitations and usability. For this reason, it firstly gives a brief\nintroduction to the bases of formal systems and automated deduction theory,\ntheir main problems and challenges, and then provides detailed comparison of\nmost notable features of the selected theorem provers with support of\nillustrative proof examples.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 09:33:58 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 22:05:30 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Yushkovskiy", "Artem", ""]]}, {"id": "1808.09875", "submitter": "Felipe Salvatore", "authors": "Melvin Fitting, Felipe Salvatore", "title": "First-order justification logic with constant domain semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Justification logic is a term used to identify a relatively new family of\nmodal-like logics. There is an established literature about propositional\njustification logic, but incursions on the first-order case are scarce. In this\npaper we present a constant domain semantics for the first-order logic of\nproofs with the Barcan Formula (FOLPb); then we prove Soundness and\nCompleteness Theorems. A monotonic semantics for a version of this logic\nwithout the Barcan Formula is already in the literature, but constant domains\nrequires substantial new machinery, which may prove useful in other contexts as\nwell. Although we work mainly with one system, we also indicate how to\ngeneralize these results for the quantified version of JT45, the justification\ncounterpart of the modal logic S5. We believe our methods are more generally\napplicable, but initially examining specific cases should make the work easier\nto follow.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 15:14:05 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Fitting", "Melvin", ""], ["Salvatore", "Felipe", ""]]}, {"id": "1808.09898", "submitter": "Paolo Perrone", "authors": "Tobias Fritz and Paolo Perrone", "title": "Stochastic order on metric spaces and the ordered Kantorovich monad", "comments": "49 pages. Removed incorrect statement (Theorem 6.1.10 of previous\n  version)", "journal-ref": "Advances in Mathematics, vol. 366, 2020", "doi": "10.1016/j.aim.2020.107081", "report-no": null, "categories": "math.PR cs.LO math.CT math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In earlier work, we had introduced the Kantorovich probability monad on\ncomplete metric spaces, extending a construction due to van Breugel. Here we\nextend the Kantorovich monad further to a certain class of ordered metric\nspaces, by endowing the spaces of probability measures with the usual\nstochastic order. It can be considered a metric analogue of the probabilistic\npowerdomain.\n  The spaces we consider, which we call L-ordered, are spaces where the order\nsatisfies a mild compatibility condition with the metric itself, rather than\nmerely with the underlying topology. As we show, this is related to the theory\nof Lawvere metric spaces, in which the partial order structure is induced by\nthe zero distances.\n  We show that the algebras of the ordered Kantorovich monad are the closed\nconvex subsets of Banach spaces equipped with a closed positive cone, with\nalgebra morphisms given by the short and monotone affine maps. Considering the\ncategory of L-ordered metric spaces as a locally posetal 2-category, the lax\nand oplax algebra morphisms are exactly the concave and convex short maps,\nrespectively.\n  In the unordered case, we had identified the Wasserstein space as the colimit\nof the spaces of empirical distributions of finite sequences. We prove that\nthis extends to the ordered setting as well by showing that the stochastic\norder arises by completing the order between the finite sequences, generalizing\na recent result of Lawson. The proof holds on any metric space equipped with a\nclosed partial order.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 15:58:36 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 02:12:53 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 00:37:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fritz", "Tobias", ""], ["Perrone", "Paolo", ""]]}, {"id": "1808.10108", "submitter": "Md Kamruzzaman Sarker", "authors": "Md. Kamruzzaman Sarker, Adila Krisnadhi, David Carral, Pascal Hitzler", "title": "Rule-based OWL Modeling with ROWLTab Protege Plugin", "comments": "Accepted at ESWC 2017", "journal-ref": "14th ESWC 2017, Portoroz, Slovenia", "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that it is much easier to convey logical statements using\nrules rather than OWL (or description logic (DL)) axioms. Based on recent\ntheoretical developments on transformations between rules and DLs, we have\ndeveloped ROWLTab, a Protege plugin that allows users to enter OWL axioms by\nway of rules; the plugin then automatically converts these rules into OWL 2 DL\naxioms if possible, and prompts the user in case such a conversion is not\npossible without weakening the semantics of the rule. In this paper, we present\nROWLTab, together with a user evaluation of its effectiveness compared to\nentering axioms using the standard Protege interface. Our evaluation shows that\nmodeling with ROWLTab is much quicker than the standard interface, while at the\nsame time, also less prone to errors for hard modeling tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 04:05:35 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Sarker", "Md. Kamruzzaman", ""], ["Krisnadhi", "Adila", ""], ["Carral", "David", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1808.10240", "submitter": "Loic Pauleve", "authors": "Thomas Chatain (MEXICO), Stefan Haar (MEXICO), Juraj Kol{\\v{c}}\\'ak\n  (LSV), Lo\\\"ic Paulev\\'e (LaBRI, BioInfo - LRI)", "title": "Most Permissive Semantics of Boolean Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As shown in (http://dx.doi.org/10.1101/2020.03.22.998377), the usual update\nmodes of Boolean networks (BNs), including synchronous and (generalized)\nasynchronous, fail to capture behaviors introduced by multivalued refinements.\nThus, update modes do not allow a correct abstract reasoning on dynamics of\nbiological systems, as they may lead to reject valid BN models.This technical\nreport lists the main definitions and properties of the most permissive\nsemantics of BNs introduced in http://dx.doi.org/10.1101/2020.03.22.998377.\nThis semantics meets with a correct abstraction of any multivalued refinements,\nwith any update mode. It subsumes all the usual updating modes, while enabling\nnew behaviors achievable by more concrete models. Moreover, it appears that\nclassical dynamical analyzes of reachability and attractors have a simpler\ncomputational complexity:- reachability can be assessed in a polynomial number\nof iterations. The computation of iterations is in NP in the very general case,\nand is linear when local functions are monotonic, or with some usual\nrepresentations of functions of BNs (binary decision diagrams, Petri nets,\nautomata networks, etc.). Thus, reachability is in P with locally-monotonic\nBNs, and P$^{\\text{NP}}$ otherwise (instead of being PSPACE-complete with\nupdate modes);- deciding wherever a configuration belongs to an attractor is in\ncoNP with locally-monotonic BNs, and coNP$^{\\text{coNP}}$ otherwise (instead of\nPSPACE-complete with update modes).Furthermore, we demonstrate that the\nsemantics completely captures any behavior achievable with any multilevel or\nODE refinement of the BN; and the semantics is minimal with respect to this\nmodel refinement criteria: to any most permissive trajectory, there exists a\nmultilevel refinement of the BN which can reproduce it.In brief, the most\npermissive semantics of BNs enables a correct abstract reasoning on dynamics of\nBNs, with a greater tractability than previously introduced update modes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 11:49:31 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 08:12:21 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Chatain", "Thomas", "", "MEXICO"], ["Haar", "Stefan", "", "MEXICO"], ["Kol{\u010d}\u00e1k", "Juraj", "", "LSV"], ["Paulev\u00e9", "Lo\u00efc", "", "LaBRI, BioInfo - LRI"]]}, {"id": "1808.10389", "submitter": "Giulio Guerrieri", "authors": "Beniamino Accattoli, Giulio Guerrieri", "title": "Types of Fireballs (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The good properties of Plotkin's call-by-value lambda-calculus crucially rely\non the restriction to weak evaluation and closed terms. Open call-by-value is\nthe more general setting where evaluation is weak but terms may be open. Such\nan extension is delicate, and the literature contains a number of proposals.\nRecently, Accattoli and Guerrieri provided detailed operational and\nimplementative studies of these proposals, showing that they are equivalent\nfrom the point of view of termination, and also at the level of time cost\nmodels.\n  This paper explores the denotational semantics of open call-by-value,\nadapting de Carvalho's analysis of call-by-name via multi types (aka\nnon-idempotent intersection types). Our type system characterises normalisation\nand thus provides an adequate relational semantics. Moreover, type derivations\ncarry quantitative information about the cost of evaluation: their size bounds\nthe number of evaluation steps and the size of the normal form, and we also\ncharacterise derivations giving exact bounds.\n  The study crucially relies on a new, refined presentation of the fireball\ncalculus, the simplest proposal for open call-by-value, that is more apt to\ndenotational investigations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 16:35:57 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 13:56:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Guerrieri", "Giulio", ""]]}, {"id": "1808.10690", "submitter": "Floris van Doorn", "authors": "Floris van Doorn", "title": "On the Formalization of Higher Inductive Types and Synthetic Homotopy\n  Theory", "comments": "Dissertation, 146 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this dissertation is to present synthetic homotopy theory in the\nsetting of homotopy type theory. We will present various results in this\nframework, most notably the construction of the Atiyah-Hirzebruch and Serre\nspectral sequences for cohomology, which have been fully formalized in the Lean\nproof assistant.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 11:34:04 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["van Doorn", "Floris", ""]]}, {"id": "1808.10831", "submitter": "Alberto Camacho", "authors": "Alberto Camacho, Meghyn Bienvenu and Sheila A. McIlraith", "title": "Finite LTL Synthesis with Environment Assumptions and Quality Measures", "comments": "14 pages. To appear in the Proceedings of the 16th International\n  Conference on Principles of Knowledge Representation and Reasoning (KR 2018)\n  without the appendix proofs. The body of this paper is the same as the KR\n  2018 paper except that a minor typographic error has been corrected, as noted\n  in this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of synthesizing strategies for\nlinear temporal logic (LTL) specifications that are interpreted over finite\ntraces -- a problem that is central to the automated construction of\ncontrollers, robot programs, and business processes. We study a natural variant\nof the finite LTL synthesis problem in which strategy guarantees are predicated\non specified environment behavior. We further explore a quantitative extension\nof LTL that supports specification of quality measures, utilizing it to\nsynthesize high-quality strategies. We propose new notions of optimality and\nassociated algorithms that yield strategies that best satisfy specified quality\nmeasures. Our algorithms utilize an automata-game approach, positioning them\nwell for future implementation via existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 16:28:54 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Camacho", "Alberto", ""], ["Bienvenu", "Meghyn", ""], ["McIlraith", "Sheila A.", ""]]}]