[{"id": "1607.00141", "submitter": "Shichao Liu", "authors": "Shichao Liu, Thomas Ehrhard, Ying Jiang", "title": "A Fully Abstract Semantics for Value-passing CCS for Trees", "comments": "arXiv admin note: substantial text overlap with arXiv:1512.00550", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a fully abstract semantics for value-passing CCS for\ntrees (VCCTS). The operational semantics is given both in terms of a reduction\nsemantics and in terms of a labelled transition semantics. The labelled\ntransition semantics is non-sequential, allowing more than one action occurring\nsimultaneously. We develop the theory of behavioral equivalence by introducing\nboth weak barbed congruence and weak bisimilarity. In particular, we show that\nweak barbed congruence coincides with weak bisimilarity on image-finite\nprocesses. This is the first such result for a concurrent model with tree\nstructures. Distributed systems can be naturally modeled by means of this\ngraph-based system, and some examples are given to illustrate this.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 07:54:46 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Liu", "Shichao", ""], ["Ehrhard", "Thomas", ""], ["Jiang", "Ying", ""]]}, {"id": "1607.00372", "submitter": "\\v{L}ubo\\v{s} Koren\\v{c}iak", "authors": "\\v{L}ubo\\v{s} Koren\\v{c}iak and Anton\\'in Ku\\v{c}era and Vojt\\v{e}ch\n  \\v{R}eh\\'ak", "title": "Efficient Timeout Synthesis in Fixed-Delay CTMC Using Policy Iteration", "comments": "This article is a full version of a paper published at Modeling,\n  Analysis, and Simulation On Computer and Telecommunication Systems (MASCOTS)\n  2016 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fixed-delay synthesis problem for continuous-time Markov\nchains extended with fixed-delay transitions (fdCTMC). The goal is to\nsynthesize concrete values of the fixed-delays (timeouts) that minimize the\nexpected total cost incurred before reaching a given set of target states. The\nsame problem has been considered and solved in previous works by computing an\noptimal policy in a certain discrete-time Markov decision process (MDP) with a\nhuge number of actions that correspond to suitably discretized values of the\ntimeouts.\n  In this paper, we design a symbolic fixed-delay synthesis algorithm which\navoids the explicit construction of large action spaces. Instead, the algorithm\ncomputes a small sets of \"promising\" candidate actions on demand. The candidate\nactions are selected by minimizing a certain objective function by computing\nits symbolic derivative and extracting a univariate polynomial whose roots are\nprecisely the points where the derivative takes zero value. Since roots of high\ndegree univariate polynomials can be isolated very efficiently using modern\nmathematical software, we achieve not only drastic memory savings but also\nspeedup by three orders of magnitude compared to the previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 19:56:19 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Koren\u010diak", "\u013dubo\u0161", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["\u0158eh\u00e1k", "Vojt\u011bch", ""]]}, {"id": "1607.00431", "submitter": "Luis Moraes", "authors": "Nicholas Radcliffe, Luis Moraes and Rakesh Verma", "title": "Uniqueness of Normal Forms for Shallow Term Rewrite Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniqueness of normal forms ($UN^=$) is an important property of term rewrite\nsystems. $UN^=$ is decidable for ground (i.e., variable-free) systems and\nundecidable in general. Recently it was shown to be decidable for linear,\nshallow systems. We generalize this previous result and show that this property\nis decidable for shallow rewrite systems, in contrast to confluence,\nreachability and other properties, which are all undecidable for flat systems.\nOur result is also optimal in some sense, since we prove that the $UN^=$\nproperty is undecidable for two classes of linear rewrite systems: left-flat\nsystems in which right-hand sides are of depth at most two and right-flat\nsystems in which left-hand sides are of depth at most two.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 23:00:39 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Radcliffe", "Nicholas", ""], ["Moraes", "Luis", ""], ["Verma", "Rakesh", ""]]}, {"id": "1607.00443", "submitter": "Iddo Tzameret", "authors": "Tonnian Pitassi, Iddo Tzameret", "title": "Algebraic Proof Complexity: Progress, Frontiers and Challenges", "comments": "Complexity Column of the ACM SIGLOG News, ACM New York, NY, USA, July\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey recent progress in the proof complexity of strong proof systems and\nits connection to algebraic circuit complexity, showing how the synergy between\nthe two gives rise to new approaches to fundamental open questions, solutions\nto old problems, and new directions of research. In particular, we focus on\ntight connections between proof complexity lower bounds (namely, lower bounds\non the size of proofs of certain tautologies), algebraic circuit lower bounds,\nand the Polynomial Identity Testing problem from derandomization theory.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jul 2016 01:01:12 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Pitassi", "Tonnian", ""], ["Tzameret", "Iddo", ""]]}, {"id": "1607.00633", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Priority, Cut, If-Then-Else and Exception Handling in Logic Programming", "comments": "3 pages. a unified solution to priority, default reasoning, mutual\n  exclusion, If-then-else, cut, exception handling is discussed. We modify the\n  previous version to use prioritized version instead of original sequential\n  disjunctive operators", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the long-standing problems on logic programming is to express {\\it\npriority}-related operations -- default reasoning, if-then-else, cut, exception\nhandling, etc -- in a high-level way. We argue that this problem can be solved\nby adopting computability logic and prioritized sequential-disjunctive goal\nformulas of the form $G_0 \\bigtriangledown^* G_1$ where $G_0, G_1$ are goals.\nThese goals have the following intended semantics: sequentially $choose$ the\nfirst true goal $G_i$ and execute $G_i$ where $i (= 0\\ {\\rm or}\\ 1)$. These\ngoals thus allow us to specify a task $G_0$ with the failure-handling\n(exception handling) routine $G_1$. This new goal can also be seen as a\nlogic-equivalent of the $if$-$then$-$else$ statement in imperative language. We\nalso discuss sequential-conjunction clauses which are {\\it dual} of\nsequential-disjunctive goals.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jul 2016 12:48:54 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 13:35:12 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 15:35:59 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 07:52:46 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1607.00678", "submitter": "Petr Novotn\\'y", "authors": "Tom\\'a\\v{s} Br\\'azdil, Anton\\'in Ku\\v{c}era, Petr Novotn\\'y", "title": "Optimizing the Expected Mean Payoff in Energy Markov Decision Processes", "comments": "Full version of a paper published in proceedings of ATVA'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy Markov Decision Processes (EMDPs) are finite-state Markov decision\nprocesses where each transition is assigned an integer counter update and a\nrational payoff. An EMDP configuration is a pair s(n), where s is a control\nstate and n is the current counter value. The configurations are changed by\nperforming transitions in the standard way. We consider the problem of\ncomputing a safe strategy (i.e., a strategy that keeps the counter\nnon-negative) which maximizes the expected mean payoff.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jul 2016 20:30:53 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["Novotn\u00fd", "Petr", ""]]}, {"id": "1607.00813", "submitter": "Michael Vanden Boom", "authors": "Antoine Amarilli, Michael Benedikt, Pierre Bourhis, Michael Vanden\n  Boom", "title": "Query Answering with Transitive and Linear-Ordered Data", "comments": "36 pages. To appear in IJCAI 2016. Extended version with proofs", "journal-ref": "A journal version of this conference article was published in JAIR\n  (Volume 63, 2018): https://www.jair.org/index.php/jair/article/view/11240", "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider entailment problems involving powerful constraint languages such\nas guarded existential rules, in which additional semantic restrictions are put\non a set of distinguished relations. We consider restricting a relation to be\ntransitive, restricting a relation to be the transitive closure of another\nrelation, and restricting a relation to be a linear order. We give some natural\ngeneralizations of guardedness that allow inference to be decidable in each\ncase, and isolate the complexity of the corresponding decision problems.\nFinally we show that slight changes in our conditions lead to undecidability.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 10:39:58 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Amarilli", "Antoine", ""], ["Benedikt", "Michael", ""], ["Bourhis", "Pierre", ""], ["Boom", "Michael Vanden", ""]]}, {"id": "1607.01146", "submitter": "Weng Kin Ho", "authors": "Hadrian Andradi and Weng Kin Ho", "title": "On a new convergence class in k-bounded sober spaces", "comments": "10 pages, Domains XII Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, J. D. Lawson encouraged the domain theory community to consider the\nscientific program of developing domain theory in the wider context of $T_0$\nspaces instead of restricting to posets. In this paper, we respond to this\ncalling by proving a topological parallel of a 2005 result due to B. Zhao and\nD. Zhao, i.e., an order-theoretic characterisation of those posets for which\nthe lim-inf convergence is topological. We do this by adopting a recent\napproach due to D. Zhao and W. K. Ho by replacing directed subsets with\nirreducible sets. As a result, we formulate a new convergence class on $T_0$\nspaces called Irr-convergence and established that this convergence class\n$\\mathcal{I}$ on a $k$-bounded sober space $X$ is topological if and only if\n$X$ is Irr-continuous.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 08:43:09 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Andradi", "Hadrian", ""], ["Ho", "Weng Kin", ""]]}, {"id": "1607.01164", "submitter": "Christoph Rauch", "authors": "Zhiwei Zou, Qingguo Li, Weng Kin Ho", "title": "Domains via approximation operators", "comments": "17 pages; 1figure, Domains XII Workshop", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (April 27,\n  2018) lmcs:4471", "doi": "10.23638/LMCS-14(2:6)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we tailor-make new approximation operators inspired by rough\nset theory and specially suited for domain theory. Our approximation operators\noffer a fresh perspective to existing concepts and results in domain theory,\nbut also reveal ways to establishing novel domain-theoretic results. For\ninstance, (1) the well-known interpolation property of the way-below relation\non a continuous poset is equivalent to the idempotence of a certain\nset-operator; (2) the continuity of a poset can be characterized by the\ncoincidence of the Scott closure operator and the upper approximation operator\ninduced by the way below relation; (3) meet-continuity can be established from\na certain property of the topological closure operator. Additionally, we show\nhow, to each approximating relation, an associated order-compatible topology\ncan be defined in such a way that for the case of a continuous poset the\ntopology associated to the way-below relation is exactly the Scott topology. A\npreliminary investigation is carried out on this new topology.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 09:30:47 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 01:20:06 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 10:30:20 GMT"}, {"version": "v4", "created": "Thu, 26 Apr 2018 13:26:00 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Zou", "Zhiwei", ""], ["Li", "Qingguo", ""], ["Ho", "Weng Kin", ""]]}, {"id": "1607.01474", "submitter": "Ernst Moritz Hahn", "authors": "Ernst Moritz Hahn, Sven Schewe, Andrea Turrini, Lijun Zhang", "title": "Synthesising Strategy Improvement and Recursive Algorithms for Solving\n  2.5 Player Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2.5 player parity games combine the challenges posed by 2.5 player\nreachability games and the qualitative analysis of parity games. These two\ntypes of problems are best approached with different types of algorithms:\nstrategy improvement algorithms for 2.5 player reachability games and recursive\nalgorithms for the qualitative analysis of parity games. We present a method\nthat - in contrast to existing techniques - tackles both aspects with the best\nsuited approach and works exclusively on the 2.5 player game itself. The\nresulting technique is powerful enough to handle games with several million\nstates.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 03:39:05 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Schewe", "Sven", ""], ["Turrini", "Andrea", ""], ["Zhang", "Lijun", ""]]}, {"id": "1607.01539", "submitter": "Lars Hupel", "authors": "Lars Hupel and Viktor Kuncak", "title": "Translating Scala Programs to Isabelle/HOL", "comments": "International Joint Conference on Automated Reasoning, 2016", "journal-ref": "IJCAR 2016: Automated Reasoning Volume 9706 of the series Lecture\n  Notes in Computer Science pp 568-577, Springer", "doi": "10.1007/978-3-319-40229-1_38", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a trustworthy connection between the Leon verification system and\nthe Isabelle proof assistant. Leon is a system for verifying functional Scala\nprograms. It uses a variety of automated theorem provers (ATPs) to check\nverification conditions (VCs) stemming from the input program. Isabelle, on the\nother hand, is an interactive theorem prover used to verify mathematical\nspecifications using its own input language Isabelle/Isar. Users specify\n(inductive) definitions and write proofs about them manually, albeit with the\nhelp of semi-automated tactics. The integration of these two systems allows us\nto exploit Isabelle's rich standard library and give greater confidence\nguarantees in the correctness of analysed programs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 09:39:33 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Hupel", "Lars", ""], ["Kuncak", "Viktor", ""]]}, {"id": "1607.01686", "submitter": "Armando Matos Dr", "authors": "Armando B. Matos", "title": "Primitive recursive functions versus partial recursive functions:\n  comparing the degree of undecidability", "comments": "Original research work. 46 pages. 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a decision problem whose instance is a function. Its degree of\nundecidability, measured by the corresponding class of the arithmetic (or\nKleene-Mostowski) hierarchy hierarchy, may depend on whether the instance is a\npartial recursive or a primitive recursive function. A similar situation\nhappens for results like Rice Theorem (which is false for primitive recursive\nfunctions). Classical Recursion Theory deals mainly with the properties of\npartial recursive functions. We study several natural decision problems related\nto primitive recursive functions and characterise their degree of\nundecidability. As an example, we show that, for primitive recursive functions,\nthe injectivity problem is Pi^0_1-complete while the surjectivity problem is\nPi_2-complete (omit superscripts from now on). We compare the degree of\nundecidability (measured by the level in the arithmetic hierarchy) of several\nprimitive recursive decision problems with the corresponding problems of\nclassical Recursion Theory. For instance, the problem \"does the codomain of a\nfunction have exactly one element?\" is Pi_1-complete for primitive recursive\nfunctions and belongs to the class [Delta_2 - (Sigma_1 UNION Pi_1)] for partial\nrecursive functions. An important decision problem, \"does a given primitive\nrecursive function have at least one zero?\" is studied in detail.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 15:50:45 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Matos", "Armando B.", ""]]}, {"id": "1607.01886", "submitter": "Weng Kin Ho", "authors": "Weng Kin Ho, Achim Jung, Dongsheng Zhao", "title": "Join-continuity + Hypercontinuity = Prime continuity", "comments": "7 pages, Domains XII Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A remarkable result due to Kou, Liu & Luo states that the condition of\ncontinuity for a dcpo can be split into quasi-continuity and meet-continuity.\nTheir argument contained a gap, however, which is probably why the authors of\nthe monograph Continuous Lattices and Domains used a different (and fairly\nsophisticated) sequence of lemmas in order to establish the result. In this\nnote we show that by considering the Stone dual, that is, the lattice of\nScott-open subsets, a straightforward proof may be given. We do this by showing\nthat a complete lattice is prime-continuous if and only if it is\njoin-continuous and hypercontinuous. A pleasant side effect of this approach is\nthat the characterisation of continuity by Kou, Liu & Luo also holds for\nposets, not just dcpos.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 06:59:04 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Ho", "Weng Kin", ""], ["Jung", "Achim", ""], ["Zhao", "Dongsheng", ""]]}, {"id": "1607.01993", "submitter": "Nikos Gorogiannis", "authors": "James Brotherston, Nikos Gorogiannis and Max Kanovich", "title": "Biabduction (and Related Problems) in Array Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate array separation logic (ASL), a variant of symbolic-heap\nseparation logic in which the data structures are either pointers or arrays,\ni.e., contiguous blocks of allocated memory. This logic provides a language for\ncompositional memory safety proofs of imperative array programs.\n  We focus on the biabduction problem for this logic, which has been\nestablished as the key to automatic specification inference at the industrial\nscale. We present an NP decision procedure for biabduction in ASL that produces\nsolutions of reasonable quality, and we also show that the problem of finding a\nconsistent solution is NP-hard.\n  Along the way, we study satisfiability and entailment in our logic, giving\ndecision procedures and complexity bounds for both problems. We show\nsatisfiability to be NP-complete, and entailment to be decidable with high\ncomplexity. The somewhat surprising fact that biabduction is much simpler than\nentailment is explained by the fact that, as we show, the element of choice\nover biabduction solutions enables us to dramatically reduce the search space.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 12:49:04 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 21:44:27 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2016 11:20:20 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Brotherston", "James", ""], ["Gorogiannis", "Nikos", ""], ["Kanovich", "Max", ""]]}, {"id": "1607.02001", "submitter": "EPTCS", "authors": "Maurice H. ter Beek (ISTI-CNR, Pisa, Italy), Michele Loreti\n  (University of Florence, Italy)", "title": "Proceedings of the Workshop on FORmal methods for the quantitative\n  Evaluation of Collective Adaptive SysTems", "comments": null, "journal-ref": "EPTCS 217, 2016", "doi": "10.4204/EPTCS.217", "report-no": null, "categories": "cs.LO cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective Adaptive Systems (CAS) consist of a large number of spatially\ndistributed heterogeneous entities with decentralised control and varying\ndegrees of complex autonomous behaviour that may be competing for shared\nresources even when collaborating to reach common goals. It is important to\ncarry out thorough quantitative modelling and analysis and verification of\ntheir design to investigate all aspects of their behaviour before they are put\ninto operation. This requires combinations of formal methods and applied\nmathematics which moreover scale to large-scale CAS. The primary goal of\nFORECAST is to raise awareness in the software engineering and formal methods\ncommunities of the particularities of CAS and the design and control problems\nwhich they bring.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 13:23:39 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["ter Beek", "Maurice H.", "", "ISTI-CNR, Pisa, Italy"], ["Loreti", "Michele", "", "University of Florence, Italy"]]}, {"id": "1607.02189", "submitter": "Bj{\\o}rn Kjos-Hanssen", "authors": "Bj{\\o}rn Kjos-Hanssen", "title": "Models of the Chisholm set", "comments": "Paper for Filosofi hovedfag spesialomr{\\aa}de 1 exam, University of\n  Oslo, Fall 1996. First cited in Carmo and Jones, Deontic logic and\n  contrary-to-duties, Handbook of Philosophical Logic, 2002, footnote 28", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a counter-example showing that Carmo and Jones' condition 5(e) may\nconflict with other conditions on the models in their paper \\emph{A new\napproach to contrary-to-duty obligations}.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 22:53:21 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Kjos-Hanssen", "Bj\u00f8rn", ""]]}, {"id": "1607.02227", "submitter": "EPTCS", "authors": "G. W. Hamilton (School of Computing, Dublin City University, Republic\n  of Ireland)", "title": "Generating Counterexamples for Model Checking by Transformation", "comments": "In Proceedings VPT 2016, arXiv:1607.01835. arXiv admin note:\n  substantial text overlap with arXiv:1512.03860", "journal-ref": "EPTCS 216, 2016, pp. 65-82", "doi": "10.4204/EPTCS.216.4", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterexamples explain why a desired temporal logic property fails to hold.\nThe generation of counterexamples is considered to be one of the primary\nadvantages of model checking as a verification technique. Furthermore, when\nmodel checking does succeed in verifying a property, there is typically no\nindependently checkable witness that can be used as evidence for the verified\nproperty. Previously, we have shown how program transformation techniques can\nbe used for the verification of both safety and liveness properties of reactive\nsystems. However, no counterexamples or witnesses were generated using the\ndescribed techniques. In this paper, we address this issue. In particular, we\nshow how the program transformation technique distillation can be used to\nfacilitate the construction of counterexamples and witnesses for temporal\nproperties of reactive systems. Example systems which are intended to model\nmutual exclusion are analysed using these techniques with respect to both\nsafety (mutual exclusion) and liveness (non-starvation), with counterexamples\nbeing generated for those properties which do not hold.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:30:53 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Hamilton", "G. W.", "", "School of Computing, Dublin City University, Republic\n  of Ireland"]]}, {"id": "1607.02230", "submitter": "EPTCS", "authors": "Antonina Nepeivoda", "title": "Turchin's Relation for Call-by-Name Computations: A Formal Approach", "comments": "In Proceedings VPT 2016, arXiv:1607.01835", "journal-ref": "EPTCS 216, 2016, pp. 137-159", "doi": "10.4204/EPTCS.216.8", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supercompilation is a program transformation technique that was first\ndescribed by V. F. Turchin in the 1970s. In supercompilation, Turchin's\nrelation as a similarity relation on call-stack configurations is used both for\ncall-by-value and call-by-name semantics to terminate unfolding of the program\nbeing transformed. In this paper, we give a formal grammar model of\ncall-by-name stack behaviour. We classify the model in terms of the Chomsky\nhierarchy and then formally prove that Turchin's relation can terminate all\ncomputations generated by the model.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:31:36 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Nepeivoda", "Antonina", ""]]}, {"id": "1607.02232", "submitter": "EPTCS", "authors": "Alessandro Aldini (University of Urbino, Italy)", "title": "A Formal Framework for Modeling Trust and Reputation in Collective\n  Adaptive Systems", "comments": "In Proceedings FORECAST 2016, arXiv:1607.02001", "journal-ref": "EPTCS 217, 2016, pp. 19-30", "doi": "10.4204/EPTCS.217.4", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust and reputation models for distributed, collaborative systems have been\nstudied and applied in several domains, in order to stimulate cooperation while\npreventing selfish and malicious behaviors. Nonetheless, such models have\nreceived less attention in the process of specifying and analyzing formally the\nfunctionalities of the systems mentioned above. The objective of this paper is\nto define a process algebraic framework for the modeling of systems that use\n(i) trust and reputation to govern the interactions among nodes, and (ii)\ncommunication models characterized by a high level of adaptiveness and\nflexibility. Hence, we propose a formalism for verifying, through model\nchecking techniques, the robustness of these systems with respect to the\ntypical attacks conducted against webs of trust.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:36:08 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Aldini", "Alessandro", "", "University of Urbino, Italy"]]}, {"id": "1607.02233", "submitter": "EPTCS", "authors": "Diego Latella (CNR-ISTI)", "title": "On Formal Methods for Collective Adaptive System Engineering. {Scalable\n  Approximated, Spatial} Analysis Techniques. Extended Abstract", "comments": "In Proceedings FORECAST 2016, arXiv:1607.02001", "journal-ref": "EPTCS 217, 2016, pp. 53-61", "doi": "10.4204/EPTCS.217.7", "report-no": null, "categories": "cs.LO cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract a view on the role of Formal Methods in System\nEngineering is briefly presented. Then two examples of useful analysis\ntechniques based on solid mathematical theories are discussed as well as the\nsoftware tools which have been built for supporting such techniques. The first\ntechnique is Scalable Approximated Population DTMC Model-checking. The second\none is Spatial Model-checking for Closure Spaces. Both techniques have been\ndeveloped in the context of the EU funded project QUANTICOL.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:36:36 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Latella", "Diego", "", "CNR-ISTI"]]}, {"id": "1607.02234", "submitter": "EPTCS", "authors": "Paul Piho (School of Informatics, University of Edinburgh), Jane\n  Hillston (School of Informatics, University of Edinburgh)", "title": "Stochastic and Spatial Equivalences for PALOMA", "comments": "In Proceedings FORECAST 2016, arXiv:1607.02001", "journal-ref": "EPTCS 217, 2016, pp. 69-80", "doi": "10.4204/EPTCS.217.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We concentrate our study on a recent process algebra - PALOMA - intended to\ncapture interactions between spatially distributed agents, for example in\ncollective adaptive systems. New agent-based semantic rules for deriving the\nunderlying continuous time Markov chain are given in terms of State to Function\nLabelled Transition Systems. Furthermore we define a bisimulation with respect\nto an isometric transformation of space allowing us to compare PALOMA models\nwith respect to their relative rather than absolute locations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:36:54 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Piho", "Paul", "", "School of Informatics, University of Edinburgh"], ["Hillston", "Jane", "", "School of Informatics, University of Edinburgh"]]}, {"id": "1607.02235", "submitter": "EPTCS", "authors": "Gina Belmonte (Azienda Ospedaliera Universitaria Senese), Vincenzo\n  Ciancia (Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo\",\n  Consiglio Nazionale delle Ricerche), Diego Latella (Istituto di Scienza e\n  Tecnologie dell'Informazione \"A. Faedo\", Consiglio Nazionale delle Ricerche),\n  Mieke Massink (Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo\",\n  Consiglio Nazionale delle Ricerche)", "title": "From Collective Adaptive Systems to Human Centric Computation and Back:\n  Spatial Model Checking for Medical Imaging", "comments": "In Proceedings FORECAST 2016, arXiv:1607.02001", "journal-ref": "EPTCS 217, 2016, pp. 81-92", "doi": "10.4204/EPTCS.217.10", "report-no": null, "categories": "cs.LO cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on formal verification for Collective Adaptive Systems (CAS)\npushed advancements in spatial and spatio-temporal model checking, and as a\nside result provided novel image analysis methodologies, rooted in logical\nmethods for topological spaces. Medical Imaging (MI) is a field where such\ntechnologies show potential for ground-breaking innovation. In this position\npaper, we present a preliminary investigation centred on applications of\nspatial model checking to MI. The focus is shifted from pure logics to a\nmixture of logical, statistical and algorithmic approaches, driven by the\nlogical nature intrinsic to the specification of the properties of interest in\nthe field. As a result, novel operators are introduced, that could as well be\nbrought back to the setting of CAS.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:37:08 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Belmonte", "Gina", "", "Azienda Ospedaliera Universitaria Senese"], ["Ciancia", "Vincenzo", "", "Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo\",\n  Consiglio Nazionale delle Ricerche"], ["Latella", "Diego", "", "Istituto di Scienza e\n  Tecnologie dell'Informazione \"A. Faedo\", Consiglio Nazionale delle Ricerche"], ["Massink", "Mieke", "", "Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo\",\n  Consiglio Nazionale delle Ricerche"]]}, {"id": "1607.02466", "submitter": "J\\\"urgen Koslowski", "authors": "Milan Bankovi\\'c (University of Belgrade)", "title": "Solving finite-domain linear constraints in presence of the\n  $\\texttt{alldifferent}$", "comments": "28 pages, 2 figures", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 3 (April 27,\n  2017) lmcs:2016", "doi": "10.2168/LMCS-12(3:5)2016", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the possibility of improvement of the\nwidely-used filtering algorithm for the linear constraints in constraint\nsatisfaction problems in the presence of the alldifferent constraints. In many\ncases, the fact that the variables in a linear constraint are also constrained\nby some alldifferent constraints may help us to calculate stronger bounds of\nthe variables, leading to a stronger constraint propagation. We propose an\nimproved filtering algorithm that targets such cases. We provide a detailed\ndescription of the proposed algorithm and prove its correctness. We evaluate\nthe approach on five different problems that involve combinations of the linear\nand the alldifferent constraints. We also compare our algorithm to other\nrelevant approaches. The experimental results show a great potential of the\nproposed improvement.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 17:32:58 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 18:33:50 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bankovi\u0107", "Milan", "", "University of Belgrade"]]}, {"id": "1607.02549", "submitter": "Adel Dokhanchi", "authors": "Adel Dokhanchi, Bardh Hoxha, Georgios Fainekos", "title": "Formal Requirement Elicitation and Debugging for Testing and\n  Verification of Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework for the elicitation and debugging of formal specifications for\nCyber-Physical Systems is presented. The elicitation of specifications is\nhandled through a graphical interface. Two debugging algorithms are presented.\nThe first checks for erroneous or incomplete temporal logic specifications\nwithout considering the system. The second can be utilized for the analysis of\nreactive requirements with respect to system test traces. The specification\ndebugging framework is applied on a number of formal specifications collected\nthrough a user study. The user study establishes that requirement errors are\ncommon and that the debugging framework can resolve many insidious\nspecification errors.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 23:31:27 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 18:20:49 GMT"}, {"version": "v3", "created": "Thu, 18 May 2017 15:22:22 GMT"}, {"version": "v4", "created": "Fri, 27 Jul 2018 17:38:58 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Dokhanchi", "Adel", ""], ["Hoxha", "Bardh", ""], ["Fainekos", "Georgios", ""]]}, {"id": "1607.02694", "submitter": "EPTCS", "authors": "Alessio Lomuscio (Imperial College London), Moshe Y. Vardi (Rice\n  University)", "title": "Proceedings of the 4th International Workshop on Strategic Reasoning", "comments": null, "journal-ref": "EPTCS 218, 2016", "doi": "10.4204/EPTCS.218", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Fourth International Workshop on\nStrategic Reasoning (SR 2016), held in New York City (USA), July 10, 2016. The\nworkshop consisted of 2 keynote talks and 9 contributed presentations on themes\nof logic, verification, games and equilibria.\n  More information about the Strategic Workshop series is available at\nhttp://www.strategicreasoning.net/\n", "versions": [{"version": "v1", "created": "Sun, 10 Jul 2016 04:53:55 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Lomuscio", "Alessio", "", "Imperial College London"], ["Vardi", "Moshe Y.", "", "Rice\n  University"]]}, {"id": "1607.02790", "submitter": "Thorsten Wi{\\ss}mann", "authors": "Bart Jacobs", "title": "Hyper Normalisation and Conditioning for Discrete Probability\n  Distributions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (August\n  29, 2017) lmcs:3885", "doi": "10.23638/LMCS-13(3:17)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalisation in probability theory turns a subdistribution into a proper\ndistribution. It is a partial operation, since it is undefined for the zero\nsubdistribution. This partiality makes it hard to reason equationally about\nnormalisation. A novel description of normalisation is given as a\nmathematically well-behaved total function. The output of this `hyper'\nnormalisation operation is a distribution of distributions. It improves\nreasoning about normalisation.\n  After developing the basics of this theory of (hyper) normalisation, it is\nput to use in a similarly new description of conditioning, producing a\ndistribution of conditional distributions. This is used to give a clean\nabstract reformulation of refinement in quantitative information flow.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jul 2016 22:11:09 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 11:11:41 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 09:35:52 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Jacobs", "Bart", ""]]}, {"id": "1607.02966", "submitter": "EPTCS", "authors": "Mirco Tribastone (IMT School for Advanced Studies Lucca, Italy)", "title": "Challenges in Quantitative Abstractions for Collective Adaptive Systems", "comments": "In Proceedings FORECAST 2016, arXiv:1607.02001", "journal-ref": "EPTCS 217, 2016, pp. 62-68", "doi": "10.4204/EPTCS.217.8", "report-no": null, "categories": "cs.SY cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like with most large-scale systems, the evaluation of quantitative properties\nof collective adaptive systems is an important issue that crosscuts all its\ndevelopment stages, from design (in the case of engineered systems) to runtime\nmonitoring and control. Unfortunately it is a difficult problem to tackle in\ngeneral, due to the typically high computational cost involved in the analysis.\nThis calls for the development of appropriate quantitative abstraction\ntechniques that preserve most of the system's dynamical behaviour using a more\ncompact representation. This paper focuses on models based on ordinary\ndifferential equations and reviews recent results where abstraction is achieved\nby aggregation of variables, reflecting on the shortcomings in the state of the\nart and setting out challenges for future research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 05:36:45 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Tribastone", "Mirco", "", "IMT School for Advanced Studies Lucca, Italy"]]}, {"id": "1607.02970", "submitter": "Christoph Rauch", "authors": "Dag Normann", "title": "The sequential functionals of type $(\\iota \\rightarrow \\iota)^n\n  \\rightarrow \\iota$ form a dcpo for all $n \\in \\Bbb N$", "comments": "10 pages", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (March 20,\n  2018) lmcs:4392", "doi": "10.23638/LMCS-14(1:23)2018", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove that the sequential functionals of some fixed types at type level 2,\ntaking finite sequences of unary functions as arguments, do form a directed\ncomplete partial ordering. This gives a full characterisation of for which\ntypes the partially ordered set of sequential functionals has this property. As\na tool, we prove a normal form theorem for the finite sequential functionals of\nthe types in question,\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 14:25:24 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 07:32:16 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 07:45:22 GMT"}, {"version": "v4", "created": "Mon, 19 Mar 2018 15:00:19 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Normann", "Dag", ""]]}, {"id": "1607.02988", "submitter": "Luigi Santocanale", "authors": "Luigi Santocanale (LIF)", "title": "The quasiequational theory of relational lattices, in the pure lattice\n  signature (embeddability into relational lattices is undecidable)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural join and the inner union operations combine relations of a\ndatabase. Tropashko and Spight realized that these two operations are themeet\nand join operations in a class of lattices, known by now as the relational\nlattices. They proposed then lattice theory as an algebraic approach to\nthetheory of databases alternative to the relational algebra. Litak et al.\nproposed an axiomatization of relational lattices over the signature that\nextends thepure lattice signature with a constant and argued that the\nquasiequational theory of relational lattices over this extended signature is\nundecidable.We prove in this paper that embeddability is undecidable for\nrelational lattices. More precisely, it is undecidable whether a finite\nsubdirectly-irreduciblelattice can be embedded into a relational lattice. Our\nproof is a reduction from the coverability problem of a multimodal frame by a\nuniversal product frameand, indirectly, from the representability problem for\nrelation algebras. As corollaries we obtain the following results: the\nquasiequational theoryof relational lattices over the pure lattice signature is\nundecidable and has no finite base; there is a quasiequation over the pure\nlattice signature which holds in all the finite relational lattices but fails\nin an infinite relational lattice.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 14:59:42 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 13:40:54 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 09:34:21 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Santocanale", "Luigi", "", "LIF"]]}, {"id": "1607.03286", "submitter": "Christoph Rauch", "authors": "Weng Kin Ho, Jean Goubault-Larrecq, Achim Jung, and Xiaoyong Xi", "title": "The Ho-Zhao Problem", "comments": "19 pages, 4 figures", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  17, 2018) lmcs:4218", "doi": "10.23638/LMCS-14(1:7)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a poset $P$, the set, $\\Gamma(P)$, of all Scott closed sets ordered by\ninclusion forms a complete lattice. A subcategory $\\mathbf{C}$ of\n$\\mathbf{Pos}_d$ (the category of posets and Scott-continuous maps) is said to\nbe $\\Gamma$-faithful if for any posets $P$ and $Q$ in $\\mathbf{C}$, $\\Gamma(P)\n\\cong \\Gamma(Q)$ implies $P \\cong Q$. It is known that the category of all\ncontinuous dcpos and the category of bounded complete dcpos are\n$\\Gamma$-faithful, while $\\mathbf{Pos}_d$ is not. Ho & Zhao (2009) asked\nwhether the category $\\mathbf{DCPO}$ of dcpos is $\\Gamma$-faithful. In this\npaper, we answer this question in the negative by exhibiting a counterexample.\nTo achieve this, we introduce a new subcategory of dcpos which is\n$\\Gamma$-faithful. This subcategory subsumes all currently known\n$\\Gamma$-faithful subcategories. With this new concept in mind, we construct\nthe desired counterexample which relies heavily on Johnstone's famous dcpo\nwhich is not sober in its Scott topology.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 09:43:22 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 15:31:03 GMT"}, {"version": "v3", "created": "Tue, 16 Jan 2018 16:00:29 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Ho", "Weng Kin", ""], ["Goubault-Larrecq", "Jean", ""], ["Jung", "Achim", ""], ["Xi", "Xiaoyong", ""]]}, {"id": "1607.03354", "submitter": "EPTCS", "authors": "Benjamin Aminof (Technische Universitat Wien, Austria), Vadim Malvone\n  (Universit\\`a degli Studi di Napoli Federico II, Italy), Aniello Murano\n  (Universit\\`a degli Studi di Napoli Federico II, Italy), Sasha Rubin\n  (Universit\\`a degli Studi di Napoli Federico II, Italy)", "title": "Extended Graded Modalities in Strategy Logic", "comments": "In Proceedings SR 2016, arXiv:1607.02694", "journal-ref": "EPTCS 218, 2016, pp. 1-14", "doi": "10.4204/EPTCS.218.1", "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategy Logic (SL) is a logical formalism for strategic reasoning in\nmulti-agent systems. Its main feature is that it has variables for strategies\nthat are associated to specific agents with a binding operator. We introduce\nGraded Strategy Logic (GradedSL), an extension of SL by graded quantifiers over\ntuples of strategy variables, i.e., \"there exist at least g different tuples\n(x_1,...,x_n) of strategies\" where g is a cardinal from the set N union\n{aleph_0, aleph_1, 2^aleph_0}. We prove that the model-checking problem of\nGradedSL is decidable. We then turn to the complexity of fragments of GradedSL.\nWhen the g's are restricted to finite cardinals, written GradedNSL, the\ncomplexity of model-checking is no harder than for SL, i.e., it is\nnon-elementary in the quantifier rank. We illustrate our formalism by showing\nhow to count the number of different strategy profiles that are Nash equilibria\n(NE), or subgame-perfect equilibria (SPE). By analyzing the structure of the\nspecific formulas involved, we conclude that the important problems of checking\nfor the existence of a unique NE or SPE can both be solved in 2ExpTime, which\nis not harder than merely checking for the existence of such equilibria.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 13:46:52 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Aminof", "Benjamin", "", "Technische Universitat Wien, Austria"], ["Malvone", "Vadim", "", "Universit\u00e0 degli Studi di Napoli Federico II, Italy"], ["Murano", "Aniello", "", "Universit\u00e0 degli Studi di Napoli Federico II, Italy"], ["Rubin", "Sasha", "", "Universit\u00e0 degli Studi di Napoli Federico II, Italy"]]}, {"id": "1607.03355", "submitter": "EPTCS", "authors": "Hein Duijf (Utrecht University), Jan Broersen (Utrecht University)", "title": "Representing Strategies", "comments": "In Proceedings SR 2016, arXiv:1607.02694", "journal-ref": "EPTCS 218, 2016, pp. 15-26", "doi": "10.4204/EPTCS.218.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quite some work in the ATL-tradition uses the differences between various\ntypes of strategies (positional, uniform, perfect recall) to give alternative\nsemantics to the same logical language. This paper contributes to another\nperspective on strategy types, one where we characterise the differences\nbetween them on the syntactic (object language) level. This is important for a\nmore traditional knowledge representation view on strategic content. Leaving\ndifferences between strategy types implicit in the semantics is a sensible idea\nif the goal is to use the strategic formalism for model checking. But, for\ntraditional knowledge representation in terms of object language level\nformulas, we need to extent the language. This paper introduces a strategic\nSTIT syntax with explicit operators for knowledge that allows us to charaterise\nstrategy types. This more expressive strategic language is interpreted on\nstandard ATL-type concurrent epistemic game structures. We introduce rule-based\nstrategies in our language and fruitfully apply them to the representation and\ncharacterisation of positional and uniform strategies. Our representations\nhighlight crucial conditions to be met for strategy types. We demonstrate the\nusefulness of our work by showing that it leads to a critical reexamination of\ncoalitional uniform strategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 13:47:01 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Duijf", "Hein", "", "Utrecht University"], ["Broersen", "Jan", "", "Utrecht University"]]}, {"id": "1607.03356", "submitter": "EPTCS", "authors": "St\\'ephane Le Roux (Universit\\'e Libre de Bruxelles), Arno Pauly\n  (Universit\\'e Libre de Bruxelles)", "title": "Extending Finite Memory Determinacy to Multiplayer Games", "comments": "In Proceedings SR 2016, arXiv:1607.02694", "journal-ref": "EPTCS 218, 2016, pp. 27-40", "doi": "10.4204/EPTCS.218.3", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that under some general conditions the finite memory determinacy of a\nclass of two-player win/lose games played on finite graphs implies the\nexistence of a Nash equilibrium built from finite memory strategies for the\ncorresponding class of multi-player multi-outcome games. This generalizes a\nprevious result by Brihaye, De Pril and Schewe. For most of our conditions we\nprovide counterexamples showing that they cannot be dispensed with.\n  Our proofs are generally constructive, that is, provide upper bounds for the\nmemory required, as well as algorithms to compute the relevant winning\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 13:47:10 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Roux", "St\u00e9phane Le", "", "Universit\u00e9 Libre de Bruxelles"], ["Pauly", "Arno", "", "Universit\u00e9 Libre de Bruxelles"]]}, {"id": "1607.03455", "submitter": "Justin Hsu", "authors": "Gilles Barthe, Benjamin Gr\\'egoire, Justin Hsu, Pierre-Yves Strub", "title": "Coupling proofs are probabilistic product programs", "comments": null, "journal-ref": null, "doi": "10.1145/3009837.3009896", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Couplings are a powerful mathematical tool for reasoning about pairs of\nprobabilistic processes. Recent developments in formal verification identify a\nclose connection between couplings and pRHL, a relational program logic\nmotivated by applications to provable security, enabling formal construction of\ncouplings from the probability theory literature. However, existing work using\npRHL merely shows existence of a coupling and does not give a way to prove\nquantitative properties about the coupling, which are need to reason about\nmixing and convergence of probabilistic processes. Furthermore, pRHL is\ninherently incomplete, and is not able to capture some advanced forms of\ncouplings such as shift couplings. We address both problems as follows.\n  First, we define an extension of pRHL, called xpRHL, which explicitly\nconstructs the coupling in a pRHL derivation in the form of a probabilistic\nproduct program that simulates two correlated runs of the original program.\nExisting verification tools for probabilistic programs can then be directly\napplied to the probabilistic product to prove quantitative properties of the\ncoupling. Second, we equip pRHL with a new rule for while loops, where\nreasoning can freely mix synchronized and unsynchronized loop iterations. Our\nproof rule can capture examples of shift couplings, and the logic is relatively\ncomplete for deterministic programs.\n  We show soundness of xpRHL and use it to analyze two classes of examples.\nFirst, we verify rapid mixing using different tools from coupling: standard\ncoupling, shift coupling, and path coupling, a compositional principle for\ncombining local couplings into a global coupling. Second, we verify\n(approximate) equivalence between a source and an optimized program for several\ninstances of loop optimizations from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 18:19:22 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 14:21:33 GMT"}, {"version": "v3", "created": "Sun, 24 Jul 2016 14:33:13 GMT"}, {"version": "v4", "created": "Tue, 26 Jul 2016 10:27:12 GMT"}, {"version": "v5", "created": "Mon, 7 Nov 2016 17:19:19 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Barthe", "Gilles", ""], ["Gr\u00e9goire", "Benjamin", ""], ["Hsu", "Justin", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1607.03618", "submitter": "Francois Clement", "authors": "Fran\\c{c}ois Cl\\'ement (SERENA), Vincent Martin (LMAC)", "title": "The Lax-Milgram Theorem. A detailed proof to be formalized in Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To obtain the highest confidence on the correction of numerical simulation\nprograms implementing the finite element method, one has to formalize the\nmathematical notions and results that allow to establish the soundness of the\nmethod. The Lax-Milgram theorem may be seen as one of those theoretical\ncornerstones: under some completeness and coercivity assumptions, it states\nexistence and uniqueness of the solution to the weak formulation of some\nboundary value problems. The purpose of this document is to provide the formal\nproof community with a very detailed pen-and-paper proof of the Lax-Milgram\ntheorem.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 07:43:54 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 13:11:12 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Cl\u00e9ment", "Fran\u00e7ois", "", "SERENA"], ["Martin", "Vincent", "", "LMAC"]]}, {"id": "1607.03747", "submitter": "Glynn Winskel", "authors": "Marc de Visme and Glynn Winskel", "title": "Strategies with Parallel Causes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a distributed game we imagine a team Player engaging a team Opponent in a\ndistributed fashion. Such games and their strategies have been formalised in\nconcurrent games based on event structures. However there are limitations in\nfounding strategies on traditional event structures. Sometimes a probabilistic\ndistributed strategy relies on certain benign races where, intuitively, several\nmembers of team Player may race each other to make a common move. Although\nthere are event structures which support such parallel causes, in which an\nevent is enabled in several compatible ways, they do not support an operation\nof hiding central to the composition of strategies; nor do they support\nprobability adequately. An extension of traditional event structures is devised\nwhich supports parallel causes and hiding, as well as the mix of probability\nand nondeterminism needed to account for probabilistic distributed strategies.\nThe extension is tested in the construction of a bicategory of probabilistic\ndistributed strategies with parallel causes. The bicategory is rich in\noperations relevant to probabilistic as well as deterministic parallel\nprogramming.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 14:13:49 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["de Visme", "Marc", ""], ["Winskel", "Glynn", ""]]}, {"id": "1607.03760", "submitter": "Glynn Winskel", "authors": "Glynn Winskel", "title": "Distributed Games and Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A summary of work on distributed games and strategies done within the first\nthree years of the ERC project ECSYM is presented.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 14:25:03 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Winskel", "Glynn", ""]]}, {"id": "1607.03819", "submitter": "Barnaby Martin", "authors": "Barnaby Martin", "title": "On the Chen Conjecture regarding the complexity of QCSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let A be an idempotent algebra on a finite domain. We combine results of Chen\n2008 and Zhuk 2015 to argue that if Inv(A) satisfies the polynomially generated\npowers property (PGP), then QCSP(Inv(A)) is in NP. We then use the result of\nZhuk to prove a converse, that if Inv(A) satisfies the exponentially generated\npowers property (EGP), then QCSP(Inv(A)) is co-NP-hard. Since Zhuk proved that\nonly PGP and EGP are possible, we derive a full dichotomy for the QCSP,\njustifying the moral correctness of what we term the Chen Conjecture.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 16:33:05 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Martin", "Barnaby", ""]]}, {"id": "1607.03877", "submitter": "Sergey Slavnov A", "authors": "Sergey Slavnov", "title": "Compactification of *-autonomous categories", "comments": "Withdrawn. The author found a stupid diverging loophole in a proof,\n  and the announced result is false anyway", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question when a *-autonomous (Mix-)category has a representation\nas a $*$-autonomous category of a compact one. We prove that necessary and\nsufficient condition is that weak distributivity maps are monic (or,\nequivalently epic). For a Mix-category, this condition is, in turn, equivalent\nto the requirement that Mix-maps be monic (or epic). We call categories\nsatisfying this property torsion-free. An important side result is that\ntorsion-free categories have canonical partial traces.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 19:29:58 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 10:06:22 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "1607.04033", "submitter": "EPTCS", "authors": "John P. Gallagher (Roskilde University), Philipp R\\\"ummer (Uppsala\n  University)", "title": "Proceedings 3rd Workshop on Horn Clauses for Verification and Synthesis", "comments": null, "journal-ref": "EPTCS 219, 2016", "doi": "10.4204/EPTCS.219", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of HCVS 2016, the Third Workshop on Horn\nClauses for Verification and Synthesis which was held on April 3, 2016 in\nEindhoven, The Netherlands as a satellite event of the European Joint\nConferences on Theory and Practice of Software (ETAPS 2016). Many program\nverification and synthesis problems of interest can be modeled directly using\nHorn clauses and many recent advances in the CLP and CAV communities have\ncentered around efficiently solving problems presented as Horn clauses. The\nThird Workshop on Horn Clauses for Verification and Synthesis was organised\nwith the aim to bring together researchers working in the two communities of\nConstraint/Logic Programming and Program Verification on the topic of Horn\nclause based analysis, verification and synthesis. Horn clauses for\nverification and synthesis have been advocated by these two communities in\ndifferent times and from different perspectives, and this workshop is organized\nto stimulate interaction and a fruitful exchange and integration of\nexperiences.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 08:46:44 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Gallagher", "John P.", "", "Roskilde University"], ["R\u00fcmmer", "Philipp", "", "Uppsala\n  University"]]}, {"id": "1607.04090", "submitter": "Saeed Salehi", "authors": "Parvin Safari and Saeed Salehi", "title": "Kripke Semantics for Fuzzy Logics", "comments": "Soft Computing (2016)", "journal-ref": "Soft Computing 22:3 (2018) 839--844", "doi": "10.1007/s00500-016-2387-4", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kripke frames (and models) provide a suitable semantics for sub-classical\nlogics, for example Intuitionistic Logic (of Brouwer and Heyting) axiomatizes\nthe reflexive and transitive Kripke frames (with persistent satisfaction\nrelations), and the Basic Logic (of Visser) axiomatizes transitive Kripke\nframes (with persistent satisfaction relations). Here, we investigate whether\nKripke frames/models could provide a semantics for fuzzy logics. For each axiom\nof the Basic Fuzzy Logic, necessary and sufficient conditions are sought for\nKripke frames/models which satisfy them. It turns out that the only fuzzy\nlogics (logics containing the Basic Fuzzy Logic) which are sound and complete\nwith respect to a class of Kripke frames/models are the extensions of the\nG\\\"odel Logic (or the super-intuitionistic logic of Dummett), indeed this logic\nis sound and strongly complete with respect to reflexive, transitive and\nconnected (linear) Kripke frames (with persistent satisfaction relations). This\nprovides a semantic characterization for the G\\\"odel Logic among\n(propositional) fuzzy logics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 11:25:34 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 07:36:46 GMT"}, {"version": "v3", "created": "Sat, 10 Dec 2016 07:22:45 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Safari", "Parvin", ""], ["Salehi", "Saeed", ""]]}, {"id": "1607.04128", "submitter": "Peter Hertling", "authors": "Peter Hertling", "title": "Two Counterexamples Concerning the Scott Topology on a Partial Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a complete lattice $Z$ such that the binary supremum function\n$\\sup:Z\\times Z\\to Z$ is discontinuous with respect to the product topology on\n$Z\\times Z$ of the Scott topologies on each copy of $Z$. In addition, we show\nthat bounded completeness of a complete lattice $Z$ is in general not inherited\nby the dcpo $C(X,Z)$ of continuous functions from $X$ to $Z$ where $X$ may be\nany topological space and where on $Z$ the Scott topology is considered.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 13:41:33 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Hertling", "Peter", ""]]}, {"id": "1607.04156", "submitter": "Simon Huber", "authors": "Simon Huber", "title": "Canonicity for Cubical Type Theory", "comments": "34 pages. v2: Added section on propositional truncation; fixed typos.\n  To appear in the Journal of Automated Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cubical type theory is an extension of Martin-L\\\"of type theory recently\nproposed by Cohen, Coquand, M\\\"ortberg and the author which allows for direct\nmanipulation of $n$-dimensional cubes and where Voevodsky's Univalence Axiom is\nprovable. In this paper we prove canonicity for cubical type theory: any\nnatural number in a context build from only name variables is judgmentally\nequal to a numeral. To achieve this we formulate a typed and deterministic\noperational semantics and employ a computability argument adapted to a\npresheaf-like setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 14:47:06 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 17:18:56 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Huber", "Simon", ""]]}, {"id": "1607.04162", "submitter": "Weng Kin Ho", "authors": "Hadrian Andradi and Weng Kin Ho", "title": "Strong completions of spaces", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-empty subset of a topological space is irreducible if whenever it is\ncovered by the union of two closed sets, then already it is covered by one of\nthem. Irreducible sets occur in proliferation: (1) every singleton set is\nirreducible, (2) directed subsets (which of fundamental status in domain\ntheory) of a poset are exactly its Alexandroff irreducible sets, (3) directed\nsubsets (with respect to the specialization order) of a $T_0$ space are always\nirreducible, and (4) the topological closure of every irreducible set is again\nirreducible. In recent years, the usefulness of irreducible sets in domain\ntheory and non-Hausdorff topology has expanded. Notably, Zhao and Ho (2009)\ndeveloped the core of domain theory directly in the context of $T_0$ spaces by\nchoosing the irreducible sets as the topological substitute for directed sets.\nJust as the existence of suprema of directed subsets is featured prominently in\ndomain theory (and hence the notion of a dcpo -- a poset in which all directed\nsuprema exist), so too is that of irreducible subsets in the topological domain\ntheory developed by Zhao and Ho (2009). The topological counterpart of a dcpo\nis thus this: A $T_0$ space is said to be strongly complete if the suprema of\nall irreducible subsets exist. In this paper, we show that the category,\n$\\mathbf{scTop^+}$, of strongly complete $T_0$ spaces forms are reflective\nsubcategory of a certain lluf subcategory, $\\mathbf{Top^+}$, of $T_0$ spaces.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 15:20:21 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 08:14:43 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Andradi", "Hadrian", ""], ["Ho", "Weng Kin", ""]]}, {"id": "1607.04287", "submitter": "Martin Grohe", "authors": "Christoph Berkholz and Martin Grohe", "title": "Linear Diophantine Equations, Group CSPs, and Graph Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have seen several approaches to the graph isomorphism\nproblem based on \"generic\" mathematical programming or algebraic (Gr\\\"obner\nbasis) techniques. For most of these, lower bounds have been established. In\nfact, it has been shown that the pairs of nonisomorphic CFI-graphs (introduced\nby Cai, F\\\"urer, and Immerman in 1992 as hard examples for the combinatorial\nWeisfeiler-Leman algorithm) cannot be distinguished by these mathematical\nalgorithms. A notable exception were the algebraic algorithms over the field\nGF(2), for which no lower bound was known. Another, in some way even stronger,\napproach to graph isomorphism testing is based on solving systems of linear\nDiophantine equations (that is, linear equations over the integers), which is\nknown to be possible in polynomial time. So far, no lower bounds for this\napproach were known.\n  Lower bounds for the algebraic algorithms can best be proved in the framework\nof proof complexity, where they can be phrased as lower bounds for algebraic\nproof systems such as Nullstellensatz or the (more powerful) polynomial\ncalculus. We give new hard examples for these systems: families of pairs of\nnon-isomorphic graphs that are hard to distinguish by polynomial calculus\nproofs simultaneously over all prime fields, including GF(2), as well as\nexamples that are hard to distinguish by the\nsystems-of-linear-Diophantine-equations approach.\n  In a previous paper, we observed that the CFI-graphs are closely related to\nwhat we call \"group CSPs\": constraint satisfaction problems where the\nconstraints are membership tests in some coset of a subgroup of a cartesian\npower of a base group (Z_2 in the case of the classical CFI-graphs). Our new\nexamples are also based on group CSPs (for Abelian groups), but here we extend\nthe CSPs by a few non-group constraints to obtain even harder instances for\ngraph isomorphism.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 20:00:11 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Berkholz", "Christoph", ""], ["Grohe", "Martin", ""]]}, {"id": "1607.04332", "submitter": "Mathys Rennela", "authors": "Mathys Rennela", "title": "Convexity and Order in Probabilistic Call-by-Name FPC", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (November\n  12, 2020) lmcs:6901", "doi": "10.23638/LMCS-16(4:10)2020", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kegelspitzen are mathematical structures coined by Keimel and Plotkin, in\norder to encompass the structure of a convex set and the structure of a dcpo.\nIn this paper, we ask ourselves what are Kegelspitzen the model of. We adopt a\ncategorical viewpoint and show that Kegelspitzen model stochastic matrices onto\na category of domains. Consequently, Kegelspitzen form a denotational model of\npPCF, an abstract functional programming language for probabilistic computing.\nWe conclude the present work with a discussion of the interpretation of\n(probabilistic) recursive types, which are types for entities which might\ncontain other entities of the same type, such as lists and trees.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 21:45:23 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 17:44:48 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 20:15:26 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 17:51:23 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2020 16:54:33 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Rennela", "Mathys", ""]]}, {"id": "1607.04456", "submitter": "EPTCS", "authors": "Tewodros A. Beyene (fortiss GmbH, Munich, Germany), Corneliu Popeea\n  (CQSE GmbH, Munich, Germany), Andrey Rybalchenko (Microsoft Research,\n  Cambridge, UK)", "title": "Efficient CTL Verification via Horn Constraints Solving", "comments": "In Proceedings HCVS2016, arXiv:1607.04033", "journal-ref": "EPTCS 219, 2016, pp. 1-14", "doi": "10.4204/EPTCS.219.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of temporal logics has long been recognised as a fundamental approach\nto the formal specification and verification of reactive systems. In this\npaper, we take on the problem of automatically verifying a temporal property,\ngiven by a CTL formula, for a given (possibly infinite-state) program. We\npropose a method based on encoding the problem as a set of Horn constraints.\nThe method takes a program, modeled as a transition system, and a property\ngiven by a CTL formula as input. It first generates a set of forall-exists\nquantified Horn constraints and well-foundedness constraints by exploiting the\nsyntactic structure of the CTL formula. Then, the generated set of constraints\nare solved by applying an off-the-shelf Horn constraints solving engine. The\nprogram is said to satisfy the property if and only if the generated set of\nconstraints has a solution. We demonstrate the practical promises of the method\nby applying it on a set of challenging examples. Although our method is based\non a generic Horn constraint solving engine, it is able to outperform\nstate-of-art methods specialised for CTL verification.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 11:04:37 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Beyene", "Tewodros A.", "", "fortiss GmbH, Munich, Germany"], ["Popeea", "Corneliu", "", "CQSE GmbH, Munich, Germany"], ["Rybalchenko", "Andrey", "", "Microsoft Research,\n  Cambridge, UK"]]}, {"id": "1607.04457", "submitter": "EPTCS", "authors": "Pierre-Lo\\\"ic Garoche (DTIM, UFT, Onera - The French Aerospace Lab),\n  Temesghen Kahsai (Nasa Ames / CMU), Xavier Thirioux (IRIT/ENSEEIHT, UFT,\n  CNRS)", "title": "Hierarchical State Machines as Modular Horn Clauses", "comments": "In Proceedings HCVS2016, arXiv:1607.04033", "journal-ref": "EPTCS 219, 2016, pp. 15-28", "doi": "10.4204/EPTCS.219.2", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model based development, embedded systems are modeled using a mix of\ndataflow formalism, that capture the flow of computation, and hierarchical\nstate machines, that capture the modal behavior of the system. For safety\nanalysis, existing approaches rely on a compilation scheme that transform the\noriginal model (dataflow and state machines) into a pure dataflow formalism.\nSuch compilation often result in loss of important structural information that\ncapture the modal behaviour of the system. In previous work we have developed a\ncompilation technique from a dataflow formalism into modular Horn clauses. In\nthis paper, we present a novel technique that faithfully compile hierarchical\nstate machines into modular Horn clauses. Our compilation technique preserves\nthe structural and modal behavior of the system, making the safety analysis of\nsuch models more tractable.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 11:04:49 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Garoche", "Pierre-Lo\u00efc", "", "DTIM, UFT, Onera - The French Aerospace Lab"], ["Kahsai", "Temesghen", "", "Nasa Ames / CMU"], ["Thirioux", "Xavier", "", "IRIT/ENSEEIHT, UFT,\n  CNRS"]]}, {"id": "1607.04458", "submitter": "EPTCS", "authors": "Peter Schrammel (University of Oxford)", "title": "Challenges in Decomposing Encodings of Verification Problems", "comments": "In Proceedings HCVS2016, arXiv:1607.04033", "journal-ref": "EPTCS 219, 2016, pp. 29-32", "doi": "10.4204/EPTCS.219.3", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern program verifiers use logic-based encodings of the verification\nproblem that are discharged by a back end reasoning engine. However, instances\nof such encodings for large programs can quickly overwhelm these back end\nsolvers. Hence, we need techniques to make the solving process scale to large\nsystems, such as partitioning (divide-and-conquer) and abstraction.\n  In recent work, we showed how decomposing the formula encoding of a\ntermination analysis can significantly increase efficiency. The analysis\ngenerates a sequence of logical formulas with existentially quantified\npredicates that are solved by a synthesis-based program analysis engine.\nHowever, decomposition introduces abstractions in addition to those required\nfor finding the unknown predicates in the formula, and can hence deteriorate\nprecision. We discuss the challenges associated with such decompositions and\ntheir interdependencies with the solving process.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 11:04:59 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Schrammel", "Peter", "", "University of Oxford"]]}, {"id": "1607.04459", "submitter": "EPTCS", "authors": "Bishoksan Kafle (Roskilde University), John P. Gallagher (Roskilde\n  University and IMDEA Software Institute), Pierre Ganty (IMDEA Software\n  Institute, Spain)", "title": "Solving non-linear Horn clauses using a linear Horn clause solver", "comments": "In Proceedings HCVS2016, arXiv:1607.04033", "journal-ref": "EPTCS 219, 2016, pp. 33-48", "doi": "10.4204/EPTCS.219.4", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that checking satisfiability of a set of non-linear\nHorn clauses (also called a non-linear Horn clause program) can be achieved\nusing a solver for linear Horn clauses. We achieve this by interleaving a\nprogram transformation with a satisfiability checker for linear Horn clauses\n(also called a solver for linear Horn clauses). The program transformation is\nbased on the notion of tree dimension, which we apply to a set of non-linear\nclauses, yielding a set whose derivation trees have bounded dimension. Such a\nset of clauses can be linearised. The main algorithm then proceeds by applying\nthe linearisation transformation and solver for linear Horn clauses to a\nsequence of sets of clauses with successively increasing dimension bound. The\napproach is then further developed by using a solution of clauses of lower\ndimension to (partially) linearise clauses of higher dimension. We constructed\na prototype implementation of this approach and performed some experiments on a\nset of verification problems, which shows some promise.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 11:05:08 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Kafle", "Bishoksan", "", "Roskilde University"], ["Gallagher", "John P.", "", "Roskilde\n  University and IMDEA Software Institute"], ["Ganty", "Pierre", "", "IMDEA Software\n  Institute, Spain"]]}, {"id": "1607.04460", "submitter": "EPTCS", "authors": "Emanuele De Angelis, Fabio Fioravanti, Alberto Pettorossi, Maurizio\n  Proietti", "title": "Removing Unnecessary Variables from Horn Clause Verification Conditions", "comments": "In Proceedings HCVS2016, arXiv:1607.04033", "journal-ref": "EPTCS 219, 2016, pp. 49-55", "doi": "10.4204/EPTCS.219.5", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification conditions (VCs) are logical formulas whose satisfiability\nguarantees program correctness. We consider VCs in the form of constrained Horn\nclauses (CHC) which are automatically generated from the encoding of (an\ninterpreter of) the operational semantics of the programming language. VCs are\nderived through program specialization based on the unfold/fold transformation\nrules and, as it often happens when specializing interpreters, they contain\nunnecessary variables, that is, variables which are not required for the\ncorrectness proofs of the programs under verification. In this paper we adapt\nto the CHC setting some of the techniques that were developed for removing\nunnecessary variables from logic programs, and we show that, in some cases, the\napplication of these techniques increases the effectiveness of Horn clause\nsolvers when proving program correctness.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 11:05:17 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["De Angelis", "Emanuele", ""], ["Fioravanti", "Fabio", ""], ["Pettorossi", "Alberto", ""], ["Proietti", "Maurizio", ""]]}, {"id": "1607.04500", "submitter": "Boas Kluiving", "authors": "Boas Kluiving and Wijnand van Woerkom", "title": "Number representations and term rewriting", "comments": "17 pages, 7 tables. For the automatic proofs, see\n  https://staff.fnwi.uva.nl/a.ponse/term_rewriting_proofs/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine a number of term rewriting system for integer number\nrepresentations, building further upon the datatype defining systems described\nin [2]. In particular, we look at automated methods for proving confluence and\ntermination in binary and decimal term rewriting systems for both append and\ntree constructor functions. We find that some of these term rewriting systems\nare not strongly terminating, which we resolve with minor changes to these\nsystems. Moreover, most of the term rewriting systems discussed do not exhibit\nthe confluence property, which seems more difficult to resolve.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 13:18:55 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Kluiving", "Boas", ""], ["van Woerkom", "Wijnand", ""]]}, {"id": "1607.04611", "submitter": "Ale\\v{s} Bizjak", "authors": "John Longley", "title": "The recursion hierarchy for PCF is strict", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (August\n  21, 2018) lmcs:4762", "doi": "10.23638/LMCS-14(3:8)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the sublanguages of Plotkin's PCF obtained by imposing some bound\nk on the levels of types for which fixed point operators are admitted. We show\nthat these languages form a strict hierarchy, in the sense that a fixed point\noperator for a type of level k can never be defined (up to observational\nequivalence) using fixed point operators for lower types. This answers a\nquestion posed by Berger. Our proof makes substantial use of the theory of\nnested sequential procedures (also called PCF B\\\"ohm trees) as expounded in the\nrecent book of Longley and Normann.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 18:44:07 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 12:38:42 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 17:01:07 GMT"}, {"version": "v4", "created": "Tue, 19 Jun 2018 12:10:28 GMT"}, {"version": "v5", "created": "Thu, 26 Jul 2018 17:08:22 GMT"}, {"version": "v6", "created": "Fri, 17 Aug 2018 11:35:18 GMT"}, {"version": "v7", "created": "Mon, 20 Aug 2018 06:38:09 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Longley", "John", ""]]}, {"id": "1607.04690", "submitter": "Christoph Rauch", "authors": "Thomas Ehrhard and Christine Tasson", "title": "Probabilistic call by push value", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (January\n  9, 2019) lmcs:5067", "doi": "10.23638/LMCS-15(1:3)2019", "report-no": "hal-01345847", "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a probabilistic extension of Levy's Call-By-Push-Value. This\nextension consists simply in adding a \" flipping coin \" boolean closed atomic\nexpression. This language can be understood as a major generalization of\nScott's PCF encompassing both call-by-name and call-by-value and featuring\nrecursive (possibly lazy) data types. We interpret the language in the\npreviously introduced denotational model of probabilistic coherence spaces, a\ncategorical model of full classical Linear Logic, interpreting data types as\ncoalgebras for the resource comonad. We prove adequacy and full abstraction,\ngeneralizing earlier results to a much more realistic and powerful programming\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 01:06:46 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 11:30:11 GMT"}, {"version": "v3", "created": "Fri, 24 Nov 2017 13:36:54 GMT"}, {"version": "v4", "created": "Sat, 4 Aug 2018 13:23:57 GMT"}, {"version": "v5", "created": "Tue, 8 Jan 2019 15:41:35 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Ehrhard", "Thomas", ""], ["Tasson", "Christine", ""]]}, {"id": "1607.04721", "submitter": "Marcel Ern\\'e Dr.", "authors": "Marcel Ern\\'e", "title": "Core spaces, sector spaces and fan spaces: a topological approach to\n  domain theory", "comments": "30 pages, 1 figure, 10 diagrams, conference on domain theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present old and new characterizations of core spaces, alias worldwide web\nspaces, originally defined by the existence of supercompact neighborhood bases.\nThe patch spaces of core spaces, obtained by joining the original topology with\na second topology having the dual specialization order, are the so-called\nsector spaces, which have good convexity and separation properties and\ndetermine the original space. The category of core spaces is shown to be\nconcretely isomorphic to the category of fan spaces; these are certain\nquasi-ordered spaces having neighborhood bases of so-called fans, obtained by\ndeleting a finite number of principal filters from a principal filter. This\napproach has useful consequences for domain theory. In fact, endowed with the\nScott topology, the continuous domains are nothing but the sober core spaces,\nand endowed with the Lawson topology, they are the corresponding fan spaces. We\ngeneralize the characterization of continuous lattices as meet-continuous\nlattices with T$_2$ Lawson topology and extend the Fundamental Theorem of\nCompact Semilattices to non-complete structures. Finally, we investigate\ncardinal invariants like density and weight of the involved objects.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 09:18:50 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Ern\u00e9", "Marcel", ""]]}, {"id": "1607.04787", "submitter": "Jakub Opr\\v{s}al", "authors": "V\\'ictor Dalmau, Marcin Kozik, Andrei Krokhin, Konstantin Makarychev,\n  Yury Makarychev, Jakub Opr\\v{s}al", "title": "Robust algorithms with polynomial loss for near-unanimity CSPs", "comments": "A preliminary version of this paper appeared in SODA 2017. Journal\n  referees' comments are incorporated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An instance of the Constraint Satisfaction Problem (CSP) is given by a family\nof constraints on overlapping sets of variables, and the goal is to assign\nvalues from a fixed domain to the variables so that all constraints are\nsatisfied. In the optimization version, the goal is to maximize the number of\nsatisfied constraints. An approximation algorithm for CSP is called robust if\nit outputs an assignment satisfying a $(1-g(\\varepsilon))$-fraction of\nconstraints on any $(1-\\varepsilon)$-satisfiable instance, where the loss\nfunction $g$ is such that $g(\\varepsilon)\\rightarrow 0$ as\n$\\varepsilon\\rightarrow 0$.\n  We study how the robust approximability of CSPs depends on the set of\nconstraint relations allowed in instances, the so-called constraint language.\nAll constraint languages admitting a robust polynomial-time algorithm (with\nsome $g$) have been characterised by Barto and Kozik, with the general bound on\nthe loss $g$ being doubly exponential, specifically\n$g(\\varepsilon)=O((\\log\\log(1/\\varepsilon))/\\log(1/\\varepsilon))$. It is\nnatural to ask when a better loss can be achieved: in particular, polynomial\nloss $g(\\varepsilon)=O(\\varepsilon^{1/k})$ for some constant $k$. In this\npaper, we consider CSPs with a constraint language having a near-unanimity\npolymorphism. We give two randomized robust algorithms with polynomial loss for\nsuch CSPs: one works for any near-unanimity polymorphism and the parameter $k$\nin the loss depends on the size of the domain and the arity of the relations in\n$\\Gamma$, while the other works for a special ternary near-unanimity operation\ncalled dual discriminator with $k=2$ for any domain size. In the latter case,\nthe CSP is a common generalisation of Unique Games with a fixed domain and\n2-SAT. In the former case, we use the algebraic approach to the CSP. Both cases\nuse the standard semidefinite programming relaxation for CSP.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 18:52:51 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 09:52:26 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 12:44:41 GMT"}, {"version": "v4", "created": "Tue, 4 Dec 2018 10:43:40 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Dalmau", "V\u00edctor", ""], ["Kozik", "Marcin", ""], ["Krokhin", "Andrei", ""], ["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""], ["Opr\u0161al", "Jakub", ""]]}, {"id": "1607.04822", "submitter": "Shumo Chu", "authors": "Shumo Chu, Konstantin Weitz, Alvin Cheung, Dan Suciu", "title": "HoTTSQL: Proving Query Rewrites with Univalent SQL Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every database system contains a query optimizer that performs query\nrewrites. Unfortunately, developing query optimizers remains a highly\nchallenging task. Part of the challenges comes from the intricacies and rich\nfeatures of query languages, which makes reasoning about rewrite rules\ndifficult. In this paper, we propose a machine-checkable denotational semantics\nfor SQL, the de facto language for relational database, for rigorously\nvalidating rewrite rules. Unlike previously proposed semantics that are either\nnon-mechanized or only cover a small amount of SQL language features, our\nsemantics covers all major features of SQL, including bags, correlated\nsubqueries, aggregation, and indexes. Our mechanized semantics, called HoTTSQL,\nis based on K-Relations and homotopy type theory, where we denote relations as\nmathematical functions from tuples to univalent types. We have implemented\nHoTTSQL in Coq, which takes only fewer than 300 lines of code and have proved a\nwide range of SQL rewrite rules, including those from database research\nliterature (e.g., magic set rewrites) and real-world query optimizers (e.g.,\nsubquery elimination). Several of these rewrite rules have never been\npreviously proven correct. In addition, while query equivalence is generally\nundecidable, we have implemented an automated decision procedure using HoTTSQL\nfor conjunctive queries: a well-studied decidable fragment of SQL that\nencompasses many real-world queries.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jul 2016 03:15:20 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 20:44:47 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Chu", "Shumo", ""], ["Weitz", "Konstantin", ""], ["Cheung", "Alvin", ""], ["Suciu", "Dan", ""]]}, {"id": "1607.04908", "submitter": "Maciej Bendkowski", "authors": "Maciej Bendkowski, Katarzyna Grygiel, Marek Zaionc", "title": "On the likelihood of normalisation in combinatory logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a quantitative basis-independent analysis of combinatory logic.\nUsing a general argument regarding plane binary trees with labelled leaves, we\ngeneralise the results of David et al. and Bendkowski et al. to all\nTuring-complete combinator bases proving, inter alia, that asymptotically\nalmost no combinator is strongly normalising nor typeable. We exploit the\nstructure of recently discovered normal-order reduction grammars showing that\nfor each positive $n$, the set of $\\mathbf{S} \\mathbf{K}$-combinators reducing\nin $n$ normal-order reduction steps has positive asymptotic density in the set\nof all combinators. Our approach is constructive, allowing us to systematically\nfind new asymptotically significant fractions of normalising combinators. We\nshow that the density of normalising combinators cannot be less than $34\\%$,\nimproving the previously best lower bound of approximately $3\\%$. Finally, we\npresent some super-computer experimental results, conjecturing that the density\nof normalising combinators is close to $85\\%$.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jul 2016 19:30:40 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Bendkowski", "Maciej", ""], ["Grygiel", "Katarzyna", ""], ["Zaionc", "Marek", ""]]}, {"id": "1607.04910", "submitter": "Shankara Narayanan Krishna", "authors": "Vrunda Dave, Shankara Narayanan Krishna, Ashutosh Trivedi", "title": "FO-definable transformations of infinite strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of regular and aperiodic transformations of finite strings has\nrecently received a lot of interest. These classes can be equivalently defined\nusing logic (Monadic second-order logic and first-order logic), two-way\nmachines (regular two-way and aperiodic two-way transducers), and one-way\nregister machines (regular streaming string and aperiodic streaming string\ntransducers). These classes are known to be closed under operations such as\nsequential composition and regular (star-free) choice; and problems such as\nfunctional equivalence and type checking, are decidable for these classes. On\nthe other hand, for infinite strings these results are only known for\n$\\omega$-regular transformations: Alur, Filiot, and Trivedi studied\ntransformations of infinite strings and introduced an extension of streaming\nstring transducers over $\\omega$-strings and showed that they capture monadic\nsecond-order definable transformations for infinite strings. In this paper we\nextend their work to recover connection for infinite strings among first-order\nlogic definable transformations, aperiodic two-way transducers, and aperiodic\nstreaming string transducers.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jul 2016 19:39:46 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Dave", "Vrunda", ""], ["Krishna", "Shankara Narayanan", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1607.05120", "submitter": "Federico Aschieri", "authors": "Federico Aschieri, Agata Ciabattoni and Francesco A. Genco", "title": "G\\\"odel Logic: from Natural Deduction to Parallel Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional G\\\"odel logic extends intuitionistic logic with the\nnon-constructive principle of linearity $A\\rightarrow B\\ \\lor\\ B\\rightarrow A$.\nWe introduce a Curry-Howard correspondence for this logic and show that a\nparticularly simple natural deduction calculus can be used as a typing system.\nThe resulting functional language enriches the simply typed lambda calculus\nwith a synchronous communication mechanism between parallel processes. Our\nnormalization proof employs original termination arguments and sophisticated\nproof transformations with a meaningful computational reading. Our results\nprovide a computational interpretation of G\\\"odel logic as a logic of\ncommunicating parallel processes, thus proving Avron's 1991 conjecture.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 15:08:59 GMT"}, {"version": "v2", "created": "Sat, 24 Dec 2016 15:46:51 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 13:13:58 GMT"}, {"version": "v4", "created": "Sun, 18 Jun 2017 18:48:25 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Aschieri", "Federico", ""], ["Ciabattoni", "Agata", ""], ["Genco", "Francesco A.", ""]]}, {"id": "1607.05671", "submitter": "Shankara Narayanan Krishna", "authors": "S Akshay, Patricia Bouyer, Shankara Narayanan Krishna, Lakshmi Manasa,\n  Ashutosh Trivedi", "title": "Stochastic Timed Games Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic timed games (STGs), introduced by Bouyer and Forejt, naturally\ngeneralize both continuous-time Markov chains and timed automata by providing a\npartition of the locations between those controlled by two players (Player Box\nand Player Diamond) with competing objectives and those governed by stochastic\nlaws. Depending on the number of players---$2$, $1$, or $0$---subclasses of\nstochastic timed games are often classified as $2\\frac{1}{2}$-player,\n$1\\frac{1}{2}$-player, and $\\frac{1}{2}$-player games where the $\\frac{1}{2}$\nsymbolizes the presence of the stochastic \"nature\" player. For STGs with\nreachability objectives it is known that $1\\frac{1}{2}$-player one-clock STGs\nare decidable for qualitative objectives, and that $2\\frac{1}{2}$-player\nthree-clock STGs are undecidable for quantitative reachability objectives. This\npaper further refines the gap in this decidability spectrum. We show that\nquantitative reachability objectives are already undecidable for $1\\frac{1}{2}$\nplayer four-clock STGs, and even under the time-bounded restriction for\n$2\\frac{1}{2}$-player five-clock STGs. We also obtain a class of\n$1\\frac{1}{2}$, $2\\frac{1}{2}$ player STGs for which the quantitative\nreachability problem is decidable.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 17:27:14 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Akshay", "S", ""], ["Bouyer", "Patricia", ""], ["Krishna", "Shankara Narayanan", ""], ["Manasa", "Lakshmi", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1607.05850", "submitter": "Wolfgang Dvo\\v{r}\\'ak", "authors": "Krishnendu Chatterjee, Wolfgang Dvo\\v{r}\\'ak, Monika Henzinger,\n  Veronika Loitzenbauer", "title": "Conditionally Optimal Algorithms for Generalized B\\\"uchi Games", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.MFCS.2016.25", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games on graphs provide the appropriate framework to study several central\nproblems in computer science, such as the verification and synthesis of\nreactive systems. One of the most basic objectives for games on graphs is the\nliveness (or B\\\"uchi) objective that given a target set of vertices requires\nthat some vertex in the target set is visited infinitely often. We study\ngeneralized B\\\"uchi objectives (i.e., conjunction of liveness objectives), and\nimplications between two generalized B\\\"uchi objectives (known as GR(1)\nobjectives), that arise in numerous applications in computer-aided\nverification. We present improved algorithms and conditional super-linear lower\nbounds based on widely believed assumptions about the complexity of (A1)\ncombinatorial Boolean matrix multiplication and (A2) CNF-SAT. We consider graph\ngames with $n$ vertices, $m$ edges, and generalized B\\\"uchi objectives with $k$\nconjunctions. First, we present an algorithm with running time $O(k \\cdot\nn^2)$, improving the previously known $O(k \\cdot n \\cdot m)$ and $O(k^2 \\cdot\nn^2)$ worst-case bounds. Our algorithm is optimal for dense graphs under (A1).\nSecond, we show that the basic algorithm for the problem is optimal for sparse\ngraphs when the target sets have constant size under (A2). Finally, we consider\nGR(1) objectives, with $k_1$ conjunctions in the antecedent and $k_2$\nconjunctions in the consequent, and present an $O(k_1 \\cdot k_2 \\cdot\nn^{2.5})$-time algorithm, improving the previously known $O(k_1 \\cdot k_2 \\cdot\nn \\cdot m)$-time algorithm for $m > n^{1.5}$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 07:57:57 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Loitzenbauer", "Veronika", ""]]}, {"id": "1607.05956", "submitter": "Thomas Geffroy", "authors": "Thomas Geffroy, J\\'er\\^ome Leroux and Gr\\'egoire Sutre", "title": "Occam's Razor Applied to the Petri Net Coverability Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification of safety properties for concurrent systems often reduces to\nthe coverability problem for Petri nets. This problem was shown to be\nExpSpace-complete forty years ago. Driven by the concurrency revolution, it has\nregained a lot of interest over the last decade. In this paper, we propose a\ngeneric and simple approach to solve this problem. Our method is inspired from\nthe recent approach of Blondin, Finkel, Haase and Haddad. Basically, we combine\nforward invariant generation techniques for Petri nets with backward\nreachability for well- structured transition systems. An experimental\nevaluation demonstrates the efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 09:54:55 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Geffroy", "Thomas", ""], ["Leroux", "J\u00e9r\u00f4me", ""], ["Sutre", "Gr\u00e9goire", ""]]}, {"id": "1607.06023", "submitter": "Michael Robinson", "authors": "Michael Robinson", "title": "Modeling wireless network routing using sheaves", "comments": "arXiv admin note: text overlap with arXiv:1311.1532, arXiv:1607.06022", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article explains how to construct a sheaf model for passing traffic\nthrough a wireless network with a single channel carrier sense multiple\naccess/collision detection (CSMA/CD) media access model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 14:44:29 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Robinson", "Michael", ""]]}, {"id": "1607.06945", "submitter": "Matthew England Dr", "authors": "E. Abraham, J. Abbott, B. Becker, A.M. Bigatti, M. Brain, B.\n  Buchberger, A. Cimatti, J.H. Davenport, M. England, P. Fontaine, S. Forrest,\n  A. Griggio, D. Kroening, W.M. Seiler and T. Sturm", "title": "Satisfiability Checking and Symbolic Computation", "comments": "3 page Extended Abstract to accompany an ISSAC 2016 poster. Poster\n  available at http://www.sc-square.org/SC2-AnnouncementPoster.pdf", "journal-ref": "ACM Communications in Computer Algebra, 50:4 (issue 198), pp.\n  145-147, ACM, 2016", "doi": "10.1145/3055282.3055285", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic Computation and Satisfiability Checking are viewed as individual\nresearch areas, but they share common interests in the development,\nimplementation and application of decision procedures for arithmetic theories.\nDespite these commonalities, the two communities are currently only weakly\nconnected. We introduce a new project SC-square to build a joint community in\nthis area, supported by a newly accepted EU (H2020-FETOPEN-CSA) project of the\nsame name. We aim to strengthen the connection between these communities by\ncreating common platforms, initiating interaction and exchange, identifying\ncommon challenges, and developing a common roadmap. This abstract and\naccompanying poster describes the motivation and aims for the project, and\nreports on the first activities.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jul 2016 14:52:23 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Abraham", "E.", ""], ["Abbott", "J.", ""], ["Becker", "B.", ""], ["Bigatti", "A. M.", ""], ["Brain", "M.", ""], ["Buchberger", "B.", ""], ["Cimatti", "A.", ""], ["Davenport", "J. H.", ""], ["England", "M.", ""], ["Fontaine", "P.", ""], ["Forrest", "S.", ""], ["Griggio", "A.", ""], ["Kroening", "D.", ""], ["Seiler", "W. M.", ""], ["Sturm", "T.", ""]]}, {"id": "1607.07183", "submitter": "Micah Beck", "authors": "Micah Beck", "title": "On the Hourglass Model", "comments": null, "journal-ref": "Commun ACM 62 7 (2019) 48-57", "doi": "10.1145/3274770", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hourglass model is a widely used as a means of describing the design of\nthe Internet, and can be found in the introduction of many modern textbooks. It\narguably also applies to the design of other successful spanning layers,\nnotably the Unix operating system kernel interface, meaning the primitive\nsystem calls and the interactions between user processes and the kernel. The\nimpressive success of the Internet has led to a wider interest in using the\nhourglass model in other layered systems, with the goal of achieving similar\nresults. However, application of the hourglass model has often led to\ncontroversy, perhaps in part because the language in which it has been\nexpressed has been informal, and arguments for its validity have not been\nprecise. Making a start on formalizing such an argument is the goal of this\npaper.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 09:07:12 GMT"}, {"version": "v2", "created": "Wed, 27 Jul 2016 03:26:02 GMT"}, {"version": "v3", "created": "Sun, 31 Jul 2016 23:56:47 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Beck", "Micah", ""]]}, {"id": "1607.07286", "submitter": "Kirstin Peters", "authors": "Manuel Adameit and Kirstin Peters and Uwe Nestmann", "title": "Session Types for Link Failures (Technical Report)", "comments": "This paper is an extended version of Adameit et al. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We strive to use session type technology to prove behavioural properties of\nfault-tolerant distributed algorithms. Session types are designed to abstractly\ncapture the structure of (even multi-party) communication protocols. The goal\nof session types is the analysis and verification of the protocols' behavioural\nproperties. One important such property is progress, i.e., the absence of\n(unintended) deadlock. Distributed algorithms often resemble (compositions of)\nmulti-party communication protocols. In contrast to protocols that are\ntypically studied with session types, they are often designed to cope with\nsystem failures. An essential behavioural property is (successful) termination,\ndespite failures, but it is often elaborate to prove for distributed\nalgorithms.\n  We extend multi-party session types (and multi-party session types with\nnested sessions) by optional blocks that cover a limited class of link and\ncrash failures. This allows us to automatically derive termination of\ndistributed algorithms that come within these limits. To illustrate our\napproach, we prove termination for an implementation of the *rotating\ncoordinator* Consensus algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 14:20:50 GMT"}, {"version": "v2", "created": "Sat, 22 Oct 2016 08:57:45 GMT"}, {"version": "v3", "created": "Thu, 4 May 2017 07:54:58 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Adameit", "Manuel", ""], ["Peters", "Kirstin", ""], ["Nestmann", "Uwe", ""]]}, {"id": "1607.07291", "submitter": "Arno Pauly", "authors": "Matthew de Brecht and Arno Pauly", "title": "Noetherian Quasi-Polish Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GN cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of suitable power spaces, compactness of $\\mathbf{X}$ can be\ncharacterized as the singleton $\\{X\\}$ being open in the space\n$\\mathcal{O}(\\mathbf{X})$ of open subsets of $\\mathbf{X}$. Equivalently, this\nmeans that universal quantification over a compact space preserves open\npredicates.\n  Using the language of represented spaces, one can make sense of notions such\nas a $\\Sigma^0_2$-subset of the space of $\\Sigma^0_2$-subsets of a given space.\nThis suggests higher-order analogues to compactness: We can, e.g.~, investigate\nthe spaces $\\mathbf{X}$ where $\\{X\\}$ is a $\\Delta^0_2$-subset of the space of\n$\\Delta^0_2$-subsets of $\\mathbf{X}$. Call this notion $\\nabla$-compactness. As\n$\\Delta^0_2$ is self-dual, we find that both universal and existential\nquantifier over $\\nabla$-compact spaces preserve $\\Delta^0_2$ predicates.\n  Recall that a space is called Noetherian iff every subset is compact. Within\nthe setting of Quasi-Polish spaces, we can fully characterize the\n$\\nabla$-compact spaces: A Quasi-Polish space is Noetherian iff it is\n$\\nabla$-compact. Note that the restriction to Quasi-Polish spaces is\nsufficiently general to include plenty of examples.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 14:28:18 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2017 15:37:58 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["de Brecht", "Matthew", ""], ["Pauly", "Arno", ""]]}, {"id": "1607.07698", "submitter": "Michael Mislove", "authors": "Michael W. Mislove", "title": "Domains and Random Variables", "comments": "This revision corrects the original, faulty proof of Corollary 3.5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to establish a theory of random variables on\ndomains. Domain theory is a fundamental component of theoretical computer\nscience, providing mathematical models of computational processes. Random\nvariables are the mainstay of probability theory. Since computational models\nincreasingly involve probabilistic aspects, it's only natural to explore the\nrelationship between these two areas. Our main results show how to cast results\nabout random variables using a domain-theoretic approach. The pay-off is an\nextension of the results from probability measures to sub-probability measures.\nWe also use our approach to extend the class of domains for which we can\nclassify the domain structure of the space of sub-probability measures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 22:09:29 GMT"}, {"version": "v2", "created": "Sat, 27 Aug 2016 17:37:07 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Mislove", "Michael W.", ""]]}, {"id": "1607.07720", "submitter": "J\\\"urgen Koslowski", "authors": "Roberto Vigo, Flemming Nielson, Hanne Riis Nielson (Technical\n  University of Denmark, Lyngby)", "title": "Discovering, quantifying, and displaying attacks", "comments": "LMCS SPECIAL ISSUE FORTE 2014", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2178", "doi": "10.2168/LMCS-12(4:5)2016", "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the design of software and cyber-physical systems, security is often\nperceived as a qualitative need, but can only be attained quantitatively.\nEspecially when distributed components are involved, it is hard to predict and\nconfront all possible attacks. A main challenge in the development of complex\nsystems is therefore to discover attacks, quantify them to comprehend their\nlikelihood, and communicate them to non-experts for facilitating the decision\nprocess. To address this three-sided challenge we propose a protection analysis\nover the Quality Calculus that (i) computes all the sets of data required by an\nattacker to reach a given location in a system, (ii) determines the cheapest\nset of such attacks for a given notion of cost, and (iii) derives an attack\ntree that displays the attacks graphically. The protection analysis is first\ndeveloped in a qualitative setting, and then extended to quantitative settings\nfollowing an approach applicable to a great many contexts. The quantitative\nformulation is implemented as an optimisation problem encoded into\nSatisfiability Modulo Theories, allowing us to deal with complex cost\nstructures. The usefulness of the framework is demonstrated on a national-scale\nauthentication system, studied through a Java implementation of the framework.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 14:29:02 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 08:56:08 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Vigo", "Roberto", "", "Technical\n  University of Denmark, Lyngby"], ["Nielson", "Flemming", "", "Technical\n  University of Denmark, Lyngby"], ["Nielson", "Hanne Riis", "", "Technical\n  University of Denmark, Lyngby"]]}, {"id": "1607.07828", "submitter": "Lutz Schr\\\"oder", "authors": "Stefan Milius and Lutz Schr\\\"oder and Thorsten Wi{\\ss}mann", "title": "Regular Behaviours with Names", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nominal sets provide a framework to study key notions of syntax and semantics\nsuch as fresh names, variable binding and $\\alpha$-equivalence on a\nconveniently abstract categorical level. Coalgebras for endofunctors on nominal\nsets model, e.g., various forms of automata with names as well as infinite\nterms with variable binding operators (such as $\\lambda$-abstraction). Here, we\nfirst study the behaviour of orbit-finite coalgebras for functors $\\bar F$ on\nnominal sets that lift some finitary set functor $F$. We provide sufficient\nconditions under which the rational fixpoint of $\\bar F$, i.e. the collection\nof all behaviours of orbit-finite $\\bar F$-coalgebras, is the lifting of the\nrational fixpoint of $F$. Second, we describe the rational fixpoint of the\nquotient functors: we introduce the notion of a sub-strength of an endofunctor\non nominal sets, and we prove that for a functor $G$ with a sub-strength the\nrational fixpoint of each quotient of $G$ is a canonical quotient of the\nrational fixpoint of $G$. As applications, we obtain a concrete description of\nthe rational fixpoint for functors arising from so-called binding signatures\nwith exponentiation, such as those arising in coalgebraic models of infinitary\n$\\lambda$-terms and various flavours of automata.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 18:22:32 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Milius", "Stefan", ""], ["Schr\u00f6der", "Lutz", ""], ["Wi\u00dfmann", "Thorsten", ""]]}, {"id": "1607.08028", "submitter": "Matthew England Dr", "authors": "E. Abraham, J. Abbott, B. Becker, A.M. Bigatti, M. Brain, B.\n  Buchberger, A. Cimatti, J.H. Davenport, M. England, P. Fontaine, S. Forrest,\n  A. Griggio, D. Kroening, W.M. Seiler, T. Sturm", "title": "Satisfiability Checking meets Symbolic Computation (Project Paper)", "comments": null, "journal-ref": "M. Kohlhase, M. Johansson, B. Miller, L. de Moura, F. Tompa, eds.,\n  Intelligent Computer Mathematics (Proceedings of CICM 2016), pp. 28-43,\n  (Lecture Notes in Computer Science, 9791). Springer International Publishing,\n  2016", "doi": "10.1007/978-3-319-42547-4_3", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic Computation and Satisfiability Checking are two research areas, both\nhaving their individual scientific focus but sharing also common interests in\nthe development, implementation and application of decision procedures for\narithmetic theories. Despite their commonalities, the two communities are\nrather weakly connected. The aim of our newly accepted SC-square project\n(H2020-FETOPEN-CSA) is to strengthen the connection between these communities\nby creating common platforms, initiating interaction and exchange, identifying\ncommon challenges, and developing a common roadmap from theory along the way to\ntools and (industrial) applications. In this paper we report on the aims and on\nthe first activities of this project, and formalise some relevant challenges\nfor the unified SC-square community.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 10:38:53 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Abraham", "E.", ""], ["Abbott", "J.", ""], ["Becker", "B.", ""], ["Bigatti", "A. M.", ""], ["Brain", "M.", ""], ["Buchberger", "B.", ""], ["Cimatti", "A.", ""], ["Davenport", "J. H.", ""], ["England", "M.", ""], ["Fontaine", "P.", ""], ["Forrest", "S.", ""], ["Griggio", "A.", ""], ["Kroening", "D.", ""], ["Seiler", "W. M.", ""], ["Sturm", "T.", ""]]}, {"id": "1607.08067", "submitter": "Oleg Verbitsky", "authors": "Oleg Verbitsky and Maksim Zhukovskii", "title": "The Descriptive Complexity of Subgraph Isomorphism without Numerics", "comments": "20 pages, 2 figures, 1 table. Sections 6 and 7.1 are new. The result\n  of Section 6 in the preceding version is removed and will appear in an\n  accompanying paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $F$ be a connected graph with $\\ell$ vertices. The existence of a\nsubgraph isomorphic to $F$ can be defined in first-order logic with quantifier\ndepth no better than $\\ell$, simply because no first-order formula of smaller\nquantifier depth can distinguish between the complete graphs $K_\\ell$ and\n$K_{\\ell-1}$. We show that, for some $F$, the existence of an $F$ subgraph in\n\\emph{sufficiently large} connected graphs is definable with quantifier depth\n$\\ell-3$. On the other hand, this is never possible with quantifier depth\nbetter than $\\ell/2$. If we, however, consider definitions over connected\ngraphs with sufficiently large treewidth, the quantifier depth can for some $F$\nbe arbitrarily small comparing to $\\ell$ but never smaller than the treewidth\nof $F$. Moreover, the definitions over highly connected graphs require\nquantifier depth strictly more than the density of $F$. Finally, we determine\nthe exact values of these descriptive complexity parameters for all connected\npattern graphs $F$ on 4 vertices.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 12:53:57 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 10:25:17 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 15:08:30 GMT"}, {"version": "v4", "created": "Mon, 11 Sep 2017 09:03:01 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Verbitsky", "Oleg", ""], ["Zhukovskii", "Maksim", ""]]}, {"id": "1607.08363", "submitter": "J\\\"urgen Koslowski", "authors": "Davide Basile, Pierpaolo Degano, Gian-Luigi Ferrari (Universit\\`a di\n  Pisa, Italy)", "title": "Automata for Specifying and Orchestrating Service Contracts", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2618", "doi": "10.2168/LMCS-12(4:6)2016", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to the formal description of service contracts is presented in\nterms of automata. We focus on the basic property of guaranteeing that in the\nmulti-party composition of principals each of them gets his requests satisfied,\nso that the overall composition reaches its goal. Depending on whether requests\nare satisfied synchronously or asynchronously, we construct an orchestrator\nthat at static time either yields composed services enjoying the required\nproperties or detects the principals responsible for possible violations. To do\nthat in the asynchronous case we resort to Linear Programming techniques. We\nalso relate our automata with two logically based methods for specifying\ncontracts.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2016 08:56:12 GMT"}, {"version": "v2", "created": "Sun, 23 Oct 2016 17:45:41 GMT"}, {"version": "v3", "created": "Fri, 23 Dec 2016 09:25:45 GMT"}, {"version": "v4", "created": "Tue, 27 Dec 2016 20:48:29 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Basile", "Davide", "", "Universit\u00e0 di\n  Pisa, Italy"], ["Degano", "Pierpaolo", "", "Universit\u00e0 di\n  Pisa, Italy"], ["Ferrari", "Gian-Luigi", "", "Universit\u00e0 di\n  Pisa, Italy"]]}, {"id": "1607.08480", "submitter": "Ashutosh Trivedi", "authors": "Shibashis Guha and Marcin Jurdzinski and Krishna S. and Ashutosh\n  Trivedi", "title": "Mean-Payoff Games on Timed Automata", "comments": "29 pages, unpublished manuscript, submitted to FSTTCS", "journal-ref": null, "doi": "10.4230/LIPIcs.FSTTCS.2016.44", "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean-payoff games on timed automata are played on the infinite weighted graph\nof configurations of priced timed automata between two players, Player Min and\nPlayer Max, by moving a token along the states of the graph to form an infinite\nrun. The goal of Player Min is to minimize the limit average weight of the run,\nwhile the goal of the Player Max is the opposite. Brenguier, Cassez, and Raskin\nrecently studied a variation of these games and showed that mean-payoff games\nare undecidable for timed automata with five or more clocks. We refine this\nresult by proving the undecidability of mean-payoff games with three clocks. On\na positive side, we show the decidability of mean-payoff games on one-clock\ntimed automata with binary price-rates. A key contribution of this paper is the\napplication of dynamic programming based proof techniques applied in the\ncontext of average reward optimization on an uncountable state and action\nspace.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2016 14:36:30 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Guha", "Shibashis", ""], ["Jurdzinski", "Marcin", ""], ["S.", "Krishna", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1607.08484", "submitter": "Vahid Hashemi", "authors": "Vahid Hashemi, Holger Hermanns, Andrea Turrini", "title": "Compositional Reasoning for Interval Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking probabilistic CTL properties of Markov decision processes with\nconvex uncertainties has been recently investigated by Puggelli et al. Such\nmodel checking algorithms typically suffer from the state space explosion. In\nthis paper, we address probabilistic bisimulation to reduce the size of such an\nMDP while preserving the probabilistic CTL properties it satisfies. In\nparticular, we discuss the key ingredients to build up the operations of\nparallel composition for composing interval MDP components at run-time. More\nprecisely, we investigate how the parallel composition operator for interval\nMDPs can be defined so as to arrive at a congruence closure. As a result, we\nshow that probabilistic bisimulation for interval MDPs is congruence with\nrespect to two facets of parallelism, namely synchronous product and\ninterleaving.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2016 14:47:23 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Hashemi", "Vahid", ""], ["Hermanns", "Holger", ""], ["Turrini", "Andrea", ""]]}]