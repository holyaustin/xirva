[{"id": "1711.00770", "submitter": "Marjan Cugmas", "authors": "Marjan Cugmas, Anu\\v{s}ka Ferligoj, Luka Kronegger", "title": "Scientific co-authorship networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the stability of the co-authorship networks in time. The\nanalysis is done on the networks of Slovenian researchers in two time periods\n(1991-2000 and 2001-2010). Two researchers are linked if they published at\nleast one scientific bibliographic unit in a given time period. As proposed by\nKronegger et al. (2011), the global network structures are examined by\ngeneralized blockmodeling with the assumed\nmulti-core--semi-periphery--periphery blockmodel type. The term core denotes a\ngroup of researchers who published together in a systematic way with each\nother.\n  The obtained blockmodels are comprehensively analyzed by visualizations and\nthrough considering several statistics regarding the global network structure.\nTo measure the stability of the obtained blockmodels, different adjusted\nmodified Rand and Wallace indices are applied. Those enable to distinguish\nbetween the splitting and merging of cores when operationalizing the stability\nof cores. Also, the adjusted modified indices can be used when new researchers\noccur in the second time period (newcomers) and when some researchers are no\nlonger present in the second time period (departures). The research disciplines\nare described and clustered according to the values of these indices.\nConsidering the obtained clusters, the sources of instability of the research\ndisciplines are studied (e.g., merging or splitting of cores, newcomers or\ndepartures). Furthermore, the differences in the stability of the obtained\ncores on the level of scientific disciplines are studied by linear regression\nanalysis where some personal characteristics of the researchers (e.g., age,\ngender), are also considered.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:54:20 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Cugmas", "Marjan", ""], ["Ferligoj", "Anu\u0161ka", ""], ["Kronegger", "Luka", ""]]}, {"id": "1711.01406", "submitter": "Zheng Xie", "authors": "Zheng Xie", "title": "Assessing the level of merging errors for coauthorship data: a Bayesian\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust analysis of coauthorship networks is based on high quality data.\nHowever, ground-truth data are usually unavailable. Empirical data suffer\nseveral types of errors, a typical one of which is called merging error,\nidentifying different persons as one entity. Specific features of authors have\nbeen used to reduce these errors. We proposed a Bayesian model to calculate the\ninformation of any given features of authors. Based on the features, the model\ncan be utilized to calculate the rate of merging errors for entities.\nTherefore, the model helps to find informative features for detecting heavily\ncompromised entities. It has potential contributions to improving the quality\nof empirical data.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 06:58:26 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 18:44:01 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Xie", "Zheng", ""]]}, {"id": "1711.01927", "submitter": "Robert B. Allen", "authors": "Robert B. Allen, Eunsang Yang, and Tatsawan Timakum", "title": "A Foundry of Human Activities and Infrastructures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct representation knowledgebases can enhance and even provide an\nalternative to document-centered digital libraries. Here we consider realist\nsemantic modeling of everyday activities and infrastructures in such\nknowledgebases. Because we want to integrate a wide variety of topics, a\ncollection of ontologies (a foundry) and a range of other knowledge resources\nare needed. We first consider modeling the routine procedures that support\nhuman activities and technologies. Next, we examine the interactions of\ntechnologies with aspects of social organization. Then, we consider approaches\nand issues for developing and validating explanations of the relationships\namong various entities.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 10:14:45 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Allen", "Robert B.", ""], ["Yang", "Eunsang", ""], ["Timakum", "Tatsawan", ""]]}, {"id": "1711.02059", "submitter": "Serhii Nazarovets", "authors": "Vladimir Lazarev, Serhii Nazarovets and Alexey Skalaban", "title": "Evaluation of research activities of universities of Ukraine and\n  Belarus: a set of bibliometric indicators and its implementation", "comments": null, "journal-ref": "Romanian Journal of Library and Information Science. 2017, 13(3):\n  75-84", "doi": "10.26660/rrbsi.2017.13.3.75", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monitoring bibliometric indicators of University rankings is considered as a\nsubject of a University library activity. In order to fulfill comparative\nassessment of research activities of the universities of Ukraine and Belarus\nthe authors introduced a set of bibliometric indicators. A comparative\nassessment of the research activities of corresponding universities was\nfulfilled; the data on the leading universities are presented. The sensitivity\nof the one of the indicators to rapid changes of the research activity of\nuniversities and the fact that the other one is normalized across the fields of\nscience condition advantage of the proposed set over the one that was used in\npractice of the corresponding national rankings.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 18:05:40 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Lazarev", "Vladimir", ""], ["Nazarovets", "Serhii", ""], ["Skalaban", "Alexey", ""]]}, {"id": "1711.02695", "submitter": "Antonin Mac\\'e", "authors": "Antonin Mac\\'e", "title": "Measuring Influence in Science: Standing on the Shoulders of Which\n  Giants?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I study the measurement of the influence of scientists based on bibliographic\ndata. I propose a new measure that accounts for indirect influence and allows\nto compare scientists across different fields of science. By contrast, common\nmeasures of influence that \"count citations\", such as the h-index, are unable\nto satisfy either of these two properties. I use the axiomatic method in two\nopposite ways: to highlight the two limitations of citation-counting schemes\nand their independence, and to carefully justify the assumptions made in the\nconstruction of the proposed measure.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 19:22:02 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Mac\u00e9", "Antonin", ""]]}, {"id": "1711.03537", "submitter": "Janneth Chicaiza", "authors": "Nelson Piedra, Janneth Chicaiza, Jorge Lopez-Vargas, Edmundo Tovar", "title": "Discovery of potential collaboration networks from open knowledge\n  sources", "comments": "2 pages, International Conference on Knowledge Engineering and\n  Semantic Web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Scientific publishing conveys the outputs of an academic or research\nactivity, in this sense; it also reflects the efforts and issues in which\npeople engage. To identify potential collaborative networks one of the simplest\napproaches is to leverage the co-authorship relations. In this approach,\nsemantic and hierarchic relationships defined by a Knowledge Organization\nSystem are used in order to improve the system's ability to recommend potential\nnetworks beyond the lexical or syntactic analysis of the topics or concepts\nthat are of interest to academics.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 20:58:16 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Piedra", "Nelson", ""], ["Chicaiza", "Janneth", ""], ["Lopez-Vargas", "Jorge", ""], ["Tovar", "Edmundo", ""]]}, {"id": "1711.04452", "submitter": "Georgina Nugent Folan", "authors": "Jennifer Edmond, Georgina Nugent Folan", "title": "Digitising Cultural Complexity: Representing Rich Cultural Data in a Big\n  Data environment", "comments": "Ways of Being in a Digital Age - A Review Conference, Oct 2017,\n  Liverpool, United Kingdom. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DB cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major terminological forces driving ICT integration in research\ntoday is that of \"big data.\" While the phrase sounds inclusive and integrative,\n\"big data\" approaches are highly selective, excluding input that cannot be\neffectively structured, represented, or digitised. Data of this complex sort is\nprecisely the kind that human activity produces, but the technological\nimperative to enhance signal through the reduction of noise does not\naccommodate this richness. Data and the computational approaches that\nfacilitate \"big data\" have acquired a perceived objectivity that belies their\ncurated, malleable, reactive, and performative nature. In an input environment\nwhere anything can \"be data\" once it is entered into the system as \"data,\" data\ncleaning and processing, together with the metadata and information\narchitectures that structure and facilitate our cultural archives acquire a\ncapacity to delimit what data are. This engenders a process of simplification\nthat has major implications for the potential for future innovation within\nresearch environments that depend on rich material yet are increasingly\nmediated by digital technologies. This paper presents the preliminary findings\nof the European-funded KPLEX (Knowledge Complexity) project which investigates\nthe delimiting effect digital mediation and datafication has on rich, complex\ncultural data. The paper presents a systematic review of existing implicit\ndefinitions of data, elaborating on the implications of these definitions and\nhighlighting the ways in which metadata and computational technologies can\nrestrict the interpretative potential of data. It sheds light on the gap\nbetween analogue or augmented digital practices and fully computational ones,\nand the strategies researchers have developed to deal with this gap. The paper\nproposes a reconceptualisation of data as it is functionally employed within\ndigitally-mediated research so as to incorporate and acknowledge the richness\nand complexity of our source materials.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 07:31:24 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Edmond", "Jennifer", ""], ["Folan", "Georgina Nugent", ""]]}, {"id": "1711.04548", "submitter": "Sahar Vahdati", "authors": "Andreas Behrend, Sahar Vahdati, Christoph Lange, Christiane Engels", "title": "Towards a Cloud-Based Service for Maintaining and Analyzing Data About\n  Scientific Events", "comments": "A completed version of this paper had been accepted in SAVE-SD\n  workshop 2017 at WWW conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the new cloud-based service OpenResearch for managing and\nanalyzing data about scientific events such as conferences and workshops in a\npersistent and reliable way. This includes data about scientific articles,\nparticipants, acceptance rates, submission numbers, impact values as well as\norganizational details such as program committees, chairs, fees and sponsors.\nOpenResearch is a centralized repository for scientific events and supports\nresearchers in collecting, organizing, sharing and disseminating information\nabout scientific events in a structured way. An additional feature currently\nunder development is the possibility to archive web pages along with the\nextracted semantic data in order to lift the burden of maintaining new and old\nconference web sites from public research institutions. However, the main\nadvantage is that this cloud-based repository enables a comprehensive analysis\nof conference data. Based on extracted semantic data, it is possible to\ndetermine quality estimations, scientific communities, research trends as well\nthe development of acceptance rates, fees, and number of participants in a\ncontinuous way complemented by projections into the future. Furthermore, data\nabout research articles can be systematically explored using a content-based\nanalysis as well as citation linkage. All data maintained in this\ncrowd-sourcing platform is made freely available through an open SPARQL\nendpoint, which allows for analytical queries in a flexible and user-defined\nway.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 12:15:53 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 16:14:00 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Behrend", "Andreas", ""], ["Vahdati", "Sahar", ""], ["Lange", "Christoph", ""], ["Engels", "Christiane", ""]]}, {"id": "1711.05098", "submitter": "Athanasios Lagopoulos", "authors": "Athanasios Lagopoulos, Grigorios Tsoumakas, Georgios Papadopoulos", "title": "Web Robot Detection in Academic Publishing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent industry reports assure the rise of web robots which comprise more\nthan half of the total web traffic. They not only threaten the security,\nprivacy and efficiency of the web but they also distort analytics and metrics,\ndoubting the veracity of the information being promoted. In the academic\npublishing domain, this can cause articles to be faulty presented as prominent\nand influential. In this paper, we present our approach on detecting web robots\nin academic publishing websites. We use different supervised learning\nalgorithms with a variety of characteristics deriving from both the log files\nof the server and the content served by the website. Our approach relies on the\nassumption that human users will be interested in specific domains or articles,\nwhile web robots crawl a web library incoherently. We experiment with features\nadopted in previous studies with the addition of novel semantic characteristics\nwhich derive after performing a semantic analysis using the Latent Dirichlet\nAllocation (LDA) algorithm. Our real-world case study shows promising results,\npinpointing the significance of semantic features in the web robot detection\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 14:20:56 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Lagopoulos", "Athanasios", ""], ["Tsoumakas", "Grigorios", ""], ["Papadopoulos", "Georgios", ""]]}, {"id": "1711.05251", "submitter": "Serhii Nazarovets", "authors": "Serhii Nazarovets", "title": "War and Peace: The Peculiarities of Ukrainian-Russian Scientific\n  Cooperation Dynamics Against the Background of Russian Military Aggression in\n  Ukraine, in 2014-2016", "comments": null, "journal-ref": "Nauka innov. 2017, 13(5):38-43", "doi": "10.15407/scin13.05.038", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper presents the results of bibliometric analysis of publications that\nwere co-written by authors affiliated with Ukrainian and Russian institutions\nin 2007-2016 according to Scopus. Results of the study show that Ukrainian and\nRussian scientists have not refused to carry out joint research in major\ninternational projects, but a decrease in the number of works, written by\nUkrainian and Russian scientific institutions staff members in 2016, provides\nevidence on the threat and negative impact the Russian military intervention\nbrings to cooperation in science. The findings are important for generating the\nscience development programs in Ukraine.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 18:51:46 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Nazarovets", "Serhii", ""]]}, {"id": "1711.05822", "submitter": "Jiangen He", "authors": "Jiangen He and Chaomei Chen", "title": "Understanding the Changing Roles of Scientific Publications via Citation\n  Embeddings", "comments": "CLBib-2017: Second Workshop on Mining Scientific Papers:\n  Computational Linguistics and Bibliometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers may describe different aspects of past scientific publications in\ntheir publications and the descriptions may keep changing in the evolution of\nscience. The diverse and changing descriptions (i.e., citation context) on a\npublication characterize the impact and contributions of the past publication.\nIn this article, we aim to provide an approach to understanding the changing\nand complex roles of a publication characterized by its citation context. We\ndescribed a method to represent the publications' dynamic roles in science\ncommunity in different periods as a sequence of vectors by training temporal\nembedding models. The temporal representations can be used to quantify how much\nthe roles of publications changed and interpret how they changed. Our study in\nthe biomedical domain shows that our metric on the changes of publications'\nroles is stable over time at the population level but significantly distinguish\nindividuals. We also show the interpretability of our methods by a concrete\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:00:43 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["He", "Jiangen", ""], ["Chen", "Chaomei", ""]]}, {"id": "1711.07291", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann and Robin Haunschild", "title": "Do altmetrics correlate with the quality of papers? A large-scale\n  empirical study based on F1000Prime data", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0197133", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we address the question whether (and to what extent,\nrespectively) altmetrics are related to the scientific quality of papers (as\nmeasured by peer assessments). Only a few studies have previously investigated\nthe relationship between altmetrics and assessments by peers. In the first\nstep, we analyse the underlying dimensions of measurement for traditional\nmetrics (citation counts) and altmetrics - by using principal component\nanalysis (PCA) and factor analysis (FA). In the second step, we test the\nrelationship between the dimensions and quality of papers (as measured by the\npost-publication peer-review system of F1000Prime assessments) - using\nregression analysis. The results of the PCA and FA show that altmetrics operate\nalong different dimensions, whereas Mendeley counts are related to citation\ncounts, and tweets form a separate dimension. The results of the regression\nanalysis indicate that citation-based metrics and readership counts are\nsignificantly more related to quality, than tweets. This result on the one hand\nquestions the use of Twitter counts for research evaluation purposes and on the\nother hand indicates potential use of Mendeley reader counts.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 12:56:35 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 08:37:36 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 13:25:43 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2018 12:43:05 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""]]}, {"id": "1711.08387", "submitter": "Loet Leydesdorff", "authors": "Iina Hellsten and Loet Leydesdorff", "title": "Automated Analysis of Topic-Actor Networks on Twitter: New approach to\n  the analysis of socio-semantic networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social-media data provides increasing opportunities for automated analysis of\nlarge sets of textual documents. So far, automated tools have been developed to\naccount for either the social networks between the participants of the debates,\nor to analyze the content of those debates. Less attention has been paid to\nmapping co-occurring actors (participants) and topics (content) in online\ndebates that form socio-semantic networks. We propose a new, automated approach\nthat uses a whole matrix approach of co-addressed topics and the actors. We\nshow the advantages of the new approach with the analysis of a large set of\nEnglish-language Twitter messages at the Rio+20 meeting, in June 2012 (72,077\ntweets), and a smaller data set of Dutch-language Twitter messages on bird flu\nrelated to poultry farming in 2015-2017 (2,139 tweets). We discuss the\ntheoretical, methodological and substantive implications of our approach, also\nfor the analysis of other social-media data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 16:53:52 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Hellsten", "Iina", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1711.08587", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Ruth Fairclough", "title": "The Research Production of Nations and Departments: A Statistical Model\n  for the Share of Publications", "comments": null, "journal-ref": "Thelwall, M. & Fairclough, R. (2017). The research production of\n  nations and departments: A statistical model for the share of publications.\n  Journal of Informetrics, 11(4), 1142-1157", "doi": "10.1016/j.joi.2017.10.001", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy makers and managers sometimes assess the share of research produced by\na group (country, department, institution). This takes the form of the\npercentage of publications in a journal, field or broad area that has been\npublished by the group. This quantity is affected by essentially random\ninfluences that obscure underlying changes over time and differences between\ngroups. A model of research production is needed to help identify whether\ndifferences between two shares indicate underlying differences. This article\nintroduces a simple production model for indicators that report the share of\nthe world's output in a journal or subject category, assuming that every new\narticle has the same probability to be authored by a given group. With this\nassumption, confidence limits can be calculated for the underlying production\ncapability (i.e., probability to publish). The results of a time series\nanalysis of national contributions to 36 large monodisciplinary journals\n1996-2016 are broadly consistent with this hypothesis. Follow up tests of\ncountries and institutions in 26 Scopus subject categories support the\nconclusions but highlight the importance of ensuring consistent subject\ncategory coverage.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 06:35:55 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Thelwall", "Mike", ""], ["Fairclough", "Ruth", ""]]}, {"id": "1711.08767", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall", "title": "Microsoft Academic: A multidisciplinary comparison of citation counts\n  with Scopus and Mendeley for 29 journals", "comments": null, "journal-ref": "Thelwall, M. (2017). Microsoft Academic: A multidisciplinary\n  comparison of citation counts with Scopus and Mendeley for 29 journals.\n  Journal of Informetrics, 11(4), 1201-1212", "doi": "10.1016/j.joi.2017.10.006", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microsoft Academic is a free citation index that allows large scale data\ncollection. This combination makes it useful for scientometric research.\nPrevious studies have found that its citation counts tend to be slightly larger\nthan those of Scopus but smaller than Google Scholar, with disciplinary\nvariations. This study reports the largest and most systematic analysis so far,\nof 172,752 articles in 29 large journals chosen from different specialisms.\nFrom Scopus citation counts, Microsoft Academic citation counts and Mendeley\nreader counts for articles published 2007-2017, Microsoft Academic found a\nslightly more (6%) citations than Scopus overall and especially for the current\nyear (51%). It found fewer citations than Mendeley readers overall (59%), and\nonly 7% as many for the current year. Differences between journals were\nprobably due to field preprint sharing cultures or journal policies rather than\nbroad disciplinary differences.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 16:42:21 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Thelwall", "Mike", ""]]}, {"id": "1711.08769", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall", "title": "Microsoft Academic Automatic Document Searches: Accuracy for Journal\n  Articles and Suitability for Citation Analysis", "comments": null, "journal-ref": "Thelwall, M. (2018). Microsoft Academic automatic document\n  searches: accuracy for journal articles and suitability for citation\n  analysis. Journal of Informetrics, 12(1), 1-9", "doi": "10.1016/j.joi.2017.11.001", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microsoft Academic is a free academic search engine and citation index that\nis similar to Google Scholar but can be automatically queried. Its data is\npotentially useful for bibliometric analysis if it is possible to search\neffectively for individual journal articles. This article compares different\nmethods to find journal articles in its index by searching for a combination of\ntitle, authors, publication year and journal name and uses the results for the\nwidest published correlation analysis of Microsoft Academic citation counts for\njournal articles so far. Based on 126,312 articles from 323 Scopus subfields in\n2012, the optimal strategy to find articles with DOIs is to search for them by\ntitle and filter out those with incorrect DOIs. This finds 90% of journal\narticles. For articles without DOIs, the optimal strategy is to search for them\nby title and then filter out matches with dissimilar metadata. This finds 89%\nof journal articles, with an additional 1% incorrect matches. The remaining\narticles seem to be mainly not indexed by Microsoft Academic or indexed with a\ndifferent language version of their title. From the matches, Scopus citation\ncounts and Microsoft Academic counts have an average Spearman correlation of\n0.95, with the lowest for any single field being 0.63. Thus, Microsoft Academic\ncitation counts are almost universally equivalent to Scopus citation counts for\narticles that are not recent but there are national biases in the results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 16:44:32 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Thelwall", "Mike", ""]]}, {"id": "1711.10172", "submitter": "J\\'anos Tapolcai", "authors": "J\\'anos Tapolcai", "title": "Digital Encyclopedia of Scientific Results", "comments": "5 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study describes a vision, how technology can help improving the\nefficiency in research. We propose a new clean-slate design, where more\nemphasis is given on the correctness and up-to-dateness of the scientific\nresults, it is more open to new ideas and better utilize the research efforts\nworldwide by providing personalized interface for every researcher. The key\nidea is to reveal the structure and connections of the problems solved in the\nscientific studies. We will build the system with the main focus on the solved\nproblems itself, and treat the studies only as one presentation form. By\nutilizing artificial intelligence and machine learning on the network of the\nsolved problems we could coordinate individual research activities in a large\nscale, that has never been seen before.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 08:22:07 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Tapolcai", "J\u00e1nos", ""]]}, {"id": "1711.11168", "submitter": "David Guillermo Fajardo Ortiz Dr.", "authors": "David Fajardo-Ortiz, Pablo Jaramillo, Claudia Jaramillo, Raul\n  Resendiz, Miguel Lara-Flores, Victor M. Castano", "title": "Emerging basic, clinical and translational research fronts in dental\n  biomaterials R&D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current (2007-2007) structure and content of dental materials research\nhas been investigated by identifying and describing the emergent research\nfronts which can be related to basic, translational and clinical observation\nresearch. By a combination of network analysis and text mining of the\nliterature on dental materials indexed in the Web of Science, we have\nidentified eleven emerging research fronts. These fronts are related to\ndifferent dental materials applications which are at different levels in the\nknowledge translation and biomedical innovation process. We identified fronts\nrelated to dominant designs like titanium implants, competing technologies like\nceramics and composites applications to prothesis and restauration, and\ndisruptive technologies like nanomaterials and mineral trioxide aggregates. Our\nresults suggest the possible relation between the technological complexity of\nthe dental materials and the level of advance in terms of knowledge\ntranslation. This is the first time the structure and content of research on\ndental materials research is analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 00:30:24 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Fajardo-Ortiz", "David", ""], ["Jaramillo", "Pablo", ""], ["Jaramillo", "Claudia", ""], ["Resendiz", "Raul", ""], ["Lara-Flores", "Miguel", ""], ["Castano", "Victor M.", ""]]}]