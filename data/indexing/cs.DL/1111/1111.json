[{"id": "1111.0735", "submitter": "Andrew Jackson", "authors": "Andrew N. Jackson", "title": "Using Automated Dependency Analysis To Generate Representation\n  Information", "comments": "4 pages, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  To preserve access to digital content, we must preserve the representation\ninformation that captures the intended interpretation of the data. In\nparticular, we must be able to capture performance dependency requirements,\ni.e. to identify the other resources that are required in order for the\nintended interpretation to be constructed successfully. Critically, we must\nidentify the digital objects that are only referenced in the source data, but\nare embedded in the performance, such as fonts. This paper describes a new\ntechnique for analysing the dynamic dependencies of digital media, focussing on\nanalysing the process that underlies the performance, rather than parsing and\ndeconstructing the source data. This allows the results of format-specific\ncharacterisation tools to be verified independently, and facilitates the\ngeneration of representation information for any digital media format, even\nwhen no suitable characterisation tool exists.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 06:26:29 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Jackson", "Andrew N.", ""]]}, {"id": "1111.2788", "submitter": "David South", "authors": "Roman Kogler, David M. South, Michael Steder", "title": "Data Preservation in High Energy Physics", "comments": "8 pages, 6 figures, proceedings of ACAT 2011 poster", "journal-ref": null, "doi": "10.1088/1742-6596/368/1/012026", "report-no": "ACAT2011", "categories": "hep-ex cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data from high-energy physics experiments are collected with significant\nfinancial and human effort and are mostly unique. However, until recently no\ncoherent strategy existed for data preservation and re-use, and many important\nand complex data sets have simply been lost. While the current focus is on the\nLHC at CERN, in the current period several important and unique experimental\nprograms at other facilities are coming to an end, including those at HERA,\nb-factories and the Tevatron. To address this issue, an inter-experimental\nstudy group on HEP data preservation and long-term analysis (DPHEP) was\nconvened at the end of 2008. The group now aims to publish a full and detailed\nreview of the present status of data preservation in high energy physics. This\ncontribution summarises the results of the DPHEP study group, describing the\nchallenges of data preservation in high energy physics and the group's first\nconclusions and recommendations. The physics motivation for data preservation,\ngeneric computing and preservation models, technological expectations and\ngovernance aspects at local and international levels are examined.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 16:24:02 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Kogler", "Roman", ""], ["South", "David M.", ""], ["Steder", "Michael", ""]]}, {"id": "1111.2829", "submitter": "Alexandre Souto Martinez PhD", "authors": "Roberto da Silva, Fahad Kalil, Alexandre Souto Martinez and Jose\n  Palazzo Moreira de Oliveira", "title": "Universality in Bibliometrics", "comments": "To appear in Physica A (8 pages, 6 figures and 2 tables)", "journal-ref": "Physica A 391 (2012) 2119-2128", "doi": "10.1016/j.physa.2011.11.021", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many discussions have enlarged the literature in Bibliometrics since the\nHirsh proposal, the so called $h$-index. Ranking papers according to their\ncitations, this index quantifies a researcher only by its greatest possible\nnumber of papers that are cited at least $h$ times. A closed formula for\n$h$-index distribution that can be applied for distinct databases is not yet\nknown. In fact, to obtain such distribution, the knowledge of citation\ndistribution of the authors and its specificities are required. Instead of\ndealing with researchers randomly chosen, here we address different groups\nbased on distinct databases. The first group is composed by physicists and\nbiologists, with data extracted from Institute of Scientific Information (ISI).\nThe second group composed by computer scientists, which data were extracted\nfrom Google-Scholar system. In this paper, we obtain a general formula for the\n$h$-index probability density function (pdf) for groups of authors by using\ngeneralized exponentials in the context of escort probability. Our analysis\nincludes the use of several statistical methods to estimate the necessary\nparameters. Also an exhaustive comparison among the possible candidate\ndistributions are used to describe the way the citations are distributed among\nauthors. The $h$-index pdf should be used to classify groups of researchers\nfrom a quantitative point of view, which is meaningfully interesting to\neliminate obscure qualitative methods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 19:33:03 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["da Silva", "Roberto", ""], ["Kalil", "Fahad", ""], ["Martinez", "Alexandre Souto", ""], ["de Oliveira", "Jose Palazzo Moreira", ""]]}, {"id": "1111.3618", "submitter": "Edwin Henneken", "authors": "Edwin A. Henneken, Alberto Accomazzi", "title": "Linking to Data - Effect on Citation Rates in Astronomy", "comments": "4 pages, 3 figures, will appear proceedings of ADASS XXI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL astro-ph.IM", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Is there a difference in citation rates between articles that were published\nwith links to data and articles that were not? Besides being interesting from a\npurely academic point of view, this question is also highly relevant for the\nprocess of furthering science. Data sharing not only helps the process of\nverification of claims, but also the discovery of new findings in archival\ndata. However, linking to data still is a far cry away from being a \"practice\",\nespecially where it comes to authors providing these links during the writing\nand submission process. You need to have both a willingness and a publication\nmechanism in order to create such a practice. Showing that articles with links\nto data get higher citation rates might increase the willingness of scientists\nto take the extra steps of linking data sources to their publications. In this\npresentation we will show this is indeed the case: articles with links to data\nresult in higher citation rates than articles without such links. The ADS is\nfunded by NASA Grant NNX09AB39G.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 19:40:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Henneken", "Edwin A.", ""], ["Accomazzi", "Alberto", ""]]}, {"id": "1111.3983", "submitter": "Alberto Pepe", "authors": "Alberto Pepe, Alyssa Goodman, August Muench", "title": "The ADS All-Sky Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ADS All-Sky Survey (ADSASS) is an ongoing effort aimed at turning the\nNASA Astrophysics Data System (ADS), widely known for its unrivaled value as a\nliterature resource for astronomers, into a data resource. The ADS is not a\ndata repository per se, but it implicitly contains valuable holdings of\nastronomical data, in the form of images, tables and object references\ncontained within articles. The objective of the ADSASS effort is to extract\nthese data and make them discoverable and available through existing data\nviewers. The resulting ADSASS data layer promises to greatly enhance workflows\nand enable new research by tying astronomical literature and data assets into\none resource.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2011 22:09:57 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Pepe", "Alberto", ""], ["Goodman", "Alyssa", ""], ["Muench", "August", ""]]}, {"id": "1111.5684", "submitter": "Loet Leydesdorff", "authors": "Michelina Venditti, Emanuela Reale, and Loet Leydesdorff", "title": "The Disclosure of University Research for Third Parties: A Non-Market\n  Perspective on an Italian University", "comments": "Science and Public Policy (in press; 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nations, universities, and regional governments commit resources to promote\nthe dissemination of scientific and technical knowledge. One focuses on\nknowledge-based innovations and the economic function of the university in\nterms of technology transfer, intellectual property,\nuniversity-industry-government relations, etc. Faculties other than engineering\nor applied sciences, however, may not be able to recognize opportunities in\nthis \"linear model\" of technology transfer. We elaborate a non-market\nperspective on the third mission in terms of disclosure of the knowledge and\nareas of expertise available for disclosure to other audiences at a provincial\nuniversity. The use of ICT can enhance communication between actors on the\nsupply and demand sides. Using an idea originally developed in the context of\nthe Dutch science shops, the university staff was questionnaired about keywords\nand areas of expertise with the specific purpose of disclosing this information\nto audiences other than academic colleagues. The results were brought online in\na thesaurus-like structure that enables users to access the university at the\nlevel of individual email address. This model stimulates variation on both the\nsupply and demand side of the innovation process, and strengthens the\naccessibility and embeddedness of the knowledge base in a regional economy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2011 07:05:29 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 11:12:44 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Venditti", "Michelina", ""], ["Reale", "Emanuela", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1111.6053", "submitter": "Filippo Radicchi", "authors": "Filippo Radicchi, Claudio Castellano", "title": "Testing the fairness of citation indicators for comparison across\n  scientific domains: the case of fractional citation counts", "comments": "8 pages, 6 figures, 1 table", "journal-ref": "J. Informetr. 6, 121-130 (2012)", "doi": "10.1016/j.joi.2011.09.002", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation numbers are extensively used for assessing the quality of scientific\nresearch. The use of raw citation counts is generally misleading, especially\nwhen applied to cross-disciplinary comparisons, since the average number of\ncitations received is strongly dependent on the scientific discipline of\nreference of the paper. Measuring and eliminating biases in citation patterns\nis crucial for a fair use of citation numbers. Several numerical indicators\nhave been introduced with this aim, but so far a specific statistical test for\nestimating the fairness of these numerical indicators has not been developed.\nHere we present a statistical method aimed at estimating the effectiveness of\nnumerical indicators in the suppression of citation biases. The method is\nsimple to implement and can be easily generalized to various scenarios. As a\npractical example we test, in a controlled case, the fairness of fractional\ncitation count, which has been recently proposed as a tool for cross-discipline\ncomparison. We show that this indicator is not able to remove biases in\ncitation patterns and performs much worse than the rescaling of citation counts\nwith average values.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 17:00:24 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Radicchi", "Filippo", ""], ["Castellano", "Claudio", ""]]}, {"id": "1111.6116", "submitter": "Norman Gray", "authors": "Norman Gray and Robert G Mann and Dave Morris and Mark Holliman and\n  Keith Noddle", "title": "AstroDAbis: Annotations and Cross-Matches for Remote Catalogues", "comments": "4 pages, 1 figure, to appear in Proceedings of ADASS XXI, Paris, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astronomers are good at sharing data, but poorer at sharing knowledge.\n  Almost all astronomical data ends up in open archives, and access to these is\nbeing simplified by the development of the global Virtual Observatory (VO).\nThis is a great advance, but the fundamental problem remains that these\narchives contain only basic observational data, whereas all the astrophysical\ninterpretation of that data -- which source is a quasar, which a low-mass star,\nand which an image artefact -- is contained in journal papers, with very little\nlinkage back from the literature to the original data archives. It is therefore\ncurrently impossible for an astronomer to pose a query like \"give me all\nsources in this data archive that have been identified as quasars\" and this\nlimits the effective exploitation of these archives, as the user of an archive\nhas no direct means of taking advantage of the knowledge derived by its\nprevious users.\n  The AstroDAbis service aims to address this, in a prototype service enabling\nastronomers to record annotations and cross-identifications in the AstroDAbis\nservice, annotating objects in other catalogues. We have deployed two\ninterfaces to the annotations, namely one astronomy-specific one using the TAP\nprotocol}, and a second exploiting generic Linked Open Data (LOD) and RDF\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 21:22:42 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Gray", "Norman", ""], ["Mann", "Robert G", ""], ["Morris", "Dave", ""], ["Holliman", "Mark", ""], ["Noddle", "Keith", ""]]}, {"id": "1111.6465", "submitter": "Andrey Belikov", "authors": "Willem-Jan Vriend, Edwin A. Valentijn, Andrey Belikov, Gijs A. Verdoes\n  Kleijn", "title": "Astro-WISE Information System", "comments": "4 pages, Proc. of ADASS XXI, ASP Conference Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astro-WISE is a scientific information system for the data processing of\noptical images. In this paper we review main features of Astro-WISE and\ndescribe the current status of the system.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 15:05:20 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Vriend", "Willem-Jan", ""], ["Valentijn", "Edwin A.", ""], ["Belikov", "Andrey", ""], ["Kleijn", "Gijs A. Verdoes", ""]]}, {"id": "1111.6792", "submitter": "Hugo Buddelmeijer", "authors": "Hugo Buddelmeijer, O. Rees Williams, John P. McFarland and Andrey\n  Belikov", "title": "Astro-WISE processing of wide-field images and other data", "comments": "4 pages, Procedings of ADASS XXI, ASP Conference Series", "journal-ref": "Astronomical Data Analysis Software and Systems XXI, volume 461,\n  year 2012, page 881", "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astro-WISE is the Astronomical Wide-field Imaging System for Europe. It is a\nscientific information system which consists of hardware and software federated\nover about a dozen institutes throughout Europe. It has been developed to\nexploit the ever increasing avalanche of data produced by astronomical surveys\nand data intensive scientific experiments in general.\n  The demo explains the architecture of the Astro-WISE information system and\nshows the use of Astro-WISE interfaces. Wide-field astronomical images are\nderived from the raw image to the final catalog according to the user's\nrequest. The demo is based on the standard Astro-WISE guided tour, which can be\naccessed from the Astro-WISE website.\n  The typical Astro-WISE data processing chain is shown, which can be used for\ndata handling for a variety of different instruments, currently 14, including\nOmegaCAM, MegaCam, WFI, WFC, ACS/HST, etc.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 12:31:17 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Buddelmeijer", "Hugo", ""], ["Williams", "O. Rees", ""], ["McFarland", "John P.", ""], ["Belikov", "Andrey", ""]]}, {"id": "1111.6934", "submitter": "Yordan Kalmukov", "authors": "Yordan Kalmukov", "title": "Architecture of a Conference Management System Providing Advanced Paper\n  Assignment Features", "comments": "Published by Foundation of Computer Science, New York, USA", "journal-ref": "International Journal of Computer Applications 34(3):51-59, 2011", "doi": "10.5120/4083-5888", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an architecture and assignment management model of a\nconference management system that performs a precise and accurate automatic\nassignment of reviewers to papers. The system relies on taxonomy of keywords to\ndescribe papers and reviewers' competences. The implied hierarchical structure\nof the taxonomy provides important additional information - the semantic\nrelationships between the separate keywords. It allows similarity measures to\ntake into account not only the number of exactly matching keywords between a\npaper and a reviewer, but in case of non-matching ones to calculate how\nsemantically close they are. Reviewers are allowed to bid on the papers they\nwould like to (or not like to) review and to explicitly state conflicts of\ninterest (CoI) with papers. An automatic CoI detection is checking for\nadditional conflicts based on institutional affiliation, co-authorship (within\nthe local database) and previous co-authorship in the past (within the major\nbibliographic indexes and digital libraries). The algorithm for automatic\nassignment takes into account all - selected keywords, reviewers' bids and\nconflicts of interest and tries to find the most accurate assignment while\nmaintaining load balancing among reviewers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 19:07:24 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Kalmukov", "Yordan", ""]]}]