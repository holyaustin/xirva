[{"id": "1504.01027", "submitter": "Marco Aurelio dos Santos", "authors": "Marco Santos", "title": "Mapeamento Sistematico", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A systematic mapping is a way to identify, evaluate and interpret all\nrelevant research available to a matter of particular research. One of the\nreasons for conducting systematic reviews is that it summarizes the existing\nevidence regarding treatment or technology [Kitchenham, 2004].\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2015 17:14:33 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Santos", "Marco", ""]]}, {"id": "1504.01877", "submitter": "Stefanie Haustein", "authors": "Stefanie Haustein, Cassidy R. Sugimoto, Vincent Larivi\\`ere", "title": "Social media in scholarly communication", "comments": "Guest Editorial to the special issue \"Social Media Metrics in\n  Scholarly Communication: Exploring Tweets, Blogs, Likes and other Altmetrics\"\n  in Aslib Journal of Information Management 67(3)", "journal-ref": "Aslib Journal of Information Management 67(3) (2015)", "doi": "10.1108/AJIM-03-2015-0047", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media metrics - commonly coined as \"altmetrics\" - have been heralded\nas great democratizers of science, providing broader and timelier indicators of\nimpact than citations. These metrics come from a range of sources, including\nTwitter, blogs, social reference managers, post-publication peer review, and\nother social media platforms. Social media metrics have begun to be used as\nindicators of scientific impact, yet the theoretical foundation, empirical\nvalidity, and extent of use of platforms underlying these metrics lack thorough\ntreatment in the literature. This editorial provides an overview of terminology\nand definitions of altmetrics and summarizes current research regarding social\nmedia use in academia, social media metrics as well as data reliability and\nvalidity. The papers of the special issue are introduced.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 09:26:22 GMT"}, {"version": "v2", "created": "Mon, 4 May 2015 19:48:53 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Haustein", "Stefanie", ""], ["Sugimoto", "Cassidy R.", ""], ["Larivi\u00e8re", "Vincent", ""]]}, {"id": "1504.01987", "submitter": "Aravind Sesagiri Raamkumar", "authors": "Aravind Sesagiri Raamkumar, Muthu Kumaar Thangavelu, Sudarsan\n  Kaleeswaran amd Christopher S.G. Khoo", "title": "Designing a Linked Data Migrational Framework for Singapore Government\n  Datasets", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject area of this report is Linked Data and its application to the\nGovernment domain. Linked Data is an alternative method of data representation\nthat aims to interlink data from varied sources through relationships.\nGovernments around the world have started publishing their data in this format\nto assist citizens in making better use of public services. This report\nprovides an eight step migrational framework for converting Singapore\nGovernment data from legacy systems to Linked Data format. The framework\nformulation is based on a study of the Singapore data ecosystem with help from\nInfocomm Development Authority (iDA) of Singapore. Each step in the migrational\nframework has been constructed with objectives, recommendations, best practices\nand issues with entry and exit points. This work builds on the existing Linked\nData literature, implementations in other countries and cookbooks provided by\nLinked Data researchers. iDA can use this report to gain an understanding of\nthe effort and work involved in the implementation of Linked Data system on top\nof their legacy systems. The framework can be evaluated by building a Proof of\nConcept (POC) application.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 14:34:41 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Raamkumar", "Aravind Sesagiri", ""], ["Thangavelu", "Muthu Kumaar", ""], ["Khoo", "Sudarsan Kaleeswaran amd Christopher S. G.", ""]]}, {"id": "1504.02148", "submitter": "Chao-Lin Liu", "authors": "Peter K. Bol and Chao-Lin Liu and Hongsu Wang", "title": "Mining and discovering biographical information in Difangzhi with a\n  language-model-based approach", "comments": "6 pages, 4 figures, 1 table, 2015 International Conference on Digital\n  Humanities. in Proceedings of the 2015 International Conference on Digital\n  Humanities (DH 2015). July 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present results of expanding the contents of the China Biographical\nDatabase by text mining historical local gazetteers, difangzhi. The goal of the\ndatabase is to see how people are connected together, through kinship, social\nconnections, and the places and offices in which they served. The gazetteers\nare the single most important collection of names and offices covering the Song\nthrough Qing periods. Although we begin with local officials we shall\neventually include lists of local examination candidates, people from the\nlocality who served in government, and notable local figures with biographies.\nThe more data we collect the more connections emerge. The value of doing\nsystematic text mining work is that we can identify relevant connections that\nare either directly informative or can become useful without deep historical\nresearch. Academia Sinica is developing a name database for officials in the\ncentral governments of the Ming and Qing dynasties.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 22:38:35 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Bol", "Peter K.", ""], ["Liu", "Chao-Lin", ""], ["Wang", "Hongsu", ""]]}, {"id": "1504.02150", "submitter": "Chao-Lin Liu", "authors": "Wei-Jie Huang and Chao-Lin Liu", "title": "Exploring Lexical, Syntactic, and Semantic Features for Chinese Textual\n  Entailment in NTCIR RITE Evaluation Tasks", "comments": "20 pages, 1 figure, 26 tables, Journal article in Soft Computing\n  (Spinger). Soft Computing, online. Springer, Germany, 2015", "journal-ref": null, "doi": "10.1007/s00500-015-1629-1", "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We computed linguistic information at the lexical, syntactic, and semantic\nlevels for Recognizing Inference in Text (RITE) tasks for both traditional and\nsimplified Chinese in NTCIR-9 and NTCIR-10. Techniques for syntactic parsing,\nnamed-entity recognition, and near synonym recognition were employed, and\nfeatures like counts of common words, statement lengths, negation words, and\nantonyms were considered to judge the entailment relationships of two\nstatements, while we explored both heuristics-based functions and\nmachine-learning approaches. The reported systems showed robustness by\nsimultaneously achieving second positions in the binary-classification subtasks\nfor both simplified and traditional Chinese in NTCIR-10 RITE-2. We conducted\nmore experiments with the test data of NTCIR-9 RITE, with good results. We also\nextended our work to search for better configurations of our classifiers and\ninvestigated contributions of individual features. This extended work showed\ninteresting results and should encourage further discussion.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 22:47:59 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Huang", "Wei-Jie", ""], ["Liu", "Chao-Lin", ""]]}, {"id": "1504.02261", "submitter": "Stevan Harnad", "authors": "A. Swan, Y. Gargouri, M. Hunt and S. Harnad", "title": "Open Access Policy: Numbers, Analysis, Effectiveness", "comments": "49 pages, 21 figures, 15 tables. Pasteur4OA Work Package 3 report:\n  Open Access policies 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The PASTEUR4OA project analyses what makes an Open Access (OA) policy\neffective. The total number of institutional or funder OA policies worldwide is\nnow 663 (March 2015), over half of them mandatory. ROARMAP, the policy\nregistry, has been rebuilt to record more policy detail and provide more\nextensive search functionality. Deposit rates were measured for articles in\ninstitutions' repositories and compared to the total number of WoS-indexed\narticles published from those institutions. Average deposit rate was over four\ntimes as high for institutions with a mandatory policy. Six positive\ncorrelations were found between deposit rates and (1) Must-Deposit; (2)\nCannot-Waive-Deposit; (3) Deposit-Linked-to-Research-Evaluation; (4)\nCannot-Waive-Rights-Retention; (5) Must-Make-Deposit-OA (after allowable\nembargo) and (6) Can-Waive-OA. For deposit latency, there is a positive\ncorrelation between earlier deposit and (7) Must-Deposit-Immediately as well as\nwith (4) Cannot-Waive-Rights-Retention and with mandate age. There are not yet\nenough OA policies to test whether still further policy conditions would\ncontribute to mandate effectiveness but the present findings already suggest\nthat it would be useful for current and future OA policies to adopt the seven\npositive conditions so as to accelerate and maximise the growth of OA.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 11:16:34 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Swan", "A.", ""], ["Gargouri", "Y.", ""], ["Hunt", "M.", ""], ["Harnad", "S.", ""]]}, {"id": "1504.02576", "submitter": "Loet Leydesdorff", "authors": "Johann Bauer, Loet Leydesdorff and Lutz Bornmann", "title": "Highly-cited papers in Library and Information Science (LIS): Authors,\n  institutions, and network structures", "comments": "accepted for publication in the Journal of the Association for\n  Information Science and Technology (JASIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a follow-up to the highly-cited authors list published by Thomson Reuters\nin June 2014, we analyze the top-1% most frequently cited papers published\nbetween 2002 and 2012 included in the Web of Science (WoS) subject category\n\"Information Science & Library Science.\" 798 authors contributed to 305 top-1%\npublications; these authors were employed at 275 institutions. The authors at\nHarvard University contributed the largest number of papers, when the addresses\nare whole-number counted. However, Leiden University leads the ranking, if\nfractional counting is used.\n  Twenty-three of the 798 authors were also listed as most highly-cited authors\nby Thomson Reuters in June 2014 (http://highlycited.com/). Twelve of these 23\nauthors were involved in publishing four or more of the 305 papers under study.\nAnalysis of co-authorship relations among the 798 highly-cited scientists shows\nthat co-authorships are based on common interests in a specific topic. Three\ntopics were important between 2002 and 2012: (1) collection and exploitation of\ninformation in clinical practices, (2) the use of internet in public\ncommunication and commerce, and (3) scientometrics.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 08:00:29 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Bauer", "Johann", ""], ["Leydesdorff", "Loet", ""], ["Bornmann", "Lutz", ""]]}, {"id": "1504.03115", "submitter": "Rasmus Persson", "authors": "Rasmus A. X. Persson", "title": "Bibliometric author evaluation through linear regression on the coauthor\n  network", "comments": "13 pages, 2 figures", "journal-ref": "Journal of Informetrics 11 (2017) pp. 299-306", "doi": "10.1016/j.joi.2017.01.003", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising trend of coauthored academic works obscures the credit assignment\nthat is the basis for decisions of funding and career advancements. In this\npaper, a simple model based on the assumption of an unvarying \"author ability\"\nis introduced. With this assumption, the weight of author contributions to a\nbody of coauthored work can be statistically estimated. The method is tested on\na set of some more than five-hundred authors in a coauthor network from the\nCiteSeerX database. The ranking obtained agrees fairly well with that given by\ntotal fractional citation counts for an author, but noticeable differences\nexist.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 10:10:19 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 16:06:02 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Persson", "Rasmus A. X.", ""]]}, {"id": "1504.04208", "submitter": "Andrea Scharnhorst", "authors": "Rob Koopman, Shenghui Wang, Andrea Scharnhorst", "title": "Contextualization of topics - browsing through terms, authors, journals\n  and cluster allocations", "comments": "proceedings of the ISSI 2015 conference (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on an innovative Information Retrieval tool, Ariadne. The\ntool has been developed as an interactive network visualization and browsing\ntool for large-scale bibliographic databases. It basically allows to gain\ninsights into a topic by contextualizing a search query (Koopman et al., 2015).\nIn this paper, we apply the Ariadne tool to a far smaller dataset of 111,616\ndocuments in astronomy and astrophysics. Labeled as the Berlin dataset, this\ndata have been used by several research teams to apply and later compare\ndifferent clustering algorithms. The quest for this team effort is how to\ndelineate topics. This paper contributes to this challenge in two different\nways. First, we produce one of the different cluster solution and second, we\nuse Ariadne (the method behind it, and the interface - called LittleAriadne) to\ndisplay cluster solutions of the different group members. By providing a tool\nthat allows the visual inspection of the similarity of article clusters\nproduced by different algorithms, we present a complementary approach to other\npossible means of comparison. More particular, we discuss how we can - with\nLittleAriadne - browse through the network of topical terms, authors, journals\nand cluster solutions in the Berlin dataset and compare cluster solutions as\nwell as see their context.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 12:38:10 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Koopman", "Rob", ""], ["Wang", "Shenghui", ""], ["Scharnhorst", "Andrea", ""]]}, {"id": "1504.04478", "submitter": "Thomas Hartmann", "authors": "Thomas Hartmann, Benjamin Zapilko, Joachim Wackerow, Kai Eckert", "title": "Evaluating the Quality of RDF Data Sets on Common Vocabularies in the\n  Social, Behavioral, and Economic Sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From 2012 to 2015 together with other Linked Data community members and\nexperts from the social, behavioral, and economic sciences (SBE), we developed\ndiverse vocabularies to represent SBE metadata and tabular data in RDF. The\nDDI-RDF Discovery Vocabulary (DDI-RDF) is designed to support the\ndissemination, management, and reuse of unit-record data, i.e., data about\nindividuals, households, and businesses, collected in form of responses to\nstudies and archived for research purposes. The RDF Data Cube Vocabulary (QB)\nis a W3C recommendation for expressing data cubes, i.e. multi-dimensional\naggregate data and its metadata. Physical Data Description (PHDD) is a\nvocabulary to model data in rectangular format, i.e., tabular data. The data\ncould either be represented in records with character-separated values (CSV) or\nfixed length. The Simple Knowledge Organization System (SKOS) is a vocabulary\nto build knowledge organization systems such as thesauri, classification\nschemes, and taxonomies. XKOS is a SKOS extension to describe formal\nstatistical classifications.\n  To ensure high quality of and trust in both metadata and data, their\nrepresentation in RDF must satisfy certain criteria - specified in terms of RDF\nconstraints. In this paper, we evaluate the data quality of 15,694 data sets\n(4.26 billion triples) of research data for the social, behavioral, and\neconomic sciences obtained from 33 SPARQL endpoints. We checked 115 constraints\non three different and representative SBE vocabularies (DDI-RDF, QB, and SKOS)\nby means of the RDF Validator, a validation environment which is available at\nhttp://purl.org/net/rdfval-demo.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 10:42:09 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 07:54:09 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Hartmann", "Thomas", ""], ["Zapilko", "Benjamin", ""], ["Wackerow", "Joachim", ""], ["Eckert", "Kai", ""]]}, {"id": "1504.04479", "submitter": "Thomas Hartmann", "authors": "Thomas Hartmann, Benjamin Zapilko, Joachim Wackerow, Kai Eckert", "title": "Constraints to Validate RDF Data Quality on Common Vocabularies in the\n  Social, Behavioral, and Economic Sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure high quality of and trust in both metadata and data, their\nrepresentation in RDF must satisfy certain criteria - specified in terms of RDF\nconstraints. From 2012 to 2015 together with other Linked Data community\nmembers and experts from the social, behavioral, and economic sciences (SBE),\nwe developed diverse vocabularies to represent SBE metadata and rectangular\ndata in RDF.\n  The DDI-RDF Discovery Vocabulary (DDI-RDF) is designed to support the\ndissemination, management, and reuse of unit-record data, i.e., data about\nindividuals, households, and businesses, collected in form of responses to\nstudies and archived for research purposes. The RDF Data Cube Vocabulary (QB)\nis a W3C recommendation for expressing data cubes, i.e. multi-dimensional\naggregate data and its metadata. Physical Data Description (PHDD) is a\nvocabulary to model data in rectangular format, i.e., tabular data. The data\ncould either be represented in records with character-separated values (CSV) or\nfixed length. The Simple Knowledge Organization System (SKOS) is a vocabulary\nto build knowledge organization systems such as thesauri, classification\nschemes, and taxonomies. XKOS is a SKOS extension to describe formal\nstatistical classifications.\n  In this paper, we describe RDF constraints to validate metadata on\nunit-record data (DDI-RDF), aggregated data (QB), thesauri (SKOS), and\nstatistical classifications (XKOS) and to validate tabular data (PHDD) - all of\nthem represented in RDF. We classified these constraints according to the\nseverity of occurring constraint violations. This technical report is updated\ncontinuously as modifying, adding, and deleting constraints remains ongoing\nwork.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 10:43:44 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2015 13:46:10 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2015 07:58:18 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Hartmann", "Thomas", ""], ["Zapilko", "Benjamin", ""], ["Wackerow", "Joachim", ""], ["Eckert", "Kai", ""]]}, {"id": "1504.04800", "submitter": "Dmitry Prokudin", "authors": "Dmitry Prokudin", "title": "Design and Implementation of an Integrated Information System to Support\n  Scientific Research", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Computerization of research activities led to the creation of large\nspecialized information resources, platforms, services and software to support\nscientific research. However, their shortcomings do not allow to fully\nrealizing the comprehensive support of scientific activity, and the absence of\na single entry point to divide the scientific community fragmented groups\ninterests. The article based on analysing the existing solutions and approaches\nto the tools of information and communication technologies of various types of\nscientific activity, and taking into account the research lifecycle proposed\nand formulated the basic principles of designing and implementing an integrated\ninformation system to support scientific research.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 06:36:11 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Prokudin", "Dmitry", ""]]}, {"id": "1504.04801", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff", "title": "Can Intellectual Processes in the Sciences Also Be Simulated? The\n  Anticipation and Visualization of Possible Future States", "comments": "accepted for publication in Scientometrics (June 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socio-cognitive action reproduces and changes both social and cognitive\nstructures. The analytical distinction between these dimensions of structure\nprovides us with richer models of scientific development. In this study, I\nassume that (i) social structures organize expectations into belief structures\nthat can be attributed to individuals and communities; (ii) expectations are\nspecified in scholarly literature; and (iii) intellectually the sciences\n(disciplines, specialties) tend to self-organize as systems of rationalized\nexpectations. Whereas social organizations remain localized, academic writings\ncan circulate, and expectations can be stabilized and globalized using\nsymbolically generalized codes of communication. The intellectual\nrestructuring, however, remains latent as a second-order dynamics that can be\naccessed by participants only reflexively. Yet, the emerging \"horizons of\nmeaning\" provide feedback to the historically developing organizations by\nconstraining the possible future states as boundary conditions. I propose to\nmodel these possible future states using incursive and hyper-incursive\nequations from the computation of anticipatory systems. Simulations of these\nequations enable us to visualize the couplings among the historical--i.e.,\nrecursive--progression of social structures along trajectories, the\nevolutionary--i.e., hyper-incursive--development of systems of expectations at\nthe regime level, and the incursive instantiations of expectations in actions,\norganizations, and texts.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 06:40:11 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 18:12:20 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2015 07:37:39 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Leydesdorff", "Loet", ""]]}, {"id": "1504.04826", "submitter": "Dmitry Prokudin", "authors": "Irina Mbogo, Dmitry Prokudin, Andrey Chugunov", "title": "Complex Integration of Digital Collections into Scientific Information\n  Space", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The article considers the solution of problems of accumulation and\nintegration of scientific electronic collections into information space of\nscientific researches. On the basis of the analysis of the existing standards\nand solutions the choice of methodology and technologies of representation of\nelectronic materials of the scientific conference 'Internet and Modern Society'\nlocates. The concept of the project of integration of the created electronic\ncollection into the main world and domestic information systems and aggregators\nof scientific information is considered.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 13:13:27 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Mbogo", "Irina", ""], ["Prokudin", "Dmitry", ""], ["Chugunov", "Andrey", ""]]}, {"id": "1504.04873", "submitter": "Ronald Hochreiter", "authors": "Laura Vana and Ronald Hochreiter and Kurt Hornik", "title": "Computing a consensus journal meta-ranking using paired comparisons and\n  adaptive lasso estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a \"publish-or-perish culture\", the ranking of scientific journals plays a\ncentral role in assessing performance in the current research environment. With\na wide range of existing methods and approaches to deriving journal rankings,\nmeta-rankings have gained popularity as a means of aggregating different\ninformation sources. In this paper, we propose a method to create a consensus\nmeta-ranking using heterogeneous journal rankings. Using a parametric model for\npaired comparison data we estimate quality scores for 58 journals in the OR/MS\ncommunity, which together with a shrinkage procedure allows for the\nidentification of clusters of journals with similar quality. The use of paired\ncomparisons provides a flexible framework for deriving a consensus score while\neliminating the problem of data missingness.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 19:14:57 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Vana", "Laura", ""], ["Hochreiter", "Ronald", ""], ["Hornik", "Kurt", ""]]}, {"id": "1504.05816", "submitter": "Sandor Soos", "authors": "Sandor Soos (Dept. Science Policy and Scientometrics, Library and\n  Information Centre of the Hungarian Academy of Sciences, MTA)", "title": "A new generation of science overlay maps with an application to the\n  history of biosystematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a text-mining based analytical framework aiming at the\ncognitive organization of complex scientific discourses. The approach is based\non models recently developed in science mapping, being a generalization of the\nso-called Science Overlay Mapping methodology, referred to as Topic Overlay\nMapping (TOM). It is shown that via applications of TOM in visualization,\ndocument clustering, time series analysis etc. the in-depth exploration and\neven the measurement of cognitive complexity and its dynamics is feasible for\nscientific domains. As a use case, an empirical study is presented into the\ndiscovery of a long-standing complex, interdisciplinary discourse, the debate\non the species concept in biosystematics.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 14:17:38 GMT"}], "update_date": "2015-04-23", "authors_parsed": [["Soos", "Sandor", "", "Dept. Science Policy and Scientometrics, Library and\n  Information Centre of the Hungarian Academy of Sciences, MTA"]]}, {"id": "1504.05840", "submitter": "Wouter de Nooy", "authors": "Wouter de Nooy, Loet Leydesdorff", "title": "The Dynamics of Triads in Aggregated Journal-Journal Citation Relations:\n  Specialty Developments at the Above-Journal Level", "comments": "Accepted for publication in Journal of Informetrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyads of journals related by citations can agglomerate into specialties\nthrough the mechanism of triadic closure. Using the Journal Citation Reports\n2011, 2012, and 2013, we analyze triad formation as indicators of integration\n(specialty growth) and disintegration (restructuring). The strongest\nintegration is found among the large journals that report on studies in\ndifferent scientific specialties, such as PLoS ONE, Nature Communications,\nNature, and Science. This tendency towards large-scale integration has not yet\nstabilized. Using the Islands algorithm, we also distinguish 51 local maxima of\nintegration. We zoom into the cited articles that carry the integration for:\n(i) a new development within high-energy physics and (ii) an emerging interface\nbetween the journals Applied Mathematical Modeling and the International\nJournal of Advanced Manufacturing Technology. In the first case, integration is\nbrought about by a specific communication reaching across specialty boundaries,\nwhereas in the second, the dyad of journals indicates an emerging interface\nbetween specialties. These results suggest that integration picks up\nsubstantive developments at the specialty level. An advantage of the bottom-up\nmethod is that no ex ante classification of journals is assumed in the dynamic\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 14:58:47 GMT"}, {"version": "v2", "created": "Tue, 5 May 2015 07:12:49 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["de Nooy", "Wouter", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1504.07479", "submitter": "Philip Davis", "authors": "Philip M. Davis, Angela Cochran", "title": "Cited Half-Life of the Journal Literature", "comments": "Table 1 is replaced to fix a sorting error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing 13,455 journals listed in the Journal Citation Report (Thomson\nReuters) from 1997 through 2013, we report that the mean cited half-life of the\nscholarly literature is 6.5 years and growing at a rate of 0.13 years per\nannum. Focusing on a subset of journals (N=4,937) for which we have a\ncontinuous series of half-life observations, 209 of 229 (91%) subject\ncategories experienced increasing cited half-lives. Contrary to the overall\ntrend, engineering and chemistry journals experienced declining cited\nhalf-lives. Last, as journals attracted more citations, a larger proportion of\nthem were directed toward older papers. The trend to cite older papers is not\nfully explained by technology (digital publishing, search and retrieval, etc.),\nbut may be the result of a structural shift to fund incremental and applied\nresearch over fundamental science.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 14:03:27 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2015 14:58:32 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Davis", "Philip M.", ""], ["Cochran", "Angela", ""]]}, {"id": "1504.07482", "submitter": "Robin Haunschild", "authors": "Robin Haunschild, Lutz Bornmann, and Loet Leydesdorff", "title": "Networks of reader and country status: An analysis of Mendeley reader\n  statistics", "comments": "26 pages, 6 figures (also web-based startable), and 2 tables", "journal-ref": "PeerJ CompSci, 32 (2015)", "doi": "10.7717/peerj-cs.32", "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of papers published in journals indexed by the Web of Science core\ncollection is steadily increasing. In recent years, nearly two million new\npapers were published each year; somewhat more than one million papers when\nprimary research papers are considered only (articles and reviews are the\ndocument types where primary research is usually reported or reviewed).\nHowever, who reads these papers? More precisely, which groups of researchers\nfrom which (self-assigned) scientific disciplines and countries are reading\nthese papers? Is it possible to visualize readership patterns for certain\ncountries, scientific disciplines, or academic status groups? One popular\nmethod to answer these questions is a network analysis. In this study, we\nanalyze Mendeley readership data of a set of 1,133,224 articles and 64,960\nreviews with publication year 2012 to generate three different kinds of\nnetworks: (1) The network based on disciplinary affiliations of Mendeley\nreaders contains four groups: (i) biology, (ii) social science and humanities\n(including relevant computer science), (iii) bio-medical sciences, and (iv)\nnatural science and engineering. In all four groups, the category with the\naddition \"miscellaneous\" prevails. (2) The network of co-readers in terms of\nprofessional status shows that a common interest in papers is mainly shared\namong PhD students, Master's students, and postdocs. (3) The country network\nfocusses on global readership patterns: a group of 53 nations is identified as\ncore to the scientific enterprise, including Russia and China as well as two\nthirds of the OECD (Organisation for Economic Co-operation and Development)\ncountries.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 14:08:06 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 14:49:51 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2015 13:32:40 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Haunschild", "Robin", ""], ["Bornmann", "Lutz", ""], ["Leydesdorff", "Loet", ""]]}]