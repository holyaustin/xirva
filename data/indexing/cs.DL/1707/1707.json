[{"id": "1707.00482", "submitter": "Olesya Mryglod", "authors": "Olesya Mryglod, Bertrand Berche, Yurij Holovatch and Ralph Kenna", "title": "Complex-network approach for visualizing and quantifying the evolution\n  of a scientific topic", "comments": "Submitted to become a chapter of the book \"Information Visualization\n  Techniques in the Social Sciences and Humanities\"", "journal-ref": "Information Visualization Techniques in the Social Sciences and\n  Humanities, edited by V. Osinska and G. Osinski (IGI Global, 2018), pp.\n  106-120", "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tracing the evolution of specific topics is a subject area which belongs to\nthe general problem of mapping the structure of scientific knowledge. Often\nbibliometric data bases are used to study the history of scientific topic\nevolution from its appearance to its extinction or merger with other topics. In\nthis chapter the authors present an analysis of the academic response to the\ndisaster that occurred in 1986 in Chornobyl (Chernobyl), Ukraine, considered as\none of the most devastating nuclear power plant accidents in history. Using a\nbibliographic database the distributions of Chornobyl-related papers in\ndifferent scientific fields are analysed, as are their growth rates and\nproperties of co-authorship networks. Elements of descriptive statistics and\ntools of complex-network theory are used to highlight interdisciplinary as well\nas international effects. In particular, tools of complex-network science\nenable information visualization complemented by further quantitative analysis.\nA further goal of the chapter is to provide a simple pedagogical introduction\nto the application of complex-network analysis for visual data representation\nand interdisciplinary communication.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 11:26:55 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Mryglod", "Olesya", ""], ["Berche", "Bertrand", ""], ["Holovatch", "Yurij", ""], ["Kenna", "Ralph", ""]]}, {"id": "1707.00510", "submitter": "Radoslaw Nielek", "authors": "Pavel Savov, Adam Jatowt, Radoslaw Nielek", "title": "Towards Understanding the Evolution of the WWW Conference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Wide Web conference is a well-established and mature venue with an\nalready long history. Over the years it has been attracting papers reporting\nmany important research achievements centered around the Web. In this work we\naim at understanding the evolution of WWW conference series by detecting\ncrucial years and important topics. We propose a simple yet novel approach\nbased on tracking the classification errors of the conference papers according\nto their predicted publication years.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 12:48:29 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Savov", "Pavel", ""], ["Jatowt", "Adam", ""], ["Nielek", "Radoslaw", ""]]}, {"id": "1707.01162", "submitter": "Fei Shu", "authors": "Wei Quan, Bikun Chen, Fei Shu", "title": "Publish or impoverish: An investigation of the monetary reward system of\n  science in China (1999-2016)", "comments": null, "journal-ref": "Aslib Journal of Information Management, 69(5), 1-18 (2017)", "doi": "10.1108/AJIM-01-2017-0014", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: The purpose of this study is to present the landscape of the\ncash-per-publication reward policy in China and reveal its trend since the late\n1990s.\n  Design/methodology/approach: This study is based on the analysis of 168\nuniversity documents regarding the cash-per-publication reward policy at 100\nChinese universities.\n  Findings: Chinese universities offer cash rewards from 30 to 165,000 USD for\npapers published in journals indexed by Web of Science (WoS), and the average\nreward amount has been increasing for the past 10 years.\n  Originality/value: The cash-per-publication reward policy in China has never\nbeen systematically studied and investigated before except for in some case\nstudies. This is the first paper that reveals the landscape of the\ncash-per-publication reward policy in China.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 21:46:35 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Quan", "Wei", ""], ["Chen", "Bikun", ""], ["Shu", "Fei", ""]]}, {"id": "1707.01425", "submitter": "Souvick Ghosh", "authors": "Souvick Ghosh, Dipankar Das and Tanmoy Chakraborty", "title": "Determining sentiment in citation text and analyzing its impact on the\n  proposed ranking index", "comments": "Sentiment Analysis, Citation, Citation Sentiment Analysis, Citation\n  Polarity, Ranking, Bibliometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever human beings interact with each other, they exchange or express\nopinions, emotions, and sentiments. These opinions can be expressed in text,\nspeech or images. Analysis of these sentiments is one of the popular research\nareas of present day researchers. Sentiment analysis, also known as opinion\nmining tries to identify or classify these sentiments or opinions into two\nbroad categories - positive and negative. In recent years, the scientific\ncommunity has taken a lot of interest in analyzing sentiment in textual data\navailable in various social media platforms. Much work has been done on social\nmedia conversations, blog posts, newspaper articles and various narrative\ntexts. However, when it comes to identifying emotions from scientific papers,\nresearchers have faced some difficulties due to the implicit and hidden nature\nof opinion. By default, citation instances are considered inherently positive\nin emotion. Popular ranking and indexing paradigms often neglect the opinion\npresent while citing. In this paper, we have tried to achieve three objectives.\nFirst, we try to identify the major sentiment in the citation text and assign a\nscore to the instance. We have used a statistical classifier for this purpose.\nSecondly, we have proposed a new index (we shall refer to it hereafter as\nM-index) which takes into account both the quantitative and qualitative factors\nwhile scoring a paper. Thirdly, we developed a ranking of research papers based\non the M-index. We also try to explain how the M-index impacts the ranking of\nscientific papers.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 15:03:30 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Ghosh", "Souvick", ""], ["Das", "Dipankar", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1707.01635", "submitter": "Loet Leydesdorff", "authors": "Helen F. Xue, Loet Leydesdorff, and Fred Y. Ye", "title": "Probing Multivariate Indicators for Academic Evaluation", "comments": "Journal of Library Science in China (in press). This is the English\n  version of a Chinese article. DOI:10.13530/j.cnki.jlis.170018", "journal-ref": null, "doi": "10.13530/j.cnki.jlis.170018", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine the Integrated Impact Indicator (I3) and the h-index into the\nI3-type framework and introduce the publication vector X = (X1, X2, X3) and the\ncitation vector Y = (Y1, Y2, Y3) , the publication score I3X=X1+X2+X3 and the\ncitation score I3Y=Y1+Y2+Y3, and alternative indicators based on percentile\nclasses generated by the h-index. These multivariate indicators can be used for\nacademic evaluation. The empirical studies show that the h-core distribution is\nsuitable to evaluate scholars, the X1 and Y1 are applied to measure core impact\npower of universities, and I3X and I3Y are alternatives of journal impact\nfactor (JIF). The multivariate indicators provide a multidimensional view of\nacademic evaluation with using the advantages of both the h-index and I3.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 04:48:58 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Xue", "Helen F.", ""], ["Leydesdorff", "Loet", ""], ["Ye", "Fred Y.", ""]]}, {"id": "1707.02204", "submitter": "Giovanni Colavizza", "authors": "Giovanni Colavizza", "title": "The structural role of the core literature in history", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intellectual landscapes of the humanities are mostly uncharted territory.\nLittle is known on the ways published research of humanist scholars defines\nareas of intellectual activity. An open question relates to the structural role\nof core literature: highly cited sources, naturally playing a disproportionate\nrole in the definition of intellectual landscapes. We introduce four indicators\nin order to map the structural role played by core sources into connecting\ndifferent areas of the intellectual landscape of citing publications (i.e.\ncommunities in the bibliographic coupling network). All indicators factor out\nthe influence of degree distributions by internalizing a null configuration\nmodel. By considering several datasets focused on history, we show that two\ndistinct structural actions are performed by the core literature: a global one,\nby connecting otherwise separated communities in the landscape, or a local one,\nby rising connectivity within communities. In our study, the global action is\nmainly performed by small sets of scholarly monographs, reference works and\nprimary sources, while the rest of the core, and especially most journal\narticles, acts mostly locally.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 14:51:54 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 22:00:17 GMT"}, {"version": "v3", "created": "Mon, 11 Sep 2017 13:19:17 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Colavizza", "Giovanni", ""]]}, {"id": "1707.02264", "submitter": "Kyle Niemeyer", "authors": "Arfon M Smith, Kyle E Niemeyer, Daniel S Katz, Lorena A Barba, George\n  Githinji, Melissa Gymrek, Kathryn D Huff, Christopher R Madan, Abigail\n  Cabunoc Mayes, Kevin M Moerman, Pjotr Prins, Karthik Ram, Ariel Rokem, Tracy\n  K Teal, Roman Valls Guimera, Jacob T Vanderplas", "title": "Journal of Open Source Software (JOSS): design and first-year review", "comments": "22 pages, 8 figures", "journal-ref": "PeerJ Computer Science 4 (2018) e147", "doi": "10.7717/peerj-cs.147", "report-no": null, "categories": "cs.DL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article describes the motivation, design, and progress of the Journal of\nOpen Source Software (JOSS). JOSS is a free and open-access journal that\npublishes articles describing research software. It has the dual goals of\nimproving the quality of the software submitted and providing a mechanism for\nresearch software developers to receive credit. While designed to work within\nthe current merit system of science, JOSS addresses the dearth of rewards for\nkey contributions to science made in the form of software. JOSS publishes\narticles that encapsulate scholarship contained in the software itself, and its\nrigorous peer review targets the software components: functionality,\ndocumentation, tests, continuous integration, and the license. A JOSS article\ncontains an abstract describing the purpose and functionality of the software,\nreferences, and a link to the software archive. The article is the entry point\nof a JOSS submission, which encompasses the full set of software artifacts.\nSubmission and review proceed in the open, on GitHub. Editors, reviewers, and\nauthors work collaboratively and openly. Unlike other journals, JOSS does not\nreject articles requiring major revision; while not yet accepted, articles\nremain visible and under review until the authors make adequate changes (or\nwithdraw, if unable to meet requirements). Once an article is accepted, JOSS\ngives it a DOI, deposits its metadata in Crossref, and the article can begin\ncollecting citations on indexers like Google Scholar and other services.\nAuthors retain copyright of their JOSS article, releasing it under a Creative\nCommons Attribution 4.0 International License. In its first year, starting in\nMay 2016, JOSS published 111 articles, with more than 40 additional articles\nunder review. JOSS is a sponsored project of the nonprofit organization\nNumFOCUS and is an affiliate of the Open Source Initiative.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 16:50:35 GMT"}, {"version": "v2", "created": "Wed, 27 Dec 2017 19:20:47 GMT"}, {"version": "v3", "created": "Wed, 24 Jan 2018 23:27:51 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Smith", "Arfon M", ""], ["Niemeyer", "Kyle E", ""], ["Katz", "Daniel S", ""], ["Barba", "Lorena A", ""], ["Githinji", "George", ""], ["Gymrek", "Melissa", ""], ["Huff", "Kathryn D", ""], ["Madan", "Christopher R", ""], ["Mayes", "Abigail Cabunoc", ""], ["Moerman", "Kevin M", ""], ["Prins", "Pjotr", ""], ["Ram", "Karthik", ""], ["Rokem", "Ariel", ""], ["Teal", "Tracy K", ""], ["Guimera", "Roman Valls", ""], ["Vanderplas", "Jacob T", ""]]}, {"id": "1707.02283", "submitter": "Iman Tahamtan", "authors": "Iman Tahamtan and Lutz Bornmann", "title": "Core Elements in the Process of Citing Publications: A Conceptual\n  Overview of the Literature", "comments": "40 pages, 1 figure", "journal-ref": "Journal of Informetrics, 2018", "doi": "10.1016/j.joi.2018.01.002", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study provides a conceptual overview of the literature dealing with the\nprocess of citing documents (focusing on the literature from the recent\ndecade). It presents theories, which have been proposed for explaining the\ncitation process, and studies having empirically analyzed this process. The\noverview is referred to as conceptual, because it is structured based on core\nelements in the citation process: the context of the cited document, processes\nfrom selection to citation of documents, and the context of the citing\ndocument. The core elements are presented in a schematic representation. The\noverview can be used to find answers on basic questions about the practice of\nciting documents. Besides understanding of the process of citing, it delivers\nbasic information for the proper application of citations in research\nevaluation.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 20:02:56 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 19:06:56 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 16:50:58 GMT"}, {"version": "v4", "created": "Wed, 3 Jan 2018 21:27:07 GMT"}, {"version": "v5", "created": "Tue, 9 Jan 2018 14:23:32 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Tahamtan", "Iman", ""], ["Bornmann", "Lutz", ""]]}, {"id": "1707.02494", "submitter": "Philipp Mayr", "authors": "Ameni Kacem, Philipp Mayr", "title": "Analysis of Footnote Chasing and Citation Searching in an Academic\n  Search Engine", "comments": "10 pages, 2 figures, paper accepted at the Bibliometric-enhanced\n  Information Retrieval and Natural Language Processing for Digital Libraries\n  (BIRNDL) workshop at SIGIR 2017. arXiv admin note: text overlap with\n  arXiv:1706.00816", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In interactive information retrieval, researchers consider the user behavior\ntowards systems and search tasks in order to adapt search results by analyzing\ntheir past interactions. In this paper, we analyze the user behavior towards\nMarcia Bates' search stratagems such as 'footnote chasing' and 'citation\nsearch' in an academic search engine. We performed a preliminary analysis of\ntheir frequency and stage of use in the social sciences search engine sowiport.\nIn addition, we explored the impact of these stratagems on the whole search\nprocess performance. We can conclude that the appearance of these two search\nfeatures in real retrieval sessions lead to an improvement of the precision in\nterms of positive interactions with 16% when using footnote chasing and 17% for\nthe citation search stratagem.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 20:45:50 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 19:58:09 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Kacem", "Ameni", ""], ["Mayr", "Philipp", ""]]}, {"id": "1707.02553", "submitter": "Vahid Garousi", "authors": "Vahid Garousi, Michael Felderer, Mika V. M\\\"antyl\\\"a", "title": "Guidelines for including grey literature and conducting multivocal\n  literature reviews in software engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Context: A Multivocal Literature Review (MLR) is a form of a Systematic\nLiterature Review (SLR) which includes the grey literature (e.g., blog posts\nand white papers) in addition to the published (formal) literature (e.g.,\njournal and conference papers). MLRs are useful for both researchers and\npractitioners since they provide summaries both the state-of-the art and\n-practice in a given area. Objective: There are several guidelines to conduct\nSLR studies in SE. However, given the facts that several phases of MLRs differ\nfrom those of traditional SLRs, for instance with respect to the search process\nand source quality assessment. Therefore, SLR guidelines are only partially\nuseful for conducting MLR studies. Our goal in this paper is to present\nguidelines on how to conduct MLR studies in SE. Method: To develop the MLR\nguidelines, we benefit from three inputs: (1) existing SLR guidelines in SE,\n(2), a literature survey of MLR guidelines and experience papers in other\nfields, and (3) our own experiences in conducting several MLRs in SE. All\nderived guidelines are discussed in the context of three examples MLRs as\nrunning examples (two from SE and one MLR from the medical sciences). Results:\nThe resulting guidelines cover all phases of conducting and reporting MLRs in\nSE from the planning phase, over conducting the review to the final reporting\nof the review. In particular, we believe that incorporating and adopting a vast\nset of recommendations from MLR guidelines and experience papers in other\nfields have enabled us to propose a set of guidelines with solid foundations.\nConclusion: Having been developed on the basis of three types of solid\nexperience and evidence, the provided MLR guidelines support researchers to\neffectively and efficiently conduct new MLRs in any area of SE.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 10:15:59 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 20:41:34 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 05:36:09 GMT"}, {"version": "v4", "created": "Tue, 18 Sep 2018 08:00:10 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Garousi", "Vahid", ""], ["Felderer", "Michael", ""], ["M\u00e4ntyl\u00e4", "Mika V.", ""]]}, {"id": "1707.02623", "submitter": "Gy\\\"orgy Csom\\'os", "authors": "Gyorgy Csomos and Geza Toth", "title": "Exploring the position of cities in global corporate research and\n  development: a bibliometric analysis by two different geographical approaches", "comments": null, "journal-ref": "Journal of Informetrics, Volume 10, Issue 2, May 2016, Pages\n  516-532", "doi": "10.1016/j.joi.2016.02.004", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global cities are defined, on the one hand, as the major command and control\ncentres of the world economy and, on the other hand, as the most significant\nsites of the production of innovation. As command and control centres, they are\nhome to the headquarters of the most powerful MNCs of the global economy, while\nas sites for the production of innovation they are supposed to be the most\nimportant sites of corporate research and development (R&D) activities. In this\npaper, we conduct a bibliometric analysis of the data located in the Scopus and\nForbes 2000 databases to reveal the correlation between the characteristics of\nthe above global city definitions. We explore which cities are the major\ncontrol points of the global corporate R&D (home city approach), and which\ncities are the most important sites of corporate R&D activities (host city\napproach). According to the home city approach we assign articles produced by\ncompanies to cities where the decision-making headquarters are located (i.e. to\ncities that control the companies' R&D activities), while according to the host\ncity approach we assign articles to cities where the R&D activities are\nactually conducted. Given Sassen's global city concept, we expect global cities\nto be both the leading home cities and host cities.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 19:01:25 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Csomos", "Gyorgy", ""], ["Toth", "Geza", ""]]}, {"id": "1707.03076", "submitter": "Giovanni Colavizza", "authors": "Giovanni Colavizza, Kevin W. Boyack, Nees Jan van Eck, Ludo Waltman", "title": "The Closer the Better: Similarity of Publication Pairs at Different\n  Co-Citation Levels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the similarities of pairs of articles which are co-cited at\nthe different co-citation levels of the journal, article, section, paragraph,\nsentence and bracket. Our results indicate that textual similarity,\nintellectual overlap (shared references), author overlap (shared authors),\nproximity in publication time all rise monotonically as the co-citation level\ngets lower (from journal to bracket). While the main gain in similarity happens\nwhen moving from journal to article co-citation, all level changes entail an\nincrease in similarity, especially section to paragraph and paragraph to\nsentence/bracket levels. We compare results from four journals over the years\n2010-2015: Cell, the European Journal of Operational Research, Physics Letters\nB and Research Policy, with consistent general outcomes and some interesting\ndifferences. Our findings motivate the use of granular co-citation information\nas defined by meaningful units of text, with implications for, among others,\nthe elaboration of maps of science and the retrieval of scholarly literature.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 22:27:10 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 08:13:22 GMT"}, {"version": "v3", "created": "Wed, 20 Sep 2017 18:09:56 GMT"}, {"version": "v4", "created": "Fri, 27 Oct 2017 10:03:45 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Colavizza", "Giovanni", ""], ["Boyack", "Kevin W.", ""], ["van Eck", "Nees Jan", ""], ["Waltman", "Ludo", ""]]}, {"id": "1707.03095", "submitter": "Demival Vasques Filho", "authors": "Ben Curran, Kyle Higham, Elisenda Ortiz, Demival Vasques Filho", "title": "Look Who's Talking: Bipartite Networks as Representations of a Topic\n  Model of New Zealand Parliamentary Speeches", "comments": "28 pages, 12 figures, 3 tables", "journal-ref": null, "doi": "10.1371/journal.pone.0199072", "report-no": null, "categories": "cs.CL cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative methods to measure the participation to parliamentary debate and\ndiscourse of elected Members of Parliament (MPs) and the parties they belong to\nare lacking. This is an exploratory study in which we propose the development\nof a new approach for a quantitative analysis of such participation. We utilize\nthe New Zealand government's digital Hansard database to construct a topic\nmodel of parliamentary speeches consisting of nearly 40 million words in the\nperiod 2003-2016. A Latent Dirichlet Allocation topic model is implemented in\norder to reveal the thematic structure of our set of documents. This generative\nstatistical model enables the detection of major themes or topics that are\npublicly discussed in the New Zealand parliament, as well as permitting their\nclassification by MP. Information on topic proportions is subsequently analyzed\nusing a combination of statistical methods. We observe patterns arising from\ntime-series analysis of topic frequencies which can be related to specific\nsocial, economic and legislative events. We then construct a bipartite network\nrepresentation, linking MPs to topics, for each of four parliamentary terms in\nthis time frame. We build projected networks (onto the set of nodes represented\nby MPs) and proceed to the study of the dynamical changes of their topology,\nincluding community structure. By performing this longitudinal network\nanalysis, we can observe the evolution of the New Zealand parliamentary topic\nnetwork and its main parties in the period studied.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 01:25:31 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 01:40:56 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 03:12:32 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Curran", "Ben", ""], ["Higham", "Kyle", ""], ["Ortiz", "Elisenda", ""], ["Filho", "Demival Vasques", ""]]}, {"id": "1707.03177", "submitter": "Gy\\\"orgy Csom\\'os", "authors": "Gyorgy Csomos", "title": "Mapping spatial and temporal changes of global corporate research and\n  development activities by conducting a bibliometric analysis", "comments": null, "journal-ref": "Quaestiones Geographicae, 36 (1), 67-77. (2017)", "doi": "10.1515/quageo-2017-0005", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Corporate research and development (R&D) activities have long been highly\nconcentrated in a handful of world cities. This is due to the fact that these\ncities (e.g., Tokyo, New York, London, and Paris) are home to the largest and\nmost powerful transnational corporations and are globally important sites for\ninnovative start-up firms that operate in the fastest growing industries.\nHowever, in tandem with the rapid technological changes of our age, corporate\nR&D activities have shifted towards newly emerging and now globally significant\nR&D centres, like San Jose, San Francisco, and Boston in the United States, and\nBeijing, Seoul, and Shenzhen in East Asia. In this paper, I will conduct a\nbibliometric analysis to define which cities are centres of corporate R&D\nactivities, how different industries influence their performance, and what\nspatial tendencies characterise the period from 1980 to 2014. The bibliometric\nanalysis is based upon an assumption that implies there is a close connection\nbetween the number of scientific articles published by a given firm and the\nvolume of its R&D activity. Results show that firms headquartered in Tokyo, New\nYork, London, and Paris published the largest combined number of scientific\narticles in the period from 1980 to 2014, but that the growth rate of the\nannual output of scientific articles was much greater in Boston, San Jose,\nBeijing, and Seoul, as well as some Taiwanese cities. Furthermore, it can also\nbe seen that those cities that have the largest number of articles; i.e., that\ncan be considered as the most significant sites of corporate R&D in which firms\noperate in fast-growing industries, are primarily in the pharmaceutical and\ninformation technology industries. For these reasons, some mid-sized cities\nthat are home to globally significant pharmaceutical or information technology\nfirms are also top corporate R&D hubs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 08:56:21 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Csomos", "Gyorgy", ""]]}, {"id": "1707.03327", "submitter": "Daniel Torres-Salinas Dr", "authors": "Daniel Torres-Salinas, Christian Gumpenberger, Juan Gorraiz", "title": "PlumX As a Potential Tool to Assess the Macroscopic Multidimensional\n  Impact of Books", "comments": null, "journal-ref": null, "doi": "10.3389/frma.2017.00005", "report-no": "11 pages", "categories": "cs.DL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this macro-study is to shed light on the broad impact of\nbooks. For this purpose, the impact of a very large collection of books has\nbeen analyzed by using PlumX, an analytical tool providing a great number of\ndifferent metrics provided by various tools.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 19:02:22 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Torres-Salinas", "Daniel", ""], ["Gumpenberger", "Christian", ""], ["Gorraiz", "Juan", ""]]}, {"id": "1707.03540", "submitter": "Moritz Schubotz", "authors": "Moritz Schubotz, Norman Meuschke, Thomas Hepp, Howard S. Cohl and Bela\n  Gipp", "title": "VMEXT: A Visualization Tool for Mathematical Expression Trees", "comments": "15 pages, 4 figures, Intelligent Computer Mathematics - 10th\n  International Conference CICM 2017, Edinburgh, UK, July 17-21, 2017,\n  Proceedings", "journal-ref": "Lecture Notes in Computer Science, Springer 2017", "doi": "10.1007/978-3-319-62075-6_24", "report-no": null, "categories": "cs.HC cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical expressions can be represented as a tree consisting of terminal\nsymbols, such as identifiers or numbers (leaf nodes), and functions or\noperators (non-leaf nodes). Expression trees are an important mechanism for\nstoring and processing mathematical expressions as well as the most frequently\nused visualization of the structure of mathematical expressions. Typically,\nresearchers and practitioners manually visualize expression trees using\ngeneral-purpose tools. This approach is laborious, redundant, and error-prone.\nManual visualizations represent a user's notion of what the markup of an\nexpression should be, but not necessarily what the actual markup is. This paper\npresents VMEXT - a free and open source tool to directly visualize expression\ntrees from parallel MathML. VMEXT simultaneously visualizes the presentation\nelements and the semantic structure of mathematical expressions to enable users\nto quickly spot deficiencies in the Content MathML markup that does not affect\nthe presentation of the expression. Identifying such discrepancies previously\nrequired reading the verbose and complex MathML markup. VMEXT also allows one\nto visualize similar and identical elements of two expressions. Visualizing\nexpression similarity can support support developers in designing retrieval\napproaches and enable improved interaction concepts for users of mathematical\ninformation retrieval systems. We demonstrate VMEXT's visualizations in two\nweb-based applications. The first application presents the visualizations\nalone. The second application shows a possible integration of the\nvisualizations in systems for mathematical knowledge management and\nmathematical information retrieval. The application converts LaTeX input to\nparallel MathML, computes basic similarity measures for mathematical\nexpressions, and visualizes the results using VMEXT.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 04:57:45 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Schubotz", "Moritz", ""], ["Meuschke", "Norman", ""], ["Hepp", "Thomas", ""], ["Cohl", "Howard S.", ""], ["Gipp", "Bela", ""]]}, {"id": "1707.03599", "submitter": "Qi Wang", "authors": "Qi Wang", "title": "A Bibliometric Model for Identifying Emerging Research Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting emerging research topics is essential, not only for research\nagencies but also for individual researchers. Previous studies have created\nvarious bibliographic indicators for the identification of emerging research\ntopics. However, as indicated by Rotolo et al. (2015), the most serious\nproblems are the lack of an acknowledged definition of emergence and incomplete\nelaboration of the linkages between the definitions that are used and the\nindicators that are created. With these issues in mind, this study first\nadjusts the definition of an emerging technology that Rotolo et al. (2015) have\nproposed in order to accommodate the analysis. Next, a set of criteria for the\nidentification of emerging topics is proposed according to the adjusted\ndefinition and attributes of emergence. By the use of two sets of parameter\nvalues, several emerging research topics are identified. Finally, evaluation\ntests are conducted by demonstration of the proposed approach and comparison\nwith previous studies. The strength of the present methodology lies in the fact\nthat it is fully transparent, straightforward, and flexible.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 08:47:55 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Wang", "Qi", ""]]}, {"id": "1707.04050", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Robin Haunschild", "title": "Plots for visualizing paper impact and journal impact of single\n  researchers in a single graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In research evaluation of single researchers, the assessment of paper and\njournal impact is of interest. High journal impact reflects the ability of\nresearchers to convince strict reviewers, and high paper impact reflects the\nusefulness of papers for future research. In many bibliometric studies, metrics\nfor journal and paper impact are separately presented. In this paper, we\nintroduce two graph types, which combine both metrics in a single graph. The\ngraphs can be used in research evaluation to visualize the performance of\nsingle researchers comprehensively.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 10:10:13 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 16:46:58 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""]]}, {"id": "1707.04134", "submitter": "Petr Knoth", "authors": "Aristotelis Charalampous and Petr Knoth", "title": "Classifying document types to enhance search and recommendations in\n  digital libraries", "comments": "12 pages, 21st International Conference on Theory and Practise of\n  Digital Libraries (TPDL), 2017, Thessaloniki, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the problem of classifying documents available from\nthe global network of (open access) repositories according to their type. We\nshow that the metadata provided by repositories enabling us to distinguish\nresearch papers, thesis and slides are missing in over 60% of cases. While\nthese metadata describing document types are useful in a variety of scenarios\nranging from research analytics to improving search and recommender (SR)\nsystems, this problem has not yet been sufficiently addressed in the context of\nthe repositories infrastructure. We have developed a new approach for\nclassifying document types using supervised machine learning based exclusively\non text specific features. We achieve 0.96 F1-score using the random forest and\nAdaboost classifiers, which are the best performing models on our data. By\nanalysing the SR system logs of the CORE [1] digital library aggregator, we\nshow that users are an order of magnitude more likely to click on research\npapers and thesis than on slides. This suggests that using document types as a\nfeature for ranking/filtering SR results in digital libraries has the potential\nto improve user experience.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 14:08:23 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Charalampous", "Aristotelis", ""], ["Knoth", "Petr", ""]]}, {"id": "1707.04207", "submitter": "David Pride Mr", "authors": "David Pride, Petr Knoth", "title": "Incidental or influential? - Challenges in automatically detecting\n  citation importance using publication full texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work looks in depth at several studies that have attempted to automate\nthe process of citation importance classification based on the publications\nfull text. We analyse a range of features that have been previously used in\nthis task. Our experimental results confirm that the number of in text\nreferences are highly predictive of influence. Contrary to the work of\nValenzuela et al. we find abstract similarity one of the most predictive\nfeatures. Overall, we show that many of the features previously described in\nliterature are not particularly predictive. Consequently, we discuss challenges\nand potential improvements in the classification pipeline, provide a critical\nreview of the performance of individual features and address the importance of\nconstructing a large scale gold standard reference dataset.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 16:34:15 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Pride", "David", ""], ["Knoth", "Petr", ""]]}, {"id": "1707.04393", "submitter": "Nicolas Rougier", "authors": "Nicolas P. Rougier, Konrad Hinsen, Fr\\'ed\\'eric Alexandre, Thomas\n  Arildsen, Lorena Barba, Fabien C. Y. Benureau, C. Titus Brown, Pierre de\n  Buyl, Ozan Caglayan, Andrew P. Davison, Marc Andr\\'e Delsuc, Georgios\n  Detorakis, Alexandra K. Diem, Damien Drix, Pierre Enel, Beno\\^it Girard,\n  Olivia Guest, Matt G. Hall, Rafael Neto Henriques, Xavier Hinaut, Kamil S\n  Jaron, Mehdi Khamassi, Almar Klein, Tiina Manninen, Pietro Marchesi, Dan\n  McGlinn, Christoph Metzner, Owen L. Petchey, Hans Ekkehard Plesser,\n  Timoth\\'ee Poisot, Karthik Ram, Yoav Ram, Etienne Roesch, Cyrille Rossant,\n  Vahid Rostami, Aaron Shifman, Joseph Stachelek, Marcel Stimberg, Frank\n  Stollmeier, Federico Vaggi, Guillaume Viejo, Julien Vitay, Anya Vostinar,\n  Roman Yurchak, Tiziano Zito", "title": "Sustainable computational science: the ReScience initiative", "comments": "8 pages, 1 figure", "journal-ref": "PeerJ Computer Science 3:e142 (2017)", "doi": "10.7717/peerj-cs.142", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer science offers a large set of tools for prototyping, writing,\nrunning, testing, validating, sharing and reproducing results, however\ncomputational science lags behind. In the best case, authors may provide their\nsource code as a compressed archive and they may feel confident their research\nis reproducible. But this is not exactly true. James Buckheit and David Donoho\nproposed more than two decades ago that an article about computational results\nis advertising, not scholarship. The actual scholarship is the full software\nenvironment, code, and data that produced the result. This implies new\nworkflows, in particular in peer-reviews. Existing journals have been slow to\nadapt: source codes are rarely requested, hardly ever actually executed to\ncheck that they produce the results advertised in the article. ReScience is a\npeer-reviewed journal that targets computational research and encourages the\nexplicit replication of already published research, promoting new and\nopen-source implementations in order to ensure that the original research can\nbe replicated from its description. To achieve this goal, the whole publishing\nchain is radically different from other traditional scientific journals.\nReScience resides on GitHub where each new implementation of a computational\nstudy is made available together with comments, explanations, and software\ntests.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 06:14:54 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 07:56:07 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Rougier", "Nicolas P.", ""], ["Hinsen", "Konrad", ""], ["Alexandre", "Fr\u00e9d\u00e9ric", ""], ["Arildsen", "Thomas", ""], ["Barba", "Lorena", ""], ["Benureau", "Fabien C. Y.", ""], ["Brown", "C. Titus", ""], ["de Buyl", "Pierre", ""], ["Caglayan", "Ozan", ""], ["Davison", "Andrew P.", ""], ["Delsuc", "Marc Andr\u00e9", ""], ["Detorakis", "Georgios", ""], ["Diem", "Alexandra K.", ""], ["Drix", "Damien", ""], ["Enel", "Pierre", ""], ["Girard", "Beno\u00eet", ""], ["Guest", "Olivia", ""], ["Hall", "Matt G.", ""], ["Henriques", "Rafael Neto", ""], ["Hinaut", "Xavier", ""], ["Jaron", "Kamil S", ""], ["Khamassi", "Mehdi", ""], ["Klein", "Almar", ""], ["Manninen", "Tiina", ""], ["Marchesi", "Pietro", ""], ["McGlinn", "Dan", ""], ["Metzner", "Christoph", ""], ["Petchey", "Owen L.", ""], ["Plesser", "Hans Ekkehard", ""], ["Poisot", "Timoth\u00e9e", ""], ["Ram", "Karthik", ""], ["Ram", "Yoav", ""], ["Roesch", "Etienne", ""], ["Rossant", "Cyrille", ""], ["Rostami", "Vahid", ""], ["Shifman", "Aaron", ""], ["Stachelek", "Joseph", ""], ["Stimberg", "Marcel", ""], ["Stollmeier", "Frank", ""], ["Vaggi", "Federico", ""], ["Viejo", "Guillaume", ""], ["Vitay", "Julien", ""], ["Vostinar", "Anya", ""], ["Yurchak", "Roman", ""], ["Zito", "Tiziano", ""]]}, {"id": "1707.04439", "submitter": "David Stuart Dr", "authors": "Mercedes Echeverria, David Stuart, Tobias Blanke", "title": "Medical Theses and Derivative Articles: Dissemination Of Contents and\n  Publication Patterns", "comments": null, "journal-ref": "Scientometrics (2015) 102: 559", "doi": "10.1007/s11192-014-1442-0", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doctoral theses are an important source of publication in universities,\nalthough little research has been carried out on the publications resulting\nfrom theses, on so-called derivative articles. This study investigates how\nderivative articles can be identified through a text analysis based on the\nfull-text of a set of medical theses and the full-text of articles, with which\nthey shared authorship. The text similarity analysis methodology applied\nconsisted in exploiting the full-text articles according to organization of\nscientific discourse (IMRaD) using the TurnItIn plagiarism tool. The study\nfound that the text similarity rate in the Discussion section can be used to\ndiscriminate derivative articles from non-derivative articles. Additional\nfindings were: the first position of the thesis's author dominated in 85% of\nderivative articles, the participation of supervisors as coauthors occurred in\n100% of derivative articles, the authorship credit retained by the thesis's\nauthor was 42% in derivative articles, the number of coauthors by article was 5\nin derivative articles versus 6.4 coauthors, as average, in non-derivative\narticles and the time differential regarding the year of thesis completion\nshowed that 87.5% of derivative articles were published before or in the same\nyear of thesis completion.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 10:07:46 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Echeverria", "Mercedes", ""], ["Stuart", "David", ""], ["Blanke", "Tobias", ""]]}, {"id": "1707.05731", "submitter": "Dai-Hai Ton That", "authors": "Dai Hai Ton That, Gabriel Fils, Zhihao Yuan, Tanu Malik", "title": "Sciunits: Reusable Research Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Science is conducted collaboratively, often requiring knowledge sharing about\ncomputational experiments. When experiments include only datasets, they can be\nshared using Uniform Resource Identifiers (URIs) or Digital Object Identifiers\n(DOIs). An experiment, however, seldom includes only datasets, but more often\nincludes software, its past execution, provenance, and associated\ndocumentation. The Research Object has recently emerged as a comprehensive and\nsystematic method for aggregation and identification of diverse elements of\ncomputational experiments. While a necessary method, mere aggregation is not\nsufficient for the sharing of computational experiments. Other users must be\nable to easily recompute on these shared research objects. In this paper, we\npresent the sciunit, a reusable research object in which aggregated content is\nrecomputable. We describe a Git-like client that efficiently creates, stores,\nand repeats sciunits. We show through analysis that sciunits repeat\ncomputational experiments with minimal storage and processing overhead.\nFinally, we provide an overview of sharing and reproducible cyberinfrastructure\nbased on sciunits gaining adoption in the domain of geosciences.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 16:32:16 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 14:32:55 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["That", "Dai Hai Ton", ""], ["Fils", "Gabriel", ""], ["Yuan", "Zhihao", ""], ["Malik", "Tanu", ""]]}, {"id": "1707.05801", "submitter": "Dimitrios Katsaros", "authors": "Dimitrios Katsaros and Yannis Manolopoulos", "title": "Impact and Productivity of PhD Graduates of Computer Science/Engineering\n  Departments of Hellenic Universities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an anatomy of PhD programmes in Hellenic universities'\ndepartments of computer science/engineering from the perspective of research\nproductivity and impact. The study aims at showing the dynamics of research\nconducted in computer science/engineering departments, and after recognizing\nweaknesses, to motivate the stakeholders to take actions that will improve\ncompetition and excellence. Beneficiaries of this investigation are the\nfollowing entities: a) the departments themselves can assess their performance\nrelative to that of other departments and then set strategic goals and design\nprocedures to achieve them, b) supervisors can assess the part of their\nresearch conducted with PhDs and set their own goals, c) former PhDs who can\nidentify their relative success, and finally d) prospective PhD students who\ncan consider the efficacy of departments and supervisors in conducting\nhigh-impact research as one more significant factor in designing the doctoral\nstudies they will follow.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 18:11:38 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Katsaros", "Dimitrios", ""], ["Manolopoulos", "Yannis", ""]]}, {"id": "1707.06070", "submitter": "Nicolas Robinson-Garcia", "authors": "Nicolas Robinson-Garcia, Philippe Mongeon, Wei Jeng and Rodrigo Costas", "title": "DataCite as a novel bibliometric source: Coverage, strengths and\n  limitations", "comments": "Paper accepted for publication in Journal of Informetrics", "journal-ref": "Journal of Informetrics, 11(3), 841-854 (2017)", "doi": "10.1016/j.joi.2017.07.003", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the characteristics of DataCite to determine its\npossibilities and potential as a new bibliometric data source to analyze the\nscholarly production of open data. Open science and the increasing data sharing\nrequirements from governments, funding bodies, institutions and scientific\njournals has led to a pressing demand for the development of data metrics. As a\nvery first step towards reliable data metrics, we need to better comprehend the\nlimitations and caveats of the information provided by sources of open data. In\nthis paper, we critically examine records downloaded from the DataCite's OAI\nAPI and elaborate a series of recommendations regarding the use of this source\nfor bibliometric analyses of open data. We highlight issues related to metadata\nincompleteness, lack of standardization, and ambiguous definitions of several\nfields. Despite these limitations, we emphasize DataCite's value and potential\nto become one of the main sources for data metrics development.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 13:14:44 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Robinson-Garcia", "Nicolas", ""], ["Mongeon", "Philippe", ""], ["Jeng", "Wei", ""], ["Costas", "Rodrigo", ""]]}, {"id": "1707.06336", "submitter": "Patricio Domingues", "authors": "Carlos Andr\\'e Rosa, Olga Craveiro and Patricio Domingues", "title": "Open Source Software for Digital Preservation Repositories: a Survey", "comments": "http://airccse.org/journal/ijcses/", "journal-ref": "International Journal of Computer Science & Engineering Survey\n  (IJCSES) Vol.8, No.3, June 2017", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the digital age, the amount of data produced is growing exponentially.\nGovernments and institutions can no longer rely on old methods for storing data\nand passing on the knowledge to future generations. Digital data preservation\nis a mandatory issue that needs proper strategies and tools. With this\nawareness, efforts are being made to create and perfect software solutions\ncapable of responding to the challenge of properly preserving digital\ninformation. This paper focuses on the state-of-the-art in open-source software\nsolutions for the digital preservation and curation field used to assimilate\nand disseminate information to designated audiences. Eleven open source\nprojects for digital preservation are surveyed in areas such as supported\nstandards and protocols, strategies for preservation, methodologies for\nreporting, dynamic of development, targeted operating systems, multilingual\nsupport and open source license. Furthermore, five of these open source\nprojects, are further analysed, with focus on features deemed important for the\narea. Along open source solutions, the paper also briefly surveys the standards\nand protocols relevant for digital data preservation. The area of digital data\npreservation repositories has several open source solutions, which can form the\nbase to overcome the challenges to reach mature and reliable digital data\npreservation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 01:46:20 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Rosa", "Carlos Andr\u00e9", ""], ["Craveiro", "Olga", ""], ["Domingues", "Patricio", ""]]}, {"id": "1707.06643", "submitter": "Boyang Li", "authors": "Ng Annalyn, Maarten W. Bos, Leonid Sigal, and Boyang Li", "title": "Predicting Personality from Book Preferences with User-Generated Content\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychological studies have shown that personality traits are associated with\nbook preferences. However, past findings are based on questionnaires focusing\non conventional book genres and are unrepresentative of niche content. For a\nmore comprehensive measure of book content, this study harnesses a massive\narchive of content labels, also known as 'tags', created by users of an online\nbook catalogue, Goodreads.com. Combined with data on preferences and\npersonality scores collected from Facebook users, the tag labels achieve high\naccuracy in personality prediction by psychological standards. We also group\ntags into broader genres, to check their validity against past findings. Our\nresults are robust across both tag and genre levels of analyses, and consistent\nwith existing literature. Moreover, user-generated tag labels reveal unexpected\ninsights, such as cultural differences, book reading behaviors, and other\nnon-content factors affecting preferences. To our knowledge, this is currently\nthe largest study that explores the relationship between personality and book\ncontent preferences.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 19:41:01 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Annalyn", "Ng", ""], ["Bos", "Maarten W.", ""], ["Sigal", "Leonid", ""], ["Li", "Boyang", ""]]}, {"id": "1707.06675", "submitter": "Nicolas Robinson-Garcia", "authors": "Nicolas Robinson-Garcia, Rakshit Trivedi, Rodrigo Costas, Kimberley\n  Isett, Julia Melkers and Diana Hicks", "title": "Tweeting about journal articles: Engagement, marketing or just\n  gibberish?", "comments": "Paper accepted for oral presentation at the STI 2017 Conference held\n  in Paris (France)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents preliminary results on the analysis of tweets to journal\narticles in the field of Dentistry. We present two case studies in which we\ncritically examine the contents and context that motivate the tweeting of\njournal articles. We then focus on a specific aspect, the role played by\njournals on self-promoting their contents and the effect this has on the total\nnumber of tweets their papers produce. In a context where many are pushing to\nthe use of altmetrics as an alternative or complement to traditional\nbibliometric indicators. We find a lack of evidence (and interest) on\ncritically examining the many claims that are being made as to their capability\nto trace evidences of 'broader forms of impact'. Our first results are not\npromising and question current approaches being made in the field of\naltmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 18:55:16 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Robinson-Garcia", "Nicolas", ""], ["Trivedi", "Rakshit", ""], ["Costas", "Rodrigo", ""], ["Isett", "Kimberley", ""], ["Melkers", "Julia", ""], ["Hicks", "Diana", ""]]}, {"id": "1707.06684", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Henry Z. Lo", "title": "ShortScience.org - Reproducing Intuition", "comments": "To appear in International Conference on Machine Learning 2017\n  Workshop on Reproducibility in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ShortScience.org, a platform for post-publication discussion of\nresearch papers. On ShortScience.org, the research community can read and write\nsummaries of papers in order to increase accessible and reproducibility.\nSummaries contain the perspective and insight of other readers, why they liked\nor disliked it, and their attempt to demystify complicated sections.\nShortScience.org has over 600 paper summaries, all of which are searchable and\norganized by paper, conference, and year. Many regular contributors are expert\nmachine learning researchers. We present statistics from the last year of\noperation, user demographics, and responses from a usage survey. Results\nindicate that ShortScience benefits students most, by providing short,\nunderstandable summaries reflecting expert opinions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 19:24:37 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Lo", "Henry Z.", ""]]}, {"id": "1707.06822", "submitter": "Alberto Baccini", "authors": "Alberto Baccini, Giuseppe De Nicolao", "title": "Errors and secret data in the Italian research assessment exercise. A\n  comment to a reply", "comments": "9 pages, 5 tables", "journal-ref": "RT. A Journal on Research Policy and Evaluation 1 (2017) 1-11", "doi": "10.13130/2282-5398/8872", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Italy adopted a performance-based system for funding universities that is\ncentered on the results of a national research assessment exercise, realized by\na governmental agency (ANVUR). ANVUR evaluated papers by using 'a dual system\nof evaluation', that is by informed peer review or by bibliometrics. In view of\nvalidating that system, ANVUR performed an experiment for estimating the\nagreement between informed review and bibliometrics. Ancaiani et al. (2015)\npresents the main results of the experiment. Baccini and De Nicolao (2017)\ndocumented in a letter, among other critical issues, that the statistical\nanalysis was not realized on a random sample of articles. A reply to the letter\nhas been published by Research Evaluation (Benedetto et al. 2017). This note\nhighlights that in the reply there are (1) errors in data, (2) problems with\n'representativeness' of the sample, (3) unverifiable claims about weights used\nfor calculating kappas, (4) undisclosed averaging procedures; (5) a statement\nabout 'same protocol in all areas' contradicted by official reports. Last but\nnot least: the data used by the authors continue to be undisclosed. A general\nwarning concludes: many recently published papers use data originating from\nItalian research assessment exercise. These data are not accessible to the\nscientific community and consequently these papers are not reproducible. They\ncan be hardly considered as containing sound evidence at least until authors or\nANVUR disclose the data necessary for replication.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 10:07:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Baccini", "Alberto", ""], ["De Nicolao", "Giuseppe", ""]]}, {"id": "1707.06937", "submitter": "Kathleen Gregory", "authors": "Kathleen Gregory, Paul Groth, Helena Cousijn, Andrea Scharnhorst,\n  Sally Wyatt", "title": "Searching Data: A Review of Observational Data Retrieval Practices in\n  Selected Disciplines", "comments": null, "journal-ref": "Journal of the Association for Information Science and Technology.\n  (2019). 70(5), 419-432", "doi": "10.1002/asi.24165", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cross-disciplinary examination of the user behaviours involved in seeking\nand evaluating data is surprisingly absent from the research data discussion.\nThis review explores the data retrieval literature to identify commonalities in\nhow users search for and evaluate observational research data. Two analytical\nframeworks rooted in information retrieval and science technology studies are\nused to identify key similarities in practices as a first step toward\ndeveloping a model describing data retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 15:36:10 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 12:51:08 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 14:43:24 GMT"}, {"version": "v4", "created": "Thu, 12 Mar 2020 09:07:40 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Gregory", "Kathleen", ""], ["Groth", "Paul", ""], ["Cousijn", "Helena", ""], ["Scharnhorst", "Andrea", ""], ["Wyatt", "Sally", ""]]}, {"id": "1707.07029", "submitter": "Claudio Gutierrez", "authors": "Claudio Gutierrez", "title": "Data, Science and Society", "comments": "Notes for a talk at LEARN Final Conference, Economic Commission for\n  Latin America and the Caribbean (ECLAC), Senate House, University of London,\n  London, May 5th., 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reflections on the Concept of Data and its Implications for Science and\nSociety\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 19:34:44 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Gutierrez", "Claudio", ""]]}, {"id": "1707.07678", "submitter": "Tobias Kuhn", "authors": "Tom Jansen and Tobias Kuhn", "title": "Extracting Core Claims from Scientific Articles", "comments": "In Post-proceedings of the 28th Benelux Conference on Artificial\n  Intelligence (BNAIC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of scientific articles has grown rapidly over the years and there\nare no signs that this growth will slow down in the near future. Because of\nthis, it becomes increasingly difficult to keep up with the latest developments\nin a scientific field. To address this problem, we present here an approach to\nhelp researchers learn about the latest developments and findings by extracting\nin a normalized form core claims from scientific articles. This normalized\nrepresentation is a controlled natural language of English sentences called\nAIDA, which has been proposed in previous work as a method to formally\nstructure and organize scientific findings and discourse. We show how such AIDA\nsentences can be automatically extracted by detecting the core claim of an\narticle, checking for AIDA compliance, and - if necessary - transforming it\ninto a compliant sentence. While our algorithm is still far from perfect, our\nresults indicate that the different steps are feasible and they support the\nclaim that AIDA sentences might be a promising approach to improve scientific\ncommunication in the future.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 15:10:40 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Jansen", "Tom", ""], ["Kuhn", "Tobias", ""]]}, {"id": "1707.09217", "submitter": "Gerhard Gossen", "authors": "Gerhard Gossen and Elena Demidova and Thomas Risse", "title": "Extracting Event-Centric Document Collections from Large-Scale Web\n  Archives", "comments": "To be published in the proceedings of the Conference on Theory and\n  Practice of Digital Libraries (TPDL) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web archives are typically very broad in scope and extremely large in scale.\nThis makes data analysis appear daunting, especially for non-computer\nscientists. These collections constitute an increasingly important source for\nresearchers in the social sciences, the historical sciences and journalists\ninterested in studying past events. However, there are currently no access\nmethods that help users to efficiently access information, in particular about\nspecific events, beyond the retrieval of individual disconnected documents.\nTherefore we propose a novel method to extract event-centric document\ncollections from large scale Web archives. This method relies on a specialized\nfocused extraction algorithm. Our experiments on the German Web archive\n(covering a time period of 19 years) demonstrate that our method enables the\nextraction of event-centric collections for different event types.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 13:18:01 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Gossen", "Gerhard", ""], ["Demidova", "Elena", ""], ["Risse", "Thomas", ""]]}, {"id": "1707.09955", "submitter": "Michael J. Kurtz", "authors": "Michael J. Kurtz", "title": "Comparing People with Bibliometrics", "comments": "to appear in Proceedings of Library and Information Science in\n  Astronomy VIII (LISA-8)", "journal-ref": null, "doi": "10.1051/epjconf/201818606004", "report-no": null, "categories": "physics.soc-ph astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bibliometric indicators, citation counts and/or download counts are\nincreasingly being used to inform personnel decisions such as hiring or\npromotions. These statistics are very often misused. Here we provide a guide to\nthe factors which should be considered when using these so-called quantitative\nmeasures to evaluate people. Rules of thumb are given for when begin to use\nbibliometric measures when comparing otherwise similar candidates.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 17:01:44 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Kurtz", "Michael J.", ""]]}]