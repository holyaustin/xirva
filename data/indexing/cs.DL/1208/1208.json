[{"id": "1208.0259", "submitter": "Pedro Hipola", "authors": "Antonio Munoz-Canavate, Pedro Hipola", "title": "Electronic administration in Spain: from its beginnings to the present", "comments": null, "journal-ref": "Government Information Quarterly, vol 28, 1, January 2011, pp.\n  74-90", "doi": "10.1016/j.giq.2010.05.008", "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents the basic lines of electronic administration in Spain.\nThe complexity of the Spanish political-administrative system makes such a\nstudy challenging, in view of the considerable degree of autonomy and\ncompetences of the regional administrative bodies and local agencies with\nrespect to the central government, the former being more visible in the 17\nregions of Spain. Nonetheless, the central government maintains a series of\nlegal instruments that allow a certain common framework of action to be\nimposed, aside from what is put into effect through diverse programs aimed\nprecisely to develop common tools for the regions and municipalities of Spain.\n  After an introduction that provides some necessary background, this study\ndescribes the legislative framework in which Spain's electronic administrative\nsystem has developed. The data included in the study refer to investment in\ninformation and communication technologies (ICT) and the services offered by\nthe different Administrations on the internet; internet access by citizens,\nhomes, businesses, and employees, as well as the interactivity existing with\nadministrations by means of the internet; the origins and rise of various\npolitical initiatives of the Central Government involving electronic\nadministration; and finally, the situation of civil service personnel, as\ncatalysts of the success of Information Society in the Public Administration\nwithin Spain.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 16:02:35 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Munoz-Canavate", "Antonio", ""], ["Hipola", "Pedro", ""]]}, {"id": "1208.0293", "submitter": "Christoph Lange", "authors": "Christoph Lange and Till Mossakowski and Oliver Kutz and Christian\n  Galinski and Michael Gr\\\"uninger and Daniel Couto Vale", "title": "The Distributed Ontology Language (DOL): Use Cases, Syntax, and\n  Extensibility", "comments": "Terminology and Knowledge Engineering Conference (TKE) 2012-06-20 to\n  2012-06-21 Madrid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Distributed Ontology Language (DOL) is currently being standardized\nwithin the OntoIOp (Ontology Integration and Interoperability) activity of\nISO/TC 37/SC 3. It aims at providing a unified framework for (1) ontologies\nformalized in heterogeneous logics, (2) modular ontologies, (3) links between\nontologies, and (4) annotation of ontologies. This paper presents the current\nstate of DOL's standardization. It focuses on use cases where distributed\nontologies enable interoperability and reusability. We demonstrate relevant\nfeatures of the DOL syntax and semantics and explain how these integrate into\nexisting knowledge engineering environments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 17:25:24 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Lange", "Christoph", ""], ["Mossakowski", "Till", ""], ["Kutz", "Oliver", ""], ["Galinski", "Christian", ""], ["Gr\u00fcninger", "Michael", ""], ["Vale", "Daniel Couto", ""]]}, {"id": "1208.0359", "submitter": "Pedro Hipola", "authors": "Amed Leiva-Mederos, Jose A. Senso, Sandor Dominguez-Velasco, Pedro\n  Hipola", "title": "An Automat for the Semantic Processing of Structured Information", "comments": "IEEE Intelligent Systems Design and Applications, 2009. ISDA '09.\n  Ninth International Conference on Date of Conference: Nov. 30 2009-Dec. 2\n  2009, Page(s): 85 - 89", "journal-ref": "IEEE Intelligent Systems Design and Applications, 2009. ISDA '09.\n  Ninth International Conference on Date of Conference: Nov. 30 2009-Dec. 2\n  2009, Page(s): 85 - 89", "doi": "10.1109/ISDA.2009.120", "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the database of the PuertoTerm project, an indexing system based on the\ncognitive model of Brigitte Enders was built. By analyzing the cognitive\nstrategies of three abstractors, we built an automat that serves to simulate\nhuman indexing processes. The automat allows the texts integrated in the system\nto be assessed, evaluated and grouped by means of the bipartite spectral graph\npartitioning algorithm, which also permits visualization of the terms and the\ndocuments. The system features an ontology and a database to enhance its\noperativity. As a result of the application, we achieved better rates of\nexhaustivity in the indexing of documents, as well as greater precision and\nretrieval of information, with high levels of efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 20:53:23 GMT"}], "update_date": "2012-08-03", "authors_parsed": [["Leiva-Mederos", "Amed", ""], ["Senso", "Jose A.", ""], ["Dominguez-Velasco", "Sandor", ""], ["Hipola", "Pedro", ""]]}, {"id": "1208.0690", "submitter": "Hamed Hassanzadeh", "authors": "Hamed Hassanzadeh and Mohammad Reza Keyvanpour", "title": "Semantic Web Requirements through Web Mining Techniques", "comments": "arXiv admin note: text overlap with arXiv:cs/0011033 by other authors", "journal-ref": "International Journal of Computer Theory and Engineering vol. 4,\n  no. 4, pp. 616-620, 2012", "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In recent years, Semantic web has become a topic of active research in\nseveral fields of computer science and has applied in a wide range of domains\nsuch as bioinformatics, life sciences, and knowledge management. The two\nfast-developing research areas semantic web and web mining can complement each\nother and their different techniques can be used jointly or separately to solve\nthe issues in both areas. In addition, since shifting from current web to\nsemantic web mainly depends on the enhancement of knowledge, web mining can\nplay a key role in facing numerous challenges of this changing. In this paper,\nwe analyze and classify the application of divers web mining techniques in\ndifferent challenges of the semantic web in form of an analytical framework.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2012 08:42:07 GMT"}], "update_date": "2012-08-06", "authors_parsed": [["Hassanzadeh", "Hamed", ""], ["Keyvanpour", "Mohammad Reza", ""]]}, {"id": "1208.1349", "submitter": "Xianwen Wang", "authors": "Xianwen Wang, Zhi Wang, Shenmeng Xu", "title": "Tracing scientist's research trends realtimely", "comments": "13 pages, 7 figures", "journal-ref": "Scientometrics. 2013, 95(2): 717-729", "doi": "10.1007/s11192-012-0884-5", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we propose a method to trace scientists' research trends\nrealtimely. By monitoring the downloads of scientific articles in the journal\nof Scientometrics for 744 hours, namely one month, we investigate the download\nstatistics. Then we aggregate the keywords in these downloaded research papers,\nand analyze the trends of article downloading and keyword downloading.\nFurthermore, taking both the download of keywords and articles into\nconsideration, we design a method to detect the emerging research trends. We\nfind that in scientometrics field, social media, new indices to quantify\nscientific productivity (g-index), webometrics, semantic, text mining, open\naccess are emerging fields that scientometrics researchers are focusing on.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2012 07:08:21 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2012 05:36:34 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Wang", "Xianwen", ""], ["Wang", "Zhi", ""], ["Xu", "Shenmeng", ""]]}, {"id": "1208.2686", "submitter": "Xianwen Wang", "authors": "Xianwen Wang, Shenmeng Xu, Lian Peng, Zhi Wang, Chuanli Wang, Chunbo\n  Zhang, Xianbing Wang", "title": "Exploring scientists' working timetable: Do scientists often work\n  overtime?", "comments": "9 pages, 5 figures", "journal-ref": "Journal of Informetrics. 2012, 6(4): 655-660", "doi": "10.1016/j.joi.2012.07.003", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method is proposed to monitor and record scientists' working\ntimetable. We record the downloads information of scientific papers real-timely\nfrom Springer round the clock, and try to explore scientists' working habits.\nAs our observation demonstrates, many scientists are still engaged in their\nresearch after working hours every day. Many of them work far into the night,\neven till next morning. In addition, research work also intrudes into their\nweekends. Different working time patterns are revealed. In the US, overnight\nwork is more prevalent among scientists, while Chinese scientists mostly have\nbusy weekends with their scientific research.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 13:36:31 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Wang", "Xianwen", ""], ["Xu", "Shenmeng", ""], ["Peng", "Lian", ""], ["Wang", "Zhi", ""], ["Wang", "Chuanli", ""], ["Zhang", "Chunbo", ""], ["Wang", "Xianbing", ""]]}, {"id": "1208.3101", "submitter": "Artjay Javier", "authors": "F. G. Serpa, Adam M. Graves and Artjay Javier", "title": "Statistical Common Author Networks (SCAN)", "comments": "Accepted to JASIST (February 2013). Copyright 2013 American Society\n  of Information Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for visualizing the relatedness of scientific areas is developed\nthat is based on measuring the overlap of researchers between areas. It is\nfound that closely related areas have a high propensity to share a larger\nnumber of common authors. A methodology for comparing areas of vastly different\nsizes and to handle name homonymy is constructed, allowing for the robust\ndeployment of this method on real data sets. A statistical analysis of the\nprobability distributions of the common author overlap that accounts for noise\nis carried out along with the production of network maps with weighted links\nproportional to the overlap strength. This is demonstrated on two case studies,\ncomplexity science and neutrino physics, where the level of relatedness of\nareas within each area is expected to vary greatly. It is found that the\nresults returned by this method closely match the intuitive expectation that\nthe broad, multidisciplinary area of complexity science possesses areas that\nare weakly related to each other while the much narrower area of neutrino\nphysics shows very strongly related areas.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 12:11:07 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 19:45:23 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Serpa", "F. G.", ""], ["Graves", "Adam M.", ""], ["Javier", "Artjay", ""]]}, {"id": "1208.3391", "submitter": "Simina Br\\^anzei", "authors": "Margareta Ackerman and Simina Br\\^anzei", "title": "The Authorship Dilemma: Alphabetical or Contribution?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific communities have adopted different conventions for ordering\nauthors on publications. Are these choices inconsequential, or do they have\nsignificant influence on individual authors, the quality of the projects\ncompleted, and research communities at large? What are the trade-offs of using\none convention over another? In order to investigate these questions, we\nformulate a basic two-player game theoretic model, which already illustrates\ninteresting phenomena that can occur in more realistic settings.\n  We find that alphabetical ordering can improve research quality, while\ncontribution-based ordering leads to a denser collaboration network and a\ngreater number of publications. Contrary to the assumption that free riding is\na weakness of the alphabetical ordering scheme, this phenomenon can occur under\nany contribution scheme, and the worst case occurs under contribution-based\nordering. Finally, we show how authors working on multiple projects can\ncooperate to attain optimal research quality and eliminate free riding given\neither contribution scheme.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2012 15:10:10 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 17:55:58 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Ackerman", "Margareta", ""], ["Br\u00e2nzei", "Simina", ""]]}, {"id": "1208.3530", "submitter": "Haimonti Dutta", "authors": "Haimonti Dutta, William Chan, Deepak Shankargouda, Manoj Pooleery,\n  Axinia Radeva, Kyle Rego, Boyi Xie, Rebecca Passonneau, Austin Lee and\n  Barbara Taranto", "title": "Leveraging Subjective Human Annotation for Clustering Historic Newspaper\n  Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The New York Public Library is participating in the Chronicling America\ninitiative to develop an online searchable database of historically significant\nnewspaper articles. Microfilm copies of the newspapers are scanned and high\nresolution Optical Character Recognition (OCR) software is run on them. The\ntext from the OCR provides a wealth of data and opinion for researchers and\nhistorians. However, categorization of articles provided by the OCR engine is\nrudimentary and a large number of the articles are labeled editorial without\nfurther grouping. Manually sorting articles into fine-grained categories is\ntime consuming if not impossible given the size of the corpus. This paper\nstudies techniques for automatic categorization of newspaper articles so as to\nenhance search and retrieval on the archive. We explore unsupervised (e.g.\nKMeans) and semi-supervised (e.g. constrained clustering) learning algorithms\nto develop article categorization schemes geared towards the needs of\nend-users. A pilot study was designed to understand whether there was unanimous\nagreement amongst patrons regarding how articles can be categorized. It was\nfound that the task was very subjective and consequently automated algorithms\nthat could deal with subjective labels were used. While the small scale pilot\nstudy was extremely helpful in designing machine learning algorithms, a much\nlarger system needs to be developed to collect annotations from users of the\narchive. The \"BODHI\" system currently being developed is a step in that\ndirection, allowing users to correct wrongly scanned OCR and providing keywords\nand tags for newspaper articles used frequently. On successful implementation\nof the beta version of this system, we hope that it can be integrated with\nexisting software being developed for the Chronicling America project.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2012 04:48:58 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Dutta", "Haimonti", ""], ["Chan", "William", ""], ["Shankargouda", "Deepak", ""], ["Pooleery", "Manoj", ""], ["Radeva", "Axinia", ""], ["Rego", "Kyle", ""], ["Xie", "Boyi", ""], ["Passonneau", "Rebecca", ""], ["Lee", "Austin", ""], ["Taranto", "Barbara", ""]]}, {"id": "1208.4566", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff and Sta\\v{s}a Milojevi\\'c", "title": "Scientometrics", "comments": "The International Encyclopedia of Social and Behavioral Sciences,\n  Section 8.5: Science and Technology Studies, Subsection 85030, 2nd Edition.\n  James D. Wright, Michael Lynch et al. (Eds.). Oxford, UK, etc.: Elsevier,\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides an overview of the field of scientometrics, that is: the\nstudy of science, technology, and innovation from a quantitative perspective.\nWe cover major historical milestones in the development of this specialism from\nthe 1960s to today and discuss its relationship with the sociology of\nscientific knowledge, the library and information sciences, and science policy\nissues such as indicator development. The disciplinary organization of\nscientometrics is analyzed both conceptually and empirically, using a map of\njournals cited in the core journal of the field, entitled Scientometrics. A\nstate-of-the-art review of five major research threads is provided: (1) the\nmeasurement of impact; (2) the delineation of reference sets; (3) theories of\ncitation; (4) mapping science; and (5) the policy and management contexts of\nindicator developments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2012 17:37:57 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2013 09:35:23 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Leydesdorff", "Loet", ""], ["Milojevi\u0107", "Sta\u0161a", ""]]}, {"id": "1208.6122", "submitter": "Ludo Waltman", "authors": "Ludo Waltman and Nees Jan van Eck", "title": "Source normalized indicators of citation impact: An overview of\n  different approaches and an empirical comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different scientific fields have different citation practices. Citation-based\nbibliometric indicators need to normalize for such differences between fields\nin order to allow for meaningful between-field comparisons of citation impact.\nTraditionally, normalization for field differences has usually been done based\non a field classification system. In this approach, each publication belongs to\none or more fields and the citation impact of a publication is calculated\nrelative to the other publications in the same field. Recently, the idea of\nsource normalization was introduced, which offers an alternative approach to\nnormalize for field differences. In this approach, normalization is done by\nlooking at the referencing behavior of citing publications or citing journals.\nIn this paper, we provide an overview of a number of source normalization\napproaches and we empirically compare these approaches with a traditional\nnormalization approach based on a field classification system. We also pay\nattention to the issue of the selection of the journals to be included in a\nnormalization for field differences. Our analysis indicates a number of\nproblems of the traditional classification-system-based normalization approach,\nsuggesting that source normalization approaches may yield more accurate\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2012 10:02:34 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2012 03:32:21 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Waltman", "Ludo", ""], ["van Eck", "Nees Jan", ""]]}]