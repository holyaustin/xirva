[{"id": "1802.00552", "submitter": "Lior Shamir", "authors": "Lior Shamir, Bruce Berriman, Peter Teuben, Robert Nemiroff, Alice\n  Allen", "title": "Best Practices for a Future Open Code Policy: Experiences and Vision of\n  the Astrophysics Source Code Library", "comments": "White paper submitted to the National Academies of Sciences,\n  Engineering, and Medicine's Best Practices for a Future Open Code Policy for\n  NASA Space Science Project Committee", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are members of the Astrophysics Source Code Library's Advisory Committee\nand its editor-in-chief. The Astrophysics Source Code Library (ASCL, ascl.net)\nis a successful initiative that advocates for open research software and\nprovides an infrastructure for registering, discovering, sharing, and citing\nthis software. Started in 1999, the ASCL has been expanding in recent years,\nwith an average of over 200 codes added each year, and now houses over 1,600\ncode entries.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 04:06:51 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Shamir", "Lior", ""], ["Berriman", "Bruce", ""], ["Teuben", "Peter", ""], ["Nemiroff", "Robert", ""], ["Allen", "Alice", ""]]}, {"id": "1802.00606", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Robin Haunschild", "title": "Allegation of scientific misconduct increases Twitter attention", "comments": null, "journal-ref": "Scientometrics, 115(2), 1097-1100 (2018)", "doi": "10.1007/s11192-018-2698-6", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web-based microblogging system Twitter is a very popular altmetrics\nsource for measuring the broader impact of science. In this case study, we\ndemonstrate how problematic the use of Twitter data for research evaluation can\nbe, even though the aspiration of measurement is degraded from impact to\nattention measurement. We collected the Twitter data for the paper published by\nYamamizu et al. (2017). An investigative committee found that the main figures\nin the paper are fraudulent.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 09:01:09 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""]]}, {"id": "1802.00983", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Jonathan Adams, Loet Leydesdorff", "title": "The negative effects of citing with a national orientation in terms of\n  recognition: national and international citations in natural-sciences papers\n  from Germany, the Netherlands, and the UK", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nations can be distinguished in terms of whether domestic or international\nresearch is cited. We analyzed the research output in natural sciences of three\nleading European research economies (Germany, the Netherlands, and the UK) and\nask where their researchers look for the knowledge that underpins their most\nhighly-cited papers. Is one internationally oriented or is citation limited to\nnational resources? Do the citation patterns reflect a growing differentiation\nbetween the domestic and international research enterprise? To evaluate change\nover time, we include natural-sciences papers published in the countries from\nthree publication years: 2004, 2009, and 2014. The results show that articles\nco-authored by researchers from Germany or the Netherlands are less likely to\nbe among the globally most highly-cited articles if they also cite \"domestic\"\nresearch (i.e. research authored by authors from the same country). To put this\nanother way, less well-cited research is more likely to stand on domestic\nshoulders and research that becomes more highly-cited is more likely to stand\non international shoulders. A possible reason for the results is that\nresearchers \"over-cite\" the papers from their own country - lacking the focus\non quality in citing. However, these differences between domestic and\ninternational shoulders are not visible for the UK.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 14:48:00 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 07:10:04 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Bornmann", "Lutz", ""], ["Adams", "Jonathan", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1802.01168", "submitter": "Dominika Tkaczyk", "authors": "Dominika Tkaczyk, Andrew Collins, Paraic Sheridan, Joeran Beel", "title": "Machine Learning vs. Rules and Out-of-the-Box vs. Retrained: An\n  Evaluation of Open-Source Bibliographic Reference and Citation Parsers", "comments": "to appear in Proceedings of Joint Conference on Digital Libraries\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bibliographic reference parsing refers to extracting machine-readable\nmetadata, such as the names of the authors, the title, or journal name, from\nbibliographic reference strings. Many approaches to this problem have been\nproposed so far, including regular expressions, knowledge bases and supervised\nmachine learning. Many open source reference parsers based on various\nalgorithms are also available. In this paper, we apply, evaluate and compare\nten reference parsing tools in a specific business use case. The tools are\nAnystyle-Parser, Biblio, CERMINE, Citation, Citation-Parser, GROBID, ParsCit,\nPDFSSA4MET, Reference Tagger and Science Parse, and we compare them in both\ntheir out-of-the-box versions and versions tuned to the project-specific data.\nAccording to our evaluation, the best performing out-of-the-box tool is GROBID\n(F1 0.89), followed by CERMINE (F1 0.83) and ParsCit (F1 0.75). We also found\nthat even though machine learning-based tools and tools based on rules or\nregular expressions achieve on average similar precision (0.77 for ML-based\ntools vs. 0.76 for non-ML-based tools), applying machine learning-based tools\nresults in a recall three times higher than in the case of non-ML-based tools\n(0.66 vs. 0.22). Our study also confirms that tuning the models to the\ntask-specific data results in the increase in the quality. The retrained\nversions of reference parsers are in all cases better than their out-of-the-box\ncounterparts; for GROBID F1 increased by 3% (0.92 vs. 0.89), for CERMINE by 11%\n(0.92 vs. 0.83), and for ParsCit by 16% (0.87 vs. 0.75).\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 18:01:00 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 10:44:33 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 10:26:32 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Tkaczyk", "Dominika", ""], ["Collins", "Andrew", ""], ["Sheridan", "Paraic", ""], ["Beel", "Joeran", ""]]}, {"id": "1802.01174", "submitter": "Dominika Tkaczyk", "authors": "Dominika Tkaczyk, Andrew Collins, Joeran Beel", "title": "A Method for Discovering and Extracting Author Contributions Information\n  from Scientific Biomedical Publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating scientific publications is a complex process, typically composed of\na number of different activities, such as designing the experiments, data\npreparation, programming software and writing and editing the manuscript. The\ninformation about the contributions of individual authors of a paper is\nimportant in the context of assessing authors' scientific achievements. Some\npublications in biomedical disciplines contain a description of authors' roles\nin the form of a short section written in natural language, typically entitled\n\"Authors' contributions\". In this paper, we present an analysis of roles\ncommonly appearing in the content of these sections, and propose an algorithm\nfor automatic extraction of authors' roles from natural language text in\nscientific publications. During the first part of the study, we used clustering\ntechniques, as well as Open Information Extraction (OpenIE), to\nsemi-automatically discover the most popular roles within a corpus of 2,000\ncontributions sections obtained from PubMed Central resources. The roles\ndiscovered by our approach include: experimenting (1,743 instances, 17% of the\nentire role set within the corpus), analysis (1,343, 16%), study design (1,132,\n13%), interpretation (879, 10%), conceptualization (865, 10%), paper reading\n(823, 10%), paper writing (724, 8%), paper review (501, 6%), paper drafting\n(351, 4%), coordination (319, 4%), data collection (76, 1%), paper review (41,\n0.5%) and literature review (41, 0.5%). Discovered roles were then used to\nautomatically build a training set for the supervised role extractor, based on\nNaive Bayes algorithm. According to the evaluation we performed, the proposed\nrole extraction algorithm is able to extract the roles from the text with\nprecision 0.71, recall 0.49 and F1 0.58.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 18:55:38 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Tkaczyk", "Dominika", ""], ["Collins", "Andrew", ""], ["Beel", "Joeran", ""]]}, {"id": "1802.01270", "submitter": "Misha Teplitskiy", "authors": "Misha Teplitskiy, Daniel Acuna, Aida Elamrani-Raoult, Konrad Kording,\n  James Evans", "title": "The Social Structure of Consensus in Scientific Review", "comments": null, "journal-ref": "Research Policy. 2018", "doi": "10.1016/j.respol.2018.06.014", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal connections between creators and evaluators of scientific works are\nubiquitous, and the possibility of bias ever-present. Although connections have\nbeen shown to bias prospective judgments of (uncertain) future performance, it\nis unknown whether such biases occur in the much more concrete task of\nassessing the scientific validity of already completed work, and if so, why.\nThis study presents evidence that personal connections between authors and\nreviewers of neuroscience manuscripts are associated with biased judgments and\nexplores the mechanisms driving the effect. Using reviews from 7,981\nneuroscience manuscripts submitted to the journal PLOS ONE, which instructs\nreviewers to evaluate manuscripts only on scientific validity, we find that\nreviewers favored authors close in the co-authorship network by ~0.11 points on\na 1.0 - 4.0 scale for each step of proximity. PLOS ONE's validity-focused\nreview and the substantial amount of favoritism shown by distant vs. very\ndistant reviewers, both of whom should have little to gain from nepotism, point\nto the central role of substantive disagreements between scientists in\ndifferent \"schools of thought.\" The results suggest that removing bias from\npeer review cannot be accomplished simply by recusing the closely-connected\nreviewers, and highlight the value of recruiting reviewers embedded in diverse\nprofessional networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 05:28:57 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Teplitskiy", "Misha", ""], ["Acuna", "Daniel", ""], ["Elamrani-Raoult", "Aida", ""], ["Kording", "Konrad", ""], ["Evans", "James", ""]]}, {"id": "1802.01403", "submitter": "Tirthankar Ghosal", "authors": "Tirthankar Ghosal, Rajeev Verma, Asif Ekbal, Sriparna Saha, Pushpak\n  Bhattacharyya", "title": "An AI aid to the editors. Exploring the possibility of an AI assisted\n  article classification system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work is a preliminary exploratory study of how we could progress a step\ntowards an AI assisted article classification sys- tem in academia. The\nproposed system aims to aid the journal editors in their decisions by\npinpointing the potential weaknesses or strengths of a submitted manuscript.\nFrom a large collection of articles and corresponding author-editor\ninteractions we explore the possible reasons that lead to a paper being not\nforwarded for review. Our investigation reveals that in most cases either it is\nbe- cause the prospective manuscript is out of scope of the journal or the\nmanuscript does not satisfy the minimum quality requirements to maintain the\nstandard of the journal. We extract several features to quantify the quality of\na paper and the degree of in-scope explor- ing keyword search, citation\nanalysis, reputations of authors and affiliations, similarity with respect to\naccepted papers. With these features we train standard machine learning\nclassifiers to develop a classification system. On a decent set of test data\nour approach yields promising results across 3 different journals. We believe\nthat our approach is generic and could be adapted to other journals with\nappropriate adjustments.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 14:21:03 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 02:36:05 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Ghosal", "Tirthankar", ""], ["Verma", "Rajeev", ""], ["Ekbal", "Asif", ""], ["Saha", "Sriparna", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1802.01424", "submitter": "Henry S Thompson", "authors": "Henry S. Thompson, Jian Tong", "title": "Can Common Crawl reliably track persistent identifier (PID) use over\n  time?", "comments": "7 pages, 1 figure, submitted to TempWeb2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report here on the results of two studies using two and four monthly web\ncrawls respectively from the Common Crawl (CC) initiative between 2014 and\n2017, whose initial goal was to provide empirical evidence for the changing\npatterns of use of so-called persistent identifiers. This paper focusses on the\ntooling needed for dealing with CC data, and the problems we found with it. The\nfirst study is based on over $10^{12}$ URIs from over $5 * 10^9$ pages crawled\nin April 2014 and April 2017, the second study adds a further $3 * 10^9$ pages\nfrom the April 2015 and April 2016 crawls. We conclude with suggestions on\nspecific actions needed to enable studies based on CC to give reliable\nlongitudinal information.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 16:44:44 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Thompson", "Henry S.", ""], ["Tong", "Jian", ""]]}, {"id": "1802.02149", "submitter": "Monica Marra", "authors": "Monica Marra", "title": "Astrophysicists and physicists as creators of ArXiv-based commenting\n  resources for their research communities. An initial survey", "comments": "Journal article 16 pages", "journal-ref": "Information Services and Use, vol.37, no.4, pp. 371-387, published\n  8 January 2018", "doi": "10.3233/ISU-170856", "report-no": null, "categories": "cs.DL astro-ph.IM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper conveys the outcomes of what results to be the first, though\ninitial, overview of commenting platforms and related 2.0 resources born within\nand for the astrophysical community (from 2004 to 2016). Experiences were\nadded, mainly in the physics domain, for a total of 22 major items, including\nfour epijournals, and four supplementary resources, thus casting some light\nonto an unexpected richness and consonance of endeavours. These experiences\nrest almost entirely on the contents of the database ArXiv, which adds to its\nmerits that of potentially setting the grounds for web 2.0 resources, and\nresearch behaviours, to be explored.\n  Most of the experiences retrieved are UK and US based, but the resulting\npicture is international, as various European countries, China and Australia\nhave been actively involved.\n  Final remarks about creation patterns and outcome of these resources are\noutlined. The results integrate the previous studies according to which the web\n2.0 is presently of limited use for communication in astrophysics and vouch for\na role of researchers in the shaping of their own professional communication\ntools that is greater than expected. Collaterally, some aspects of ArXiv s\nrecent pathway towards partial inclusion of web 2.0 features are touched upon.\nFurther investigation is hoped for.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:35:51 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Marra", "Monica", ""]]}, {"id": "1802.02188", "submitter": "Barbara McGillivray", "authors": "Barbara McGillivray, Elisa De Ranieri", "title": "Uptake and outcome of manuscripts in Nature journals by review model and\n  author characteristics", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Double-blind peer review has been proposed as a possible solution to avoid\nimplicit referee bias in academic publishing. The aims of this study are to\nanalyse the demographics of corresponding authors choosing double blind peer\nreview, and to identify differences in the editorial outcome of manuscripts\ndepending on their review model. Data includes 128,454 manuscripts received\nbetween March 2015 and February 2017 by 25 Nature-branded journals. Author\nuptake for double-blind was 12%. We found a small but significant association\nbetween journal tier and review type. We found no statistically significant\ndifference in the distribution of peer review model between males and females.\nWe found that corresponding authors from the less prestigious institutions are\nmore likely to choose double-blind review. In the ten countries with the\nhighest number of submissions, we found a small but significant association\nbetween country and review type. The outcome at both first decision and post\nreview is significantly more negative (i.e. a higher likelihood for rejection)\nfor double than single-blind papers. Authors choose double-blind review more\nfrequently when they submit to more prestigious journals, they are affiliated\nwith less prestigious institutions or they are from specific countries; the\ndouble-blind option is also linked to less successful editorial outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 19:52:00 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["McGillivray", "Barbara", ""], ["De Ranieri", "Elisa", ""]]}, {"id": "1802.02482", "submitter": "Lise Verlaet", "authors": "Lise Verlaet (LERASS), Sidonie Gallot (LERASS), Audilio Gonzales\n  Aguilar (IRSIC)", "title": "The paradigm of complexity. Contributions for hypertext's formal\n  approaches", "comments": "in French", "journal-ref": "H2PTM'13, Oct 2013, Paris, France", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article argues for a return to formal approaches of hypertext and builds\non the paradigm of complexity to develop the idea of \"hypermediator website\". A\nhypermediator website is an intermediate device between a digitalization of\nbook culture and a \"real\" hypertext writing. If our thinking on the\nhypermediator website joined the hypertext's notions and the databases, it\ndiffers by the relationship reader-device no longer based on information search\nquery but using the visualization of the information.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 09:28:49 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Verlaet", "Lise", "", "LERASS"], ["Gallot", "Sidonie", "", "LERASS"], ["Aguilar", "Audilio Gonzales", "", "IRSIC"]]}, {"id": "1802.02689", "submitter": "Milena Golshan", "authors": "Christine L. Borgman, Andrea Scharnhorst, Milena S. Golshan", "title": "Digital Data Archives as Knowledge Infrastructures: Mediating Data\n  Sharing and Reuse", "comments": "31 pages, 1 table, 2 figures. Accepted for publication in the Journal\n  of the Association for Information Science and Technology (JASIST), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital archives are the preferred means for open access to research data.\nThey play essential roles in knowledge infrastructures - robust networks of\npeople, artifacts, and institutions - but little is known about how they\nmediate information exchange between stakeholders. We open the \"black box\" of\ndata archives by studying DANS, the Data Archiving and Networked Services\ninstitute of The Netherlands, which manages 50+ years of data from the social\nsciences, humanities, and other domains. Our interviews, weblogs, ethnography,\nand document analyses reveal that a few large contributors provide a steady\nflow of content, but most are academic researchers who submit datasets\ninfrequently and often restrict access to their files. Consumers are a diverse\ngroup that overlaps minimally with contributors. Archivists devote about half\ntheir time to aiding contributors with curation processes and half to assisting\nconsumers. Given the diversity and infrequency of usage, human assistance in\ncuration and search remains essential. DANS' knowledge infrastructure\nencompasses public and private stakeholders who contribute, consume, harvest,\nand serve their data - many of whom did not exist at the time the DANS\ncollections originated - reinforcing the need for continuous investment in\ndigital data archives as their communities, technologies, and services evolve.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 02:04:03 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 22:32:30 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Borgman", "Christine L.", ""], ["Scharnhorst", "Andrea", ""], ["Golshan", "Milena S.", ""]]}, {"id": "1802.02790", "submitter": "Weishu Liu", "authors": "Weishu Liu, Yishan Ding, Mengdi Gu", "title": "Book reviews in academic journals: patterns and dynamics", "comments": null, "journal-ref": "Liu, W., Ding, Y. & Gu, M.Book reviews in academic journals:\n  patterns and dynamics Scientometrics. 2017,110(1):355-364.\n  https://doi.org/10.1007/s11192-016-2172-2", "doi": "10.1007/s11192-016-2172-2", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Book reviews play important roles in scholarly communication especially in\narts and humanities disciplines. By using Web of Science's Science Citation\nIndex Expanded, Social Sciences Citation Index, and Arts & Humanities Citation\nIndex, this study probed the patterns and dynamics of book reviews within these\nthree indexes empirically during the past decade (2006-2015). We found that the\nabsolute numbers of book reviews among all the three indexes were relatively\nstable but the relative shares were decreasing. Book reviews were very common\nin arts and humanities, common in social sciences, but rare in natural\nsciences. Book reviews are mainly contributed by authors from developed\neconomies such as the USA and the UK. Oppositely, scholars from China and Japan\nare unlikely to contribute to book reviews.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 10:31:29 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Liu", "Weishu", ""], ["Ding", "Yishan", ""], ["Gu", "Mengdi", ""]]}, {"id": "1802.02827", "submitter": "Thed Leeuwen van", "authors": "Thed van Leeuwen, Ingeborg Meijer, Alfredo Yegros-Yegros and Rodrigo\n  Costas", "title": "Developing indicators on Open Access by combining evidence from diverse\n  data sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last couple of years, the role of Open Access (OA) publishing has\nbecome central in science management and research policy. In the UK and the\nNetherlands, national OA mandates require the scientific community to seriously\nconsider publishing research outputs in OA forms. At the same time, other\nelements of Open Science are becoming also part of the debate, thus including\nnot only publishing research outputs but also other related aspects of the\nchain of scientific knowledge production such as open peer review and open\ndata. From a research management point of view, it is important to keep track\nof the progress made in the OA publishing debate. Until now, this has been\nquite problematic, given the fact that OA as a topic is hard to grasp by\nbibliometric methods, as most databases supporting bibliometric data lack\nexhaustive and accurate open access labelling of scientific publications. In\nthis study, we present a methodology that systematically creates OA labels for\nlarge sets of publications processed in the Web of Science database. The\nmethodology is based on the combination of diverse data sources that provide\nevidence of publications being OA\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 12:36:57 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["van Leeuwen", "Thed", ""], ["Meijer", "Ingeborg", ""], ["Yegros-Yegros", "Alfredo", ""], ["Costas", "Rodrigo", ""]]}, {"id": "1802.02953", "submitter": "Christine Borgman", "authors": "Christine L. Borgman", "title": "Open Data, Grey Data, and Stewardship: Universities at the Privacy\n  Frontier", "comments": "Final published version, Sept 30, 2018", "journal-ref": "Borgman, C.L. (2018). Open data, grey data, and stewardship:\n  Universities at the privacy frontier. Berkeley Technology Law Journal, 33:2,\n  365-412", "doi": "10.15779/Z38B56D489", "report-no": null, "categories": "cs.DL cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As universities recognize the inherent value in the data they collect and\nhold, they encounter unforeseen challenges in stewarding those data in ways\nthat balance accountability, transparency, and protection of privacy, academic\nfreedom, and intellectual property. Two parallel developments in academic data\ncollection are converging: (1) open access requirements, whereby researchers\nmust provide access to their data as a condition of obtaining grant funding or\npublishing results in journals; and (2) the vast accumulation of 'grey data'\nabout individuals in their daily activities of research, teaching, learning,\nservices, and administration. The boundaries between research and grey data are\nblurring, making it more difficult to assess the risks and responsibilities\nassociated with any data collection. Many sets of data, both research and grey,\nfall outside privacy regulations such as HIPAA, FERPA, and PII. Universities\nare exploiting these data for research, learning analytics, faculty evaluation,\nstrategic decisions, and other sensitive matters. Commercial entities are\nbesieging universities with requests for access to data or for partnerships to\nmine them. The privacy frontier facing research universities spans open access\npractices, uses and misuses of data, public records requests, cyber risk, and\ncurating data for privacy protection. This paper explores the competing values\ninherent in data stewardship and makes recommendations for practice, drawing on\nthe pioneering work of the University of California in privacy and information\nsecurity, data governance, and cyber risk.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 16:32:53 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 17:41:44 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Borgman", "Christine L.", ""]]}, {"id": "1802.03272", "submitter": "Ferdinando Patat", "authors": "F. Patat, H.M.J. Boffin, D. Bordelon, U. Grothkopf, S. Meakins, S.\n  Mieske, M. Rejkuba", "title": "The ESO Survey of Non-Publishing Programmes", "comments": "10 pages, 4 figures, Appeared on The Messenger, 170, 51. A few typos\n  fixed", "journal-ref": "Patat, F. et al., 2017, The Messenger, 170, 51P", "doi": "10.18727/0722-6691/5055", "report-no": null, "categories": "astro-ph.IM cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the classic ways to measure the success of a scientific facility is\nthe publication return, which is defined as the number of refereed papers\nproduced per unit of allocated resources (for example, telescope time or\nproposals). The recent studies by Sterzik et al. (2015, 2016) have shown that\n30-50 % of the programmes allocated time at ESO do not produce a refereed\npublication. While this may be inherent to the scientific process, this finding\nprompted further investigation. For this purpose, ESO conducted a Survey of\nNon-Publishing Programmes (SNPP) within the activities of the Time Allocation\nWorking Group, similar to the monitoring campaign that was recently implemented\nat ALMA (Stoehr et al. 2016). The SNPP targeted 1278 programmes scheduled\nbetween ESO Periods 78 and 90 (October 2006 to March 2013) that had not\npublished a refereed paper as of April 2016. The poll was launched on 6 May\n2016, remained open for four weeks, and returned 965 valid responses. This\narticle summarises and discusses the results of this survey, the first of its\nkind at ESO.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 14:18:34 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 08:59:21 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Patat", "F.", ""], ["Boffin", "H. M. J.", ""], ["Bordelon", "D.", ""], ["Grothkopf", "U.", ""], ["Meakins", "S.", ""], ["Mieske", "S.", ""], ["Rejkuba", "M.", ""]]}, {"id": "1802.03311", "submitter": "L. A. Barba", "authors": "Lorena A. Barba", "title": "Terminologies for Reproducible Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reproducible research---by its many names---has come to be regarded as a key\nconcern across disciplines and stakeholder groups. Funding agencies and\njournals, professional societies and even mass media are paying attention,\noften focusing on the so-called \"crisis\" of reproducibility. One big problem\nkeeps coming up among those seeking to tackle the issue: different groups are\nusing terminologies in utter contradiction with each other. Looking at a broad\nsample of publications in different fields, we can classify their terminology\nvia decision tree: they either, A---make no distinction between the words\nreproduce and replicate, or B---use them distinctly. If B, then they are\ncommonly divided in two camps. In a spectrum of concerns that starts at a\nminimum standard of \"same data+same methods=same results,\" to \"new data and/or\nnew methods in an independent study=same findings,\" group 1 calls the minimum\nstandard reproduce, while group 2 calls it replicate. This direct swap of the\ntwo terms aggravates an already weighty issue. By attempting to inventory the\nterminologies across disciplines, I hope that some patterns will emerge to help\nus resolve the contradictions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 15:36:38 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Barba", "Lorena A.", ""]]}, {"id": "1802.03544", "submitter": "Kyrylo Malakhov", "authors": "A.V. Palagin, N.G. Petrenko, V.Yu. Velychko, K.S. Malakhov, Yu.L.\n  Tikhonov", "title": "To the problem of \"The Instrumental complex for ontological engineering\n  purpose\" software system design", "comments": "in Russian; updated \"Bibliography\" section for correct identification\n  of references by the Google Scholar parser software; updated figures; 10\n  pages; 8 figures", "journal-ref": "Problems in programming, 2012, (2-3), pp.289-298. PROBLEMS IN\n  PROGRAMMING SCIENTIFIC JOURNAL , (2-3), pp.289-298", "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The given work describes methodological principles of design instrumental\ncomplex of ontological purpose. Instrumental complex intends for the\nimplementation of the integrated information technologies automated build of\ndomain ontologies. Results focus on enhancing the effectiveness of the\nautomatic analysis and understanding of natural-language texts, building of\nknowledge description of subject areas (primarily in the area of science and\ntechnology) and for interdisciplinary research in conjunction with the solution\nof complex problems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 08:13:54 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 11:35:22 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Palagin", "A. V.", ""], ["Petrenko", "N. G.", ""], ["Velychko", "V. Yu.", ""], ["Malakhov", "K. S.", ""], ["Tikhonov", "Yu. L.", ""]]}, {"id": "1802.03629", "submitter": "Gretchen Stahlman", "authors": "P. Bryan Heidorn, Gretchen R. Stahlman, and Julie Steffen", "title": "Astrolabe: Curating, Linking and Computing Astronomy's Dark Data", "comments": "Accepted for publication in the Astrophysical Journal Supplement\n  Series, 22 pages, 2 figures", "journal-ref": "ApJS (2018), 236.1, 3", "doi": "10.3847/1538-4365/aab77e", "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where appropriate repositories are not available to support all relevant\nastronomical data products, data can fall into darkness: unseen and unavailable\nfor future reference and re-use. Some data in this category are legacy or old\ndata, but newer datasets are also often uncurated and could remain \"dark\". This\npaper provides a description of the design motivation and development of\nAstrolabe, a cyberinfrastructure project that addresses a set of community\nrecommendations for locating and ensuring the long-term curation of dark or\notherwise at-risk data and integrated computing. This paper also describes the\noutcomes of the series of community workshops that informed creation of\nAstrolabe. According to participants in these workshops, much astronomical dark\ndata currently exist that are not curated elsewhere, as well as software that\ncan only be executed by a few individuals and therefore becomes unusable\nbecause of changes in computing platforms. Astronomical research questions and\nchallenges would be better addressed with integrated data and computational\nresources that fall outside the scope of existing observatory and space mission\nprojects. As a solution, the design of the Astrolabe system is aimed at\ndeveloping new resources for management of astronomical data. The project is\nbased in CyVerse cyberinfrastructure technology and is a collaboration between\nthe University of Arizona and the American Astronomical Society. Overall the\nproject aims to support open access to research data by leveraging existing\ncyberinfrastructure resources and promoting scientific discovery by making\npotentially-useful data in a computable format broadly available to the\nastronomical community.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 18:00:32 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 18:59:34 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Heidorn", "P. Bryan", ""], ["Stahlman", "Gretchen R.", ""], ["Steffen", "Julie", ""]]}, {"id": "1802.04538", "submitter": "Mayank Singh", "authors": "Mayank Singh, Rajdeep Sarkar, Atharva Vyas, Pawan Goyal, Animesh\n  Mukherjee and Soumen Chakrabarti", "title": "Automated Early Leaderboard Generation From Comparative Tables", "comments": "Accepted at ECIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A leaderboard is a tabular presentation of performance scores of the best\ncompeting techniques that address a specific scientific problem. Manually\nmaintained leaderboards take time to emerge, which induces a latency in\nperformance discovery and meaningful comparison. This can delay dissemination\nof best practices to non-experts and practitioners. Regarding papers as proxies\nfor techniques, we present a new system to automatically discover and maintain\nleaderboards in the form of partial orders between papers, based on performance\nreported therein. In principle, a leaderboard depends on the task, data set,\nother experimental settings, and the choice of performance metrics. Often there\nare also tradeoffs between different metrics. Thus, leaderboard discovery is\nnot just a matter of accurately extracting performance numbers and comparing\nthem. In fact, the levels of noise and uncertainty around performance\ncomparisons are so large that reliable traditional extraction is infeasible. We\nmitigate these challenges by using relatively cleaner, structured parts of the\npapers, e.g., performance tables. We propose a novel performance improvement\ngraph with papers as nodes, where edges encode noisy performance comparison\ninformation extracted from tables. Every individual performance edge is\nextracted from a table with citations to other papers. These extractions\nresemble (noisy) outcomes of 'matches' in an incomplete tournament. We propose\nseveral approaches to rank papers from these noisy 'match' outcomes. We show\nthat our ranking scheme can reproduce various manually curated leaderboards\nvery well. Using widely-used lists of state-of-the-art papers in 27 areas of\nComputer Science, we demonstrate that our system produces very reliable\nrankings.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 10:18:13 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 02:33:30 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Singh", "Mayank", ""], ["Sarkar", "Rajdeep", ""], ["Vyas", "Atharva", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1802.04853", "submitter": "Drahomira Herrmannova", "authors": "Drahomira Herrmannova and Robert M. Patton and Petr Knoth and\n  Christopher G. Stahl", "title": "Do Citations and Readership Identify Seminal Publications?", "comments": "Accepted to journal Scientometrics", "journal-ref": "Herrmannova, D., Patton, R.M., Knoth, P. et al. Scientometrics\n  (2018). https://doi.org/10.1007/s11192-018-2669-y", "doi": "10.1007/s11192-018-2669-y", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that citation counts work better than a random\nbaseline (by a margin of 10%) in distinguishing excellent research, while\nMendeley reader counts don't work better than the baseline. Specifically, we\nstudy the potential of these metrics for distinguishing publications that\ncaused a change in a research field from those that have not. The experiment\nhas been conducted on a new dataset for bibliometric research called\nTrueImpactDataset. TrueImpactDataset is a collection of research publications\nof two types -- research papers which are considered seminal works in their\narea and papers which provide a literature review of a research area. We\nprovide overview statistics of the dataset and propose to use it for validating\nresearch evaluation metrics. Using the dataset, we conduct a set of experiments\nto study how citation and reader counts perform in distinguishing these\npublication types, following the intuition that causing a change in a field\nsignifies research contribution. We show that citation counts help in\ndistinguishing research that strongly influenced later developments from works\nthat predominantly discuss the current state of the art with a degree of\naccuracy (63%, i.e. 10% over the random baseline). In all setups, Mendeley\nreader counts perform worse than a random baseline.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 20:53:28 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Herrmannova", "Drahomira", ""], ["Patton", "Robert M.", ""], ["Knoth", "Petr", ""], ["Stahl", "Christopher G.", ""]]}, {"id": "1802.05012", "submitter": "Nicolas Robinson-Garcia", "authors": "Joaqu\\'in M. Azagra-Caro, Anabel Fern\\'andez-Mesa and Nicol\\'as\n  Robinson-Garc\\'ia", "title": "'Getting out of the closet': Scientific authorship of literary fiction\n  and knowledge transfer", "comments": "Paper published in Journal of Technology Transfer", "journal-ref": "Azagra-Caro, J.M., Fern\\'andez-Mesa, A., Robinson-Garcia, N.\n  (2018). 'Getting out of the closet': Scientific authorship of literary\n  fiction and knowledge transfer. Journal of Technology Transfer.\n  doi:10.1007/s10961-018-9672-6", "doi": "10.1007/s10961-018-9672-6", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some scientists write literary fiction books in their spare time. If these\nbooks contain scientific knowledge, literary fiction becomes a mechanism of\nknowledge transfer. In this case, we could conceptualize literary fiction as\nnon-formal knowledge transfer. We model knowledge transfer via literary fiction\nas a function of the type of scientist (academic or non-academic) and his/her\nscientific field. Academic scientists are those employed in academia and public\nresearch organizations whereas non-academic scientists are those with a\nscientific background employed in other sectors. We also distinguish between\ndirect knowledge transfer (the book includes the scientist's research topics),\nindirect knowledge transfer (scientific authors talk about their research with\ncultural agents) and reverse knowledge transfer (cultural agents give\nscientists ideas for future research). Through mixed-methods research and a\nsample from Spain, we find that scientific authorship accounts for a\nconsiderable percentage of all literary fiction authorship. Academic scientists\ndo not transfer knowledge directly so often as non-academic scientists, but the\nformer engage into indirect and reverse transfer knowledge more often than the\nlatter. Scientists from History stand out in direct knowledge transfer. We draw\npropositions about the role of the academic logic and scientific field on\nknowledge transfer via literary fiction. We advance some tentative conclusions\nregarding the consideration of scientific authorship of literary fiction as a\nvaluable knowledge transfer mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:02:17 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 08:08:37 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Azagra-Caro", "Joaqu\u00edn M.", ""], ["Fern\u00e1ndez-Mesa", "Anabel", ""], ["Robinson-Garc\u00eda", "Nicol\u00e1s", ""]]}, {"id": "1802.05055", "submitter": "Selen Gurbuz", "authors": "Selen Gurbuz, Galip Aydin", "title": "Classification of Scientific Papers With Big Data Technologies", "comments": "in Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sizes that cannot be processed by conventional data storage and analysis\nsystems are named as Big Data.It also refers to nex technologies developed to\nstore, process and analyze large amounts of data. Automatic information\nretrieval about the contents of a large number of documents produced by\ndifferent sources, identifying research fields and topics, extraction of the\ndocument abstracts, or discovering patterns are some of the topics that have\nbeen studied in the field of big data.In this study, Naive Bayes classification\nalgorithm, which is run on a data set consisting of scientific articles, has\nbeen tried to automatically determine the classes to which these documents\nbelong. We have developed an efficient system that can analyze the Turkish\nscientific documents with the distributed document classification algorithm run\non the Cloud Computing infrastructure. The Apache Mahout library is used in the\nstudy. The servers required for classifying and clustering distributed\ndocuments are\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 12:03:35 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Gurbuz", "Selen", ""], ["Aydin", "Galip", ""]]}, {"id": "1802.05058", "submitter": "David Stuart Dr", "authors": "Mercedes Echeverria, David Stuart, and Jose-Antonio Cordon-Garcia", "title": "The influence of online posting dates on the bibliometric indicators of\n  scientific articles", "comments": null, "journal-ref": "ECHEVERRIA, Mercedes; STUART, David; CORDON-GARCIA, Jose Antonio\n  (2017). The influence of online posting dates on the bibliometric indicators\n  of scientific articles. Revista espanola de Documentacion Cientifica, v. 40,\n  n. 3, p. e183", "doi": "10.3989/redc.2017.3.1422", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article analyses the difference in timing between the online\navailability of articles and their corresponding print publication and how it\naffects two bibliometric indicators: Journal Impact Factor (JIF) and Immediacy\nIndex. This research examined 18,526 articles, the complete collection of\narticles and reviews published by a set of 61 journals on Urology and\nNephrology in 2013 and 2014. The findings suggest that Advance Online\nPublication (AOP) accelerates the citation of articles and affects the JIF and\nImmediacy Index values. Regarding the JIF values, the comparison between\njournals with or without AOP showed statistically significant differences\n(P=0.001, Mann-Whitney U test). The Spearman's correlation between the JIF and\nthe median online-to-print publication delay was not statistically significant.\nAs to the Immediacy Index, a significant Spearman's correlation (rs=0.280,\nP=0.029) was found regarding the median online-to-print publication delays for\njournals published in 2014, although no statistically significant correlation\nwas found for those published in 2013. Most journals examined (n=52 out of 61)\npublished their articles in AOP. The analysis also showed different publisher\npractices: eight journals did not include the online posting dates in the\nfull-text and nine journals published articles showing two different online\nposting dates--the date provided on the journal website and another provided by\nElsevier's Science Direct. These practices suggest the need for transparency\nand standardization of the AOP dates of scientific articles for calculating\nbibliometric indicators for journals.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 12:09:22 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Echeverria", "Mercedes", ""], ["Stuart", "David", ""], ["Cordon-Garcia", "Jose-Antonio", ""]]}, {"id": "1802.05458", "submitter": "Peter Kokol PhD", "authors": "Peter Kokol", "title": "Point systems in Games for Health: A bibliometric scoping study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Very few details about point systems used in games for health are reported in\nscientific literature. To shed some light on this topic a bibliometric study,\nanalyzing the papers containing terms related to games for health and point\nsystems was performed and a mini taxonomy was derived. The search string game*\nAND health AND (point* OR score) AND system* in a Scopus bibliographic database\nwas used to produce the corpus. We limited the search to articles, reviews and\nconference papers written in English and to topics related to medical, health\nand social subjects. The corpus papers abstracts and titles were analysed by\nVOSviewer and a scientific landscape was generated. The search resulted in a\ncorpus consisting of 354 papers. The derived taxonomy contains three objects;\nvideo games, serious games and educational games. The biblimetric mapping and\ntaxonomy revealed some interesting conclusions: (1) the video games have mostly\nnegative effects on health, (2) the serious games might have both a direct\npositive health effects on users and also indirect effects by improved\ncompetencies of health professionals, and (3) the research is concerned not\nonly to computer based educational games, but also to traditional table games\nand sporting games. Based on the derived taxonomy we can conclude that point\nsystems should reward physical activity and healthy living style and punish\nsedentary activities.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 10:06:59 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Kokol", "Peter", ""]]}, {"id": "1802.05941", "submitter": "Eugenio Petrovich", "authors": "Eugenio Petrovich", "title": "Accumulation of Knowledge in Para-Scientific Areas. The Case of Analytic\n  Philosophy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study analyzes how the accumulation of knowledge takes place in\npara-scientific areas, focusing on the case of Analytic Philosophy. The\ntheoretical framework chosen for the analysis is Kuhn's theory of normal\nscience. The methodology employed is qualitative citation context analysis. A\nsample of 60 papers published in leading Analytic Philosophy journals between\n1950 and 2009 is analyzed, and a specific classsificatory scheme is developed\nto classify citations according to their epistemological function. Compared to\nprevious studies of citation context, this is the first paper that includes the\ntemporal dimension into the analysis of citation context, in order to gain\ninsights into the process of knowledge accumulation. Interestingly, the results\nshow that Analytic Philosophy started accumulating after Second World War, but\nin a peculiar way. The accumulation was not matched by a corresponding rising\nconsensus. This can be explained by the hypothesis that AP underwent a process\nof fragmentation in sub-fields during the second half of the century.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 14:14:29 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 13:54:31 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Petrovich", "Eugenio", ""]]}, {"id": "1802.05945", "submitter": "Thed Leeuwen van", "authors": "Alex Rushforth, Alfredo Yegros-Yegros, Philippe Mongeon, Thed van\n  Leeuwen", "title": "How does undone science get funded? A bibliometric analysis linking rare\n  diseases publications to national and European funding sources", "comments": "Paper presented at the EU-SPRI Early Career Researcher Conferences,\n  Vienna, November 21, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the notable features of undone science debates is how formation of new\ninterest groups becomes pivotal in mobilizing and championing emerging research\non undone topics. Clearly money is one of the most important mediums through\nwhich different types of actors can support and steer scientists to work on\nundone topics. Yet which actors are more visible in their support for\nscientific research is something which has seldom been measured. This study\ndelves into research funding in the context of rare diseases research, a topic\nwhich has evolved from the margins of medical research into a priority area\narticulated by many contemporary funding agencies. Rare diseases refer to\nconditions affecting relatively few people in a population. Given low\nincidences, interest groups have articulated a lack of attention within medical\nresearch compared to more common conditions. The rise to prominence of rare\ndiseases in research funding policies is often explained in the science studies\nliterature in terms of effective lobbying by social movements Likewise,\ninnovative fundraising initiatives, infrastructure building, and close\npartnerships with research groups are other means through which interested\nactors have sought to build capacity for research into rare medical conditions.\nTo date however systematic empirical evidence to compare the relative\nimportance of different actors in funding rare disease research has not been\nproduced. Building on interest in undone science in STS and science policy\nstudies, our study hopes to map-out different kinds of funding actors and their\ninfluence on leading scientific research on rare diseases, by use of\nbibliometric tools. The approach we are developing relies on the use of Funding\nAcknowledgement data provided in Web of Science database.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 14:22:55 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Rushforth", "Alex", ""], ["Yegros-Yegros", "Alfredo", ""], ["Mongeon", "Philippe", ""], ["van Leeuwen", "Thed", ""]]}, {"id": "1802.06007", "submitter": "Catalin Stoean", "authors": "Daniel Lichtblau, Catalin Stoean", "title": "Authorship Attribution Using the Chaos Game Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chaos Game Representation, a method for creating images from nucleotide\nsequences, is modified to make images from chunks of text documents. Machine\nlearning methods are then applied to train classifiers based on authorship.\nExperiments are conducted on several benchmark data sets in English, including\nthe widely used Federalist Papers, and one in Portuguese. Validation results\nfor the trained classifiers are competitive with the best methods in prior\nliterature. The methodology is also successfully applied for text\ncategorization with encouraging results. One classifier method is moreover seen\nto hold promise for the task of digital fingerprinting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:44:24 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Lichtblau", "Daniel", ""], ["Stoean", "Catalin", ""]]}, {"id": "1802.06015", "submitter": "Vaiva Vasiliauskaite", "authors": "Vaiva Vasiliauskaite, Tim S. Evans", "title": "Diversity from the Topology of Citation Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "Imperial/TP/18/TSE/1", "categories": "physics.soc-ph cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study transitivity in directed acyclic graphs and its usefulness in\ncapturing nodes that act as bridges between more densely interconnected parts\nin such type of network. In transitively reduced citation networks degree\ncentrality could be used as a measure of interdisciplinarity or diversity. We\nstudy the measure's ability to capture \"diverse\" nodes in random directed\nacyclic graphs and citation networks. We show that transitively reduced degree\ncentrality is capable of capturing \"diverse\" nodes, thus this measure could be\na timely alternative to text analysis techniques for retrieving papers,\ninfluential in a variety of research fields.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:32:07 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Vasiliauskaite", "Vaiva", ""], ["Evans", "Tim S.", ""]]}, {"id": "1802.06565", "submitter": "Andrew Collins Mr", "authors": "Andrew Collins, Dominika Tkaczyk, Akiko Aizawa, Joeran Beel", "title": "A Study of Position Bias in Digital Library Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Position bias\" describes the tendency of users to interact with items on top\nof a list with higher probability than with items at a lower position in the\nlist, regardless of the items' actual relevance. In the domain of recommender\nsystems, particularly recommender systems in digital libraries, position bias\nhas received little attention. We conduct a study in a real-world recommender\nsystem that delivered ten million related-article recommendations to the users\nof the digital library Sowiport, and the reference manager JabRef.\nRecommendations were randomly chosen to be shuffled or non-shuffled, and we\ncompared click-through rate (CTR) for each rank of the recommendations.\nAccording to our analysis, the CTR for the highest rank in the case of Sowiport\nis 53% higher than expected in a hypothetical non-biased situation (0.189% vs.\n0.123%). Similarly, in the case of Jabref the highest rank received a CTR of\n1.276%, which is 87% higher than expected (0.683%). A chi-squared test confirms\nthe strong relationship between the rank of the recommendation shown to the\nuser and whether the user decided to click it (p < 0.01 for both Jabref and\nSowiport). Our study confirms the findings from other domains, that\nrecommendations in the top positions are more often clicked, regardless of\ntheir actual relevance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 09:40:49 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Collins", "Andrew", ""], ["Tkaczyk", "Dominika", ""], ["Aizawa", "Akiko", ""], ["Beel", "Joeran", ""]]}, {"id": "1802.06633", "submitter": "Ricardo Brito", "authors": "Alonso Rodriguez-Navarro and Ricardo Brito", "title": "Technological research in the EU is less efficient than the world\n  average. EU research policy risks Europeans' future", "comments": "30 pages, 3 figures, 7 tables, in one single file. Version accepted\n  in Journal of Informetrics", "journal-ref": null, "doi": "10.1016/j.joi.2018.06.00", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We have studied the efficiency of research in the EU by a percentile-based\ncitation approach that analyzes the distribution of country papers among the\nworld papers. Going up in the citation scale, the frequency of papers from\nefficient countries increases while the frequency from inefficient countries\ndecreases. In the percentile-based approach, this trend, which is permanent at\nany citation level, is measured by the ep index that equals the Ptop 1%/Ptop\n10% ratio. By using the ep index we demonstrate that EU research on\nfast-evolving technological topics is less efficient than the world average and\nthat the EU is far from being able to compete with the most advanced countries.\nThe ep index also shows that the USA is well ahead of the EU in both fast- and\nslow-evolving technologies, which suggests that the advantage of the USA over\nthe EU in innovation is due to low research efficiency in the EU. In accord\nwith some previous studies, our results show that the European Commission's\nongoing claims about the excellence of EU research are based on a wrong\ndiagnosis. The EU must focus its research policy on the improvement of its\ninefficient research. Otherwise, the future of Europeans is at risk.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 14:10:12 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 14:35:41 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Rodriguez-Navarro", "Alonso", ""], ["Brito", "Ricardo", ""]]}, {"id": "1802.07285", "submitter": "Waqar Detho", "authors": "Waqar Detho", "title": "Developing a system for securely time-stamping and visualizing the\n  changes made to online news content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the Internet is indispensable when it comes to information\ndissemination. People rely on the Internet to inform themselves on current news\nevents, as well as to verify facts. We, as a community, are quickly approaching\nan 'electronic information age' where the majority of information will be\ndistributed electronically and tools to preserve this information will become\nessential. While archiving online digital information is a good way to preserve\nonline information for future generations, it has many disadvantages including\nthe easy manipulation of archived information, e.g. by the archiving authority.\nOnline information is also prone to getting hacked or being taken offline.\nTherefore, it is necessary that archived online news information is securely\ntime-stamped with the date and time when it was first archived in a way that\ncannot be manipulated. The process of 'trusted timestamping' is an established\napproach for claiming that particular digital information existed at a\nparticular 'point in time' in the past. However, traditional approaches for\ntrusted timestamping depend on the time-stamping authority's fidelity. Directly\nembedding the hash of a digital file into the blockchain of a cryptocurrency is\na more recent method that allows for secure time-stamping, since digital\ninformation is stored as part of the transaction information in, e.g.\nBitcoin's, blockchain, and not stored at a centralized time-stamping authority.\nHowever, there is no system yet available, which uses this approach for\narchiving and time-stamping online news articles. Therefore, the aim of this\nthesis is to develop a system that 1) enables decentralized trusted\ntime-stamping of web and news articles as a means of making future manipulation\nof online information identifiable, and 2) allows users to determine the\nauthenticity of articles by checking different versions of the same article\nonline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:05:28 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 12:01:28 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Detho", "Waqar", ""]]}, {"id": "1802.07544", "submitter": "Kyrylo Malakhov", "authors": "O. V. Palagin, K. S. Malakhov, V. Yu. Velychko, O. S. Shchurov", "title": "Personal research information system. About developing the methods for\n  searching patent analogs of invention", "comments": "in Russian; 9 pages; \"Bibliography\" section updated for correct\n  identification of references by the Google Scholar parser software; Corrected\n  spelling of the name of one of the authors (Velychko)", "journal-ref": "Computer means, networks and systems 16 (2017) 5-13", "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes information model and the method for searching patent\nanalogs for Personal Research Information System.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 12:44:56 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 09:47:28 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Palagin", "O. V.", ""], ["Malakhov", "K. S.", ""], ["Velychko", "V. Yu.", ""], ["Shchurov", "O. S.", ""]]}, {"id": "1802.07677", "submitter": "Mike Thelwall Prof", "authors": "Kayvan Kousha, Mike Thelwall, Mahshid Abdoli", "title": "Can Microsoft Academic assess the early citation impact of in-press\n  articles? A multi-discipline exploratory analysis", "comments": null, "journal-ref": "A multi-discipline exploratory analysis. Journal of Informetrics,\n  12(1), 287-298", "doi": "10.1016/j.joi.2018.01.009", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many journals post accepted articles online before they are formally\npublished in an issue. Early citation impact evidence for these articles could\nbe helpful for timely research evaluation and to identify potentially important\narticles that quickly attract many citations. This article investigates whether\nMicrosoft Academic can help with this task. For over 65,000 Scopus in-press\narticles from 2016 and 2017 across 26 fields, Microsoft Academic found 2-5\ntimes as many citations as Scopus, depending on year and field. From manual\nchecks of 1,122 Microsoft Academic citations not found in Scopus, Microsoft\nAcademic's citation indexing was faster but not much wider than Scopus for\njournals. It achieved this by associating citations to preprints with their\nsubsequent in-press versions and by extracting citations from in-press\narticles. In some fields its coverage of scholarly digital libraries, such as\narXiv.org, was also an advantage. Thus, Microsoft Academic seems to be a more\ncomprehensive automatic source of citation counts for in-press articles than\nScopus.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:22:06 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Kousha", "Kayvan", ""], ["Thelwall", "Mike", ""], ["Abdoli", "Mahshid", ""]]}, {"id": "1802.08141", "submitter": "Andrea Scharnhorst", "authors": "Rick Szostak, Andrea Scharnhorst, Wouter Beek, Richard P. Smiraglia", "title": "Connecting KOSs and the LOD Cloud", "comments": "accepted for the 15th INTERNATIONAL ISKO CONFERENCE, Porto, Portugal,\n  9 to 11 July 2018, http://www.iskoiberico.org/about-isko-porto-2018/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a specific project, the current situation leading to it,\nits project design and first results. In particular, we will examine the\nterminology employed in the Linked Open Data cloud and compare this to the\nterminology employed in both the Universal Decimal Classification and the Basic\nConcepts Classification. We will explore whether these classifications can\nencourage greater consistency in LOD terminology. We thus hope to link the\nlargely distinct scholarly literatures that address LOD and KOSs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 16:27:23 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Szostak", "Rick", ""], ["Scharnhorst", "Andrea", ""], ["Beek", "Wouter", ""], ["Smiraglia", "Richard P.", ""]]}, {"id": "1802.08301", "submitter": "Chandra Sekhar Bhagavatula", "authors": "Chandra Bhagavatula and Sergey Feldman and Russell Power and Waleed\n  Ammar", "title": "Content-Based Citation Recommendation", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a content-based method for recommending citations in an academic\npaper draft. We embed a given query document into a vector space, then use its\nnearest neighbors as candidates, and rerank the candidates using a\ndiscriminative model trained to distinguish between observed and unobserved\ncitations. Unlike previous work, our method does not require metadata such as\nauthor names which can be missing, e.g., during the peer review process.\nWithout using metadata, our method outperforms the best reported results on\nPubMed and DBLP datasets with relative improvements of over 18% in F1@20 and\nover 22% in MRR. We show empirically that, although adding metadata improves\nthe performance on standard metrics, it favors self-citations which are less\nuseful in a citation recommendation setup. We release an online portal\n(http://labs.semanticscholar.org/citeomatic/) for citation recommendation based\non our method, and a new dataset OpenCorpus of 7 million research articles to\nfacilitate future research on this task.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 21:13:47 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Bhagavatula", "Chandra", ""], ["Feldman", "Sergey", ""], ["Power", "Russell", ""], ["Ammar", "Waleed", ""]]}, {"id": "1802.09219", "submitter": "Luis Martinez-Uribe", "authors": "Luis Martinez-Uribe", "title": "Digital Archives as Big Data", "comments": "Mathematical Population Studies 2018", "journal-ref": null, "doi": "10.1080/08898480.2017.1418116", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Digital archives contribute to Big data. Combining social network analysis,\ncoincidence analysis, data reduction, and visual analytics leads to better\ncharacterize topics over time, publishers' main themes and best authors of all\ntimes, according to the British newspaper The Guardian and from the 3 million\nrecords of the British National Bibliography.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 09:45:20 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Martinez-Uribe", "Luis", ""]]}, {"id": "1802.09944", "submitter": "Jaimie Murdock", "authors": "Jaimie Murdock and Colin Allen and Simon DeDeo", "title": "The Development of Darwin's Origin of Species", "comments": "8 pages, 3 figures. Pre-print of Current Research in Digital History\n  (CRDH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From 1837, when he returned to England aboard the $\\textit{HMS Beagle}$, to\n1860, just after publication of $\\textit{The Origin of Species}$, Charles\nDarwin kept detailed notes of each book he read or wanted to read. His notes\nand manuscripts provide information about decades of individual scientific\npractice. Previously, we trained topic models on the full texts of each\nreading, and applied information-theoretic measures to detect that changes in\nhis reading patterns coincided with the boundaries of his three major\nintellectual projects in the period 1837-1860. In this new work we apply the\nreading model to five additional documents, four of them by Darwin: the first\nedition of $\\textit{The Origin of Species}$, two private essays stating\nintermediate forms of his theory in 1842 and 1844, a third essay of disputed\ndating, and Alfred Russel Wallace's essay, which Darwin received in 1858. We\naddress three historical inquiries, previously treated qualitatively: 1) the\nmythology of \"Darwin's Delay,\" that despite completing an extensive draft in\n1844, Darwin waited until 1859 to publish $\\textit{The Origin of Species}$ due\nto external pressures; 2) the relationship between Darwin and Wallace's\ncontemporaneous theories, especially in light of their joint presentation; and\n3) dating of the \"Outline and Draft\" which was rediscovered in 1975 and\npostulated first as an 1839 draft preceding the Sketch of 1842, then as an\ninterstitial draft between the 1842 and 1844 essays.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 16:22:14 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Murdock", "Jaimie", ""], ["Allen", "Colin", ""], ["DeDeo", "Simon", ""]]}, {"id": "1802.10033", "submitter": "Christoph Wick", "authors": "Christoph Wick, Christian Reul, Frank Puppe", "title": "Improving OCR Accuracy on Early Printed Books using Deep Convolutional\n  Networks", "comments": "16 pages, 4 figures, 8 tables, submitted to JLCL Volume 33 (2018),\n  Issue 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a combination of a convolutional and a LSTM network to\nimprove the accuracy of OCR on early printed books. While the standard model of\nline based OCR uses a single LSTM layer, we utilize a CNN- and Pooling-Layer\ncombination in advance of an LSTM layer. Due to the higher amount of trainable\nparameters the performance of the network relies on a high amount of training\nexamples to unleash its power. Hereby, the error is reduced by a factor of up\nto 44%, yielding a CER of 1% and below. To further improve the results we use a\nvoting mechanism to achieve character error rates (CER) below $0.5%$. The\nruntime of the deep model for training and prediction of a book behaves very\nsimilar to a shallow network.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 17:17:50 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Wick", "Christoph", ""], ["Reul", "Christian", ""], ["Puppe", "Frank", ""]]}, {"id": "1802.10141", "submitter": "Thomas Scheidsteger", "authors": "Thomas Scheidsteger, Robin Haunschild, Sven Hug, Lutz Bornmann", "title": "The concordance of field-normalized scores based on Web of Science and\n  Microsoft Academic data: A case study in computer sciences", "comments": "10 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to assess Microsoft Academic as a useful data source for evaluative\nbibliometrics it is crucial to know, if citation counts from Microsoft Academic\ncould be used in common normalization procedures and whether the normalized\nscores agree with the scores calculated on the basis of established databases.\nTo this end, we calculate the field-normalized citation scores of the\npublications of a computer science institute based on Microsoft Academic and\nthe Web of Science and estimate the statistical concordance of the scores. Our\nresults suggest that field-normalized citation scores can be calculated with\nMicrosoft Academic and that these scores are in good agreement with the\ncorresponding scores from the Web of Science.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 20:02:12 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 14:31:17 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Scheidsteger", "Thomas", ""], ["Haunschild", "Robin", ""], ["Hug", "Sven", ""], ["Bornmann", "Lutz", ""]]}]