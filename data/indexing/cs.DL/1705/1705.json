[{"id": "1705.00018", "submitter": "Darko Hric", "authors": "Darko Hric, Kimmo Kaski, Mikko Kivel\\\"a", "title": "Stochastic Block Model Reveals the Map of Citation Patterns and Their\n  Evolution in Time", "comments": "38 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we map out the large-scale structure of citation networks of\nscience journals and follow their evolution in time by using stochastic block\nmodels (SBMs). The SBM fitting procedures are principled methods that can be\nused to find hierarchical grouping of journals into blocks that show similar\nincoming and outgoing citations patterns. These methods work directly on the\ncitation network without the need to construct auxiliary networks based on\nsimilarity of nodes. We fit the SBMs to the networks of journals we have\nconstructed from the data set of around 630 million citations and find a\nvariety of different types of blocks, such as clusters, bridges, sources, and\nsinks. In addition we use a recent generalization of SBMs to determine how much\na manually curated classification of journals into subfields of science is\nrelated to the block structure of the journal network and how this relationship\nchanges in time. The SBM method tries to find a network of blocks that is the\nbest high-level representation of the network of journals, and we illustrate\nhow these block networks (at various levels of resolution) can be used as maps\nof science.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 18:01:50 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Hric", "Darko", ""], ["Kaski", "Kimmo", ""], ["Kivel\u00e4", "Mikko", ""]]}, {"id": "1705.00258", "submitter": "Fang Han", "authors": "Fang Han and Christopher L. Magee", "title": "Testing the science/technology relationship by analysis of patent\n  citations of scientific papers after decomposition of both science and\n  technology", "comments": "32 pages, 6 figures, 7 tables, the paper was presented at the 16th\n  ISS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship of scientific knowledge development to technological\ndevelopment is widely recognized as one of the most important and complex\naspects of technological evolution. This paper adds to our understanding of the\nrelationship through use of a more rigorous structure for differentiating among\ntechnologies based upon technological domains (defined as consisting of the\nartifacts over time that fulfill a specific generic function using a specific\nbody of technical knowledge).\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 00:56:15 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Han", "Fang", ""], ["Magee", "Christopher L.", ""]]}, {"id": "1705.00359", "submitter": "Jian Wang", "authors": "Ruizhi Zhang, Jian Wang and Yajun Mei", "title": "Search for Evergreens in Science: A Functional Data Analysis", "comments": "40 pages, 9 figures", "journal-ref": "Journal of Informetrics, Volume 11, Issue 3, Pages 629-644 (August\n  2017)", "doi": "10.1016/j.joi.2017.05.007", "report-no": null, "categories": "stat.AP cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evergreens in science are papers that display a continual rise in annual\ncitations without decline, at least within a sufficiently long time period.\nAiming to better understand evergreens in particular and patterns of citation\ntrajectory in general, this paper develops a functional data analysis method to\ncluster citation trajectories of a sample of 1699 research papers published in\n1980 in the American Physical Society (APS) journals. We propose a functional\nPoisson regression model for individual papers' citation trajectories, and fit\nthe model to the observed 30-year citations of individual papers by functional\nprincipal component analysis and maximum likelihood estimation. Based on the\nestimated paper-specific coefficients, we apply the K-means clustering\nalgorithm to cluster papers into different groups, for uncovering general types\nof citation trajectories. The result demonstrates the existence of an evergreen\ncluster of papers that do not exhibit any decline in annual citations over 30\nyears.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 19:00:39 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 17:09:48 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Zhang", "Ruizhi", ""], ["Wang", "Jian", ""], ["Mei", "Yajun", ""]]}, {"id": "1705.00578", "submitter": "Petr Knoth", "authors": "Petr Knoth, Lucas Anastasiou, Aristotelis Charalampous, Matteo\n  Cancellieri, Samuel Pearce, Nancy Pontika, Vaclav Bayer", "title": "Towards effective research recommender systems for repositories", "comments": "In proceedings of Open Repositories 2017, Brisbane, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we argue why and how the integration of recommender systems\nfor research can enhance the functionality and user experience in repositories.\nWe present the latest technical innovations in the CORE Recommender, which\nprovides research article recommendations across the global network of\nrepositories and journals. The CORE Recommender has been recently redeveloped\nand released into production in the CORE system and has also been deployed in\nseveral third-party repositories. We explain the design choices of this unique\nsystem and the evaluation processes we have in place to continue raising the\nquality of the provided recommendations. By drawing on our experience, we\ndiscuss the main challenges in offering a state-of-the-art recommender solution\nfor repositories. We highlight two of the key limitations of the current\nrepository infrastructure with respect to developing research recommender\nsystems: 1) the lack of a standardised protocol and capabilities for exposing\nanonymised user-interaction logs, which represent critically important input\ndata for recommender systems based on collaborative filtering and 2) the lack\nof a voluntary global sign-on capability in repositories, which would enable\nthe creation of personalised recommendation and notification solutions based on\npast user interactions.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 16:08:08 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Knoth", "Petr", ""], ["Anastasiou", "Lucas", ""], ["Charalampous", "Aristotelis", ""], ["Cancellieri", "Matteo", ""], ["Pearce", "Samuel", ""], ["Pontika", "Nancy", ""], ["Bayer", "Vaclav", ""]]}, {"id": "1705.01089", "submitter": "Sandipan Sikdar", "authors": "Sandipan Sikdar, Matteo Marsili, Niloy Ganguly, Animesh Mukherjee", "title": "Influence of Reviewer Interaction Network on Long-term Citations: A Case\n  Study of the Scientific Peer-Review System of the Journal of High Energy\n  Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A `peer-review system' in the context of judging research contributions, is\none of the prime steps undertaken to ensure the quality of the submissions\nreceived, a significant portion of the publishing budget is spent towards\nsuccessful completion of the peer-review by the publication houses.\nNevertheless, the scientific community is largely reaching a consensus that\npeer-review system, although indispensable, is nonetheless flawed. A very\npertinent question therefore is \"could this system be improved?\". In this\npaper, we attempt to present an answer to this question by considering a\nmassive dataset of around $29k$ papers with roughly $70k$ distinct review\nreports together consisting of $12m$ lines of review text from the Journal of\nHigh Energy Physics (JHEP) between 1997 and 2015. In specific, we introduce a\nnovel \\textit{reviewer-reviewer interaction network} (an edge exists between\ntwo reviewers if they were assigned by the same editor) and show that\nsurprisingly the simple structural properties of this network such as degree,\nclustering coefficient, centrality (closeness, betweenness etc.) serve as\nstrong predictors of the long-term citations (i.e., the overall scientific\nimpact) of a submitted paper. These features, when plugged in a regression\nmodel, alone achieves a high $R^2$ of \\0.79 and a low $RMSE$ of 0.496 in\npredicting the long-term citations. In addition, we also design a set of\nsupporting features built from the basic characteristics of the submitted\npapers, the authors and the referees (e.g., the popularity of the submitting\nauthor, the acceptance rate history of a referee, the linguistic properties\nladen in the text of the review reports etc.), which further results in overall\nimprovement with $R^2$ of 0.81 and $RMSE$ of 0.46.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 17:47:45 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Sikdar", "Sandipan", ""], ["Marsili", "Matteo", ""], ["Ganguly", "Niloy", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1705.01151", "submitter": "Elisabeth de Turckheim", "authors": "Lorenzo Cassi, Ag\\'enor Lahatte, Ismael Rafols, Pierre Sautier,\n  \\'Elisabeth de Turckheim", "title": "Improving fitness: Mapping research priorities against societal needs on\n  obesity", "comments": "37 pages, 10 figures. Section 3: We partly revised the text\n  describing the first topic map (Fig. 2). We changed Fig. 4 (same data).\n  Section 5: We added a warning against a too rapid political interpretation of\n  the lack of similarity between the two maps. Section 7: We acknowledged that\n  parameter choices are questionable and discussed this issue", "journal-ref": "Journal of Informetrics 11 (2017) 1095-1113", "doi": "10.1016/j.joi.2017.09.010", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Science policy is increasingly shifting towards an emphasis in societal\nproblems or grand challenges. As a result, new evaluative tools are needed to\nhelp assess not only the knowledge production side of research programmes or\norganisations, but also the articulation of research agendas with societal\nneeds. In this paper, we present an exploratory investigation of science supply\nand societal needs on the grand challenge of obesity -an emerging health\nproblem with enormous social costs. We illustrate a potential approach that\nuses topic modelling to explore: (a) how scientific publications can be used to\ndescribe existing priorities in science production; (b) how records of\nquestions posed in the European parliament can be used as an instance of\nmapping discourse of social needs; (c) how the comparison between the two may\nshow (mis)alignments between societal concerns and scientific outputs. While\nthis is a technical exercise, we propose that this type of mapping methods can\nbe useful for informing strategic planning and evaluation in funding agencies.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 19:29:44 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 13:22:37 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Cassi", "Lorenzo", ""], ["Lahatte", "Ag\u00e9nor", ""], ["Rafols", "Ismael", ""], ["Sautier", "Pierre", ""], ["de Turckheim", "\u00c9lisabeth", ""]]}, {"id": "1705.01464", "submitter": "Claudiu Herteliu", "authors": "Claudiu Herteliu, Marcel Ausloos, Bogdan Vasile Ileanu, Giulia Rotundo\n  and Tudorel Andrei", "title": "Quantitative and Qualitative Analysis of Editor Behavior through\n  Potentially Coercive Citations", "comments": "23 pages, 6 figures, 5 tables, 45 references, published in\n  Publications (MDPI), 2017 (http://www.mdpi.com/2304-6775/5/2/15). The title\n  of published version is slightly changed", "journal-ref": "Publications 5 (2017) 15", "doi": "10.3390/publications5020015", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How much is the h-index of an editor of a well ranked journal improved due to\ncitations which occur after his or her appointment? Scientific recognition\nwithin academia is widely measured nowadays by the number of citations or\nh-index. Our dataset is based on a sample of four editors from a well ranked\njournal (impact factor - IF - greater than 2). The target group consists of two\neditors who seem to benefit by their position through an increased citation\nnumber (and subsequently h-index) within journal. The total amount of citations\nfor the target group is bigger than 600. The control group is formed by another\nset of two editors from the same journal whose relations between their\npositions and their citation records remain neutral. The total amount of\ncitations for the control group is more than 1200. The timespan for which\npattern of citations has been studied is 1975-2015. Previous coercive citations\nfor a journal benefit (increase its IF) has been signaled. To the best of our\nknowledge, this is a pioneering work on coercive citations for personal (or\neditors) benefit. Editorial teams should be aware about this type of\npotentially unethical behavior and act accordingly.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 15:44:10 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 14:41:03 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Herteliu", "Claudiu", ""], ["Ausloos", "Marcel", ""], ["Ileanu", "Bogdan Vasile", ""], ["Rotundo", "Giulia", ""], ["Andrei", "Tudorel", ""]]}, {"id": "1705.01731", "submitter": "Aftab Alam", "authors": "Conan Mukherje, Ranojoy Basu and Aftab Alam", "title": "A measure of authorship by publications", "comments": "18 pages, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring publication success of a researcher is a complicated task as\npublications are often co-authored by multiple authors, and so, require\ncomparison of solo publications with joint publications. In this paper, like\n\\cite{price1981multiple}, we argue for an egalitarian perspective in\naccomplishing this task.\n  More specifically, we justify the need for an ethical perspective in\nquantifying academic author by identifying certain ethical difficulties of some\npopular contemporary indices used for this purpose. And then we show that for\nany given dataset of research papers, the unique method satisfying the ethical\nnotions of {\\it identity independence} and performance invariance must be the\negaliatarian E-index proposed by \\cite{bps} and \\cite{price1981multiple}. In\nour setting, this egalitarian method divides authorship of joint projects\nequally among authors and sums across all publications of each author.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 08:16:44 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 14:17:19 GMT"}, {"version": "v3", "created": "Wed, 19 Jul 2017 16:59:07 GMT"}, {"version": "v4", "created": "Sun, 20 Oct 2019 06:55:32 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Mukherje", "Conan", ""], ["Basu", "Ranojoy", ""], ["Alam", "Aftab", ""]]}, {"id": "1705.02203", "submitter": "Tesfamariam Mulugeta Abuhay", "authors": "Tesfamariam M. Abuhay, Sergey V. Kovalchuk, Klavdiya O. Bochenina,\n  George Kampis, Valeria V. Krzhizhanovskaya, Michael H. Lees", "title": "Analysis of Computational Science Papers from ICCS 2001-2016 using Topic\n  Modeling and Graph Theory", "comments": "Accepted by International Conference on Computational Science (ICCS)\n  2017 which will be held in Zurich, Switzerland from June 11-June 14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents results of topic modeling and network models of topics\nusing the International Conference on Computational Science corpus, which\ncontains domain-specific (computational science) papers over sixteen years (a\ntotal of 5695 papers). We discuss topical structures of International\nConference on Computational Science, how these topics evolve over time in\nresponse to the topicality of various problems, technologies and methods, and\nhow all these topics relate to one another. This analysis illustrates\nmultidisciplinary research and collaborations among scientific communities, by\nconstructing static and dynamic networks from the topic modeling results and\nthe keywords of authors. The results of this study give insights about the past\nand future trends of core discussion topics in computational science. We used\nthe Non-negative Matrix Factorization topic modeling algorithm to discover\ntopics and labeled and grouped results hierarchically.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 13:24:41 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Abuhay", "Tesfamariam M.", ""], ["Kovalchuk", "Sergey V.", ""], ["Bochenina", "Klavdiya O.", ""], ["Kampis", "George", ""], ["Krzhizhanovskaya", "Valeria V.", ""], ["Lees", "Michael H.", ""]]}, {"id": "1705.02499", "submitter": "Mayank Singh", "authors": "Mayank Singh, Abhishek Niranjan, Divyansh Gupta, Nikhil Angad Bakshi,\n  Animesh Mukherjee, Pawan Goyal", "title": "Citation sentence reuse behavior of scientists: A case study on massive\n  bibliographic text dataset of computer science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our current knowledge of scholarly plagiarism is largely based on the\nsimilarity between full text research articles. In this paper, we propose an\ninnovative and novel conceptualization of scholarly plagiarism in the form of\nreuse of explicit citation sentences in scientific research articles. Note that\nwhile full-text plagiarism is an indicator of a gross-level behavior, copying\nof citation sentences is a more nuanced micro-scale phenomenon observed even\nfor well-known researchers. The current work poses several interesting\nquestions and attempts to answer them by empirically investigating a large\nbibliographic text dataset from computer science containing millions of lines\nof citation sentences. In particular, we report evidences of massive copying\nbehavior. We also present several striking real examples throughout the paper\nto showcase widespread adoption of this undesirable practice. In contrast to\nthe popular perception, we find that copying tendency increases as an author\nmatures. The copying behavior is reported to exist in all fields of computer\nscience; however, the theoretical fields indicate more copying than the applied\nfields.\n", "versions": [{"version": "v1", "created": "Sat, 6 May 2017 16:16:36 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Singh", "Mayank", ""], ["Niranjan", "Abhishek", ""], ["Gupta", "Divyansh", ""], ["Bakshi", "Nikhil Angad", ""], ["Mukherjee", "Animesh", ""], ["Goyal", "Pawan", ""]]}, {"id": "1705.03178", "submitter": "Mayank Singh", "authors": "Mayank Singh, Ajay Jaiswal, Priya Shree, Arindam Pal, Animesh\n  Mukherjee, Pawan Goyal", "title": "Understanding the Impact of Early Citers on Long-Term Scientific Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores an interesting new dimension to the challenging problem\nof predicting long-term scientific impact (LTSI) usually measured by the number\nof citations accumulated by a paper in the long-term. It is well known that\nearly citations (within 1-2 years after publication) acquired by a paper\npositively affects its LTSI. However, there is no work that investigates if the\nset of authors who bring in these early citations to a paper also affect its\nLTSI. In this paper, we demonstrate for the first time, the impact of these\nauthors whom we call early citers (EC) on the LTSI of a paper. Note that this\nstudy of the complex dynamics of EC introduces a brand new paradigm in citation\nbehavior analysis. Using a massive computer science bibliographic dataset we\nidentify two distinct categories of EC - we call those authors who have high\noverall publication/citation count in the dataset as influential and the rest\nof the authors as non-influential. We investigate three characteristic\nproperties of EC and present an extensive analysis of how each category\ncorrelates with LTSI in terms of these properties. In contrast to popular\nperception, we find that influential EC negatively affects LTSI possibly owing\nto attention stealing. To motivate this, we present several representative\nexamples from the dataset. A closer inspection of the collaboration network\nreveals that this stealing effect is more profound if an EC is nearer to the\nauthors of the paper being investigated. As an intuitive use case, we show that\nincorporating EC properties in the state-of-the-art supervised citation\nprediction models leads to high performance margins. At the closing, we present\nan online portal to visualize EC statistics along with the prediction results\nfor a given query paper.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 05:14:46 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Singh", "Mayank", ""], ["Jaiswal", "Ajay", ""], ["Shree", "Priya", ""], ["Pal", "Arindam", ""], ["Mukherjee", "Animesh", ""], ["Goyal", "Pawan", ""]]}, {"id": "1705.03258", "submitter": "Saeed-Ul Hassan", "authors": "Saeed-Ul Hassan, Mubashir Imran, Uzair Gillani, Naif Radi Aljohani,\n  Timothy D. Bowman, Fereshteh Didegah", "title": "Measuring Social Media Activity of Scientific Literature: An Exhaustive\n  Comparison of Scopus and Novel Altmetrics Big Data", "comments": "34 Pages, 3 Figures, 15 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper measures social media activity of 15 broad scientific disciplines\nindexed in Scopus database using Altmetric.com data. First, the presence of\nAltmetric.com data in Scopus database is investigated, overall and across\ndisciplines. Second, the correlation between the bibliometric and altmetric\nindices is examined using Spearman correlation. Third, a zero-truncated\nnegative binomial model is used to determine the association of various factors\nwith increasing or decreasing citations. Lastly, the effectiveness of altmetric\nindices to identify publications with high citation impact is comprehensively\nevaluated by deploying Area Under the Curve (AUC) - an application of receiver\noperating characteristic. Results indicate a rapid increase in the presence of\nAltmetric.com data in Scopus database from 10.19% in 2011 to 20.46% in 2015. A\nzero-truncated negative binomial model is implemented to measure the extent to\nwhich different bibliometric and altmetric factors contribute to citation\ncounts. Blog count appears to be the most important factor increasing the\nnumber of citations by 38.6% in the field of Health Professions and Nursing,\nfollowed by Twitter count increasing the number of citations by 8% in the field\nof Physics and Astronomy. Interestingly, both Blog count and Twitter count\nalways show positive increase in the number of citations across all fields.\nWhile there was a positive weak correlation between bibliometric and altmetric\nindices, the results show that altmetric indices can be a good indicator to\ndiscriminate highly cited publications, with an encouragingly AUC= 0.725\nbetween highly cited publications and total altmetric count. Overall, findings\nsuggest that altmetrics could better distinguish highly cited publications.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 10:12:03 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 07:40:02 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Hassan", "Saeed-Ul", ""], ["Imran", "Mubashir", ""], ["Gillani", "Uzair", ""], ["Aljohani", "Naif Radi", ""], ["Bowman", "Timothy D.", ""], ["Didegah", "Fereshteh", ""]]}, {"id": "1705.03272", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff, Caroline S. Wagner, and Lutz Bornmann", "title": "Betweenness and Diversity in Journal Citation Networks as Measures of\n  Interdisciplinarity -- A Tribute to Eugene Garfield --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Journals were central to Eugene Garfield's research interests. Among other\nthings, journals are considered as units of analysis for bibliographic\ndatabases such as the Web of Science (WoS) and Scopus. In addition to\ndisciplinary classifications of journals, journal citation patterns span\nnetworks across boundaries to variable extents. Using betweenness centrality\n(BC) and diversity, we elaborate on the question of how to distinguish and rank\njournals in terms of interdisciplinarity. Interdisciplinarity, however, is\ndifficult to operationalize in the absence of an operational definition of\ndisciplines, the diversity of a unit of analysis is sample-dependent. BC can be\nconsidered as a measure of multi-disciplinarity. Diversity of co-citation in a\nciting document has been considered as an indicator of knowledge integration,\nbut an author can also generate trans-disciplinary--that is,\nnon-disciplined--variation by citing sources from other disciplines. Diversity\nin the bibliographic coupling among citing documents can analogously be\nconsidered as diffusion of knowledge across disciplines. Because the citation\nnetworks in the cited direction reflect both structure and variation, diversity\nin this direction is perhaps the best available measure of interdisciplinarity\nat the journal level. Furthermore, diversity is based on a summation and can\ntherefore be decomposed, differences among (sub)sets can be tested for\nstatistical significance. In an appendix, a general-purpose routine for\nmeasuring diversity in networks is provided.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 10:55:28 GMT"}, {"version": "v2", "created": "Sun, 14 May 2017 19:41:53 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Leydesdorff", "Loet", ""], ["Wagner", "Caroline S.", ""], ["Bornmann", "Lutz", ""]]}, {"id": "1705.03339", "submitter": "Enrique Ordu\\~na-Malea", "authors": "Enrique Orduna-Malea, Alberto Martin-Martin, Mike Thelwall, Emilio\n  Delgado Lopez-Cozar", "title": "Do ResearchGate Scores create ghost academic reputations?", "comments": "19 pages, 7 tables, 4 figures", "journal-ref": null, "doi": "10.1007/s11192-017-2396-9", "report-no": null, "categories": "cs.SI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The academic social network site ResearchGate (RG) has its own indicator, RG\nScore, for its members. The high profile nature of the site means that the RG\nscore may be used for recruitment, promotion and other tasks for which\nresearchers are evaluated. In response, this study investigates whether it is\nreasonable to employ the RG Score as evidence of scholarly reputation. For\nthis, three different author samples were investigated. An outlier sample\nincludes 104 authors with high values. A Nobel sample comprises 73 Nobel\nwinners from Medicine & Physiology, Chemistry, Physics and Economics (from 1975\nto 2015). A longitudinal sample includes weekly data on 4 authors with\ndifferent RG Scores. The results suggest that high RG Scores are built\nprimarily from activity related to asking and answering questions in the site.\nIn particular, it seems impossible to get a high RG Score solely through\npublications. Within RG it is possible to distinguish between (passive)\nacademics that interact little in the site and active platform users, who can\nget high RG Scores through engaging with others inside the site (questions,\nanswers, social networks with influential researchers). Thus, RG Scores should\nnot be mistaken for academic reputation indicators.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 14:09:33 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Orduna-Malea", "Enrique", ""], ["Martin-Martin", "Alberto", ""], ["Thelwall", "Mike", ""], ["Lopez-Cozar", "Emilio Delgado", ""]]}, {"id": "1705.04517", "submitter": "Jorge Ma\\~nana-Rodr\\'iguez", "authors": "Elea Gim\\'enez-Toledo and Jorge Ma\\~nana-Rodr\\'iguez", "title": "Is there agreement on the prestige of scholarly book publishers in the\n  Humanities? DELPHI over survey results", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite having an important role supporting assessment processes, criticism\ntowards evaluation systems and the categorizations used are frequent.\nConsidering the acceptance by the scientific community as an essential issue\nfor using rankings or categorizations in research evaluation, the aim of this\npaper is testing the results of rankings of scholarly book publishers'\nprestige, Scholarly Publishers Indicators (SPI hereafter). SPI is a public,\nsurvey-based ranking of scholarly publishers' prestige (among other\nindicators). The latest version of the ranking (2014) was based on an expert\nconsultation with a large number of respondents. In order to validate and\nrefine the results for Humanities' fields as proposed by the assessment\nagencies, a Delphi technique was applied with a panel of randomly selected\nexperts over the initial rankings. The results show an equalizing effect of the\ntechnique over the initial rankings as well as a high degree of concordance\nbetween its theoretical aim (consensus among experts) and its empirical results\n(summarized with Gini Index). The resulting categorization is understood as\nmore conclusive and susceptible of being accepted by those under evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 11:30:01 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Gim\u00e9nez-Toledo", "Elea", ""], ["Ma\u00f1ana-Rodr\u00edguez", "Jorge", ""]]}, {"id": "1705.05311", "submitter": "Lukas Galke", "authors": "Lukas Galke, Florian Mai, Alan Schelten, Dennis Brunsch, Ansgar Scherp", "title": "Using Titles vs. Full-text as Source for Automated Semantic Document\n  Annotation", "comments": "Accepted as SHORT PAPER by K-CAP 2017, 9 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant part of the largest Knowledge Graph today, the Linked Open Data\ncloud, consists of metadata about documents such as publications, news reports,\nand other media articles. While the widespread access to the document metadata\nis a tremendous advancement, it is yet not so easy to assign semantic\nannotations and organize the documents along semantic concepts. Providing\nsemantic annotations like concepts in SKOS thesauri is a classical research\ntopic, but typically it is conducted on the full-text of the documents. For the\nfirst time, we offer a systematic comparison of classification approaches to\ninvestigate how far semantic annotations can be conducted using just the\nmetadata of the documents such as titles published as labels on the Linked Open\nData cloud. We compare the classifications obtained from analyzing the\ndocuments' titles with semantic annotations obtained from analyzing the\nfull-text. Apart from the prominent text classification baselines kNN and SVM,\nwe also compare recent techniques of Learning to Rank and neural networks and\nrevisit the traditional methods logistic regression, Rocchio, and Naive Bayes.\nThe results show that across three of our four datasets, the performance of the\nclassifications using only titles reaches over 90% of the quality compared to\nthe classification performance when using the full-text. Thus, conducting\ndocument classification by just using the titles is a reasonable approach for\nautomated semantic annotation and opens up new possibilities for enriching\nKnowledge Graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 16:07:35 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 10:05:49 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Galke", "Lukas", ""], ["Mai", "Florian", ""], ["Schelten", "Alan", ""], ["Brunsch", "Dennis", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1705.05840", "submitter": "Wolfgang Kerzendorf", "authors": "W. E. Kerzendorf", "title": "Knowledge discovery through text-based similarity searches for astronomy\n  literature", "comments": "6 pages, 5 figures, subm., comments welcome", "journal-ref": null, "doi": "10.1007/s12036-019-9590-5", "report-no": null, "categories": "cs.DL astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in the number of researchers coupled with the ease of publishing\nand distribution of scientific papers (due to technological advancements) has\nresulted in a dramatic increase in astronomy literature. This has likely led to\nthe predicament that the body of the literature is too large for traditional\nhuman consumption and that related and crucial knowledge is not discovered by\nresearchers. In addition to the increased production of astronomical\nliterature, recent decades have also brought several advancements in\ncomputational linguistics. Especially, the machine-aided processing of\nliterature dissemination might make it possible to convert this stream of\npapers into a coherent knowledge set. In this paper, we present the application\nof computational linguistics techniques to astronomy literature. In particular,\nwe developed a tool that will find similar articles purely based on text\ncontent from an input paper. We find that our technique performs robustly in\ncomparison with other tools recommending articles given a reference paper\n(known as recommender system). Our novel tool shows the great power in\ncombining computational linguistics with astronomy literature and suggests that\nadditional research in this endeavor will likely produce even better tools that\nwill help researchers cope with the vast amounts of knowledge being produced.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 18:00:01 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 15:39:32 GMT"}, {"version": "v3", "created": "Thu, 16 Aug 2018 12:26:55 GMT"}, {"version": "v4", "created": "Mon, 20 Aug 2018 14:07:27 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kerzendorf", "W. E.", ""]]}, {"id": "1705.06110", "submitter": "Henk Moed", "authors": "Henk F. Moed", "title": "Applied Evaluative Informetrics: Part 1", "comments": "The posted version is a preprint (author copy) of Part 1 (General\n  Introduction and Synopsis) of a book entitled Applied Evaluative\n  Bibliometrics, to be published by Springer in the summer of 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript is a preprint version of Part 1 (General Introduction and\nSynopsis) of the book Applied Evaluative Informetrics, to be published by\nSpringer in the summer of 2017. This book presents an introduction to the field\nof applied evaluative informetrics, and is written for interested scholars and\nstudents from all domains of science and scholarship. It sketches the field's\nhistory, recent achievements, and its potential and limits. It explains the\nnotion of multi-dimensional research performance, and discusses the pros and\ncons of 28 citation-, patent-, reputation- and altmetrics-based indicators. In\naddition, it presents quantitative research assessment as an evaluation\nscience, and focuses on the role of extra-informetric factors in the\ndevelopment of indicators, and on the policy context of their application. It\nalso discusses the way forward, both for users and for developers of\ninformetric tools.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 12:00:23 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Moed", "Henk F.", ""]]}, {"id": "1705.06218", "submitter": "Yasmin AlNoamany", "authors": "Yasmin AlNoamany, Michele C. Weigle, Michael L. Nelson", "title": "Stories From the Past Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archiving Web pages into themed collections is a method for ensuring these\nresources are available for posterity. Services such as Archive-It exists to\nallow institutions to develop, curate, and preserve collections of Web\nresources. Understanding the contents and boundaries of these archived\ncollections is a challenge for most people, resulting in the paradox of the\nlarger the collection, the harder it is to understand. Meanwhile, as the sheer\nvolume of data grows on the Web, \"storytelling\" is becoming a popular technique\nin social media for selecting Web resources to support a particular narrative\nor \"story\". There are multiple stories that can be generated from an archived\ncollection with different perspectives about the collection. For example, a\nuser may want to see a story that is composed of the key events from a specific\nWeb site, a story that is composed of the key events of the story regardless of\nthe sources, or how a specific event at a specific point in time was covered by\ndifferent Web sites, etc. In this paper, we provide different case studies for\npossible types of stories that can be extracted from a collection. We also\nprovide the definitions and models of these types of stories.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 15:39:10 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["AlNoamany", "Yasmin", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "1705.06510", "submitter": "Alessio Cardillo", "authors": "Andrea Martini and Alessio Cardillo and Paolo De Los Rios", "title": "Entropic selection of concepts unveils hidden topics in documents\n  corpora", "comments": "Main + SI. Major overhaul after first round of review", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The organization and evolution of science has recently become itself an\nobject of scientific quantitative investigation, thanks to the wealth of\ninformation that can be extracted from scientific documents, such as citations\nbetween papers and co-authorship between researchers. However, only few studies\nhave focused on the concepts that characterize full documents and that can be\nextracted and analyzed, revealing the deeper organization of scientific\nknowledge. Unfortunately, several concepts can be so common across documents\nthat they hinder the emergence of the underlying topical structure of the\ndocument corpus, because they give rise to a large amount of spurious and\ntrivial relations among documents. To identify and remove common concepts, we\nintroduce a method to gauge their relevance according to an objective\ninformation-theoretic measure related to the statistics of their occurrence\nacross the document corpus. After progressively removing concepts that,\naccording to this metric, can be considered as generic, we find that the topic\norganization displays a correspondingly more refined structure.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 10:24:03 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 07:17:34 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Martini", "Andrea", ""], ["Cardillo", "Alessio", ""], ["Rios", "Paolo De Los", ""]]}, {"id": "1705.07862", "submitter": "Joshua Finnell", "authors": "Joshua Finnell, Martin Klein and Brian J. Cain", "title": "Nucleus: A Pilot Project", "comments": "13 pages, report", "journal-ref": null, "doi": null, "report-no": "LA-UR-17-23791", "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Early in 2016, an environmental scan was conducted by the Research Library\nData Working Group for three purposes:\n  1.) Perform a survey of the data management landscape at Los Alamos National\nLaboratory in order to identify local gaps in data management services.\n  2.) Conduct an environmental scan of external institutions to benchmark\nbudgets, infrastructure, and personnel dedicated to data management.\n  3.) Draft a research data infrastructure model that aligns with the current\nworkflow and classification restrictions at Los Alamos National Laboratory.\n  This report is a summary of those activities and the draft for a pilot data\nmanagement project.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 17:09:17 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Finnell", "Joshua", ""], ["Klein", "Martin", ""], ["Cain", "Brian J.", ""]]}, {"id": "1705.08154", "submitter": "Martin K\\\"orner", "authors": "Martin K\\\"orner", "title": "Reference String Extraction Using Line-Based Conditional Random Fields", "comments": "5 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The extraction of individual reference strings from the reference section of\nscientific publications is an important step in the citation extraction\npipeline. Current approaches divide this task into two steps by first detecting\nthe reference section areas and then grouping the text lines in such areas into\nreference strings. We propose a classification model that considers every line\nin a publication as a potential part of a reference string. By applying\nline-based conditional random fields rather than constructing the graphical\nmodel based on the individual words, dependencies and patterns that are typical\nin reference sections provide strong features while the overall complexity of\nthe model is reduced.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 09:36:41 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["K\u00f6rner", "Martin", ""]]}, {"id": "1705.08275", "submitter": "J Federico Medrano", "authors": "J. Federico Medrano", "title": "Calidad en repositorios digitales en Argentina, estudio comparativo y\n  cualitativo", "comments": "BIREDIAL-ISTEC 2017, in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerous institutions and organizations need not only to preserve the\nmaterial and publications they produce, but also have as their task (although\nit would be desirable it was an obligation) to publish, disseminate and make\npublicly available all the results of the research and any other\nscientific/academic material. The Open Archives Initiative (OAI) and the\nintroduction of Open Archives Initiative Protocol for Metadata Harvesting\n(OAI-PMH), make this task much easier. The main objective of this work is to\nmake a comparative and qualitative study of the data -metadata specifically-\ncontained in the whole set of Argentine repositories listed in the ROAR portal,\nfocusing on the functional perspective of the quality of this metadata. Another\nobjective is to offer an overview of the status of these repositories, in an\nattempt to detect common failures and errors institutions incur when storing\nthe metadata of the resources contained in these repositories, and thus be able\nto suggest measures to be able to improve the load and further retrieval\nprocesses. It was found that the eight most used Dublin Core fields are:\nidentifier, type, title, date, subject, creator, language and description. Not\nall repositories fill all the fields, and the lack of normalization, or the\nexcessive use of fields like language, type, format and subject is somewhat\nstriking, and in some cases even alarming\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 14:00:24 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Medrano", "J. Federico", ""]]}, {"id": "1705.08730", "submitter": "Phillip Lord Dr", "authors": "Michael J Bell, Phillip Lord", "title": "On Patterns and Re-Use in Bioinformatics Databases", "comments": null, "journal-ref": "Bioinformatics 2017", "doi": "10.1093/bioinformatics/btx310", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the quantity of data being depositing into biological databases continues\nto increase, it becomes ever more vital to develop methods that enable us to\nunderstand this data and ensure that the knowledge is correct. It is\nwidely-held that data percolates between different databases, which causes\nparticular concerns for data correctness; if this percolation occurs, incorrect\ndata in one database may eventually affect many others while, conversely,\ncorrections in one database may fail to percolate to others.\n  In this paper, we test this widely-held belief by directly looking for\nsentence reuse both within and between databases. Further, we investigate\npatterns of how sentences are reused over time. Finally, we consider the\nlimitations of this form of analysis and the implications that this may have\nfor bioinformatics database design.\n  We show that reuse of annotation is common within many different databases,\nand that also there is a detectable level of reuse between databases. In\naddition, we show that there are patterns of reuse that have previously been\nshown to be associated with percolation errors.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 12:47:18 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Bell", "Michael J", ""], ["Lord", "Phillip", ""]]}, {"id": "1705.08816", "submitter": "Anna Samoilenko", "authors": "Anna Samoilenko and Florian Lemmerich and Katrin Weller and Maria Zens\n  and Markus Strohmaier", "title": "Analysing Timelines of National Histories across Wikipedia Editions: A\n  Comparative Computational Approach", "comments": null, "journal-ref": "Proceedings of the Eleventh International AAAI Conference on Web\n  an Social Media (ICWSM 2017 in Montreal, Canada)", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portrayals of history are never complete, and each description inherently\nexhibits a specific viewpoint and emphasis. In this paper, we aim to\nautomatically identify such differences by computing timelines and detecting\ntemporal focal points of written history across languages on Wikipedia. In\nparticular, we study articles related to the history of all UN member states\nand compare them in 30 language editions. We develop a computational approach\nthat allows to identify focal points quantitatively, and find that Wikipedia\nnarratives about national histories (i) are skewed towards more recent events\n(recency bias) and (ii) are distributed unevenly across the continents with\nsignificant focus on the history of European countries (Eurocentric bias). We\nalso establish that national historical timelines vary across language\neditions, although average interlingual consensus is rather high. We hope that\nthis paper provides a starting point for a broader computational analysis of\nwritten history on Wikipedia and elsewhere.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 15:23:37 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Samoilenko", "Anna", ""], ["Lemmerich", "Florian", ""], ["Weller", "Katrin", ""], ["Zens", "Maria", ""], ["Strohmaier", "Markus", ""]]}, {"id": "1705.09390", "submitter": "Roberto Piazza", "authors": "Roberto Piazza", "title": "On the \"persistency\" of scientific publications: introducing an h-index\n  for journals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What do we really mean by a \"good\" scientific journal? Do we care more about\nthe short-time impact of our papers, or about the chance that they will still\nbe read and cited on the long run? Here I show that, by regarding a journal as\na \"virtual scientist\" that can be attributed a time-dependent Hirsch h-index,\nwe can introduce a parameter that, arguably, better captures the \"persistency\"\nof a scientific publication. Curiously, however, this parameter seems to depend\nabove all on the \"thickness\" of a journal.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 07:05:00 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Piazza", "Roberto", ""]]}]