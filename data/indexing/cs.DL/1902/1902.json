[{"id": "1902.00712", "submitter": "Flavio Moraes", "authors": "Flavio C. D. Moraes, Ana Lia Leonel, Pedro H. C. Torres, Pedro R.\n  Jacobi, Sandra Momm", "title": "Climate Change and Social Sciences: a bibliometric analysis", "comments": "13 pages 10 figures", "journal-ref": "V!rus, Sao Carlos, 20 (2020)", "doi": "10.4237/virus_journal", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of emergent wicked problems, such as climate change,\nculminates in a reformulation of how we think about society and mobilize\nscientists from various disciplines to seek solutions and perspectives on the\nproblem. From an epistemological point of view, it is essential to evaluate how\nsuch topics can be developed inside the academic arena but, to do that, it is\nnecessary to perform complex analysis of the great number of recent academic\npublications. In this work, we discuss how climate change has been addressed by\nsocial sciences in practice. Can we observe the development of a new\nepistemology by the emergence of the climate change debate? Are there\ncontributions in academic journals within the field of social sciences\naddressing climate change? Which journals are these? Who are the authors? To\nanswer these questions, we developed an innovative method combining different\ntools to search, filter, and analyze the impact of the academic production\nrelated to climate change in social sciences in the most relevant journals.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 13:00:26 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 05:53:51 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 18:18:11 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Moraes", "Flavio C. D.", ""], ["Leonel", "Ana Lia", ""], ["Torres", "Pedro H. C.", ""], ["Jacobi", "Pedro R.", ""], ["Momm", "Sandra", ""]]}, {"id": "1902.00952", "submitter": "Leshang Chen", "authors": "Leshang Chen, Susan Davidson", "title": "Automating Software Citation using GitCite", "comments": null, "journal-ref": "2020 IEEE 36th International Conference on Data Engineering\n  (ICDE), Dallas, TX, USA, 2020, pp. 1754-1757", "doi": "10.1109/ICDE48307.2020.00162", "report-no": null, "categories": "cs.DB cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to cite software and give credit to its authors and contributors\nis increasingly important. While the number of online open-source software\nrepositories has grown rapidly over the past few years, few are being properly\ncited when used due to the difficulty of creating appropriate citations and the\nlack of automated techniques. This paper presents GitCite, a model for software\ncitation with version control which enables citations to be inferred for any\nproject component based on a small number of explicit citations attached to\nsubdirectories/files, and an implementation that integrates with Git and\nGitHub. The implementation includes a browser extension and a local executable\ntool, which enable citations to be added/modified/deleted to software project\nrepositories and managed through functions such as fork/merge/copy.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 18:43:25 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 17:14:03 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 22:25:22 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 23:59:19 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chen", "Leshang", ""], ["Davidson", "Susan", ""]]}, {"id": "1902.01333", "submitter": "Barbara McGillivray", "authors": "Barbara McGillivray (The Alan Turing Institute and University of\n  Cambridge) and Mathias Astell (Hindawi Limited)", "title": "The relationship between usage and citations in an open access mega\n  journal", "comments": "22 pages, 7 figures. Scientometrics (2019)", "journal-ref": null, "doi": "10.1007/s11192-019-03228-3", "report-no": null, "categories": "cs.DL stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How do the level of usage of an article, the timeframe of its usage and its\nsubject area relate to the number of citations it accrues? This paper aims to\nanswer this question through an observational study of usage and citation data\ncollected about the multidisciplinary, open access mega-journal Scientific\nReports. This observational study answers these questions using the following\nmethods: an overlap analysis of most read and top-cited articles; Spearman\ncorrelation tests between total citation counts over two years and usage over\nvarious timeframes; a comparison of first months of citation for most read and\nall articles; a Wilcoxon test on the distribution of total citations of early\ncited articles and the distribution of total citations of all other articles.\nAll analyses were performed using the programming language R. As Scientific\nReports is a multidisciplinary journal covering all natural and clinical\nsciences, we also looked at the differences across subjects. We found a\nmoderate correlation between usage in the first year and citations in the first\ntwo years since publication, and that articles with high usage in the first 6\nmonths are more likely to have their first citation earlier (Wilcoxon=1811500,\np < 0.0001), which is also related to higher citations in the first two years\n(Wilcoxon=8071200, p < 0.0001). As this final assertion is inferred based on\nthe results of the other elements of this paper, it requires further analysis.\nMoreover, our choice of a 2 year window for our analysis did not consider the\narticles' citation half-life, and our use of Scientific Reports (a journal that\nis atypical compared to most academic journals) as the source of the articles\nanalysed has likely played a role in our findings, and so analysing a longer\ntimeframe and carrying out similar analysis on a different journal (or group of\njournals) may lead to different conclusions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:44:20 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 15:06:23 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 17:55:16 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 17:07:07 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["McGillivray", "Barbara", "", "The Alan Turing Institute and University of\n  Cambridge"], ["Astell", "Mathias", "", "Hindawi Limited"]]}, {"id": "1902.01693", "submitter": "Riccardo Torre", "authors": "Paolo Rossi, Alessandro Strumia, Riccardo Torre", "title": "Bibliometrics for collaboration works", "comments": "v1: 9 pages, 5 figures; v2: extension of the version published in the\n  proceedings of the ISSI 2019 conference (v1), with updated data and a new\n  discussion about the $h$ index; 16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL hep-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in bibliometrics is the weighing of co-authorship in the\nproduction of scientific collaborations, which are becoming the standard\nmodality of research activity in many disciplines. The problem is especially\nrelevant in the field of high-energy physics, where collaborations reach 3000\nauthors, but it can no longer be ignored also in other domains, like medicine\nor biology. We present theoretical and numerical arguments in favour of\nweighing the individual contributions as $1/N_{\\rm aut}^\\alpha$ where $N_{\\rm\naut}$ is the number of co-authors. When counting citations we suggest the\nexponent $\\alpha\\approx 1$, that corresponds to fractional counting. When\ncounting the number of papers we suggest $\\alpha \\approx 1/3 - 1/2$, with the\nformer (latter) value more appropriate for larger (smaller) collaborations. We\nexpect and verify that the $h$ index scales as the square root of the average\nnumber of co-authors, and define a fractionalized $h$ index that does not scale\nwith collaboration size.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 07:36:47 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 12:03:33 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Rossi", "Paolo", ""], ["Strumia", "Alessandro", ""], ["Torre", "Riccardo", ""]]}, {"id": "1902.01790", "submitter": "Fabio Crestani Prof.", "authors": "Fabio Crestani, Stefano Mizzaro, Ivan Scagnetto", "title": "Mobile Information Retrieval", "comments": "116 pages, published in 2017", "journal-ref": null, "doi": "10.1007/978-3-319-60777-1", "report-no": null, "categories": "cs.IR cs.DL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Information Retrieval (Mobile IR) is a relatively recent branch of\nInformation Retrieval (IR) that is concerned with enabling users to carry out,\nusing a mobile device, all the classical IR operations that they were used to\ncarry out on a desktop. This includes finding content available on local\nrepositories or on the web in response to a user query, interacting with the\nsystem in an explicit or implicit way, reformulate the query and/or visualise\nthe content of the retrieved documents, as well as providing relevance\njudgments to improve the retrieval process.\n  This book is structured as follows. Chapter 2 provides a very brief overview\nof IR and of Mobile IR, briefly outlining what in Mobile IR is different from\nIR. Chapter 3 provides the foundations of Mobile IR, looking at the\ncharacteristics of mobile devices and what they bring to IR, but also looking\nat how the concept of relevance changed from standard IR to Mobile IR. Chapter\n4 presents an overview of the document collections that are searchable by a\nMobile IR system, and that are somehow different from classical IR ones;\navailable for experimentation, including collections of data that have become\ncomplementary to Mobile IR. Similarly, Chapter 5 reviews mobile information\nneeds studies and users log analysis. Chapter 6 reviews studies aimed at\nadapting and improving the users interface to the needs of Mobile IR. Chapter\n7, instead, reviews work on context awareness, which studies the many aspects\nof the user context that Mobile IR employs. Chapter 8 reviews some of\nevaluation work done in Mobile IR, highlighting the distinctions with classical\nIR from the perspectives of two main IR evaluation methodologies: users studies\nand test collections. Finally, Chapter 9 reports the conclusions of this\nreview, highlighting briefly some trends in Mobile IR that we believe will\ndrive research in the next few years.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 17:00:08 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Crestani", "Fabio", ""], ["Mizzaro", "Stefano", ""], ["Scagnetto", "Ivan", ""]]}, {"id": "1902.02534", "submitter": "Silvio Peroni", "authors": "Ivan Heibi, Silvio Peroni, David Shotton", "title": "Crowdsourcing open citations with CROCI -- An analysis of the current\n  status of open citations, and a proposal", "comments": "7 pages, 3 figures, accepted to ISSI 2019 (https://www.issi2019.org/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyse the current availability of open citations data in\none particular dataset, namely COCI (the OpenCitations Index of Crossref open\nDOI-to-DOI citations; http://opencitations.net/index/coci) provided by\nOpenCitations. The results of these analyses show a persistent gap in the\ncoverage of the currently available open citation data. In order to address\nthis specific issue, we propose a strategy whereby the community (e.g. scholars\nand publishers) can directly involve themselves in crowdsourcing open\ncitations, by uploading their citation data via the OpenCitations\ninfrastructure into our new index, CROCI, the Crowdsourced Open Citations\nIndex.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:22:51 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 06:21:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Heibi", "Ivan", ""], ["Peroni", "Silvio", ""], ["Shotton", "David", ""]]}, {"id": "1902.03287", "submitter": "Silvio Peroni", "authors": "Angelo Di Iorio, Silvio Peroni, Francesco Poggi", "title": "Open data to evaluate academic researchers: an experiment with the\n  Italian Scientific Habilitation", "comments": "12 pages, 1 figure, 6 tables, submitted to the 17th International\n  Conference on Scientometrics and Informentrics (ISSI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need for scholarly open data is ever increasing. While there are large\nrepositories of open access articles and free publication indexes, there are\nstill a few examples of free citation networks and their coverage is partial.\nOne of the results is that most of the evaluation processes based on citation\ncounts rely on commercial citation databases. Things are changing under the\npressure of the Initiative for Open Citations (I4OC), whose goal is to campaign\nfor scholarly publishers to make their citations as totally open. This paper\ninvestigates the growth of open citations with an experiment on the Italian\nScientific Habilitation, the National process for University Professor\nqualification which instead uses data from commercial indexes. We simulated the\nprocedure by only using open data and explored similarities and differences\nwith the official results. The outcomes of the experiment show that the amount\nof open citation data currently available is not yet enough for obtaining\nsimilar results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 20:46:25 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Di Iorio", "Angelo", ""], ["Peroni", "Silvio", ""], ["Poggi", "Francesco", ""]]}, {"id": "1902.03937", "submitter": "Aliakbar Akbaritabar", "authors": "Aliakbar Akbaritabar, Stephan Stahlschmidt", "title": "Merits and Limits: Applying open data to monitor open access\n  publications in bibliometric databases", "comments": "7 pages, 2 figures, 6 tables, submitted to ISSI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying and monitoring Open Access (OA) publications might seem a trivial\ntask while practical efforts prove otherwise. Contradictory information arise\noften depending on metadata employed. We strive to assign OA status to\npublications in Web of Science (WOS) and Scopus while complementing it with\ndifferent sources of OA information to resolve contradicting cases. We linked\npublications from WOS and Scopus via DOIs and ISSNs to Unpaywall, Crossref,\nDOAJ and ROAD. Only about 50% of articles and reviews from WOS and Scopus could\nbe matched via a DOI to Unpaywall. Matching with Crossref brought 56 distinct\nlicences, which define in many cases the legally binding access status of\npublications. But only 44% of publications hold only a single licence on\nCrossref, while more than 50% have no licence information submitted to\nCrossref. Contrasting OA information from Crossref licences with Unpaywall we\nfound contradictory cases overall amounting to more than 25%, which might be\npartially explained by (ex-)including green OA. A further manual check found\nabout 17% of OA publications that are not accessible and 15% non-OA\npublications that are accessible through publishers' websites. These\npreliminary results suggest that identification of OA state of publications\ndenotes a difficult and currently unfulfilled task.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:10:40 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 07:52:01 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Akbaritabar", "Aliakbar", ""], ["Stahlschmidt", "Stephan", ""]]}, {"id": "1902.04298", "submitter": "Cristian Consonni", "authors": "Cristian Consonni, David Laniado and Alberto Montresor", "title": "WikiLinkGraphs: A Complete, Longitudinal and Multi-Language Dataset of\n  the Wikipedia Link Networks", "comments": "10 pages, 3 figures, 7 tables, LaTeX. Final camera-ready version\n  accepted at the 13TH International AAAI Conference on Web and Social Media\n  (ICWSM 2019) - Munich (Germany), 11-14 June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Wikipedia articles contain multiple links connecting a subject to other pages\nof the encyclopedia. In Wikipedia parlance, these links are called internal\nlinks or wikilinks. We present a complete dataset of the network of internal\nWikipedia links for the $9$ largest language editions. The dataset contains\nyearly snapshots of the network and spans $17$ years, from the creation of\nWikipedia in 2001 to March 1st, 2018. While previous work has mostly focused on\nthe complete hyperlink graph which includes also links automatically generated\nby templates, we parsed each revision of each article to track links appearing\nin the main text. In this way we obtained a cleaner network, discarding more\nthan half of the links and representing all and only the links intentionally\nadded by editors. We describe in detail how the Wikipedia dumps have been\nprocessed and the challenges we have encountered, including the need to handle\nspecial pages such as redirects, i.e., alternative article titles. We present\ndescriptive statistics of several snapshots of this network. Finally, we\npropose several research opportunities that can be explored using this new\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 09:47:05 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 10:15:00 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Consonni", "Cristian", ""], ["Laniado", "David", ""], ["Montresor", "Alberto", ""]]}, {"id": "1902.05170", "submitter": "Christine Betts", "authors": "Christine Betts, Joanna Power, Waleed Ammar", "title": "GrapAL: Connecting the Dots in Scientific Literature", "comments": "To appear at ACL 2019 (Demonstration Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GrapAL (Graph database of Academic Literature), a versatile tool\nfor exploring and investigating a knowledge base of scientific literature, that\nwas semi-automatically constructed using NLP methods. GrapAL satisfies a\nvariety of use cases and information needs requested by researchers. At the\ncore of GrapAL is a Neo4j graph database with an intuitive schema and a simple\nquery language. In this paper, we describe the basic elements of GrapAL, how to\nuse it, and several use cases such as finding experts on a given topic for peer\nreviewing, discovering indirect connections between biomedical entities and\ncomputing citation-based metrics. We open source the demo code to help other\nresearchers develop applications that build on GrapAL.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 00:07:26 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 19:11:16 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Betts", "Christine", ""], ["Power", "Joanna", ""], ["Ammar", "Waleed", ""]]}, {"id": "1902.05265", "submitter": "Ulrich Z\\\"ulicke", "authors": "K. W. Higham, M. Governale, A. B. Jaffe, U. Z\\\"ulicke", "title": "Ex-ante measure of patent quality reveals intrinsic fitness for\n  citation-network growth", "comments": "6 pages, 3 figures, RevTex4.1, v2: minor changes, version to appear\n  as a Rapid Communication in Phys. Rev. E", "journal-ref": "Phys. Rev. E 99, 060301 (2019)", "doi": "10.1103/PhysRevE.99.060301", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have constructed a fitness parameter, characterizing the intrinsic\nattractiveness for patents to be cited, from attributes of the associated\ninventions known at the time a patent is granted. This exogenously obtained\nfitness is shown to determine the temporal growth of the citation network in\nconjunction with mechanisms of preferential attachment and obsolescence-induced\nageing that operate without reference to characteristics of individual patents.\nOur study opens a window on understanding quantitatively the interplay of the\nrich-gets-richer and fit-gets-richer paradigms that have been suggested to\ngovern the growth dynamics of real-world complex networks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 08:57:27 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:35:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Higham", "K. W.", ""], ["Governale", "M.", ""], ["Jaffe", "A. B.", ""], ["Z\u00fclicke", "U.", ""]]}, {"id": "1902.05423", "submitter": "Felicie Faizand de Maupeou", "authors": "F\\'elicie Faizand de Maupeou (HAR)", "title": "The artist libraries project", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of the Artist Libraries Project was sparked by the observation\nthat artist libraries are still not well known, yet many art historians are\ninterested in this archive for the value it adds to understanding the person\nbehind the artist and his or her creative process. The problem is that these\nlibraries are rarely physically preserved. To remedy this dispersion, we built\nan online database and a website www.lesbibliothequesdartistes.org that house\nthis valuable source in the form of lists of books and their electronic\nversions. First data on Monet's library was made available, and several\nadditional artist libraries from the 19 th and 20 th centuries are on the way\nfor 2019. By gathering all these bibliographical data in a central database,\nit's possible to explore one library and to compare several. This article\nexplains how we built the database and the website and how the implementation\nof those IT tools has raised questions about the use of this resource as an\narchive on the one hand, as well as its value for art history on the other.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:48:07 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["de Maupeou", "F\u00e9licie Faizand", "", "HAR"]]}, {"id": "1902.06692", "submitter": "Muhammad Fahad Khan", "authors": "Adeel Ahmed, Muhammad Fahad Khan, Muhammad Usman, Khalid Saleem", "title": "Analysis of Coauthorship Network in Political Science using Centrality\n  Measures", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent era, networks of data are growing massively and forming a shape of\ncomplex structure. Data scientists try to analyze different complex networks\nand utilize these networks to understand the complex structure of a network in\na meaningful way. There is a need to detect and identify such a complex network\nin order to know how these networks provide communication means while using the\ncomplex structure. Social network analysis provides methods to explore and\nanalyze such complex networks using graph theories, network properties and\ncommunity detection algorithms. In this paper, an analysis of coauthorship\nnetwork of Public Relation and Public Administration subjects of Microsoft\nAcademic Graph (MAG) is presented, using common centrality measures. The\nauthors belong to different research and academic institutes present all over\nthe world. Cohesive groups of authors have been identified and ranked on the\nbasis of centrality measures, such as betweenness, degree, page rank and\ncloseness. Experimental results show the discovery of authors who are good in\nspecific domain, have a strong field knowledge and maintain collaboration among\ntheir peers in the field of Public Relations and Public Administration.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 01:13:19 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Ahmed", "Adeel", ""], ["Khan", "Muhammad Fahad", ""], ["Usman", "Muhammad", ""], ["Saleem", "Khalid", ""]]}, {"id": "1902.07622", "submitter": "Bingsheng Chen", "authors": "Bingsheng Chen, Zhengyu Lin, Tim S. Evans", "title": "Analysis of the Wikipedia Network of Mathematicians", "comments": "(Updated two captions in the appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look at the network of mathematicians defined by the hyperlinks between\ntheir biographies on Wikipedia. We show how to extract this information using\nthree snapshots of the Wikipedia data, taken in 2013, 2017 and 2018. We\nillustrate how such Wikipedia data can be used by performing a centrality\nanalysis. These measures show that Hilbert and Newton are the most important\nmathematicians. We use our example to illustrate the strengths and weakness of\ncentrality measures and to show how to provide estimates of the robustness of\ncentrality measurements. In part, we do this by comparison to results from two\nother sources: an earlier study of biographies on the MacTutor website and a\nsmall informal survey of the opinion of mathematics and physics students at\nImperial College London.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 16:18:18 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 10:20:59 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Chen", "Bingsheng", ""], ["Lin", "Zhengyu", ""], ["Evans", "Tim S.", ""]]}, {"id": "1902.08746", "submitter": "Mike Thelwall Prof", "authors": "Kayvan Kousha and Mike Thelwall", "title": "Can Google Scholar and Mendeley help to assess the scholarly impacts of\n  dissertations?", "comments": "Kousha, K. & Thelwall, M. (2019). Can Google Scholar and Mendeley\n  help to assess the scholarly impacts of dissertations? Journal of\n  Informetrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dissertations can be the single most important scholarly outputs of junior\nresearchers. Whilst sets of journal articles are often evaluated with the help\nof citation counts from the Web of Science or Scopus, these do not index\ndissertations and so their impact is hard to assess. In response, this article\nintroduces a new multistage method to extract Google Scholar citation counts\nfor large collections of dissertations from repositories indexed by Google. The\nmethod was used to extract Google Scholar citation counts for 77,884 American\ndoctoral dissertations from 2013-2017 via ProQuest, with a precision of over\n95%. Some ProQuest dissertations that were dual indexed with other repositories\ncould not be retrieved with ProQuest-specific searches but could be found with\nGoogle Scholar searches of the other repositories. The Google Scholar citation\ncounts were then compared with Mendeley reader counts, a known source of\nscholarly-like impact data. A fifth of the dissertations had at least one\ncitation recorded in Google Scholar and slightly fewer had at least one\nMendeley reader. Based on numerical comparisons, the Mendeley reader counts\nseem to be more useful for impact assessment purposes for dissertations that\nare less than two years old, whilst Google Scholar citations are more useful\nfor older dissertations, especially in social sciences, arts and humanities.\nGoogle Scholar citation counts may reflect a more scholarly type of impact than\nthat of Mendeley reader counts because dissertations attract a substantial\nminority of their citations from other dissertations. In summary, the new\nmethod now makes it possible for research funders, institutions and others to\nsystematically evaluate the impact of dissertations, although additional Google\nScholar queries for other online repositories are needed to ensure\ncomprehensive coverage.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 06:35:12 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Kousha", "Kayvan", ""], ["Thelwall", "Mike", ""]]}, {"id": "1902.09178", "submitter": "Thomas Scheidsteger", "authors": "Thomas Scheidsteger, Robin Haunschild", "title": "Telling the Early Story of Solar Energy Meteorology by Applying\n  (Co-Citation) Reference Publication Year Spectroscopy", "comments": "11 pages, 4 figures, 1 table", "journal-ref": "17th INTERNATIONAL CONFERENCE ON SCIENTOMETRICS & INFORMETRICS\n  ISSI2019, p. 1964 (2019), ISBN 978-88-3381-118-5", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the history of research fields by analyzing publication records and\ntopical and/or keyword searches with a full Reference Publication Year\nSpectroscopy (RPYS) has been introduced as a powerful tool to identify the\ncorresponding root publications. However, for a rather new and\ninterdisciplinary research field like Solar Energy Meteorology (SEM), this\nmethod is not feasible to get a reasonably exhaustive publication set.\nTherefore we apply its variant RPYS-CO to all publications co-cited with one\nhighly important marker paper, using the CRExplorer for plotting and inspecting\nthe spectrogram of the number of cited references. Examining its peaks and\ntheir main contributing publications, we get a list of seminal papers, which\nare able to adequately tell us the story of SEM up to the 1990s. Generally, we\nrecommend this method to gain valuable insights in (new) research fields.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:16:47 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 14:27:36 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Scheidsteger", "Thomas", ""], ["Haunschild", "Robin", ""]]}, {"id": "1902.10838", "submitter": "Timur Bazhirov", "authors": "Timur Bazhirov", "title": "Data-centric online ecosystem for digital materials science", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.DL physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials science is becoming increasingly more reliant on digital data to\nfacilitate progress in the field. Due to a large diversity in its scope,\nbreadth, and depth, organizing the data in a standard way to optimize the speed\nand creative breadth of the resulting research represents a significant\nchallenge. We outline a modular and extensible ecosystem aimed at facilitating\nresearch work performed in an accessible, collaborative, and agile manner,\nwithout compromising on fidelity, security, and defensibility of the findings.\nWe discuss the critical components of the ecosystem and explain the\nimplementation of data standards and associated tools. We focus initial\nattention on modeling and simulations from nanoscale and explain how to add\nsupport for other domains. Finally, we discuss example applications or the data\nconvention and future outlook.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 23:59:08 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Bazhirov", "Timur", ""]]}, {"id": "1902.11058", "submitter": "Robin Brochier", "authors": "Robin Brochier", "title": "Representation Learning for Recommender Systems with Application to the\n  Scientific Literature", "comments": null, "journal-ref": null, "doi": "10.1145/3308560.3314195", "report-no": null, "categories": "cs.CL cs.DL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scientific literature is a large information network linking various\nactors (laboratories, companies, institutions, etc.). The vast amount of data\ngenerated by this network constitutes a dynamic heterogeneous attributed\nnetwork (HAN), in which new information is constantly produced and from which\nit is increasingly difficult to extract content of interest. In this article, I\npresent my first thesis works in partnership with an industrial company,\nDigital Scientific Research Technology. This later offers a scientific watch\ntool, Peerus, addressing various issues, such as the real time recommendation\nof newly published papers or the search for active experts to start new\ncollaborations. To tackle this diversity of applications, a common approach\nconsists in learning representations of the nodes and attributes of this HAN\nand use them as features for a variety of recommendation tasks. However, most\nworks on attributed network embedding pay too little attention to textual\nattributes and do not fully take advantage of recent natural language\nprocessing techniques. Moreover, proposed methods that jointly learn node and\ndocument representations do not provide a way to effectively infer\nrepresentations for new documents for which network information is missing,\nwhich happens to be crucial in real time recommender systems. Finally, the\ninterplay between textual and graph data in text-attributed heterogeneous\nnetworks remains an open research direction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:53:38 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Brochier", "Robin", ""]]}, {"id": "1902.11116", "submitter": "Miriam Redi", "authors": "Miriam Redi and Besnik Fetahu and Jonathan Morgan and Dario\n  Taraborelli", "title": "Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia's\n  Verifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia is playing an increasingly central role on the web,and the policies\nits contributors follow when sourcing and fact-checking content affect million\nof readers. Among these core guiding principles, verifiability policies have a\nparticularly important role. Verifiability requires that information included\nin a Wikipedia article be corroborated against reliable secondary sources.\nBecause of the manual labor needed to curate and fact-check Wikipedia at scale,\nhowever, its contents do not always evenly comply with these policies.\nCitations (i.e. reference to external sources) may not conform to verifiability\nrequirements or may be missing altogether, potentially weakening the\nreliability of specific topic areas of the free encyclopedia. In this paper, we\naim to provide an empirical characterization of the reasons why and how\nWikipedia cites external sources to comply with its own verifiability\nguidelines. First, we construct a taxonomy of reasons why inline citations are\nrequired by collecting labeled data from editors of multiple Wikipedia language\neditions. We then collect a large-scale crowdsourced dataset of Wikipedia\nsentences annotated with categories derived from this taxonomy. Finally, we\ndesign and evaluate algorithmic models to determine if a statement requires a\ncitation, and to predict the citation reason based on our taxonomy. We evaluate\nthe robustness of such models across different classes of Wikipedia articles of\nvarying quality, as well as on an additional dataset of claims annotated for\nfact-checking purposes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 14:50:59 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Redi", "Miriam", ""], ["Fetahu", "Besnik", ""], ["Morgan", "Jonathan", ""], ["Taraborelli", "Dario", ""]]}, {"id": "1902.11162", "submitter": "Erik Schultes", "authors": "P. Wittenburg, H. Pergl Sustkova, A. Montesanti, S. M. Bloemers, S. H.\n  de Waard, M. A. Musen, J. B. Graybeal, K. M. Hettne, A. Jacobsen, R. Pergl,\n  R. W. W. Hooft, C. Staiger, C. W. G. van Gelder, S. L. Knijnenburg, A.C. van\n  Arkel, B. Meerman, M. D. Wilkinson, S-A Sansone, P. Rocca-Serra, P.\n  McQuilton, A. N. Gonzalez-Beltran, G. J. C. Aben, P. Henning, S. Alencar, C.\n  Ribeiro, C. R. L. Silva, L. Sayao, L. Sales, V. Veiga, J. Lima, S. Dib, P.\n  Xavier, R. Murtinho, J. Tendel, B. F. Schaap, P. M. Brouwer, A. K. Gavai, Y.\n  Bouzembrak, H. J. P. Marvin, A. Mons, T. Kuhn, A. A. Gambardella, R. de\n  Miranda Azevedo, V. Muhonen, M. van der Naald, N. W. Smit, M. J. Buys, T. F.\n  de Bruin, F. Schoots, H. J. E. Goodson, H. S. Rzepa, K. G. Jeffery, H. P.\n  Shanahan, M. Axton, V. Tkachenko, A. D. Maya, N. K. Meyers, M. Conlon, L. L.\n  Haak, E. A. Schultes", "title": "The FAIR Funder pilot programme to make it easy for funders to require\n  and for grantees to produce FAIR Data", "comments": "This is a pre-print of the FAIR Funders pilot, an outcome of the\n  first Metadata for Machines workshop, see:\n  https://www.go-fair.org/resources/go-fair-workshop-series/metadata-for-machines-workshops/.\n  Corresponding author: E. A Schultes, ORCID 0000-0001-8888-635X", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is a growing acknowledgement in the scientific community of the\nimportance of making experimental data machine findable, accessible,\ninteroperable, and reusable (FAIR). Recognizing that high quality metadata are\nessential to make datasets FAIR, members of the GO FAIR Initiative and the\nResearch Data Alliance (RDA) have initiated a series of workshops to encourage\nthe creation of Metadata for Machines (M4M), enabling any self-identified\nstakeholder to define and promote the reuse of standardized, comprehensive\nmachine-actionable metadata. The funders of scientific research recognize that\nthey have an important role to play in ensuring that experimental results are\nFAIR, and that high quality metadata and careful planning for FAIR data\nstewardship are central to these goals. We describe the outcome of a recent M4M\nworkshop that has led to a pilot programme involving two national science\nfunders, the Health Research Board of Ireland (HRB) and the Netherlands\nOrganisation for Health Research and Development (ZonMW). These funding\norganizations will explore new technologies to define at the time that a\nrequest for proposals is issued the minimal set of machine-actionable metadata\nthat they would like investigators to use to annotate their datasets, to enable\ninvestigators to create such metadata to help make their data FAIR, and to\ndevelop data-stewardship plans that ensure that experimental data will be\nmanaged appropriately abiding by the FAIR principles. The FAIR Funders design\nenvisions a data-management workflow having seven essential stages, where\nsolution providers are openly invited to participate. The initial pilot\nprogramme will launch using existing computer-based tools of those who attended\nthe M4M Workshop.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 08:28:11 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 07:54:31 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Wittenburg", "P.", ""], ["Sustkova", "H. Pergl", ""], ["Montesanti", "A.", ""], ["Bloemers", "S. M.", ""], ["de Waard", "S. H.", ""], ["Musen", "M. A.", ""], ["Graybeal", "J. B.", ""], ["Hettne", "K. M.", ""], ["Jacobsen", "A.", ""], ["Pergl", "R.", ""], ["Hooft", "R. W. W.", ""], ["Staiger", "C.", ""], ["van Gelder", "C. W. G.", ""], ["Knijnenburg", "S. L.", ""], ["van Arkel", "A. C.", ""], ["Meerman", "B.", ""], ["Wilkinson", "M. D.", ""], ["Sansone", "S-A", ""], ["Rocca-Serra", "P.", ""], ["McQuilton", "P.", ""], ["Gonzalez-Beltran", "A. N.", ""], ["Aben", "G. J. C.", ""], ["Henning", "P.", ""], ["Alencar", "S.", ""], ["Ribeiro", "C.", ""], ["Silva", "C. R. L.", ""], ["Sayao", "L.", ""], ["Sales", "L.", ""], ["Veiga", "V.", ""], ["Lima", "J.", ""], ["Dib", "S.", ""], ["Xavier", "P.", ""], ["Murtinho", "R.", ""], ["Tendel", "J.", ""], ["Schaap", "B. F.", ""], ["Brouwer", "P. M.", ""], ["Gavai", "A. K.", ""], ["Bouzembrak", "Y.", ""], ["Marvin", "H. J. P.", ""], ["Mons", "A.", ""], ["Kuhn", "T.", ""], ["Gambardella", "A. A.", ""], ["Azevedo", "R. de Miranda", ""], ["Muhonen", "V.", ""], ["van der Naald", "M.", ""], ["Smit", "N. W.", ""], ["Buys", "M. J.", ""], ["de Bruin", "T. F.", ""], ["Schoots", "F.", ""], ["Goodson", "H. J. E.", ""], ["Rzepa", "H. S.", ""], ["Jeffery", "K. G.", ""], ["Shanahan", "H. P.", ""], ["Axton", "M.", ""], ["Tkachenko", "V.", ""], ["Maya", "A. D.", ""], ["Meyers", "N. K.", ""], ["Conlon", "M.", ""], ["Haak", "L. L.", ""], ["Schultes", "E. A.", ""]]}, {"id": "1902.11197", "submitter": "Ademir Gabardo Dr", "authors": "Ademir Cristiano Gabardo, Leandro Takeshi Hattori, Brenda Cinthya\n  Solari Berno, Matheus Gutoski, Wagner Rodrigues Ulian Agostinho, Heitor\n  Silverio Lopes", "title": "Como Mensurar a Import\\^ancia, Influ\\^encia e a Relev\\^ancia de\n  Usu\\'arios do Twitter? Uma an\\'alise da intera\\c{c}\\~ao dos candidatos \\`a\n  presid\\^encia do Brasil nas elei\\c{c}\\~oes de 2018", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contemporary world, a significant number of people use social\nnetworking services for a variety of purposes, including, but not limited to,\ncommunicating, exchanging messages and searching for information. A popular\nsocial network in the political arena is Twitter, a microblogging service for\nposting messages of up to 280 characters, called \"tweets,\" where influential\npoliticians from various countries often use this medium to spread ideas and\nmake public statements. In this work, an analysis was made of the connections\nof candidates for the presidency of the Republic of Brazil in the year 2018.\nUsing the analysis of complex networks to measure influence and relevance, a\nmetric was established able to quantify the importance of users in the network.\nAs part of the analysis, a Memory Algorithm was used to detect communities,\ngroups of strongly connected vertices (tweets) evidencing groupings of users.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 17:04:26 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Gabardo", "Ademir Cristiano", ""], ["Hattori", "Leandro Takeshi", ""], ["Berno", "Brenda Cinthya Solari", ""], ["Gutoski", "Matheus", ""], ["Agostinho", "Wagner Rodrigues Ulian", ""], ["Lopes", "Heitor Silverio", ""]]}]