[{"id": "1807.00071", "submitter": "Emery Berger", "authors": "Emery Berger and Stephen M. Blackburn and Carla Brodley and H. V.\n  Jagadish and Kathryn S. McKinley and Mario A. Nascimento and Minjeong Shin\n  and Lexing Xie", "title": "GOTO Rankings Considered Helpful", "comments": "Accepted, to appear in Communications of the ACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rankings are a fact of life. Whether or not one likes them, they exist and\nare influential. Within academia, and in computer science in particular,\nrankings not only capture our attention but also widely influence people who\nhave a limited understanding of computing science research, including\nprospective students, university administrators, and policy-makers. In short,\nrankings matter. This position paper advocates for the adoption of \"GOTO\nrankings\": rankings that use Good data, are Open, Transparent, and Objective,\nand the rejection of rankings that do not meet these criteria.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 21:23:47 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 22:23:47 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Berger", "Emery", ""], ["Blackburn", "Stephen M.", ""], ["Brodley", "Carla", ""], ["Jagadish", "H. V.", ""], ["McKinley", "Kathryn S.", ""], ["Nascimento", "Mario A.", ""], ["Shin", "Minjeong", ""], ["Xie", "Lexing", ""]]}, {"id": "1807.00181", "submitter": "Ted Underwood", "authors": "Ted Underwood", "title": "The Historical Significance of Textual Distances", "comments": "Preprint of a paper for the 2nd Joint SIGHUM Workshop on\n  Computational Linguistics for Cultural Heritage, Social Sciences, Humanities\n  and Literature (LaTeCH-CLfL 2018). Code is available at\n  https://github.com/tedunderwood/genredistance or, archivally, at\n  https://zenodo.org/record/1300934", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring similarity is a basic task in information retrieval, and now often\na building-block for more complex arguments about cultural change. But do\nmeasures of textual similarity and distance really correspond to evidence about\ncultural proximity and differentiation? To explore that question empirically,\nthis paper compares textual and social measures of the similarities between\ngenres of English-language fiction. Existing measures of textual similarity\n(cosine similarity on tf-idf vectors or topic vectors) are also compared to new\nstrategies that use supervised learning to anchor textual measurement in a\nsocial context.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 14:06:54 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Underwood", "Ted", ""]]}, {"id": "1807.00212", "submitter": "Serhiy Semerikov", "authors": "Serhiy O. Semerikov, Vladyslav S. Pototskyi, Kateryna I. Slovak,\n  Svitlana M. Hryshchenko, Arnold E. Kiv", "title": "Automation of the Export Data from Open Journal Systems to the Russian\n  Science Citation Index", "comments": "12 pages, 8 figures, 2 tables, AREdu 2018 Augmented Reality in\n  Education", "journal-ref": "CEUR Workshop Proceedings 2257 (2018) 215-226", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is shown that the calculation of scientometric indicators of the scientist\nand also the scientific journal continues to be an actual problem nowadays. It\nis revealed that the leading scientometric databases have the capabilities of\nautomated metadata collection from the scientific journal website by the use of\nspecialized electronic document management systems, in particular Open Journal\nSystems. It is established that Open Journal Systems successfully exports\nmetadata about an article from scientific journals to scientometric databases\nScopus, Web of Science and Google Scholar. However, there is no standard method\nof export from Open Journal Systems to such scientometric databases as the\nRussian Science Citation Index and Index Copernicus, which determined the need\nfor research. The aim of the study is to develop the plug-in to the Open\nJournal Systems for the export of data from this system to scientometric\ndatabase Russian Science Citation Index. As a result of the study, an\ninfological model for exporting metadata from Open Journal Systems to the\nRussian Science Citation Index was proposed. The SirenExpo plug-in was\ndeveloped to export data from Open Journal Systems to the Russian Science\nCitation Index by the use of the Articulus release preparation system.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 18:00:24 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 12:01:15 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Semerikov", "Serhiy O.", ""], ["Pototskyi", "Vladyslav S.", ""], ["Slovak", "Kateryna I.", ""], ["Hryshchenko", "Svitlana M.", ""], ["Kiv", "Arnold E.", ""]]}, {"id": "1807.01049", "submitter": "Jean-Jacques Bessoule", "authors": "Domingo Docampo and Jean-Jacques Bessoule", "title": "An approach based on the geometric mean of basic quantitative and\n  qualitative bibliometric indicators to evaluate and analyse the research\n  performance of countries and institutions", "comments": "Page 3: The formula for the p-index was wrong (but the right formula\n  was used to draw Fig. 5a), as well as in P7 the formula for the quantitative\n  and qualitative parameters related to the p-index. Fig 7: Japan was\n  associated with Western and not Asian countries; in caption, we added: Green\n  letters correspond to countries of former Soviet-Union and satellite\n  countries. P16 L1,added:Except Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a straightforward procedure to evaluate the scientific\ncontribution of territories and institutions that combines the size-dependent\ngeometric mean, Q, of the number of research documents (N) and citations (C),\nand a scale-free measure of quality, q=C/N. We introduce a Global Research\nOutput (GRO-index) as the geometric mean of Q and q. We show that the GRO-index\ncorrelates with the h-index, but appears to be more strongly correlated with\nother well known, widely used bibliometric indicators. We also compute relative\nGRO-indexes (GROr) associated with the scientific production within research\nfields. We note that although total sums of GROr values are larger than the\nGRO-index, due to the non-linearity in the computation of the geometric means,\nboth counts are nevertheless highly correlated. That enables us to make useful\ncomparative analyses among territories and institutions. Furthermore, to\nidentify strengths and weaknesses of a given country or institution, we compute\na Relative Research Output count (RROr-index) to tackle variations of the C/N\nratio across research fields. Moreover, by using a wealth-index also based on\nquantitative and qualitative variables, we show that the GRO and RRO indexes\nare highly correlated with the wealth of the countries and the states of the\nUSA. Given the simplicity of the procedures introduced in this paper and the\nfact that their results are easily understandable by non-specialists, we\nbelieve they could become as useful for the assessment of the research output\nof countries and institutions as the impact factor is for journals or the\nh-index for individuals.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 09:44:52 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 13:40:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Docampo", "Domingo", ""], ["Bessoule", "Jean-Jacques", ""]]}, {"id": "1807.01225", "submitter": "Ricardo Brito", "authors": "Ricardo Brito, Alonso Rodr\\'iguez-Navarro", "title": "The USA is an indisputable world leader in medical and biotechnological\n  research", "comments": "single pdf file, 22 pages, figures and tables included", "journal-ref": "Journal of Scientometric Res. 2020; 9(2):86-94", "doi": "10.5530/jscires.8.2.14", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A country's research success can be assessed from the power law function that\nlinks country and world rank numbers when publications are ordered by their\nnumber of citations; a similar function describes the distribution of country\npapers in world percentiles. These functions allow calculating the ep index and\nthe probability of publishing highly cited papers, which measure the efficiency\nof the research system and the ability of achieving important discoveries or\nscientific breakthroughs, respectively. The aim of this paper was to use these\nmetrics and other parameters derived from the percentile-based power law\nfunction to investigate research success in the USA, the EU, and other\ncountries in hot medical, biochemical, and biotechnological topics. The results\nshow that, in the investigated fields, the USA is scientifically ahead of all\ncountries and that its research is likely to produce approximately 80% of the\nimportant global breakthroughs in the research topics investigated in this\nstudy. EU research has maintained a constant weak position with reference to\nUSA research over the last 30 years.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:04:19 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 16:06:42 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Brito", "Ricardo", ""], ["Rodr\u00edguez-Navarro", "Alonso", ""]]}, {"id": "1807.01408", "submitter": "Lucie Tvrznikova", "authors": "Lucie Tvrznikova", "title": "Case for the double-blind peer review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is a process designed to produce a fair assessment of research\nquality before the publication of scholarly work in a journal. Demographics,\nnepotism, and seniority have been all shown to affect reviewer behavior\nsuggesting the most common, single-blind review method (or the less common open\nreview method) might be biased. A survey of current research indicates that\ndouble-blind review offers a solution to many biases stemming from author's\ngender, seniority, or location without imposing any significant downsides.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 00:18:20 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 18:16:43 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 21:26:18 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Tvrznikova", "Lucie", ""]]}, {"id": "1807.01795", "submitter": "Giovanni Colavizza", "authors": "Giovanni Colavizza", "title": "A diachronic study of historiography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The humanities are often characterized by sociologists as having a low mutual\ndependence among scholars and high task uncertainty. According to Fuchs' theory\nof scientific change, this leads over time to intellectual and social\nfragmentation, as new scholarship accumulates in the absence of shared unifying\ntheories. We consider here a set of specialisms in the discipline of history\nand measure the connectivity properties of their bibliographic coupling\nnetworks over time, in order to assess whether fragmentation is indeed\noccurring. We construct networks using both reference overlap and textual\nsimilarity. It is shown that the connectivity of reference overlap networks is\ngradually and steadily declining over time, whilst that of textual similarity\nnetworks is stable. Author bibliographic coupling networks also show signs of a\ndecline in connectivity, in the absence of an increasing propensity for\ncollaborations. We speculate that, despite the gradual weakening of ties among\nhistorians as mapped by references, new scholarship might be continually\nintegrated through shared vocabularies and narratives. This would support our\nbelief that citations are but one kind of bibliometric data to consider ---\nperhaps even of secondary importance --- when studying the humanities, while\ntext should play a more prominent role.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 21:38:46 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 18:13:56 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Colavizza", "Giovanni", ""]]}, {"id": "1807.02830", "submitter": "Dejan Lavbi\\v{c}", "authors": "Alja\\v{z} Zrnec and Dejan Lavbi\\v{c}", "title": "Social network aided plagiarism detection: Social network aided\n  plagiarism detection", "comments": "16 pages, 6 figures", "journal-ref": "British Journal of Educational Technology 48 (2017) 113-128", "doi": "10.1111/bjet.12345", "report-no": null, "categories": "cs.SI cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of different kinds of electronic devices and the volume of\ncontent on the Web have increased the amount of plagiarism, which is considered\nan unethical act. If we want to be efficient in the detection and prevention of\nthese acts, we have to improve today's methods of discovering plagiarism. The\npaper presents a research study where a framework for the improved detection of\nplagiarism is proposed. The framework focuses on the integration of social\nnetwork information, information from the Web, and an advanced semantically\nenriched visualization of information about authors and documents that enables\nthe exploration of obtained data by seeking of advanced patterns of plagiarism.\nTo support the proposed framework, a special software tool was also developed.\nThe statistical evaluation confirmed that the employment of social network\nanalysis and advanced visualization techniques led to improvements in the\nconfirmation and investigation stages of the plagiarism detection process,\nthereby enhancing the overall efficiency of the plagiarism detection process.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 14:29:00 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Zrnec", "Alja\u017e", ""], ["Lavbi\u010d", "Dejan", ""]]}, {"id": "1807.03353", "submitter": "Olesya Mryglod", "authors": "Olesya Mryglod, Yurij Holovatch and Ralph Kenna", "title": "Data Mining in Scientometrics: usage analysis for academic publications", "comments": "The paper will be presented during DSMP'2018 conference", "journal-ref": "IEEE Second International Conference on Data Stream Mining &\n  Processing (Dsmp2018) IEEE Catalog Number: CFP18J13-POD, ISBN:\n  978-1-5386-2875-1 (2018) pp. 241-246", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a statistical analysis of scientific-publication data with a goal\nto provide quantitative analysis of scientific process. Such an investigation\nbelongs to the newly established field of scientometrics: a branch of the\ngeneral science of science that covers all quantitative methods to analyze\nscience and research process. As a case study we consider download and citation\nstatistics of the journal `Europhysics Letters' (EPL), as Europe's flagship\nletters journal of broad interest to the physics community. While citations are\nusually considered as an indicator of academic impact, downloads reflect rather\nthe level of attractiveness or popularity of a publication. We discuss\npeculiarities of both processes and correlations between them.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 19:34:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Mryglod", "Olesya", ""], ["Holovatch", "Yurij", ""], ["Kenna", "Ralph", ""]]}, {"id": "1807.03977", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Robin Haunschild, Jonathan Adams", "title": "Do altmetrics assess societal impact in a comparable way to case\n  studies? An empirical test of the convergent validity of altmetrics based on\n  data from the UK Research Excellence Framework (REF)", "comments": null, "journal-ref": "Journal of Informetrics, 13, 325-340 (2019)", "doi": "10.1016/j.joi.2019.01.008", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Altmetrics have been proposed as a way to assess the societal impact of\nresearch. Although altmetrics are already in use as impact or attention metrics\nin different contexts, it is still not clear whether they really capture or\nreflect societal impact. This study is based on altmetrics, citation counts,\nresearch output and case study data from the UK Research Excellence Framework\n(REF), and peers' REF assessments of research output and societal impact. We\ninvestigated the convergent validity of altmetrics by using two REF datasets:\npublications submitted as research output (PRO) to the REF and publications\nreferenced in case studies (PCS). Case studies, which are intended to\ndemonstrate societal impact, should cite the most relevant research papers. We\nused the MHq' indicator for assessing impact - an indicator which has been\nintroduced for count data with many zeros. The results of the first part of the\nanalysis show that news media as well as mentions on Facebook, in blogs, in\nWikipedia, and in policy-related documents have higher MHq' values for PCS than\nfor PRO. Thus, the altmetric indicators seem to have convergent validity for\nthese data. In the second part of the analysis, altmetrics have been correlated\nwith REF reviewers' average scores on PCS. The negative or close to zero\ncorrelations question the convergent validity of altmetrics in that context. We\nsuggest that they may capture a different aspect of societal impact (which can\nbe called unknown attention) to that seen by reviewers (who are interested in\nthe causal link between research and action in society).\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 07:49:05 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 07:32:36 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""], ["Adams", "Jonathan", ""]]}, {"id": "1807.04115", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff, Caroline S. Wagner, and Lutz Bornmann", "title": "Interdisciplinarity as Diversity in Citation Patterns among Journals:\n  Rao-Stirling Diversity, Relative Variety, and the Gini coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions of definition and measurement continue to constrain a consensus on\nthe measurement of interdisciplinarity. Using Rao-Stirling (RS) Diversity\nproduces sometimes anomalous results. We argue that these unexpected outcomes\ncan be related to the use of \"dual-concept diversity\" which combines \"variety\"\nand \"balance\" in the definitions (ex ante). We propose to modify RS Diversity\ninto a new indicator (DIV) which operationalizes variety, balance, and\ndisparity independently and then combines them ex post. \"Balance\" can be\nmeasured using the Gini coefficient. We apply DIV to the aggregated citation\npatterns of 11,487 journals covered by the Journal Citation Reports 2016 of the\nScience Citation Index and the Social Sciences Citation Index as an empirical\ndomain and, in more detail, to the citation patterns of 85 journals assigned to\nthe Web-of-Science category \"information science & library science\" in both the\ncited and citing directions. We compare the results of the indicators and show\nthat DIV provides improved results in terms of distinguishing between\ninterdisciplinary knowledge integration (citing) versus knowledge diffusion\n(cited). The new diversity indicator and RS diversity measure different\nfeatures. A routine for the measurement of the various operationalizations of\ndiversity (in any data matrix) is made available online.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 13:13:10 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 07:50:38 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Leydesdorff", "Loet", ""], ["Wagner", "Caroline S.", ""], ["Bornmann", "Lutz", ""]]}, {"id": "1807.04535", "submitter": "Nicolas Robinson-Garcia", "authors": "Daniel Torres-Salinas, Nicolas Robinson-Garcia and Henk F. Moed", "title": "Disentangling Gold Open Access", "comments": "Forthcoming in Glanzel, W., Moed, H.F., Schmoch U., Thelwall, M.\n  (2018). Springer Handbook of Science and Technology Indicators. Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter focuses on the analysis of current publication trends in gold\nOpen Access (OA). The purpose of the chapter is to develop a full understanding\non country patterns, OA journals characteristics and citation differences\nbetween gold OA and non-gold OA publications. For this, we will first review\ncurrent literature regarding Open Access and its relation with its so-called\ncitation advantage. Starting with a chronological perspective we will describe\nits development, how different countries are promoting OA publishing, and its\neffects on the journal publishing industry. We will deepen the analysis by\ninvestigating the research output produced by different units of analysis.\nFirst, we will focus on the production of countries with a special emphasis on\ncitation and disciplinary differences. A point of interest will be\nidentification of national idiosyncrasies and the relation between OA\npublication and research of local interest. This will lead to our second unit\nof analysis, OA journals indexed in Web of Science. Here we will deepen on\njournals characteristics and publisher types to clearly identify factors which\nmay affect citation differences between OA and traditional journals which may\nnot necessarily be derived from the OA factor. Gold OA publishing is being\nencouraged in many countries as opposed to Green OA. This chapter aims at fully\nunderstanding how it affects researchers' publication patterns and whether it\nensures an alleged citation advantage as opposed to non-gold OA publications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 11:00:04 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Torres-Salinas", "Daniel", ""], ["Robinson-Garcia", "Nicolas", ""], ["Moed", "Henk F.", ""]]}, {"id": "1807.04673", "submitter": "Robin Haunschild", "authors": "Robin Haunschild, Werner Marx, Andreas Thor, and Lutz Bornmann", "title": "How to identify the roots of broad research topics and fields? The\n  introduction of RPYS sampling using the example of climate change research", "comments": "30 pages, 6 figures, 3 script listings, and 4 tables", "journal-ref": "Journal of Information Science, in print (2019), DOI\n  10.1177/0165551519837175", "doi": "10.1177/0165551519837175", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction of the reference publication year spectroscopy (RPYS)\nmethod and the corresponding program CRExplorer, many studies have been\npublished revealing the historical roots of topics, fields, and researchers.\nThe application of the method was restricted up to now by the available memory\nof the computer used for running the CRExplorer. Thus, many users could not\nperform RPYS for broader research fields or topics. In this study, we present\nvarious sampling methods to solve this problem: random, systematic, and cluster\nsampling. We introduce the script language of the CRExplorer which can be used\nto draw many samples from the population dataset. Based on a large dataset of\npublications from climate change research, we compare RPYS results using\npopulation data with RPYS results using different sampling techniques. From our\ncomparison with the full RPYS (population spectrogram), we conclude that the\ncluster sampling performs worst and the systematic sampling performs best. The\nrandom sampling also performs very well but not as well as the systematic\nsampling. The study therefore demonstrates the fruitfulness of the sampling\napproach for applying RPYS.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:27:51 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Haunschild", "Robin", ""], ["Marx", "Werner", ""], ["Thor", "Andreas", ""], ["Bornmann", "Lutz", ""]]}, {"id": "1807.04712", "submitter": "Christian Schulz", "authors": "Christian Schulz, Brian Uzzi, Dirk Helbing, Olivia Woolley-Meza", "title": "A network-based citation indicator of scientific performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists are embedded in social and information networks that influence and\nare influenced by the quality of their scientific work, its impact, and the\nrecognition they receive. Here we quantify the systematic relationship between\na scientist's position in the network of scientific collaborations and the\ncitations they receive. As expected, we find that authors closer to others in\nthis network are, on average, more highly cited than those further away from\nothers. We construct a novel indicator, the s-index, that explicitly captures\nperformance linked to network position along two complimentary dimensions:\nperformance expected due to network position and performance relative to this\nposition. The basis of our approach is to represent an author's network\nposition through their distribution of distances to other authors. The s-index\nthen ranks (1) the citation potential of an individual's network position\nrelative to all other authors, and (2) the citations they accrue relative to\nauthors that have a comparable network position. Characterizing scientists\nthrough these two complimentary dimensions can be used to make more informed\nevaluations in a networked environment. For example, it can identify\nindividuals that play an important role in diffusing scientific ideas. It also\nsheds a new light on central debates in the Science of Science, namely the\nimpact of author teams and comparisons of impact across scientific fields.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:29:54 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Schulz", "Christian", ""], ["Uzzi", "Brian", ""], ["Helbing", "Dirk", ""], ["Woolley-Meza", "Olivia", ""]]}, {"id": "1807.05115", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Julian N. Marewski", "title": "Heuristics as conceptual lens for understanding and studying the usage\n  of bibliometrics in research evaluation", "comments": "in press at Scientometrics", "journal-ref": null, "doi": "10.1007/s11192-019-03018-x", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While bibliometrics are widely used for research evaluation purposes, a\ncommon theoretical framework for conceptually understanding, empirically\nstudying, and effectively teaching its usage is lacking. In this paper, we\noutline such a framework: the fast-and-frugal heuristics research program,\nproposed originally in the context of the cognitive and decision sciences,\nlends itself particularly well for understanding and investigating the usage of\nbibliometrics in research evaluations. Such evaluations represent judgments\nunder uncertainty in which typically not all possible options, their\nconsequences, and those consequences' probabilities of occurring may be known.\nIn these situations of incomplete information, candidate descriptive and\nprescriptive models of human behavior are heuristics. Heuristics are simple\nstrategies that, by exploiting the structure of environments, can aid people to\nmake smart decisions. Relying on heuristics does not mean trading off accuracy\nagainst effort: while reducing complexity, heuristics can yield better\ndecisions than more information-greedy procedures in many decision\nenvironments. The prescriptive power of heuristics is documented in a\ncross-disciplinary literature, cutting across medicine, crime, business,\nsports, and other domains. We outline the fast-and-frugal heuristics research\nprogram, provide examples of past empirical work on heuristics outside the\nfield of bibliometrics, explain why heuristics may be especially suitable for\nstudying the usage of bibliometrics, and propose a corresponding conceptual\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 14:53:00 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 08:39:49 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 14:12:01 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2019 06:38:35 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Bornmann", "Lutz", ""], ["Marewski", "Julian N.", ""]]}, {"id": "1807.05571", "submitter": "Aravind Sesagiri Raamkumar", "authors": "Aravind Sesagiri Raamkumar, Mojisola Erdt, Harsha Vijayakumar, Edie\n  Rasmussen, Yin-Leng Theng", "title": "Understanding the Twitter Usage of Humanities and Social Sciences\n  Academic Journals", "comments": "2018 Annual Meeting of The Association for Information Science &\n  Technology", "journal-ref": null, "doi": "10.1002/pra2.2018.14505501047", "report-no": null, "categories": "cs.SI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scholarly communication has the scope to transcend the limitations of the\nphysical world through social media extended coverage and shortened information\npaths. Accordingly, publishers have created profiles for their journals in\nTwitter to promote their publications and to initiate discussions with public.\nThis paper investigates the Twitter presence of humanities and social sciences\n(HSS) journal titles obtained from mainstream citation indices, by analysing\nthe interaction and communication patterns. This study utilizes webometric data\ncollection, descriptive analysis, and social network analysis. Findings\nindicate that the presence of HSS journals in Twitter across disciplines is not\nyet substantial. Sharing of general websites appears to be the key activity\nperformed by HSS journals in Twitter. Among them, web content from news portals\nand magazines are highly disseminated. Sharing of research articles and\nretweeting was not majorly observed. Inter-journal communication is apparent\nwithin the same citation index, but it is very minimal with journals from the\nother index. However, there seems to be an effort to broaden communication\nbeyond the research community, reaching out to connect with the public.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 16:21:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Raamkumar", "Aravind Sesagiri", ""], ["Erdt", "Mojisola", ""], ["Vijayakumar", "Harsha", ""], ["Rasmussen", "Edie", ""], ["Theng", "Yin-Leng", ""]]}, {"id": "1807.05786", "submitter": "Konstantin Bulatov", "authors": "Vladimir V. Arlazarov, Konstantin Bulatov, Timofey Chernov, Vladimir\n  L. Arlazarov", "title": "MIDV-500: A Dataset for Identity Documents Analysis and Recognition on\n  Mobile Devices in Video Stream", "comments": "7 pages, 6 figures, 5 tables", "journal-ref": "Computer optics 43 N5 (2019) 818-824", "doi": "10.18287/2412-6179-2019-43-5-818-824", "report-no": null, "categories": "cs.CV cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of research has been devoted to identity documents analysis and\nrecognition on mobile devices. However, no publicly available datasets designed\nfor this particular problem currently exist. There are a few datasets which are\nuseful for associated subtasks but in order to facilitate a more comprehensive\nscientific and technical approach to identity document recognition more\nspecialized datasets are required. In this paper we present a Mobile Identity\nDocument Video dataset (MIDV-500) consisting of 500 video clips for 50\ndifferent identity document types with ground truth which allows to perform\nresearch in a wide scope of document analysis problems. The paper presents\ncharacteristics of the dataset and evaluation results for existing methods of\nface detection, text line recognition, and document fields data extraction.\nSince an important feature of identity documents is their sensitiveness as they\ncontain personal data, all source document images used in MIDV-500 are either\nin public domain or distributed under public copyright licenses.\n  The main goal of this paper is to present a dataset. However, in addition and\nas a baseline, we present evaluation results for existing methods for face\ndetection, text line recognition, and document data extraction, using the\npresented dataset.\n  (The dataset is available for download at ftp://smartengines.com/midv-500/.)\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 10:51:10 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 12:17:23 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 08:30:01 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 07:28:48 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Arlazarov", "Vladimir V.", ""], ["Bulatov", "Konstantin", ""], ["Chernov", "Timofey", ""], ["Arlazarov", "Vladimir L.", ""]]}, {"id": "1807.05789", "submitter": "Nicolas Robinson-Garcia", "authors": "Alesia Zuccala and Nicolas Robinson-Garcia", "title": "Reviewing, indicating, and counting books for modern research evaluation\n  systems", "comments": "Forthcoming in Glanzel, W., Moed, H.F., Schmoch U., Thelwall, M.\n  (2018). Springer Handbook of Science and Technology Indicators. Springer Some\n  corrections made in subsection 'Publisher prestige or quality'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we focus on the specialists who have helped to improve the\nconditions for book assessments in research evaluation exercises, with\nempirically based data and insights supporting their greater integration. Our\nreview highlights the research carried out by four types of expert communities,\nreferred to as the monitors, the subject classifiers, the indexers and the\nindicator constructionists. Many challenges lie ahead for scholars affiliated\nwith these communities, particularly the latter three. By acknowledging their\nunique, yet interrelated roles, we show where the greatest potential is for\nboth quantitative and qualitative indicator advancements in book-inclusive\nevaluation systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:00:26 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 07:28:32 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Zuccala", "Alesia", ""], ["Robinson-Garcia", "Nicolas", ""]]}, {"id": "1807.06366", "submitter": "Ronaldo Araujo", "authors": "Ronaldo Ferreira Araujo and Marcelo Alves", "title": "The altmetric performance of publications authored by Brazilian\n  researchers: analysis of CNPq productivity scholarship holders", "comments": "This is a post-peer-review, pre-copyedit english version of the paper\n  accepted at 6th Brazilian Meeting on Bibliometrics and Scientometrics (EBBC),\n  Rio de Janeiro, RJ, July 17th to 20th, 2018. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The present work seeks to analyse the altmetric performance of Brazilian\npublications authored by researchers who are productivity scholarship holders\n(PQ) of the National Council of Scientific and Technological Development\n(CNPq). It was considered, within the scope of this research, the PQs in\nactivity in October, 2017 (n = 14.609). The scientific production registered on\nLattes was collected via GetLattesData and filtered by articles from academic\njournals published between 2016 and October 2017 that hold the Digital Object\nIdentifier (n = 99064). The online attention data are analysed according to\ntheir distribution by density and variation; language of the publication and\nfield of knowledge; and by average performance of the type of source that has\nprovided its altmetric values. The density evidences the long tail behavior of\nthe variable, with most part of the articles with altmetrics score = 0, while\nfew articles have a high index. The average of the online attention indicates a\nbetter performance of articles written in English and belonging to the Health\nand Biological Sciences field of knowledge. As for the sources, there was a\ngood performance from Mendeley, followed by Twitter and a low coverage from\nFacebook\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 11:53:15 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Araujo", "Ronaldo Ferreira", ""], ["Alves", "Marcelo", ""]]}, {"id": "1807.06442", "submitter": "Christoph Steinbruchel", "authors": "Christoph Steinbr\\\"uchel (Rensselaer Polytechnic Institute)", "title": "$h_{PI}$: The Citation Index for Principal Investigators", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new citation index $h_{PI}$ for principal investigators (PIs) is defined in\nanalogy to Hirsch's index $h$, but based on renormalized citations of a PI's\npapers. To this end, the authors of a paper are divided into two groups: PIs\nand non-PIs. A PI is defined as an assistant, associate or full professor at a\nuniversity who supervises an individual research program. The citations for\neach paper of a certain PI are then divided by the number of PIs among the\nauthors of that paper. Data are presented for a sample of 48 PIs who are senior\nfaculty members of physics and physics-related engineering departments at a\nprivate research-oriented U.S. university, using the ISI Web of Science\ncitations database. The main result is that individual rankings based on $h$\nand $h_{PI}$ differ substantially. Also, to a good approximation across the\nsample of 48 PIs, one finds that $h_{PI} = h \\,/ \\sqrt{<N_{PI}>}$ where\n<$N_{PI}$> is the average number of principal investigators on the papers of a\nparticular PI. In addition, $h_{PI} = \\frac{1}{2} \\sqrt{C_{tot}\\,/<N_{PI}>}$,\nwhere $C_{tot}$ is the total number of citations. Approaches to broadening the\nscope of $h$ or $h_{PI}$ are discussed briefly, and a new metric for highly\ncited papers called $h_x$ is introduced which represents the average number of\ncitations exceeding the minimum of $h^2$ in the $h$-core.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:02:44 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Steinbr\u00fcchel", "Christoph", "", "Rensselaer Polytechnic Institute"]]}, {"id": "1807.06808", "submitter": "Emeric Dynomant", "authors": "Levin Cl\\'ement, Dynomant Emeric, Gonzalez Bruno J, Mouchard Laurent,\n  Landsman David, Hovig Eivind, Vlahovicek Kristian", "title": "A data-supported history of bioinformatics tools", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the advent of next-generation sequencing in the early 2000s, the volume\nof bioinformatics software tools and databases has exploded and continues to\ngrow rapidly. Documenting this evolution on a global and time-dependent scale\nis a challenging task, limited by the scarcity of comprehensive tool\nrepositories. We collected data from over ~23,000 references classified in the\nOMICtools database, spanning the last 26 years of bioinformatics to present a\ndata-supported snapshot of bioinformatics software tool evolution and the\ncurrent status, to shed light on future directions and opportunities in this\nfield. The present review explores new aspects of computational biology,\nincluding country partnerships, trends in technologies and area of development,\nresearch and development (R&D) investments and coding languages. This is the\nmost comprehensive systematic overview of the field to date and provides the\ncommunity with insights and knowledge on the direction of the development and\nevolution of bioinformatics software tools, highlighting the increasing\ncomplexity of analysis.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 07:43:13 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Cl\u00e9ment", "Levin", ""], ["Emeric", "Dynomant", ""], ["J", "Gonzalez Bruno", ""], ["Laurent", "Mouchard", ""], ["David", "Landsman", ""], ["Eivind", "Hovig", ""], ["Kristian", "Vlahovicek", ""]]}, {"id": "1807.06816", "submitter": "Guillermo Palma", "authors": "Sahar Vahdati, Guillermo Palma, Rahul Jyoti Nath, Christoph Lange,\n  S\\\"oren Auer, and Maria-Esther Vidal", "title": "Unveiling Scholarly Communities over Knowledge Graphs", "comments": "12 pages. Paper accepted in the 22nd International Conference on\n  Theory and Practice of Digital Libraries, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs represent the meaning of properties of real-world entities\nand relationships among them in a natural way. Exploiting semantics encoded in\nknowledge graphs enables the implementation of knowledge-driven tasks such as\nsemantic retrieval, query processing, and question answering, as well as\nsolutions to knowledge discovery tasks including pattern discovery and link\nprediction. In this paper, we tackle the problem of knowledge discovery in\nscholarly knowledge graphs, i.e., graphs that integrate scholarly data, and\npresent Korona, a knowledge-driven framework able to unveil scholarly\ncommunities for the prediction of scholarly networks. Korona implements a graph\npartition approach and relies on semantic similarity measures to determine\nrelatedness between scholarly entities. As a proof of concept, we built a\nscholarly knowledge graph with data from researchers, conferences, and papers\nof the Semantic Web area, and apply Korona to uncover co-authorship networks.\nResults observed from our empirical evaluation suggest that exploiting\nsemantics in scholarly knowledge graphs enables the identification of\npreviously unknown relations between researchers. By extending the ontology,\nthese observations can be generalized to other scholarly entities, e.g.,\narticles or institutions, for the prediction of other scholarly patterns, e.g.,\nco-citations or academic collaboration.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 08:32:01 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Vahdati", "Sahar", ""], ["Palma", "Guillermo", ""], ["Nath", "Rahul Jyoti", ""], ["Lange", "Christoph", ""], ["Auer", "S\u00f6ren", ""], ["Vidal", "Maria-Esther", ""]]}, {"id": "1807.06918", "submitter": "Joeran Beel", "authors": "Joeran Beel and Barry Smyth and Andrew Collins", "title": "RARD II: The 94 Million Related-Article Recommendation Dataset", "comments": null, "journal-ref": "1st Workshop on Algorithm Selection and Meta-Learning in\n  Information Retrieval (AMIR). 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper is to introduce and describe a new\nrecommender-systems dataset (RARD II). It is based on data from Mr. DLib, a\nrecommender-system as-a-service in the digital library and\nreference-management-software domain. As such, RARD II complements datasets\nfrom other domains such as books, movies, and music. The dataset encompasses\n94m recommendations, delivered in the two years from September 2016 to\nSeptember 2018. The dataset covers an item-space of 24m unique items. RARD II\nprovides a range of rich recommendation data, beyond conventional ratings. For\nexample, in addition to the usual (implicit) ratings matrices, RARD II includes\nthe original recommendation logs, which provide a unique insight into many\naspects of the algorithms that generated the recommendations. The logs enable\nresearchers to conduct various analyses about a real-world recommender system.\nThis includes the evaluation of meta-learning approaches for predicting\nalgorithm performance. In this paper, we summarise the key features of this\ndataset release, describe how it was generated and discuss some of its unique\nfeatures. Compared to its predecessor RARD, RARD II contains 64% more\nrecommendations, 187% more features (algorithms, parameters, and statistics),\n50% more clicks, 140% more documents, and one additional service partner\n(JabRef).\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:27:33 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 08:46:06 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 10:47:36 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Beel", "Joeran", ""], ["Smyth", "Barry", ""], ["Collins", "Andrew", ""]]}, {"id": "1807.07285", "submitter": "Ricardo Brito", "authors": "Alonso Rodriguez-Navarro, Ricardo Brito", "title": "Probability and expected frequency of breakthroughs - a robust method of\n  research assessment based on the double rank property of citation\n  distributions", "comments": "30 pages, 4 tables and 4 figures. One single pdf file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In research policy, effective measures that lead to improvements in the\ngeneration of knowledge must be based on reliable methods of research\nassessment, but for many countries and institutions this is not the case.\nPublication and citation analyses can be used to estimate the part played by\ncountries and institutions in the global progress of knowledge, but a concrete\nmethod of estimation is far from evident. The challenge arises because\npublications that report real progress of knowledge form an extremely low\nproportion of all publications; in most countries and institutions such\ncontributions appear less than once per year. One way to overcome this\ndifficulty is to calculate probabilities instead of counting the rare events on\nwhich scientific progress is based. This study reviews and summarizes several\nrecent publications, and adds new results that demonstrate that the citation\ndistribution of normal publications allows the probability of the infrequent\nevents that support the progress of knowledge to be calculated.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:29:39 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Rodriguez-Navarro", "Alonso", ""], ["Brito", "Ricardo", ""]]}, {"id": "1807.07298", "submitter": "Joeran Beel", "authors": "Joeran Beel and Andrew Collins and Oliver Kopp and Linus W. Dietz and\n  Petr Knoth", "title": "Online Evaluations for Everyone: Mr. DLib's Living Lab for Scholarly\n  Recommendations", "comments": "Published at the 41st European Conference on Information Retrieval\n  (ECIR) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-15719-7_27", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first 'living lab' for scholarly recommender systems. This\nlab allows recommender-system researchers to conduct online evaluations of\ntheir novel algorithms for scholarly recommendations, i.e., recommendations for\nresearch papers, citations, conferences, research grants, etc. Recommendations\nare delivered through the living lab's API to platforms such as reference\nmanagement software and digital libraries. The living lab is built on top of\nthe recommender-system as-a-service Mr. DLib. Current partners are the\nreference management software JabRef and the CORE research team. We present the\narchitecture of Mr. DLib's living lab as well as usage statistics on the first\nsixteen months of operating it. During this time, 1,826,643 recommendations\nwere delivered with an average click-through rate of 0.21%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:55:09 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 08:42:02 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Beel", "Joeran", ""], ["Collins", "Andrew", ""], ["Kopp", "Oliver", ""], ["Dietz", "Linus W.", ""], ["Knoth", "Petr", ""]]}, {"id": "1807.07595", "submitter": "Ari Mariano", "authors": "Ari Melo Mariano and Ma\\'ira Rocha Santos", "title": "Universalizing science: alternative indices to direct research", "comments": "22 pages, 9 equations, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Measurement is a complicated but very necessary task. Many indices have been\ncreated in an effort to define the quality of knowledge produced but they have\nattracted strong criticism, having become synonymous with individualism,\ncompetition and mere productivity and, furthermore, they fail to head science\ntowards addressing local demands or towards producing international knowledge\nby means of collaboration. Institutions, countries, publishers, governments and\nauthors have a latent need to create quality and productivity indices because\nthey can serve as filters that influence far-reaching decision making and even\ndecisions on the professional promotion of university teachers. Even so, in the\npresent-day context, the very creators of those indices admit that they were\nnot designed for that purpose, given that different research areas, the age of\nthe researcher, the country and the language spoken all have an influence on\nthe index calculations. Accordingly, this research sets out three indices\ndesigned to head science towards its universal objective by valuing\ncollaboration and the dissemination of knowledge. It is hoped that the proposed\nindices may provoke new discussions and the proposal of new, more assertive\nindicators for the analysis of scientific research quality.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 18:33:12 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Mariano", "Ari Melo", ""], ["Santos", "Ma\u00edra Rocha", ""]]}, {"id": "1807.08477", "submitter": "Marco van Veller", "authors": "Marco G.P. van Veller", "title": "Identification of multidisciplinary research based upon dissimilarity\n  analysis of journals included in reference lists of Wageningen University &\n  Research articles", "comments": "Manuscript to be submitted to Collection and Curation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper discusses the identification of journal articles that probably\nreport on multidisciplinary research. Identification of these articles may be\nimportant for strategic purposes for the institution where the research is\nperformed or for the evaluation of researchers or groups. In order to identify\npossibly multidisciplinary research, this paper describes an analysis on the\njournals from which articles have been cited in the journal articles published\nby Wageningen University & Research (WUR) staff in 2006-2015. The journals with\ncited articles are inventoried from the reference lists of the WUR journal\narticles. For each WUR article a mean dissimilarity is calculated between the\njournal in which it has been published and the journals that contain the cited\narticles. Dissimilarities are derived from a large matrix with similarity\nvalues between journals, calculated from co-citations to these journals from\nthe same WUR articles published in 2006-2015. For 21,191 WUR articles published\nin 2,535 journals mean dissimilarities have been calculated. For WUR articles\nwith high mean dissimilarities this paper shows that they often are published\nin multidisciplinary journals. WUR articles with high mean dissimilarities also\nare found in non-multidisciplinary (research field specific) journals. For\nthese articles (with high mean dissimilarities) this paper shows that citations\nare often made to more various research fields than for articles with lower\nmean dissimilarities. The mean dissimilarities, calculated per WUR article,\nalso can be aggregated for the journals in which they have been published. This\nresults in a listing of journals than can be ordered on the mean dissimilarity\nof the WUR articles that have been published in them. The analysis described in\nthis paper shows that journals for which a high mean dissimilarity is\ncalculated tend to have a multidisciplinary scope.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 08:30:02 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 09:24:02 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["van Veller", "Marco G. P.", ""]]}, {"id": "1807.08685", "submitter": "Mike Thelwall Prof", "authors": "Benedetto Lepori, Mike Thelwall, Bareerah Hafeez Hoorania", "title": "Which US and European Higher Education Institutions are visible in\n  ResearchGate and what affects their RG Score?", "comments": null, "journal-ref": "Journal of Informetrics, 12(3), 806-818 (2018)", "doi": "10.1016/j.joi.2018.07.001", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While ResearchGate has become the most popular academic social networking\nsite in terms of regular users, not all institutions have joined and the scores\nit assigns to academics and institutions are controversial. This paper assesses\nthe presence in ResearchGate of higher education institutions in Europe and the\nUS in 2017, and the extent to which institutional ResearchGate Scores reflect\ninstitutional academic impact. Most of the 2258 European and 4355 US higher\neducational institutions included in the sample had an institutional\nResearchGate profile, with near universal coverage for PhD-awarding\ninstitutions found in the Web of Science (WoS). For non-PhD awarding\ninstitutions that did not publish, size (number of staff members) was most\nassociated with presence in ResearchGate. For PhD-awarding institutions in WoS,\npresence in RG was strongly related to the number of WoS publications. In\nconclusion, a) institutional RG scores reflect research volume more than\nvisibility and b) this indicator is highly correlated to the number of WoS\npublications. Hence, the value of RG Scores for institutional comparisons is\nlimited.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 15:53:15 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lepori", "Benedetto", ""], ["Thelwall", "Mike", ""], ["Hoorania", "Bareerah Hafeez", ""]]}, {"id": "1807.09266", "submitter": "Klerisson Paixao", "authors": "Marco Tulio Valente and Kl\\'erisson Paix\\~ao", "title": "CSIndexbr: Exploring the Brazilian Scientific Production in Computer\n  Science", "comments": "CSIndexbr whitepaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  CSIndexbr is a web-based system that provides meaningful,open,and transparent\ndata about Brazilian scientific production in Computer Science. Currently, the\nsystem collects full research papers published in the main track of selected\nconferences. The papers are retrieved from DBLP. In this article, we describe\nthe main features and resources provided by CSIndexbr. We also comment on how\nother researchers can use the data provided by the system to analyze the\nBrazilian production in Computer Science.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 02:23:31 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Valente", "Marco Tulio", ""], ["Paix\u00e3o", "Kl\u00e9risson", ""]]}, {"id": "1807.09944", "submitter": "Weishu Liu", "authors": "Weishu Liu, Guangyuan Hu, Li Tang", "title": "Missing author address information in Web of Science-An explorative\n  study", "comments": "Accepted by Journal of Informetrics", "journal-ref": "Journal of Informetrics, 12(3), 2018, 985-997", "doi": "10.1016/j.joi.2018.07.008", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bibliometric analysis is increasingly used to evaluate and compare research\nperformance across geographical regions. However, the problem of missing\ninformation from author addresses has not attracted sufficient attention from\nscholars and practitioners. This study probes the missing data problem in the\nthree core journal citation databases of Web of Science (WoS). Our findings\nreveal that from 1900 to 2015 over one-fifth of the publications indexed in WoS\nhave completely missing information from the address field. The magnitude of\nthe problem varies greatly among time periods, citation databases, document\ntypes, and publishing languages. The problem is especially serious for research\nin the sciences and social sciences published before the early 1970s and\nremains significant for recent publications in the arts and humanities. Further\nexaminations suggest that many records with completely missing address\ninformation do not represent scholarly research. Full-text scanning of a random\nsample reveals that about 40% of the articles have some address information\nthat is not indexed in WoS. This study also finds that the problem of partially\nmissing address information for U.S. research has diminished dramatically since\n1998. The paper ends by providing some discussion and tentative remedies.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:44:42 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Liu", "Weishu", ""], ["Hu", "Guangyuan", ""], ["Tang", "Li", ""]]}, {"id": "1807.10804", "submitter": "Tanmoy Chakraborty", "authors": "Joyita Chakraborty, Dinesh Pradhan, Hridoy Sankar Dutta, Subrata\n  Nandi, Tanmoy Chakraborty", "title": "On Good and Bad Intentions behind Anomalous Citation Patterns among\n  Journals in Computer Sciences", "comments": "8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific journals are an important choice of publication venue for most\nauthors. Publishing in prestigious journal plays a decisive role for authors in\nhiring and promotions. In last decade, citation pressure has become intact for\nall scientific entities more than ever before. Unethical publication practices\nhas started to manipulate widely used performance metric such as \"impact\nfactor\" for journals and citation based indices for authors. This threatens the\nintegrity of scientific quality and takes away deserved credit of legitimate\nauthors and their authentic publications.\n  In this paper we extract all possible anomalous citation patterns between\njournals from a Computer Science bibliographic dataset which contains more than\n2,500 journals. Apart from excessive self-citations, we mostly focus on finding\nseveral patterns between two or more journals such as bi-directional mutual\ncitations, chains, triangles, mesh, cartel relationships. On a macroscopic\nscale, the motivation is to understand the nature of these patterns by modeling\nhow journals mutually interact through citations. On microscopic level, we\ndifferentiate between possible intentions (good or bad) behind such patterns.\nWe see whether such patterns prevail for long period or during any specific\ntime duration. For abnormal citation behavior, we study the nature of sudden\ninflation in impact factor of journals on a time basis which may occur due to\naddition of irrelevant and superfluous citations in such closed pattern\ninteraction. We also study possible influences such as abrupt increase in paper\ncount due to the presence of self-referential papers or duplicate manuscripts,\nauthor self-citation, author co-authorship network, author-editor network,\npublication houses etc. The entire study is done to question the reliability of\nexisting bibliometrics, and hence, it is an urgent need to curtail their usage\nor redefine them.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 19:05:28 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chakraborty", "Joyita", ""], ["Pradhan", "Dinesh", ""], ["Dutta", "Hridoy Sankar", ""], ["Nandi", "Subrata", ""], ["Chakraborty", "Tanmoy", ""]]}]