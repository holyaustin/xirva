[{"id": "1901.00429", "submitter": "Giovanni Abramo", "authors": "Giovanni Abramo, Ciriaco Andrea D'Angelo, Francesco Rosati", "title": "Gender bias in academic recruitment", "comments": "arXiv admin note: text overlap with arXiv:1810.13236,\n  arXiv:1810.12207", "journal-ref": "Scientometrics, 106(1), 119-141", "doi": "10.1007/s11192-015-1783-3", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that women are underrepresented in the academic systems of\nmany countries. Gender discrimination is one of the factors that could\ncontribute to this phenomenon. This study considers a recent national academic\nrecruitment campaign in Italy, examining whether women are subject to more or\nless bias than men. The findings show that no gender-related differences occur\namong the candidates who benefit from positive bias, while among those\ncandidates affected by negative bias, the incidence of women is lower than that\nof men. Among the factors that determine success in a competition for an\nacademic position, the number of the applicant's career years in the same\nuniversity as the committee members assumes greater weight for male candidates\nthan for females. Being of the same gender as the committee president is also a\nfactor that assumes greater weight for male applicants. On the other hand, for\nfemale applicants, the presence of a full professor in the same university with\nthe same family name as the candidate assumes greater weight than for male\ncandidates.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:24:47 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Abramo", "Giovanni", ""], ["D'Angelo", "Ciriaco Andrea", ""], ["Rosati", "Francesco", ""]]}, {"id": "1901.01010", "submitter": "Aili Shen", "authors": "Aili Shen, Bahar Salehi, Timothy Baldwin, and Jianzhong Qi", "title": "A Joint Model for Multimodal Document Quality Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of a document is affected by various factors, including\ngrammaticality, readability, stylistics, and expertise depth, making the task\nof document quality assessment a complex one. In this paper, we explore this\ntask in the context of assessing the quality of Wikipedia articles and academic\npapers. Observing that the visual rendering of a document can capture implicit\nquality indicators that are not present in the document text --- such as\nimages, font choices, and visual layout --- we propose a joint model that\ncombines the text content with a visual rendering of the document for document\nquality assessment. Experimental results over two datasets reveal that textual\nand visual features are complementary, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 08:05:56 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 00:46:42 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Shen", "Aili", ""], ["Salehi", "Bahar", ""], ["Baldwin", "Timothy", ""], ["Qi", "Jianzhong", ""]]}, {"id": "1901.02789", "submitter": "Federico Battiston", "authors": "Federico Battiston, Federico Musciotto, Dashun Wang, Albert-Laszlo\n  Barabasi, Michael Szell, Roberta Sinatra", "title": "Taking census of physics", "comments": "pre-peer-reviewed version of the Nature Reviews Physics perspective", "journal-ref": "Nature Reviews Physics 1, 89-97 (2019)", "doi": "10.1038/s42254-018-0005-3", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, the diversity of areas explored by physicists has\nexploded, encompassing new topics from biophysics and chemical physics to\nnetwork science. However, it is unclear how these new subfields emerged from\nthe traditional subject areas and how physicists explore them. To map out the\nevolution of physics subfields, here, we take an intellectual census of physics\nby studying physicists' careers. We use a large-scale publication data set,\nidentify the subfields of 135,877 physicists and quantify their heterogeneous\nbirth, growth and migration patterns among research areas. We find that the\nmajority of physicists began their careers in only three subfields, branching\nout to other areas at later career stages, with different rates and transition\ntimes. Furthermore, we analyse the productivity, impact and team sizes across\ndifferent subfields, finding drastic changes attributable to the recent rise in\nlarge-scale collaborations. This detailed, longitudinal census of physics can\ninform resource allocation policies and provide students, editors and\nscientists with a broader view of the field's internal dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 15:55:24 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Battiston", "Federico", ""], ["Musciotto", "Federico", ""], ["Wang", "Dashun", ""], ["Barabasi", "Albert-Laszlo", ""], ["Szell", "Michael", ""], ["Sinatra", "Roberta", ""]]}, {"id": "1901.02880", "submitter": "Philip Hofmann", "authors": "Anna Tietze and Philip Hofmann", "title": "The $h$-index and multi-author $h_m$-index for individual researchers in\n  condensed matter physics", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characteristics of the $h$-index in the field of condensed matter physics\nare studied using high-quality data from ResearcherID. The results are examined\nin terms of theoretical descriptions of the $h$-index' overall dependence on a\nresearcher's total number of published papers, and total number of citations.\nIn particular, the models by Hirsch, Egghe and Rousseau, as well as by\nGl\\\"anzel and Schubert are examined. Special emphasis is placed on the\ndeviations from such statistical descriptions, and it is argued that the\ndeviation of a particular researcher's $h$ value from the Egghe-Rouseau model's\nprediction can be used as a supplementary measure of impact. A corresponding\nanalysis with similar results is performed using the multi-author $h_m$-index.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:59:44 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 15:05:44 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tietze", "Anna", ""], ["Hofmann", "Philip", ""]]}, {"id": "1901.03607", "submitter": "Alessandro Pluchino", "authors": "Alessandro Pluchino, Giulio Burgio, Andrea Rapisarda, Alessio Emanuele\n  Biondo, Alfredo Pulvirenti, Alfredo Ferro and Toni Giorgino", "title": "Exploring the Role of Interdisciplinarity in Physics: Success, Talent\n  and Luck", "comments": "21 pages, 19 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0218793", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although interdisciplinarity is often touted as a necessity for modern\nresearch, the evidence on the relative impact of sectorial versus to\ninterdisciplinary science is qualitative at best. In this paper we leverage the\nbibliographic data set of the American Physical Society to quantify the role of\ninterdisciplinarity in physics, and that of talent and luck in achieving\nsuccess in scientific careers. We analyze a period of 30 years (1980-2009)\ntagging papers and their authors by means of the Physics and Astronomy\nClassification Scheme (PACS), to show that some degree of interdisciplinarity\nis quite helpful to reach success, measured as a proxy of either the number of\narticles or the citations score. We also propose an agent-based model of the\npublication-reputation-citation dynamics reproduces the trends observed in the\nAPS data set. On the one hand, the results highlight the crucial role of\nrandomness and serendipity in real scientific research; on the other, they shed\nlight on a counter-intuitive effect indicating that the most talented authors\nare not necessarily the most successful ones.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 15:02:37 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Pluchino", "Alessandro", ""], ["Burgio", "Giulio", ""], ["Rapisarda", "Andrea", ""], ["Biondo", "Alessio Emanuele", ""], ["Pulvirenti", "Alfredo", ""], ["Ferro", "Alfredo", ""], ["Giorgino", "Toni", ""]]}, {"id": "1901.03925", "submitter": "Bowen Yan", "authors": "Bowen Yan, Jianxi Luo", "title": "The Superior Knowledge Proximity Measure for Patent Mapping", "comments": "8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network maps of patent classes have been widely used to analyze the coherence\nand diversification of technology or knowledge positions of inventors, firms,\nindustries, regions, and so on. To create such networks, a measure is required\nto associate different classes of patents in the patent database and often\nindicates knowledge proximity (or distance). Prior studies have used a variety\nof knowledge proximity measures based on different perspectives and association\nrules. It is unclear how to consistently assess and compare them, and which\nones are superior for constructing a generally useful total patent class\nnetwork. Such uncertainty has limited the generality and applications of the\npreviously reported maps. Herein, we use a statistical method to identify the\nsuperior proximity measure from a comprehensive set of typical measures, by\nevaluating and comparing their explanatory powers on the historical expansions\nof the patent portfolios of individual inventors and organizations across\ndifferent patent classes. Based on the complete United States granted patent\ndatabase from 1976 to 2017, our analysis identifies a reference-based Jaccard\nindex as the statistically superior measure, for explaining the historical\ndiversifications and predicting future movement directions of both individual\ninventors and organizations across technology domains.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 03:03:51 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 13:11:16 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Yan", "Bowen", ""], ["Luo", "Jianxi", ""]]}, {"id": "1901.05273", "submitter": "Peter Sj\\\"og{\\aa}rde", "authors": "Peter Sj\\\"og{\\aa}rde and Per Ahlgren", "title": "Granularity of algorithmically constructed publication-level\n  classifications of research publications: Identification of specialties", "comments": "arXiv admin note: text overlap with arXiv:1801.02466", "journal-ref": null, "doi": "10.1162/qss_a_00004", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, in which we build on, and use the outcome of, an earlier study\non topic identification in an algorithmically constructed publication-level\nclassification (ACPLC), we address the issue how to algorithmically obtain a\nclassification of topics (containing articles), where the classes of the\nclassification correspond to specialties. The methodology we propose, which is\nsimilar to the one used in the earlier study, uses journals and their articles\nto construct a baseline classification. The underlying assumption of our\napproach is that journals of a particular size and foci have a scope that\ncorrespond to specialties. By measuring the similarity between (1) the baseline\nclassification and (2) multiple classifications obtained by topic clustering\nand using different values of a resolution parameter, we have identified a\nbest-performing ACPLC. In two case studies, we could identify the subject foci\nof involved specialties, and the subject foci of specialties were relatively\neasy to distinguish. Further, the class size variation regarding the best\nperforming ACPLC is moderate, and only a small proportion of the articles\nbelong to very small classes. For these reasons, we conclude that the proposed\nmethodology is suitable to determine the specialty granularity level of an\nACPLC.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 13:39:13 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Sj\u00f6g\u00e5rde", "Peter", ""], ["Ahlgren", "Per", ""]]}, {"id": "1901.05447", "submitter": "Taekho You", "authors": "Taekho You, Woo-Sung Jung", "title": "A System Dynamics Analysis of National R&D Performance Measurement\n  System in Korea", "comments": null, "journal-ref": "Industrial Engineering & Management Systems Vol.17 No.4 pp.833-839\n  (2018)", "doi": "10.7232/iems.2018.17.4.833", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is one of useful and powerful performance measurement process. In\nKorea, it needs to increase quality of R&D performance, but bibliometric\nevaluation and lack of peers have opposite effect. We used system dynamics to\ndescribe Korean R&D performance measurement system and ways to increase\nperformance quality. To meet a desired R&D performance quality, increasing\nfairness and quality of evaluation is needed. Size of peer pool decreased\nbecause of the specialization of R&D projects and the Sangpi process both, and\nit is critical to acquire both fairness and quality. Also, shortening\nevaluation period affect to R&D performance quality, by causing workloads\nincrease, limiting long-term and innovative R&D projects, and decreasing\nevaluation quality. Previous evaluation policies do a role like\nmicro-controlling the R&D's activities, but increasing the size of peer pool\nand changing evaluation period would make a change to quality and fairness of\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 08:46:46 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["You", "Taekho", ""], ["Jung", "Woo-Sung", ""]]}, {"id": "1901.05463", "submitter": "Sergi Blanco-Cuaresma", "authors": "Sergi Blanco-Cuaresma, Alberto Accomazzi, Michael J. Kurtz, Edwin\n  Henneken, Carolyn S. Grant, Donna M. Thompson, Roman Chyla, Stephen McDonald,\n  Golnaz Shapurian, Timothy W. Hostetler, Matthew R. Templeton, Kelly E.\n  Lockhart, Kris Bukovi and Nathan Rapport", "title": "Fundamentals of effective cloud management for the new NASA Astrophysics\n  Data System", "comments": "To appear in the proceedings of the 28th annual international\n  Astronomical Data Analysis Software & Systems (ADASS XXVIII)", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new NASA Astrophysics Data System (ADS) is designed with a\nserviceoriented architecture (SOA) that consists of multiple customized Apache\nSolr search engine instances plus a collection of microservices, containerized\nusing Docker, and deployed in Amazon Web Services (AWS). For complex systems,\nlike the ADS, this loosely coupled architecture can lead to a more scalable,\nreliable and resilient system if some fundamental questions are addressed.\nAfter having experimented with different AWS environments and deployment\nmethods, we decided in December 2017 to go with Kubernetes as our container\norchestration. Defining the best strategy to properly setup Kubernetes has\nshown to be challenging: automatic scaling services and load balancing traffic\ncan lead to errors whose origin is difficult to identify, monitoring and\nlogging the activity that happens across multiple layers for a single request\nneeds to be carefully addressed, and the best workflow for a Continuous\nIntegration and Delivery (CI/CD) system is not self-evident. We present here\nhow we tackle these challenges and our plans for the future.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:00:01 GMT"}], "update_date": "2019-01-27", "authors_parsed": [["Blanco-Cuaresma", "Sergi", ""], ["Accomazzi", "Alberto", ""], ["Kurtz", "Michael J.", ""], ["Henneken", "Edwin", ""], ["Grant", "Carolyn S.", ""], ["Thompson", "Donna M.", ""], ["Chyla", "Roman", ""], ["McDonald", "Stephen", ""], ["Shapurian", "Golnaz", ""], ["Hostetler", "Timothy W.", ""], ["Templeton", "Matthew R.", ""], ["Lockhart", "Kelly E.", ""], ["Bukovi", "Kris", ""], ["Rapport", "Nathan", ""]]}, {"id": "1901.06246", "submitter": "Jasper Snoek", "authors": "D Sculley and Jasper Snoek and Alex Wiltschko", "title": "Avoiding a Tragedy of the Commons in the Peer Review Process", "comments": "Appeared in the 2018 Advances in Neural Information Processing\n  Systems Workshop on Critiquing and Correcting Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is the foundation of scientific publication, and the task of\nreviewing has long been seen as a cornerstone of professional service. However,\nthe massive growth in the field of machine learning has put this community\nbenefit under stress, threatening both the sustainability of an effective\nreview process and the overall progress of the field. In this position paper,\nwe argue that a tragedy of the commons outcome may be avoided by emphasizing\nthe professional aspects of this service. In particular, we propose a rubric to\nhold reviewers to an objective standard for review quality. In turn, we also\npropose that reviewers be given appropriate incentive. As one possible such\nincentive, we explore the idea of financial compensation on a per-review basis.\nWe suggest reasonable funding models and thoughts on long term effects.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 15:32:29 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Sculley", "D", ""], ["Snoek", "Jasper", ""], ["Wiltschko", "Alex", ""]]}, {"id": "1901.06815", "submitter": "Ludo Waltman", "authors": "Ludo Waltman and Kevin W. Boyack and Giovanni Colavizza and Nees Jan\n  van Eck", "title": "A principled methodology for comparing relatedness measures for\n  clustering publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many different relatedness measures, based for instance on citation\nrelations or textual similarity, that can be used to cluster scientific\npublications. We propose a principled methodology for evaluating the accuracy\nof clustering solutions obtained using these relatedness measures. We formally\nshow that the proposed methodology has an important consistency property. The\nempirical analyses that we present are based on publications in the fields of\ncell biology, condensed matter physics, and economics. Using the BM25\ntext-based relatedness measure as evaluation criterion, we find that\nbibliographic coupling relations yield more accurate clustering solutions than\ndirect citation relations and co-citation relations. The so-called extended\ndirect citation approach performs similarly to or slightly better than\nbibliographic coupling in terms of the accuracy of the resulting clustering\nsolutions. The other way around, using a citation-based relatedness measure as\nevaluation criterion, BM25 turns out to yield more accurate clustering\nsolutions than other text-based relatedness measures.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 08:00:27 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 11:25:56 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Waltman", "Ludo", ""], ["Boyack", "Kevin W.", ""], ["Colavizza", "Giovanni", ""], ["van Eck", "Nees Jan", ""]]}, {"id": "1901.07337", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Alexander Tekles, Loet Leydesdorff", "title": "How well does I3 perform for impact measurement compared to other\n  bibliometric indicators? The convergent validity of several\n  (field-normalized) indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the integrated impact indicator (I3) indicator was introduced where\ncitations are weighted in accordance with the percentile rank class of each\npublication in a set of publications. I3 can also be used as a field-normalized\nindicator. Field-normalization is common practice in bibliometrics, especially\nwhen institutions and countries are compared. Publication and citation\npractices are so different among fields that citation impact is normalized for\ncross-field comparisons. In this study, we test the ability of the indicator to\ndiscriminate between quality levels of papers as defined by Faculty members at\nF1000Prime. F1000Prime is a post-publication peer review system for assessing\npapers in the biomedical area. Thus, we test the convergent validity of I3 (in\nthis study, we test I3/N - the size-independent variant of I3 where I3 is\ndivided by the number of papers) using assessments by peers as baseline and\ncompare its validity with several other (field-normalized) indicators: the\nmean-normalized citation score (MNCS), relative-citation ratio (RCR), citation\nscore normalized by cited references (CSNCR), characteristic scores and scales\n(CSS), source-normalized citation score (SNCS), citation percentile, and\nproportion of papers which belong to the x% most frequently cited papers (PPtop\nx%). The results show that the PPtop 1% indicator discriminates best among\ndifferent quality levels. I3 performs similar as (slightly better than) most of\nthe other field-normalized indicators. Thus, the results point out that the\nindicator could be a valuable alternative to other indicators in bibliometrics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 10:48:14 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 12:54:20 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Bornmann", "Lutz", ""], ["Tekles", "Alexander", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1901.07352", "submitter": "Robin Haunschild", "authors": "Robin Haunschild and Werner Marx", "title": "Discovering seminal works with marker papers", "comments": "26 pages, 7 figures, 4 tables, Keywords: Bibliometrics, RPYS,\n  RPYS-CO, marker paper, seminal papers, historical roots, DFT, Web of Science,\n  Microsoft Academic, CAplus; earlier version was presented at 8th\n  International Workshop on Bibliometric-Enhanced Information Retrieval, BIR\n  2019; Cologne; Germany; 14 April 2019; current version has been accepted for\n  publication in Scientometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bibliometric information retrieval in databases can employ different\nstrategies. Com-monly, queries are performed by searching in title, abstract\nand/or author keywords (author vocabulary). More advanced queries employ\ndatabase keywords to search in a controlled vo-cabulary. Queries based on\nsearch terms can be augmented with their citing papers if a re-search field\ncannot be curtailed by the search query alone. Here, we present another\nstrategy to discover the most important papers of a research field. A marker\npaper is used to reveal the most important works for the relevant community.\nAll papers co-cited with the marker paper are analyzed using reference\npublication year spectroscopy (RPYS). For demonstration of the marker paper\napproach, density functional theory (DFT) is used as a research field.\nCompari-sons between a prior RPYS on a publication set compiled using a\nkeyword-based search in a controlled vocabulary and three different co-citation\nRPYS (RPYS-CO) analyses show very similar results. Similarities and differences\nare discussed.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 14:45:59 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 14:22:51 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 16:38:58 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 13:40:12 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Haunschild", "Robin", ""], ["Marx", "Werner", ""]]}, {"id": "1901.08593", "submitter": "Ehsan Mohammadi Dr", "authors": "Ehsan Mohammadi, Mike Thelwall", "title": "Readership Data and Research Impact", "comments": null, "journal-ref": "Handbook of Quantitative Science and Technology Research, 2019", "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reading academic publications is a key scholarly activity. Scholars accessing\nand recording academic publications online are producing new types of\nreadership data. These include publisher, repository, and academic social\nnetwork download statistics as well as online reference manager records. This\nchapter discusses the use of download and reference manager data for research\nevaluation and library collection development. The focus is on the validity and\napplication of readership data as an impact indicator for academic publications\nacross different disciplines. Mendeley is particularly promising in this\nregard, although all data sources are not subjected to rigorous quality control\nand can be manipulated.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 01:42:56 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Mohammadi", "Ehsan", ""], ["Thelwall", "Mike", ""]]}, {"id": "1901.08775", "submitter": "Andreas Thor", "authors": "Andreas Thor, Lutz Bornmann, Robin Haunschild, Loet Leydesdorff", "title": "Which are the influential publications in the Web of Science subject\n  categories over a long period of time? CRExplorer software used for big-data\n  analyses in bibliometrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the landmark papers in scientific disciplines? On whose shoulders\ndoes research in these fields stand? Which papers are indispensable for\nscientific progress? These are typical questions which are not only of interest\nfor researchers (who frequently know the answers - or guess to know them), but\nalso for the interested general public. Citation counts can be used to identify\nvery useful papers, since they reflect the wisdom of the crowd; in this case,\nthe scientists using the published results for their own research. In this\nstudy, we identified with recently developed methods for the program CRExplorer\nlandmark publications in nearly all Web of Science subject categories (WoSSCs).\nThese are publications which belong more frequently than other publications\nacross the citing years to the top-per mill in their subject category. The\nresults for three subject categories \"Information Science and Library Science\",\n\"Computer Science, Information Systems\", and \"Computer Science, Software\nEngineering\" are exemplarily discussed in more detail. The results for the\nother WoSSCs can be found online at http://crexplorer.net.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:13:41 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Thor", "Andreas", ""], ["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1901.08977", "submitter": "Valentina Franzoni", "authors": "Valentina Franzoni, Michele Lepri, Alfredo Milani", "title": "Topological and Semantic Graph-based Author Disambiguation on DBLP Data\n  in Neo4j", "comments": "Pre-print of article presented at AIKE (Artificial Intelligence and\n  Knowledge Engineering) IEEE Conference, September 2018, Laguna Hills,\n  California (USA)", "journal-ref": "AIKE 2018: 239-243", "doi": "10.1109/AIKE.2018.00054", "report-no": null, "categories": "cs.IR cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we introduce a novel method for entity resolution author\ndisambiguation in bibliographic networks. Such a method is based on a 2-steps\nnetwork traversal using topological similarity measures for rating candidate\nnodes. Topological similarity is widely used in the Link Prediction application\ndomain to assess the likelihood of an unknown link. A similarity function can\nbe a good approximation for equality, therefore can be used to disambiguate,\nbasing on the hypothesis that authors with many common co-authors are similar.\nOur method has experimented on a graph-based representation of the public DBLP\nComputer Science database. The results obtained are extremely encouraging\nregarding Precision, Accuracy, and Specificity. Further good aspects are the\nlocality of the method for disambiguation assessment which avoids the need to\nknow the global network, and the exploitation of only a few data, e.g. author\nname and paper title (i.e., co-authorship data).\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 16:49:53 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Franzoni", "Valentina", ""], ["Lepri", "Michele", ""], ["Milani", "Alfredo", ""]]}, {"id": "1901.09099", "submitter": "Woo-Sung Jung", "authors": "Hyunuk Kim, Inho Hong, Woo-Sung Jung", "title": "Measuring national capability over big sciences multidisciplinarity: A\n  case study of nuclear fusion research", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0211963", "report-no": null, "categories": "cs.DL physics.plasm-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big science, countries allocate big research and development\nbudgets to large scientific facilities that boost collaboration and research\ncapability. A nuclear fusion device called the \"tokamak\" is a source of great\ninterest for many countries because it ideally generates sustainable energy\nexpected to solve the energy crisis in the future. Here, to explore the\nscientific effects of tokamaks, we map a country's research capability in\nnuclear fusion research with normalized revealed comparative advantage on five\ntopical clusters -- material, plasma, device, diagnostics, and simulation --\ndetected through a dynamic topic model. Our approach captures not only the\ngrowth of China, India, and the Republic of Korea but also the decline of\nCanada, Japan, Sweden, and the Netherlands. Time points of their rise and fall\nare related to tokamak operation, highlighting the importance of large\nfacilities in big science. The gravity model points out that two countries\ncollaborate less in device, diagnostics, and plasma research if they have\ncomparative advantages in different topics. This relation is a unique feature\nof nuclear fusion compared to other science fields. Our results can be used and\nextended when building national policies for big science.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:04:33 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Kim", "Hyunuk", ""], ["Hong", "Inho", ""], ["Jung", "Woo-Sung", ""]]}, {"id": "1901.09663", "submitter": "Yi Bu", "authors": "Yi Bu, Ludo Waltman, Yong Huang", "title": "A multi-dimensional framework for characterizing the citation impact of\n  scientific publications", "comments": "40 pages, 9 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The citation impact of a scientific publication is usually seen as a\none-dimensional concept. We introduce a multi-dimensional framework for\ncharacterizing the citation impact of a publication. In addition to the level\nof citation impact, quantified by the number of citations received by a\npublication, we also conceptualize and operationalize the depth and breadth and\nthe dependence and independence of the citation impact of a publication. The\nproposed framework distinguishes between publications that have a deep citation\nimpact, typically in a relatively narrow research area, and publications that\nhave a broad citation impact, probably covering a wider area of research. It\nalso makes a distinction between publications that are strongly dependent on\nearlier work and publications that make a more independent scientific\ncontribution. We use our multi-dimensional citation impact framework to report\nbasic descriptive statistics on the citation impact of highly cited\npublications in all scientific disciplines. In addition, we present a detailed\ncase study focusing on the field of scientometrics. The proposed citation\nimpact framework provides a more in-depth understanding of the citation impact\nof a publication than a traditional one-dimensional perspective.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:14:10 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 20:44:19 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 01:17:38 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 04:28:04 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bu", "Yi", ""], ["Waltman", "Ludo", ""], ["Huang", "Yong", ""]]}, {"id": "1901.10816", "submitter": "Mohamad Yaser Jaradeh", "authors": "Mohamad Yaser Jaradeh, Allard Oelen, Kheir Eddine Farfar, Manuel\n  Prinz, Jennifer D'Souza, G\\'abor Kismih\\'ok, Markus Stocker, S\\\"oren Auer", "title": "Open Research Knowledge Graph: Next Generation Infrastructure for\n  Semantic Scholarly Knowledge", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite improved digital access to scholarly knowledge in recent decades,\nscholarly communication remains exclusively document-based. In this form,\nscholarly knowledge is hard to process automatically. In this paper, we present\nthe first steps towards a knowledge graph based infrastructure that acquires\nscholarly knowledge in machine actionable form thus enabling new possibilities\nfor scholarly knowledge curation, publication and processing. The primary\ncontribution is to present, evaluate and discuss multi-modal scholarly\nknowledge acquisition, combining crowdsourced and automated techniques. We\npresent the results of the first user evaluation of the infrastructure with the\nparticipants of a recent international conference. Results suggest that users\nwere intrigued by the novelty of the proposed infrastructure and by the\npossibilities for innovative scholarly knowledge processing it could enable.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 13:34:45 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 08:50:41 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 14:55:14 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Jaradeh", "Mohamad Yaser", ""], ["Oelen", "Allard", ""], ["Farfar", "Kheir Eddine", ""], ["Prinz", "Manuel", ""], ["D'Souza", "Jennifer", ""], ["Kismih\u00f3k", "G\u00e1bor", ""], ["Stocker", "Markus", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "1901.11267", "submitter": "Tobias Weber", "authors": "Tobias Weber and Dieter Kranzlm\\\"uller", "title": "Methods to Evaluate Lifecycle Models for Research Data Management", "comments": null, "journal-ref": null, "doi": "10.1515/dmpt-2016-00", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lifecycle models for research data are often abstract and simple. This comes\nat the danger of oversimplifying the complex concepts of research data\nmanagement. The analysis of 90 different lifecycle models lead to two\napproaches to assess the quality of these models. While terminological issues\nmake direct comparisons of models hard, an empirical evaluation seems possible.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 08:41:31 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Weber", "Tobias", ""], ["Kranzlm\u00fcller", "Dieter", ""]]}]