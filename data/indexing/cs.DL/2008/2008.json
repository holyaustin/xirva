[{"id": "2008.00016", "submitter": "Hoang Nguyen Mr.", "authors": "Minh-Hoang Nguyen, Huyen Thanh T. Nguyen, Thanh-Hang Pham, Manh-Toan\n  Ho and Quan-Hoang Vuong", "title": "Western ideological homogeneity in entrepreneurial finance research:\n  Evidence from highly cited publications", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entrepreneurs play crucial roles in global sustainable development, but\nlimited financial resources constrain their performance and survival rate.\nEntrepreneurial finance discipline is, therefore, born to explore the\nconnection between finance and entrepreneurship. Despite the global presence of\nentrepreneurship, the literature of entrepreneurial finance is suspected to be\nWestern ideologically homogenous. Thus, the objective of this study is to\nexamine the existence of Western ideological homogeneity in entrepreneurial\nfinance literature. Employing the mindsponge mechanism and bibliometric\nanalyses (Y-index and social structure), we analyze 412 highly cited\npublications extracted from Web of Science database and find Western\nideological dominance as well as weak tolerance towards heterogeneity in the\nset of core ideologies of entrepreneurial finance. These results are consistent\nacross author-, institution-, and country-levels, which reveals strong evidence\nfor the existence of Western ideological homogeneity in the field. We recommend\neditors, reviewers, and authors to have proactive actions to diversify research\ntopics and enhancing knowledge exchange to avoid the shortfalls of ideological\nhomogeneity. Moreover, the synthesis of mindsponge mechanism and bibliometric\nanalyses are suggested as a possible way to evaluate the state of ideological\ndiversity in other scientific disciplines.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:03:44 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nguyen", "Minh-Hoang", ""], ["Nguyen", "Huyen Thanh T.", ""], ["Pham", "Thanh-Hang", ""], ["Ho", "Manh-Toan", ""], ["Vuong", "Quan-Hoang", ""]]}, {"id": "2008.00137", "submitter": "Shawn Jones", "authors": "Shawn M. Jones, Martin Klein, Michele C. Weigle, Michael L. Nelson", "title": "MementoEmbed and Raintale for Web Archive Storytelling", "comments": "54 pages, 5 tables, 46 figures", "journal-ref": "Presented at the Web Archiving and Digital Libraries 2020 Workshop", "doi": null, "report-no": null, "categories": "cs.DL cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For traditional library collections, archivists can select a representative\nsample from a collection and display it in a featured physical or digital\nlibrary space. Web archive collections may consist of thousands of archived\npages, or mementos. How should an archivist display this sample to drive\nvisitors to their collection? Search engines and social media platforms often\nrepresent web pages as cards consisting of text snippets, titles, and images.\nWeb storytelling is a popular method for grouping these cards in order to\nsummarize a topic. Unfortunately, social media platforms are not archive-aware\nand fail to consistently create a good experience for mementos. They also allow\nno UI alterations for their cards. Thus, we created MementoEmbed to generate\ncards for individual mementos and Raintale for creating entire stories that\narchivists can export to a variety of formats.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 00:52:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Jones", "Shawn M.", ""], ["Klein", "Martin", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "2008.00139", "submitter": "Shawn Jones", "authors": "Shawn M. Jones, Alexander C. Nwala, Martin Klein, Michele C. Weigle,\n  Michael L. Nelson", "title": "SHARI -- An Integration of Tools to Visualize the Story of the Day", "comments": "19 pages, 16 figures, 1 Table", "journal-ref": "Presented at the Web Archiving and Digital Libraries 2020 Workshop", "doi": null, "report-no": null, "categories": "cs.DL cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tools such as Google News and Flipboard exist to convey daily news, but what\nabout the past? In this paper, we describe how to combine several existing\ntools with web archive holdings to perform news analysis and visualization of\nthe \"biggest story\" for a given date. StoryGraph clusters news articles\ntogether to identify a common news story. Hypercane leverages ArchiveNow to\nstore URLs produced by StoryGraph in web archives. Hypercane analyzes these\nURLs to identify the most common terms, entities, and highest quality images\nfor social media storytelling. Raintale then uses the output of these tools to\nproduce a visualization of the news story for a given day. We name this process\nSHARI (StoryGraph Hypercane ArchiveNow Raintale Integration).\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 01:02:37 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Jones", "Shawn M.", ""], ["Nwala", "Alexander C.", ""], ["Klein", "Martin", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "2008.00202", "submitter": "Malte Ostendorff", "authors": "Malte Ostendorff", "title": "Contextual Document Similarity for Content-based Literature Recommender\n  Systems", "comments": "In Proceedings of the Doctoral Consortium at ACM/IEEE Joint\n  Conference on Digital Libraries (JCDL 2020)", "journal-ref": "Proceedings of the Doctoral Consortium at ACM/IEEE Joint\n  Conference on Digital Libraries (JCDL 2020)", "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the ever-growing information overload, an increasing number of\ndigital libraries employ content-based recommender systems. These systems\ntraditionally recommend related documents with the help of similarity measures.\nHowever, current document similarity measures simply distinguish between\nsimilar and dissimilar documents. This simplification is especially crucial for\nextensive documents, which cover various facets of a topic and are often found\nin digital libraries. Still, these similarity measures neglect to what facet\nthe similarity relates. Therefore, the context of the similarity remains\nill-defined. In this doctoral thesis, we explore contextual document similarity\nmeasures, i.e., methods that determine document similarity as a triple of two\ndocuments and the context of their similarity. The context is here a further\nspecification of the similarity. For example, in the scientific domain,\nresearch papers can be similar with respect to their background, methodology,\nor findings. The measurement of similarity in regards to one or more given\ncontexts will enhance recommender systems. Namely, users will be able to\nexplore document collections by formulating queries in terms of documents and\ntheir contextual similarities. Thus, our research objective is the development\nand evaluation of a recommender system based on contextual similarity. The\nunderlying techniques will apply established similarity measures and as well as\nneural approaches while utilizing semantic features obtained from links between\ndocuments and their text.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:42:40 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Ostendorff", "Malte", ""]]}, {"id": "2008.00774", "submitter": "Daniel Kershaw", "authors": "Daniel Kershaw and Rob Koeling", "title": "Elsevier OA CC-By Corpus", "comments": "6 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Elsevier OA CC-BY corpus. This is the first open corpus of\nScientific Research papers which has a representative sample from across\nscientific disciplines. This corpus not only includes the full text of the\narticle, but also the metadata of the documents, along with the bibliographic\ninformation for each reference.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:51:10 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 17:47:41 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 09:39:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Kershaw", "Daniel", ""], ["Koeling", "Rob", ""]]}, {"id": "2008.00993", "submitter": "Wenceslao Arroyo-Machado", "authors": "Ana Gallego-Cui\\~nas, Esteban Romero-Fr\\'ias, Wenceslao Arroyo-Machado", "title": "Independent publishers and social networks in the 21st century: the\n  balance of power in the transatlantic Spanish-language book market", "comments": null, "journal-ref": null, "doi": "10.1108/OIR-10-2019-0342", "report-no": null, "categories": "cs.SI cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present paper uses Twitter to analyze the current state of the worldwide,\nSpanish-language, independent publishing market. The main purposes are to\ndetermine whether certain Latin American Spanish-language independent\npublishers function as gatekeepers of World Literature and to analyze the\ngeopolitical structure of this global market, addressing both the\nEurope-America dialectic and neocolonial practices. After selecting the sample\nof publishers, we conducted a search for their Twitter profiles and located\n131; we then downloaded data from the corresponding Twitter APIs. Finally, we\napplied social network analysis to study the presence of and interaction\nbetween our sample of independent publishers on this social media. Our results\nprovide data-based evidence supporting the hypothesis of some literary critics\nwho suggest that in Latin America, certain publishers act as gatekeepers to the\nmainstream book market. Therefore, Twitter could be considered a valid source\nof information to address the independent book market in Spanish. By extension,\nthis approach could be applied to other cultural industries in which small and\nmedium-sized agents develop a digital presence in social media. This paper\ncombines social network analysis and literary criticism to provide new evidence\nabout the Spanish-language book market. It helps validate the aforementioned\nhypothesis, proposed by literary critics, and opens up new paths along which to\npursue an interpretative, comparative analysis.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:26:03 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gallego-Cui\u00f1as", "Ana", ""], ["Romero-Fr\u00edas", "Esteban", ""], ["Arroyo-Machado", "Wenceslao", ""]]}, {"id": "2008.03129", "submitter": "Samin Aref", "authors": "Alexander Subbotin and Samin Aref", "title": "Brain Drain and Brain Gain in Russia: Analyzing International Migration\n  of Researchers by Discipline using Scopus Bibliometric Data 1996-2020", "comments": "26 pages, 9 figures, 2 tables, peer-reviewed and accepted\n  author-copy. Publisher's verified version: Subbotin, A. and Aref, S. (2021)\n  Brain Drain and Brain Gain in Russia: Analyzing International Migration of\n  Researchers by Discipline using Scopus Bibliometric Data 1996-2020.\n  Forthcoming in Scientometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study international mobility in academia, with a focus on the migration of\npublished researchers to and from Russia. Using an exhaustive set of over $2.4$\nmillion Scopus publications, we analyze all researchers who have published with\na Russian affiliation address in Scopus-indexed sources in 1996-2020. The\nmigration of researchers is observed through the changes in their affiliation\naddresses, which altered their mode countries of affiliation across different\nyears. While only $5.2\\%$ of these researchers were internationally mobile,\nthey accounted for a substantial proportion of citations. Our estimates of net\nmigration rates indicate that while Russia was a donor country in the late\n1990s and early 2000s, it has experienced a relatively balanced circulation of\nresearchers in more recent years. These findings suggest that the current\ntrends in scholarly migration in Russia could be better framed as brain\ncirculation, rather than as brain drain. Overall, researchers emigrating from\nRussia outnumbered and outperformed researchers immigrating to Russia. Our\nanalysis on the subject categories of publication venues shows that in the past\n25 years, Russia has, overall, suffered a net loss in most disciplines, and\nmost notably in the five disciplines of neuroscience, decision sciences,\nmathematics, biochemistry, and pharmacology. We demonstrate the robustness of\nour main findings under random exclusion of data and changes in numeric\nparameters. Our substantive results shed light on new aspects of international\nmobility in academia, and on the impact of this mobility on a national science\nsystem, which have direct implications for policy development.\nMethodologically, our novel approach to handling big data can be adopted as a\nframework of analysis for studying scholarly migration in other countries.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:47:38 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 09:41:54 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 01:34:33 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Subbotin", "Alexander", ""], ["Aref", "Samin", ""]]}, {"id": "2008.03134", "submitter": "Alexandre Benatti", "authors": "Alexandre Benatti, Henrique Ferraz de Arruda, Filipi Nascimento Silva,\n  and Luciano da Fontoura Costa", "title": "Transistors: A Network Science-Based Historical Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of modern electronics was to a large extent related to the\nadvent and popularization of bipolar junction technology. The present work\napplies science of science concepts and methodologies in order to develop a\nrelatively systematic, quantitative study of the development of electronics\nfrom a bipolar-junction-centered perspective. First, we searched the adopted\ndataset (Microsoft Academic Graph) for entries related to \"bipolar junction\ntransistor\". Community detection was then applied in order to derive sub-areas,\nwhich were tentatively labeled into 10 overall groups. This modular graph was\nthen studied from several perspectives, including topological measurements and\ntime evolution. A number of interesting results are reported, including a good\nlevel of thematic coherence within each identified area, as well as the\nidentification of distinct periods along the time evolution including the onset\nand coming of age of bipolater junction technology and related areas. A\nparticularly surprising result was the verification of stable interrelationship\nbetween the identified areas along time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:43:55 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 11:28:49 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Benatti", "Alexandre", ""], ["de Arruda", "Henrique Ferraz", ""], ["Silva", "Filipi Nascimento", ""], ["Costa", "Luciano da Fontoura", ""]]}, {"id": "2008.03397", "submitter": "Lana Yeganova", "authors": "Lana Yeganova, Rezarta Islamaj, Qingyu Chen, Robert Leaman, Alexis\n  Allot, Chin-Hsuan Wei, Donald C. Comeau, Won Kim, Yifan Peng, W. John Wilbur,\n  Zhiyong Lu", "title": "Navigating the landscape of COVID-19 research through literature\n  analysis: A bird's eye view", "comments": "10 pages, 8 Figures, Submitted to KDD 2020 Health Day", "journal-ref": "KDD 2020 Health Day: AI for COVID, August 23-27, 2020, Virtual\n  Conference, CA, US", "doi": null, "report-no": null, "categories": "cs.DL cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely access to accurate scientific literature in the battle with the\nongoing COVID-19 pandemic is critical. This unprecedented public health risk\nhas motivated research towards understanding the disease in general,\nidentifying drugs to treat the disease, developing potential vaccines, etc.\nThis has given rise to a rapidly growing body of literature that doubles in\nnumber of publications every 20 days as of May 2020. Providing medical\nprofessionals with means to quickly analyze the literature and discover growing\nareas of knowledge is necessary for addressing their question and information\nneeds.\n  In this study we analyze the LitCovid collection, 13,369 COVID-19 related\narticles found in PubMed as of May 15th, 2020 with the purpose of examining the\nlandscape of literature and presenting it in a format that facilitates\ninformation navigation and understanding. We do that by applying\nstate-of-the-art named entity recognition, classification, clustering and other\nNLP techniques. By applying NER tools, we capture relevant bioentities (such as\ndiseases, internal body organs, etc.) and assess the strength of their\nrelationship with COVID-19 by the extent they are discussed in the corpus. We\nalso collect a variety of symptoms and co-morbidities discussed in reference to\nCOVID-19. Our clustering algorithm identifies topics represented by groups of\nrelated terms, and computes clusters corresponding to documents associated with\nthe topic terms. Among the topics we observe several that persist through the\nduration of multiple weeks and have numerous associated documents, as well\nseveral that appear as emerging topics with fewer documents. All the tools and\ndata are publicly available, and this framework can be applied to any\nliterature collection. Taken together, these analyses produce a comprehensive,\nsynthesized view of COVID-19 research to facilitate knowledge discovery from\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:39:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:01:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yeganova", "Lana", ""], ["Islamaj", "Rezarta", ""], ["Chen", "Qingyu", ""], ["Leaman", "Robert", ""], ["Allot", "Alexis", ""], ["Wei", "Chin-Hsuan", ""], ["Comeau", "Donald C.", ""], ["Kim", "Won", ""], ["Peng", "Yifan", ""], ["Wilbur", "W. John", ""], ["Lu", "Zhiyong", ""]]}, {"id": "2008.03640", "submitter": "Feng Xia", "authors": "Jie Hou, Hanxiao Pan, Teng Guo, Ivan Lee, Xiangjie Kong, Feng Xia", "title": "Prediction Methods and Applications in the Science of Science: A Survey", "comments": "17 pages, 6 figures", "journal-ref": "Computer Science Review, Volume 34, November 2019, 100197", "doi": "10.1016/j.cosrev.2019.100197", "report-no": null, "categories": "cs.SI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Science of science has become a popular topic that attracts great attentions\nfrom the research community. The development of data analytics technologies and\nthe readily available scholarly data enable the exploration of data-driven\nprediction, which plays a pivotal role in finding the trend of scientific\nimpact. In this paper, we analyse methods and applications in data-driven\nprediction in the science of science, and discuss their significance. First, we\nintroduce the background and review the current state of the science of\nscience. Second, we review data-driven prediction based on paper citation\ncount, and investigate research issues in this area. Then, we discuss methods\nto predict scholar impact, and we analyse different approaches to promote the\nscholarly collaboration in the collaboration network. This paper also discusses\nopen issues and existing challenges, and suggests potential research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:42:43 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hou", "Jie", ""], ["Pan", "Hanxiao", ""], ["Guo", "Teng", ""], ["Lee", "Ivan", ""], ["Kong", "Xiangjie", ""], ["Xia", "Feng", ""]]}, {"id": "2008.03844", "submitter": "Xiaomei Bai", "authors": "Xiaomei Bai, Ivan Lee, Zhaolong Ning, Amr Tolba, Feng Xia", "title": "The Role of Positive and Negative Citations in Scientific Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the impact of scientific papers objectively is crucial for\nresearch output assessment, which subsequently affects institution and country\nrankings, research funding allocations, academic recruitment and\nnational/international scientific priorities. While most of the assessment\nschemes based on publication citations may potentially be manipulated through\nnegative citations, in this study, we explore Conflict of Interest (COI)\nrelationships and discover negative citations and subsequently weaken the\nassociated citation strength. PANDORA (Positive And Negative COI- Distinguished\nObjective Rank Algorithm) has been developed, which captures the positive and\nnegative COI, together with the positive and negative suspected COI\nrelationships. In order to alleviate the influence caused by negative COI\nrelationship, collaboration times, collaboration time span, citation times and\ncitation time span are employed to determine the citing strength; while for\npositive COI relationship, we regard it as normal citation relationship.\nFurthermore, we calculate the impact of scholarly papers by PageRank and HITS\nalgorithms, based on a credit allocation algorithm which is utilized to assess\nthe impact of institutions fairly and objectively. Experiments are conducted on\nthe publication dataset from American Physical Society (APS) dataset, and the\nresults demonstrate that our method significantly outperforms the current\nsolutions in Recommendation Intensity of list R at top-K and Spearman's rank\ncorrelation coefficient at top-K.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 00:23:53 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bai", "Xiaomei", ""], ["Lee", "Ivan", ""], ["Ning", "Zhaolong", ""], ["Tolba", "Amr", ""], ["Xia", "Feng", ""]]}, {"id": "2008.03857", "submitter": "Xiaomei Bai", "authors": "Xiaomei Bai, Fuli Zhang, Jie Hou, Ivan Lee, Xiangjie Kong, Amr Tolba,\n  Feng Xia", "title": "Quantifying the Impact of Scholarly Papers Based on Higher-Order\n  Weighted Citations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the impact of a scholarly paper is of great significance, yet the\neffect of geographical distance of cited papers has not been explored. In this\npaper, we examine 30,596 papers published in Physical Review C, and identify\nthe relationship between citations and geographical distances between author\naffiliations. Subsequently, a relative citation weight is applied to assess the\nimpact of a scholarly paper. A higher-order weighted quantum PageRank algorithm\nis also developed to address the behavior of multiple step citation flow.\nCapturing the citation dynamics with higher-order dependencies reveals the\nactual impact of papers, including necessary self-citations that are sometimes\nexcluded in prior studies. Quantum PageRank is utilized in this paper to help\ndifferentiating nodes whose PageRank values are identical.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 01:58:50 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bai", "Xiaomei", ""], ["Zhang", "Fuli", ""], ["Hou", "Jie", ""], ["Lee", "Ivan", ""], ["Kong", "Xiangjie", ""], ["Tolba", "Amr", ""], ["Xia", "Feng", ""]]}, {"id": "2008.03867", "submitter": "Xiaomei Bai", "authors": "Xiaomei Bai, Hui Liu, Fuli Zhang, Zhaolong Ning, Xiangjie Kong, Ivan\n  Lee and Feng Xia", "title": "An Overview on Evaluating and Predicting Scholarly Article Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scholarly article impact reflects the significance of academic output\nrecognised by academic peers, and it often plays a crucial role in assessing\nthe scientific achievements of researchers, teams, institutions and countries.\nIt is also used for addressing various needs in the academic and scientific\narena, such as recruitment decisions, promotions, and funding allocations. This\narticle provides a comprehensive review of recent progresses related to article\nimpact assessment and prediction. The~review starts by sharing some insight\ninto the article impact research and outlines current research status. Some\ncore methods and recent progress are presented to outline how article impact\nmetrics and prediction have evolved to consider integrating multiple networks.\nKey techniques, including statistical analysis, machine learning, data mining\nand network science, are discussed. In particular, we highlight important\napplications of each technique in article impact research. Subsequently, we\ndiscuss the open issues and challenges of article impact research. At the same\ntime, this review points out some important research directions, including\narticle impact evaluation by considering Conflict of Interest, time and\nlocation information, various distributions of scholarly entities, and rising\nstars.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 02:38:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bai", "Xiaomei", ""], ["Liu", "Hui", ""], ["Zhang", "Fuli", ""], ["Ning", "Zhaolong", ""], ["Kong", "Xiangjie", ""], ["Lee", "Ivan", ""], ["Xia", "Feng", ""]]}, {"id": "2008.04180", "submitter": "Niels Taubert", "authors": "Niels Taubert, Andre Bruns, Christopher Lenke, Graham Stone", "title": "Waiving Article Processing Charges for Least Developed Countries. A\n  Brick Stone of a Large-scale Open Access Transformation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article investigates the question, if it is economically feasible for a\nlarge publishing house to waive article processing charges for the group of 47\nso called least developed countries (LDC). As an example Springer-Nature is\nselected. The analysis is based on the Web of Science, OpenAPC and the Jisc\ncollections Springer compact journal list. As a result, it estimates an average\nyearly publication output of 520 publications (or a share of 0,26% of the\nworldwide publication output in Springer-Nature journals) for the LDC country\ngroup. The loss of revenues for Springer-Nature would be 1,1 million $ if a\nwaiver would be applied for all of these countries. Given that money is\nindispensable for development in the case of LDC (e.g. life expectancy, health,\neducation), it is not only desirable but also possible in economic terms for a\npublisher like Springer-Nature to waive APCs for these countries without much\nloss in revenues.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:04:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Taubert", "Niels", ""], ["Bruns", "Andre", ""], ["Lenke", "Christopher", ""], ["Stone", "Graham", ""]]}, {"id": "2008.04541", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2) and Nikitasha Kapoor (3) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft, and (3) Pure & Applied Group)", "title": "Comprehensiveness of Archives: A Modern AI-enabled Approach to Build\n  Comprehensive Shared Cultural Heritage", "comments": "Accepted for presentation at Datafication and Cultural Heritage\n  Workshop and Messy Ethnography Workshop at ECSCW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Archives play a crucial role in the construction and advancement of society.\nHumans place a great deal of trust in archives and depend on them to craft\npublic policies and to preserve languages, cultures, self-identity, views and\nvalues. Yet, there are certain voices and viewpoints that remain elusive in the\ncurrent processes deployed in the classification and discoverability of records\nand archives.\n  In this paper, we explore the ramifications and effects of centralized, due\nprocess archival systems on marginalized communities. There is strong evidence\nto prove the need for progressive design and technological innovation while in\nthe pursuit of comprehensiveness, equity and justice. Intentionality and\ncomprehensiveness is our greatest opportunity when it comes to improving\narchival practices and for the advancement and thrive-ability of societies at\nlarge today. Intentionality and comprehensiveness is achievable with the\nsupport of technology and the Information Age we live in today. Reopening,\nquestioning and/or purposefully including others voices in archival processes\nis the intention we present in our paper.\n  We provide examples of marginalized communities who continue to lead\n\"community archive\" movements in efforts to reclaim and protect their cultural\nidentity, knowledge, views and futures. In conclusion, we offer design and\nAI-dominant technological considerations worth further investigation in efforts\nto bridge systemic gaps and build robust archival processes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:35:23 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Kapoor", "Nikitasha", ""]]}, {"id": "2008.04595", "submitter": "Nestor Sanchez Dr.", "authors": "Nestor Sanchez (VIU, Spain)", "title": "The decline of astronomical research in Venezuela", "comments": "7 pages including 1 table and 2 figures. Comment published on Nature\n  Astronomy. This is the author version, the published version is available at\n  the Shareedit link https://rdcu.be/b6aWp", "journal-ref": "Nature Astronomy, vol. 4, pp. 724-726, 2020", "doi": "10.1038/s41550-020-1175-3", "report-no": null, "categories": "cs.DL astro-ph.IM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last 15 years the number of astronomy-related papers published by\nscientists in Venezuela has been continuously decreasing, mainly due to\nemigration. If rapid corrective actions are not implemented, Venezuelan\nastronomy could disappear.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:17:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Sanchez", "Nestor", "", "VIU, Spain"]]}, {"id": "2008.04647", "submitter": "Xiaomei Bai", "authors": "Xiaomei Bai, Fuli Zhang, Jin Ni, Lei Shi, Ivan Lee", "title": "Measure the Impact of Institution and Paper via Institution-citation\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the impact of institutes and papers over time based\non the heterogeneous institution-citation network. A new model, IPRank, is\nintroduced to measure the impact of institution and paper simultaneously. This\nmodel utilises the heterogeneous structural measure method to unveil the impact\nof institution and paper, reflecting the effects of citation, institution, and\nstructural measure. To evaluate the performance, the model first constructs a\nheterogeneous institution-citation network based on the American Physical\nSociety (APS) dataset. Subsequently, PageRank is used to quantify the impact of\ninstitution and paper. Finally, impacts of same institution are merged, and the\nranking of institutions and papers is calculated. Experimental results show\nthat the IPRank model better identifies universities that host Nobel Prize\nlaureates, demonstrating that the proposed technique well reflects impactful\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 04:13:20 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Bai", "Xiaomei", ""], ["Zhang", "Fuli", ""], ["Ni", "Jin", ""], ["Shi", "Lei", ""], ["Lee", "Ivan", ""]]}, {"id": "2008.04648", "submitter": "Xiaomei Bai", "authors": "Fuli Zhang, Xiaomei Bai, Ivan Lee", "title": "Author Impact: Evaluations, Predictions, and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Author impact evaluation and prediction play a key role in determining\nrewards, funding, and promotion. In this paper, we first introduce the\nbackground of author impact evaluation and prediction. Then, we review recent\ndevelopments of author impact evaluation, including data collection, data\npre-processing, data analysis, feature selection, algorithm design, and\nalgorithm evaluation. Thirdly, we provide an in-depth literature review on\nauthor impact predictive models and common evaluation metrics. Finally, we look\ninto the representative research issues, including author impact inflation,\nunified evaluation standards, academic success gene, identification of the\norigins of hot streaks, and higher-order academic networks analysis. This paper\nshould help the researchers obtain a broader understanding in author impact\nevaluation and prediction, and provides future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:33:00 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhang", "Fuli", ""], ["Bai", "Xiaomei", ""], ["Lee", "Ivan", ""]]}, {"id": "2008.04649", "submitter": "Xiaomei Bai", "authors": "Xiaomei Bai, Hanxiao Pan, Jie Hou, Teng Guo, Ivan Lee, Feng Xia", "title": "Quantifying Success in Science: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying success in science plays a key role in guiding funding\nallocations, recruitment decisions, and rewards. Recently, a significant amount\nof progresses have been made towards quantifying success in science. This lack\nof detailed analysis and summary continues a practical issue. The literature\nreports the factors influencing scholarly impact and evaluation methods and\nindices aimed at overcoming this crucial weakness. We focus on categorizing and\nreviewing the current development on evaluation indices of scholarly impact,\nincluding paper impact, scholar impact, and journal impact. Besides, we\nsummarize the issues of existing evaluation methods and indices, investigate\nthe open issues and challenges, and provide possible solutions, including the\npattern of collaboration impact, unified evaluation standards, implicit success\nfactor mining, dynamic academic network embedding, and scholarly impact\ninflation. This paper should help the researchers obtaining a broader\nunderstanding of quantifying success in science, and identifying some potential\nresearch directions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:49:07 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Bai", "Xiaomei", ""], ["Pan", "Hanxiao", ""], ["Hou", "Jie", ""], ["Guo", "Teng", ""], ["Lee", "Ivan", ""], ["Xia", "Feng", ""]]}, {"id": "2008.04652", "submitter": "Feng Xia", "authors": "Feng Xia, Haifeng Liu, Ivan Lee, Longbing Cao", "title": "Scientific Article Recommendation: Exploiting Common Author Relations\n  and Historical Preferences", "comments": "13 pages, 14 figures", "journal-ref": "IEEE Transactions on Big Data, Vol. 2, No. 2, June 2016, pp: 101 -\n  112", "doi": "10.1109/TBDATA.2016.2555318", "report-no": null, "categories": "cs.SI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific article recommender systems are playing an increasingly important\nrole for researchers in retrieving scientific articles of interest in the\ncoming era of big scholarly data. Most existing studies have designed unified\nmethods for all target researchers and hence the same algorithms are run to\ngenerate recommendations for all researchers no matter which situations they\nare in. However, different researchers may have their own features and there\nmight be corresponding methods for them resulting in better recommendations. In\nthis paper, we propose a novel recommendation method which incorporates\ninformation on common author relations between articles (i.e., two articles\nwith the same author(s)). The rationale underlying our method is that\nresearchers often search articles published by the same author(s). Since not\nall researchers have such author-based search patterns, we present two\nfeatures, which are defined based on information about pairwise articles with\ncommon author relations and frequently appeared authors, to determine target\nresearchers for recommendation. Extensive experiments we performed on a\nreal-world dataset demonstrate that the defined features are effective to\ndetermine relevant target researchers and the proposed method generates more\naccurate recommendations for relevant researchers when compared to a Baseline\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:44:25 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Xia", "Feng", ""], ["Liu", "Haifeng", ""], ["Lee", "Ivan", ""], ["Cao", "Longbing", ""]]}, {"id": "2008.04711", "submitter": "Sta\\v{s}a Milojevi\\'c", "authors": "Sta\\v{s}a Milojevi\\'c", "title": "Towards a more realistic citation model: The key role of research team\n  sizes", "comments": "Published in journal Entropy. Open access article available at\n  https://www.mdpi.com/journal/entropy", "journal-ref": "Entropy 2020, 22(8), 875", "doi": "10.3390/e22080875", "report-no": null, "categories": "cs.DL astro-ph.IM cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new citation model which builds on the existing models that\nexplicitly or implicitly include \"direct\" and \"indirect\" (learning about a\ncited paper's existence from references in another paper) citation mechanisms.\nOur model departs from the usual, unrealistic assumption of uniform probability\nof direct citation, in which initial differences in citation arise purely\nrandomly. Instead, we demonstrate that a two-mechanism model in which the\nprobability of direct citation is proportional to the number of authors on a\npaper (team size) is able to reproduce the empirical citation distributions of\narticles published in the field of astronomy remarkably well, and at different\npoints in time. Interpretation of our model is that the intrinsic citation\ncapacity, and hence the initial visibility of a paper, will be enhanced when\nmore people are intimately familiar with some work, favoring papers from larger\nteams. While the intrinsic citation capacity cannot depend only on the team\nsize, our model demonstrates that it must be to some degree correlated with it,\nand distributed in a similar way, i.e., having a power-law tail. Consequently,\nour team-size model qualitatively explains the existence of a correlation\nbetween the number of citations and the number of authors on a paper.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:13:29 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Milojevi\u0107", "Sta\u0161a", ""]]}, {"id": "2008.04721", "submitter": "Sta\\v{s}a Milojevi\\'c", "authors": "Sta\\v{s}a Milojevi\\'c", "title": "Nature, Science, and PNAS -- Disciplinary profiles and impact", "comments": "Published in Scientometrics\n  (https://link.springer.com/article/10.1007/s11192-020-03441-5)", "journal-ref": "Scientometrics 123, 1301-1315 (2020)", "doi": "10.1007/s11192-020-03441-5", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature, Science, and PNAS are the three most prestigious general-science\njournals, and Nature and Science are among the most influential journals\noverall, based on the journal Impact Factor (IF). In this paper we perform\nautomatic classification of ~50,000 articles in these journals (published in\nthe period 2005-2015) into 14 broad areas, to explore disciplinary profiles and\nto determine their field-specific IFs. We find that in all three journals the\narticles from Bioscience, Astronomy, and Geosciences are over-represented, with\nother areas being under-represented, some of them severely. Discipline-specific\nIFs in these journals vary greatly, for example, between 18 and 46 for Nature.\nWe find that the areas that have the highest disciplinary IFs are not the ones\nthat contribute the most articles. We also find that publishing articles in\nthese three journals brings prestige for articles in all areas, but at\ndifferent levels, the least being for Astronomy. Comparing field-specific IFs\nof Nature, Science and PNAS to other top journals in six largest areas\n(Bioscience, Medicine, Geosciences, Physics, Astronomy, and Chemistry) these\nthree journals are always among the top seven journals, with Nature being at\nthe very top for all fields except in Medicine.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:28:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Milojevi\u0107", "Sta\u0161a", ""]]}, {"id": "2008.05013", "submitter": "Xiaomei Bai", "authors": "Xiaomei Bai, Fuli Zhang, Ivan Lee", "title": "Predicting the Citations of Scholarly Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation prediction of scholarly papers is of great significance in guiding\nfunding allocations, recruitment decisions, and rewards. However, little is\nknown about how citation patterns evolve over time. By exploring the inherent\ninvolution property in scholarly paper citation, we introduce the Paper\nPotential Index (PPI) model based on four factors: inherent quality of\nscholarly paper, scholarly paper impact decaying over time, early citations,\nand early citers' impact. In addition, by analyzing factors that drive citation\ngrowth, we propose a multi-feature model for impact prediction. Experimental\nresults demonstrate that the two models improve the accuracy in predicting\nscholarly paper citations. Compared to the multi-feature model, the PPI model\nyields superior predictive performance in terms of range-normalized RMSE. The\nPPI model better interprets the changes in citation, without the need to adjust\nparameters. Compared to the PPI model, the multi-feature model performs better\nprediction in terms of Mean Absolute Percentage Error and Accuracy; however,\ntheir predictive performance is more dependent on the parameter adjustment.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:19:14 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Bai", "Xiaomei", ""], ["Zhang", "Fuli", ""], ["Lee", "Ivan", ""]]}, {"id": "2008.06008", "submitter": "Eleonora Dagiene", "authors": "Eleonora Dagiene", "title": "Prestige of scholarly book publishers: an investigation into criteria,\n  processes, and practices across countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerous national research assessment policies set the goal of promoting\n\"excellence\" and incentivise scholars to publish their research in the most\nprestigious journals or with the most prestigious book publishers. We\ninvestigate the practicalities of the assessment of book outputs based on the\nprestige of book publishers (Denmark, Finland, Flanders, Lithuania, Norway).\nAdditionally, we test whether such assessments are transparent and yield\nconsistent results. We show inconsistencies in the assessment of publishers,\nsuch as the same publisher being ranked as prestigious and not so prestigious\nin different countries or in different years in the same country. Likewise, we\nfind that verification of compliance with the mandatory prerequisites is not\nalways possible because of the lack of transparency. Our findings raise doubts\nabout whether the assessment of books based on a judgement about their\npublisher yields acceptable outcomes. Currently used rankings of publishers\nfocus on evaluating the gatekeeping role of publishers but do not assess their\ndissemination role. Our suggestion for future research is to develop approaches\nfor assessing books which consider both quality control and the distribution of\nbooks (and their metadata) as measured by the importance of communication\nbetween researchers. That means that publishers should be transparent about the\nservices they deliver in both areas, preferably at the level of individual\nbooks, so that there is no need to rely on general information about\npublishers.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:49:01 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Dagiene", "Eleonora", ""]]}, {"id": "2008.08355", "submitter": "Aliakbar Akbaritabar", "authors": "Aliakbar Akbaritabar", "title": "Berlin: A Quantitative View of the Structure of Institutional Scientific\n  Collaborations", "comments": "10 tables, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the structure of scientific collaborations in a large\nEuropean metropolitan area. It aims to identify strategic coalitions among\norganizations in Berlin as a specific case with high institutional and sectoral\ndiversity. By adopting a global, regional and organization based approach we\nprovide a quantitative, exploratory and macro view of this diversity. We use\npublications data with at least one organization located in Berlin from\n1996-2017. We further investigate four members of the Berlin University\nAlliance (BUA) through their self-represented research profiles comparing it\nwith empirical results of OECD disciplines. Using a bipartite network modeling\nframework, we are able to move beyond the uncontested trend towards team\nscience and increasing internationalization. Our results show that BUA members\nshape the structure of scientific collaborations in the region. However, they\nare not collaborating cohesively in all disciplines. Larger divides exist in\nsome disciplines e.g., Agricultural Sciences and Humanities. Only Medical and\nHealth Sciences have cohesive intraregional collaborations which signals the\nsuccess of regional cooperation established in 2003. We explain possible\nunderlying factors shaping the observed trends and sectoral and intra-regional\ngroupings. A major methodological contribution of this paper is evaluating\ncoverage and accuracy of different organization name disambiguation techniques.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:54:06 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Akbaritabar", "Aliakbar", ""]]}, {"id": "2008.08743", "submitter": "Jiaying Liu", "authors": "Jiaying Liu, Tao Tang, Xiangjie Kong, Amr Tolba, Zafer AL-Makhadmeh,\n  Feng Xia", "title": "Understanding the Advisor-advisee Relationship via Scholarly Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advisor-advisee relationship is important in academic networks due to its\nuniversality and necessity. Despite the increasing desire to analyze the career\nof newcomers, however, the outcomes of different collaboration patterns between\nadvisors and advisees remain unknown. The purpose of this paper is to find out\nthe correlation between advisors' academic characteristics and advisees'\nacademic performance in Computer Science. Employing both quantitative and\nqualitative analysis, we find that with the increase of advisors' academic age,\nadvisees' performance experiences an initial growth, follows a sustaining\nstage, and finally ends up with a declining trend. We also discover the\nphenomenon that accomplished advisors can bring up skilled advisees. We explore\nthe conclusion from two aspects: (1) Advisees mentored by advisors with high\nacademic level have better academic performance than the rest; (2) Advisors\nwith high academic level can raise their advisees' h-index ranking. This work\nprovides new insights on promoting our understanding of the relationship\nbetween advisors' academic characteristics and advisees' performance, as well\nas on advisor choosing.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:57:25 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Liu", "Jiaying", ""], ["Tang", "Tao", ""], ["Kong", "Xiangjie", ""], ["Tolba", "Amr", ""], ["AL-Makhadmeh", "Zafer", ""], ["Xia", "Feng", ""]]}, {"id": "2008.09011", "submitter": "Manlio De Domenico", "authors": "Andrea Mambrini, Andrea Baronchelli, Michele Starnini, Daniele\n  Marinazzo, Manlio De Domenico", "title": "PRINCIPIA: a Decentralized Peer-Review Ecosystem", "comments": "14 pages, 3 figures, comments and feedbacks welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is a cornerstone of modern scientific endeavor. However, there is\ngrowing consensus that several limitations of the current peer review system,\nfrom lack of incentives to reviewers to lack of transparency, risks to\nundermine its benefits. Here, we introduce the PRINCIPIA\n(http://www.principia.network/) framework for peer-review of scientific outputs\n(e.g., papers, grant proposals or patents). The framework allows key players of\nthe scientific ecosystem -- including existing publishing groups -- to create\nand manage peer-reviewed journals, by building a free market for reviews and\npublications. PRINCIPIA's referees are transparently rewarded according to\ntheir efforts and the quality of their reviews. PRINCIPIA also naturally allows\nto recognize the prestige of users and journals, with an intrinsic reputation\nsystem that does not depend on third-parties. PRINCIPIA re-balances the power\nbetween researchers and publishers, stimulates valuable assessments from\nreferees, favors a fair competition between journals, and reduces the costs to\naccess research output and to publish.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:59:04 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mambrini", "Andrea", ""], ["Baronchelli", "Andrea", ""], ["Starnini", "Michele", ""], ["Marinazzo", "Daniele", ""], ["De Domenico", "Manlio", ""]]}, {"id": "2008.11473", "submitter": "Cl\\'ementine Cottineau", "authors": "Cl\\'ementine Cottineau", "title": "MetaMetaZipf. What do analyses of city size distributions have in\n  common?", "comments": "18 pages (+8 in supplement), 3 tables (+2 in supplement) and 8\n  figures (+5 in supplement)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, I conduct a textual and contextual analysis of the empirical\nliterature on Zipf's law for cities. Building on previous meta-analysis\nmaterial openly available, I collect full texts and bibliographies of 66\nscientific articles published in English and construct similarity networks of\nthe terms they use as well as of the references and disciplines they cite. I\nuse these networks as explanatory variables in a model of the similarity\nnetwork of the distribution of Zipf estimates reported in the 66 articles. I\nfind that the proximity in words frequently used by authors correlates\npositively with their tendency to report similar values and dispersion of Zipf\nestimates. The reference framework of articles also plays a role, as articles\nwhich cite similar references tend to report similar average values of Zipf\nestimates. As a complement to previous meta-analyses, the present approach\nsheds light on the scientific text and context mobilized to report on city size\ndistributions. It allows to identified gaps in the corpus and potentially\noverlooked articles.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 10:18:37 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Cottineau", "Cl\u00e9mentine", ""]]}, {"id": "2008.11680", "submitter": "Michael Nelson", "authors": "Michael L. Nelson, Herbert Van de Sompel", "title": "A 25 Year Retrospective on D-Lib Magazine", "comments": "44 pages, 29 figures. Minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In July, 1995 the first issue of D-Lib Magazine was published as an on-line,\nHTML-only, open access magazine, serving as the focal point for the then\nemerging digital library research community. In 2017 it ceased publication, in\npart due to the maturity of the community it served as well as the increasing\navailability of and competition from eprints, institutional repositories,\nconferences, social media, and online journals -- the very ecosystem that D-Lib\nMagazine nurtured and enabled. As long-time members of the digital library\ncommunity and authors with the most contributions to D-Lib Magazine, we reflect\non the history of the digital library community and D-Lib Magazine, taking its\nvery first issue as guidance. It contained three articles, which described: the\nDublin Core Metadata Element Set, a project status report from the\nNSF/DARPA/NASA-funded Digital Library Initiative (DLI), and a summary of the\nKahn-Wilensky Framework (KWF) which gave us, among other things, Digital Object\nIdentifiers (DOIs). These technologies, as well as many more described in D-Lib\nMagazine through its 23 years, have had a profound and continuing impact on the\ndigital library and general web communities.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 14:53:00 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Nelson", "Michael L.", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "2008.11933", "submitter": "Mikael Laakso", "authors": "Mikael Laakso, Lisa Matthias, Najko Jahn", "title": "Open is not forever: a study of vanished open access journals", "comments": "14 pages, 5 tables, 5 figures, Published version", "journal-ref": null, "doi": "10.1002/ASI.24460", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The preservation of the scholarly record has been a point of concern since\nthe beginning of knowledge production. With print publications, the\nresponsibility rested primarily with librarians, but the shift toward digital\npublishing and, in particular, the introduction of open access (OA) have caused\nambiguity and complexity. Consequently, the long-term accessibility of journals\nis not always guaranteed, and they can even disappear from the web completely.\nThe focus of this exploratory study is on the phenomenon of vanished journals,\nsomething that has not been carried out before. For the analysis, we consulted\nseveral major bibliographic indexes, such as Scopus, Ulrichsweb, and the\nDirectory of Open Access Journals, and traced the journals through the Internet\nArchive's Wayback Machine. We found 174 OA journals that, through lack of\ncomprehensive and open archives, vanished from the web between 2000 and 2019,\nspanning all major research disciplines and geographic regions of the world.\nOur results raise vital concern for the integrity of the scholarly record and\nhighlight the urgency to take collaborative action to ensure continued access\nand prevent the loss of more scholarly knowledge. We encourage those interested\nin the phenomenon of vanished journals to use the public dataset for their own\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:24:29 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 08:18:06 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 15:41:06 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 18:10:28 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Laakso", "Mikael", ""], ["Matthias", "Lisa", ""], ["Jahn", "Najko", ""]]}, {"id": "2008.12007", "submitter": "Yi Bu", "authors": "Zaida Chinchilla-Rodr\\'iguez, Yi Bu, Nicol\\'as Robinson-Garc\\'ia,\n  Cassidy R. Sugimoto", "title": "An empirical review of the different variants of the Probabilistic\n  Affinity Index as applied to scientific collaboration", "comments": "35 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responsible indicators are crucial for research assessment and monitoring.\nTransparency and accuracy of indicators are required to make research\nassessment fair and ensure reproducibility. However, sometimes it is difficult\nto conduct or replicate studies based on indicators due to the lack of\ntransparency in conceptualization and operationalization. In this paper, we\nreview the different variants of the Probabilistic Affinity Index (PAI),\nconsidering both the conceptual and empirical underpinnings. We begin with a\nreview of the historical development of the indicator and the different\nalternatives proposed. To demonstrate the utility of the indicator, we\ndemonstrate the application of PAI to identifying preferred partners in\nscientific collaboration. A streamlined procedure is provided, to demonstrate\nthe variations and appropriate calculations. We then compare the results of\nimplementation for five specific countries involved in international scientific\ncollaboration. Despite the different proposals on its calculation, we do not\nobserve large differences between the PAI variants, particularly with respect\nto country size. As with any indicator, the selection of a particular variant\nis dependent on the research question. To facilitate appropriate use, we\nprovide recommendations for the use of the indicator given specific contexts.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:22:43 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chinchilla-Rodr\u00edguez", "Zaida", ""], ["Bu", "Yi", ""], ["Robinson-Garc\u00eda", "Nicol\u00e1s", ""], ["Sugimoto", "Cassidy R.", ""]]}, {"id": "2008.12742", "submitter": "Jose Manuel Gomez-Perez", "authors": "Ronald Denaux and Jose Manuel Gomez-Perez", "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "comments": "Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:55:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Denaux", "Ronald", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "2008.12828", "submitter": "Mike Merrill", "authors": "Ge Zhang, Mike A. Merrill, Yang Liu, Jeffrey Heer, Tim Althoff", "title": "CORAL: COde RepresentAtion Learning with Weakly-Supervised Transformers\n  for Analyzing Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale analysis of source code, and in particular scientific source\ncode, holds the promise of better understanding the data science process,\nidentifying analytical best practices, and providing insights to the builders\nof scientific toolkits. However, large corpora have remained unanalyzed in\ndepth, as descriptive labels are absent and require expert domain knowledge to\ngenerate. We propose a novel weakly supervised transformer-based architecture\nfor computing joint representations of code from both abstract syntax trees and\nsurrounding natural language comments. We then evaluate the model on a new\nclassification task for labeling computational notebook cells as stages in the\ndata analysis process from data import to wrangling, exploration, modeling, and\nevaluation. We show that our model, leveraging only easily-available weak\nsupervision, achieves a 38% increase in accuracy over expert-supplied\nheuristics and outperforms a suite of baselines. Our model enables us to\nexamine a set of 118,000 Jupyter Notebooks to uncover common data analysis\npatterns. Focusing on notebooks with relationships to academic articles, we\nconduct the largest ever study of scientific code and find that notebook\ncomposition correlates with the citation count of corresponding papers.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:57:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhang", "Ge", ""], ["Merrill", "Mike A.", ""], ["Liu", "Yang", ""], ["Heer", "Jeffrey", ""], ["Althoff", "Tim", ""]]}, {"id": "2008.13020", "submitter": "Saeed-Ul Hassan", "authors": "Sehrish Iqbal, Saeed-Ul Hassan, Naif Radi Aljohani, Salem Alelyani,\n  Raheel Nawaz and Lutz Bornmann", "title": "A Decade of In-text Citation Analysis based on Natural Language\n  Processing and Machine Learning Techniques: An overview of empirical studies", "comments": "59 pages, 4 figures, 8 tables (submitted to Scientometrics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation analysis is one of the most frequently used methods in research\nevaluation. We are seeing significant growth in citation analysis through\nbibliometric metadata, primarily due to the availability of citation databases\nsuch as the Web of Science, Scopus, Google Scholar, Microsoft Academic, and\nDimensions. Due to better access to full-text publication corpora in recent\nyears, information scientists have gone far beyond traditional bibliometrics by\ntapping into advancements in full-text data processing techniques to measure\nthe impact of scientific publications in contextual terms. This has led to\ntechnical developments in citation context and content analysis, citation\nclassifications, citation sentiment analysis, citation summarisation, and\ncitation-based recommendation. This article aims to narratively review the\nstudies on these developments. Its primary focus is on publications that have\nused natural language processing and machine learning techniques to analyse\ncitations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 17:27:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Iqbal", "Sehrish", ""], ["Hassan", "Saeed-Ul", ""], ["Aljohani", "Naif Radi", ""], ["Alelyani", "Salem", ""], ["Nawaz", "Raheel", ""], ["Bornmann", "Lutz", ""]]}, {"id": "2008.13099", "submitter": "Qingyun Sun", "authors": "Qingyun Sun, Hao Peng, Jianxin Li, Senzhang Wang, Xiangyu Dong,\n  Liangxuan Zhao, Philip S. Yu and Lifang He", "title": "Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous\n  Academic Networks", "comments": "accepted by ICDM 2020 as regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name disambiguation aims to identify unique authors with the same name.\nExisting name disambiguation methods always exploit author attributes to\nenhance disambiguation results. However, some discriminative author attributes\n(e.g., email and affiliation) may change because of graduation or job-hopping,\nwhich will result in the separation of the same author's papers in digital\nlibraries. Although these attributes may change, an author's co-authors and\nresearch topics do not change frequently with time, which means that papers\nwithin a period have similar text and relation information in the academic\nnetwork. Inspired by this idea, we introduce Multi-view Attention-based\nPairwise Recurrent Neural Network (MA-PairRNN) to solve the name disambiguation\nproblem. We divided papers into small blocks based on discriminative author\nattributes and blocks of the same author will be merged according to pairwise\nclassification results of MA-PairRNN. MA-PairRNN combines heterogeneous graph\nembedding learning and pairwise similarity learning into a framework. In\naddition to attribute and structure information, MA-PairRNN also exploits\nsemantic information by meta-path and generates node representation in an\ninductive way, which is scalable to large graphs. Furthermore, a semantic-level\nattention mechanism is adopted to fuse multiple meta-path based\nrepresentations. A Pseudo-Siamese network consisting of two RNNs takes two\npaper sequences in publication time order as input and outputs their\nsimilarity. Results on two real-world datasets demonstrate that our framework\nhas a significant and consistent improvement of performance on the name\ndisambiguation task. It was also demonstrated that MA-PairRNN can perform well\nwith a small amount of training data and have better generalization ability\nacross different research areas.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 06:08:20 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 03:50:21 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 14:22:45 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 12:31:45 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Sun", "Qingyun", ""], ["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Wang", "Senzhang", ""], ["Dong", "Xiangyu", ""], ["Zhao", "Liangxuan", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2008.13244", "submitter": "Jean-Marc Schlenker", "authors": "Jean-Marc Schlenker", "title": "The prestige and status of research fields within mathematics", "comments": "28 pages,many graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the ``hierarchy of science'' has been widely analysed, there is no\ncorresponding study of the status of subfields within a given scientific field.\nWe use bibliometric data to show that subfields of mathematics have a different\n``standing'' within the mathematics community. Highly ranked departments tend\nto specialize in some subfields more than in others, and the same subfields are\nalso over-represented in the most selective mathematics journals or among\nrecipients of top prizes. Moreover this status of subfields evolves markedly\nover the period of observation (1984--2016), with some subfields gaining and\nothers losing in standing. The status of subfields is related to different\npublishing habits, but some of those differences are opposite to those observed\nwhen considering the hierarchy of scientific fields.\n  We examine possible explanations for the ``status'' of different subfields.\nSome natural explanations -- availability of funding, importance of\napplications -- do not appear to function, suggesting that factors internal to\nthe discipline are at work. We propose a different type of explanation, based\non a notion of ``focus'' of a subfield, that might or might not be specific to\nmathematics.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 18:58:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Schlenker", "Jean-Marc", ""]]}, {"id": "2008.13542", "submitter": "Maksim Eren", "authors": "Maksim Ekin Eren, Nick Solovyev, Edward Raff, Charles Nicholas, Ben\n  Johnson", "title": "COVID-19 Kaggle Literature Organization", "comments": "Maksim Ekin Eren, Nick Solovyev, Edward Raff, Charles Nicholas, and\n  Ben Johnson. 2020. COVID-19 Kaggle Literature Organization. In ACM Sym-posium\n  on Document Engineering 2020 (DocEng 20), September 29-October2, 2020,\n  Virtual Event, CA, USA.ACM, New York, NY, USA, 4 pages.\n  https://doi.org/10.1145/3395027.3419591", "journal-ref": null, "doi": "10.1145/3395027.3419591", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has faced the devastating outbreak of Severe Acute Respiratory\nSyndrome Coronavirus-2 (SARS-CoV-2), or COVID-19, in 2020. Research in the\nsubject matter was fast-tracked to such a point that scientists were struggling\nto keep up with new findings. With this increase in the scientific literature,\nthere arose a need for organizing those documents. We describe an approach to\norganize and visualize the scientific literature on or related to COVID-19\nusing machine learning techniques so that papers on similar topics are grouped\ntogether. By doing so, the navigation of topics and related papers is\nsimplified. We implemented this approach using the widely recognized CORD-19\ndataset to present a publicly available proof of concept.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:02:32 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 14:09:43 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 03:54:34 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Eren", "Maksim Ekin", ""], ["Solovyev", "Nick", ""], ["Raff", "Edward", ""], ["Nicholas", "Charles", ""], ["Johnson", "Ben", ""]]}]