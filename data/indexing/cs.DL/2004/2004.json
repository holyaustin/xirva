[{"id": "2004.00199", "submitter": "Hideaki Hata", "authors": "Supatsara Wattanakriengkrai, Bodin Chinthanet, Hideaki Hata, Raula\n  Gaikovina Kula, Christoph Treude, Jin Guo, Kenichi Matsumoto", "title": "GitHub Repositories with Links to Academic Papers: Open Access,\n  Traceability, and Evolution", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traceability between published scientific breakthroughs and their\nimplementation is essential, especially in the case of Open Source Software\nimplements bleeding edge science into its code. However, aligning the link\nbetween GitHub repositories and academic papers can prove difficult, and the\nlink impact remains unknown. This paper investigates the role of academic paper\nreferences contained in these repositories. We conducted a large-scale study of\n20 thousand GitHub repositories to establish prevalence of references to\nacademic papers. We use a mixed-methods approach to identify Open Access (OA),\ntraceability and evolutionary aspects of the links. Although referencing a\npaper is not typical, we find that a vast majority of referenced academic\npapers are OA. In terms of traceability, our analysis revealed that machine\nlearning is the most prevalent topic of repositories. These repositories tend\nto be affiliated with academic communities. More than half of the papers do not\nlink back to any repository. A case study of referenced arXiv paper shows that\nmost of these papers are high-impact and influential and do align with\nacademia, referenced by repositories written in different programming\nlanguages. From the evolutionary aspect, we find very few changes of papers\nbeing referenced and links to them.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:14:15 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 01:09:19 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Wattanakriengkrai", "Supatsara", ""], ["Chinthanet", "Bodin", ""], ["Hata", "Hideaki", ""], ["Kula", "Raula Gaikovina", ""], ["Treude", "Christoph", ""], ["Guo", "Jin", ""], ["Matsumoto", "Kenichi", ""]]}, {"id": "2004.00514", "submitter": "Roberto Di Cosmo", "authors": "Roberto Di Cosmo (IRIF)", "title": "Archiving and referencing source code with Software Heritage", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.10760", "journal-ref": null, "doi": "10.1007/978-3-030-52200-1_36", "report-no": null, "categories": "cs.DL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software, and software source code in particular, is widely used in modern\nresearch. It must be properly archived, referenced, described and cited in\norder to build a stable and long lasting corpus of scientic knowledge. In this\narticle we show how the Software Heritage universal source code archive\nprovides a means to fully address the first two concerns, by archiving\nseamlessly all publicly available software source code, and by providing\nintrinsic persistent identifiers that allow to reference it at various\ngranularities in a way that is at the same time convenient and effective. We\ncall upon the research community to adopt widely this approach.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:48:58 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Di Cosmo", "Roberto", "", "IRIF"]]}, {"id": "2004.00520", "submitter": "Maryam Zamani Dr", "authors": "Maryam Zamani, Alejandro Tejedor, Malte Vogl, Florian Krautli, Matteo\n  Valleriani, and Holger Kantz", "title": "Evolution and Transformation of Scientific Knowledge over the Sphaera\n  Corpus: A Network Study", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.hist-ph cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the evolution and transformation of scientific knowledge in\nthe early modern period, analyzing more than 350 different editions of\ntextbooks used for teaching astronomy in European universities from the late\nfifteenth century to mid-seventeenth century. These historical sources\nconstitute the Sphaera Corpus. By examining different semantic relations among\nindividual parts of each edition on record, we built a multiplex network\nconsisting of six layers, as well as the aggregated network built from the\nsuperposition of all the layers. The network analysis reveals the emergence of\nfive different communities. The contribution of each layer in shaping the\ncommunities and the properties of each community are studied. The most\ninfluential books in the corpus are found by calculating the average age of all\nthe out-going and in-coming links for each book. A small group of editions is\nidentified as a transmitter of knowledge as they bridge past knowledge to the\nfuture through a long temporal interval. Our analysis, moreover, identifies the\nmost disruptive books. These books introduce new knowledge that is then adopted\nby almost all the books published afterwards until the end of the whole period\nof study. The historical research on the content of the identified books, as an\nempirical test, finally corroborates the results of all our analyses.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:44:39 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zamani", "Maryam", ""], ["Tejedor", "Alejandro", ""], ["Vogl", "Malte", ""], ["Krautli", "Florian", ""], ["Valleriani", "Matteo", ""], ["Kantz", "Holger", ""]]}, {"id": "2004.01291", "submitter": "Christopher Manning", "authors": "Daniel Ramage, Christopher D. Manning and Daniel A. McFarland", "title": "Mapping Three Decades of Intellectual Change in Academia", "comments": "10 pages and 6 figures plus appendix of 5 pages and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on the development of science has focused on the creation of\nmultidisciplinary teams. However, while this coming together of people is\nsymmetrical, the ideas, methods, and vocabulary of science have a directional\nflow. We present a statistical model of the text of dissertation abstracts from\n1980 to 2010, revealing for the first time the large-scale flow of language\nacross fields. Results of the analysis include identifying methodological\nfields that export broadly, emerging topical fields that borrow heavily and\nexpand, and old topical fields that grow insular and retract. Particular\nfindings show a growing split between molecular and ecological forms of biology\nand a sea change in the humanities and social sciences driven by the rise of\ngender and ethnic studies.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 22:34:36 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 17:15:53 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Ramage", "Daniel", ""], ["Manning", "Christopher D.", ""], ["McFarland", "Daniel A.", ""]]}, {"id": "2004.01449", "submitter": "Wenceslao Arroyo-Machado", "authors": "Daniel Torres-Salinas, Wenceslao Arroyo-Machado, Nicol\\'as\n  Robinson-Garc\\'ia", "title": "An alternative analysis on the scientific output of Spanish Sociology\n  What can altmetrics tell us?", "comments": "in Spanish, Cap\\'itulo aceptado para su publicaci\\'on en una\n  monograf\\'ia de la editorial CIS-Centro de Investigaci\\'on Sociol\\'ogicas", "journal-ref": null, "doi": "10.5281/zenodo.3739011", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, new indicators known as altmetrics have been introduced to\nmeasure the impact of scientific activity. These indicators are obtained\nthrough the mentions realised from different social media, existing several\naggregators of these data that collect several of them in the same database,\nbeing Altmetric.com the most popular. However, in spite of the popularization\nof these metrics, several limitations in their use have been manifested. For\nthis reason, rhe objective of this work is twofold: (1) to show the\npossibilities of altimetric techniques applied to the Spanish social sciences\nin general and sociology in particular; (2) to critically analyse the results\nto observe the limitations of these indicators; (3) to check whether they can\nreally add useful information that can be used to describe a scientific field\nand (4) to see the reasons why altmetrics cannot be applied in these fields.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 09:43:48 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Torres-Salinas", "Daniel", ""], ["Arroyo-Machado", "Wenceslao", ""], ["Robinson-Garc\u00eda", "Nicol\u00e1s", ""]]}, {"id": "2004.01791", "submitter": "Jingyuan Yu", "authors": "Jingyuan Yu", "title": "Open access institutional and news media tweet dataset for COVID-19\n  social science research", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As COVID-19 quickly became one of the most concerned global crisis, the\ndemand for data in academic research is also increasing. Currently, there are\nseveral open access Twitter datasets, but none of them is dedicated to the\ninstitutional and news media Twitter data collection, to fill this blank, we\nretrieved data from 69 institutional/news media Twitter accounts, 17 of them\nwere related to government and international organizations, 52 of them were\nnews media across North America, Europe and Asia. We believe our open access\ndata can provide researchers more availability to conduct social science\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 21:57:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yu", "Jingyuan", ""]]}, {"id": "2004.02085", "submitter": "Sabber Ahamed", "authors": "Sabber Ahamed and Manar Samad", "title": "Information Mining for COVID-19 Research From a Large Volume of\n  Scientific Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The year 2020 has seen an unprecedented COVID-19 pandemic due to the outbreak\nof a novel strain of coronavirus in 180 countries. In a desperate effort to\ndiscover new drugs and vaccines for COVID-19, many scientists are working\naround the clock. Their valuable time and effort may benefit from\ncomputer-based mining of a large volume of health science literature that is a\ntreasure trove of information. In this paper, we have developed a graph-based\nmodel using abstracts of 10,683 scientific articles to find key information on\nthree topics: transmission, drug types, and genome research related to\ncoronavirus. A subgraph is built for each of the three topics to extract more\ntopic-focused information. Within each subgraph, we use a betweenness\ncentrality measurement to rank order the importance of keywords related to\ndrugs, diseases, pathogens, hosts of pathogens, and biomolecules. The results\nreveal intriguing information about antiviral drugs (Chloroquine, Amantadine,\nDexamethasone), pathogen-hosts (pigs, bats, macaque, cynomolgus), viral\npathogens (zika, dengue, malaria, and several viruses in the coronaviridae\nvirus family), and proteins and therapeutic mechanisms (oligonucleotide,\ninterferon, glycoprotein) in connection with the core topic of coronavirus. The\ncategorical summary of these keywords and topics may be a useful reference to\nexpedite and recommend new and alternative directions for COVID-19 research.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 03:51:40 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ahamed", "Sabber", ""], ["Samad", "Manar", ""]]}, {"id": "2004.02793", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Saheeda Thelwall", "title": "A thematic analysis of highly retweeted early COVID -19 tweets:\n  Consensus, information, dissent, and lockdown life", "comments": null, "journal-ref": null, "doi": "10.1108/AJIM-05-2020-0134", "report-no": null, "categories": "cs.DL cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Public attitudes towards COVID-19 and social distancing are critical\nin reducing its spread. It is therefore important to understand public\nreactions and information dissemination in all major forms, including on social\nmedia. This article investigates important issues reflected on Twitter in the\nearly stages of the public reaction to COVID-19. Design/methodology/approach: A\nthematic analysis of the most retweeted English-language tweets mentioning\nCOVID-19 during March 10-29, 2020. Findings: The main themes identified for the\n87 qualifying tweets accounting for 14 million retweets were: lockdown life;\nattitude towards social restrictions; politics; safety messages; people with\nCOVID-19; support for key workers; work; and COVID-19 facts/news. Research\nlimitations/implications: Twitter played many positive roles, mainly through\nunofficial tweets. Users shared social distancing information, helped build\nsupport for social distancing, criticised government responses, expressed\nsupport for key workers, and helped each other cope with social isolation. A\nfew popular tweets not supporting social distancing show that government\nmessages sometimes failed. Practical implications: Public health campaigns in\nfuture may consider encouraging grass roots social web activity to support\ncampaign goals. At a methodological level, analysing retweet counts emphasised\npolitics and ignored practical implementation issues. Originality/value: This\nis the first qualitative analysis of general COVID-19-related retweeting.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:34:23 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 11:13:13 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 15:33:34 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Thelwall", "Mike", ""], ["Thelwall", "Saheeda", ""]]}, {"id": "2004.02845", "submitter": "Marieke Van Erp", "authors": "Albert Mero\\~no-Pe\\~nuela, Victor de Boer, Marieke van Erp, Richard\n  Zijdeman, Rick Mourits, Willem Melder, Auke Rijpma, Ruben Schalk", "title": "Ontologies in CLARIAH: Towards Interoperability in History, Language and\n  Media", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important goals of digital humanities is to provide\nresearchers with data and tools for new research questions, either by\nincreasing the scale of scholarly studies, linking existing databases, or\nimproving the accessibility of data. Here, the FAIR principles provide a useful\nframework as these state that data needs to be: Findable, as they are often\nscattered among various sources; Accessible, since some might be offline or\nbehind paywalls; Interoperable, thus using standard knowledge representation\nformats and shared vocabularies; and Reusable, through adequate licensing and\npermissions. Integrating data from diverse humanities domains is not trivial,\nresearch questions such as \"was economic wealth equally distributed in the 18th\ncentury?\", or \"what are narratives constructed around disruptive media\nevents?\") and preparation phases (e.g. data collection, knowledge organisation,\ncleaning) of scholars need to be taken into account. In this chapter, we\ndescribe the ontologies and tools developed and integrated in the Dutch\nnational project CLARIAH to address these issues across datasets from three\nfundamental domains or \"pillars\" of the humanities (linguistics, social and\neconomic history, and media studies) that have paradigmatic data\nrepresentations (textual corpora, structured data, and multimedia). We\nsummarise the lessons learnt from using such ontologies and tools in these\ndomains from a generalisation and reusability perspective.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:38:47 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 15:34:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Mero\u00f1o-Pe\u00f1uela", "Albert", ""], ["de Boer", "Victor", ""], ["van Erp", "Marieke", ""], ["Zijdeman", "Richard", ""], ["Mourits", "Rick", ""], ["Melder", "Willem", ""], ["Rijpma", "Auke", ""], ["Schalk", "Ruben", ""]]}, {"id": "2004.03011", "submitter": "Martin Klein", "authors": "Martin Klein and Lyudmila Balakireva", "title": "On the Persistence of Persistent Identifiers of the Scholarly Web", "comments": "14 pages, 4 Figures (10 total), 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scholarly resources, just like any other resources on the web, are subject to\nreference rot as they frequently disappear or significantly change over time.\nDigital Object Identifiers (DOIs) are commonplace to persistently identify\nscholarly resources and have become the de facto standard for citing them. We\ninvestigate the notion of persistence of DOIs by analyzing their resolution on\nthe web. We derive confidence in the persistence of these identifiers in part\nfrom the assumption that dereferencing a DOI will consistently return the same\nresponse, regardless of which HTTP request method we use or from which network\nenvironment we send the requests. Our experiments show, however, that\npersistence, according to our interpretation, is not warranted. We find that\nscholarly content providers respond differently to varying request methods and\nnetwork environments and even change their response to requests against the\nsame DOI. In this paper we present the results of our quantitative analysis\nthat is aimed at informing the scholarly communication community about this\ndisconcerting lack of consistency.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 21:48:37 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Klein", "Martin", ""], ["Balakireva", "Lyudmila", ""]]}, {"id": "2004.03807", "submitter": "Abhinav Ramesh Kashyap", "authors": "Abhinav Ramesh Kashyap, Min-Yen Kan", "title": "SciWING -- A Software Toolkit for Scientific Document Processing", "comments": "6 pages, 3 figures, First Workshop on Scholarly Document Processing -\n  SDP@EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SciWING, an open-source software toolkit which provides access\nto pre-trained models for scientific document processing tasks, inclusive of\ncitation string parsing and logical structure recovery. SciWING enables\nresearchers to rapidly experiment with different models by swapping and\nstacking different modules. It also enables them declare and run models from a\nconfiguration file. It enables researchers to perform production-ready transfer\nlearning from general, pre-trained transformers (i.e., BERT, SciBERT etc), and\naids development of end-user applications. It includes ready-to-use web and\nterminal-based applications and demonstrations (Available from\nhttp://sciwing.io).\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 04:43:37 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 07:27:01 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kashyap", "Abhinav Ramesh", ""], ["Kan", "Min-Yen", ""]]}, {"id": "2004.05125", "submitter": "Jimmy Lin", "authors": "Edwin Zhang, Nikhil Gupta, Rodrigo Nogueira, Kyunghyun Cho, and Jimmy\n  Lin", "title": "Rapidly Deploying a Neural Search Engine for the COVID-19 Open Research\n  Dataset: Preliminary Thoughts and Lessons Learned", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Neural Covidex, a search engine that exploits the latest\nneural ranking architectures to provide information access to the COVID-19 Open\nResearch Dataset curated by the Allen Institute for AI. This web application\nexists as part of a suite of tools that we have developed over the past few\nweeks to help domain experts tackle the ongoing global pandemic. We hope that\nimproved information access capabilities to the scientific literature can\ninform evidence-based decision making and insight generation. This paper\ndescribes our initial efforts and offers a few thoughts about lessons we have\nlearned along the way.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:12:29 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Zhang", "Edwin", ""], ["Gupta", "Nikhil", ""], ["Nogueira", "Rodrigo", ""], ["Cho", "Kyunghyun", ""], ["Lin", "Jimmy", ""]]}, {"id": "2004.05535", "submitter": "Xuejia Sang", "authors": "Xuejia Sang, Linfu Xue, Xiaopeng Leng, Xiaoshun Li and Jianping Zhou", "title": "Using Photo Modeling Based 3DGRSL to Promote the Sustainability of\n  Geo-Education, a case study from China", "comments": "13 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In earth science education, observation of field geological phenomena is very\nimportant. Due to China's huge student population, it is difficult to guarantee\neducation fairness and teaching quality in field teaching. Specimens are\nindispensable geo-education resources. However, the specimen cabinet or picture\nspecimen library has many limitations and it is difficult to meet the\ninternet-spirit or geo-teaching needs. Based on photo modeling, this research\nbuilds a 3D Geo-Resource Sharing Library (3DGRSL) for Geo-Education. It uses\nthe Cesium engine and data-oriented distributed architecture to provide the\neducational resources to many universities. With Browser/Server (B/S)\narchitecture, the system can realize multi-terminal and multi-scenario access\nof mobile phones, tablets, VR, PC, indoor, outdoor, field, providing a flexible\nand convenient way for preserving and sharing scientific information about\ngeo-resources. This makes sense to students who cannot accept field teaching in\nunder-funded colleges, and the ones with mobility problems. Tests and scoring\nresults show that 3DGRSL is a suitable solution for displaying and sharing\ngeological specimens. Which is of great significance for the sustainable use\nand protection of geoscience teaching resources, the maintenance of the right\nto fair education, and the construction of virtual simulation solutions in the\nfuture.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 03:22:48 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sang", "Xuejia", ""], ["Xue", "Linfu", ""], ["Leng", "Xiaopeng", ""], ["Li", "Xiaoshun", ""], ["Zhou", "Jianping", ""]]}, {"id": "2004.05751", "submitter": "Bahram Kalhor", "authors": "Bahram Kalhor, Mohammad Reza Ghane, Alireza Nikravanshalmani", "title": "Approximating percentage of academic traffic in the World Wide Web and\n  rankings of countries based on academic traffic", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a novel mechanism for approximating traffic of the\nacademic sites (universities and research institutes) in the World Wide Web\nbased on Alexa rankings. Firstly we introduce and discuss new method for\ncalculating score (weight) of each site based on its Alexa rank. Secondly we\ncalculate percentage of academic traffic in the World Wide Web. Thirdly we\nintroduce and discuss two new rankings of countries based on academic traffic.\nFinally we discuss about three indicators and effects of them in traffic of the\nacademic sites. Results indicate that the methodology can be useful for\napproximating traffic of the academic sites and producing rankings of countries\nin practice\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 03:11:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Kalhor", "Bahram", ""], ["Ghane", "Mohammad Reza", ""], ["Nikravanshalmani", "Alireza", ""]]}, {"id": "2004.05876", "submitter": "Fernando Almeida Dr.", "authors": "Fernando Almeida", "title": "Bibliometric Analysis of Agile Software Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agile methodologies are currently considered one of the main paradigms of\nsoftware development. Its study, from a scientific point of view, has deserved\nprominence in recent years by the scientific community related to the area of\nsoftware engineering. This study intends to perform a bibliometric analysis of\nthe quantity, characteristics and scope of the most relevant studies published\nin this area of knowledge. The findings indicate that the number of studies\npublished from 2010 to 2016 significantly increased, having reached a peak in\n2015. The study identifies the main journals and conferences in the field and\nwe also concluded that the majority of published studies are literature reviews\nof agile software development, and qualitative and quantitative research\nmethods have identical number of publications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 11:39:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Almeida", "Fernando", ""]]}, {"id": "2004.05904", "submitter": "Jinhyuk Yun", "authors": "Jinhyuk Yun, Sejung Ahn, June Young Lee", "title": "Return to basics: Clustering of scientific literature using structural\n  information", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scholars frequently employ relatedness measures to estimate the similarity\nbetween two different items (e.g., documents, authors, and institutes). Such\nrelatedness measures are commonly based on overlapping references\n($\\textit{i.e.}$, bibliographic coupling) or citations ($\\textit{i.e.}$,\nco-citation) and can then be used with cluster analysis to find boundaries\nbetween research fields. Unfortunately, calculating a relatedness measure is\nchallenging, especially for a large number of items, because the computational\ncomplexity is greater than linear. We propose an alternative method for\nidentifying the research front that uses direct citation inspired by\nrelatedness measures. Our novel approach simply replicates a node into two\ndistinct nodes: a citing node and cited node. We then apply typical clustering\nmethods to the modified network. Clusters of citing nodes should emulate those\nfrom the bibliographic coupling relatedness network, while clusters of cited\nnodes should act like those from the co-citation relatedness network. In\nvalidation tests, our proposed method demonstrated high levels of similarity\nwith conventional relatedness-based methods. We also found that the clustering\nresults of proposed method outperformed those of conventional relatedness-based\nmeasures regarding similarity with natural language processing--based\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 13:39:39 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Yun", "Jinhyuk", ""], ["Ahn", "Sejung", ""], ["Lee", "June Young", ""]]}, {"id": "2004.05976", "submitter": "Brendan Hoover", "authors": "Brendan Hoover, Gil Bohrer, Jerod Merkle, Jennifer A. Miller", "title": "A Digital Ecosystem for Animal Movement Science: Making animal movement\n  datasets, data-linkage techniques, methods, and environmental layers easier\n  to find, interpret, and analyze", "comments": "Permission was not granted by the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Movement is a fundamental aspect of animal life and plays a crucial role in\ndetermining the structure of population dynamics, communities, ecosystems, and\ndiversity. In recent years, the recording of animal movements via GPS collars,\ncamera traps, acoustic sensors, and citizen science, along with the abundance\nof environmental and other ancillary data used by researchers to contextualize\nthose movements, has reached a level of volume, velocity, and variety that puts\nmovement ecology research in the realm of big data science. That data growth\nhas spawned increasingly complex methods for movement analysis. Consequently,\nanimal ecologists need a greater understanding of technical skills such as\nstatistics, geographic information systems (GIS), remote sensing, and coding.\nTherefore, collaboration has become increasingly crucial, as research requires\nboth domain knowledge and technical expertise. Datasets of animal movement and\nenvironmental data are typically available in repositories run by government\nagencies, universities, and non-governmental organizations (NGOs) with methods\ndescribed in scientific journals. However, there is little connectivity between\nthese entities. The construction of a digital ecosystem for animal movement\nscience is critically important right now. The digital ecosystem represents a\nsetting where movement data, environmental layers, and analysis methods are\ndiscoverable and available for efficient storage, manipulation, and analysis.\nWe argue that such a system which will help mature the field of movement\necology by engendering collaboration, facilitating replication, expanding the\nspatiotemporal range of potential analyses, and limiting redundancy in method\ndevelopment. We describe the key components of the digital ecosystem, the\ncritical challenges that would need addressing, as well as potential solutions\nto those challenges.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 14:52:06 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 22:11:39 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hoover", "Brendan", ""], ["Bohrer", "Gil", ""], ["Merkle", "Jerod", ""], ["Miller", "Jennifer A.", ""]]}, {"id": "2004.06153", "submitter": "Ming Jiang", "authors": "Ming Jiang, Jennifer D'Souza, S\\\"oren Auer, J. Stephen Downie", "title": "Improving Scholarly Knowledge Representation: Evaluating BERT-based\n  Models for Scientific Relation Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of research publications, there is a vast amount of\nscholarly knowledge that needs to be organized in digital libraries. To deal\nwith this challenge, techniques relying on knowledge-graph structures are being\nadvocated. Within such graph-based pipelines, inferring relation types between\nrelated scientific concepts is a crucial step. Recently, advanced techniques\nrelying on language models pre-trained on the large corpus have been popularly\nexplored for automatic relation classification. Despite remarkable\ncontributions that have been made, many of these methods were evaluated under\ndifferent scenarios, which limits their comparability. To this end, we present\na thorough empirical evaluation on eight Bert-based classification models by\nfocusing on two key factors: 1) Bert model variants, and 2) classification\nstrategies. Experiments on three corpora show that domain-specific pre-training\ncorpus benefits the Bert-based classification model to identify the type of\nscientific relations. Although the strategy of predicting a single relation\neach time achieves a higher classification accuracy than the strategy of\nidentifying multiple relation types simultaneously in general, the latter\nstrategy demonstrates a more consistent performance in the corpus with either a\nlarge or small size of annotations. Our study aims to offer recommendations to\nthe stakeholders of digital libraries for selecting the appropriate technique\nto build knowledge-graph-based systems for enhanced scholarly information\norganization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:46:55 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 14:30:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jiang", "Ming", ""], ["D'Souza", "Jennifer", ""], ["Auer", "S\u00f6ren", ""], ["Downie", "J. Stephen", ""]]}, {"id": "2004.06179", "submitter": "Andrea Giovanni Nuzzolese", "authors": "Erik Boetto and Maria Pia Fantini and Aldo Gangemi and Davide\n  Golinelli and Manfredi Greco and Andrea Giovanni Nuzzolese and Valentina\n  Presutti and Flavia Rallo", "title": "Using altmetrics for detecting impactful research in quasi-zero-day\n  time-windows: the case of COVID-19", "comments": "21 pages, 12 figures, 4 tables", "journal-ref": null, "doi": "10.1007/s11192-020-03809-7", "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On December 31st 2019, the World Health Organization (WHO) China Country\nOffice was informed of cases of pneumonia of unknown etiology detected in Wuhan\nCity. The cause of the syndrome was a new type of coronavirus isolated on\nJanuary 7th 2020 and named Severe Acute Respiratory Syndrome CoronaVirus 2\n(SARS-CoV-2). SARS-CoV-2 is the cause of the coronavirus disease 2019\n(COVID-19). Since January 2020 an ever increasing number of scientific works\nhave appeared in literature. Identifying relevant research outcomes at very\nearly stages is challenging. In this work we use COVID-19 as a use-case for\ninvestigating: (i) which tools and frameworks are mostly used for early\nscholarly communication; (ii) to what extent altmetrics can be used to identify\npotential impactful research in tight (i.e. quasi-zero-day) time-windows. A\nliterature review with rigorous eligibility criteria is performed for gathering\na sample composed of scientific papers about SARS-CoV-2/COVID-19 appeared in\nliterature in the tight time-window ranging from January 15th 2020 to February\n24th 2020. This sample is used for building a knowledge graph that represents\nthe knowledge about papers and indicators formally. This knowledge graph feeds\na data analysis process which is applied for experimenting with altmetrics as\nimpact indicators. We find moderate correlation among traditional citation\ncount, citations on social media, and mentions on news and blogs. This suggests\nthere is a common intended meaning of the citational acts associated with\naforementioned indicators. Additionally, we define a method that harmonises\ndifferent indicators for providing a multi-dimensional impact indicator.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 20:04:41 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 16:39:39 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 19:40:35 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Boetto", "Erik", ""], ["Fantini", "Maria Pia", ""], ["Gangemi", "Aldo", ""], ["Golinelli", "Davide", ""], ["Greco", "Manfredi", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""], ["Rallo", "Flavia", ""]]}, {"id": "2004.06539", "submitter": "Samin Aref", "authors": "Andrea Miranda-Gonz\\'alez, Samin Aref, Tom Theile, and Emilio Zagheni", "title": "Scholarly migration within Mexico: Analyzing internal migration among\n  researchers using Scopus longitudinal bibliometric data", "comments": "Peer-reviewed author copy, 28 pages, 11 figures", "journal-ref": null, "doi": "10.1140/epjds/s13688-020-00252-9", "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The migration of scholars is a major driver of innovation and of diffusion of\nknowledge. Although large-scale bibliometric data have been used to measure\ninternational migration of scholars, our understanding of internal migration\namong researchers is very limited. This is partly due to a lack of data\naggregated at a suitable sub-national level. In this study, we analyze internal\nmigration in Mexico based on over 1.1 million authorship records from the\nScopus database. We trace the movements of scholars between Mexican states, and\nprovide key demographic measures of internal migration for the 1996-2018\nperiod. From a methodological perspective, we develop a new framework for\nenhancing data quality, inferring states from affiliations, and detecting moves\nfrom modal states for the purposes of studying internal migration among\nresearchers. Substantively, we combine demographic and network science\ntechniques to improve our understanding of internal migration patterns within\ncountry boundaries. The migration patterns between states in Mexico appear to\nbe heterogeneous in size and direction across regions. However, while many\nscholars remain in their regions, there seems to be a preference for Mexico\nCity and the surrounding states as migration destinations. We observed that\nover the past two decades, there has been a general decreasing trend in the\ncrude migration intensity. However, the migration network has become more dense\nand more diverse, and has included greater exchanges between states along the\nGulf and the Pacific Coast. Our analysis, which is mostly empirical in nature,\nlays the foundations for testing and developing theories that can rely on the\nanalytical framework developed by migration scholars, and the richness of\nappropriately processed bibliometric data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:18:42 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 08:45:12 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 09:30:11 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Miranda-Gonz\u00e1lez", "Andrea", ""], ["Aref", "Samin", ""], ["Theile", "Tom", ""], ["Zagheni", "Emilio", ""]]}, {"id": "2004.06721", "submitter": "Daniel Torres-Salinas Dr", "authors": "Daniel Torres-Salinas", "title": "Daily growth rate of scientific production on Covid-19. Analysis in\n  databases and open access repositories", "comments": "in Spanish", "journal-ref": null, "doi": "10.3145/epi.2020.mar.15", "report-no": null, "categories": "cs.DL cs.IR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scientific community is facing one of its greatest challenges in solving\na global health problem: COVID-19 pandemic. This situation has generated an\nunprecedented volume of publications. What is the volume, in terms of\npublications, of research on COVID-19? The general objective of this research\nwork is to obtain a global vision of the daily growth of scientific production\non COVID-19 in different databases (Dimensions, Web of Science Core Collection,\nScopus-Elsevier, Pubmed and eight repositories). In relation to the results\nobtained, Dimensions indexes a total of 9435 publications (69% with peer review\nand 2677 preprints) well above Scopus (1568) and WoS (718). This is a classic\nbiliometric phenomenon of exponential growth (R2 = 0.92). The global growth\nrate is 500 publications and the production doubles every 15 days. In the case\nof Pubmed the weekly growth is around 1000 publications. Of the eight\nrepositories analysed, Pubmed Central, Medrxiv and SSRN are the leaders.\nDespite their enormous contribution, the journals continue to be the core of\nscientific communication. Finally, it has been established that three out of\nevery four publications on the COVID-19 are available in open access. The\ninformation explosion demands a serious and coordinated response from\ninformation professionals, which places us at the centre of the information\npandemic.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:30:01 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Torres-Salinas", "Daniel", ""]]}, {"id": "2004.07102", "submitter": "Chaocheng He", "authors": "Chaocheng He, Jiang Wu, Qingpeng Zhang", "title": "Characterizing Research Leadership on Geographical Weighted\n  Collaboration Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research collaborations, especially long-distance and cross-border\ncollaborations, have become increasingly prevalent worldwide. Recent studies\nhighlighted the significant role of research leadership in collaborations.\nHowever, existing measures of the research leadership do not take into account\nthe intensity of leadership in the co-authorship network. More importantly, the\nspatial features, which influence the collaboration patterns and research\noutcomes, have not been incorporated in measuring the research leadership. To\nfill the gap, we construct an institution-level weighted co-authorship network\nthat has two types of weight on the edges: the intensity of collaborations and\nthe spatial score (the geographic distance adjusted by the cross-border\nnature). Based on this network, we propose a novel metric, namely the spatial\nresearch leadership rank (SpatialLeaderRank), to identify the leading\ninstitutions while considering both the collaboration intensity and the spatial\nfeatures. Harnessing a dataset of 323,146 journal publications in\npharmaceutical sciences during 2010-2018, we perform a comprehensive analysis\nof the geographical distribution and dynamic patterns of research leadership\nflows at the institution level. The results demonstrate that the\nSpatialLeaderRank outperforms baseline metrics in predicting the scholarly\nimpact of institutions. And the result remains robust in the field of\nInformation Science & Library Science.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 14:13:01 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["He", "Chaocheng", ""], ["Wu", "Jiang", ""], ["Zhang", "Qingpeng", ""]]}, {"id": "2004.07123", "submitter": "Seif Ben Chaabene", "authors": "Seif Ben Chaabene", "title": "Nouvelles repr\\'esentations concises exactes des motifs rares", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until a present, the majority of work in data mining were interested in the\nextraction of the frequent itemsets and the generation of the frequent\nassociation rules from these itemsets. Sometimes, the frequent of associations\nrules can revealed not-interesting in the direction where a frequent behavior\nis in general a normal behavior in the database. These last years, some work\nwas focused on the exploitation and the extraction of rare itemset and shows\nthem interest. However, the very important size of those itemset was the\nhandicap of algorithms that exploit the rare pattern. In order to relieve this\nproblem, the present report proposes two exact concise representations of the\nrare itemset, one based on the minimal generators and the other based on the\nclosed itemset. In this context, we introduce two new algorithms called GMRare\nand MFRare which extract these two exact concise representations.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:35:33 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Chaabene", "Seif Ben", ""]]}, {"id": "2004.07840", "submitter": "Ciriaco Andrea D'Angelo", "authors": "Giovanni Abramo, Dag W. Aksnes, Ciriaco Andrea D'Angelo", "title": "Unveiling the distinctive traits of a nation's research performance: the\n  case of Italy and Norway", "comments": "arXiv admin note: text overlap with arXiv:1907.02043", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we are analysing the research performance of Italian and\nNorwegian professors using constituent components of the Fractional Scientific\nStrength (FSS) indicator. The main focus is on differences across fields in\npublication output and citation impact. The overall performance (FSS) of the\ntwo countries, which differ considerably in research size and profile, is\nremarkedly similar. However, an in-depth analysis shows that there are large\nunderlying performance differences. An average Italian professor publishes more\npapers than a Norwegian, while the citation impact of the research output is\nhigher for the Norwegians. In addition, at field level the pattern varies along\nboth dimensions, and we analyse in which fields each country have their\nrelative strengths. Overall, this study contributes to further insights on how\nthe research performance of different countries may be analysed and compared,\nto inform research policy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:01:07 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Abramo", "Giovanni", ""], ["Aksnes", "Dag W.", ""], ["D'Angelo", "Ciriaco Andrea", ""]]}, {"id": "2004.08090", "submitter": "Peter Sj\\\"og{\\aa}rde", "authors": "Peter Sj\\\"og{\\aa}rde, Per Ahlgren, Ludo Waltman", "title": "Algorithmic labeling in hierarchical classifications of publications:\n  Evaluation of bibliographic fields and term weighting approaches", "comments": null, "journal-ref": null, "doi": "10.1002/asi.24452", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic classifications of research publications can be used to study\nmany different aspects of the science system, such as the organization of\nscience into fields, the growth of fields, interdisciplinarity, and emerging\ntopics. How to label the classes in these classifications is a problem that has\nnot been thoroughly addressed in the literature. In this study we evaluate\ndifferent approaches to label the classes in algorithmically constructed\nclassifications of research publications. We focus on two important choices:\nthe choice of (1) different bibliographic fields and (2) different approaches\nto weight the relevance of terms. To evaluate the different choices, we created\ntwo baselines: one based on the Medical Subject Headings in MEDLINE and another\nbased on the Science-Metrix journal classification. We tested to what extent\ndifferent approaches yield the desired labels for the classes in the two\nbaselines. Based on our results we recommend extracting terms from titles and\nkeywords to label classes at high levels of granularity (e.g. topics). At low\nlevels of granularity (e.g. disciplines) we recommend extracting terms from\njournal names and author addresses. We recommend the use of a new approach,\nterm frequency to specificity ratio, to calculate the relevance of terms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:21:59 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:00:46 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 15:37:44 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 09:23:08 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sj\u00f6g\u00e5rde", "Peter", ""], ["Ahlgren", "Per", ""], ["Waltman", "Ludo", ""]]}, {"id": "2004.08806", "submitter": "Endel Poder", "authors": "Endel Poder", "title": "On the rules of science game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit allocation in the mainstream bibliometrics is fundamentally flawed and\nthe popular indicators have been misleading science for decades. Originally a\nsimple technical mistake has become an integral part of our culture and is very\ndifficult to correct. Although the problem has been raised in scientific\narticles, it seems mostly unknown to wider audience.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 10:29:20 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Poder", "Endel", ""]]}, {"id": "2004.09006", "submitter": "Ali Dasdan", "authors": "Ali Dasdan, Eric Van Lare, and Bosko Zivaljevic", "title": "How Reliable are University Rankings?", "comments": "47 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  University or college rankings have almost become an industry of their own,\npublished by US News \\& World Report (USNWR) and similar organizations. Most of\nthe rankings use a similar scheme: Rank universities in decreasing score order,\nwhere each score is computed using a set of attributes and their weights; the\nattributes can be objective or subjective while the weights are always\nsubjective. This scheme is general enough to be applied to ranking objects\nother than universities. As shown in the related work, these rankings have\nimportant implications and also many issues. In this paper, we take a fresh\nlook at this ranking scheme using the public College dataset; we both formally\nand experimentally show in multiple ways that this ranking scheme is not\nreliable and cannot be trusted as authoritative because it is too sensitive to\nweight changes and can easily be gamed. For example, we show how to derive\nreasonable weights programmatically to move multiple universities in our\ndataset to the top rank; moreover, this task takes a few seconds for over 600\nuniversities on a personal laptop. Our mathematical formulation, methods, and\nresults are applicable to ranking objects other than universities too. We\nconclude by making the case that all the data and methods used for rankings\nshould be made open for validation and repeatability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 01:00:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Dasdan", "Ali", ""], ["Van Lare", "Eric", ""], ["Zivaljevic", "Bosko", ""]]}, {"id": "2004.09715", "submitter": "Mayank Singh", "authors": "Mayank Singh, Arindam Pal, Lipika Dey and Animesh Mukherjee", "title": "Innovation and Revenue: Deep Diving into the Temporal Rank-shifts of\n  Fortune 500 Companies", "comments": "Accepted at CODS-COMAD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research and innovation is important agenda for any company to remain\ncompetitive in the market. The relationship between innovation and revenue is a\nkey metric for companies to decide on the amount to be invested for future\nresearch. Two important parameters to evaluate innovation are the quantity and\nquality of scientific papers and patents. Our work studies the relationship\nbetween innovation and patenting activities for several Fortune 500 companies\nover a period of time. We perform a comprehensive study of the patent citation\ndataset available in the Reed Technology Index collected from the US Patent\nOffice. We observe several interesting relations between parameters like the\nnumber of (i) patent applications, (ii) patent grants, (iii) patent citations\nand Fortune 500 ranks of companies. We also study the trends of these\nparameters varying over the years and derive causal explanations for these with\nqualitative and intuitive reasoning. To facilitate reproducible research, we\nmake all the processed patent dataset publicly available at\nhttps://github.com/mayank4490/Innovation-and-revenue.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:28:52 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Singh", "Mayank", ""], ["Pal", "Arindam", ""], ["Dey", "Lipika", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2004.09741", "submitter": "Marcos Kalinowski", "authors": "Erica Mour\\~ao, Jo\\~ao Felipe Pimentel, Leonardo Murta, Marcos\n  Kalinowski, Emilia Mendes, Claes Wohlin", "title": "On the Performance of Hybrid Search Strategies for Systematic Literature\n  Reviews in Software Engineering", "comments": "Accepted for publication at the Information and Software Technology\n  Journal", "journal-ref": null, "doi": "10.1016/j.infsof.2020.106294", "report-no": null, "categories": "cs.DL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: When conducting a Systematic Literature Review (SLR), researchers\nusually face the challenge of designing a search strategy that appropriately\nbalances result quality and review effort. Using digital library (or database)\nsearches or snowballing alone may not be enough to achieve high-quality\nresults. On the other hand, using both digital library searches and snowballing\ntogether may increase the overall review effort.\n  Objective: The goal of this research is to propose and evaluate hybrid search\nstrategies that selectively combine database searches with snowballing.\n  Method: We propose four hybrid search strategies combining database searches\nin digital libraries with iterative, parallel, or sequential backward and\nforward snowballing. We simulated the strategies over three existing SLRs in SE\nthat adopted both database searches and snowballing. We compared the outcome of\ndigital library searches, snowballing, and hybrid strategies using precision,\nrecall, and F-measure to investigate the performance of each strategy.\n  Results: Our results show that, for the analyzed SLRs, combining database\nsearches from the Scopus digital library with parallel or sequential\nsnowballing achieved the most appropriate balance of precision and recall.\n  Conclusion: We put forward that, depending on the goals of the SLR and the\navailable resources, using a hybrid search strategy involving a representative\ndigital library and parallel or sequential snowballing tends to represent an\nappropriate alternative to be used when searching for evidence in SLRs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 03:49:46 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Mour\u00e3o", "Erica", ""], ["Pimentel", "Jo\u00e3o Felipe", ""], ["Murta", "Leonardo", ""], ["Kalinowski", "Marcos", ""], ["Mendes", "Emilia", ""], ["Wohlin", "Claes", ""]]}, {"id": "2004.09915", "submitter": "Bahram Kalhor", "authors": "Bahram Kalhor, Farzaneh Mehrparvar", "title": "Rankings of countries based on rankings of universities", "comments": "13 pagges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many methods have been designed for ranking universities, there is\nno suitable system that focuses on the ranking of countries based on the\nperformance of their universities. The overall ranking of the universities in a\nregion can indicate the growth of interests in science among the people of that\nland. This paper introduces a novel ranking mechanism based on the rankings of\nuniversities. Firstly, we introduce and discuss two new rankings of countries,\nbased on the rank of their universities. Secondly, we create rankings of\ncountries according to the selected method, based on the top 12000 universities\nin webometrics.info (January 2012) and compare rankings of countries in 4\neditions (January 2012 to July 2013). Firstly, we introduce two new methods of\nranking countries based on their university rankings, Weighted Ranking (WR) and\nAverage Ranking (AR). Secondly, we discuss how the introduced ranking systems,\nperform in ranking countries based on the two years of data. Thirdly, we choose\nQS (http://www.topuniversities.com) and webometrics.info as two different\nclassification systems for comparing rankings of countries, based on the top\n500 universities in these rankings. Results indicate that the methodology can\nbe used to show the quality of the whole universities of each country used to\ncompare rankings of countries in practice compare to other countries in the\nworld.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 11:30:10 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Kalhor", "Bahram", ""], ["Mehrparvar", "Farzaneh", ""]]}, {"id": "2004.09958", "submitter": "Jes\\'us Tramullas", "authors": "Jes\\'us Tramullas, Piedad Garrido-Picazo, Ana I. S\\'anchez-Casab\\'on", "title": "Use of Wikipedia categories on information retrieval research: a brief\n  review", "comments": null, "journal-ref": null, "doi": "10.1145/3230599.3230617", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wikipedia categories, a classification scheme built for organizing and\ndescribing Wikpedia articles, are being applied in computer science research.\nThis paper adopts a systematic literature review approach, in order to identify\ndifferent approaches and uses of Wikipedia categories in information retrieval\nresearch. Several types of work are identified, depending on the intrinsic\nstudy of the categories structure, or its use as a tool for the processing and\nanalysis of other documentary corpus different to Wikipedia. Information\nretrieval is identified as one of the major areas of use, in particular its\napplication in the refinement and improvement of search expressions, and the\nconstruction of textual corpus. However, the set of available works shows that\nin many cases research approaches applied and results obtained can be\nintegrated into a comprehensive and inclusive concept of information retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:45:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Tramullas", "Jes\u00fas", ""], ["Garrido-Picazo", "Piedad", ""], ["S\u00e1nchez-Casab\u00f3n", "Ana I.", ""]]}, {"id": "2004.09959", "submitter": "Kerstin H\\\"otte", "authors": "Kerstin H\\\"otte, Anton Pichler, Fran\\c{c}ois Lafond", "title": "The rise of science in low-carbon energy technologies", "comments": null, "journal-ref": null, "doi": "10.1016/j.rser.2020.110654", "report-no": null, "categories": "cs.DL econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successfully combating climate change will require substantial technological\nimprovements in Low-Carbon Energy Technologies (LCETs), but designing efficient\nallocation of R\\&D budgets requires a better understanding of how LCETs rely on\nscientific knowledge. Using data covering almost all US patents and scientific\narticles that are cited by them over the past two centuries, we describe the\nevolution of knowledge bases of ten key LCETs and show how technological\ninterdependencies have changed over time. The composition of low-carbon energy\ninnovations shifted over time, from Hydro and Wind energy in the 19th and early\n20th century, to Nuclear fission after World War II, and more recently to Solar\nPV and back to Wind. In recent years, Solar PV, Nuclear fusion and Biofuels\n(including energy from waste) have 35-65\\% of their citations directed toward\nscientific papers, while this ratio is less than 10\\% for Wind, Solar thermal,\nHydro, Geothermal, and Nuclear fission. Over time, the share of patents citing\nscience and the share of citations that are to scientific papers has been\nincreasing for all technology types. The analysis of the scientific knowledge\nbase of each LCET reveals three fairly separate clusters, with nuclear energy\ntechnologies, Biofuels and Waste, and all the other LCETs. Our detailed\ndescription of knowledge requirements for each LCET helps to design of targeted\ninnovation policies.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:47:04 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 11:35:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["H\u00f6tte", "Kerstin", ""], ["Pichler", "Anton", ""], ["Lafond", "Fran\u00e7ois", ""]]}, {"id": "2004.10400", "submitter": "Mike Thelwall Prof", "authors": "Kayvan Kousha, Mike Thelwall", "title": "COVID-19 publications: Database coverage, citations, readers, tweets,\n  news, Facebook walls, Reddit posts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic requires a fast response from researchers to help\naddress biological, medical and public health issues to minimize its impact. In\nthis rapidly evolving context, scholars, professionals and the public may need\nto quickly identify important new studies. In response, this paper assesses the\ncoverage of scholarly databases and impact indicators during 21 March to 18\nApril 2020. The results confirm a rapid increase in the volume of research,\nwhich particularly accessible through Google Scholar and Dimensions, and less\nthrough Scopus, the Web of Science, PubMed. A few COVID-19 papers from the\n21,395 in Dimensions were already highly cited, with substantial news and\nsocial media attention. For this topic, in contrast to previous studies, there\nseems to be a high degree of convergence between articles shared in the social\nweb and citation counts, at least in the short term. In particular, articles\nthat are extensively tweeted on the day first indexed are likely to be highly\nread and relatively highly cited three weeks later. Researchers needing wide\nscope literature searches (rather than health focused PubMed or medRxiv\nsearches) should start with Google Scholar or Dimensions and can use tweet and\nMendeley reader counts as indicators of likely importance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 05:52:07 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kousha", "Kayvan", ""], ["Thelwall", "Mike", ""]]}, {"id": "2004.10706", "submitter": "Lucy Lu Wang", "authors": "Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas,\n  Jiangjiang Yang, Doug Burdick, Darrin Eide, Kathryn Funk, Yannis Katsis,\n  Rodney Kinney, Yunyao Li, Ziyang Liu, William Merrill, Paul Mooney, Dewey\n  Murdick, Devvret Rishi, Jerry Sheehan, Zhihong Shen, Brandon Stilson, Alex\n  Wade, Kuansan Wang, Nancy Xin Ru Wang, Chris Wilhelm, Boya Xie, Douglas\n  Raymond, Daniel S. Weld, Oren Etzioni, Sebastian Kohlmeier", "title": "CORD-19: The COVID-19 Open Research Dataset", "comments": "ACL NLP-COVID Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 Open Research Dataset (CORD-19) is a growing resource of\nscientific papers on COVID-19 and related historical coronavirus research.\nCORD-19 is designed to facilitate the development of text mining and\ninformation retrieval systems over its rich collection of metadata and\nstructured full text papers. Since its release, CORD-19 has been downloaded\nover 200K times and has served as the basis of many COVID-19 text mining and\ndiscovery systems. In this article, we describe the mechanics of dataset\nconstruction, highlighting challenges and key design decisions, provide an\noverview of how CORD-19 has been used, and describe several shared tasks built\naround the dataset. We hope this resource will continue to bring together the\ncomputing community, biomedical experts, and policy makers in the search for\neffective treatments and management policies for COVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:10:18 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 02:44:54 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 18:42:13 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 21:40:34 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Wang", "Lucy Lu", ""], ["Lo", "Kyle", ""], ["Chandrasekhar", "Yoganand", ""], ["Reas", "Russell", ""], ["Yang", "Jiangjiang", ""], ["Burdick", "Doug", ""], ["Eide", "Darrin", ""], ["Funk", "Kathryn", ""], ["Katsis", "Yannis", ""], ["Kinney", "Rodney", ""], ["Li", "Yunyao", ""], ["Liu", "Ziyang", ""], ["Merrill", "William", ""], ["Mooney", "Paul", ""], ["Murdick", "Dewey", ""], ["Rishi", "Devvret", ""], ["Sheehan", "Jerry", ""], ["Shen", "Zhihong", ""], ["Stilson", "Brandon", ""], ["Wade", "Alex", ""], ["Wang", "Kuansan", ""], ["Wang", "Nancy Xin Ru", ""], ["Wilhelm", "Chris", ""], ["Xie", "Boya", ""], ["Raymond", "Douglas", ""], ["Weld", "Daniel S.", ""], ["Etzioni", "Oren", ""], ["Kohlmeier", "Sebastian", ""]]}, {"id": "2004.10786", "submitter": "Marianne Gauffriau", "authors": "Marianne Gauffriau", "title": "Validation of counting methods in bibliometrics", "comments": "Preprint: Author's manuscript submitted to the conference STI2020.\n  Due to the Corona virus, STI2020 was postponed until September 2021. All\n  submissions were returned to the authors before peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The discussion about counting methods in bibliometrics is often reduced to\nthe choice between full and fractional counting. However, several studies\ndocument that this distinction is too simple. The aim of the present study is\nto give an overview of counting methods in the bibliometric literature and to\nprovide insight into their properties and use. A mix of methods is used. In the\npreliminary results, a literature review covering 1970-2018 identified 29\noriginal counting methods. Seventeen were introduced in the period 2010-2018.\nTwenty-one of the 29 counting methods are rank-dependent and fractionalized\nmeaning that the authors of a publications share 1 credit but do not receive\nequal shares, for example harmonic counting. The internal and external\nvalidation of the counting methods are assessed. Three criteria for\nwell-constructed bibliometric indicators - adequacy, sensitivity, and\nhomogeneity - are used to assess the internal validity. Regarding the external\nvalidation of the counting methods, it is investigated whether the intentions\nin the studies that introduced the 29 counting methods comply with the\nsubsequent use of the counting methods. This study has the potential to give a\nsolid foundation for the use of and discussion about counting methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 18:45:35 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Gauffriau", "Marianne", ""]]}, {"id": "2004.10878", "submitter": "Sujit Bhattacharya Professor", "authors": "Sujit Bhattacharya and Shubham Singh", "title": "Visible Insights of the Invisible Pandemic: A Scientometric, Altmetric\n  and Topic Trend Analysis", "comments": "21 pages, 4 Figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent SARS-COV-2 virus outbreak has created an unprecedented global\nhealth crisis! The disease is showing alarming trends with the number of people\ngetting infected with this disease, new cases and death rate are all\nhighlighting the need to control this disease at the earliest. The strategy now\nfor the governments around the globe is how to limit the spread of the virus\nuntil the research community develops treatment/drug or vaccination against the\nvirus. The outbreak of this disease has unsurprisingly led to huge volume of\nresearch within a short period of time surrounding this disease. It has also\nled to aggressive social media activity on twitter, Facebook, dedicated blogs,\nnews reports and other online sites actively involved in discussing about the\nvarious aspects of and related to this disease. It becomes a useful and\nchallenging exercise to draw from this huge volume of research, the key papers\nthat form the research front, its influence in the research community, and\nother important research insights. Similarly, it becomes important to discern\nthe key issues that influence the society concerning this disease. The paper is\nmotivated by this. It attempts to distinguish which are the most influential\npapers, the key knowledge base and major topics surrounding the research\ncovered by COVID-19. Further it attempts to capture the society's perception by\ndiscerning key topics that are trending online. The study concludes by\nhighlighting the implications of this study.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 21:53:15 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bhattacharya", "Sujit", ""], ["Singh", "Shubham", ""]]}, {"id": "2004.12018", "submitter": "Morgan Wofford F", "authors": "Morgan F. Wofford, Bernadette M. Boscoe, Christine L. Borgman, Irene\n  V. Pasquetto, and Milena S. Golshan", "title": "Jupyter notebooks as discovery mechanisms for open science: Citation\n  practices in the astronomy community", "comments": null, "journal-ref": "Computing in Science & Engineering Vol. 22, Issue 1, 2020", "doi": "10.1109/MCSE.2019.2932067", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Citing data and software is a means to give scholarly credit and to\nfacilitate access to research objects. Citation principles encourage authors to\nprovide full descriptions of objects, with stable links, in their papers. As\nJupyter notebooks aggregate data, software, and other objects, they may\nfacilitate or hinder citation, credit, and access to data and software. We\nreport on a study of references to Jupyter notebooks in astronomy over a 5-year\nperiod (2014-2018). References increased rapidly, but fewer than half of the\nreferences led to Jupyter notebooks that could be located and opened. Jupyter\nnotebooks appear better suited to supporting the research process than to\nproviding access to research objects. We recommend that authors cite individual\ndata and software objects, and that they stabilize any notebooks cited in\npublications. Publishers should increase the number of citations allowed in\npapers and employ descriptive metadata-rich citation styles that facilitate\ncredit and discovery.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:58:54 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wofford", "Morgan F.", ""], ["Boscoe", "Bernadette M.", ""], ["Borgman", "Christine L.", ""], ["Pasquetto", "Irene V.", ""], ["Golshan", "Milena S.", ""]]}, {"id": "2004.12159", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Amalia Mas-Bleda", "title": "A gender equality paradox in academic publishing: Countries with a\n  higher proportion of female first-authored journal articles have larger first\n  author gender disparities between fields", "comments": "Quantitative Science Studies, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current attempts to address the shortfall of female researchers in Science,\nTechnology, Engineering and Mathematics (STEM) have not yet succeeded despite\nother academic subjects having female majorities. This article investigates the\nextent to which gender disparities are subject-wide or nation-specific by a\nfirst author gender comparison of 30 million articles from all 27 Scopus broad\nfields within the 31 countries with the most Scopus-indexed articles 2014-18.\nThe results show overall and geocultural patterns as well as individual\nnational differences. Almost half of the subjects were always more male (7;\ne.g., Mathematics) or always more female (6; e.g., Immunology & Microbiology)\nthan the national average. A strong overall trend (Spearman correlation 0.546)\nis for countries with a higher proportion of female first-authored research to\nalso have larger differences in gender disparities between fields (correlation\n0.314 for gender ratios). This confirms the international gender equality\nparadox previously found for degree subject choices: increased gender equality\noverall associates with moderately greater gender differentiation between\nsubjects. This is consistent with previous USA-based claims that gender\ndifferences in academic careers are partly due to (socially constrained) gender\ndifferences in personal preferences. Radical solutions may therefore be needed\nfor some STEM subjects to overcome gender disparities.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:47:25 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Thelwall", "Mike", ""], ["Mas-Bleda", "Amalia", ""]]}, {"id": "2004.12195", "submitter": "Georg Rehm", "authors": "Georg Rehm, Peter Bourgonje, Stefanie Hegele, Florian Kintzel,\n  Juli\\'an Moreno Schneider, Malte Ostendorff, Karolina Zaczynska, Armin\n  Berger, Stefan Grill, S\\\"oren R\\\"auchle, Jens Rauenbusch, Lisa Rutenburg,\n  Andr\\'e Schmidt, Mikka Wild, Henry Hoffmann, Julian Fink, Sarah Schulz,\n  Jurica Seva, Joachim Quantz, Joachim B\\\"ottger, Josefine Matthey, Rolf\n  Fricke, Jan Thomsen, Adrian Paschke, Jamal Al Qundus, Thomas Hoppe, Naouel\n  Karam, Frauke Weichhardt, Christian Fillies, Clemens Neudecker, Mike Gerber,\n  Kai Labusch, Vahid Rezanezhad, Robin Schaefer, David Zellh\\\"ofer, Daniel\n  Siewert, Patrick Bunk, Lydia Pintscher, Elena Aleynikova, Franziska Heine", "title": "QURATOR: Innovative Technologies for Content and Data Curation", "comments": "Proceedings of QURATOR 2020: The conference for intelligent content\n  solutions, Berlin, Germany, February 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In all domains and sectors, the demand for intelligent systems to support the\nprocessing and generation of digital content is rapidly increasing. The\navailability of vast amounts of content and the pressure to publish new content\nquickly and in rapid succession requires faster, more efficient and smarter\nprocessing and generation methods. With a consortium of ten partners from\nresearch and industry and a broad range of expertise in AI, Machine Learning\nand Language Technologies, the QURATOR project, funded by the German Federal\nMinistry of Education and Research, develops a sustainable and innovative\ntechnology platform that provides services to support knowledge workers in\nvarious industries to address the challenges they face when curating digital\ncontent. The project's vision and ambition is to establish an ecosystem for\ncontent curation technologies that significantly pushes the current state of\nthe art and transforms its region, the metropolitan area Berlin-Brandenburg,\ninto a global centre of excellence for curation technologies.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:21:15 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Rehm", "Georg", ""], ["Bourgonje", "Peter", ""], ["Hegele", "Stefanie", ""], ["Kintzel", "Florian", ""], ["Schneider", "Juli\u00e1n Moreno", ""], ["Ostendorff", "Malte", ""], ["Zaczynska", "Karolina", ""], ["Berger", "Armin", ""], ["Grill", "Stefan", ""], ["R\u00e4uchle", "S\u00f6ren", ""], ["Rauenbusch", "Jens", ""], ["Rutenburg", "Lisa", ""], ["Schmidt", "Andr\u00e9", ""], ["Wild", "Mikka", ""], ["Hoffmann", "Henry", ""], ["Fink", "Julian", ""], ["Schulz", "Sarah", ""], ["Seva", "Jurica", ""], ["Quantz", "Joachim", ""], ["B\u00f6ttger", "Joachim", ""], ["Matthey", "Josefine", ""], ["Fricke", "Rolf", ""], ["Thomsen", "Jan", ""], ["Paschke", "Adrian", ""], ["Qundus", "Jamal Al", ""], ["Hoppe", "Thomas", ""], ["Karam", "Naouel", ""], ["Weichhardt", "Frauke", ""], ["Fillies", "Christian", ""], ["Neudecker", "Clemens", ""], ["Gerber", "Mike", ""], ["Labusch", "Kai", ""], ["Rezanezhad", "Vahid", ""], ["Schaefer", "Robin", ""], ["Zellh\u00f6fer", "David", ""], ["Siewert", "Daniel", ""], ["Bunk", "Patrick", ""], ["Pintscher", "Lydia", ""], ["Aleynikova", "Elena", ""], ["Heine", "Franziska", ""]]}, {"id": "2004.12275", "submitter": "Chao Min", "authors": "Chao Min, Qingyu Chen, Erjia Yan, Yi Bu, Jianjun Sun", "title": "Citation Cascade and the Evolution of Topic Relevance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation analysis, as a tool for quantitative studies of science, has long\nemphasized direct citation relations, leaving indirect or high order citations\noverlooked. However, a series of early and recent studies demonstrate the\nexistence of indirect and continuous citation impact across generations. Adding\nto the literature on high order citations, we introduce the concept of a\ncitation cascade: the constitution of a series of subsequent citing events\ninitiated by a certain publication. We investigate this citation structure by\nanalyzing more than 450,000 articles and over 6 million citation relations. We\nshow that citation impact exists not only within the three generations\ndocumented in prior research, but also in much further generations. Still, our\nexperimental results indicate that two to four generations are generally\nadequate to trace a work's scientific impact. We also explore specific\nstructural properties such as depth, width, structural virality, and size,\nwhich account for differences among individual citation cascades. Finally, we\nfind evidence that it is more important for a scientific work to inspire trans\ndomain (or indirectly related domain) works than to receive only intra domain\nrecognition in order to achieve high impact. Our methods and findings can serve\nas a new tool for scientific evaluation and the modeling of scientific history.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 02:37:02 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Min", "Chao", ""], ["Chen", "Qingyu", ""], ["Yan", "Erjia", ""], ["Bu", "Yi", ""], ["Sun", "Jianjun", ""]]}, {"id": "2004.13159", "submitter": "Kevin Boyack", "authors": "Richard Klavans, Kevin W. Boyack, Dewey A. Murdick", "title": "A Novel Approach to Predicting Exceptional Growth in Research", "comments": "25 pages, 4 figures, 10 tables inline", "journal-ref": null, "doi": "10.1371/journal.pone.0239177", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of exceptional or surprising growth in research is an issue\nwith deep roots and few practical solutions. In this study we develop and\nvalidate a novel approach to forecasting growth in highly specific research\ncommunities. Each research community is represented by a cluster of papers.\nMultiple indicators were tested, and a composite indicator was created that\npredicts which research communities will experience exceptional growth over the\nnext three years. The accuracy of this predictor was tested using hundreds of\nthousands of community-level forecasts and was found to exceed the performance\nbenchmarks established in Intelligence Advanced Research Projects Activity's\n(IARPA) Foresight Using Scientific Exposition (FUSE) program in six of nine\nmajor fields in science. Furthermore, ten of eleven disciplines within the\nComputing Technologies field met the benchmarks. Specific detailed forecast\nexamples are given and evaluated, and a critical evaluation of the forecasting\napproach is also provided.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:33:50 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Klavans", "Richard", ""], ["Boyack", "Kevin W.", ""], ["Murdick", "Dewey A.", ""]]}, {"id": "2004.13717", "submitter": "Neslihan Suzen", "authors": "Neslihan Suzen, Evgeny M. Mirkes, Alexander N. Gorban", "title": "Informational Space of Meaning for Scientific Texts", "comments": "320 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Natural Language Processing, automatic extracting the meaning of texts\nconstitutes an important problem. Our focus is the computational analysis of\nmeaning of short scientific texts (abstracts or brief reports). In this paper,\na vector space model is developed for quantifying the meaning of words and\ntexts. We introduce the Meaning Space, in which the meaning of a word is\nrepresented by a vector of Relative Information Gain (RIG) about the subject\ncategories that the text belongs to, which can be obtained from observing the\nword in the text. This new approach is applied to construct the Meaning Space\nbased on Leicester Scientific Corpus (LSC) and Leicester Scientific\nDictionary-Core (LScDC). The LSC is a scientific corpus of 1,673,350 abstracts\nand the LScDC is a scientific dictionary which words are extracted from the\nLSC. Each text in the LSC belongs to at least one of 252 subject categories of\nWeb of Science (WoS). These categories are used in construction of vectors of\ninformation gains. The Meaning Space is described and statistically analysed\nfor the LSC with the LScDC. The usefulness of the proposed representation model\nis evaluated through top-ranked words in each category. The most informative n\nwords are ordered. We demonstrated that RIG-based word ranking is much more\nuseful than ranking based on raw word frequency in determining the\nscience-specific meaning and importance of a word. The proposed model based on\nRIG is shown to have ability to stand out topic-specific words in categories.\nThe most informative words are presented for 252 categories. The new scientific\ndictionary and the 103,998 x 252 Word-Category RIG Matrix are available online.\nAnalysis of the Meaning Space provides us with a tool to further explore\nquantifying the meaning of a text using more complex and context-dependent\nmeaning models that use co-occurrence of words and their combinations.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 14:26:12 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Suzen", "Neslihan", ""], ["Mirkes", "Evgeny M.", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2004.13974", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Robin Haunschild, and Vanash M. Patel", "title": "Are papers addressing certain diseases perceived where these diseases\n  are prevalent? The proposal to use Twitter data as social-spatial sensors", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0242550", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use Twitter data as social-spatial sensors. This study deals\nwith the question whether research papers on certain diseases are perceived by\npeople in regions (worldwide) that are especially concerned by the diseases.\nSince (some) Twitter data contain location information, it is possible to\nspatially map the activity of Twitter users referring to certain papers (e.g.,\ndealing with tuberculosis). The resulting maps reveal whether heavy activity on\nTwitter is correlated with large numbers of people having certain diseases. In\nthis study, we focus on tuberculosis, human immunodeficiency virus (HIV), and\nmalaria, since the World Health Organization ranks these diseases as the top\nthree causes of death worldwide by a single infectious agent. The results of\nthe social-spatial Twitter maps (and additionally performed regression models)\nreveal the usefulness of the proposed sensor approach. One receives an\nimpression of how research papers on the diseases have been perceived by people\nin regions that are especially concerned by the diseases. Our study\ndemonstrates a promising approach for using Twitter data for research\nevaluation purposes beyond simple counting of tweets.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:32:42 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""], ["Patel", "Vanash M.", ""]]}, {"id": "2004.14329", "submitter": "Alberto Mart\\'in-Mart\\'in", "authors": "Alberto Mart\\'in-Mart\\'in, Mike Thelwall, Enrique Orduna-Malea, Emilio\n  Delgado L\\'opez-C\\'ozar", "title": "Google Scholar, Microsoft Academic, Scopus, Dimensions, Web of Science,\n  and OpenCitations' COCI: a multidisciplinary comparison of coverage via\n  citations", "comments": "40 pages, 10 figures, 4 tables", "journal-ref": "2021. Scientometrics, 126(1), 871-906", "doi": "10.1007/s11192-020-03690-4", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New sources of citation data have recently become available, such as\nMicrosoft Academic, Dimensions, and the OpenCitations Index of CrossRef open\nDOI-to-DOI citations (COCI). Although these have been compared to the Web of\nScience (WoS), Scopus, or Google Scholar, there is no systematic evidence of\ntheir differences across subject categories. In response, this paper\ninvestigates 3,073,351 citations found by these six data sources to 2,515\nEnglish-language highly-cited documents published in 2006 from 252 subject\ncategories, expanding and updating the largest previous study. Google Scholar\nfound 88% of all citations, many of which were not found by the other sources,\nand nearly all citations found by the remaining sources (89%-94%). A similar\npattern held within most subject categories. Microsoft Academic is the second\nlargest overall (60% of all citations), including 82% of Scopus citations and\n86% of Web of Science citations. In most categories, Microsoft Academic found\nmore citations than Scopus and WoS (182 and 223 subject categories,\nrespectively), but had coverage gaps in some areas, such as Physics and some\nHumanities categories. After Scopus, Dimensions is fourth largest (54% of all\ncitations), including 84% of Scopus citations and 88% of WoS citations. It\nfound more citations than Scopus in 36 categories, more than WoS in 185, and\ndisplays some coverage gaps, especially in the Humanities. Following WoS, COCI\nis the smallest, with 28% of all citations. Google Scholar is still the most\ncomprehensive source. In many subject categories Microsoft Academic and\nDimensions are good alternatives to Scopus and WoS in terms of coverage.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:56:19 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 21:29:35 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 12:50:55 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mart\u00edn-Mart\u00edn", "Alberto", ""], ["Thelwall", "Mike", ""], ["Orduna-Malea", "Enrique", ""], ["L\u00f3pez-C\u00f3zar", "Emilio Delgado", ""]]}]