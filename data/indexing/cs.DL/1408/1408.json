[{"id": "1408.0090", "submitter": "Anup Kumar Das", "authors": "Anup Kumar Das, Sanjaya Mishra", "title": "Genesis of Altmetrics or Article-level Metrics for Measuring Efficacy of\n  Scholarly Communications: Current Perspectives", "comments": null, "journal-ref": "Journal of Scientometric Research, 2014, 3(2), 82-92", "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The article-level metrics (ALMs) or altmetrics becomes a new trendsetter in\nrecent times for measuring the impact of scientific publications and their\nsocial outreach to intended audiences. The popular social networks such as\nFacebook, Twitter, and Linkedin and social bookmarks such as Mendeley and\nCiteULike are nowadays widely used for communicating research to larger\ntransnational audiences. In 2012, the San Francisco Declaration on Research\nAssessment got signed by the scientific and researchers communities across the\nworld. This declaration has given preference to the ALM or altmetrics over\ntraditional but faulty journal impact factor (JIF)-based assessment of career\nscientists. JIF does not consider impact or influence beyond citations count as\nthis count reflected only through Thomson Reuters' Web of Science database.\nFurthermore, JIF provides indicator related to the journal, but not related to\na published paper. Thus, altmetrics now becomes an alternative metrics for\nperformance assessment of individual scientists and their contributed scholarly\npublications. This paper provides a glimpse of genesis of altmetrics in\nmeasuring efficacy of scholarly communications and highlights available\naltmetric tools and social platforms linking altmetric tools, which are widely\nused in deriving altmetric scores of scholarly publications. The paper thus\nargues for institutions and policy makers to pay more attention to altmetrics\nbased indicators for evaluation purpose but cautions that proper safeguards and\nvalidations are needed before their adoption.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 06:36:40 GMT"}, {"version": "v2", "created": "Wed, 10 Dec 2014 12:07:12 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Das", "Anup Kumar", ""], ["Mishra", "Sanjaya", ""]]}, {"id": "1408.0135", "submitter": "Nicolas Robinson-Garcia", "authors": "Nicol\\'as Robinson-Garc\\'ia, Daniel Torres-Salinas, Zohreh Zahedi and\n  Rodrigo Costas", "title": "New data, new possibilities: Exploring the insides of Altmetric.com", "comments": null, "journal-ref": "El profesional de la informaci\\'on, 23(4), 359-366 (2014)", "doi": "10.3145/epi.2014.jul.03", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes Altmetric.com, one of the most important altmetric data\nproviders currently used. We have analyzed a set of publications with DOI\nnumber indexed in the Web of Science during the period 2011-2013 and collected\ntheir data with the Altmetric API. 19% of the original set of papers was\nretrieved from Altmetric.com including some altmetric data. We identified 16\ndifferent social media sources from which Altmetric.com retrieves data. However\nfive of them cover 95.5% of the total set. Twitter (87.1%) and Mendeley (64.8%)\nhave the highest coverage. We conclude that Altmetric.com is a transparent,\nrich and accurate tool for altmetric data. Nevertheless, there are still\npotential limitations on its exhaustiveness as well as on the selection of\nsocial media sources that need further research.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 11:27:47 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Robinson-Garc\u00eda", "Nicol\u00e1s", ""], ["Torres-Salinas", "Daniel", ""], ["Zahedi", "Zohreh", ""], ["Costas", "Rodrigo", ""]]}, {"id": "1408.1260", "submitter": "Maxim Kolchin Mr.", "authors": "Maxim Kolchin, Fedor Kozlov", "title": "Unstable markup: A template-based information extraction from web sites\n  with unstable markup", "comments": "ESWC 2014 Semantic Publishing Challenge, Task 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents results of a work on crawling CEUR Workshop proceedings\nweb site to a Linked Open Data (LOD) dataset in the framework of ESWC 2014\nSemantic Publishing Challenge 2014. Our approach is based on using an\nextensible template-dependent crawler and DBpedia for linking extracted\nentities, such as the names of universities and countries.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 12:36:23 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Kolchin", "Maxim", ""], ["Kozlov", "Fedor", ""]]}, {"id": "1408.1274", "submitter": "James Clough", "authors": "James R. Clough and Tim S. Evans", "title": "What is the dimension of citation space?", "comments": "20 pages, 11 figures + appendix, 3 pages, 2 figures", "journal-ref": "Physica A, 448 (2016) 235-247", "doi": "10.1016/j.physa.2015.12.053", "report-no": "Imperial/TP/14/TSE/1", "categories": "physics.soc-ph cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation networks represent the flow of information between agents. They are\nconstrained in time and so form directed acyclic graphs which have a causal\nstructure. Here we provide novel quantitative methods to characterise that\nstructure by adapting methods used in the causal set approach to quantum\ngravity by considering the networks to be embedded in a Minkowski spacetime and\nmeasuring its dimension using Myrheim-Meyer and Midpoint-scaling estimates. We\nillustrate these methods on citation networks from the arXiv, supreme court\njudgements from the USA, and patents and find that otherwise similar citation\nnetworks have measurably different dimensions. We suggest that these\ndifferences can be interpreted in terms of the level of diversity or narrowness\nin citation behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 13:40:10 GMT"}, {"version": "v2", "created": "Thu, 4 Sep 2014 11:08:42 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2015 14:20:16 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Clough", "James R.", ""], ["Evans", "Tim S.", ""]]}, {"id": "1408.1713", "submitter": "Mark A. Matienzo", "authors": "Mark A. Matienzo and Amy Rudersdorf (Digital Public Library of\n  America)", "title": "The Digital Public Library of America Ingestion Ecosystem: Lessons\n  Learned After One Year of Large-Scale Collaborative Metadata Aggregation", "comments": "11 pages, 3 figures; Int'l Conf. on Dublin Core and Metadata\n  Applications 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The Digital Public Library of America (DPLA) aggregates metadata for cultural\nheritage materials from 20 direct partners, or Hubs, across the United States.\nWhile the initial build-out of the DPLA's infrastructure used a lightweight\ningestion system that was ultimately pushed into production, a year's\nexperience has allowed DPLA and its partners to identify limitations to that\nsystem, the quality and scalability of metadata remediation and enhancement\npossible, and areas for collaboration and leadership across the partnership.\nAlthough improved infrastructure is needed to support aggregation at this scale\nand complexity, ultimately DPLA needs to balance responsibilities across the\npartnership and establish a strong community that shares ownership of the\naggregation process.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 21:10:09 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Matienzo", "Mark A.", "", "Digital Public Library of\n  America"], ["Rudersdorf", "Amy", "", "Digital Public Library of\n  America"]]}, {"id": "1408.2123", "submitter": "Alexander Konovalov", "authors": "Sylwester Arabas, Michael R. Bareford, Lakshitha R. de Silva, Ian P.\n  Gent, Benjamin M. Gorman, Masih Hajiarabderkani, Tristan Henderson, Luke\n  Hutton, Alexander Konovalov, Lars Kotthoff, Ciaran McCreesh, Miguel A.\n  Nacenta, Ruma R. Paul, Karen E. J. Petrie, Abdul Razaq, Dani\\\"el Reijsbergen,\n  Kenji Takeda", "title": "Case Studies and Challenges in Reproducibility in the Computational\n  Sciences", "comments": "This paper was written at the First Summer School on Experimental\n  Methodology in Computational Science Research, St Andrews, August 4-8, 2014,\n  http://blogs.cs.st-andrews.ac.uk/emcsr2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the reproducibility of computational science research\nand identifies key challenges facing the community today. It is the result of\nthe First Summer School on Experimental Methodology in Computational Science\nResearch (https://blogs.cs.st-andrews.ac.uk/emcsr2014/).\n  First, we consider how to reproduce experiments that involve human subjects,\nand in particular how to deal with different ethics requirements at different\ninstitutions. Second, we look at whether parallel and distributed computational\nexperiments are more or less reproducible than serial ones. Third, we consider\nreproducible computational experiments from fields outside computer science.\nOur final case study looks at whether reproducibility for one researcher is the\nsame as for another, by having an author attempt to have others reproduce their\nown, reproducible, paper.\n  This paper is open, executable and reproducible: the whole process of writing\nthis paper is captured in the source control repository hosting both the source\nof the paper, supplementary codes and data; we are providing setup for several\nexperiments on which we were working; finally, we try to describe what we have\nachieved during the week of the school in a way that others may reproduce (and\nhopefully improve) our experiments.\n", "versions": [{"version": "v1", "created": "Sat, 9 Aug 2014 15:12:11 GMT"}, {"version": "v2", "created": "Thu, 11 Sep 2014 22:01:57 GMT"}], "update_date": "2014-09-15", "authors_parsed": [["Arabas", "Sylwester", ""], ["Bareford", "Michael R.", ""], ["de Silva", "Lakshitha R.", ""], ["Gent", "Ian P.", ""], ["Gorman", "Benjamin M.", ""], ["Hajiarabderkani", "Masih", ""], ["Henderson", "Tristan", ""], ["Hutton", "Luke", ""], ["Konovalov", "Alexander", ""], ["Kotthoff", "Lars", ""], ["McCreesh", "Ciaran", ""], ["Nacenta", "Miguel A.", ""], ["Paul", "Ruma R.", ""], ["Petrie", "Karen E. J.", ""], ["Razaq", "Abdul", ""], ["Reijsbergen", "Dani\u00ebl", ""], ["Takeda", "Kenji", ""]]}, {"id": "1408.2468", "submitter": "Christoph Lange", "authors": "Jeremy Debattista and Christoph Lange and S\\\"oren Auer", "title": "Representing Dataset Quality Metadata using Multi-Dimensional Views", "comments": "Preprint of a paper submitted to the forthcoming SEMANTiCS 2014, 4-5\n  September 2014, Leipzig, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quality is commonly defined as fitness for use. The problem of\nidentifying quality of data is faced by many data consumers. Data publishers\noften do not have the means to identify quality problems in their data. To make\nthe task for both stakeholders easier, we have developed the Dataset Quality\nOntology (daQ). daQ is a core vocabulary for representing the results of\nquality benchmarking of a linked dataset. It represents quality metadata as\nmulti-dimensional and statistical observations using the Data Cube vocabulary.\nQuality metadata are organised as a self-contained graph, which can, e.g., be\nembedded into linked open datasets. We discuss the design considerations, give\nexamples for extending daQ by custom quality metrics, and present use cases\nsuch as analysing data versions, browsing datasets by quality, and link\nidentification. We finally discuss how data cube visualisation tools enable\ndata publishers and consumers to analyse better the quality of their data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 17:00:40 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Debattista", "Jeremy", ""], ["Lange", "Christoph", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "1408.2946", "submitter": "Michael Schreiber", "authors": "Michael Schreiber", "title": "How to improve the outcome of performance evaluations in terms of\n  percentiles for citation frequencies of my papers", "comments": "8 pages, 3 figures, 5 tables", "journal-ref": "Journal of Informetrics 8, 873-879 (2014)", "doi": "10.1016/j.joi.2014.09.002", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Using empirical data I demonstrate that the result of performance evaluations\nby percentiles can be drastically influenced by the proper choice of the\njournal in which a manuscript is published.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 08:51:18 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Schreiber", "Michael", ""]]}, {"id": "1408.2970", "submitter": "Sophia Rachel Goldberg", "authors": "S.R. Goldberg, H. Anthony and T.S. Evans", "title": "Modelling Citation Networks", "comments": "29 pages, 22 figures", "journal-ref": "Scientometrics 105 (2015) 1577-1604", "doi": "10.1007/s11192-015-1737-9", "report-no": "Imperial/TP/14/TSE/2", "categories": "physics.soc-ph cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of the number of academic publications as a function of\ncitation count for a given year is remarkably similar from year to year. We\nmeasure this similarity as a width of the distribution and find it to be\napproximately constant from year to year. We show that simple citation models\nfail to capture this behaviour. We then provide a simple three parameter\ncitation network model using a mixture of local and global search processes\nwhich can reproduce the correct distribution over time. We use the citation\nnetwork of papers from the hep-th section of arXiv to test our model. For this\ndata, around 20% of citations use global information to reference recently\npublished papers, while the remaining 80% are found using local searches. We\nnote that this is consistent with other studies though our motivation is very\ndifferent from previous work. Finally, we also find that the fluctuations in\nthe size of an academic publication's bibliography is important for the model.\nThis is not addressed in most models and needs further work.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 10:53:55 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Goldberg", "S. R.", ""], ["Anthony", "H.", ""], ["Evans", "T. S.", ""]]}, {"id": "1408.3297", "submitter": "Petra Isenberg", "authors": "Petra Isenberg (INRIA Saclay - Ile de France), Tobias Isenberg (INRIA\n  Saclay - Ile de France), Michael Sedlmair, Jian Chen, Torsten M\\\"oller", "title": "Toward a deeper understanding of Visualization through keyword analysis", "comments": null, "journal-ref": null, "doi": "10.1109/TVCG.2016.2598827", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results of a comprehensive analysis of visualization paper\nkeywords supplied for 4366 papers submitted to five main visualization\nconferences. We describe main keywords, topic areas, and 10-year historic\ntrends from two datasets: (1) the standardized PCS taxonomy keywords in use for\npaper submissions for IEEE InfoVis, IEEE Vis-SciVis, IEEE VAST, EuroVis, and\nIEEE PacificVis since 2009 and (2) the author-chosen keywords for papers\npublished in the IEEE Visualization conference series (now called IEEE VIS)\nsince 2004. Our analysis of research topics in visualization can serve as a\nstarting point to (a) help create a common vocabulary to improve communication\namong different visualization sub-groups, (b) facilitate the process of\nunderstanding differences and commonalities of the various research sub-fields\nin visualization, (c) provide an understanding of emerging new research trends,\n(d) facilitate the crucial step of finding the right reviewers for research\nsubmissions, and (e) it can eventually lead to a comprehensive taxonomy of\nvisualization research. One additional tangible outcome of our work is an\napplication that allows visualization researchers to easily browse the 2600+\nkeywords used for IEEE VIS papers during the past 10 years, aiming at more\ninformed and, hence, more effective keyword selections for future visualization\npublications.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 07:21:04 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Isenberg", "Petra", "", "INRIA Saclay - Ile de France"], ["Isenberg", "Tobias", "", "INRIA\n  Saclay - Ile de France"], ["Sedlmair", "Michael", ""], ["Chen", "Jian", ""], ["M\u00f6ller", "Torsten", ""]]}, {"id": "1408.3455", "submitter": "Hua-Wei Shen", "authors": "Hua-Wei Shen and Albert-L\\'aszl\\'o Barab\\'asi", "title": "Collective credit allocation in science", "comments": "7 pages, 4 figures, 1 table, appears in Proceedings of the National\n  Academy of Sciences of the United States of America, 2014", "journal-ref": null, "doi": "10.1073/pnas.1401992111", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaboration among researchers is an essential component of the modern\nscientific enterprise, playing a particularly important role in\nmultidisciplinary research. However, we continue to wrestle with allocating\ncredit to the coauthors of publications with multiple authors, since the\nrelative contribution of each author is difficult to determine. At the same\ntime, the scientific community runs an informal field-dependent credit\nallocation process that assigns credit in a collective fashion to each work.\nHere we develop a credit allocation algorithm that captures the coauthors'\ncontribution to a publication as perceived by the scientific community,\nreproducing the informal collective credit allocation of science. We validate\nthe method by identifying the authors of Nobel-winning papers that are credited\nfor the discovery, independent of their positions in the author list. The\nmethod can also compare the relative impact of researchers working in the same\nfield, even if they did not publish together. The ability to accurately measure\nthe relative credit of researchers could affect many aspects of credit\nallocation in science, potentially impacting hiring, funding, and promotion\ndecisions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 01:21:16 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Shen", "Hua-Wei", ""], ["Barab\u00e1si", "Albert-L\u00e1szl\u00f3", ""]]}, {"id": "1408.3863", "submitter": "Christoph Lange", "authors": "Christoph Lange and Angelo Di Iorio", "title": "Semantic Publishing Challenge -- Assessing the Quality of Scientific\n  Output", "comments": "To appear in: Valentina Presutti and Milan Stankovic and Erik Cambria\n  and Reforgiato Recupero, Diego and Di Iorio, Angelo and Christoph Lange and\n  Di Noia, Tommaso and Ivan Cantador (eds.). Semantic Web Evaluation Challenges\n  2014. Number 457 in Communications in Computer and Information Science,\n  Springer, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linked Open Datasets about scholarly publications enable the development and\nintegration of sophisticated end-user services; however, richer datasets are\nstill needed. The first goal of this Challenge was to investigate novel\napproaches to obtain such semantic data. In particular, we were seeking methods\nand tools to extract information from scholarly publications, to publish it as\nLOD, and to use queries over this LOD to assess quality. This year we focused\non the quality of workshop proceedings, and of journal articles w.r.t. their\ncitation network. A third, open task, asked to showcase how such semantic data\ncould be exploited and how Semantic Web technologies could help in this\nemerging context.\n", "versions": [{"version": "v1", "created": "Sun, 17 Aug 2014 21:33:10 GMT"}, {"version": "v2", "created": "Wed, 20 Aug 2014 22:23:41 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Lange", "Christoph", ""], ["Di Iorio", "Angelo", ""]]}, {"id": "1408.3881", "submitter": "Ognjen Arandjelovi\\'c PhD", "authors": "Ognjen Arandjelovic", "title": "Fairer citation-based metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe a simple modification which can be applied to any citation\ncount-based index (e.g. Hirsch's h-index) quantifying a researcher's\npublication output. The key idea behind the proposed approach is that the merit\nfor the citations of a paper should be distributed amongst its authors\naccording to their relative contributions. In addition to producing inherently\nfairer metrics I show that the proposed modification has the potential to\npartially normalize for the unfair effects of honorary authorship and thus\ndiscourage this practice.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 01:35:56 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Arandjelovic", "Ognjen", ""]]}, {"id": "1408.4440", "submitter": "Philipp Mayr", "authors": "Philipp Mayr", "title": "Are topic-specific search term, journal name and author name\n  recommendations relevant for researchers?", "comments": "4 pages, 1 figure, research paper accepted at EuroHCIR 2014 workshop\n  in London. arXiv admin note: text overlap with arXiv:1101.1637", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a case study where researchers in the social\nsciences (n=19) assess topical relevance for controlled search terms, journal\nnames and author names which have been compiled automatically by\nbibliometric-enhanced information retrieval (IR) services. We call these\nbibliometric-enhanced IR services Search Term Recommender (STR), Journal Name\nRecommender (JNR) and Author Name Recommender (ANR) in this paper. The\nresearchers in our study (practitioners, PhD students and postdocs) were asked\nto assess the top n pre-processed recommendations from each recommender for\nspecific research topics which have been named by them in an interview before\nthe experiment. Our results show clearly that the presented search term,\njournal name and author name recommendations are highly relevant to the\nresearchers' topic and can easily be integrated for search in Digital\nLibraries. The average precision for top ranked recommendations is 0.75 for\nauthor names, 0.74 for search terms and 0.73 for journal names. The relevance\ndistribution differs largely across topics and researcher types. Practitioners\nseem to favor author name recommendations while postdocs have rated author name\nrecommendations the lowest. In the experiment the small postdoc group (n=3)\nfavor journal name recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 19:39:57 GMT"}, {"version": "v2", "created": "Sun, 31 Aug 2014 18:57:58 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Mayr", "Philipp", ""]]}, {"id": "1408.5001", "submitter": "Wilko van Hoek", "authors": "Wilko van Hoek and Philipp Mayr", "title": "Is Evaluating Visual Search Interfaces in Digital Libraries Still an\n  Issue?", "comments": "10 pages, 2 figures, LWA Workshop 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although various visual interfaces for digital libraries have been developed\nin prototypical systems, very few of these visual approaches have been\nintegrated into today's digital libraries. In this position paper we argue that\nthis is most likely due to the fact that the evaluation results of most visual\nsystems lack comparability. There is no fix standard on how to evaluate visual\ninteractive user interfaces. Therefore it is not possible to identify which\napproach is more suitable for a certain context. We feel that the comparability\nof evaluation results could be improved by building a common evaluation setup\nconsisting of a reference system, based on a standardized corpus with fixed\ntasks and a panel for possible participants.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 13:31:40 GMT"}, {"version": "v2", "created": "Wed, 1 Oct 2014 08:01:54 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["van Hoek", "Wilko", ""], ["Mayr", "Philipp", ""]]}, {"id": "1408.5700", "submitter": "Lorna Wildgaard", "authors": "Lorna Wildgaard, Jesper W. Schneider, Birger Larsen", "title": "A review of the characteristics of 108 author-level bibliometric\n  indicators", "comments": "to be published in Scientometrics, 2014", "journal-ref": null, "doi": "10.1007/s11192-014-1423-3", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing demand for bibliometric assessment of individuals has led to a\ngrowth of new bibliometric indicators as well as new variants or combinations\nof established ones. The aim of this review is to contribute with objective\nfacts about the usefulness of bibliometric indicators of the effects of\npublication activity at the individual level. This paper reviews 108 indicators\nthat can potentially be used to measure performance on the individual author\nlevel, and examines the complexity of their calculations in relation to what\nthey are supposed to reflect and ease of end-user application.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 09:36:08 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Wildgaard", "Lorna", ""], ["Schneider", "Jesper W.", ""], ["Larsen", "Birger", ""]]}, {"id": "1408.5893", "submitter": "Lutz Bornmann Dr.", "authors": "Werner Marx, Lutz Bornmann", "title": "On the causes of subject-specific citation rates in Web of Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known in bibliometrics that the average number of citations per\npaper differs greatly between the various disciplines. The differing citation\nculture (in particular the different average number of references per paper and\nthereby the different probability of being cited) is widely seen as the cause\nof this variation. Based on all Web of Science (WoS) records published in 1990,\n1995, 2000, 2005, and 2010 we demonstrate that almost all disciplines show\nsimilar numbers of references in the appendices of their papers. Our results\nsuggest that the average citation rate is far more influenced by the extent to\nwhich the papers (cited as references) are included in WoS as linked database\nrecords. For example, the comparatively low citation rates in the humanities\nare not at all the result of a lower average number of references per paper but\nare caused by the low fraction of linked references which refer to papers\npublished in the core journals covered by WoS.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 12:28:59 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Marx", "Werner", ""], ["Bornmann", "Lutz", ""]]}, {"id": "1408.6126", "submitter": "Jacopo Pellegrino", "authors": "Jacopo Pellegrino", "title": "A Multi-agent Based Digital Preservation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Master's Degree Thesis: Department of Physics, University of Turin\n  Supervisor: Prof. Marco Maggiora, Department of Physics, University of Turin;\nemail: marco.maggiora@unito.it\n  Co-Supervisor: Prof. Walter Allasia, Innovation Department, EURIX; email:\nallasia@eurix.it\n  The thesis describes an agent-based model aimed to simulate those processes\nin which a digital object faces the risk of obsolescence, a migration process\nhas to be performed and the most appropriate file format has to be adopted.\nAgents have been designed in order to monitor and control the local system\nwhere they reside and its environment. They are able to become aware of\nobsolescent formats based on global parameters such as their diffusion. They\ncommunicate as well with each other to find out the most suitable preservation\naction to be performed. Agents request suggestions that are evaluated and\npropagated according to a weighting based on the level of trust assigned to\nboth the agents who identified the problem and proposed the solution. In the\ncurrent research, the definition of the trust level has been chosen based on\nthe cultural and geographical distances, the expertise of the involved agents\nand the file format numerosity. The level of trust between two agents is\nautomatically updated after every interaction by the mean of a feedback\nmechanism profiting of an inter agent communication based on stigmergy. Summing\nup, the thesis demonstrates how a multi-agent system can either perform an\nautonomous preservation action or suggest a list of best candidate solutions to\nthe user. It benefits the management of several kinds of digital archive,\nespecially those with limited resources specifically dedicated to digital\npreservation, such as small personal collections and many public institutions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 14:23:53 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 17:22:14 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Pellegrino", "Jacopo", ""]]}, {"id": "1408.6438", "submitter": "Eisa Alanazi", "authors": "Eisa Alanazi", "title": "A Note on the Ranking of Saudi Arabian Universities based on\n  highlycited.com", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Thomson Reuters has published its 2014 list of highly cited\nresearchers (HCRs)[1]. Initial studies over the list [2] suggested that some\nuniversities (for instance, King Abdulaziz University in Saudi Arabia) may have\nbeen manipulating its world ranking by contracting with highly cited\nresearchers. In this work, we analyse the ranking of other Saudi universities\nbased solely on the list. Our analysis suggests that other universities in\nSaudi Arabia do not follow the steps of King Abdulaziz University when it comes\nto contracting with HCRs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 00:45:19 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Alanazi", "Eisa", ""]]}, {"id": "1408.6806", "submitter": "Nikita Zhiltsov", "authors": "Alexander Elizarov and Alexander Kirillovich and Evgeny Lipachev and\n  Olga Nevzorova and Valery Solovyev and Nikita Zhiltsov", "title": "Mathematical Knowledge Representation: Semantic Models and Formalisms", "comments": "10 pages, Lobachevskii J. of Mathematics, 2014, V.35, No 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides a survey of semantic methods for solution of fundamental\ntasks in mathematical knowledge management. Ontological models and formalisms\nare discussed. We propose an ontology of mathematical knowledge, covering a\nwide range of fields of mathematics. We demonstrate applications of this\nrepresentation in mathematical formula search, and learning.\n", "versions": [{"version": "v1", "created": "Thu, 28 Aug 2014 18:47:18 GMT"}, {"version": "v2", "created": "Fri, 29 Aug 2014 07:24:57 GMT"}], "update_date": "2014-09-01", "authors_parsed": [["Elizarov", "Alexander", ""], ["Kirillovich", "Alexander", ""], ["Lipachev", "Evgeny", ""], ["Nevzorova", "Olga", ""], ["Solovyev", "Valery", ""], ["Zhiltsov", "Nikita", ""]]}]