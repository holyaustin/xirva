[{"id": "0807.0023", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez, Johan Bollen, Herbert Van de Sompel", "title": "Automatic Metadata Generation using Associative Networks", "comments": null, "journal-ref": "ACM Transactions on Information Systems, volume 27, number 2,\n  pages 1-20, ISSN: 1046-8188, ACM Press, February 2009", "doi": "10.1145/1462198.1462199", "report-no": "LA-UR-06-3445", "categories": "cs.IR cs.DL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In spite of its tremendous value, metadata is generally sparse and\nincomplete, thereby hampering the effectiveness of digital information\nservices. Many of the existing mechanisms for the automated creation of\nmetadata rely primarily on content analysis which can be costly and\ninefficient. The automatic metadata generation system proposed in this article\nleverages resource relationships generated from existing metadata as a medium\nfor propagation from metadata-rich to metadata-poor resources. Because of its\nindependence from content analysis, it can be applied to a wide variety of\nresource media types and is shown to be computationally inexpensive. The\nproposed method operates through two distinct phases. Occurrence and\nco-occurrence algorithms first generate an associative network of repository\nresources leveraging existing repository metadata. Second, using the\nassociative network as a substrate, metadata associated with metadata-rich\nresources is propagated to metadata-poor resources by means of a discrete-form\nspreading activation algorithm. This article discusses the general framework\nfor building associative networks, an algorithm for disseminating metadata\nthrough such networks, and the results of an experiment and validation of the\nproposed method using a standard bibliographic dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2008 21:23:28 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2009 01:20:48 GMT"}], "update_date": "2009-03-07", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Bollen", "Johan", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "0807.0967", "submitter": "Raffaele D'Abrusco", "authors": "M. Brescia, S. Cavuoti, G. D'Angelo, R. D'Abrusco, C. Donalek, N.\n  Deniskina, O. Laurino, G. Longo", "title": "Astrophysics in S.Co.P.E", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  S.Co.P.E. is one of the four projects funded by the Italian Government in\norder to provide Southern Italy with a distributed computing infrastructure for\nfundamental science. Beside being aimed at building the infrastructure,\nS.Co.P.E. is also actively pursuing research in several areas among which\nastrophysics and observational cosmology. We shortly summarize the most\nsignificant results obtained in the first two years of the project and related\nto the development of middleware and Data Mining tools for the Virtual\nObservatory.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2008 08:38:00 GMT"}], "update_date": "2008-07-08", "authors_parsed": [["Brescia", "M.", ""], ["Cavuoti", "S.", ""], ["D'Angelo", "G.", ""], ["D'Abrusco", "R.", ""], ["Donalek", "C.", ""], ["Deniskina", "N.", ""], ["Laurino", "O.", ""], ["Longo", "G.", ""]]}, {"id": "0807.1182", "submitter": "R. Alexander Bentley", "authors": "R. Alexander Bentley", "title": "Random drift versus selection in academic vocabulary: an evolutionary\n  analysis of published keywords", "comments": "9 pages, 4 figures", "journal-ref": "PLoS ONE, 3 (2008) e3057", "doi": "10.1371/journal.pone.0003057", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of vocabulary in academic publishing is characterized via\nkeyword frequencies recorded the ISI Web of Science citations database. In four\ndistinct case-studies, evolutionary analysis of keyword frequency change\nthrough time is compared to a model of random copying used as the null\nhypothesis, such that selection may be identified against it. The case studies\nfrom the physical sciences indicate greater selection in keyword choice than in\nthe social sciences. Similar evolutionary analyses can be applied to a wide\nrange of phenomena; wherever the popularity of multiple items through time has\nbeen recorded, as with web searches, or sales of popular music and books, for\nexample.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2008 07:05:01 GMT"}], "update_date": "2009-02-18", "authors_parsed": [["Bentley", "R. Alexander", ""]]}, {"id": "0807.2678", "submitter": "Philip Davis", "authors": "Philip M. Davis", "title": "Eigenfactor : Does the Principle of Repeated Improvement Result in\n  Better Journal Impact Estimates than Raw Citation Counts?", "comments": "bibliographic information corrected", "journal-ref": "Journal of the American Society for Information Science &\n  Technology (2008) v59 n12 p.2186-2188", "doi": "10.1002/asi.20943", "report-no": null, "categories": "cs.DL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigenfactor.org, a journal evaluation tool which uses an iterative algorithm\nto weight citations (similar to the PageRank algorithm used for Google) has\nbeen proposed as a more valid method for calculating the impact of journals.\nThe purpose of this brief communication is to investigate whether the principle\nof repeated improvement provides different rankings of journals than does a\nsimple unweighted citation count (the method used by ISI).\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2008 01:01:59 GMT"}, {"version": "v2", "created": "Tue, 29 Jul 2008 19:35:25 GMT"}, {"version": "v3", "created": "Mon, 27 Oct 2008 19:16:39 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Davis", "Philip M.", ""]]}, {"id": "0807.3755", "submitter": "Martin Klein", "authors": "Martin Klein, Michael L. Nelson", "title": "Approximating Document Frequency with Term Count Values", "comments": "11 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For bounded datasets such as the TREC Web Track (WT10g) the computation of\nterm frequency (TF) and inverse document frequency (IDF) is not difficult.\nHowever, when the corpus is the entire web, direct IDF calculation is\nimpossible and values must instead be estimated. Most available datasets\nprovide values for term count (TC) meaning the number of times a certain term\noccurs in the entire corpus. Intuitively this value is different from document\nfrequency (DF), the number of documents (e.g., web pages) a certain term occurs\nin. We conduct a comparison study between TC and DF values within the Web as\nCorpus (WaC). We found a very strong correlation with Spearman's rho >0.8\n(p<0.005) which makes us confident in claiming that for such recently created\ncorpora the TC and DF values can be used interchangeably to compute IDF values.\nThese results are useful for the generation of accurate lexical signatures\nbased on the TF-IDF scheme.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2008 21:44:46 GMT"}], "update_date": "2008-07-25", "authors_parsed": [["Klein", "Martin", ""], ["Nelson", "Michael L.", ""]]}, {"id": "0807.3908", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez", "title": "A Distributed Process Infrastructure for a Distributed Data Structure", "comments": "written as a column for the Semantic Web and Information Systems\n  Bulletin, AIS Special Interest Group on Semantic Web and Information Systems\n  (SIGSEMIS), ISSN: 1556-2301", "journal-ref": null, "doi": null, "report-no": "LA-UR-08-04138", "categories": "cs.AI cs.DL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The Resource Description Framework (RDF) is continuing to grow outside the\nbounds of its initial function as a metadata framework and into the domain of\ngeneral-purpose data modeling. This expansion has been facilitated by the\ncontinued increase in the capacity and speed of RDF database repositories known\nas triple-stores. High-end RDF triple-stores can hold and process on the order\nof 10 billion triples. In an effort to provide a seamless integration of the\ndata contained in RDF repositories, the Linked Data community is providing\nspecifications for linking RDF data sets into a universal distributed graph\nthat can be traversed by both man and machine. While the seamless integration\nof RDF data sets is important, at the scale of the data sets that currently\nexist and will ultimately grow to become, the \"download and index\" philosophy\nof the World Wide Web will not so easily map over to the Semantic Web. This\nessay discusses the importance of adding a distributed RDF process\ninfrastructure to the current distributed RDF data structure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2008 15:16:16 GMT"}], "update_date": "2008-07-25", "authors_parsed": [["Rodriguez", "Marko A.", ""]]}]