[{"id": "1508.01134", "submitter": "Maciej Mrowinski", "authors": "Maciej J. Mrowinski, Agata Fronczak, Piotr Fronczak, Olgica Nedic,\n  Marcel Ausloos", "title": "Review times in peer review: quantitative analysis of editorial\n  workflows", "comments": null, "journal-ref": "Scientometrics 107 (2016) 271-286", "doi": "10.1007/s11192-016-1871-z", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine selected aspects of peer review and suggest possible improvements.\nTo this end, we analyse a dataset containing information about 300 papers\nsubmitted to the Biochemistry and Biotechnology section of the Journal of the\nSerbian Chemical Society. After separating the peer review process into stages\nthat each review has to go through, we use a weighted directed graph to\ndescribe it in a probabilistic manner and test the impact of some modifications\nof the editorial policy on the efficiency of the whole process.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 17:11:14 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Mrowinski", "Maciej J.", ""], ["Fronczak", "Agata", ""], ["Fronczak", "Piotr", ""], ["Nedic", "Olgica", ""], ["Ausloos", "Marcel", ""]]}, {"id": "1508.02179", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann and Robin Haunschild", "title": "t factor: A metric for measuring impact on Twitter", "comments": "URL: http://e-journal.um.edu.my/public/article-view.php?id=9398", "journal-ref": "Malaysian Journal of Library & Information Science, 21(2) (2015)", "doi": "10.22452/mjlis.vol21no2.2", "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the definition of the well-known h index we propose a t factor for\nmeasuring the impact of publications (and other entities) on Twitter. The new\nindex combines tweet and retweet data in a balanced way whereby retweets are\nseen as data reflecting the impact of initial tweets. The t factor is defined\nas follows: A unit (single publication, journal, researcher, research group\netc.) has factor t if t of its Nt tweets have at least t retweets each and the\nother (Nt-t) tweets have <=t retweets each.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 09:23:46 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 08:04:34 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""]]}, {"id": "1508.02315", "submitter": "Justin F Brunelle", "authors": "Justin F. Brunelle, Michele C. Weigle, and Michael L. Nelson", "title": "Archiving Deferred Representations Using a Two-Tiered Crawling Approach", "comments": "To appear at iPRES2015 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web resources are increasingly interactive, resulting in resources that are\nincreasingly difficult to archive. The archival difficulty is based on the use\nof client-side technologies (e.g., JavaScript) to change the client-side state\nof a representation after it has initially loaded. We refer to these\nrepresentations as deferred representations. We can better archive deferred\nrepresentations using tools like headless browsing clients. We use 10,000 seed\nUniversal Resource Identifiers (URIs) to explore the impact of including\nPhantomJS -- a headless browsing tool -- into the crawling process by comparing\nthe performance of wget (the baseline), PhantomJS, and Heritrix. Heritrix\ncrawled 2.065 URIs per second, 12.15 times faster than PhantomJS and 2.4 times\nfaster than wget. However, PhantomJS discovered 531,484 URIs, 1.75 times more\nthan Heritrix and 4.11 times more than wget. To take advantage of the\nperformance benefits of Heritrix and the URI discovery of PhantomJS, we\nrecommend a tiered crawling strategy in which a classifier predicts whether a\nrepresentation will be deferred or not, and only resources with deferred\nrepresentations are crawled with PhantomJS while resources without deferred\nrepresentations are crawled with Heritrix. We show that this approach is 5.2\ntimes faster than using only PhantomJS and creates a frontier (set of URIs to\nbe crawled) 1.8 times larger than using only Heritrix.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 16:39:18 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Brunelle", "Justin F.", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "1508.03713", "submitter": "Selcuk Bilir", "authors": "S. Bilir, E. Gogus, O. Onal Tas, T. Yontan", "title": "A New Ranking Scheme for the Institutional Scientific Performance", "comments": "12 pages, 3 figures and 2 tables, accepted for publication in Journal\n  of Scientometric Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new performance indicator to evaluate the productivity of\nresearch institutions by their disseminated scientific papers. The new quality\nmeasure includes two principle components: the normalized impact factor of the\njournal in which paper was published, and the number of citations received per\nyear since it was published. In both components, the scientific impacts are\nweighted by the contribution of authors from the evaluated institution. As a\nwhole, our new metric, namely, the institutional performance score takes into\naccount both journal based impact and articles specific impacts. We apply this\nnew scheme to evaluate research output performance of Turkish institutions\nspecialized in astronomy and astrophysics in the period of 1998-2012. We\ndiscuss the implications of the new metric, and emphasize the benefits of it\nalong with comparison to other proposed institutional performance indicators.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2015 09:08:31 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Bilir", "S.", ""], ["Gogus", "E.", ""], ["Tas", "O. Onal", ""], ["Yontan", "T.", ""]]}, {"id": "1508.03950", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Moritz Stefaner, Felix de Moya Anegon, and Ruediger\n  Mutz", "title": "Excellence networks in science: A Web-based application based on\n  Bayesian multilevel logistic regression (BMLR) for the identification of\n  institutions collaborating successfully", "comments": "accepted for publication in the Journal of Informetrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we present an application which can be accessed via\nwww.excellence-networks.net and which represents networks of scientific\ninstitutions worldwide. The application is based on papers (articles, reviews\nand conference papers) published between 2007 and 2011. It uses (network) data,\non which the SCImago Institutions Ranking is based (Scopus data from Elsevier).\nUsing this data, institutional networks have been estimated with statistical\nmodels (Bayesian multilevel logistic regression, BMLR) for a number of Scopus\nsubject areas. Within single subject areas, we have investigated and visualized\nhow successfully overall an institution (reference institution) has\ncollaborated (compared to all the other institutions in a subject area), and\nwith which other institutions (network institutions) a reference institution\nhas collaborated particularly successfully. The \"best paper rate\"\n(statistically estimated) was used as an indicator for evaluating the\ncollaboration success of an institution. This gives the proportion of highly\ncited papers from an institution, and is considered generally as an indicator\nfor measuring impact in bibliometrics.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 08:39:02 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2015 11:51:49 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 16:01:58 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2016 07:36:53 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Bornmann", "Lutz", ""], ["Stefaner", "Moritz", ""], ["Anegon", "Felix de Moya", ""], ["Mutz", "Ruediger", ""]]}, {"id": "1508.04347", "submitter": "Fran\\c{c}ois Renaville", "authors": "Fran\\c{c}ois Renaville, Yosef Branse, Xiaotian Chen, Mark Needleman", "title": "SFX Miscellaneous Free Ejournals Target: Usage Survey among the SFX\n  Community", "comments": null, "journal-ref": "Serials Review 41 (2015) 58-68", "doi": "10.1080/00987913.2015.1031317", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The number of free or open access articles is increasing rapidly, and their\nretrieval with library indexes and OpenURL link resolvers has been a challenge.\nIn June 2014, the SFX MISCELLANEOUS FREE EJOURNALS target contained more than\n24,000 portfolios of all kinds. The SFX Knowledge Base Advisory Board (KBAB)\ncarried out an international survey to get an overview of the usage of this\ntarget by the SFX community and to precisely identify what could be done to\nimprove it. The target is widely used among the community. However, many\nrespondents complained about three major problems: (a) incorrect links, (b)\nfull texts actually not free, and (c) incorrect or missing thresholds (years\nand volumes information).\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 15:20:39 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Renaville", "Fran\u00e7ois", ""], ["Branse", "Yosef", ""], ["Chen", "Xiaotian", ""], ["Needleman", "Mark", ""]]}, {"id": "1508.04977", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn", "title": "nanopub-java: A Java Library for Nanopublications", "comments": "Proceedings of 5th Workshop on Linked Science 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of nanopublications was first proposed about six years ago, but\nit lacked openly available implementations. The library presented here is the\nfirst one that has become an official implementation of the nanopublication\ncommunity. Its core features are stable, but it also contains unofficial and\nexperimental extensions: for publishing to a decentralized server network, for\ndefining sets of nanopublications with indexes, for informal assertions, and\nfor digitally signing nanopublications. Most of the features of the library can\nalso be accessed via an online validator interface.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 13:32:20 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Kuhn", "Tobias", ""]]}, {"id": "1508.05624", "submitter": "Marcel Ausloos", "authors": "Marcel Ausloos, Olgica Nedic, Agata Fronczak, and Piotr Fronczak", "title": "Quantifying the quality of peer reviewers through Zipf's law", "comments": "28 pages; 8 Tables; 9 Figures; 39 references; prepared for and to be\n  published in Scientometrics", "journal-ref": "Scientometrics 106 (2016) 347-368", "doi": "10.1007/s11192-015-1704-5", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a statistical and other analysis of peer reviewers in\norder to approach their \"quality\" through some quantification measure, thereby\nleading to some quality metrics. Peer reviewer reports for the Journal of the\nSerbian Chemical Society are examined. The text of each report has first to be\nadapted to word counting software in order to avoid jargon inducing confusion\nwhen searching for the word frequency: e.g. C must be distinguished, depending\nif it means Carbon or Celsius, etc. Thus, every report has to be carefully\n\"rewritten\". Thereafter, the quantity, variety and distribution of words are\nexamined in each report and compared to the whole set. Two separate months,\naccording when reports came in, are distinguished to observe any possible\nhidden spurious effects. Coherence is found. An empirical distribution is\nsearched for through a Zipf-Pareto rank-size law. It is observed that peer\nreview reports are very far from usual texts in this respect. Deviations from\nthe usual (first) Zipf's law are discussed. A theoretical suggestion for the\n\"best (or worst) report\" and by extension \"good (or bad) reviewer\", within this\ncontext, is provided from an entropy argument, through the concept of \"distance\nto average\" behavior. Another entropy-based measure also allows to measure the\njournal reviews (whence reviewers) for further comparison with other journals\nthrough their own reviewer reports.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 15:49:52 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Ausloos", "Marcel", ""], ["Nedic", "Olgica", ""], ["Fronczak", "Agata", ""], ["Fronczak", "Piotr", ""]]}, {"id": "1508.06206", "submitter": "Sahar Vahdati", "authors": "Angelo Di Iorio, Christoph Lange, Anastasia Dimou, Sahar Vahdati", "title": "Semantic Publishing Challenge - Assessing the Quality of Scientific\n  Output by Information Extraction and Interlinking", "comments": "To appear in: E. Cabrio and M. Stankovic and M. Dragoni and A.\n  Gangemi and R. Navigli and V. Presutti and D. Garigliotti and A. L. Gentile\n  and A. Nuzzolese and A. Di Iorio and A. Dimou and C. Lange and S. Vahdati and\n  A. Freitas and C. Unger and D. Reforgiato Recupero (eds.). Semantic Web\n  Evaluation Challenges 2015. Communications in Computer and Information\n  Science, Springer, 2015. arXiv admin note: text overlap with arXiv:1408.3863", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Semantic Publishing Challenge series aims at investigating novel\napproaches for improving scholarly publishing using Linked Data technology. In\n2014 we had bootstrapped this effort with a focus on extracting information\nfrom non-semantic publications - computer science workshop proceedings volumes\nand their papers - to assess their quality. The objective of this second\nedition was to improve information extraction but also to interlink the 2014\ndataset with related ones in the LOD Cloud, thus paving the way for\nsophisticated end-user services.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 16:17:24 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Di Iorio", "Angelo", ""], ["Lange", "Christoph", ""], ["Dimou", "Anastasia", ""], ["Vahdati", "Sahar", ""]]}, {"id": "1508.07480", "submitter": "Jes\\'us Tramullas", "authors": "Jes\\'us Tramullas, Ana I. S\\'anchez-Casab\\'on, Piedad Garrido-Picazo", "title": "Studies and analysis of reference management software: a literature\n  review", "comments": "Preprint. Accepted to be published in El Profesional de la\n  Informaci\\'on, 2015. ISSN: 1386-6710", "journal-ref": null, "doi": "10.3145/epi.2015.sep.17", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reference management software is a well-known tool for scientific research\nwork. Since the 1980s, it has been the subject of reviews and evaluations in\nlibrary and information science literature. This paper presents a systematic\nreview of published studies that evaluate reference management software with a\ncomparative approach. The objective is to identify the types, models, and\nevaluation criteria that authors have adopted, in order to determine whether\nthe methods used provide adequate methodological rigor and useful contributions\nto the field of study.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2015 17:26:54 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Tramullas", "Jes\u00fas", ""], ["S\u00e1nchez-Casab\u00f3n", "Ana I.", ""], ["Garrido-Picazo", "Piedad", ""]]}, {"id": "1508.07744", "submitter": "Gilles Louppe", "authors": "Gilles Louppe, Hussein Al-Natsheh, Mateusz Susik, Eamonn Maguire", "title": "Ethnicity sensitive author disambiguation using semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Author name disambiguation in bibliographic databases is the problem of\ngrouping together scientific publications written by the same person,\naccounting for potential homonyms and/or synonyms. Among solutions to this\nproblem, digital libraries are increasingly offering tools for authors to\nmanually curate their publications and claim those that are theirs. Indirectly,\nthese tools allow for the inexpensive collection of large annotated training\ndata, which can be further leveraged to build a complementary automated\ndisambiguation system capable of inferring patterns for identifying\npublications written by the same person. Building on more than 1 million\npublicly released crowdsourced annotations, we propose an automated author\ndisambiguation solution exploiting this data (i) to learn an accurate\nclassifier for identifying coreferring authors and (ii) to guide the clustering\nof scientific publications by distinct authors in a semi-supervised way. To the\nbest of our knowledge, our analysis is the first to be carried out on data of\nthis size and coverage. With respect to the state of the art, we validate the\ngeneral pipeline used in most existing solutions, and improve by: (i) proposing\nphonetic-based blocking strategies, thereby increasing recall; and (ii) adding\nstrong ethnicity-sensitive features for learning a linkage function, thereby\ntailoring disambiguation to non-Western author names whenever necessary.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 09:49:27 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 06:35:55 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Louppe", "Gilles", ""], ["Al-Natsheh", "Hussein", ""], ["Susik", "Mateusz", ""], ["Maguire", "Eamonn", ""]]}]