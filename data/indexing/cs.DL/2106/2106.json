[{"id": "2106.00302", "submitter": "Anastasios Nentidis", "authors": "Anastasios Nentidis, Anastasia Krithara, Grigorios Tsoumakas, Georgios\n  Paliouras", "title": "Harvesting the Public MeSH Note field", "comments": "3 pages, 1 figure, 1 table. Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we report an analysis of the Public MeSH Note field of the\nnew descriptors introduced in the MeSH thesaurus between 2006 and 2020. The aim\nof this analysis was to extract information about the previous status of these\nnew descriptors as Supplementary Concept Records. The Public MeSH Note field\ncontains information in semi-structured text, meant to be read by humans.\nTherefore, we adopted a semi-automated approach, based on regular expressions,\nto extract information from it. In the large majority of cases, we managed to\nminimize the required manual effort for extracting the previous state of a new\ndescriptor as a Supplementary Concept Record. The source code for this analysis\nis openly available on GitHub.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:17:13 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Nentidis", "Anastasios", ""], ["Krithara", "Anastasia", ""], ["Tsoumakas", "Grigorios", ""], ["Paliouras", "Georgios", ""]]}, {"id": "2106.00411", "submitter": "D\\'avid Lupt\\'ak", "authors": "D\\'avid Lupt\\'ak, V\\'it Novotn\\'y, Michal \\v{S}tef\\'anik, and Petr\n  Sojka", "title": "WebMIaS on Docker: Deploying Math-Aware Search in a Single Line of Code", "comments": "Accepted to be published in: Intelligent Computer Mathematics 14th\n  International Conference, CICM 2021, Timisoara, Romania, July 26--31, 2021,\n  Proceedings, Fairouz Kamareddine and Claudio Sacerdotti-Coen (eds.), Lecture\n  Notes in Artificial Intelligence, Springer, Cham, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Math informational retrieval (MIR) search engines are absent in the\nwide-spread production use, even though documents in the STEM fields contain\nmany mathematical formulae, which are sometimes more important than text for\nunderstanding. We have developed and open-sourced the WebMIaS MIR search engine\nthat has been successfully deployed in the European Digital Mathematics Library\n(EuDML). However, its deployment is difficult to automate due to the complexity\nof this task. Moreover, the solutions developed so far to tackle this challenge\nare imperfect in terms of speed, maintenance, and robustness. In this paper, we\nwill describe the virtualization of WebMIaS using Docker that solves all three\nproblems and allows anyone to deploy containerized WebMIaS in a single line of\ncode. The publicly available Docker image will also help the community push the\ndevelopment of math-aware search engines in the ARQMath workshop series.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 11:49:37 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 08:12:37 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lupt\u00e1k", "D\u00e1vid", ""], ["Novotn\u00fd", "V\u00edt", ""], ["\u0160tef\u00e1nik", "Michal", ""], ["Sojka", "Petr", ""]]}, {"id": "2106.00412", "submitter": "Vashti Galpin", "authors": "Vashti Galpin, James Cheney", "title": "Curating Covid-19 data in Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curated scientific databases play an important role in the scientific\nendeavour and support is needed for the significant effort that goes into their\ncreation and maintenance. This demonstration and case study illustrate how\ncuration support has been developed in the Links cross-tier programming\nlanguage, a functional, strongly typed language with language-integrated query\nand support for temporal databases. The chosen case study uses weekly released\nCovid-19 fatality figures from the Scottish government which exhibit updates to\npreviously released data. This data allows the capture and query of update\nprovenance in our prototype. This demonstration will highlight the potential\nfor language-integrated support for curation to simplify and streamline\nprototyping of web-applications in support of scientific databases\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 11:52:59 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Galpin", "Vashti", ""], ["Cheney", "James", ""]]}, {"id": "2106.01083", "submitter": "Kai Li", "authors": "Kai Li, Chenyue Jiao", "title": "The data paper as a socio-linguistic epistemic object: A content\n  analysis on the rhetorical moves used in data paper abstracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The data paper is an emerging academic genre that focuses on the description\nof research data objects. However, there is a lack of empirical knowledge about\nthis rising genre in quantitative science studies, particularly from the\nperspective of its linguistic features. To fill this gap, this research aims to\noffer a first quantitative examination of which rhetorical moves-rhetorical\nunits performing a coherent narrative function-are used in data paper\nabstracts, as well as how these moves are used. To this end, we developed a new\nclassification scheme for rhetorical moves in data paper abstracts by expanding\na well-received system that focuses on English-language research article\nabstracts. We used this expanded scheme to classify and analyze rhetorical\nmoves used in two flagship data journals, Scientific Data and Data in Brief. We\nfound that data papers exhibit a combination of IMRaD- and data-oriented moves\nand that the usage differences between the journals can be largely explained by\njournal policies concerning abstract and paper structure. This research offers\na novel examination of how the data paper, a novel data-oriented knowledge\nrepresentation, is composed, which greatly contributes to a deeper\nunderstanding of data and data publication in the scholarly communication\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 11:35:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Li", "Kai", ""], ["Jiao", "Chenyue", ""]]}, {"id": "2106.01148", "submitter": "Amit Nanavati", "authors": "Nishit Narang, Manoj Kumar Ganji and Amit Anil Nanavati", "title": "Your Tribe Decides Your Vibe: Analyzing Local Popularity in the US\n  Patent Citation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many networks, the indegree of a vertex is a measure of its popularity.\nPast research has studied indegree distributions treating the network as a\nwhole. In the US Patent citation network (USPCN), patents are classified into\ncategories and subcategories. A natural question arises: How do patents gather\ntheir popularity from various (sub)categories? We analyse local indegree\ndistributions to answer this question.\n  The citation (indegree) of a patent within the same category indicates its\ninternal popularity, while a cross-category citation indicates its external\npopularity. We analyze the internal and external indegree distributions at each\nlevel of USPCN hierarchy to learn how the internal and external popularity of\npatents varies across (sub)categories.\n  We find that all (sub)categories have local preferences that decide internal\nand external patents' popularities. Different patents are popular in different\ngroups: Groups C1, C2 and C3 may not agree on popular patents in C1. In\ngeneral, patent popularity appears to be a highly local phenomenon with\nsubcategories (not even categories) deciding their own popular patents\nindependent of the other (sub)categories.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 13:39:34 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Narang", "Nishit", ""], ["Ganji", "Manoj Kumar", ""], ["Nanavati", "Amit Anil", ""]]}, {"id": "2106.01232", "submitter": "Kiran Sharma Dr.", "authors": "Parul Khurana, Geetha Ganesan, Gulshan Kumar, Kiran Sharma", "title": "A weighted unified informetrics based on Scopus and WoS", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerous indexing databases keep track of the number of publications,\ncitations, etc. in order to maintain the progress of science and individual.\nHowever, the choice of journals and articles varies among these indexing\ndatabases, hence the number of citations and h-index varies. There is no common\nplatform exists that can provide a single count for the number of publications,\ncitations, h-index, etc. To overcome this limitation, we have proposed a\nweighted unified informetrics, named \"conflate\". The proposed system takes into\naccount the input from multiple indexing databases and generates a single\noutput. Here, we have used the data from Scopus and WoS to generate a conflate\ndataset. Further, a comparative analysis of conflate has been performed with\nScopus and WoS at three levels: author, organization, and journal. Finally, a\nmapping is proposed between research publications and distributed ledger\ntechnology in order to provide a transparent and distributed view to its\nstakeholders.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 15:30:41 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Khurana", "Parul", ""], ["Ganesan", "Geetha", ""], ["Kumar", "Gulshan", ""], ["Sharma", "Kiran", ""]]}, {"id": "2106.01560", "submitter": "Vijay Viswanathan", "authors": "Vijay Viswanathan, Graham Neubig, Pengfei Liu", "title": "CitationIE: Leveraging the Citation Graph for Scientific Information\n  Extraction", "comments": "ACL-IJCNLP 2021 camera-ready (long paper in main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically extracting key information from scientific documents has the\npotential to help scientists work more efficiently and accelerate the pace of\nscientific progress. Prior work has considered extracting document-level entity\nclusters and relations end-to-end from raw scientific text, which can improve\nliterature search and help identify methods and materials for a given problem.\nDespite the importance of this task, most existing works on scientific\ninformation extraction (SciIE) consider extraction solely based on the content\nof an individual paper, without considering the paper's place in the broader\nliterature. In contrast to prior work, we augment our text representations by\nleveraging a complementary source of document context: the citation graph of\nreferential links between citing and cited papers. On a test set of\nEnglish-language scientific documents, we show that simple ways of utilizing\nthe structure and content of the citation graph can each lead to significant\ngains in different scientific information extraction tasks. When these tasks\nare combined, we observe a sizable improvement in end-to-end information\nextraction over the state-of-the-art, suggesting the potential for future work\nalong this direction. We release software tools to facilitate citation-aware\nSciIE development.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 03:00:12 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Viswanathan", "Vijay", ""], ["Neubig", "Graham", ""], ["Liu", "Pengfei", ""]]}, {"id": "2106.01695", "submitter": "Stephan Stahlschmidt", "authors": "Stephan Stahlschmidt, Dimity Stephen", "title": "From indexation policies through citation networks to normalized\n  citation impacts: Web of Science, Scopus, and Dimensions as varying resonance\n  chambers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensions was introduced as an alternative bibliometric database to the\nwell-established Web of Science (WoS) and Scopus, however all three databases\nhave fundamental differences in coverage and content, resultant from their\nowners' indexation philosophies. In light of these differences, we explore\nhere, using a citation network analysis and assessment of normalised citation\nimpact of \"duplicate\" publications, whether the three databases offer\nstructurally different perspectives of the bibliometric landscape or if they\nare essentially homogenous substitutes. Our citation network analysis of core\nand exclusive 2016-2018 publications revealed a large set of core publications\nindexed in all three databases that are highly self-referential. In comparison,\neach database selected a set of exclusive publications that appeared to hold\nsimilarly low levels of relevance to the core set and to one another, with\nslightly more internal communication between exclusive publications in Scopus\nand Dimensions than WoS. Our comparison of normalised citations for 41,848\npublications indexed in all three databases found that German sectors were\nvaluated as more impactful in Scopus and Dimensions compared to WoS,\nparticularly for sectors with an applied research focus. We conclude that the\ndatabases do present structurally different perspectives, although Scopus and\nDimensions with their additional circle of applied research vary more from the\nmore base research-focused WoS than they do from one another.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:53:26 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Stahlschmidt", "Stephan", ""], ["Stephen", "Dimity", ""]]}, {"id": "2106.01781", "submitter": "Ivan Heibi", "authors": "Ivan Heibi, Silvio Peroni", "title": "A protocol to gather, characterize and analyze incoming citations of\n  retracted articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we present a methodology which takes as input a collection\nof retracted articles, gathers the entities citing them, characterizes such\nentities according to multiple dimensions (disciplines, year of publication,\nsentiment, etc.), and applies a quantitative and qualitative analysis on the\ncollected values. The methodology is composed of four phases: (1) identifying,\nretrieving, and extracting basic metadata of the entities which have cited a\nretracted article, (2) extracting and labeling additional features based on the\ntextual content of the citing entities, (3) building a descriptive statistical\nsummary based on the collected data, and finally (4) running a topic modeling\nanalysis. The goal of the methodology is to generate data and visualizations\nthat help understanding possible behaviors related to retraction cases. We\npresent the methodology in a structured step-by-step form following its four\nphases, discuss its limits and possible workarounds, and list the planned\nfuture improvements.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:09:41 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Heibi", "Ivan", ""], ["Peroni", "Silvio", ""]]}, {"id": "2106.02110", "submitter": "Ashkan Ebadi", "authors": "Elva Luz Crespo Neira and Ashkan Ebadi and Catherine Beaudry and\n  Andrea Schiffauerova", "title": "Influence of cognitive, geographical, and collaborative proximity on\n  knowledge production of Canadian nanotechnology", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Incorporating existing knowledge is vital for innovating, discovering, and\ngenerating new ideas. Knowledge production through research and invention is\nthe key to scientific and technological development. As an emerging technology,\nnanotechnology has already proved its great potential for the global economy,\nattracting considerable federal investments. Canada is reported as one of the\nmajor players in producing nanotechnology research. In this paper, we focused\non the main drivers of knowledge production and diffusion by analyzing Canadian\nnanotechnology researchers. We hypothesized that knowledge production in\nCanadian nanotechnology is influenced by three key proximity factors, namely\ncognitive, geographical, and collaborative. Using statistical analysis, social\nnetwork analysis, and machine learning techniques we comprehensively assessed\nthe influence of the proximity factors on academic knowledge production. Our\nresults not only prove a significant impact of the three key proximity factors\nbut also their predictive potential.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:07:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Neira", "Elva Luz Crespo", ""], ["Ebadi", "Ashkan", ""], ["Beaudry", "Catherine", ""], ["Schiffauerova", "Andrea", ""]]}, {"id": "2106.02961", "submitter": "Giovanni Colavizza", "authors": "Giovanni Colavizza", "title": "Meta-research on COVID-19: An overview of the early trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 is having a dramatic impact on research and researchers. The\npandemic has underlined the severity of known challenges in research and\nsurfaced new ones, but also accelerated the adoption of innovations and\nmanifested new opportunities. This review considers early trends emerging from\nmeta-research on COVID-19. In particular, it focuses on the following topics:\ni) mapping COVID-19 research; ii) data and machine learning; iii) research\npractices including open access and open data, reviewing, publishing and\nfunding; iv) communicating research to the public; v) the impact of COVID-19 on\nresearchers, in particular with respect to gender and career trajectories. This\noverview finds that most early meta-research on COVID-19 has been reactive and\nfocused on short-term questions, while more recently a shift to consider the\nlong-term consequences of COVID-19 is taking place. Based on these findings,\nthe author speculates that some aspects of doing research during COVID-19 are\nmore likely to persist than others. These include: the shift to virtual for\nacademic events such as conferences; the use of openly accessible pre-prints;\nthe `datafication' of scholarly literature and consequent broader adoption of\nmachine learning in science communication; the public visibility of research\nand researchers on social and online media.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 20:50:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Colavizza", "Giovanni", ""]]}, {"id": "2106.02989", "submitter": "Huquan Kang", "authors": "Luoyi Fu (1), Huquan Kang (1), Jianghao Wang (2), Ling Yao (2),\n  Xinbing Wang (1), Chenghu Zhou (2) ((1) Shanghai Jiao Tong University, (2)\n  State Key Laboratory of Resources and Environmental Information System,\n  Institute of Geographic Sciences and Natural Resources Research, Chinese\n  Academy of Sciences)", "title": "Exploring the Disproportion Between Scientific Productivity and\n  Knowledge Amount", "comments": "Luoyi Fu and Huquan Kang contribute equally to the work. Xinbing Wang\n  and Chenghu Zhou both are corresponding authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The pursuit of knowledge is the permanent goal of human beings. Scientific\nliterature, as the major medium that carries knowledge between scientists,\nexhibits explosive growth during the last century. Despite the frequent use of\nmany tangible measures, such as citation, impact factor and g-index, to\nquantify the influence of papers from different perspectives based on\nscientific productivity, it has not yet been well understood how the\nrelationship between scientific productivity and knowledge amount turns out to\nbe, i.e., how the knowledge value of papers and knowledge amount vary with\ndevelopment of the discipline. This raises the question of whether high\nscientific productivity equals large knowledge amount. Here, building on rich\nliterature on academic conferences and journals, we collect 185 million\narticles covering 19 disciplines published during 1970 to 2020, and establish\ncitation network research area to represent the knowledge flow from the authors\nof the article being cited to the authors of the articles that cite it under\neach specific area. As a result, the structure formed during the evolution of\neach scientific area can implicitly tells how the knowledge flows between nodes\nand how it behaves as the number of literature (productivity) increases. By\nleveraging Structural entropy in structured high-dimensional space and Shannon\nentropy in unstructured probability space, we propose the Quantitative Index of\nKnowledge (KQI), which is taken as the subtraction between the two types of\nentropy, to reflect the extent of disorder difference (knowledge amount) caused\nby structure (order). With the aid of KQI, we find that, although the published\nliterature shows an explosive growth, the amount of knowledge (KQI) contained\nin it obviously slows down, and there is a threshold after which the growth of\nknowledge accelerates...\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 23:41:58 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 10:03:23 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 09:17:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Fu", "Luoyi", ""], ["Kang", "Huquan", ""], ["Wang", "Jianghao", ""], ["Yao", "Ling", ""], ["Wang", "Xinbing", ""], ["Zhou", "Chenghu", ""]]}, {"id": "2106.04376", "submitter": "Philipp Mayr", "authors": "Thomas Kr\\\"amer, Zeljko Carevic, Dwaipayan Roy, Claus-Peter Klas,\n  Philipp Mayr", "title": "ConSTR: A Contextual Search Term Recommender", "comments": "2 pages, 2 figures, accepted demo paper at JCDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this demo paper, we present ConSTR, a novel Contextual Search Term\nRecommender that utilises the user's interaction context for search term\nrecommendation and literature retrieval. ConSTR integrates a two-layered\nrecommendation interface: the first layer suggests terms with respect to a\nuser's current search term, and the second layer suggests terms based on the\nusers' previous search activities (interaction context). For the demonstration,\nConSTR is built on the arXiv, an academic repository consisting of 1.8 million\ndocuments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:09:59 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Kr\u00e4mer", "Thomas", ""], ["Carevic", "Zeljko", ""], ["Roy", "Dwaipayan", ""], ["Klas", "Claus-Peter", ""], ["Mayr", "Philipp", ""]]}, {"id": "2106.04664", "submitter": "Moritz Schubotz", "authors": "Matteo Petrera and Dennis Trautwein and Isabel Beckenbach and Dariush\n  Ehsani and Fabian Mueller and Olaf Teschke and Bela Gipp and Moritz Schubotz", "title": "zbMATH Open: API Solutions and Research Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present zbMATH Open, the most comprehensive collection of reviews and\nbibliographic metadata of scholarly literature in mathematics. Besides our\nwebsite https://zbMATH.org which is openly accessible since the beginning of\nthis year, we provide API endpoints to offer our data. The API improves\ninteroperability with others, i.e., digital libraries, and allows using our\ndata for research purposes. In this article, we\n  (1) illustrate the current and future overview of the services offered by\nzbMATH;\n  (2) present the initial version of the zbMATH links API;\n  (3) analyze potentials and limitations of the links API based on the example\nof the NIST Digital Library of Mathematical Functions;\n  (4) and finally, present the zbMATH Open dataset as a research resource and\ndiscuss connected open research problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 20:08:58 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 11:27:19 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Petrera", "Matteo", ""], ["Trautwein", "Dennis", ""], ["Beckenbach", "Isabel", ""], ["Ehsani", "Dariush", ""], ["Mueller", "Fabian", ""], ["Teschke", "Olaf", ""], ["Gipp", "Bela", ""], ["Schubotz", "Moritz", ""]]}, {"id": "2106.04695", "submitter": "B. Ian Hutchins", "authors": "B. Ian Hutchins", "title": "A tipping point for open citation data", "comments": null, "journal-ref": null, "doi": "10.1162/qss_c_00138", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Open citation data can improve the transparency and robustness of scientific\nportfolio analysis, improve science policy decision-making, stimulate\ndownstream commercial activity, and increase the discoverability of scientific\narticles. Once sparsely populated, public-domain citation databases crossed a\nthreshold of one billion citations in February 2021, during the COVID-19\npandemic. Shortly thereafter, the threshold of one billion public-domain\ncitations from the Crossref database alone. Since the relative advantage of\nwithholding data in closed databases has diminished with the flood of\npublic-domain data, this likely constitutes an irreversible change in the\ncitation data ecosystem. The successes of this movement can guide future open\ndata efforts.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:13:16 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Hutchins", "B. Ian", ""]]}, {"id": "2106.04810", "submitter": "Milad Haghani", "authors": "Milad Haghani, Pegah Varamini", "title": "Sleeping beauties and temporal evolution of the coronavirus literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal evolution of the coronavirus literature over the last thirty years\n(N=43,769) is analyzed along with its subdomain of SARS-CoV-2 articles\n(N=27,460) and the subdomain of reviews and meta-analytic studies (N=1,027).\n(i) The analyses on the subset of SARS-CoV-2 literature identified studies\npublished prior to 2020 that have now proven highly instrumental in the\ndevelopment of various clusters of publications linked to SARS-CoV-2. In\nparticular, the so-called sleeping beauties of the coronavirus literature with\nan awakening in 2020 were identified, i.e., previously published studies of\nthis literature that had remained relatively unnoticed for several years but\ngained sudden traction in 2020 in the wake of the SARS-CoV-2 outbreak. (ii) The\nsubset of 2020 SARS-CoV-2 articles is bibliographically distant from the rest\nof this literature published prior to 2020. Individual articles of the\nSARS-CoV-2 segment with a bridging role between the two bodies of articles\n(i.e., before and after 2020) are identifiable. (iii) Furthermore, the degree\nof bibliographic coupling within the 2020 SARS-CoV-2 cluster is much poorer\ncompared to the cluster of articles published prior to 2020. This could, in\npart, be explained by the higher diversity of topics that are studied in\nrelation to SARS-CoV-2 compared to the literature of coronaviruses published\nprior to the SARS-CoV-2 disease. This work demonstrates how scholarly efforts\nundertaken during peace time or prior to a disease outbreak could suddenly play\na critical role in prevention and mitigation of health disasters caused by new\ndiseases.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 05:04:19 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 02:47:06 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Haghani", "Milad", ""], ["Varamini", "Pegah", ""]]}, {"id": "2106.05027", "submitter": "Keisuke Okamura", "authors": "Keisuke Okamura", "title": "Scientometric engineering: Revealing spatiotemporal citation dynamics\n  via open eprints", "comments": "1+25 pages, 6 figures for main text; 1+24 pages, 14 figures for\n  supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing speed and volume of knowledge production and\nconsumption, scholarly communication systems have been rapidly transformed into\ndigitised and networked open ecosystems, where preprint servers have played a\npivotal role. However, evidence is scarce regarding how this paradigm shift has\naffected the dynamics of collective attention on scientific knowledge. Herein,\nwe address this issue by investigating the citation dynamics of more than 1.5\nmillion eprints on arXiv, the most prominent and oldest eprint archive. The\ndiscipline-average citation history curves are estimated by applying a\nnonlinear regression model to the long-term citation data. The revealed\nspatiotemporal characteristics, including the growth and obsolescence patterns,\nare shown to vary across disciplines, reflecting the different publication and\ncitation practices. The results are used to develop a spatiotemporally\nnormalised citation index, called the $\\gamma$-index, with an approximately\nnormal distribution. It can be used to compare the citational impact of\nindividual papers across disciplines and time periods, providing a less biased\nmeasure of research impact than those widely used in the literature and in\npractice. Further, a stochastic model for the observed spatiotemporal citation\ndynamics is derived, reproducing both the Lognormal Law for the cumulative\ncitation distribution and the time trajectory of average citations in a unified\nformalism.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:38:44 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Okamura", "Keisuke", ""]]}, {"id": "2106.05581", "submitter": "Xiaozan Lyu", "authors": "Xiaozan Lyu and Rodrigo Costas", "title": "Studying the characteristics of scientific communities using\n  individual-level bibliometrics: the case of Big Data research", "comments": null, "journal-ref": "Scientometrics (2021)", "doi": "10.1007/s11192-021-04034-6", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unlike most bibliometric studies focusing on publications, taking Big Data\nresearch as a case study, we introduce a novel bibliometric approach to unfold\nthe status of a given scientific community from an individual level\nperspective. We study the academic age, production, and research focus of the\ncommunity of authors active in Big Data research. Artificial Intelligence (AI)\nis selected as a reference area for comparative purposes. Results show that the\nacademic realm of \"Big Data\" is a growing topic with an expanding community of\nauthors, particularly of new authors every year. Compared to AI, Big Data\nattracts authors with a longer academic age, who can be regarded to have\naccumulated some publishing experience before entering the community. Despite\nthe highly skewed distribution of productivity amongst researchers in both\ncommunities, Big Data authors have higher values of both research focus and\nproduction than those of AI. Considering the community size, overall academic\nage, and persistence of publishing on the topic, our results support the idea\nof Big Data as a research topic with attractiveness for researchers. We argue\nthat the community-focused indicators proposed in this study could be\ngeneralized to investigate the development and dynamics of other research\nfields and topics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:17:09 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Lyu", "Xiaozan", ""], ["Costas", "Rodrigo", ""]]}, {"id": "2106.05626", "submitter": "Bidyarthi Dutta DUTTA", "authors": "Bidyarthi Dutta", "title": "Citation Swing Factor: An Indicator to Measure the Diffusion of Cited\n  Items", "comments": "5 pages, 1 Figure", "journal-ref": "Journal of Scientometric Research, 9 (2) 214-218, 2020", "doi": "10.5530/jscires.9.2.26", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The h-index, introduced by Hirsch, is based on the mutual variation between\nthe number of cited and source items. The temporally continuous nature of the\ncitation accretion process causes a shift of cited items from the h-core zone\nto the adjacent citation-asymmetric zones, viz. h-excess zone, or h-tail zone.\nThe name given to this shifting phenomenon is the Diffusion of Cited Items\n(DCI). In this paper, two new variables are introduced, i.e., the Fold of\nExcess citation over Total citations (FET), denoted by $\\epsilon^2$ and the\nFold of h-core citation over Excess citations (FHE), denoted by $\\theta^2$. On\nthe basis of $\\theta$ and $\\epsilon$, another indicator is introduced, i.e.,\nthe Citation Swing Factor (CSF), defined as $d\\theta/d\\epsilon$, which\nindicates the differential coefficient of $\\theta$ with respect to $\\epsilon$.\nThe time dependence of FET and FHE is also discussed. The possible solutions of\nare derived here. The functionality of CSF ($d\\theta/d\\epsilon$) to measure the\ndiffusion process quantitatively will be tested later on for journals, authors\nand institutions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:08:04 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Dutta", "Bidyarthi", ""]]}, {"id": "2106.05633", "submitter": "Arthur Brack", "authors": "Arthur Brack and Anett Hoppe and Ralph Ewerth", "title": "Citation Recommendation for Research Papers via Knowledge Graphs", "comments": "Accepted for publication in 25th International Conference on Theory\n  and Practice of Digital Libraries (TPDL), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Citation recommendation for research papers is a valuable task that can help\nresearchers improve the quality of their work by suggesting relevant related\nwork. Current approaches for this task rely primarily on the text of the papers\nand the citation network. In this paper, we propose to exploit an additional\nsource of information, namely research knowledge graphs (KG) that interlink\nresearch papers based on mentioned scientific concepts. Our experimental\nresults demonstrate that the combination of information from research KGs with\nexisting state-of-the-art approaches is beneficial. Experimental results are\npresented for the STM-KG (STM: Science, Technology, Medicine), which is an\nautomatically populated knowledge graph based on the scientific concepts\nextracted from papers of ten domains. The proposed approach outperforms the\nstate of the art with a mean average precision of 20.6% (+0.8) for the top-50\nretrieved results.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:16:51 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Brack", "Arthur", ""], ["Hoppe", "Anett", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2106.05725", "submitter": "Federica Bologna", "authors": "Federica Bologna, Angelo Di Iorio, Silvio Peroni, Francesco Poggi", "title": "Academics evaluating academics: a methodology to inform the review\n  process on top of open citations", "comments": "arXiv admin note: substantial text overlap with arXiv:2103.07942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past, several works have investigated ways for combining quantitative\nand qualitative methods in research assessment exercises. In this work, we aim\nat introducing a methodology to explore whether citation-based metrics,\ncalculated only considering open bibliographic and citation data, can yield\ninsights on how human peer-review of research assessment exercises is\nconducted. To understand if and what metrics provide relevant information, we\npropose to use a series of machine learning models to replicate the decisions\nof the committees of the research assessment exercises.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:09:15 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Bologna", "Federica", ""], ["Di Iorio", "Angelo", ""], ["Peroni", "Silvio", ""], ["Poggi", "Francesco", ""]]}, {"id": "2106.05764", "submitter": "Norman Meuschke", "authors": "Norman Meuschke", "title": "Analyzing Non-Textual Content Elements to Detect Academic Plagiarism", "comments": "Ph.D. Thesis, University of Konstanz", "journal-ref": null, "doi": "10.5281/zenodo.4913345", "report-no": null, "categories": "cs.IR cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying academic plagiarism is a pressing problem, among others, for\nresearch institutions, publishers, and funding organizations. Detection\napproaches proposed so far analyze lexical, syntactical, and semantic text\nsimilarity. These approaches find copied, moderately reworded, and literally\ntranslated text. However, reliably detecting disguised plagiarism, such as\nstrong paraphrases, sense-for-sense translations, and the reuse of non-textual\ncontent and ideas, is an open research problem.\n  The thesis addresses this problem by proposing plagiarism detection\napproaches that implement a different concept: analyzing non-textual content in\nacademic documents, specifically citations, images, and mathematical content.\n  To validate the effectiveness of the proposed detection approaches, the\nthesis presents five evaluations that use real cases of academic plagiarism and\nexploratory searches for unknown cases.\n  The evaluation results show that non-textual content elements contain a high\ndegree of semantic information, are language-independent, and largely immutable\nto the alterations that authors typically perform to conceal plagiarism.\nAnalyzing non-textual content complements text-based detection approaches and\nincreases the detection effectiveness, particularly for disguised forms of\nacademic plagiarism.\n  To demonstrate the benefit of combining non-textual and text-based detection\nmethods, the thesis describes the first plagiarism detection system that\nintegrates the analysis of citation-based, image-based, math-based, and\ntext-based document similarity. The system's user interface employs\nvisualizations that significantly reduce the effort and time users must invest\nin examining content similarity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:11:52 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Meuschke", "Norman", ""]]}, {"id": "2106.06487", "submitter": "Qing Ke", "authors": "Qing Ke, Lizhen Liang, Ying Ding, Stephen V. David, Daniel E. Acuna", "title": "A dataset of mentorship in science with semantic and demographic\n  estimations", "comments": "Data can be found at https://doi.org/10.5281/zenodo.4917086", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mentorship in science is crucial for topic choice, career decisions, and the\nsuccess of mentees and mentors. Typically, researchers who study mentorship use\narticle co-authorship and doctoral dissertation datasets. However, available\ndatasets of this type focus on narrow selections of fields and miss out on\nearly career and non-publication-related interactions. Here, we describe\nMENTORSHIP, a crowdsourced dataset of 743176 mentorship relationships among\n738989 scientists across 112 fields that avoids these shortcomings. We enrich\nthe scientists' profiles with publication data from the Microsoft Academic\nGraph and \"semantic\" representations of research using deep learning content\nanalysis. Because gender and race have become critical dimensions when\nanalyzing mentorship and disparities in science, we also provide estimations of\nthese factors. We perform extensive validations of the profile--publication\nmatching, semantic content, and demographic inferences. We anticipate this\ndataset will spur the study of mentorship in science and deepen our\nunderstanding of its role in scientists' career outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 16:12:15 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ke", "Qing", ""], ["Liang", "Lizhen", ""], ["Ding", "Ying", ""], ["David", "Stephen V.", ""], ["Acuna", "Daniel E.", ""]]}, {"id": "2106.06786", "submitter": "Alex Lamb", "authors": "Alex Lamb, Tarin Clanuwat, Siyu Han, Mikel Bober-Irizar, Asanobu\n  Kitamoto", "title": "Predicting the Ordering of Characters in Japanese Historical Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 14:39:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lamb", "Alex", ""], ["Clanuwat", "Tarin", ""], ["Han", "Siyu", ""], ["Bober-Irizar", "Mikel", ""], ["Kitamoto", "Asanobu", ""]]}, {"id": "2106.07213", "submitter": "Naman Jain", "authors": "Naman Jain and Mayank Singh", "title": "TweetPap: A Dataset to Study the Social Media Discourse of Scientific\n  Papers", "comments": "2 Pages, JCDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, researchers have moved to platforms like Twitter to spread\ninformation about their ideas and empirical evidence. Recent studies have shown\nthat social media affects the scientific impact of a paper. However, these\nstudies only utilize the tweet counts to represent Twitter activity. In this\npaper, we propose TweetPap, a large-scale dataset that introduces temporal\ninformation of citation/tweets and the metadata of the tweets to quantify and\nunderstand the discourse of scientific papers on social media. The dataset is\npublicly available at https://github.com/lingo-iitgn/TweetPap\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:00:28 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jain", "Naman", ""], ["Singh", "Mayank", ""]]}, {"id": "2106.07277", "submitter": "Achille Felicetti", "authors": "Nicola Amico and Achille Felicetti", "title": "Ontological Entities for Planning and Describing Cultural Heritage 3D\n  Models Creation", "comments": "Submitted to ACM Journal on Computing and Cultural Heritage (JOCCH)\n  2021. 20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the last decades the rapid development of technologies and methodologies\nin the field of digitization and 3D modelling has led to an increasing\nproliferation of 3D technologies in the Cultural Heritage domain. Despite the\ngreat potential of 3D digital heritage, the \"special effects\" of 3D may often\noverwhelm its importance in research. Projects and consortia of scholars have\ntried to put order in the different fields of application of these\ntechnologies, providing guidelines and proposing workflows. The use of computer\ngraphics as an effective methodology for CH research and communication\nhighlighted the need of transparent provenance data to properly document\ndigital assets and understand the degree of scientific quality and reliability\nof their outcomes. The building and release of provenance knowledge, consisting\nin the complete formal documentation of each phase of the process, is therefore\nof fundamental importance to ensure its repeatability and to guarantee the\nintegration and interoperability of the generated metadata on the Semantic Web.\nThis paper proposes a methodology for documenting the planning and creation of\n3D models used in archaeology and Cultural Heritage, by means of an application\nprofile based on the CIDOC CRM ecosystem and other international standards.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:10:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Amico", "Nicola", ""], ["Felicetti", "Achille", ""]]}, {"id": "2106.07359", "submitter": "Zeyd Boukhers", "authors": "Zeyd Boukhers and Nada Beili and Timo Hartmann and Prantik Goswami and\n  Muhammad Arslan Zafar", "title": "MexPub: Deep Transfer Learning for Metadata Extraction from German\n  Publications", "comments": "A long version of an accepted paper @ JCDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CV cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Extracting metadata from scientific papers can be considered a solved problem\nin NLP due to the high accuracy of state-of-the-art methods. However, this does\nnot apply to German scientific publications, which have a variety of styles and\nlayouts. In contrast to most of the English scientific publications that follow\nstandard and simple layouts, the order, content, position and size of metadata\nin German publications vary greatly among publications. This variety makes\ntraditional NLP methods fail to accurately extract metadata from these\npublications. In this paper, we present a method that extracts metadata from\nPDF documents with different layouts and styles by viewing the document as an\nimage. We used Mask R-CNN that is trained on COCO dataset and finetuned with\nPubLayNet dataset that consists of ~200K PDF snapshots with five basic classes\n(e.g. text, figure, etc). We refine-tuned the model on our proposed synthetic\ndataset consisting of ~30K article snapshots to extract nine patterns (i.e.\nauthor, title, etc). Our synthetic dataset is generated using contents in both\nlanguages German and English and a finite set of challenging templates obtained\nfrom German publications. Our method achieved an average accuracy of around\n$90\\%$ which validates its capability to accurately extract metadata from a\nvariety of PDF documents with challenging templates.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:43:48 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Boukhers", "Zeyd", ""], ["Beili", "Nada", ""], ["Hartmann", "Timo", ""], ["Goswami", "Prantik", ""], ["Zafar", "Muhammad Arslan", ""]]}, {"id": "2106.07385", "submitter": "Jennifer D'Souza", "authors": "Jennifer D'Souza, S\\\"oren Auer and Ted Pedersen", "title": "SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP\n  Contributions for a Research Knowledge Graph", "comments": "13 pages, 5 figures, 8 tables, In Proceedings of the Fifteenth\n  Workshop on Semantic Evaluation SemEval-2021 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is currently a gap between the natural language expression of scholarly\npublications and their structured semantic content modeling to enable\nintelligent content search. With the volume of research growing exponentially\nevery year, a search feature operating over semantically structured content is\ncompelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. 'the NCG\ntask') tasks participants to develop automated systems that structure\ncontributions from NLP scholarly articles in the English language. Being the\nfirst-of-its-kind in the SemEval series, the task released structured data from\nNLP scholarly articles at three levels of information granularity, i.e. at\nsentence-level, phrase-level, and phrases organized as triples toward Knowledge\nGraph (KG) building. The sentence-level annotations comprised the few sentences\nabout the article's contribution. The phrase-level annotations were scientific\nterm and predicate phrases from the contribution sentences. Finally, the\ntriples constituted the research overview KG. For the Shared Task,\nparticipating systems were then expected to automatically classify contribution\nsentences, extract scientific terms and relations from the sentences, and\norganize them as KG triples.\n  Overall, the task drew a strong participation demographic of seven teams and\n27 participants. The best end-to-end task system classified contribution\nsentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While\nthe absolute performance to generate triples remains low, in the conclusion of\nthis article, the difficulty of producing such data and as a consequence of\nmodeling it is highlighted.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:43:47 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:26:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["D'Souza", "Jennifer", ""], ["Auer", "S\u00f6ren", ""], ["Pedersen", "Ted", ""]]}, {"id": "2106.08701", "submitter": "Olesya Mryglod", "authors": "O. Mryglod, S. Nazarovets and S. Kozmenko", "title": "Universal and specific features of Ukrainian economic research:\n  publication analysis based on Crossref data", "comments": "This is the version of the Article before peer-review has taken\n  place. The paper is submitted to \\textit{Scientometrics} journal, Manuscript\n  Number: SCIM-D-21-00282R1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our study is one of the first examples of multidimensional and longitudinal\ndisciplinary analysis at the national level based on Crossref data. We present\na large-scale quantitative analysis of Ukrainian economics. This study is not\nyet another example of research aimed at ranking of local journals, authors or\ninstitutions, but rather exploring general tendencies that can be compared to\nother countries or regions. We study different aspects of Ukrainian economics\noutput. In particular, the collaborative nature, geographic landscape and some\npeculiarities of citation statistics are investigated. We have found that\nUkrainian economics is characterized by a comparably small share of co-authored\npublications, however, it demonstrates the tendency towards more collaborative\noutput. Based on our analysis, we discuss specific and universal features of\nUkrainian economic research. The importance of supporting various initiatives\naimed at enriching open scholarly metadata is considered. A comprehensive and\nhigh-quality meta description of publications is probably the shortest path to\na better understanding of national trends, especially for non-English speaking\ncountries. The results of our analysis can be used to better understand\nUkrainian economic research and support research policy decisions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 11:07:11 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Mryglod", "O.", ""], ["Nazarovets", "S.", ""], ["Kozmenko", "S.", ""]]}, {"id": "2106.08708", "submitter": "Peter Sj\\\"og{\\aa}rde", "authors": "Peter Sj\\\"og{\\aa}rde and Fereshteh Didegah", "title": "The association between topic growth and citation impact of research\n  publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Citations are used for research evaluation, and it is therefore important to\nknow which factors influence or associate with citation impact of articles.\nSeveral citation factors have been studied in the literature. In this study we\npropose a new factor, topic growth, that no previous study has taken into\nconsideration. The growth rate of topics may influence future citation counts,\nbecause a high growth in a topic means there are more publications citing\nprevious publications in that topic. We construct topics using community\ndetection in a citation network and use a two-part regression model is used to\nstudy the association between topic growth and citation counts in eight broad\ndisciplines. The first part of the model uses quantile regression to estimate\nthe effect of growth ratio on citation counts for publications with more than\nthree citations. The second part of the model uses logistic regression to model\nthe influence of the independent variables on the probability of being lowly\ncited versus being modestly or highly cited. Both models control for three\nvariables that may distort the association between the topic growth and\ncitations: journal impact, number of references, and number of authors. The\nregression model clearly shows that publications in fast-growing topics have a\ncitation advantage compared to publications in slow-growing or declining topics\nin all of the eight disciplines. Using citation indicators for research\nevaluation may give incentives for researchers to publish in fast-growing\ntopics, but they may cause research to be less diversified. The results have\nalso some implications for citation normalization.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 11:21:30 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sj\u00f6g\u00e5rde", "Peter", ""], ["Didegah", "Fereshteh", ""]]}, {"id": "2106.09399", "submitter": "Antti Rousi Dr.", "authors": "Antti Mikael Rousi (1) ((1) Research services, Aalto University)", "title": "Data sharing of computer scientists: an analysis of current research\n  information system data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without sufficient information about researchers data sharing, there is a\nrisk of mismatching FAIR data service efforts with the needs of researchers.\nThis study describes a methodology where departmental publications are used to\nanalyse the ways in which computer scientists share research data. All journal\narticles published by researchers in the computer science department of the\ncase studys university during 2019 were extracted for scrutiny from the current\nresearch information system. For these 193 articles, a coding framework was\ndeveloped to capture the key elements of acquiring and sharing research data.\nFurthermore, a rudimentary classification of the main study types exhibited in\nthe investigated articles was developed to accommodate the multidisciplinary\nnature of the case departments research agenda. Human interaction and\nintervention studies often collected original data, whereas research on novel\ncomputational methods and life sciences more frequently used openly available\ndata. Articles that made data available for reuse were most often in life\nscience studies, whereas data sharing was least frequent in human interaction\nstudies. The use of open code was most frequent in life science studies and\nnovel computational methods. The findings highlight that multidisciplinary\nresearch organisations may include diverse subfields that have their own\ncultures of data sharing, and suggest that research information system-based\nmethods may be valuable additions to the questionnaire and interview\nmethodologies eliciting insight into researchers data sharing. The collected\ndata and coding framework are provided as open data to facilitate future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 11:34:26 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Rousi", "Antti Mikael", "", "Research services, Aalto University"]]}, {"id": "2106.10038", "submitter": "Maryam Zamani Dr", "authors": "Maryam Zamani, Erez Aghion, Peter Pollner, Tamas Vicsek and Holger\n  Kantz", "title": "Anomalous diffusion in the citation time series of scientific\n  publications", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the citation time-series of manuscripts in three different fields\nof science; physics, social science and technology. The evolution of the\ntime-series of the yearly number of citations, namely the citation\ntrajectories, diffuse anomalously, their variance scales with time $\\propto\nt^{2H}$, where $H\\neq 1/2$. We provide detailed analysis of the various factors\nthat lead to the anomalous behavior: non-stationarity, long-ranged correlations\nand a fat-tailed increment distribution. The papers exhibit high degree of\nheterogeneity, across the various fields, as the statistics of the highest\ncited papers is fundamentally different from that of the lower ones. The\ncitation data is shown to be highly correlated and non-stationary; as all the\npapers except the small percentage of them with high number of citations, die\nout in time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 10:20:54 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 13:39:04 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zamani", "Maryam", ""], ["Aghion", "Erez", ""], ["Pollner", "Peter", ""], ["Vicsek", "Tamas", ""], ["Kantz", "Holger", ""]]}, {"id": "2106.10700", "submitter": "Diego Amancio", "authors": "Jorge A. V. Tohalino and Diego R. Amancio", "title": "On predicting research grants productivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the reasons associated with successful proposals is of\nparamount importance to improve evaluation processes. In this context, we\nanalyzed whether bibliometric features are able to predict the success of\nresearch grants. We extracted features aiming at characterizing the academic\nhistory of Brazilian researchers, including research topics, affiliations,\nnumber of publications and visibility. The extracted features were then used to\npredict grants productivity via machine learning in three major research areas,\nnamely Medicine, Dentistry and Veterinary Medicine. We found that research\nsubject and publication history play a role in predicting productivity. In\naddition, institution-based features turned out to be relevant when combined\nwith other features. While the best results outperformed text-based attributes,\nthe evaluated features were not highly discriminative. Our findings indicate\nthat predicting grants success, at least with the considered set of\nbibliometric features, is not a trivial task.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 14:21:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tohalino", "Jorge A. V.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "2106.11534", "submitter": "Yinyu Jin Ms.", "authors": "Yinyu Jin, Sha Yuan, Zhou Shao, Wendy Hall and Jie Tang", "title": "Turing Award elites revisited: patterns of productivity, collaboration,\n  authorship and impact", "comments": null, "journal-ref": "Scientometrics 126, 2329-2348 (2021)", "doi": "10.1007/s11192-020-03860-4", "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Turing Award is recognized as the most influential and prestigious award\nin the field of computer science(CS). With the rise of the science of science\n(SciSci), a large amount of bibliographic data has been analyzed in an attempt\nto understand the hidden mechanism of scientific evolution. These include the\nanalysis of the Nobel Prize, including physics, chemistry, medicine, etc. In\nthis article, we extract and analyze the data of 72 Turing Award laureates from\nthe complete bibliographic data, fill the gap in the lack of Turing Award\nanalysis, and discover the development characteristics of computer science as\nan independent discipline. First, we show most Turing Award laureates have\nlong-term and high-quality educational backgrounds, and more than 61% of them\nhave a degree in mathematics, which indicates that mathematics has played a\nsignificant role in the development of computer science. Secondly, the data\nshows that not all scholars have high productivity and high h-index; that is,\nthe number of publications and h-index is not the leading indicator for\nevaluating the Turing Award. Third, the average age of awardees has increased\nfrom 40 to around 70 in recent years. This may be because new breakthroughs\ntake longer, and some new technologies need time to prove their influence.\nBesides, we have also found that in the past ten years, international\ncollaboration has experienced explosive growth, showing a new paradigm in the\nform of collaboration. It is also worth noting that in recent years, the\nemergence of female winners has also been eye-catching. Finally, by analyzing\nthe personal publication records, we find that many people are more likely to\npublish high-impact articles during their high-yield periods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 04:20:30 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jin", "Yinyu", ""], ["Yuan", "Sha", ""], ["Shao", "Zhou", ""], ["Hall", "Wendy", ""], ["Tang", "Jie", ""]]}, {"id": "2106.12320", "submitter": "Zeyd Boukhers", "authors": "Zeyd Boukhers, Philipp Mayr, Silvio Peroni", "title": "BiblioDAP: The 1st Workshop on Bibliographic Data Analysis and\n  Processing", "comments": "This workshop will be held in conjunction with KDD' 2021", "journal-ref": null, "doi": "10.1145/3447548.346", "report-no": null, "categories": "cs.DL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automatic processing of bibliographic data becomes very important in digital\nlibraries, data science and machine learning due to its importance in keeping\npace with the significant increase of published papers every year from one side\nand to the inherent challenges from the other side. This processing has several\naspects including but not limited to I) Automatic extraction of references from\nPDF documents, II) Building an accurate citation graph, III) Author name\ndisambiguation, etc. Bibliographic data is heterogeneous by nature and occurs\nin both structured (e.g. citation graph) and unstructured (e.g. publications)\nformats. Therefore, it requires data science and machine learning techniques to\nbe processed and analysed. Here we introduce BiblioDAP'21: The 1st Workshop on\nBibliographic Data Analysis and Processing.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:33:19 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Boukhers", "Zeyd", ""], ["Mayr", "Philipp", ""], ["Peroni", "Silvio", ""]]}, {"id": "2106.12340", "submitter": "Andreea Iana", "authors": "Andreea Iana, Heiko Paulheim", "title": "GraphConfRec: A Graph Neural Network-Based Conference Recommender System", "comments": "Accepted at the Joint Conference on Digital Libraries (JCDL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's academic publishing model, especially in Computer Science,\nconferences commonly constitute the main platforms for releasing the latest\npeer-reviewed advancements in their respective fields. However, choosing a\nsuitable academic venue for publishing one's research can represent a\nchallenging task considering the plethora of available conferences,\nparticularly for those at the start of their academic careers, or for those\nseeking to publish outside of their usual domain. In this paper, we propose\nGraphConfRec, a conference recommender system which combines SciGraph and graph\nneural networks, to infer suggestions based not only on title and abstract, but\nalso on co-authorship and citation relationships. GraphConfRec achieves a\nrecall@10 of up to 0.580 and a MAP of up to 0.336 with a graph attention\nnetwork-based recommendation model. A user study with 25 subjects supports the\npositive results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 12:10:40 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Iana", "Andreea", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2106.12624", "submitter": "Ludo Waltman", "authors": "Hanjo Boekhout and Inge van der Weijden and Ludo Waltman", "title": "Gender differences in scientific careers: A large-scale bibliometric\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a large-scale bibliometric analysis of gender differences in\nscientific careers, covering all scientific disciplines and a large number of\ncountries worldwide. We take a longitudinal perspective in which we trace the\npublication careers of almost six million male and female researchers in the\nperiod 1996-2018. Our analysis reveals an increasing trend in the percentage of\nwomen starting a career as publishing researcher, from 33% in 2000 to about 40%\nin recent years. Looking at cohorts of male and female researchers that started\ntheir publication career in the same year, we find that women seem to be\nsomewhat less likely to continue their career as publishing researcher than\nmen, but the difference is small. We also observe that men produce on average\nbetween 15% and 20% more publications than women. Moreover, in biomedical\ndisciplines, men are about 25% more likely than women to be last author of a\npublication, suggesting that men tend to have more senior roles than women.\nCompared with cross-sectional studies, our longitudinal analysis has the\nadvantage of providing a more in-depth understanding of gender imbalances among\nauthors of scientific publications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 18:49:03 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Boekhout", "Hanjo", ""], ["van der Weijden", "Inge", ""], ["Waltman", "Ludo", ""]]}, {"id": "2106.12875", "submitter": "Angelo Salatino Dr", "authors": "Angelo Salatino and Andrea Mannocci and Francesco Osborne", "title": "Detection, Analysis, and Prediction of Research Topics with Scientific\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysing research trends and predicting their impact on academia and\nindustry is crucial to gain a deeper understanding of the advances in a\nresearch field and to inform critical decisions about research funding and\ntechnology adoption. In the last years, we saw the emergence of several\npublicly-available and large-scale Scientific Knowledge Graphs fostering the\ndevelopment of many data-driven approaches for performing quantitative analyses\nof research trends. This chapter presents an innovative framework for\ndetecting, analysing, and forecasting research topics based on a large-scale\nknowledge graph characterising research articles according to the research\ntopics from the Computer Science Ontology. We discuss the advantages of a\nsolution based on a formal representation of topics and describe how it was\napplied to produce bibliometric studies and innovative tools for analysing and\npredicting research dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:17:01 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Salatino", "Angelo", ""], ["Mannocci", "Andrea", ""], ["Osborne", "Francesco", ""]]}, {"id": "2106.12967", "submitter": "Sofia Baroncini", "authors": "S. Baroncini (1), M. Daquino (1), F. Tomasi (1) ((1) Department of\n  Classical Philology and Italian Studies, University of Bologna)", "title": "Modelling Art Interpretation and Meaning. A Data Model for Describing\n  Iconology and Iconography", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Iconology is a branch of art history that investigates the meaning of\nartworks in relation to their social and cultural background. Nowadays, several\ninterdisciplinary research fields leverage theoretical frameworks close to\niconology to pursue quantitative Art History with data science methods and\nSemantic Web technologies. However, while Iconographic studies have been\nrecently addressed in ontologies, a complete description of aspects relevant to\niconological studies is still missing. In this article, we present a\npreliminary study on eleven case studies selected from the literature and we\nenvision new terms for extending existing ontologies. We validate new terms\naccording to a common evaluation method and we discuss our results in the light\nof the opportunities that such an extended ontology would arise in the\ncommunity of Digital Art History.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:37:58 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Baroncini", "S.", ""], ["Daquino", "M.", ""], ["Tomasi", "F.", ""]]}, {"id": "2106.13282", "submitter": "Kevin Gross", "authors": "Kevin Gross and Carl T. Bergstrom", "title": "Why ex post peer review encourages high-risk research while ex ante\n  review discourages it", "comments": "11 pages, 4 figures, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Peer review is an integral component of contemporary science. While peer\nreview focuses attention on promising and interesting science, it also\nencourages scientists to pursue some questions at the expense of others. Here,\nwe use ideas from forecasting assessment to examine how two modes of peer\nreview -- ex ante review of proposals for future work and ex post review of\ncompleted science -- motivate scientists to favor some questions instead of\nothers. Our main result is that ex ante and ex post peer review push\ninvestigators toward distinct sets of scientific questions. This tension arises\nbecause ex post review allows an investigator to leverage her own scientific\nbeliefs to generate results that others will find surprising, whereas ex ante\nreview does not. Moreover, ex ante review will favor different research\nquestions depending on whether reviewers rank proposals in anticipation of\nchanges to their own personal beliefs, or to the beliefs of their peers. The\ntension between ex ante and ex post review puts investigators in a bind,\nbecause most researchers need to find projects that will survive both. By\nunpacking the tension between these two modes of review, we can understand how\nthey shape the landscape of science and how changes to peer review might shift\nscientific activity in unforeseen directions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:09:21 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Gross", "Kevin", ""], ["Bergstrom", "Carl T.", ""]]}, {"id": "2106.13295", "submitter": "Mikhail Simkin", "authors": "M.V. Simkin", "title": "Stochastic modeling of scientific impact", "comments": "Accepted for publication by Europhysics Letters", "journal-ref": "EPL, 134 (2021) 48004", "doi": "10.1209/0295-5075/134/48004", "report-no": null, "categories": "physics.soc-ph cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has found that select scientists have a disproportional share\nof highly cited papers. Researchers reasoned that this could not have happened\nif success in science was random and introduced a hidden parameter Q, or\ntalent, to explain this finding. So, the talented high-Q scientists have many\nhigh impact papers. Here I show that an upgrade of an old random citation\ncopying model could also explain this finding. In the new model the probability\nof citation copying is not the same for all papers but is proportional to the\nlogarithm of the total number of citations to all papers of its author.\nNumerical simulations of the model give results similar to the empirical\nfindings of the Q-factor article.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:54:43 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Simkin", "M. V.", ""]]}, {"id": "2106.13321", "submitter": "Abdelghani Maddi", "authors": "Abdelghani Maddi (HCERES)", "title": "Game theory and scholarly publishing: premises for an agreement around\n  open access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.DL q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actors in research and scientific publishing are gradually joining the\nOpen-Access (OA) movement, which is gaining momentum to become nowadays at the\nheart of scientific policies in high-income countries. The rise of OA generates\nprofound changes in the chain of production and dissemination of knowledge.\nFree access to peer-reviewed research methods and results has contributed to\nthe dynamics of science observed in recent years. The modes of publication and\naccess have also evolved; the classic model, based on journal subscriptions is\ngradually giving way to new economic models that have appeared with the arrival\nof OA. The objective of this article is twofold. First, propose a model for the\npublishing market based on the literature as well as on changes in open science\npolicies. Second, analyze publishing strategies of publishers and institutions.\nTo do so, we relied on game theory in economics. Results show that in the short\nterm, the publisher's equilibrium strategy is to adopt a hybridpublishing\nmodel, while the institutions' equilibrium strategy is to publish in OA. This\nequilibrium is not stable and that in the medium/long term, the two players\nwill converge on an OA publishing strategy. The analysis of the equilibrium in\nmixed-strategies confirms this result.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:09:39 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 08:02:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Maddi", "Abdelghani", "", "HCERES"]]}, {"id": "2106.13375", "submitter": "Tristan Naumann", "authors": "Yu Wang, Jinchao Li, Tristan Naumann, Chenyan Xiong, Hao Cheng, Robert\n  Tinn, Cliff Wong, Naoto Usuyama, Richard Rogahn, Zhihong Shen, Yang Qin, Eric\n  Horvitz, Paul N. Bennett, Jianfeng Gao, Hoifung Poon", "title": "Domain-Specific Pretraining for Vertical Search: Case Study on\n  Biomedical Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information overload is a prevalent challenge in many high-value domains. A\nprominent case in point is the explosion of the biomedical literature on\nCOVID-19, which swelled to hundreds of thousands of papers in a matter of\nmonths. In general, biomedical literature expands by two papers every minute,\ntotalling over a million new papers every year. Search in the biomedical realm,\nand many other vertical domains is challenging due to the scarcity of direct\nsupervision from click logs. Self-supervised learning has emerged as a\npromising direction to overcome the annotation bottleneck. We propose a general\napproach for vertical search based on domain-specific pretraining and present a\ncase study for the biomedical domain. Despite being substantially simpler and\nnot using any relevance labels for training or development, our method performs\ncomparably or better than the best systems in the official TREC-COVID\nevaluation, a COVID-related biomedical search competition. Using distributed\ncomputing in modern cloud infrastructure, our system can scale to tens of\nmillions of articles on PubMed and has been deployed as Microsoft Biomedical\nSearch, a new search experience for biomedical literature:\nhttps://aka.ms/biomedsearch.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 01:02:55 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Wang", "Yu", ""], ["Li", "Jinchao", ""], ["Naumann", "Tristan", ""], ["Xiong", "Chenyan", ""], ["Cheng", "Hao", ""], ["Tinn", "Robert", ""], ["Wong", "Cliff", ""], ["Usuyama", "Naoto", ""], ["Rogahn", "Richard", ""], ["Shen", "Zhihong", ""], ["Qin", "Yang", ""], ["Horvitz", "Eric", ""], ["Bennett", "Paul N.", ""], ["Gao", "Jianfeng", ""], ["Poon", "Hoifung", ""]]}, {"id": "2106.13469", "submitter": "Mathieu Andro", "authors": "Mathieu Andro (DSAF, SPM), Marc Maisonneuve", "title": "Digital libraries: textual analysis for a systematic review and\n  meta-analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: We seek to explore the realm of literature about digital libraries.\nWe specifically seek to ascertain how interest in this subject has evolved, its\nimpact, the most productive journals and countries, the number of occurrences\nof digital libraries, the relationships and dynamics of the main concepts\nmentioned, and the dynamics of metadata formats.Methods: We extracted corpora\nfrom the Google Scholar and Microsoft Academic Search bibliographic databases.\nWe analyzed the named entities and concepts contained within these corpora with\nthe help of text mining technologies, CorTexT in particular.Results: While the\nnumber of publications on the subject of digital libraries is increasing, their\naverage number of citations is decreasing. China, the United States and India\nare the most productive countries on the subject. Literature about conservation\nand national libraries has gradually been replaced by literature about open\naccess, university libraries and the relationship with users. Internet Archive\nis the most cited digital library in literature and continues to grow. Dublin\nCore is the most talked about metadata format, however the subject of metadata\nformats is declining in the corpus today.Conclusion: Digital libraries now seem\nto be reaching the age of maturity.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 07:33:09 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Andro", "Mathieu", "", "DSAF, SPM"], ["Maisonneuve", "Marc", ""]]}, {"id": "2106.13537", "submitter": "Robin Haunschild", "authors": "Werner Marx, Robin Haunschild, Lutz Bornmann", "title": "Heat Waves -- a hot topic in climate change research", "comments": "38 pages, 2 tables, and 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on heat waves (periods of excessively hot weather, which may be\naccompanied by high humidity) is a newly emerging research topic within the\nfield of climate change research with high relevance for the whole of society.\nIn this study, we analyzed the rapidly growing scientific literature dealing\nwith heat waves. No summarizing overview has been published on this literature\nhitherto. We developed a suitable search query to retrieve the relevant\nliterature covered by the Web of Science (WoS) as complete as possible and to\nexclude irrelevant literature (n = 6,569 papers). The time-evolution of the\npublications shows that research dealing with heat waves is a highly dynamic\nresearch topic, doubling within about 5 years. An analysis of the thematic\ncontent reveals the most severe heat wave events within the recent decades\n(1995, 2003, 2010), the cities and countries/regions affected (Australia,\nUnited States, and Europe), and the ecological and medical impacts (drought,\nurban heat islands, excess hospital admissions, and mortality). Risk estimation\nand future strategies for adaptation to hot weather are major political issues.\nWe identified 83 citation classics which include fundamental early works of\nresearch on heat waves and more recent works (which are characterized by a\nrelatively strong connection to climate change).\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 10:08:45 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Marx", "Werner", ""], ["Haunschild", "Robin", ""], ["Bornmann", "Lutz", ""]]}, {"id": "2106.15166", "submitter": "Taekho You", "authors": "Taekho You, Jinseo Park, June Young Lee, Jinhyuk Yun, Woo-Sung Jung", "title": "Disturbance of greedy publishing to academia", "comments": "16 pages of main text including 4 figures + 32 pages of supplementary\n  information including 30 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questionable publications have been accused of \"greedy\" practices; however,\ntheir influence on academia has not been gauged. Here, we probe the impact of\nquestionable publications through a systematic and comprehensive analysis with\nvarious participants from academia and compare the results with those of their\nunaccused counterparts using billions of citation records, including liaisons,\ne.g., journals and publishers, and prosumers, e.g., authors. The analysis\nreveals that questionable publications embellished their citation scores by\nattributing publisher-level self-citations to their journals while also\ncontrolling the journal-level self-citations to circumvent the evaluation of\njournal-indexing services. This approach makes it difficult to detect\nmalpractice by conventional journal-level metrics. We propose\njournal-publisher-hybrid metric that help detect malpractice. We also\ndemonstrate that the questionable publications had a weaker disruptiveness and\ninfluence than their counterparts. This indicates the negative effect of\nsuspicious publishers in the academia. The findings provide a basis for\nactionable policy making against questionable publications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 08:26:39 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 07:42:56 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["You", "Taekho", ""], ["Park", "Jinseo", ""], ["Lee", "June Young", ""], ["Yun", "Jinhyuk", ""], ["Jung", "Woo-Sung", ""]]}, {"id": "2106.15255", "submitter": "Thomas Benjamin Britton", "authors": "Philip Ball, T. Benjamin Britton, Erin Hengel, Philip Moriarty, Rachel\n  A. Oliver, Gina Rippon, Angela Saini, and Jessica Wade", "title": "Gender issues in fundamental physics: Strumia's bibliometric analysis\n  fails to account for key confounders and confuses correlation with causation", "comments": "As submitted to Quantitative Science Studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alessandro Strumia recently published a survey of gender differences in\npublications and citations in high-energy physics (HEP). In addition to\nproviding full access to the data, code, and methodology, Strumia (2020)\nsystematically describes and accounts for gender differences in HEP citation\nnetworks. His analysis points both to ongoing difficulties in attracting women\nto high-energy physics and an encouraging-though slow-trend in improvement.\nUnfortunately, however, the time and effort Strumia (2020) devoted to collating\nand quantifying the data are not matched by a similar rigour in interpreting\nthe results. To support his conclusions, he selectively cites available\nliterature and fails to adequately adjust for a range of confounding factors.\nFor example, his analyses do not consider how unobserved factors -- e.g., a\ntendency to overcite well-known authors -- drive a wedge between quality and\ncitations and correlate with author gender. He also fails to take into account\nmany structural and non-structural factors -- including, but not limited to,\ndirect discrimination and the expectations women form (and actions they take)\nin response to it -- that undoubtedly lead to gender differences in\nproductivity. We therefore believe that a number of Strumia's conclusions are\nnot supported by his analysis. Indeed, we re-analyse a subsample of\nsolo-authored papers from his data, adjusting for year and journal of\npublication, authors' research age and their lifetime \"fame\". Our re-analysis\nsuggests that female-authored papers are actually cited more than male-authored\npapers. This finding is inconsistent with the \"greater male variability\"\nhypothesis Strumia (2020) proposes to explain many of his results.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 11:43:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ball", "Philip", ""], ["Britton", "T. Benjamin", ""], ["Hengel", "Erin", ""], ["Moriarty", "Philip", ""], ["Oliver", "Rachel A.", ""], ["Rippon", "Gina", ""], ["Saini", "Angela", ""], ["Wade", "Jessica", ""]]}, {"id": "2106.15320", "submitter": "Sampanna Yashwant Kahu", "authors": "Sampanna Yashwant Kahu, William A. Ingram, Edward A. Fox, Jian Wu", "title": "ScanBank: A Benchmark Dataset for Figure Extraction from Scanned\n  Electronic Theses and Dissertations", "comments": "16 pages, 3 figures, submitted to ACM/IEEE Joint Conference on\n  Digital Libraries", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on electronic theses and dissertations (ETDs), aiming to improve\naccess and expand their utility, since more than 6 million are publicly\navailable, and they constitute an important corpus to aid research and\neducation across disciplines. The corpus is growing as new born-digital\ndocuments are included, and since millions of older theses and dissertations\nhave been converted to digital form to be disseminated electronically in\ninstitutional repositories. In ETDs, as with other scholarly works, figures and\ntables can communicate a large amount of information in a concise way. Although\nmethods have been proposed for extracting figures and tables from born-digital\nPDFs, they do not work well with scanned ETDs. Considering this problem, our\nassessment of state-of-the-art figure extraction systems is that the reason\nthey do not function well on scanned PDFs is that they have only been trained\non born-digital documents. To address this limitation, we present ScanBank, a\nnew dataset containing 10 thousand scanned page images, manually labeled by\nhumans as to the presence of the 3.3 thousand figures or tables found therein.\nWe use this dataset to train a deep neural network model based on YOLOv5 to\naccurately extract figures and tables from scanned ETDs. We pose and answer\nimportant research questions aimed at finding better methods for figure\nextraction from scanned documents. One of those concerns the value for\ntraining, of data augmentation techniques applied to born-digital documents\nwhich are used to train models better suited for figure extraction from scanned\ndocuments. To the best of our knowledge, ScanBank is the first manually\nannotated dataset for figure and table extraction for scanned ETDs. A\nYOLOv5-based model, trained on ScanBank, outperforms existing comparable\nopen-source and freely available baseline methods by a considerable margin.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 04:43:56 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kahu", "Sampanna Yashwant", ""], ["Ingram", "William A.", ""], ["Fox", "Edward A.", ""], ["Wu", "Jian", ""]]}, {"id": "2106.15541", "submitter": "Giacomo Vaccario Dr.", "authors": "Giacomo Vaccario and Luca Verginer", "title": "When standard network measures fail to rank journals: A theoretical and\n  empirical analysis", "comments": "17 pages, 6 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Journal rankings are widely used and are often based on citation data in\ncombination with a network perspective. We argue that some of these\nnetwork-based rankings can produce misleading results. From a theoretical point\nof view, we show that the standard network modelling approach of citation data\nat the journal level (i.e., the projection of paper citations onto journals)\nintroduces fictitious relations among journals. To overcome this problem, we\npropose a citation path perspective, and empirically show that rankings based\non the network and the citation path perspective are very different. Based on\nour theoretical and empirical analysis, we highlight the limitations of\nstandard network metrics, and propose a method to overcome these limitations\nand compute journal rankings.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:20:33 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Vaccario", "Giacomo", ""], ["Verginer", "Luca", ""]]}, {"id": "2106.16095", "submitter": "Hitoshi Koshiba", "authors": "Koshiba Hitoshi and HayashiI Kazuhiro", "title": "Differences between preprints and journal articles : Trial using bioRxiv\n  data", "comments": "17 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we attempted to obtain knowledge about how research is\nconducted, especially how journal articles are produced, by comparing preprints\nwith journal articles that are finally published.\n  First, due to the recent trend of open journals, we were able to secure a\ncertain amount of full-text XML of preprints and journal articles, and verified\nthe technical feasibility of comparing preprints and journal articles. On the\nother hand, within the scope of this trial, in which we tried to clarify the\ndifference between them based on external criteria such as the number of\nreferences and the number of words, and simple document similarity, we could\nnot find a clear difference between preprints and journal articles, or between\npreprints that became journal articles and those that did not. Even with the\nmachine learning method, the classification accuracy was not high at about 47%.\n  The result that there is no significant difference between preprints and\njournal articles is a finding that has been shown in previous studies and has\nbeen replicated in larger and relatively recent situations. In addition to\nthese, the new findings of this paper are that the differences in many external\ncriteria, such as the number of authors, are small, and the differences with\npreprints that are not journal articles are not large.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 14:41:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hitoshi", "Koshiba", ""], ["Kazuhiro", "HayashiI", ""]]}]