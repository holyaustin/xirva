[{"id": "1512.00126", "submitter": "Alex Zhavoronkov", "authors": "Yuri Nikolsky, Roman Gurinovich, Oleg Kuryan, Aleksandr Pashuk, Alexej\n  Scherbakov, Konstantin Romantsov, Leslie C. Jellen, Alex Zhavoronkov", "title": "GrantMed: a new, international system for tracking grants and funding\n  trends in the life sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of PubMed and other search engines in managing the\nmassive volume of biomedical literature and the retrieval of individual\npublications, grant-related data remains scattered and relatively inaccessible.\nThis is problematic, as project and funding data has significant analytical\nvalue and could be integral to publication retrieval. Here, we introduce\nGrantMed, a searchable international database of biomedical grants that\nintegrates some 20 million publications with the nearly 1.4 million research\nprojects and 650 billion dollars of funding that made them possible. For any\ngiven topic in the life sciences, Grantmed provides instantaneous visualization\nof the past 30 years of dollars spent and projects awarded, along with detailed\nindividual project descriptions, funding amounts, and links to investigators,\nresearch organizations, and resulting publications. It summarizes trends in\nfunding and publication rates for areas of interest and merges data from\nvarious national grant databases to create one international grant tracking\nsystem. This information will benefit the research community and funding\nentities alike. Users can view trends over time or current projects underway\nand use this information to navigate the decision-making process in moving\nforward. They can view projects prior to publication and records of previous\nprojects. Convenient access to this data for analytical purposes will be\nbeneficial in many ways, helping to prevent project overlap, reduce funding\nredundancy, identify areas of success, accelerate dissemination of ideas, and\nexpose knowledge gaps in moving forward. It is our hope that this will be a\ncentral resource for international life sciences research communities and the\nfunding organizations that support them, ultimately streamlining progress.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 03:06:47 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Nikolsky", "Yuri", ""], ["Gurinovich", "Roman", ""], ["Kuryan", "Oleg", ""], ["Pashuk", "Aleksandr", ""], ["Scherbakov", "Alexej", ""], ["Romantsov", "Konstantin", ""], ["Jellen", "Leslie C.", ""], ["Zhavoronkov", "Alex", ""]]}, {"id": "1512.00127", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Carla Aravena and Wei Ding", "title": "The cost of reading research. A study of Computer Science publication\n  venues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does the cost of academic publishing look like to the common researcher\ntoday? Our goal is to convey the current state of academic publishing,\nspecifically in regards to the field of computer science and provide analysis\nand data to be used as a basis for future studies. We will focus on author and\nreader costs as they are the primary points of interaction within the\npublishing world. In this work, we restrict our focus to only computer science\nin order to make the data collection more feasible (the authors are computer\nscientists) and hope future work can analyze and collect data across all\nacademic fields.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 03:09:55 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Aravena", "Carla", ""], ["Ding", "Wei", ""]]}, {"id": "1512.00443", "submitter": "Mark A. Matienzo", "authors": "Valentine Charles, Esm\\'e Cowles, Karen Estlund, Antoine Isaac, Tom\n  Johnson, Mark A. Matienzo, Patrick Peiffer, Richard J. Urban, Maarten\n  Zeinstra (International Rights Statements Working Group-Technical Working\n  Group)", "title": "Recommendations for the Technical Infrastructure for Standardized\n  International Rights Statements", "comments": "15 pages; released May 2015 at http://bit.ly/1QtmmmT 0 also available\n  at\n  http://rightsstatements.org/files/150701_recommendations_for_technical_infastructure_for_standardized_international_rights_statements.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This white paper is the product of a joint Digital Public Library of America\n(DPLA)-Europeana working group organized to develop minimum rights statement\nmetadata standards for organizations that contribute to DPLA and Europeana.\nThis white paper deals specifically with the technical infrastructure of a\ncommon namespace (rightsstatements.org) that hosts the rights statements to be\nused by (at minimum) the DPLA and Europeana. These recommendations for a common\ntechnical infrastructure for rights statements outline a simple, flexible, and\nextensible framework to host the rights statements at rightsstatements.org.\nThis white paper specifically outlines the management of rights statements as\nlinked open data. The rights statements are published according to Best\nPractices for Publishing RDF Vocabularies. They are encoded into\ndereferenceable URIs, express further information encoded in RDF, and link to\nexisting vocabularies and standards. The rights statements adhere to\nexpressions of existing rights vocabularies. Furthermore the paper reviews the\npublication and implementation to make the rights statements available through\nhuman-readable web pages augmented with machine-readable formats.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 20:54:37 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 15:51:45 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Charles", "Valentine", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Cowles", "Esm\u00e9", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Estlund", "Karen", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Isaac", "Antoine", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Johnson", "Tom", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Matienzo", "Mark A.", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Peiffer", "Patrick", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Urban", "Richard J.", "", "International Rights Statements Working Group-Technical Working\n  Group"], ["Zeinstra", "Maarten", "", "International Rights Statements Working Group-Technical Working\n  Group"]]}, {"id": "1512.00448", "submitter": "Bruce Desmarais", "authors": "Mia Costa, Bruce A. Desmarais, John A. Hird", "title": "Science Use in Regulatory Impact Analysis: The Effects of Political\n  Attention and Controversy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scholars, policymakers, and research sponsors have long sought to understand\nthe conditions under which scientific research is used in the policymaking\nprocess. Recent research has identified a resource that can be used to trace\nthe use of science across time and many policy domains. US federal agencies are\nmandated by executive order to justify all economically significant regulations\nby regulatory impact analyses (RIAs), in which they present evidence of the\nscientific underpinnings and consequences of the proposed rule. To gain new\ninsight into when and how regulators invoke science in their policy\njustifications, we ask: does the political attention and controversy\nsurrounding a regulation affect the extent to which science is utilized in\nRIAs? We examine scientific citation activity in all 101 economically\nsignificant RIAs from 2008-2012 and evaluate the effects of attention -- from\nthe public, policy elites and the media -- on the degree of science use in\nRIAs. Our main finding is that regulators draw more heavily on scientific\nresearch when justifying rules subject to a high degree of attention from\noutside actors. These findings suggest that scientific research plays an\nimportant role in the justification of regulations, especially those that are\nhighly salient to the public and other policy actors.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 01:57:51 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Costa", "Mia", ""], ["Desmarais", "Bruce A.", ""], ["Hird", "John A.", ""]]}, {"id": "1512.01364", "submitter": "Amelia Carolina Sparavigna", "authors": "A.C. Sparavigna and R. Marazzato", "title": "Using Google Ngram Viewer for Scientific Referencing and History of\n  Science", "comments": "Keywords: Computers and Society, Literary works, Time-series,\n  Referencing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, several universal digital libraries exist such as Google Books,\nProject Gutenberg, Internet Archive libraries, which possess texts from general\ncollections, and many other archives are available, concerning more specific\nsubjects. On the digitalized texts available from these libraries, we can\nperform several analyses, from those typically used for time-series to those of\nnetwork theory. For what concerns time-series, an interesting tool provided by\nGoogle Books exists, which can help us in bibliographical and reference\nresearches. This tool is the Ngram Viewer, based on yearly count of n-grams. As\nwe will show in this paper, although it seems suitable just for literary works,\nit can be useful for scientific researches, not only for history of science,\nbut also for acquiring references often unknown to researchers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 10:48:35 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Sparavigna", "A. C.", ""], ["Marazzato", "R.", ""]]}, {"id": "1512.01388", "submitter": "Jesper Schneider jws", "authors": "Jesper W. Schneider and Rodrigo Costas", "title": "Identifying potential breakthrough publications using refined citation\n  analyses: Three related explorative approaches", "comments": "Accepted for publication in Journal of the Association for\n  Information Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents three advanced citation-based methods used to detect\npotential breakthrough papers among very highly cited papers. We approach the\ndetection of such papers from three different perspectives in order to provide\ndifferent typologies of breakthrough papers. In all three cases we use the\nclassification of scientific publications developed at CWTS based on direct\ncitation relationships. This classification establishes clusters of papers at\nthree levels of aggregation. Papers are clustered based on their similar\ncitation orientations and it is assumed that they are focused on similar\nresearch interests. We use the clustering as the context for detecting\npotential breakthrough papers. We utilize the Characteristics Scores and Scales\n(CSS) approach to partition citation distributions and implement a specific\nfiltering algorithm to sort out potential highly-cited followers, papers not\nconsidered breakthroughs in themselves. After invoking thresholds and\nfiltering, three methods are explored: A very exclusive one where only the\nhighest cited paper in a micro-cluster is considered as a potential\nbreakthrough paper (M1); as well as two conceptually different methods, one\nthat detects potential breakthrough papers among the two percent highest cited\npapers according to CSS (M2a), and finally a more restrictive version where, in\naddition to the CSS two percent filter, knowledge diffusion is also taken in as\nan extra parameter (M2b). The advance citation-based methods are explored and\nevaluated using specifically validated publication sets linked to different\nDanish funding instruments including centres of excellence.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 12:33:07 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Schneider", "Jesper W.", ""], ["Costas", "Rodrigo", ""]]}, {"id": "1512.01420", "submitter": "A. Nihat Berker", "authors": "Nazli Yurdakul and A. Nihat Berker", "title": "A Comparative Study of Interdisciplinarity in Sciences in Brazil, South\n  Korea, Turkey, and USA", "comments": "Expanded study to include Brazil. More data, more conclusions. 6\n  pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comparative study is done of interdisciplinary citations in 2013 between\nphysics, chemistry, and molecular biology, in Brazil, South Korea, Turkey, and\nUSA. Several surprising conclusions emerge from our tabular and graphical\nanalysis: The cross-science citation rates are in general strikingly similar,\nbetween Brazil, South Korea, Turkey, and USA. One apparent exception is the\ncomparatively more tenuous relation between molecular biology and physics in\nBrazil and USA. Other slight exceptions are the higher amount of citing of\nphysicists by chemists in South Korea, of chemists by molecular biologists in\nTurkey, and of molecular biologists by chemists in Brazil and USA. Chemists\nare, by a sizable margin, the most cross-science citing scientists in this\ngroup of three sciences. Physicist are, again by a sizable margin, the least\ncross-science citing scientists in this group of three sciences. In all four\ncountries, the strongest cross-science citation is from chemistry to physics\nand the weakest cross-science citation is from physics to molecular biology.\nOur findings are consistent with a V-shaped backbone connectivity, as opposed\nto a Delta connectivity, as also found in a previous study of earlier citation\nyears.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 10:49:56 GMT"}, {"version": "v2", "created": "Fri, 11 Mar 2016 22:26:24 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Yurdakul", "Nazli", ""], ["Berker", "A. Nihat", ""]]}, {"id": "1512.01688", "submitter": "Mike Thelwall", "authors": "Mike Thelwall", "title": "The precision of the arithmetic mean, geometric mean and percentiles for\n  citation data: An experimental simulation modelling approach", "comments": "Thelwall, M. (in press). The precision of the arithmetic mean,\n  geometric mean and percentiles for citation data: An experimental simulation\n  modelling approach. Journal of Informetrics", "journal-ref": null, "doi": "10.1016/j.joi.2015.12.001", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing the citation impact of nations, departments or other groups of\nresearchers within individual fields, three approaches have been proposed:\narithmetic means, geometric means, and percentage in the top X%. This article\ncompares the precision of these statistics using 97 trillion experimentally\nsimulated citation counts from 6875 sets of different parameters (although all\nhaving the same scale parameter) based upon the discretised lognormal\ndistribution with limits from 1000 repetitions for each parameter set. The\nresults show that the geometric mean is the most precise, closely followed by\nthe percentage of a country's articles in the top 50% most cited articles for a\nfield, year and document type. Thus the geometric mean citation count is\nrecommended for future citation-based comparisons between nations. The\npercentage of a country's articles in the top 1% most cited is a particularly\nimprecise indicator and is not recommended for international comparisons based\non individual fields. Moreover, whereas standard confidence interval formulae\nfor the geometric mean appear to be accurate, confidence interval formulae are\nless accurate and consistent for percentile indicators. These recommendations\nassume that the scale parameters of the samples are the same but the choice of\nindicator is complex and partly conceptual if they are not.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 17:12:06 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Thelwall", "Mike", ""]]}, {"id": "1512.02019", "submitter": "Frank Berghaus", "authors": "DPHEP Collaboration: Silvia Amerio, Roberto Barbera, Frank Berghaus,\n  Jakob Blomer, Andrew Branson, Germ\\'an Cancio, Concetta Cartaro, Gang Chen,\n  S\\\"unje Dallmeier-Tiessen, Cristinel Diaconu, Gerardo Ganis, Mihaela Gheata,\n  Takanori Hara, Ken Herner, Mike Hildreth, Roger Jones, Stefan Kluth, Dirk\n  Kr\\\"ucker, Kati Lassila-Perini, Marcello Maggi, Jesus Marco de Lucas,\n  Salvatore Mele, Alberto Pace, Matthias Schr\\\"oder, Jetendr Shamdasani, Jamie\n  Shiers, Tim Smith, Randall Sobie, David Michael South, Andrii Verbytskyi,\n  Matthew Viljoen, Lu Wang, Markus Zimmermann", "title": "Status Report of the DPHEP Collaboration: A Global Effort for\n  Sustainable Data Preservation in High Energy Physics", "comments": "report, 60 pages", "journal-ref": null, "doi": "10.5281/zenodo.46158", "report-no": null, "categories": "hep-ex cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data from High Energy Physics (HEP) experiments are collected with\nsignificant financial and human effort and are mostly unique. An\ninter-experimental study group on HEP data preservation and long-term analysis\nwas convened as a panel of the International Committee for Future Accelerators\n(ICFA). The group was formed by large collider-based experiments and\ninvestigated the technical and organizational aspects of HEP data preservation.\nAn intermediate report was released in November 2009 addressing the general\nissues of data preservation in HEP and an extended blueprint paper was\npublished in 2012. In July 2014 the DPHEP collaboration was formed as a result\nof the signature of the Collaboration Agreement by seven large funding agencies\n(others have since joined or are in the process of acquisition) and in June\n2015 the first DPHEP Collaboration Workshop and Collaboration Board meeting\ntook place.\n  This status report of the DPHEP collaboration details the progress during the\nperiod from 2013 to 2015 inclusive.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 12:42:59 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 15:44:46 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["DPHEP Collaboration", "", ""], ["Amerio", "Silvia", ""], ["Barbera", "Roberto", ""], ["Berghaus", "Frank", ""], ["Blomer", "Jakob", ""], ["Branson", "Andrew", ""], ["Cancio", "Germ\u00e1n", ""], ["Cartaro", "Concetta", ""], ["Chen", "Gang", ""], ["Dallmeier-Tiessen", "S\u00fcnje", ""], ["Diaconu", "Cristinel", ""], ["Ganis", "Gerardo", ""], ["Gheata", "Mihaela", ""], ["Hara", "Takanori", ""], ["Herner", "Ken", ""], ["Hildreth", "Mike", ""], ["Jones", "Roger", ""], ["Kluth", "Stefan", ""], ["Kr\u00fccker", "Dirk", ""], ["Lassila-Perini", "Kati", ""], ["Maggi", "Marcello", ""], ["de Lucas", "Jesus Marco", ""], ["Mele", "Salvatore", ""], ["Pace", "Alberto", ""], ["Schr\u00f6der", "Matthias", ""], ["Shamdasani", "Jetendr", ""], ["Shiers", "Jamie", ""], ["Smith", "Tim", ""], ["Sobie", "Randall", ""], ["South", "David Michael", ""], ["Verbytskyi", "Andrii", ""], ["Viljoen", "Matthew", ""], ["Wang", "Lu", ""], ["Zimmermann", "Markus", ""]]}, {"id": "1512.02898", "submitter": "Marco Peressotti", "authors": "Dario De Nart and Dante Degl'Innocenti and Marco Peressotti", "title": "Well-Stratified Linked Data for Well-Behaved Data Citation", "comments": "in Bulletin of IEEE Technical Committee on Digital Libraries, Volume\n  12 Issue 1, May 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyse the functional requirements of linked data citation\nand identify a minimal set of operations and primitives needed to realize such\ntask. Citing linked data implies solving a series of data provenance issues and\nfinding a way to identify data subsets. Those two tasks can be handled defining\na simple type system inside data and verifying it with a type checker, which is\nsignificantly less complex than interpreting reified RDF statements and can be\nimplemented in a non data invasive way. Finally we suggest that data citation\nshould be handled outside of the data, possibly with an ad-hoc language.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 15:30:15 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 08:24:40 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 10:56:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["De Nart", "Dario", ""], ["Degl'Innocenti", "Dante", ""], ["Peressotti", "Marco", ""]]}, {"id": "1512.04214", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff, Henry Etzkowitz, and Duncan Kushnir", "title": "The Globalization of Academic Entrepreneurship? The Recent Growth\n  (2009-2014) in University Patenting Decomposed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of academia to US patents has become increasingly global.\nFollowing a pause, with a relatively flat rate, from 1998 to 2008, the\nlong-term trend of university patenting rising as a share of all patenting has\nresumed, driven by the internationalization of academic entrepreneurship and\nthe persistence of US university technology transfer. We disaggregate this\nrecent growth in university patenting at the US Patent and Trademark\nOrganization (USPTO) in terms of nations and patent classes. Foreign patenting\nin the US has almost doubled during the period 2009-2014, mainly due to\npatenting by universities in Taiwan, Korea, China, and Japan. These nations\ncompete with the US in terms of patent portfolios, whereas most European\ncountries--with the exception of the UK--have more specific portfolios, mainly\nin the bio-medical fields. In the case of China, Tsinghua University holds 63%\nof the university patents in USPTO, followed by King Fahd University with 55.2%\nof the national portfolio.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 08:14:24 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Leydesdorff", "Loet", ""], ["Etzkowitz", "Henry", ""], ["Kushnir", "Duncan", ""]]}, {"id": "1512.04250", "submitter": "Phillip Lord Dr", "authors": "Phillip Lord and Jennifer Warrendar", "title": "A Highly Literate Approach to Ontology Building", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ontologies present an attractive technology for describing bio-medicine,\nbecause they can be shared, and have rich computational properties. However,\nthey lack the rich expressivity of English and fit poorly with the current\nscientific \"publish or perish\" model. While, there have been attempts to\ncombine free text and ontologies, most of these perform \\textit{post-hoc}\nannotation of text. In this paper, we introduce our new environment which\nborrows from literate programming, to allow an author to co-develop both text\nand ontological description. We are currently using this environment to\ndocument the Karyotype Ontology which allows rich descriptions of the\nchromosomal complement in humans. We explore some of the advantages and\ndifficulties of this form of ontology development.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 10:43:52 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Lord", "Phillip", ""], ["Warrendar", "Jennifer", ""]]}, {"id": "1512.05004", "submitter": "Jaimie Murdock", "authors": "Jaimie Murdock and Jiaan Zeng and Colin Allen", "title": "Towards Evaluation of Cultural-scale Claims in Light of Topic Model\n  Sampling Effects", "comments": "2016 International Conference on Computational Social Science\n  (IC2S2), June 23-26, 2016. 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cultural-scale models of full text documents are prone to over-interpretation\nby researchers making unintentionally strong socio-linguistic claims (Pechenick\net al., 2015) without recognizing that even large digital libraries are merely\nsamples of all the books ever produced. In this study, we test the sensitivity\nof the topic models to the sampling process by taking random samples of books\nin the Hathi Trust Digital Library from different areas of the Library of\nCongress Classification Outline. For each classification area, we train several\ntopic models over the entire class with different random seeds, generating a\nset of spanning models. Then, we train topic models on random samples of books\nfrom the classification area, generating a set of sample models. Finally, we\nperform a topic alignment between each pair of models by computing the\nJensen-Shannon distance (JSD) between the word probability distributions for\neach topic. We take two measures on each model alignment: alignment distance\nand topic overlap. We find that sample models with a large sample size\ntypically have an alignment distance that falls in the range of the alignment\ndistance between spanning models. Unsurprisingly, as sample size increases,\nalignment distance decreases. We also find that the topic overlap increases as\nsample size increases. However, the decomposition of these measures by sample\nsize differs by number of topics and by classification area. We speculate that\nthese measures could be used to find classes which have a common \"canon\"\ndiscussed among all books in the area, as shown by high topic overlap and low\nalignment distance even in small sample sizes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 23:07:58 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 21:12:17 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 15:48:16 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Murdock", "Jaimie", ""], ["Zeng", "Jiaan", ""], ["Allen", "Colin", ""]]}, {"id": "1512.05057", "submitter": "Murali Krishna Enduri", "authors": "Murali Krishna Enduri, I. Vinod Reddy, Shivakumar Jolad", "title": "Does diversity of papers affect their citations? Evidence from American\n  Physical Society Journals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the correlation between interdisciplinarity of papers\nwithin physical sciences and their citations by using meta data of articles\npublished in American Physical Society's Physical Review journals between 1985\nto 2012. We use the Weitzman diversity index to measure the diversity of papers\nand authors, exploiting the hierarchical structure of PACS (Physics and\nAstronomy Classification Scheme) codes. We find that the fraction of authors\nwith high diversity is increasing with time, where as the fraction of least\ndiversity are decreasing, and moderate diversity authors have higher tendency\nto switch over to other diversity groups. The diversity index of papers is\ncorrelated with the citations they received in a given time period from their\npublication year. Papers with lower and higher end of diversity index receive\nlesser citations than the moderate diversity papers.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 05:55:43 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Enduri", "Murali Krishna", ""], ["Reddy", "I. Vinod", ""], ["Jolad", "Shivakumar", ""]]}, {"id": "1512.05382", "submitter": "Paul Hanel", "authors": "Paul H. P. Hanel", "title": "Why scientific publications should be anonymous", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies have revealed biases within the scientific communication\nsystem and across all scientific fields. For example, already prominent\nresearchers receive disproportional credit compared to their (almost) equally\nqualified colleagues -- because of their prominence. However, none of those\nstudies has offered a solution as to how to decrease the incidence of these\nbiases. In this paper I argue that by publishing anonymously, we can decrease\nthe incidence of inaccurate heuristics in the current scientific communication\nsystem. Specific suggestions are made as to how to implement the changes.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 21:39:55 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Hanel", "Paul H. P.", ""]]}, {"id": "1512.05741", "submitter": "Henk Moed", "authors": "Henk F. Moed, Judit Bar-Ilan and Gali Halevi", "title": "A new methodology for comparing Google Scholar and Scopus", "comments": "Version 26 April 2016 accepted for publication in Journal of\n  Informetrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new methodology is proposed for comparing Google Scholar (GS) with other\ncitation indexes. It focuses on the coverage and citation impact of sources,\nindexing speed, and data quality, including the effect of duplicate citation\ncounts. The method compares GS with Elsevier's Scopus, and is applied to a\nlimited set of articles published in 12 journals from six subject fields, so\nthat its findings cannot be generalized to all journals or fields. The study is\nexploratory, and hypothesis generating rather than hypothesis-testing. It\nconfirms findings on source coverage and citation impact obtained in earlier\nstudies. The ratio of GS over Scopus citation varies across subject fields\nbetween 1.0 and 4.0, while Open Access journals in the sample show higher\nratios than their non-OA counterparts. The linear correlation between GS and\nScopus citation counts at the article level is high: Pearson's R is in the\nrange of 0.8-0.9. A median Scopus indexing delay of two months compared to GS\nis largely though not exclusively due to missing cited references in articles\nin press in Scopus. The effect of double citation counts in GS due to multiple\ncitations with identical or substantially similar meta-data occurs in less than\n2 per cent of cases. Pros and cons of article-based and what is termed as\nconcept-based citation indexes are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 19:47:54 GMT"}, {"version": "v2", "created": "Sat, 30 Apr 2016 15:38:14 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Moed", "Henk F.", ""], ["Bar-Ilan", "Judit", ""], ["Halevi", "Gali", ""]]}, {"id": "1512.06195", "submitter": "Mohamed Aturban", "authors": "Mohamed Aturban, Michael L. Nelson, Michele C. Weigle", "title": "Quantifying Orphaned Annotations in Hypothes.is", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web annotation has been receiving increased attention recently with the\norganization of the Open Annotation Collaboration and new tools for open\nannotation, such as Hypothes.is. We investigate the prevalence of orphaned\nannotations, where neither the live Web page nor an archived copy of the Web\npage contains the text that had previously been annotated in the Hypothes.is\nannotation system (containing 20,953 highlighted text annotations). We found\nthat about 22% of highlighted text annotations can no longer be attached to\ntheir live Web pages. Unfortunately, only about 12% of these annotations can be\nreattached using the holdings of current public web archives, leaving the\nremaining 88% of these annotations orphaned. For those annotations that are\nstill attached, 53% are in danger of becoming orphans if the live Web page\nchanges. This points to the need for archiving the target of an annotation at\nthe time the annotation is created.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 05:57:32 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Aturban", "Mohamed", ""], ["Nelson", "Michael L.", ""], ["Weigle", "Michele C.", ""]]}, {"id": "1512.07069", "submitter": "Enrique Wulff Barreiro", "authors": "Enrique Wulff Barreiro", "title": "Using HistCite software to identify significant articles in subject\n  searches of the Web of Science", "comments": null, "journal-ref": "Documentaci{\\'o}n de las Ciencias de la Informaci{\\'o}n,\n  Universidad Complutense de Madrid, 2007, 30, pp.45-64.\n  http://revistas.ucm.es/index.php/DCIN/article/view/DCIN0707110045A", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HistCite TM is a large-scale computer tool for mapping science. Its power of\nvisualization combines the production of historiographs on the basis of the\nanalysis of co-citations of documents, with the use of bibliometrics specific\nindicators. The objective of this article is, to present the advantages of the\nnew bibliometrics configuration of HistCite TM (2004) when identifying\narticles. The analysis of the histograms that produces HistCite TM , in terms\nof cumulative advantage and aging of the citations. And the comparative study\nof the results of HistCite TM , in its indicators of amplitude and recognition.\nAlso is examined its treatment of the sampling problems, by formalizing the\nKendall method of estimating the robust standard deviation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 13:07:20 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Barreiro", "Enrique Wulff", ""]]}, {"id": "1512.07071", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Robin Haunschild, Werner Marx", "title": "Policy documents as sources for measuring societal impact: How often is\n  climate change research mentioned in policy-related documents?", "comments": "in press at Scientometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current UK Research Excellence Framework (REF) and the Excellence in\nResearch for Australia (ERA) societal impact measurements are inherent parts of\nthe national evaluation systems. In this study, we deal with a relatively new\nform of societal impact measurements. Recently, Altmetric - a start-up\nproviding publication level metrics - started to make data for publications\navailable which have been mentioned in policy documents. We regard this data\nsource as an interesting possibility to specifically measure the (societal)\nimpact of research. Using a comprehensive dataset with publications on climate\nchange as an example, we study the usefulness of the new data source for impact\nmeasurement. Only 1.2% (n=2,341) out of 191,276 publications on climate change\nin the dataset have at least one policy mention. We further reveal that papers\npublished in Nature and Science as well as from the areas \"Earth and related\nenvironmental sciences\" and \"Social and economic geography\" are especially\nrelevant in the policy context. Given the low coverage of the climate change\nliterature in policy documents, this study can be only a first attempt to study\nthis new source of altmetric data. Further empirical studies are necessary in\nupcoming years, because mentions in policy documents are of special interest in\nthe use of altmetric data for measuring target-oriented the broader impact of\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 13:09:52 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2016 13:04:34 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Bornmann", "Lutz", ""], ["Haunschild", "Robin", ""], ["Marx", "Werner", ""]]}, {"id": "1512.07193", "submitter": "Laura Waugh", "authors": "Laura Waugh, Hannah Tarver, Mark Phillips, Daniel Alemneh", "title": "Comparison of full-text versus metadata searching in an institutional\n  repository: Case study of the UNT Scholarly Works", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Authors in the library science field disagree about the importance of using\ncostly resources to create local metadata records, particularly for scholarly\nmaterials that have full-text search alternatives. At the University of North\nTexas (UNT) Libraries, we decided to test this concept by answering the\nquestion: What percentage of search terms retrieved results based on full-text\nversus metadata values for items in the UNT Scholarly Works institutional\nrepository? The analysis matched search query logs to indexes of the metadata\nrecords and full text of the items in the collection. Results show the\ndistribution of item discoveries that were based on metadata exclusively, on\nfull text exclusively, and on the combination of both. This paper describes in\ndetail the methods and findings of this study.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 18:33:44 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Waugh", "Laura", ""], ["Tarver", "Hannah", ""], ["Phillips", "Mark", ""], ["Alemneh", "Daniel", ""]]}, {"id": "1512.07250", "submitter": "Daniele Rotolo", "authors": "Alexander M. Petersen, Daniele Rotolo, and Loet Leydesdorff", "title": "A Triple Helix Model of Medical Innovation: Supply, Demand, and\n  Technological Capabilities in terms of Medical Subject Headings", "comments": "Accepted for publication in Research Policy (in press)", "journal-ref": "Research Policy 45(3), 666-681 (2016)", "doi": "10.1016/j.respol.2015.12.004", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model of innovation that enables us to trace the interplay among\nthree key dimensions of the innovation process: (i) demand of and (ii) supply\nfor innovation, and (iii) technological capabilities available to generate\ninnovation in the forms of products, processes, and services. Building on\ntriple helix research, we use entropy statistics to elaborate an indicator of\nmutual information among these dimensions that can provide indication of\nreduction of uncertainty. To do so, we focus on the medical context, where\nuncertainty poses significant challenges to the governance of innovation. We\nuse the Medical Subject Headings (MeSH) of MEDLINE/PubMed to identify\npublications classified within the categories \"Diseases\" (C), \"Drugs and\nChemicals\" (D), \"Analytic, Diagnostic, and Therapeutic Techniques and\nEquipment\" (E) and use these as knowledge representations of demand, supply,\nand technological capabilities, respectively. Three case-studies of medical\nresearch areas are used as representative 'entry perspectives' of the medical\ninnovation process. These are: (i) human papilloma virus, (ii) RNA\ninterference, and (iii) magnetic resonance imaging. We find statistically\nsignificant periods of synergy among demand, supply, and technological\ncapabilities (C-D-E) that point to three-dimensional interactions as a\nfundamental perspective for the understanding and governance of the uncertainty\nassociated with medical innovation. Among the pairwise configurations in these\ncontexts, the demand-technological capabilities (C-E) provided the strongest\nlink, followed by the supply-demand (D-C) and the supply-technological\ncapabilities (D-E) channels.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 20:58:25 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 13:14:39 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Petersen", "Alexander M.", ""], ["Rotolo", "Daniele", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1512.07919", "submitter": "Alice Allen", "authors": "Alice Allen, G. Bruce Berriman, Kimberly DuPrie, Jessica Mink, Robert\n  Nemiroff, Thomas Robitaille, Lior Shamir, Keith Shortridge, Mark Taylor,\n  Peter Teuben, John Wallin", "title": "Improving Software Citation and Credit", "comments": "Birds of a Feather session organized by the Astrophysics Source Code\n  Library (ASCL, http://ascl.net/ ); to be published in Proceedings of ADASS\n  XXV (Sydney, Australia; October, 2015). 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past year has seen movement on several fronts for improving software\ncitation, including the Center for Open Science's Transparency and Openness\nPromotion (TOP) Guidelines, the Software Publishing Special Interest Group that\nwas started at January's AAS meeting in Seattle at the request of that\norganization's Working Group on Astronomical Software, a Sloan-sponsored\nmeeting at GitHub in San Francisco to begin work on a cohesive research\nsoftware citation-enabling platform, the work of Force11 to \"transform and\nimprove\" research communication, and WSSSPE's ongoing efforts that include\nsoftware publication, citation, credit, and sustainability.\n  Brief reports on these efforts were shared at the BoF, after which\nparticipants discussed ideas for improving software citation, generating a list\nof recommendations to the community of software authors, journal publishers,\nADS, and research authors. The discussion, recommendations, and feedback will\nhelp form recommendations for software citation to those publishers represented\nin the Software Publishing Special Interest Group and the broader community.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 21:01:08 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Allen", "Alice", ""], ["Berriman", "G. Bruce", ""], ["DuPrie", "Kimberly", ""], ["Mink", "Jessica", ""], ["Nemiroff", "Robert", ""], ["Robitaille", "Thomas", ""], ["Shamir", "Lior", ""], ["Shortridge", "Keith", ""], ["Taylor", "Mark", ""], ["Teuben", "Peter", ""], ["Wallin", "John", ""]]}, {"id": "1512.08395", "submitter": "Mathieu Andro", "authors": "Mathieu Andro, Imad Saleh", "title": "Biblioth\\`eques num\\'eriques et gamification : panorama et \\'etat de\n  l'art", "comments": "in French.\n  http://www.adbs.fr/i2d-n-4-decembre-2015-dossier-les-services-d-information-au-prisme-de-la-valeur-153432.htm", "journal-ref": "I2D -- Information, donn\\'ees & documents, A.D.B.S., 2015, 52 (4),\n  pp.70-79", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an overview of the main gamification projects for\ndigital libraries, either for tagging or OCR correction. This overview is\nfollowed by a state of the art with functionalities, motivations, sociology of\ncontributors and the scope of gamification compared to the serious games and\nexplicit crowdsourcing. Finally a comparison of results between explicit\ncrowdsourcing and gamification is proposed.\n  [English Title: Digital libraries and gamification: overview and state of the\nart]\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 12:59:17 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Andro", "Mathieu", ""], ["Saleh", "Imad", ""]]}, {"id": "1512.08754", "submitter": "Lawrence Smolinsky", "authors": "Lawrence Smolinsky", "title": "Discrete power law with exponential cutoff and Lotka's Law", "comments": "11 pages", "journal-ref": "Journal of Informetrics 13 (2019) 462-463", "doi": "10.1016/j.joi.2019.02.005", "report-no": null, "categories": "cs.DL physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first bibliometric law appeared in Alfred J. Lotka's 1926 examination of\nauthor productivity in chemistry and physics. The result is that the\nproductivity distribution is thought to be described by a power law. In this\npaper, Lotka's original data on author productivity in chemistry is\nreconsidered by comparing the fit of the data to both a discrete power law and\na discrete power law with exponential cutoff.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 18:59:38 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Smolinsky", "Lawrence", ""]]}, {"id": "1512.09023", "submitter": "Lovro \\v{S}ubelj", "authors": "Lovro \\v{S}ubelj, Nees Jan van Eck, Ludo Waltman", "title": "Clustering scientific publications based on citation relations: A\n  systematic comparison of different methods", "comments": "24 pages, 7 figures, 7 tables", "journal-ref": "PLoS ONE 11(4), e0154404 (2016)", "doi": "10.1371/journal.pone.0154404", "report-no": null, "categories": "cs.DL cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering methods are applied regularly in the bibliometric literature to\nidentify research areas or scientific fields. These methods are for instance\nused to group publications into clusters based on their relations in a citation\nnetwork. In the network science literature, many clustering methods, often\nreferred to as graph partitioning or community detection techniques, have been\ndeveloped. Focusing on the problem of clustering the publications in a citation\nnetwork, we present a systematic comparison of the performance of a large\nnumber of these clustering methods. Using a number of different citation\nnetworks, some of them relatively small and others very large, we extensively\nstudy the statistical properties of the results provided by different methods.\nIn addition, we also carry out an expert-based assessment of the results\nproduced by different methods. The expert-based assessment focuses on\npublications in the field of scientometrics. Our findings seem to indicate that\nthere is a trade-off between different properties that may be considered\ndesirable for a good clustering of publications. Overall, map equation methods\nappear to perform best in our analysis, suggesting that these methods deserve\nmore attention from the bibliometric community.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 17:20:27 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 10:54:11 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["\u0160ubelj", "Lovro", ""], ["van Eck", "Nees Jan", ""], ["Waltman", "Ludo", ""]]}, {"id": "1512.09070", "submitter": "Robert B. Allen", "authors": "Robert Burnell Allen", "title": "Repositories with Direct Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new generation of digital repositories could be based on direct\nrepresentation of the contents with rich semantics and models rather than be\ncollections of documents. The contents of such repositories would be highly\nstructured which should help users to focus on meaningful relationships of the\ncontents. These repositories would implement earlier proposals for\nmodel-oriented information organization by extending current work on ontologies\nto cover state changes, instances, and scenarios. They could also apply other\napproaches such as object-oriented design and frame semantics. In addition to\nsemantics, the representation needs to allow for discourse and repository\nknowledge-support services and policies. For instance, the knowledge base would\nneed to be systematically updated as new findings and theories reshape it.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 19:27:15 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Allen", "Robert Burnell", ""]]}]