[{"id": "1911.00295", "submitter": "Stephanie Van De Sandt", "authors": "Stephanie van de Sandt, Lars Holm Nielsen, Alexandros Ioannidis,\n  August Muench, Edwin Henneken, Alberto Accomazzi, Chiara Bigarella, Jose\n  Benito Gonzalez Lopez, S\\\"unje Dallmeier-Tiessen", "title": "Practice meets Principle: Tracking Software and Data Citations to Zenodo\n  DOIs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data and software citations are crucial for the transparency of research\nresults and for the transmission of credit. But they are hard to track, because\nof the absence of a common citation standard. As a consequence, the FORCE11\nrecently proposed data and software citation principles as guidance for\nauthors. Zenodo is recognized for the implementation of DOIs for software on a\nlarge scale. The minting of complementary DOIs for the version and concept\nallows measuring the impact of dynamic software. This article investigates\ncharacteristics of 5,456 citations to Zenodo data and software that were\ncaptured by the Asclepias Broker in January 2019. We analyzed the current state\nof data and software citation practices and the quality of software citation\nrecommendations with regard to the impact of recent standardization efforts.\nOur findings prove that current citation practices and recommendations do not\nmatch proposed citation standards. We consequently suggest practical first\nsteps towards the implementation of the software citation principles.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:51:01 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["van de Sandt", "Stephanie", ""], ["Nielsen", "Lars Holm", ""], ["Ioannidis", "Alexandros", ""], ["Muench", "August", ""], ["Henneken", "Edwin", ""], ["Accomazzi", "Alberto", ""], ["Bigarella", "Chiara", ""], ["Lopez", "Jose Benito Gonzalez", ""], ["Dallmeier-Tiessen", "S\u00fcnje", ""]]}, {"id": "1911.00760", "submitter": "Sendong Zhao", "authors": "Sendong Zhao, Chang Su, Andrea Sboner, Fei Wang", "title": "GRAPHENE: A Precise Biomedical Literature Retrieval Engine with Graph\n  Augmented Deep Learning and External Knowledge Empowerment", "comments": "CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3358038", "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective biomedical literature retrieval (BLR) plays a central role in\nprecision medicine informatics. In this paper, we propose GRAPHENE, which is a\ndeep learning based framework for precise BLR. GRAPHENE consists of three main\ndifferent modules 1) graph-augmented document representation learning; 2) query\nexpansion and representation learning and 3) learning to rank biomedical\narticles. The graph-augmented document representation learning module\nconstructs a document-concept graph containing biomedical concept nodes and\ndocument nodes so that global biomedical related concept from external\nknowledge source can be captured, which is further connected to a BiLSTM so\nboth local and global topics can be explored. Query expansion and\nrepresentation learning module expands the query with abbreviations and\ndifferent names, and then builds a CNN-based model to convolve the expanded\nquery and obtain a vector representation for each query. Learning to rank\nminimizes a ranking loss between biomedical articles with the query to learn\nthe retrieval function. Experimental results on applying our system to TREC\nPrecision Medicine track data are provided to demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:05:20 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 20:39:33 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhao", "Sendong", ""], ["Su", "Chang", ""], ["Sboner", "Andrea", ""], ["Wang", "Fei", ""]]}, {"id": "1911.02533", "submitter": "Manolis Antonoyiannakis", "authors": "Manolis Antonoyiannakis", "title": "Impact Factor volatility to a single paper: A comprehensive analysis", "comments": "Quantitative Science Studies (accepted). arXiv admin note: text\n  overlap with arXiv:1906.02660", "journal-ref": "Quantitative Science Studies 1, 639 (2020)", "doi": "10.1162/qss_a_00037", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how a single paper affects the Impact Factor (IF) by analyzing data\nfrom 3,088,511 papers published in 11639 journals in the 2017 Journal Citation\nReports of Clarivate Analytics. We find that IFs are highly volatile. For\nexample, the top-cited paper of 381 journals caused their IF to increase by\nmore than 0.5 points, while for 818 journals the relative increase exceeded\n25%. And one in 10 journals had their IF boosted by more than 50% by their top\nthree cited papers. Because the single-paper effect on the IF is inversely\nproportional to journal size, small journals are rewarded much more strongly\nthan large journals for a highly-cited paper, while they are penalized more for\na low-cited paper, especially if their IF is high. This skewed reward mechanism\nincentivizes high-IF journals to stay small, to remain competitive in rankings.\nWe discuss the implications for breakthrough papers appearing in prestigious\njournals. We question the reliability of IF rankings given the high IF\nsensitivity to a few papers for thousands of journals.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:03:21 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 00:58:35 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Antonoyiannakis", "Manolis", ""]]}, {"id": "1911.02562", "submitter": "Robert O'Shea", "authors": "Robert O'Shea", "title": "Gextext: Disease Network Extraction from Biomedical Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PURPOSE: We propose a fully unsupervised method to learn latent disease\nnetworks directly from unstructured biomedical text corpora. This method\naddresses current challenges in unsupervised knowledge extraction, such as the\ndetection of long-range dependencies and requirements for large training\ncorpora. METHODS: Let C be a corpus of n text chunks. Let V be a set of p\ndisease terms occurring in the corpus. Let X indicate the occurrence of V in C.\nGextext identifies disease similarities by positively correlated occurrence\npatterns. This information is combined to generate a graph on which geodesic\ndistance describes dissimilarity. Diseasomes were learned by Gextext and GloVE\non corpora of 100-1000 PubMed abstracts. Similarity matrix estimates were\nvalidated against biomedical semantic similarity metrics and gene profile\nsimilarity. RESULTS: Geodesic distance on Gextext-inferred diseasomes\ncorrelated inversely with external measures of semantic similarity. Gene\nprofile similarity also correlated significant with proximity on the inferred\ngraph. Gextext outperformed GloVE in our experiments. The information contained\non the Gextext graph exceeded the explicit information content within the text.\nCONCLUSIONS: Gextext extracts latent relationships from unstructured text,\nenabling fully unsupervised modelling of diseasome graphs from PubMed\nabstracts.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 10:57:38 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 10:15:39 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["O'Shea", "Robert", ""]]}, {"id": "1911.02648", "submitter": "Philippe Vincent-Lamarre", "authors": "Philippe Vincent-Lamarre and Vincent Larivi\\`ere", "title": "Textual analysis of artificial intelligence manuscripts reveals features\n  associated with peer review outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We analysed a dataset of scientific manuscripts that were submitted to\nvarious conferences in artificial intelligence. We performed a combination of\nsemantic, lexical and psycholinguistic analyses of the full text of the\nmanuscripts and compared them with the outcome of the peer review process. We\nfound that accepted manuscripts scored lower than rejected manuscripts on two\nindicators of readability, and that they also used more scientific and\nartificial intelligence jargon. We also found that accepted manuscripts were\nwritten with words that are less frequent, that are acquired at an older age,\nand that are more abstract than rejected manuscripts. The analysis of\nreferences included in the manuscripts revealed that the subset of accepted\nsubmissions were more likely to cite the same publications. This finding was\nechoed by pairwise comparisons of the word content of the manuscripts (i.e. an\nindicator or semantic similarity), which were more similar in the subset of\naccepted manuscripts. Finally, we predicted the peer review outcome of\nmanuscripts with their word content, with words related to machine learning and\nneural networks positively related with acceptance, whereas words related to\nlogic, symbolic processing and knowledge-based systems negatively related with\nacceptance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:36:51 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:07:13 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Vincent-Lamarre", "Philippe", ""], ["Larivi\u00e8re", "Vincent", ""]]}, {"id": "1911.02712", "submitter": "Han Zhuang", "authors": "Han Zhuang and Daniel E. Acuna", "title": "The effect of novelty on the future impact of scientific grants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Government funding agencies and foundations tend to perceive novelty as\nnecessary for scientific impact and hence prefer to fund novel instead of\nincremental projects. Evidence linking novelty and the eventual impact of a\ngrant is surprisingly scarce, however. Here, we examine this link by analyzing\n920,000 publications funded by 170,000 grants from the National Science\nFoundation (NSF) and the National Institutes of Health (NIH) between 2008 and\n2016. We use machine learning to quantify grant novelty at the time of funding\nand relate that measure to the citation dynamics of these publications. Our\nresults show that grant novelty leads to robust increases in citations while\ncontrolling for the principal investigator's grant experience, award amount,\nyear of publication, prestige of the journal, and team size. All else held\nconstant, an article resulting from a fully-novel grant would on average double\nthe citations of a fully-incremental grant. We also find that novel grants\nproduce as many articles as incremental grants while publishing in higher\nprestige journals. Taken together, our results provide compelling evidence\nsupporting NSF, NIH, and many other funding agencies' emphases on novelty.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:47:35 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhuang", "Han", ""], ["Acuna", "Daniel E.", ""]]}, {"id": "1911.02782", "submitter": "Lucy Lu Wang", "authors": "Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, Dan S. Weld", "title": "S2ORC: The Semantic Scholar Open Research Corpus", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce S2ORC, a large corpus of 81.1M English-language academic papers\nspanning many academic disciplines. The corpus consists of rich metadata, paper\nabstracts, resolved bibliographic references, as well as structured full text\nfor 8.1M open access papers. Full text is annotated with automatically-detected\ninline mentions of citations, figures, and tables, each linked to their\ncorresponding paper objects. In S2ORC, we aggregate papers from hundreds of\nacademic publishers and digital archives into a unified source, and create the\nlargest publicly-available collection of machine-readable academic text to\ndate. We hope this resource will facilitate research and development of tools\nand tasks for text mining over academic text.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 07:34:43 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 03:48:03 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:40:21 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Lo", "Kyle", ""], ["Wang", "Lucy Lu", ""], ["Neumann", "Mark", ""], ["Kinney", "Rodney", ""], ["Weld", "Dan S.", ""]]}, {"id": "1911.02854", "submitter": "Juste Raimbault", "authors": "Denise Pumain and Juste Raimbault", "title": "Perspectives on urban theories", "comments": "31 pages, 3 figures, 2 tables", "journal-ref": "In: Pumain D. (eds) Theories and Models of Urbanization (pp.\n  303-330). Lecture Notes in Morphogenesis. Springer, Cham (2020)", "doi": "10.1007/978-3-030-36656-8_16", "report-no": null, "categories": "cs.DL cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the end of the five years of work in our GeoDiverCity program, we brought\ntogether a diversity of authors from different disciplines. Each person was\ninvited to present an important question about the theories and models of\nurbanization. They are representative of a variety of currents in urban\nresearch. Rather than repeat here the contents of all chapters, we propose two\nways to synthesize the scientific contributions of this book. In a first part\nwe replace them in relation to a few principles that were experimented in our\nprogram, and in a second part we situate them with respect to a broader view of\ninternational literature on these topics.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:13:25 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 11:28:48 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Pumain", "Denise", ""], ["Raimbault", "Juste", ""]]}, {"id": "1911.03379", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Verena Weigert, Liz Allen, Zena Nyakoojo, Eleanor-Rose\n  Papas", "title": "Does the use of open, non-anonymous peer review in scholarly publishing\n  introduce bias? Evidence from the F1000 post-publication open peer review\n  publishing model", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study examines whether there is any evidence of bias in two areas of\ncommon critique of open, non-anonymous peer review - and used in the\npost-publication, peer review system operated by the open-access scholarly\npublishing platform F1000Research. First, is there evidence of bias where a\nreviewer based in a specific country assesses the work of an author also based\nin the same country? Second, are reviewers influenced by being able to see the\ncomments and know the origins of previous reviewer? Methods: Scrutinising the\nopen peer review comments published on F1000Research, we assess the extent of\ntwo frequently cited potential influences on reviewers that may be the result\nof the transparency offered by a fully attributable, open peer review\npublishing model: the national affiliations of authors and reviewers, and the\nability of reviewers to view previously-published reviewer reports before\nsubmitting their own. The effects of these potential influences were\ninvestigated for all first versions of articles published by 8 July 2019 to\nF1000Research. In 16 out of the 20 countries with the most articles, there was\na tendency for reviewers based in the same country to give a more positive\nreview. The difference was statistically significant in one. Only 3 countries\nhad the reverse tendency. Second, there is no evidence of a conformity bias.\nWhen reviewers mentioned a previous review in their peer review report, they\nwere not more likely to give the same overall judgement. Although reviewers who\nhad longer to potentially read a previously published reviewer reports were\nslightly less likely to agree with previous reviewer judgements, this could be\ndue to these articles being difficult to judge rather than deliberate\nnon-conformity.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:59:50 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Thelwall", "Mike", ""], ["Weigert", "Verena", ""], ["Allen", "Liz", ""], ["Nyakoojo", "Zena", ""], ["Papas", "Eleanor-Rose", ""]]}, {"id": "1911.03562", "submitter": "Saif Mohammad Dr.", "authors": "Saif M. Mohammad", "title": "The State of NLP Literature: A Diachronic Analysis of the ACL Anthology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ACL Anthology (AA) is a digital repository of tens of thousands of\narticles on Natural Language Processing (NLP). This paper examines the\nliterature as a whole to identify broad trends in productivity, focus, and\nimpact. It presents the analyses in a sequence of questions and answers. The\ngoal is to record the state of the AA literature: who and how many of us are\npublishing? what are we publishing on? where and in what form are we\npublishing? and what is the impact of our publications? The answers are usually\nin the form of numbers, graphs, and inter-connected visualizations. Special\nemphasis is laid on the demographics and inclusiveness of NLP publishing.\nNotably, we find that only about 30% of first authors are female, and that this\npercentage has not improved since the year 2000. We also show that, on average,\nfemale first authors are cited less than male first authors, even when\ncontrolling for experience. We hope that recording citation and participation\ngaps across demographic groups will encourage more inclusiveness and fairness\nin research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:15:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Mohammad", "Saif M.", ""]]}, {"id": "1911.04548", "submitter": "Attila Varga", "authors": "Attila Varga", "title": "Shorter Distances between Papers over Time are Due to More Cross-Field\n  References and Increased Citation Rate to Higher Impact Papers", "comments": null, "journal-ref": "PNAS (116)44: 22094-22099p (2019)", "doi": "10.1073/pnas.1905819116", "report-no": null, "categories": "cs.SI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential increase in the number of scientific publications raises the\nquestion of whether the sciences are expanding into a fractured structure,\nmaking cross-field communication difficult. On the other hand, scientists may\nbe motivated to learn extensively across fields to enhance their innovative\ncapacity, and this may offset the negative effects of fragmentation. Through an\ninvestigation of the distances within and clustering of cross-sectional\ncitation networks, this study presents evidence that fields of science become\nmore integrated over time. The average citation distance between papers\npublished in the same year decreased from approximately 5.33 to 3.18 steps\nbetween 1950 and 2018. This observation is attributed to the growth of\ncross-field communication throughout the entire period as well as the growing\nimportance of high impact papers to bridge networks in the same year. Three\nempirical findings support this conclusion. First, distances decreased between\nalmost all disciplines throughout the time period. Second, inequality in the\nnumber of citations received by papers increased, and as a consequence the\nshortest paths in the network depend more on high impact papers later in the\nperiod. Third, the dispersion of connections between fields increased\ncontinually. Moreover, these changes did not entail a lower level of clustering\nof citations. Both within- and cross-field citations show a similar rate of\nslowly growing clustering values in all years. The latter findings suggest that\ndomain spanning scholarly communication is partly enabled by new fields that\nconnect disciplines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 20:10:41 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Varga", "Attila", ""]]}, {"id": "1911.04625", "submitter": "Mark A. Matienzo", "authors": "Emily Goodmann, Mark A. Matienzo, Shawn VanCour, William Vanden Dries", "title": "Building the National Radio Recordings Database: A Big Data Approach to\n  Documenting Audio Heritage", "comments": "7 pages; accepted by 4th Computational Archival Science (CAS)\n  workshop, IEEE Big Data 2019", "journal-ref": "2019 IEEE International Conference on Big Data (Big Data), Los\n  Angeles, CA, USA, 2019, pp. 3080-3086", "doi": "10.1109/BigData47090.2019.9006520", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper traces strategies used by the Radio Preservation Task Force of the\nLibrary of Congress's National Recording Preservation Board to develop a\npublicly searchable database documenting extant radio materials held by\ncollecting institutions throughout the country. Having aggregated metadata on\n2,500 unique collections to date, the project has encountered a series of\nlogistical challenges that are not only technical in nature but also\ninstitutional and social, raising critical issues involving organizational\nstructure, political representation, and the ethics of data access. As the\nproject continues to expand and evolve, lessons from its early development\noffer valuable reminders of the human judgment, hidden labor, and interpersonal\nrelations required for successful big data work.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:59:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Goodmann", "Emily", ""], ["Matienzo", "Mark A.", ""], ["VanCour", "Shawn", ""], ["Dries", "William Vanden", ""]]}, {"id": "1911.05197", "submitter": "Lawrence Smolinsky", "authors": "Lawrence Smolinsky", "title": "Arbitrage opportunities in publication and ghost authors", "comments": null, "journal-ref": "Journal of Informetrics (2020)", "doi": "10.1016/j.joi.2020.101016", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some research evaluation systems, credit awarded to an article depends on\nthe number of co-authors on the article with total credit to the article\nincreasing with the number of co-authors. There are many examples of such\nevaluation systems (e.g., the United States National Research Council\nevaluation of graduate programs gave full credit to each co-author). Such\ncredit systems run the risk of encouraging ghost or honorary authorships. In a\nrecent article, Antonio Osorio and Lutz Bornmann (2019) propose a scheme to\ndiscourage ghost authorships but increase the total credit to a paper when\nco-authorships increase. It is shown that if articles are valued more highly as\nthe number of co-authorships increases, then there are opportunities to\nincrease credit by mutually agreeing to add each other as authors. Unrelated\nauthors of unrelated papers may all benefit by expanding their co-author list.\nI call this phenomena arbitrage--a term borrowed from economics and\nfinance--since the content of the articles do not change, but the value\nincreases by moving to a \"market\" of more co-authors where articles are valued\ndifferently.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:14:17 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Smolinsky", "Lawrence", ""]]}, {"id": "1911.08775", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Sitaram Devarakonda, Alexander Tekles, George Chacko", "title": "Do disruption index indicators measure what they propose to measure? The\n  comparison of several indicator variants with assessments by peers", "comments": null, "journal-ref": null, "doi": "10.1162/qss_a_00068", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Wu, Wang, and Evans (2019) and Bu, Waltman, and Huang (2019)\nproposed a new family of indicators, which measure whether a scientific\npublication is disruptive to a field or tradition of research. Such disruptive\ninfluences are characterized by citations to a focal paper, but not its cited\nreferences. In this study, we are interested in the question of convergent\nvalidity, i.e., whether these indicators of disruption are able to measure what\nthey propose to measure ('disruptiveness'). We used external criteria of\nnewness to examine convergent validity: in the post-publication peer review\nsystem of F1000Prime, experts assess papers whether the reported research\nfulfills these criteria (e.g., reports new findings). This study is based on\n120,179 papers from F1000Prime published between 2000 and 2016. In the first\npart of the study we discuss the indicators. Based on the insights from the\ndiscussion, we propose alternate variants of disruption indicators. In the\nsecond part, we investigate the convergent validity of the indicators and the\n(possibly) improved variants. Although the results of a factor analysis show\nthat the different variants measure similar dimensions, the results of\nregression analyses reveal that one variant (DI5) performs slightly better than\nthe others.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:01:38 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bornmann", "Lutz", ""], ["Devarakonda", "Sitaram", ""], ["Tekles", "Alexander", ""], ["Chacko", "George", ""]]}, {"id": "1911.09041", "submitter": "Laura Koesten", "authors": "Laura Koesten, Kathleen Gregory, Paul Groth, Elena Simperl", "title": "Talking datasets: Understanding data sensemaking behaviours", "comments": "26 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sharing and reuse of data are seen as critical to solving the most\ncomplex problems of today. Despite this potential, relatively little is known\nabout a key step in data reuse: people's behaviours involved in data-centric\nsensemaking. We aim to address this gap by presenting a mixed-methods study\ncombining in-depth interviews, a think-aloud task and a screen recording\nanalysis with 31 researchers as they summarised and interacted with both\nfamiliar and unfamiliar data. We use our findings to identify and detail common\nactivity patterns and necessary data attributes across three clusters of\nsensemaking activities: inspecting data, engaging with content, and placing\ndata within broader contexts. We conclude by proposing design recommendations\nfor tools and documentation practices which can be used to facilitate\nsensemaking and subsequent data reuse.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:14:18 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 17:17:03 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 16:36:18 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Koesten", "Laura", ""], ["Gregory", "Kathleen", ""], ["Groth", "Paul", ""], ["Simperl", "Elena", ""]]}, {"id": "1911.09197", "submitter": "James Davis", "authors": "James Davis", "title": "Do top conferences contain well cited papers or junk?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to answer questions about top conference publication patterns,\ncitation data is collected and analyzed for several computer science\nconferences, with focus on computer vision and graphics. Both top and second\ntier conferences are included, and sampling occurred for two different 5 year\nperiods. Example questions include: Do top conferences contain well cited\npapers or junk? (Yes) Are top conferences similarly cited? (No) Are second tier\nconferences as good as first tier conferences? (Sometimes) Has something been\nchanging at CVPR? (Yes)\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 22:24:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Davis", "James", ""]]}, {"id": "1911.10745", "submitter": "Chao Lu", "authors": "Chao Lu, Yingyi Zhang, Yong-Yeol Ahn, Ying Ding, Chenwei Zhang, Dandan\n  Ma", "title": "Co-contributorship Network and Division of Labor in Individual\n  Scientific Collaborations", "comments": "accepted by JASIST", "journal-ref": "Journal of Association for Information Science and Technology 2019", "doi": "10.1002/asi.24321", "report-no": null, "categories": "cs.SI cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborations are pervasive in current science. Collaborations have been\nstudied and encouraged in many disciplines. However, little is known how a team\nreally functions from the detailed division of labor within. In this research,\nwe investigate the patterns of scientific collaboration and division of labor\nwithin individual scholarly articles by analyzing their co-contributorship\nnetworks. Co-contributorship networks are constructed by performing the\none-mode projection of the author-task bipartite networks obtained from 138,787\npapers published in PLoS journals. Given a paper, we define three types of\ncontributors: Specialists, Team-players, and Versatiles. Specialists are those\nwho contribute to all their tasks alone; team-players are those who contribute\nto every task with other collaborators; and versatiles are those who do both.\nWe find that team-players are the majority and they tend to contribute to the\nfive most common tasks as expected, such as \"data analysis\" and \"performing\nexperiments\". The specialists and versatiles are more prevalent than expected\nby a random-graph null model. Versatiles tend to be senior authors associated\nwith funding and supervisions. Specialists are associated with two contrasting\nroles: the supervising role as team leaders or marginal and specialized\ncontributions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:45:35 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 23:41:20 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Lu", "Chao", ""], ["Zhang", "Yingyi", ""], ["Ahn", "Yong-Yeol", ""], ["Ding", "Ying", ""], ["Zhang", "Chenwei", ""], ["Ma", "Dandan", ""]]}, {"id": "1911.10892", "submitter": "Chaitra", "authors": "Chaitra, Sara Bertocco, Marco Molinaro, Sergio Molinari, Antonio\n  Ragagnin, and Giuliano Taffoni", "title": "Exposing SED Models And Snapshots Via VO Simulation Artefacts", "comments": "4 pages, 2 figures The 29th annual international Astronomical Data\n  Analysis Software & Systems ( ADASS) conference held at Groningen from\n  October 6-10, 2019 This is a proceedings submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Virtual Observatory (VO) simulation standards, Simulation Data Model\n(SimDM) and Simulation Data Access Layer (SimDAL), establish a framework for\nthe discoverability and dissemination of data created in simulation projects.\nThese standards address the complexity of having a standard access and facade\nfor data which is expected to be multifaceted and, of a diverse range. In this\npaper, we detail the realisation of an application exposing the theoretical\nproducts of one such scientific project via the simulation facades proposed by\nthe VO. The scientific project in question, is a study of the evolution of\nyoung clusters in dense molecular clumps. The theoretical products arising from\nthis study include a grid of 20 million SED (Spectral Energy Distribution)\nmodels for synthetic young clusters and related data products. Details on the\nimplementation of SimDAL components in the application as well as the ways in\nwhich the data structures of SimDM are incorporated onto the existing data\nproducts are provided.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:39:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chaitra", "", ""], ["Bertocco", "Sara", ""], ["Molinaro", "Marco", ""], ["Molinari", "Sergio", ""], ["Ragagnin", "Antonio", ""], ["Taffoni", "Giuliano", ""]]}, {"id": "1911.11240", "submitter": "Julian Risch", "authors": "Julian Risch and Ralf Krestel", "title": "My Approach = Your Apparatus? Entropy-Based Topic Modeling on Multiple\n  Domain-Specific Text Collections", "comments": null, "journal-ref": "Proceedings of the 18th ACM/IEEE Joint Conference on Digital\n  Libraries (JCDL). bll. 283-292 (2018)", "doi": "10.1145/3197026.3197038", "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparative text mining extends from genre analysis and political bias\ndetection to the revelation of cultural and geographic differences, through to\nthe search for prior art across patents and scientific papers. These\napplications use cross-collection topic modeling for the exploration,\nclustering, and comparison of large sets of documents, such as digital\nlibraries. However, topic modeling on documents from different collections is\nchallenging because of domain-specific vocabulary. We present a\ncross-collection topic model combined with automatic domain term extraction and\nphrase segmentation. This model distinguishes collection-specific and\ncollection-independent words based on information entropy and reveals\ncommonalities and differences of multiple text collections. We evaluate our\nmodel on patents, scientific papers, newspaper articles, forum posts, and\nWikipedia articles. In comparison to state-of-the-art cross-collection topic\nmodeling, our model achieves up to 13% higher topic coherence, up to 4% lower\nperplexity, and up to 31% higher document classification accuracy. More\nimportantly, our approach is the first topic model that ensures disjunct\ngeneral and specific word distributions, resulting in clear-cut topic\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:29:59 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Risch", "Julian", ""], ["Krestel", "Ralf", ""]]}, {"id": "1911.11926", "submitter": "Filipi Nascimento Silva", "authors": "Filipi Nascimento Silva, Aditya Tandon, Diego Raphael Amancio,\n  Alessandro Flammini, Filippo Menczer, Sta\\v{s}a Milojevi\\'c and Santo\n  Fortunato", "title": "Recency predicts bursts in the evolution of author citations", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1162/qss_a_00070", "report-no": null, "categories": "cs.DL cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The citations process for scientific papers has been studied extensively. But\nwhile the citations accrued by authors are the sum of the citations of their\npapers, translating the dynamics of citation accumulation from the paper to the\nauthor level is not trivial. Here we conduct a systematic study of the\nevolution of author citations, and in particular their bursty dynamics. We find\nempirical evidence of a correlation between the number of citations most\nrecently accrued by an author and the number of citations they receive in the\nfuture. Using a simple model where the probability for an author to receive new\ncitations depends only on the number of citations collected in the previous\n12-24 months, we are able to reproduce both the citation and burst size\ndistributions of authors across multiple decades.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 02:52:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Silva", "Filipi Nascimento", ""], ["Tandon", "Aditya", ""], ["Amancio", "Diego Raphael", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""], ["Milojevi\u0107", "Sta\u0161a", ""], ["Fortunato", "Santo", ""]]}, {"id": "1911.12637", "submitter": "Carlos Badenes-Olmedo", "authors": "Carlos Badenes-Olmedo, Jose-Luis Redondo-Garcia and Oscar Corcho", "title": "Legal document retrieval across languages: topic hierarchies based on\n  synsets", "comments": "IberLegal Workshop co-located with Jurix 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-lingual annotations of legislative texts enable us to explore major\nthemes covered in multilingual legal data and are a key facilitator of semantic\nsimilarity when searching for similar documents. Multilingual probabilistic\ntopic models have recently emerged as a group of semi-supervised machine\nlearning models that can be used to perform thematic explorations on\ncollections of texts in multiple languages. However, these approaches require\ntheme-aligned training data to create a language-independent space, which\nlimits the amount of scenarios where this technique can be used. In this work,\nwe provide an unsupervised document similarity algorithm based on hierarchies\nof multi-lingual concepts to describe topics across languages. The algorithm\ndoes not require parallel or comparable corpora, or any other type of\ntranslation resource. Experiments performed on the English, Spanish, French and\nPortuguese editions of JCR-Acquis corpora reveal promising results on\nclassifying and sorting documents by similar content.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 10:49:36 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Badenes-Olmedo", "Carlos", ""], ["Redondo-Garcia", "Jose-Luis", ""], ["Corcho", "Oscar", ""]]}]