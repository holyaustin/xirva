[{"id": "1403.0068", "submitter": "Nithya C", "authors": "C. Nithya and K. Saravanan", "title": "Semantic Annotation and Search for Educational Resources Supporting\n  Distance Learning", "comments": "Linked Data, Semantic search, Cloud Applications, Web services,\n  Semantic annotation, Ontology", "journal-ref": "IJETT V8(6),277-285 February 2014. ISSN:2231-5381", "doi": "10.14445/22315381/IJETT-V8P252", "report-no": null, "categories": "cs.IR cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Multimedia educational resources play an important role in education,\nparticularly for distance learning environments. With the rapid growth of the\nmultimedia web, large numbers of education articles video resources are\nincreasingly being created by several different organizations. It is crucial to\nexplore, share, reuse, and link these educational resources for better\ne-learning experiences. Most of the video resources are currently annotated in\nan isolated way, which means that they lack semantic connections. Thus,\nproviding the facilities for annotating these video resources is highly\ndemanded. These facilities create the semantic connections among video\nresources and allow their metadata to be understood globally. Adopting Linked\nData technology, this paper introduces a video annotation and browser platform\nwith two online tools: Notitia and Sansu-Wolke. Notitia enables users to\nsemantically annotate video resources using vocabularies defined in the Linked\nData cloud. Sansu-Wolke allows users to browse semantically linked educational\nvideo resources with enhanced web information from different online resources.\nIn the prototype development, the platform uses existing video resources for\neducation articles. The result of the initial development demonstrates the\nbenefits of applying Linked Data technology in the aspects of reusability,\nscalability, and extensibility\n", "versions": [{"version": "v1", "created": "Sat, 1 Mar 2014 09:26:35 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Nithya", "C.", ""], ["Saravanan", "K.", ""]]}, {"id": "1403.1180", "submitter": "Nikos Chondros", "authors": "Nikos Chondros, Mema Roussopoulos", "title": "A distributed Integrity Catalog for digital repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital repositories, either digital preservation systems or archival\nsystems, periodically check the integrity of stored objects to assure users of\ntheir correctness. To do so, prior solutions calculate integrity metadata and\nrequire the repository to store it alongside the actual data objects. This\nintegrity metadata is essential for regularly verifying the correctness of the\nstored data objects. To safeguard and detect damage to this metadata, prior\nsolutions rely on widely visible media, that is unaffiliated third parties, to\nstore and provide back digests of the metadata to verify it is intact. However,\nthey do not address recovery of the integrity metadata in case of damage or\nattack by an adversary. In essence, they do not preserve this metadata. We\nintroduce IntegrityCatalog, a system that collects all integrity related\nmetadata in a single component, and treats them as first class objects,\nmanaging both their integrity and their preservation. We introduce a\ntreap-based persistent authenticated dictionary managing arbitrary length\nkey/value pairs, which we use to store all integrity metadata, accessible\nsimply by object name. Additionally, IntegrityCatalog is a distributed system\nthat includes a network protocol that manages both corruption detection and\npreservation of this metadata, using administrator-selected network peers with\ntwo possible roles. Verifiers store and offer attestations on digests and have\nminimal storage requirements, while preservers efficiently synchronize a\ncomplete copy of the catalog to assist in recovery in case of a detected\ncatalog compromise on the local system. We describe our prototype\nimplementation of IntegrityCatalog, measure its performance empirically, and\ndemonstrate its effectiveness in real-world situations, with worst measured\nthroughput of approximately 1K insertions per second, and 2K verified search\noperations per second.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 17:52:22 GMT"}, {"version": "v2", "created": "Thu, 25 Sep 2014 09:13:02 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Chondros", "Nikos", ""], ["Roussopoulos", "Mema", ""]]}, {"id": "1403.1310", "submitter": "Roshan Ragel", "authors": "M.A.C. Jiffriya, M.A.C. Akmal Jahan, R.G. Ragel and S. Deegalla", "title": "AntiPlag: Plagiarism Detection on Electronic Submissions of Text Based\n  Assignments", "comments": null, "journal-ref": "Industrial and Information Systems (ICIIS), 2013 8th IEEE\n  International Conference on, pp. 376 - 380, 17-20 Dec. 2013", "doi": "10.1109/ICIInfS.2013.6732013", "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plagiarism is one of the growing issues in academia and is always a concern\nin Universities and other academic institutions. The situation is becoming even\nworse with the availability of ample resources on the web. This paper focuses\non creating an effective and fast tool for plagiarism detection for text based\nelectronic assignments. Our plagiarism detection tool named AntiPlag is\ndeveloped using the tri-gram sequence matching technique. Three sets of text\nbased assignments were tested by AntiPlag and the results were compared against\nan existing commercial plagiarism detection tool. AntiPlag showed better\nresults in terms of false positives compared to the commercial tool due to the\npre-processing steps performed in AntiPlag. In addition, to improve the\ndetection latency, AntiPlag applies a data clustering technique making it four\ntimes faster than the commercial tool considered. AntiPlag could be used to\nisolate plagiarized text based assignments from non-plagiarised assignments\neasily. Therefore, we present AntiPlag, a fast and effective tool for\nplagiarism detection on text based electronic assignments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 01:16:01 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Jiffriya", "M. A. C.", ""], ["Jahan", "M. A. C. Akmal", ""], ["Ragel", "R. G.", ""], ["Deegalla", "S.", ""]]}, {"id": "1403.1349", "submitter": "Sam Anzaroot", "authors": "Sam Anzaroot, Alexandre Passos, David Belanger, Andrew McCallum", "title": "Learning Soft Linear Constraints with Application to Citation Field\n  Extraction", "comments": "appears in Proc. the 52nd Annual Meeting of the Association for\n  Computational Linguistics (ACL2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately segmenting a citation string into fields for authors, titles, etc.\nis a challenging task because the output typically obeys various global\nconstraints. Previous work has shown that modeling soft constraints, where the\nmodel is encouraged, but not require to obey the constraints, can substantially\nimprove segmentation performance. On the other hand, for imposing hard\nconstraints, dual decomposition is a popular technique for efficient prediction\ngiven existing algorithms for unconstrained inference. We extend the technique\nto perform prediction subject to soft constraints. Moreover, with a technique\nfor performing inference given soft constraints, it is easy to automatically\ngenerate large families of constraints and learn their costs with a simple\nconvex optimization problem during training. This allows us to obtain\nsubstantial gains in accuracy on a new, challenging citation extraction\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 05:24:02 GMT"}, {"version": "v2", "created": "Fri, 17 Oct 2014 13:27:02 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Anzaroot", "Sam", ""], ["Passos", "Alexandre", ""], ["Belanger", "David", ""], ["McCallum", "Andrew", ""]]}, {"id": "1403.1745", "submitter": "Arnab Chatterjee", "authors": "Abdul Khaleque, Arnab Chatterjee, Parongama Sen", "title": "On the evolution and utility of annual citation indices", "comments": "7 pages, 8 figs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistics of citations made to the top ranked indexed journals\nfor Science and Social Science databases in the Journal Citation Reports using\ndifferent measures. Total annual citation and impact factor, as well as a third\nmeasure called the annual citation rate are used to make the detailed analysis.\nWe observe that the distribution of the annual citation rate has an universal\nfeature - it shows a maximum at the rate scaled by half the average,\nirrespective of how the journals are ranked, and even across Science and Social\nScience journals, and fits well to log-Gumbel distribution. Correlations\nbetween different quantities are studied and a comparative analysis of the\nthree measures is presented. The newly introduced annual citation rate factor\nhelps in understanding the effect of scaling the number of citation by the\ntotal number of publications. The effect of the impact factor on authors\ncontributing to the journals as well as on editorial policies is also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 13:28:36 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Khaleque", "Abdul", ""], ["Chatterjee", "Arnab", ""], ["Sen", "Parongama", ""]]}, {"id": "1403.2036", "submitter": "Mathew McLean", "authors": "Mathew W. McLean", "title": "Straightforward Bibliography Management in R with the RefManageR Package", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces the R package RefManageR, which provides tools for\nimporting and working with bibliographic references. It extends the bibentry\nclass in R in a number of useful ways, including providing R with previously\nunavailable support for BibLaTeX. BibLaTeX provides a superset of the\nfunctionality of BibTeX, including full Unicode support, no memory limitations,\nadditional fields and entry types, and more sophisticated sorting of\nreferences. RefManageR provides functions for citing and generating a\nbibliography with hyperlinks for documents prepared with RMarkdown or RHTML.\nExisting .bib files can be read into R and converted from BibTeX to BibLaTeX\nand vice versa. References can also be imported via queries to NCBI's Entrez,\nZotero libraries, Google Scholar, and CrossRef. Additionally, references can be\ncreated by reading PDFs stored on the user's machine with the help of Poppler.\nEntries stored in the reference manager can be easily searched by any field, by\ndate ranges, and by various formats for name lists (author by last names,\ntranslator by full names, etc.). Entries can also be updated, combined, sorted,\nprinted in a number of styles, and exported.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 08:09:02 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["McLean", "Mathew W.", ""]]}, {"id": "1403.2096", "submitter": "Daniele Rotolo", "authors": "Antonio Messeni Petruzzelli, Daniele Rotolo, Vito Albino", "title": "Determinants of Patent Citations in Biotechnology: An Analysis of Patent\n  Influence Across the Industrial and Organizational Boundaries", "comments": "Technological Forecasting and Social Change (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper extends the literature investigating key drivers leading\ncertain patents to exert a stronger influence on the subsequent technological\ndevelopments (inventions) than other ones. We investigated six key\ndeterminants, as (i) the use of scientific knowledge, (ii) the breadth of the\ntechnological base, (iii) the existence of collaboration in patent development,\n(iv) the number of claims, (v) the scope, and (vi) the novelty, and how the\neffect of these determinants varies when patent influence - as measured by the\nnumber of forward citations the patent received - is distinguished as within\nand across the industrial and organizational boundaries. We conducted an\nempirical analysis on a sample of 5671 patents granted to 293 US biotechnology\nfirms from 1976 to 2003. Results reveal that the contribution of the\ndeterminants to patent influence differs across the domains that are identified\nby the industrial and organizational boundaries. Findings, for example, show\nthat the use of scientific knowledge negatively affects patent influence\noutside the biotechnology industry, while it positively contributes to make a\npatent more relevant for the assignee's subsequent technological developments.\nIn addition, the broader the scope of a patent the higher the number of\ncitations the patent receives from subsequent non-biotechnology patents. This\nrelationship is inverted-U shaped when considering the influence of a patent on\ninventions granted to other organizations than the patent's assignee. Finally,\nthe novelty of a patent is inverted-U related with the influence the patent\nexerts on the subsequent inventions granted across the industrial and\norganizational boundaries.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 19:46:03 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Petruzzelli", "Antonio Messeni", ""], ["Rotolo", "Daniele", ""], ["Albino", "Vito", ""]]}, {"id": "1403.2140", "submitter": "Illes Farkas", "authors": "Adam Szanto-Varnagy, Peter Pollner, Tamas Vicsek, Illes J. Farkas", "title": "Scientometrics: Untangling the topics", "comments": "2 pages, 2 figures", "journal-ref": "National Science Review (September 2014) 1 (3): 343-345", "doi": "10.1093/nsr/nwu027", "report-no": null, "categories": "cs.DL cs.SI physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring science is based on comparing articles to similar others. However,\nkeyword-based groups of thematically similar articles are dominantly small.\nThese small sizes keep the statistical errors of comparisons high. With the\ngrowing availability of bibliographic data such statistical errors can be\nreduced by merging methods of thematic grouping, citation networks and keyword\nco-usage.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 06:05:51 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2014 07:51:29 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Szanto-Varnagy", "Adam", ""], ["Pollner", "Peter", ""], ["Vicsek", "Tamas", ""], ["Farkas", "Illes J.", ""]]}, {"id": "1403.2642", "submitter": "Camilo Calderon", "authors": "Richard H. Taylor, Frisco Rose, Cormac Toher, Ohad Levy, Marco\n  Buongiorno Nardelli, Stefano Curtarolo", "title": "A RESTful API for exchanging Materials Data in the AFLOWLIB.org\n  consortium", "comments": "22 pages, 7 figures", "journal-ref": "Comp. Mat. Sci., 93, 2014, 178-192", "doi": "10.1016/j.commatsci.2014.05.014", "report-no": null, "categories": "cond-mat.mtrl-sci cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continued advancement of science depends on shared and reproducible data.\nIn the field of computational materials science and rational materials design\nthis entails the construction of large open databases of materials properties.\nTo this end, an Application Program Interface (API) following REST principles\nis introduced for the AFLOWLIB.org materials data repositories consortium.\nAUIDs (Aflowlib Unique IDentifier) and AURLs (Aflowlib Uniform Resource\nlocator) are assigned to the database resources according to a well-defined\nprotocol described herein, which enables the client to access, through\nappropriate queries, the desired data for post-processing. This introduces a\nnew level of openness into the AFLOWLIB repository, allowing the community to\nconstruct high-level work-flows and tools exploiting its rich data set of\ncalculated structural, thermodynamic, and electronic properties. Furthermore,\nfederating these tools would open the door to collaborative investigation of\nthe data by an unprecedented extended community of users to accelerate the\nadvancement of computational materials design and development.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 16:49:19 GMT"}, {"version": "v2", "created": "Wed, 19 Mar 2014 16:25:06 GMT"}, {"version": "v3", "created": "Fri, 2 May 2014 23:00:46 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Taylor", "Richard H.", ""], ["Rose", "Frisco", ""], ["Toher", "Cormac", ""], ["Levy", "Ohad", ""], ["Nardelli", "Marco Buongiorno", ""], ["Curtarolo", "Stefano", ""]]}, {"id": "1403.2656", "submitter": "Robert White", "authors": "Robert R. White and Kristin Munch", "title": "Handling Large and Complex Data in a Photovoltaic Research Institution\n  Using a Custom Laboratory Information Management System", "comments": "12 pages, 8 figures Prepared for the MRS Fall 2013 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twenty-five years ago the desktop computer started becoming ubiquitous in the\nscientific lab. Researchers were delighted with its ability to both control\ninstrumentation and acquire data on a single system, but they were not\ncompletely satisfied. There were often gaps in knowledge that they thought\nmight be gained if they just had more data and they could get the data faster.\nComputer technology has evolved in keeping with Moore's Law meeting those\ndesires; however those improvement have of late become both a boon and bane for\nresearchers. Computers are now capable of producing high speed data streams\ncontaining terabytes of information; capabilities that evolved faster than\nenvisioned last century. Software to handle large scientific data sets has not\nkept up. How much information might be lost through accidental mismanagement or\nhow many discoveries are missed through data overload are now vital questions.\nAn important new task in most scientific disciplines involves developing\nmethods to address those issues and to create software that can handle large\ndata sets with an eye towards scalability. This software must create archived,\nindexed, and searchable data from heterogeneous instrumentation for the\nimplementation of a strong data-driven materials development strategy. At the\nNational Center for Photovoltaics in the National Renewable Energy Lab, we\nbegan development a few years ago on a Laboratory Information Management System\n(LIMS) designed to handle lab-wide scientific data acquisition, management,\nprocessing, and mining needs for physics and materials science data. and with a\nspecific focus on future scalability for new equipment or research focuses. We\nwill present the decisions, process, and problems we went through while\nbuilding our LIMS for materials research, its current operational state, and\nour steps for future development.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 17:24:42 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["White", "Robert R.", ""], ["Munch", "Kristin", ""]]}, {"id": "1403.2787", "submitter": "Sta\\v{s}a Milojevi\\'c", "authors": "Sta\\v{s}a Milojevi\\'c", "title": "Principles of scientific research team formation and evolution", "comments": "Published in PNAS. Model tested on astronomy. Published version and\n  Supplemental Information available at\n  http://www.pnas.org/cgi/doi/10.1073/pnas.1309723111", "journal-ref": null, "doi": "10.1073/pnas.1309723111", "report-no": null, "categories": "physics.soc-ph astro-ph.IM cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research teams are the fundamental social unit of science, and yet there is\ncurrently no model that describes their basic property: size. In most fields\nteams have grown significantly in recent decades. We show that this is partly\ndue to the change in the character of team-size distribution. We explain these\nchanges with a comprehensive yet straightforward model of how teams of\ndifferent sizes emerge and grow. This model accurately reproduces the evolution\nof empirical team-size distribution over the period of 50 years. The modeling\nreveals that there are two modes of knowledge production. The first and more\nfundamental mode employs relatively small, core teams. Core teams form by a\nPoisson process and produce a Poisson distribution of team sizes in which\nlarger teams are exceedingly rare. The second mode employs extended teams,\nwhich started as core teams, but subsequently accumulated new members\nproportional to the past productivity of their members. Given time, this mode\ngives rise to a power-law tail of large teams (10-1000 members), which features\nin many fields today. Based on this model we construct an analytical functional\nform that allows the contribution of different modes of authorship to be\ndetermined directly from the data and is applicable to any field. The model\nalso offers a solid foundation for studying other social aspects of science,\nsuch as productivity and collaboration.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 01:49:33 GMT"}], "update_date": "2014-03-13", "authors_parsed": [["Milojevi\u0107", "Sta\u0161a", ""]]}, {"id": "1403.2941", "submitter": "Jinyun Yan", "authors": "Graham Cormode and S. Muthukrishnan and Jinyun Yan", "title": "People Like Us: Mining Scholarly Data for Comparable Researchers", "comments": "BigScholar at WWW 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the problem of finding comparable researchers for any given\nresearcher. This problem has many motivations. Firstly, know thyself. The\nanswers of where we stand among research community and who we are most alike\nmay not be easily found by existing evaluations of ones' research mainly based\non citation counts. Secondly, there are many situations where one needs to find\ncomparable researchers e.g., for reviewing peers, constructing programming\ncommittees or compiling teams for grants. It is often done through an ad hoc\nand informal basis. Utilizing the large scale scholarly data accessible on the\nweb, we address the problem of automatically finding comparable researchers. We\npropose a standard to quantify the quality of research output, via the quality\nof publishing venues. We represent a researcher as a sequence of her\npublication records, and develop a framework of comparison of researchers by\nsequence matching. Several variations of comparisons are considered including\nmatching by quality of publication venue and research topics, and performing\nprefix matching. We evaluate our methods on a large corpus and demonstrate the\neffectiveness of our methods through examples. In the end, we identify several\npromising directions for further work.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 02:13:10 GMT"}, {"version": "v2", "created": "Sun, 6 Jul 2014 22:15:51 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Cormode", "Graham", ""], ["Muthukrishnan", "S.", ""], ["Yan", "Jinyun", ""]]}, {"id": "1403.5107", "submitter": "Klaus Jaffe Dr", "authors": "Klaus Jaffe", "title": "Social and Natural Sciences Differ in Their Research Strategies, Adapted\n  to Work for Different Knowledge Landscapes", "comments": "Formerly called: Simulations suggest that social and natural sciences\n  differ in their research strategies adapted to work for different knowledge\n  landscapes", "journal-ref": "PLoS ONE 9(11): e113901. (2014)", "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do different fields of knowledge require different research strategies? A\nnumerical model exploring different virtual knowledge landscapes, revealed two\ndiverging optimal search strategies. Trend following is maximized when the\npopularity of new discoveries determine the number of individuals researching\nit. This strategy works best when many researchers explore few large areas of\nknowledge. In contrast, individuals or small groups of researchers are better\nin discovering small bits of information in dispersed knowledge landscapes.\nBibliometric data of scientific publications showed a continuous bipolar\ndistribution of these strategies, ranging from natural sciences, with highly\ncited publications in journals containing a large number of articles, to the\nsocial sciences, with rarely cited publications in many journals containing a\nsmall number of articles. The natural sciences seem to adapt their research\nstrategies to landscapes with large concentrated knowledge clusters, whereas\nsocial sciences seem to have adapted to search in landscapes with many small\nisolated knowledge clusters. Similar bipolar distributions were obtained when\ncomparing levels of insularity estimated by indicators of international\ncollaboration and levels of country-self citations: researchers in academic\nareas with many journals such as social sciences, arts and humanities, were the\nmost isolated, and that was true in different regions of the world. The work\nshows that quantitative measures estimating differences between academic\ndisciplines improve our understanding of different research strategies,\neventually helping interdisciplinary research and may be also help improve\nscience policies worldwide.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 11:57:13 GMT"}, {"version": "v2", "created": "Thu, 16 Oct 2014 19:49:32 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2015 14:01:28 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Jaffe", "Klaus", ""]]}, {"id": "1403.6656", "submitter": "Alberto Accomazzi", "authors": "Alberto Accomazzi, Norman Gray, Chris Erdmann, Chris Biemesderfer,\n  Katie Frey, and Justin Soles", "title": "The Unified Astronomy Thesaurus", "comments": "4 pages, 1 figure, to appear in Proceedings of Astronomical Data\n  Analysis Software and Systems XXIII, which took place September 29-October 3,\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unified Astronomy Thesaurus (UAT) is an open, interoperable and\ncommunity-supported thesaurus which unifies the existing divergent and isolated\nAstronomy & Astrophysics vocabularies into a single high-quality,\nfreely-available open thesaurus formalizing astronomical concepts and their\ninter-relationships. The UAT builds upon the existing IAU Thesaurus with major\ncontributions from the astronomy portions of the thesauri developed by the\nInstitute of Physics Publishing, the American Institute of Physics, and SPIE.\nWe describe the effort behind the creation of the UAT and the process through\nwhich we plan to maintain the document updated through broad community\nparticipation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2014 12:46:31 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Accomazzi", "Alberto", ""], ["Gray", "Norman", ""], ["Erdmann", "Chris", ""], ["Biemesderfer", "Chris", ""], ["Frey", "Katie", ""], ["Soles", "Justin", ""]]}, {"id": "1403.7748", "submitter": "Sandra Payette", "authors": "Sandy Payette", "title": "The State of Technology for Digital Archiving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The Windsor Study Group on Digital Archiving was commissioned to recommend\nstrategies, policies, and technologies necessary for ensuring the integrity and\nlongevity of electronic publications. The goal of this work is to inform\ninstitutions of the challenges and opportunities faced by information stewards\nin fulfilling their mission of guaranteeing a permanent and authoritative\nscholarly record in the digital age. This white paper focuses specifically on\nthe technological dimensions of digital archiving. It provides an analysis of\nthe current state of technologies as well as a forecast of how digital archive\nsystems are likely to evolve over the next decade. The thesis of this white\npaper is that technology does not present a barrier to long term digital\narchiving, but instead presents an opportunity to harness the current and\nfuture power of these technologies to create the architectural underpinnings of\na comprehensive digital archiving strategy.\n", "versions": [{"version": "v1", "created": "Sun, 30 Mar 2014 12:34:34 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Payette", "Sandy", ""]]}, {"id": "1403.7827", "submitter": "David Fabian Klosik", "authors": "David F. Klosik, Stefan Bornholdt, Marc-Thorsten H\\\"utt", "title": "Motif-based success scores in coauthorship networks are highly sensitive\n  to author name disambiguation", "comments": "7 pages, 7 figures", "journal-ref": "Phys. Rev. E 90, 032811 (2014)", "doi": "10.1103/PhysRevE.90.032811", "report-no": null, "categories": "physics.soc-ph cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the work of Krumov et al. [Eur. Phys. J. B 84, 535 (2011)] we\nrevisit the question whether the usage of large citation datasets allows for\nthe quantitative assessment of social (by means of coauthorship of\npublications) influence on the progression of science. Applying a more\ncomprehensive and well-curated dataset containing the publications in the\njournals of the American Physical Society during the whole 20th century we find\nthat the measure chosen in the original study, a score based on small induced\nsubgraphs, has to be used with caution, since the obtained results are highly\nsensitive to the exact implementation of the author disambiguation task.\n", "versions": [{"version": "v1", "created": "Sun, 30 Mar 2014 22:39:48 GMT"}, {"version": "v2", "created": "Thu, 2 Oct 2014 13:12:32 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Klosik", "David F.", ""], ["Bornholdt", "Stefan", ""], ["H\u00fctt", "Marc-Thorsten", ""]]}, {"id": "1403.7899", "submitter": "Wilko van Hoek", "authors": "Wilko van Hoek, Wei Shen and Philipp Mayr", "title": "Identifying User Behavior in domain-specific Repositories", "comments": "Elpub Conference 2014, 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an analysis of the user behavior of two different\ndomain-specific repositories. The web analytic tool etracker was used to gain a\nfirst overall insight into the user behavior of these repositories. Moreover,\nwe extended our work to describe an apache web log analysis approach which\nfocuses on the identification of the user behavior. Therefore the user traffic\nwithin our systems is visualized using chord diagrams. We could find that\nrecommendations are used frequently and users do rarely combine searching with\nfaceting or filtering.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 07:51:43 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["van Hoek", "Wilko", ""], ["Shen", "Wei", ""], ["Mayr", "Philipp", ""]]}]