[{"id": "1703.01072", "submitter": "Mokhtar Ben Henda", "authors": "Mokhtar Ben Henda (MICA)", "title": "\\'Etude sur les portails et agr\\'egateurs des ressources p\\'edagogiques\n  universitaires francophones en acc\\`es libre", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study responds to the first measure undertaken on July 17, 2015 by\nIDNEUF prject, that of an exploratory analysis of the existing portals and\naggregators of free French-language academic resources. The idea is to provide\nan overview of the most common trends and practices in the constitution and\norganization of digital online learning resource portals. The study of these\ntrends would help to define the appropriate choices and conditions for\ndesigning the future common French-language portal and to optimize its services\nfor the conservation, exchange, integration and pooling of educational\nresources within the distributed technological framework of French-language\nuniversities. This framework should therefore be interconnected, transparent\nand interoperable, reflecting both the linguistic and cultural specificities of\npartner institutions and their ambitions for technological and economic\ndevelopments. The development of this first exploratory study of portals would\ntake into account the two technological solutions discussed at the task force\nmeeting on 17 July 2015.1. The alternative of extending the capabilities of\nFrance's Digital University's search engine to French-language academic\ninstitutions will require that the experience of the UNT (Numerical Thematic\nUniversity) be taken into account as a key player in the digital portal In\nhigher education (supnumerique.gouv.fr). Thus, the present study should first\ntarget the portals of the UNT as models replicable or extensible to the French\ncontext by analyzing their technological choices, their modes of organization\nand their modes of use and communication;2. Next, the study will not be limited\nto analyzing UNT portals. The proposed hypothesis to create a common portal of\nFrench portals from the existing university portals also requires exploring\nthis possibility and proposing an analysis of existing portals that function\naccording to other organizational models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 08:05:43 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Henda", "Mokhtar Ben", "", "MICA"]]}, {"id": "1703.01319", "submitter": "Philipp Mayr", "authors": "Thomas Kr\\\"amer, Fakhri Momeni, Philipp Mayr", "title": "Coverage of Author Identifiers in Web of Science and Scopus", "comments": "23 pages, 1 figure, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As digital collections of scientific literature are widespread and used\nfrequently in knowledge-intense working environments, it has become a challenge\nto identify author names correctly. The treatment of homonyms is crucial for\nthe reliable resolution of author names. Apart from varying handling of first,\nmiddle and last names, vendors as well as the digital library community created\ntools to address the problem of author name disambiguation. This technical\nreport focuses on two widespread collections of scientific literature, Web of\nScience (WoS) and Scopus, and the coverage with author identification\ninformation such as Researcher ID, ORCID and Scopus Author Identifier in the\nperiod 1996 - 2014. The goal of this study is to describe the significant\ndifferences of the two collections with respect to overall distribution of\nauthor identifiers and its use across different subject domains. We found that\nthe STM disciplines show the best coverage of author identifiers in our dataset\nof 6,032,000 publications which are both covered by WoS and Scopus. In our\ndataset we found 184,823 distinct ResearcherIDs and 70,043 distinct ORCIDs. In\nthe appendix of this report we list a complete overview of all WoS subject\nareas and the amount of author identifiers in these subject areas.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 19:53:46 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Kr\u00e4mer", "Thomas", ""], ["Momeni", "Fakhri", ""], ["Mayr", "Philipp", ""]]}, {"id": "1703.01469", "submitter": "Gangan Prathap", "authors": "Gangan Prathap", "title": "Scientific wealth and inequality within nations", "comments": "10 pages, 3 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the greater the scientific wealth of a nation, the more likely\nthat it will tend to concentrate this excellence in a few premier institutions.\nThat is, great wealth implies great inequality of distribution. The scientific\nwealth is interpreted in terms of citation data harvested by Google Scholar\nCitations for profiled institutions from all countries in the world.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 14:55:41 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Prathap", "Gangan", ""]]}, {"id": "1703.01476", "submitter": "Mirco Musolesi", "authors": "Mirco Musolesi", "title": "Tracing Networks of Knowledge in the Digital Age", "comments": "8 pages. In Proceedings of the British Academy. Accepted for\n  Publication. To Appear. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of new digital technologies has allowed the study of human\nbehaviour at a scale and at level of granularity that were unthinkable just a\ndecade ago. In particular, by analysing the digital traces left by people\ninteracting in the online and offline worlds, we are able to trace the\nspreading of knowledge and ideas at both local and global scales. In this\narticle we will discuss how these digital traces can be used to map knowledge\nacross the world, outlining both the limitations and the challenges in\nperforming this type of analysis. We will focus on data collected from social\nmedia platforms, large-scale digital repositories and mobile data. Finally, we\nwill provide an overview of the tools that are available to scholars and\npractitioners for understanding these processes using these emerging forms of\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 15:16:08 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 22:00:53 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Musolesi", "Mirco", ""]]}, {"id": "1703.01601", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma", "title": "Doing Things Twice (Or Differently): Strategies to Identify Studies for\n  Targeted Validation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL physics.soc-ph q-bio.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The \"reproducibility crisis\" has been a highly visible source of scientific\ncontroversy and dispute. Here, I propose and review several avenues for\nidentifying and prioritizing research studies for the purpose of targeted\nvalidation. Of the various proposals discussed, I identify scientific data\nscience as being a strategy that merits greater attention among those\ninterested in reproducibility. I argue that the tremendous potential of\nscientific data science for uncovering high-value research studies is a\nsignificant and rarely discussed benefit of the transition to a fully\nopen-access publishing model.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 15:00:10 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 20:34:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Sarma", "Gopal P.", ""]]}, {"id": "1703.02334", "submitter": "Ludo Waltman", "authors": "Ludo Waltman and Vincent A. Traag", "title": "Use of the journal impact factor for assessing individual articles:\n  Statistically flawed or not?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most scientometricians reject the use of the journal impact factor for\nassessing individual articles and their authors. The well-known San Francisco\nDeclaration on Research Assessment also strongly objects against this way of\nusing the impact factor. Arguments against the use of the impact factor at the\nlevel of individual articles are often based on statistical considerations. The\nskewness of journal citation distributions typically plays a central role in\nthese arguments. We present a theoretical analysis of statistical arguments\nagainst the use of the impact factor at the level of individual articles. Our\nanalysis shows that these arguments do not support the conclusion that the\nimpact factor should not be used for assessing individual articles. Using\ncomputer simulations, we demonstrate that under certain conditions the number\nof citations an article has received is a more accurate indicator of the value\nof the article than the impact factor. However, under other conditions, the\nimpact factor is a more accurate indicator. It is important to critically\ndiscuss the dominant role of the impact factor in research evaluations, but the\ndiscussion should not be based on misplaced statistical arguments. Instead, the\nprimary focus should be on the socio-technical implications of the use of the\nimpact factor.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 11:28:40 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 22:29:36 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 22:33:46 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Waltman", "Ludo", ""], ["Traag", "Vincent A.", ""]]}, {"id": "1703.03220", "submitter": "Pablo Dorta-Gonzalez", "authors": "Pablo Dorta-Gonzalez, Sara M. Gonzalez-Betancor, Maria Isabel\n  Dorta-Gonzalez", "title": "Reconsidering the gold open access citation advantage postulate in a\n  multidisciplinary context: an analysis of the subject categories in the Web\n  of Science database 2009-2014", "comments": "25 pages, 4 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since Lawrence in 2001 proposed the open access (OA) citation advantage, the\npotential benefit of OA in relation to the citation impact has been discussed\nin depth. The methodology to test this postulate ranges from comparing the\nimpact factors of OA journals versus traditional ones, to comparing citations\nof OA versus non-OA articles published in the same non-OA journals. However,\nconclusions are not entirely consistent among fields, and two possible\nexplications have been suggested in those fields where a citation advantage has\nbeen observed for OA: the early view and the selection bias postulates. In this\nstudy, a longitudinal and multidisciplinary analysis of the gold OA citation\nadvantage is developed. All research articles in all journals for all subject\ncategories in the multidisciplinary database Web of Science are considered. A\ntotal of 1,137,634 articles - 86,712 OA articles (7.6%) and 1,050,922 non-OA\narticles (92.4%)- published in 2009 are analysed. The citation window\nconsidered goes from 2009 to 2014, and data are aggregated for the 249\ndisciplines (subject categories). At journal level, we also study the evolution\nof journal impact factors for OA and non-OA journals in those disciplines whose\nOA prevalence is higher (top 36 subject categories). As the main conclusion,\nthere is no generalizable gold OA citation advantage, neither at article nor at\njournal level.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 10:34:01 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Dorta-Gonzalez", "Pablo", ""], ["Gonzalez-Betancor", "Sara M.", ""], ["Dorta-Gonzalez", "Maria Isabel", ""]]}, {"id": "1703.03302", "submitter": "Mat Kelly", "authors": "Mat Kelly, Lulwah M. Alkwai, Michael L. Nelson, Michele C. Weigle, and\n  Herbert Van de Sompel", "title": "Impact of URI Canonicalization on Memento Count", "comments": "43 pages, 8 figures", "journal-ref": null, "doi": "10.1109/JCDL.2017.7991601", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantifying the captures of a URI over time is useful for researchers to\nidentify the extent to which a Web page has been archived. Memento TimeMaps\nprovide a format to list mementos (URI-Ms) for captures along with brief\nmetadata, like Memento-Datetime, for each URI-M. However, when some URI-Ms are\ndereferenced, they simply provide a redirect to a different URI-M (instead of a\nunique representation at the datetime), often also present in the TimeMap. This\ninfers that confidently obtaining an accurate count quantifying the number of\nnon-forwarding captures for a URI-R is not possible using a TimeMap alone and\nthat the magnitude of a TimeMap is not equivalent to the number of\nrepresentations it identifies. In this work we discuss this particular\nphenomena in depth. We also perform a breakdown of the dynamics of counting\nmementos for a particular URI-R (google.com) and quantify the prevalence of the\nvarious canonicalization patterns that exacerbate attempts at counting using\nonly a TimeMap. For google.com we found that 84.9% of the URI-Ms result in an\nHTTP redirect when dereferenced. We expand on and apply this metric to TimeMaps\nfor seven other URI-Rs of large Web sites and thirteen academic institutions.\nUsing a ratio metric DI for the number of URI-Ms without redirects to those\nrequiring a redirect when dereferenced, five of the eight large web sites' and\ntwo of the thirteen academic institutions' TimeMaps had a ratio of ratio less\nthan one, indicating that more than half of the URI-Ms in these TimeMaps result\nin redirects when dereferenced.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 15:46:08 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Kelly", "Mat", ""], ["Alkwai", "Lulwah M.", ""], ["Nelson", "Michael L.", ""], ["Weigle", "Michele C.", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "1703.04031", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Ruth Fairclough", "title": "The Accuracy of Confidence Intervals for Field Normalised Indicators", "comments": "Journal of Informetrics, in press", "journal-ref": null, "doi": "10.1016/j.joi.2017.03.004", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing the average citation impact of research groups, universities\nand countries, field normalisation reduces the influence of discipline and\ntime. Confidence intervals for these indicators can help with attempts to infer\nwhether differences between sets of publications are due to chance factors.\nAlthough both bootstrapping and formulae have been proposed for these, their\naccuracy is unknown. In response, this article uses simulated data to\nsystematically compare the accuracy of confidence limits in the simplest\npossible case, a single field and year. The results suggest that the MNLCS\n(Mean Normalised Log-transformed Citation Score) confidence interval formula is\nconservative for large groups but almost always safe, whereas bootstrap MNLCS\nconfidence intervals tend to be accurate but can be unsafe for smaller world or\ngroup sample sizes. In contrast, bootstrap MNCS (Mean Normalised Citation\nScore) confidence intervals can be very unsafe, although their accuracy\nincreases with sample sizes.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 20:36:53 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 12:00:25 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Thelwall", "Mike", ""], ["Fairclough", "Ruth", ""]]}, {"id": "1703.04222", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen, Daniel Mietchen, Egon Willighagen", "title": "Scholia and scientometrics with Wikidata", "comments": "16 pages, 5 figures, Scientometrics 2017", "journal-ref": "Joint Proceedings of the 1st International Workshop on\n  Scientometrics and 1st International Workshop on Enabling Decentralised\n  Scholarly Communication (2017)", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scholia is a tool to handle scientific bibliographic information in Wikidata.\nThe Scholia Web service creates on-the-fly scholarly profiles for researchers,\norganizations, journals, publishers, individual scholarly works, and for\nresearch topics. To collect the data, it queries the SPARQL-based Wikidata\nQuery Service. Among several display formats available in Scholia are lists of\npublications for individual researchers and organizations, publications per\nyear, employment timelines, as well as co-author networks and citation graphs.\nThe Python package implementing the Web service is also able to format Wikidata\nbibliographic entries for use in LaTeX/BIBTeX.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:50:48 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 17:55:22 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""], ["Mietchen", "Daniel", ""], ["Willighagen", "Egon", ""]]}, {"id": "1703.04428", "submitter": "Philipp Mayr", "authors": "Afshin Sadeghi, Johannes Wilm, Philipp Mayr, Christoph Lange", "title": "Opening Scholarly Communication in Social Sciences by Connecting\n  Collaborative Authoring to Peer Review", "comments": "11 pages, 2 figures, submitted to the journal IWP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the OSCOSS research project on \"Opening Scholarly\nCommunication in the Social Sciences\" is to build a coherent collaboration\nenvironment that facilitates scholarly communication workflows of social\nscientists in the roles of authors, reviewers, editors and readers. This paper\npresents the implementation of the core of this environment: the integration of\nthe Fidus Writer academic word processor with the Open Journal Systems (OJS)\nsubmission and review management system.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 14:55:28 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Sadeghi", "Afshin", ""], ["Wilm", "Johannes", ""], ["Mayr", "Philipp", ""], ["Lange", "Christoph", ""]]}, {"id": "1703.04478", "submitter": "Nikolaos K Tselios", "authors": "Marina Pitsolanti, Fotini Papadopoulou, Nikolaos Tselios", "title": "Evaluation of 50 Greek Science and Engineering University Departments\n  using Google Scholar", "comments": null, "journal-ref": null, "doi": "10.5530/jscires.7.1.2", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the scientometric evaluation of faculty members of 50 Greek\nScience and Engineering University Departments is presented. 1978 academics\nwere examined in total. The number of papers, citations, h-index and i10-index\nhave been collected for each academic, department, school and university using\nGoogle Scholar and the citations analysis program Publish or Perish. Analysis\nof the collected data showed that departments of the same academic discipline\nare characterized by significant differences on the scientific outcome. In\naddition, in the majority of the evaluated departments a significant difference\nin h-index between academics who report scientific activity on the departments\nwebsite and those who do not, was observed. Moreover, academics who earned\ntheir PhD title in the USA demonstrate higher indices in comparison to scholars\nwho obtained their PhD title in Europe or in Greece. Finally, the correlation\nbetween the academic rank and the scholars h-index (or the number of their\ncitations) is quite low in some departments, which, under specific\ncircumstances, could be an indication of the lack of meritocracy.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 16:46:26 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 11:20:21 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Pitsolanti", "Marina", ""], ["Papadopoulou", "Fotini", ""], ["Tselios", "Nikolaos", ""]]}, {"id": "1703.04746", "submitter": "Vivek Kulkarni", "authors": "Michael J. Hazoglu, Vivek Kulkarni, Steven S. Skiena, Ken A. Dill", "title": "Citation histories of papers: sometimes the rich get richer, sometimes\n  they don't", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple model of how a publication's citations change over time,\nbased on pure-birth stochastic processes with a linear cumulative advantage\neffect. The model is applied to citation data from the Physical Review corpus\nprovided by APS. Our model reveals that papers fall into three different\nclusters: papers that have rapid initial citations and ultimately high impact\n(fast-hi), fast to rise but quick to plateau (fast-flat), or late bloomers\n(slow-late), which may either never achieve many citations, or do so many years\nafter publication. In \"fast-hi\" and \"slow-late\", there is a rich-get-richer\neffect: papers that have many citations accumulate additional citations more\nrapidly while the \"fast-flat\" papers do not display this effect. We conclude by\nshowing that only a few years of post-publication statistics are needed to\nidentify high impact (\"fast-hi\") papers.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:08:34 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Hazoglu", "Michael J.", ""], ["Kulkarni", "Vivek", ""], ["Skiena", "Steven S.", ""], ["Dill", "Ken A.", ""]]}, {"id": "1703.05485", "submitter": "Mazurek Ji\\v{r}\\'i", "authors": "Jiri Mazurek", "title": "A modification to Hirsch index allowing comparisons across different\n  scientific fields", "comments": "6 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to propose a simple modification to the original\nmeasure, the relative Hirsch index, which assigns each researcher a value\nbetween 0 (the bottom) and 1 (the top), expressing his/her distance to the top\nin a given field. By this normalization scholars from different scientific\ndisciplines can be compared.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 06:41:58 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Mazurek", "Jiri", ""]]}, {"id": "1703.05539", "submitter": "Sven Hug", "authors": "Sven E. Hug, Martin P. Braendle", "title": "The coverage of Microsoft Academic: Analyzing the publication output of\n  a university", "comments": null, "journal-ref": null, "doi": "10.1007/s11192-017-2535-3", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first detailed study on the coverage of Microsoft Academic (MA).\nBased on the complete and verified publication list of a university, the\ncoverage of MA was assessed and compared with two benchmark databases, Scopus\nand Web of Science (WoS), on the level of individual publications. Citation\ncounts were analyzed, and issues related to data retrieval and data quality\nwere examined. A Perl script was written to retrieve metadata from MA based on\npublication titles. The script is freely available on GitHub. We find that MA\ncovers journal articles, working papers, and conference items to a substantial\nextent and indexes more document types than the benchmark databases (e.g.,\nworking papers, dissertations). MA clearly surpasses Scopus and WoS in covering\nbook-related document types and conference items but falls slightly behind\nScopus in journal articles. The coverage of MA is favorable for evaluative\nbibliometrics in most research fields, including economics/business,\ncomputer/information sciences, and mathematics. However, MA shows biases\nsimilar to Scopus and WoS with regard to the coverage of the humanities,\nnon-English publications, and open-access publications. Rank correlations of\ncitation counts are high between MA and the benchmark databases. We find that\nthe publication year is correct for 89.5% of all publications and the number of\nauthors is correct for 95.1% of the journal articles. Given the fast and\nongoing development of MA, we conclude that MA is on the verge of becoming a\nbibliometric superpower. However, comprehensive studies on the quality of MA\nmetadata are still lacking.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 09:56:33 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 23:29:36 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 13:06:37 GMT"}, {"version": "v4", "created": "Mon, 25 Sep 2017 17:42:22 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Hug", "Sven E.", ""], ["Braendle", "Martin P.", ""]]}, {"id": "1703.05777", "submitter": "Zohreh Zahedi", "authors": "Zohreh Zahedi, Rodrigo Costas, Vincent Larivi\\`ere, and Stefanie\n  Haustein", "title": "What makes papers visible on social media? An analysis of various\n  document characteristics", "comments": "Presented at the 21th International Conference in Science &\n  Technology Indicators (STI), 13-16, September, 2016, Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we have investigated the relationship between different\ndocument characteristics and the number of Mendeley readership counts, tweets,\nFacebook posts, mentions in blogs and mainstream media for 1.3 million papers\npublished in journals covered by the Web of Science (WoS). It aims to\ndemonstrate that how factors affecting various social media-based indicators\ndiffer from those influencing citations and which document types are more\npopular across different platforms. Our results highlight the heterogeneous\nnature of altmetrics, which encompasses different types of uses and user groups\nengaging with research on social media.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 18:04:42 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Zahedi", "Zohreh", ""], ["Costas", "Rodrigo", ""], ["Larivi\u00e8re", "Vincent", ""], ["Haustein", "Stefanie", ""]]}, {"id": "1703.06645", "submitter": "Paul Sheridan", "authors": "Paul Sheridan and Taku Onodera", "title": "A Preferential Attachment Paradox: How Preferential Attachment Combines\n  with Growth to Produce Networks with Log-normal In-degree Distributions", "comments": "13 pages, 4 figures, 2 table, 1 supplementary notes file; fixed\n  broken figure and table references", "journal-ref": "Scientific Reports 8 (1), 1-11 (2020)", "doi": "10.1038/s41598-018-21133-2", "report-no": null, "categories": "cs.DL cond-mat.stat-mech physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every network scientist knows that preferential attachment combines with\ngrowth to produce networks with power-law in-degree distributions. How, then,\nis it possible for the network of American Physical Society journal collection\ncitations to enjoy a log-normal citation distribution when it was found to have\ngrown in accordance with preferential attachment? This anomalous result, which\nwe exalt as the preferential attachment paradox, has remained unexplained since\nthe physicist Sidney Redner first made light of it over a decade ago. Here we\npropose a resolution. The chief source of the mischief, we contend, lies in\nRedner having relied on a measurement procedure bereft of the accuracy required\nto distinguish preferential attachment from another form of attachment that is\nconsistent with a log-normal in-degree distribution. There was a high-accuracy\nmeasurement procedure in use at the time, but it would have have been difficult\nto use it to shed light on the paradox, due to the presence of a systematic\nerror inducing design flaw. In recent years the design flaw had been recognised\nand corrected. We show that the bringing of the newly corrected measurement\nprocedure to bear on the data leads to a resolution of the paradox.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 09:41:34 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 06:10:31 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 22:10:53 GMT"}, {"version": "v4", "created": "Mon, 22 Jan 2018 01:51:22 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sheridan", "Paul", ""], ["Onodera", "Taku", ""]]}, {"id": "1703.07104", "submitter": "Zohreh Zahedi", "authors": "Zohreh Zahedi, Rodrigo Costas, and Paul Wouters", "title": "Mendeley readership as a filtering tool to identify highly cited\n  publications", "comments": null, "journal-ref": null, "doi": "10.1002/asi.23883", "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a large scale analysis of the distribution and presence\nof Mendeley readership scores over time and across disciplines. We study\nwhether Mendeley readership scores (RS) can identify highly cited publications\nmore effectively than journal citation scores (JCS). Web of Science (WoS)\npublications with DOIs published during the period 2004-2013 and across 5 major\nscientific fields have been analyzed. The main result of this study shows that\nreadership scores are more effective (in terms of precision/recall values) than\njournal citation scores to identify highly cited publications across all fields\nof science and publication years. The findings also show that 86.5% of all the\npublications are covered by Mendeley and have at least one reader. Also the\nshare of publications with Mendeley readership scores is increasing from 84% in\n2004 to 89% in 2009, and decreasing from 88% in 2010 to 82% in 2013. However,\nit is noted that publications from 2010 onwards exhibit on average a higher\ndensity of readership vs. citation scores. This indicates that compared to\ncitation scores, readership scores are more prevalent for recent publications\nand hence they could work as an early indicator of research impact. These\nfindings highlight the potential and value of Mendeley as a tool for\nscientometric purposes and particularly as a relevant tool to identify highly\ncited publications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 09:29:29 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Zahedi", "Zohreh", ""], ["Costas", "Rodrigo", ""], ["Wouters", "Paul", ""]]}, {"id": "1703.07138", "submitter": "R\\'emi Cura", "authors": "R\\'emi Cura, Bertrand Dumenieu, Nathalie Abadie, Benoit Costes, Julien\n  Perret, Maurizio Gribaudi", "title": "Historical collaborative geocoding", "comments": "WORKING PAPER", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest developments in digital have provided large data sets that can\nincreasingly easily be accessed and used. These data sets often contain\nindirect localisation information, such as historical addresses. Historical\ngeocoding is the process of transforming the indirect localisation information\nto direct localisation that can be placed on a map, which enables spatial\nanalysis and cross-referencing. Many efficient geocoders exist for current\naddresses, but they do not deal with the temporal aspect and are based on a\nstrict hierarchy (..., city, street, house number) that is hard or impossible\nto use with historical data. Indeed historical data are full of uncertainties\n(temporal aspect, semantic aspect, spatial precision, confidence in historical\nsource, ...) that can not be resolved, as there is no way to go back in time to\ncheck. We propose an open source, open data, extensible solution for geocoding\nthat is based on the building of gazetteers composed of geohistorical objects\nextracted from historical topographical maps. Once the gazetteers are\navailable, geocoding an historical address is a matter of finding the\ngeohistorical object in the gazetteers that is the best match to the historical\naddress. The matching criteriae are customisable and include several dimensions\n(fuzzy semantic, fuzzy temporal, scale, spatial precision ...). As the goal is\nto facilitate historical work, we also propose web-based user interfaces that\nhelp geocode (one address or batch mode) and display over current or historical\ntopographical maps, so that they can be checked and collaboratively edited. The\nsystem is tested on Paris city for the 19-20th centuries, shows high returns\nrate and is fast enough to be used interactively.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 10:45:09 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 08:06:43 GMT"}, {"version": "v3", "created": "Sun, 13 May 2018 05:10:35 GMT"}, {"version": "v4", "created": "Thu, 31 May 2018 01:17:43 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Cura", "R\u00e9mi", ""], ["Dumenieu", "Bertrand", ""], ["Abadie", "Nathalie", ""], ["Costes", "Benoit", ""], ["Perret", "Julien", ""], ["Gribaudi", "Maurizio", ""]]}, {"id": "1703.07656", "submitter": "Manuel Sebastian Mariani", "authors": "Zhuo-Ming Ren, Manuel Sebastian Mariani, Yi-Cheng Zhang, Matus Medo", "title": "Randomizing growing networks with a time-respecting null model", "comments": "13 pages, 10 figures", "journal-ref": "Phys. Rev. E 97, 052311 (2018)", "doi": "10.1103/PhysRevE.97.052311", "report-no": null, "categories": "physics.soc-ph cs.DL cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are often used to represent systems that are not static but\ngrow with time: people make new friendships, new papers are published and refer\nto the existing ones, and so forth. To assess the statistical significance of\nmeasurements made on such networks, we propose a randomization methodology---a\ntime-respecting null model---that preserves both the network's degree sequence\nand the time evolution of individual nodes' degree values. By preserving the\ntemporal linking patterns of the analyzed system, the proposed model is able to\nfactor out the effect of the system's temporal patterns on its structure. We\napply the model to the citation network of Physical Review scholarly papers and\nthe citation network of US movies. The model reveals that the two datasets are\nstrikingly different with respect to their degree-degree correlations, and we\ndiscuss the important implications of this finding on the information provided\nby paradigmatic node centrality metrics such as indegree and Google's PageRank.\nThe randomization methodology proposed here can be used to assess the\nsignificance of any structural property in growing networks, which could bring\nnew insights into the problems where null models play a critical role, such as\nthe detection of communities and network motifs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 13:49:37 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 08:06:58 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 09:29:55 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Ren", "Zhuo-Ming", ""], ["Mariani", "Manuel Sebastian", ""], ["Zhang", "Yi-Cheng", ""], ["Medo", "Matus", ""]]}, {"id": "1703.08071", "submitter": "Manuel Sebastian Mariani", "authors": "Giacomo Vaccario, Matus Medo, Nicolas Wider, Manuel Sebastian Mariani", "title": "Quantifying and suppressing ranking bias in a large citation network", "comments": "Main text (pp. 1-12) and Appendices (pp. 13-17)", "journal-ref": "Journal of Informetrics 11, 766-782 (2017)", "doi": "10.1016/j.joi.2017.05.014", "report-no": null, "categories": "physics.soc-ph cs.DL cs.IR physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely recognized that citation counts for papers from different fields\ncannot be directly compared because different scientific fields adopt different\ncitation practices. Citation counts are also strongly biased by paper age since\nolder papers had more time to attract citations. Various procedures aim at\nsuppressing these biases and give rise to new normalized indicators, such as\nthe relative citation count. We use a large citation dataset from Microsoft\nAcademic Graph and a new statistical framework based on the Mahalanobis\ndistance to show that the rankings by well known indicators, including the\nrelative citation count and Google's PageRank score, are significantly biased\nby paper field and age. We propose a general normalization procedure motivated\nby the $z$-score which produces much less biased rankings when applied to\ncitation count and PageRank score.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 13:53:06 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Vaccario", "Giacomo", ""], ["Medo", "Matus", ""], ["Wider", "Nicolas", ""], ["Mariani", "Manuel Sebastian", ""]]}, {"id": "1703.09108", "submitter": "Joeran Beel", "authors": "Joeran Beel and Akiko Aizawa and Corinna Breitinger and Bela Gipp", "title": "Mr. DLib: Recommendations-as-a-Service (RaaS) for Academia", "comments": "Accepted for publication at the JCDL conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Only few digital libraries and reference managers offer recommender systems,\nalthough such systems could assist users facing information overload. In this\npaper, we introduce Mr. DLib's recommendations-as-a-service, which allows third\nparties to easily integrate a recommender system into their products. We\nexplain the recommender approaches implemented in Mr. DLib (content-based\nfiltering among others), and present details on 57 million recommendations,\nwhich Mr. DLib delivered to its partner GESIS Sowiport. Finally, we outline our\nplans for future development, including integration into JabRef, establishing a\nliving lab, and providing personalized recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 14:35:37 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 09:50:03 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Beel", "Joeran", ""], ["Aizawa", "Akiko", ""], ["Breitinger", "Corinna", ""], ["Gipp", "Bela", ""]]}, {"id": "1703.09343", "submitter": "Martin Klein", "authors": "Martin Klein and Herbert Van de Sompel", "title": "Discovering Scholarly Orphans Using ORCID", "comments": "10 pages, 5 figures, 5 tables accepted for publication at JCDL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archival efforts such as (C)LOCKSS and Portico are in place to ensure the\nlongevity of traditional scholarly resources like journal articles. At the same\ntime, researchers are depositing a broad variety of other scholarly artifacts\ninto emerging online portals that are designed to support web-based\nscholarship. These web-native scholarly objects are largely neglected by\ncurrent archival practices and hence they become scholarly orphans. We\ntherefore argue for a novel paradigm that is tailored towards archiving these\nscholarly orphans. We are investigating the feasibility of using Open\nResearcher and Contributor ID (ORCID) as a supporting infrastructure for the\nprocess of discovery of web identities and scholarly orphans for active\nresearchers. We analyze ORCID in terms of coverage of researchers, subjects,\nand location and assess the richness of its profiles in terms of web identities\nand scholarly artifacts. We find that ORCID currently lacks in all considered\naspects and hence can only be considered in conjunction with other discovery\nsources. However, ORCID is growing fast so there is potential that it could\nachieve a satisfactory level of coverage and richness in the near future.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 23:36:02 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Klein", "Martin", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "1703.09550", "submitter": "Benjamin Kiessling", "authors": "Maxim Romanov, Matthew Thomas Miller, Sarah Bowen Savant, Benjamin\n  Kiessling", "title": "Important New Developments in Arabographic Optical Character Recognition\n  (OCR)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OpenITI team has achieved Optical Character Recognition (OCR) accuracy\nrates for classical Arabic-script texts in the high nineties. These numbers are\nbased on our tests of seven different Arabic-script texts of varying quality\nand typefaces, totaling over 7,000 lines. These accuracy rates not only\nrepresent a distinct improvement over the actual accuracy rates of the various\nproprietary OCR options for classical Arabic-script texts, but, equally\nimportant, they are produced using an open-source OCR software, thus enabling\nus to make this Arabic-script OCR technology freely available to the broader\nIslamic, Persian, and Arabic Studies communities.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 12:42:58 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Romanov", "Maxim", ""], ["Miller", "Matthew Thomas", ""], ["Savant", "Sarah Bowen", ""], ["Kiessling", "Benjamin", ""]]}, {"id": "1703.10407", "submitter": "Olesya Mryglod", "authors": "R. Kenna, O. Mryglod, B. Berche", "title": "A scientists' view of scientometrics: Not everything that counts can be\n  counted", "comments": "10 pages, 1 figure", "journal-ref": "Condens. Matter Phys., 2017, vol. 20, No. 1, 13803", "doi": "10.5488/CMP.20.13803", "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like it or not, attempts to evaluate and monitor the quality of academic\nresearch have become increasingly prevalent worldwide. Performance reviews\nrange from at the level of individuals, through research groups and\ndepartments, to entire universities. Many of these are informed by, or\nfunctions of, simple scientometric indicators and the results of such exercises\nimpact onto careers, funding and prestige. However, there is sometimes a\nfailure to appreciate that scientometrics are, at best, very blunt instruments\nand their incorrect usage can be misleading. Rather than accepting the rise and\nfall of individuals and institutions on the basis of such imprecise measures,\ncalls have been made for indicators be regularly scrutinised and for\nimprovements to the evidence base in this area. It is thus incumbent upon the\nscientific community, especially the physics, complexity-science and\nscientometrics communities, to scrutinise metric indicators. Here, we review\nrecent attempts to do this and show that some metrics in widespread use cannot\nbe used as reliable indicators research quality.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 11:08:52 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Kenna", "R.", ""], ["Mryglod", "O.", ""], ["Berche", "B.", ""]]}]