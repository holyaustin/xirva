[{"id": "2011.00223", "submitter": "Vivek Kumar Singh Ph.D.", "authors": "Vivek Kumar Singh, Prashasti Singh, Mousumi Karmakar, Jacqueline Leta,\n  Philipp Mayr", "title": "The Journal Coverage of Web of Science, Scopus and Dimensions: A\n  Comparative Analysis", "comments": "Submitted to Scientometrics", "journal-ref": "Scientometrics 2021", "doi": "10.1007/s11192-021-03948-5", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, Web of Science and Scopus have been the two most widely used\ndatabases for bibliometric analyses. However, during the last few years some\nnew scholarly databases, such as Dimensions, have come up. Several previous\nstudies have compared different databases, either through a direct comparison\nof article coverage or by comparing the citations across the databases. This\narticle attempts to compare the journal coverage of the three databases: Web of\nScience, Scopus and Dimensions. The most recent master journal lists of the\nthree databases have been used for the purpose of identifying the overlapping\nand unique journals covered in the databases. The results indicate that the\ndatabases have significantly different journal coverage, with the Web of\nScience being most selective and Dimensions being the most exhaustive. About\n99.11% and 96.61% of the journals indexed in Web of Science are also indexed in\nScopus and Dimensions, respectively. Scopus has 96.42% of its indexed journals\nalso covered by Dimensions. Dimensions database has the most exhaustive\ncoverage, with 82.22% more journals covered as compared to Web of Science and\n48.17% more journals covered as compared to Scopus. We also analysed the\nresearch outputs for 20 highly productive countries for the 2010-2019 period,\nas indexed in the three databases, and identified database-induced variations\nin research output volume, rank and global share of different countries. In\naddition to variations in overall coverage of research output from different\ncountries, the three databases appear to have differential coverage of\ndifferent disciplines.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 09:33:12 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 06:30:46 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Singh", "Vivek Kumar", ""], ["Singh", "Prashasti", ""], ["Karmakar", "Mousumi", ""], ["Leta", "Jacqueline", ""], ["Mayr", "Philipp", ""]]}, {"id": "2011.01733", "submitter": "Gerta R\\\"ucker", "authors": "Gerta R\\\"ucker", "title": "Comment on `Open is not forever: a study of vanished open access\n  journals'", "comments": "Short comment with 2 pages, no figures, revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is a comment to an article by Laakso, Matthias and Jahn\n(arXiv:2008.11933).\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:37:02 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 14:37:47 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["R\u00fccker", "Gerta", ""]]}, {"id": "2011.01881", "submitter": "Kiran Sharma Dr.", "authors": "Kiran Sharma and Parul Khurana", "title": "Growth and dynamics of Econophysics: A bibliometric and network analysis", "comments": "14 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digitization of publications, advancement in communication technology, and\nthe availability of bibliographic data have made it easier for the researchers\nto study the growth and dynamics of any discipline. We present a study on\n\"Econophysics\" metadata extracted from the Web of Science managed by the\nClarivate Analytics from 2000-2019. The study highlights the growth and\ndynamics of the discipline by measures of a number of publications, citations\non publications, other disciplines contribution, institutions participation,\ncountry-wise spread, etc. We investigate the impact of self-citations on\ncitations with every five-year interval. Also, we find the contribution of\nother disciplines by analyzing the cited references. Results emerged from\nmicro, meso and macro-level analysis of collaborations show that the\ndistributions among authors collaboration and affiliations of authors follow a\npower law. Thus, very few authors keep producing most of the papers and are\nfrom a few institutions. We find that China is leading in the production of a\nnumber of authors and a number of papers; however, shares more of national\ncollaboration rather than international, whereas the USA shares more\ninternational collaboration. Finally, we demonstrate the evolution of the\nauthor's collaborations and affiliations networks from 2000-2019. Overall the\nanalysis reveals the \"small-world\" property of the network with average path\nlength 5. As a consequence of our analysis, this study can serve as in-depth\nknowledge to understand the growth and dynamics of the Econophysics network\nboth qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:57:51 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sharma", "Kiran", ""], ["Khurana", "Parul", ""]]}, {"id": "2011.02068", "submitter": "Sichang Tu", "authors": "Amir Zeldes, Lance Martin and Sichang Tu", "title": "Exhaustive Entity Recognition for Coptic: Challenges and Solutions", "comments": "9 pages, 2 figures, 5 tables. Accepted by The 4th Joint SIGHUM\n  Workshop on Computational Linguistics for Cultural Heritage, Social Sciences,\n  Humanities and Literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity recognition provides semantic access to ancient materials in the\nDigital Humanities: itexposes people and places of interest in texts that\ncannot be read exhaustively, facilitates linkingresources and can provide a\nwindow into text contents, even for texts with no translations. Inthis paper we\npresent entity recognition for Coptic, the language of Hellenistic era Egypt.\nWeevaluate NLP approaches to the task and lay out difficulties in applying them\nto a low-resource,morphologically complex language. We present solutions for\nnamed and non-named nested en-tity recognition and semi-automatic entity\nlinking to Wikipedia, relying on robust dependencyparsing, feature-based CRF\nmodels, and hand-crafted knowledge base resources, enabling highaccuracy NER\nwith orders of magnitude less data than those used for high resource\nlanguages.The results suggest avenues for research on other languages in\nsimilar settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 23:49:42 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zeldes", "Amir", ""], ["Martin", "Lance", ""], ["Tu", "Sichang", ""]]}, {"id": "2011.04382", "submitter": "Jose Fontanari", "authors": "Sandro M. Reia and Jos\\'e F. Fontanari", "title": "A SIR epidemic model for citation dynamics", "comments": null, "journal-ref": "Eur. Phys. J. Plus (2021) 136:207", "doi": "10.1140/epjp/s13360-021-01199-0", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of citations in the scientific literature crosses the boundaries\nbetween the traditional branches of science and stands on its own as a most\nprofitable research field dubbed the `science of science'. Although the\nunderstanding of the citation histories of individual papers involves many\nintangible factors, the basic assumption that citations beget citations can\nexplain most features of the empirical citation patterns. Here we use the SIR\nepidemic model as a mechanistic model for the citation dynamics of well-cited\npapers published in selected journals of the American Physical Society. The\nestimated epidemiological parameters offer insight on unknown quantities as the\nsize of the community that could cite a paper and its ultimate impact on that\ncommunity. We find a good, though imperfect, agreement between the rank of the\njournals obtained using the epidemiological parameters and the impact factor\nrank.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:27:55 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Reia", "Sandro M.", ""], ["Fontanari", "Jos\u00e9 F.", ""]]}, {"id": "2011.05703", "submitter": "Robin Delabays", "authors": "Robin Delabays and Melvyn Tyloo", "title": "Heavy-tailed distribution of the number of publications within\n  scientific journals", "comments": "9 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The community of scientists is characterized by their need to publish in\npeer-reviewed journals, in an attempt to avoid the \"perish\" side of the famous\nmaxim. Accordingly, almost all researchers authored some scientific articles.\nScholarly publications represent at least two benefits for the study of the\nscientific community as a social group. First, they attest of some form of\nrelation between scientists (collaborations, mentoring, heritage,...), useful\nto determine and analyze social subgroups. Second, most of them are recorded in\nlarge data bases, easily accessible and including a lot of pertinent\ninformation, easing the quantitative and qualitative study of the scientific\ncommunity. Understanding the underlying dynamics driving the creation of\nknowledge in general, and of scientific publication in particular, in addition\nto its interest from the social science point of view, can contribute to\nmaintaining a high level of research, by identifying good and bad practices in\nscience. In this manuscript, we attempt to advance this understanding by a\nstatistical analysis of publications within peer-reviewed journals. Namely, we\nshow that the distribution of the number of articles published by an author in\na given journal is heavy-tailed, but has lighter tail than a power law.\nMoreover, we observe some anomalies in the data that pinpoint underlying\ndynamics of the scholarly publication process.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:13:58 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Delabays", "Robin", ""], ["Tyloo", "Melvyn", ""]]}, {"id": "2011.06561", "submitter": "Olesya Mryglod", "authors": "Olesya Mryglod and Ihor Mryglod", "title": "Collective authorship in Ukrainian science: marginal effect or new\n  phenomenon?", "comments": "Language of article: Ukrainian", "journal-ref": null, "doi": "10.15407/visn2020.07.034", "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the features of modern science is the formation of stable large\ncollaborations of researchers working together within the projects that require\nthe concentration of huge financial and human resources. Results of such common\nwork are published in scientific papers by large co-authorship teams that\ninclude sometimes thousands of names. The goal of this work is to study the\ninfluence of such publications on the values of scientometric indicators\ncalculated for individuals, research groups and science of Ukraine in general.\nBibliometric data related to Ukraine, some academic institutions and selected\nindividual researchers were collected from Scopus database and used for our\nstudy. It is demonstrated that while the relative share of publications by\ncollective authors is comparatively small, their presence in a general pool can\nlead to statistically significant effects. The obtained results clearly show\nthat traditional quantitative approaches for research assessment should be\nchanged in order to take into account this phenomenon. Keywords: collective\nauthorship, scientometrics, group science, Ukraine.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:24:26 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Mryglod", "Olesya", ""], ["Mryglod", "Ihor", ""]]}, {"id": "2011.06795", "submitter": "Alberto Baccini", "authors": "Federica Baccini, Lucio Barabesi, Alberto Baccini, Mahdi Khelfaoui,\n  Yves Gingras", "title": "Similarity network fusion for scholarly journals", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores intellectual and social proximity among scholarly\njournals by using network fusion techniques. Similarities among journals are\ninitially represented by means of a three-layer network based on co-citations,\ncommon authors and common editors. The information contained in the three\nlayers is then combined by building a fused similarity network. The fusion\nconsists in an unsupervised process that exploits the structural properties of\nthe layers. Subsequently, partial distance correlations are adopted for\nmeasuring the contribution of each layer to the structure of the fused network.\nFinally, the community morphology of the fused network is explored by using\nmodularity. In the three fields considered (i.e. economics, information and\nlibrary sciences and statistics) the major contribution to the structure of the\nfused network arises from editors. This result suggests that the role of\neditors as gatekeepers of journals is the most relevant in defining the\nboundaries of scholarly communities. In information and library sciences and\nstatistics, the clusters of journals reflect sub-field specializations. In\neconomics, clusters of journals appear to be better interpreted in terms of\nalternative methodological approaches. Thus, the graphs representing the\nclusters of journals in the fused network are powerful instruments for\nexploring research fields.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:41:12 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 13:57:24 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Baccini", "Federica", ""], ["Barabesi", "Lucio", ""], ["Baccini", "Alberto", ""], ["Khelfaoui", "Mahdi", ""], ["Gingras", "Yves", ""]]}, {"id": "2011.07571", "submitter": "Robert Haines", "authors": "Caroline Jay, Robert Haines, Daniel S. Katz", "title": "Software must be recognised as an important output of scholarly research", "comments": "6 pages. Submitted to IJDC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software now lies at the heart of scholarly research. Here we argue that as\nwell as being important from a methodological perspective, software should, in\nmany instances, be recognised as an output of research, equivalent to an\nacademic paper. The article discusses the different roles that software may\nplay in research and highlights the relationship between software and research\nsustainability and reproducibility. It describes the challenges associated with\nthe processes of citing and reviewing software, which differ from those used\nfor papers. We conclude that whilst software outputs do not necessarily fit\ncomfortably within the current publication model, there is a great deal of\npositive work underway that is likely to make an impact in addressing this.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 16:34:31 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jay", "Caroline", ""], ["Haines", "Robert", ""], ["Katz", "Daniel S.", ""]]}, {"id": "2011.07880", "submitter": "Alexis-Michel Mugabushaka", "authors": "Alexis-Michel Mugabushaka", "title": "Linking Publications to Funding at Project Level: A curated dataset of\n  publications reported by FP7 projects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Datasets explicitly linking publications to funding at project level are the\nbasis of evaluative bibliometric analysis of funding programmes. Analysis of\nthe impact of the EU funding programmes has been often frustrated by the lack\nof data on publications to which the funding has contributed. Here we present a\ndataset 2 of scholarly publications reported by the projects funded by the\nEuropean Union under the 7th Framework Programme. The dataset was created by\nfirst consolidating data from different reporting channels and validating the\nrecords by systematically matching them to external authoritative sources and\nassigning them external identifiers.\n  The initial dataset had 299.000 records linked to one or more projects out of\nwhich 68% had a digital object identify (doi). Through the data quality\nassurance, we validate 92% of the initial records (277000) and assign a doi to\n89% of them of them (267000). The resulting dataset has 240000 unique dois. It\nis, to our knowledge, the first comprehensive and curated dataset of scholarly\noutputs of the Framework Programme.\n  The dataset could only be created thanks to significant improvements and\ninvestments made in the reporting systems used by EU funded projects.\n  The dataset is available on zenodo: https://doi.org/10.5281/zenodo.4275528\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:35:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mugabushaka", "Alexis-Michel", ""]]}, {"id": "2011.07910", "submitter": "Alexis-Michel Mugabushaka", "authors": "Alexis-Michel Mugabushaka, Jasmin Sadat, Jorge Costa Dantas Faria", "title": "In Search of Outstanding Research Advances: Prototyping the creation of\n  an open dataset of \"editorial highlights\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A long-standing research question in bibliometrics is how one identifies\npublications, which represent major advances in their fields, making high\nimpact in there and other areas. In this context, the term \"Breakthrough\" is\noften used and commonly used approaches rely on citation links between\npublications implicitly positing that peers who use or build upon previously\npublished results collectively inform about their standing in terms of\nadvancing the research frontiers.\n  Here we argue that the \"Breakthrough\" concept is rooted in the Kuhnian model\nof scientific revolution which has been both conceptually and empirically\nchallenged. A more fruitful approach is to consider various ways in which\nauthoritative actors in scholarly communication system signal the importance of\nresearch results. We bring to discussions different \"recognition channels\" and\npilot the creation of an open dataset of editorial highlights from regular\nlists of notable research advances. The dataset covers the last ten years and\nincludes: the \"discoveries of the year\" from Science magazine and La Recherche\nand weekly editorial highlights from Nature (\"research highlights\") and Science\n(\"editor's choice\"). The final dataset includes 230 entries in the \"discoveries\nof the years\" (with over 720 references) and about 9,000 weekly highlights\n(with over 8,000 references).\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 12:54:42 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mugabushaka", "Alexis-Michel", ""], ["Sadat", "Jasmin", ""], ["Faria", "Jorge Costa Dantas", ""]]}, {"id": "2011.08184", "submitter": "Jan Egger", "authors": "Jan Egger, Antonio Pepe, Christina Gsaxner, Jianning Li", "title": "Deep Learning -- A first Meta-Survey of selected Reviews across\n  Scientific Disciplines and their Research Impact", "comments": "39 pages, 5 tables, 80 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning belongs to the field of artificial intelligence, where machines\nperform tasks that typically require some kind of human intelligence. Deep\nlearning tries to achieve this by mimicking the learning of a human brain.\nSimilar to the basic structure of a brain, which consists of (billions of)\nneurons and connections between them, a deep learning algorithm consists of an\nartificial neural network, which resembles the biological brain structure.\nMimicking the learning process of humans with their senses, deep learning\nnetworks are fed with (sensory) data, like texts, images, videos or sounds.\nThese networks outperform the state-of-the-art methods in different tasks and,\nbecause of this, the whole field saw an exponential growth during the last\nyears. This growth resulted in way over 10 000 publications per year in the\nlast years. For example, the search engine PubMed alone, which covers only a\nsub-set of all publications in the medical field, provides over 11 000 results\nfor the search term $'$deep learning$'$ in Q3 2020, and ~90% of these results\nare from the last three years. Consequently, a complete overview over the field\nof deep learning is already impossible to obtain and, in the near future, it\nwill potentially become difficult to obtain an overview over a subfield.\nHowever, there are several review articles about deep learning, which are\nfocused on specific scientific fields or applications, for example deep\nlearning advances in computer vision or in specific tasks like object\ndetection. With these surveys as a foundation, the aim of this contribution is\nto provide a first high-level, categorized meta-analysis of selected reviews on\ndeep learning across different scientific disciplines and outline the research\nimpact that they already have during a short period of time.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:14:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Egger", "Jan", ""], ["Pepe", "Antonio", ""], ["Gsaxner", "Christina", ""], ["Li", "Jianning", ""]]}, {"id": "2011.08278", "submitter": "Ciriaco Andrea D'Angelo", "authors": "Giovanni Abramo and Ciriaco Andrea D'Angelo", "title": "A bibliometric methodology to unveil territorial inequities in the\n  scientific wealth to combat COVID-19", "comments": "25 Pages, 5 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a methodology to assess the scientific wealth of\nterritories at field level. Our methodology uses a bibliometric approach based\non the observation of academic research performance and overall scientific\nproduction in each territory. We apply it to assess disparities in the Italian\nterritories in the medical specialties at the front line of the COVID-19\nemergency. Italy has been the first among western countries to be severely\naffected by the onset of the COVID-19 pandemic. The study reveals remarkable\ninequities across territories, with scientific weaknesses concentrated in the\nsouth. Policies for rebalancing the north-south divide should also consider, in\naddition to tangible assets, the gap in production and availability of quality\nmedical knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:11:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Abramo", "Giovanni", ""], ["D'Angelo", "Ciriaco Andrea", ""]]}, {"id": "2011.08591", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff, Caroline S. Wagner, and Lin Zhang", "title": "Are University Rankings Statistically Significant? A Comparison among\n  Chinese Universities and with the USA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: We address the question of whether differences are statistically\nsignificant in the rankings of universities. We propose methods measuring the\nstatistical significance among different universities and illustrate the\nresults by empirical data. Design/methodology/approach: Based on z-testing and\noverlapping confidence intervals, and using data about 205 Chinese universities\nincluded in the Leiden Rankings 2020, we argue that three main groups of\nChinese research universities can be distinguished.\n  Findings: When the sample of 205 Chinese universities is merged with the 197\nUS universities included in Leiden Rankings 2020, the results similarly\nindicate three main groups: high, middle, low. Using this data (Leiden Rankings\nand Web-of-Science), the z-scores of the Chinese universities are significantly\nbelow those of the US universities albeit with some overlap.\n  Research limitations: We show empirically that differences in ranking may be\ndue to changes in the data, the models, or the modeling effects on the data.\nThe scientometric groupings are not always stable when we use different\nmethods.\n  R&D policy implications: Differences among universities can be tested for\ntheir statistical significance. The statistics relativize the values of\ndecimals in the rankings. One can operate with a scheme of low/middle/high in\npolicy debates and leave the more fine-grained rankings of individual\nuniversities to operational management and local settings.\n  Originality/value: In the discussion about the rankings of universities, the\nquestion of whether differences are statistically significant, is, in our\nopinion, insufficiently addressed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:27:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Leydesdorff", "Loet", ""], ["Wagner", "Caroline S.", ""], ["Zhang", "Lin", ""]]}, {"id": "2011.08637", "submitter": "Hannes Leeb", "authors": "Hannes Leeb", "title": "A Tale of Two Referees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success in academia hinges on publishing in top tier journals. This requires\ninnovative results. And this requires clear and convincing presentation of said\nresults. Presentation can make the difference of one tier in journal level. A\nlot of useful advice on this topic is available online from well-respected\noutlets; see, for example, El-Omar (2014); Gould (2014); Neiles et al. (2015);\nNotz and Kafadar (2011); or Sachdeva (2020). This text provides a different\nangle.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:57:21 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Leeb", "Hannes", ""]]}, {"id": "2011.09069", "submitter": "Vivek Kumar Singh Ph.D.", "authors": "Mousumi Karmakar, Sumit Kumar Banshal, Vivek Kumar Singh", "title": "A large-scale comparison of social media coverage and mentions captured\n  by the two altmetric aggregators- Altmetric.com and PlumX", "comments": "23 pages including 4 figures and 7 tables", "journal-ref": "Scientometrics 2021", "doi": "10.1007/s11192-021-03941-y", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increased social media attention to scholarly articles has resulted in\nefforts to create platforms & services to track and measure the social media\ntransactions around scholarly articles in different social platforms (such as\nTwitter, Blog, Facebook) and academic social networks (such as Mendeley,\nAcademia and ResearchGate). Altmetric.com and PlumX are two popular aggregators\nthat track social media activity around scholarly articles from a variety of\nsocial platforms and provide the coverage and transaction data to researchers\nfor various purposes. However, some previous studies have shown that the social\nmedia data captured by the two aggregators have differences in terms of\ncoverage and magnitude of mentions. This paper aims to revisit the question by\ndoing a large-scale analysis of social media mentions of a data sample of\n1,785,149 publication records (drawn from multiple disciplines, demographies,\npublishers). Results obtained show that PlumX tracks more wide sources and more\narticles as compared to Altmetric.com. However, the coverage and average\nmentions of the two aggregators vary across different social media platforms,\nwith Altmetric.com recording higher mentions in Twitter and Blog, and PlumX\nrecording higher mentions in Facebook and Mendeley, for the same set of\narticles. The coverage and average mentions captured by the two aggregators\nacross different document types, disciplines and publishers is also analyzed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 03:38:56 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 06:28:07 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Karmakar", "Mousumi", ""], ["Banshal", "Sumit Kumar", ""], ["Singh", "Vivek Kumar", ""]]}, {"id": "2011.09079", "submitter": "Vivek Kumar Singh Ph.D.", "authors": "Sumit Kumar Banshal, Aparna Basu, Vivek Kumar Singh, Solanki Gupta,\n  Pranab K. Muhuri", "title": "Do 'altmetric mentions' follow Power Laws? Evidence from social media\n  mention data in Altmetric.com", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Power laws are a characteristic distribution that are ubiquitous, in that\nthey are found almost everywhere, in both natural as well as in man-made\nsystems. They tend to emerge in large, connected and self-organizing systems,\nfor example, scholarly publications. Citations to scientific papers have been\nfound to follow a power law, i.e., the number of papers having a certain level\nof citation x are proportional to x raised to some negative power. The\ndistributional character of altmetrics has not been studied yet as altmetrics\nare among the newest indicators related to scholarly publications. Here we\nselect a data sample from the altmetrics aggregator Altmetrics.com containing\nrecords from the platforms Facebook, Twitter, News, Blogs, etc., and the\ncomposite variable Alt-score for the period 2016. The individual and the\ncomposite data series of 'mentions' on the various platforms are fit to a power\nlaw distribution, and the parameters and goodness of fit determined using least\nsquares regression. The log-log plot of the data, 'mentions' vs. number of\npapers, falls on an approximately linear line, suggesting the plausibility of a\npower law distribution. The fit is not very good in all cases due to large\nfluctuations in the tail. We show that fit to the power law can be improved by\ntruncating the data series to eliminate large fluctuations in the tail. We\nconclude that altmetric distributions also follow power laws with a fairly good\nfit over a wide range of values. More rigorous methods of determination may not\nbe necessary at present.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 04:11:56 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Banshal", "Sumit Kumar", ""], ["Basu", "Aparna", ""], ["Singh", "Vivek Kumar", ""], ["Gupta", "Solanki", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2011.09328", "submitter": "Manh Toan Ho Mr.", "authors": "Ngo Bao Chau, Vuong Quan Hoang, La Viet Phuong, Le Tuan Hoa, Le Minh\n  Ha, Trinh Thi Thuy Giang, Pham Hung Hiep, Nguyen Thanh Thanh Huyen, Nguyen\n  Thanh Dung, Nguyen Thi Linh, Tran Trung, Nguyen Minh Hoang and Ho Manh Toan", "title": "The 80-year development of Vietnam mathematical research: Preliminary\n  insights from the SciMath database on mathematicians, their works and their\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL math.HO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Starting with the first international publication of Le Van Thiem in 1947,\nmodern mathematics in Vietnam is a longstanding research field. However, what\nis known about its development usually comes from discrete essays such as\nanecdotes or interviews of renowned mathematicians. We introduce SciMath-a\ndatabase on publications of Vietnamese mathematicians. To ensure this database\ncovers as many publications as possible, data entries are manually collected\nfrom scientists' publication records, journals' websites, universities, and\nresearch institutions. Collected data went through various verification steps\nto ensure data quality and minimize errors. At the time of this report, the\ndatabase covered 8372 publications, profiles of 1566 Vietnamese, and 1492\nforeign authors since 1947. We found a growing capability in mathematics\nresearch in Vietnam in various aspects: scientific output, publications on\ninfluential journals, or collaboration. The database and preliminary results\nwere presented to the Scientific Council of Vietnam Institute for Advanced\nStudy in Mathematics (VIASM) on November 13th, 2020.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:06:38 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Chau", "Ngo Bao", ""], ["Hoang", "Vuong Quan", ""], ["Phuong", "La Viet", ""], ["Hoa", "Le Tuan", ""], ["Ha", "Le Minh", ""], ["Giang", "Trinh Thi Thuy", ""], ["Hiep", "Pham Hung", ""], ["Huyen", "Nguyen Thanh Thanh", ""], ["Dung", "Nguyen Thanh", ""], ["Linh", "Nguyen Thi", ""], ["Trung", "Tran", ""], ["Hoang", "Nguyen Minh", ""], ["Toan", "Ho Manh", ""]]}, {"id": "2011.11940", "submitter": "Zhiqi Wang", "authors": "Zhiqi Wang, Yue Chen, Wolfgang Gl\\\"anzel", "title": "Preprints as accelerator of scholarly communication: An empirical\n  analysis in Mathematics", "comments": "This is the accepted manuscript of the paper being published in\n  Journal of Informetrics. The link to the final published journal version :\n  https://linkinghub.elsevier.com/retrieve/pii/S1751157720300729", "journal-ref": "Journal of Informetrics,2020,14(4)", "doi": "10.1016/j.joi.2020.101097", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this study we analyse the key driving factors of preprints in enhancing\nscholarly communication. To this end we use four groups of metrics, one\nreferring to scholarly communication and based on bibliometric indicators (Web\nof Science and Scopus citations), while the others reflect usage (usage counts\nin Web of Science), capture (Mendeley readers) and social media attention\n(Tweets). Hereby we measure two effects associated with preprint publishing:\npublication delay and impact. We define and use several indicators to assess\nthe impact of journal articles with previous preprint versions in arXiv. In\nparticular, the indicators measure several times characterizing the process of\narXiv preprints publishing and the reviewing process of the journal versions,\nand the ageing patterns of citations to preprints. In addition, we compare the\nobserved patterns between preprints and non-OA articles without any previous\npreprint versions in arXiv. We could observe that the \"early-view\" and\n\"open-access\" effects of preprints contribute to a measurable citation and\nreadership advantage of preprints. Articles with preprint versions are more\nlikely to be mentioned in social media and have shorter Altmetric attention\ndelay. Usage and capture prove to have only moderate but stronger correlation\nwith citations than Tweets. The different slopes of the regression lines\nbetween the different indicators reflect different order of magnitude of usage,\ncapture and citation data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 07:32:35 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 00:00:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Zhiqi", ""], ["Chen", "Yue", ""], ["Gl\u00e4nzel", "Wolfgang", ""]]}, {"id": "2011.12479", "submitter": "Diego Amancio", "authors": "Ana C. M. Brito and Filipi N. Silva and Diego R. Amancio", "title": "Associations between author-level metrics in subsequent time periods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the dynamics of authors is relevant to predict and quantify\nperformance in science. While the relationship between recent and future\ncitation counts is well-known, many relationships between scholarly metrics at\nthe author-level remain unknown. In this context, we performed an analysis of\nauthor-level metrics extracted from subsequent periods, focusing on visibility,\nproductivity and interdisciplinarity. First, we investigated how metrics\ncontrolled by the authors (such as references diversity and productivity)\naffect their visibility and citation diversity. We also explore the relation\nbetween authors' interdisciplinarity and citation counts. The analysis in a\nsubset of Physics papers revealed that there is no strong correlation between\nauthors' productivity and future visibility for most of the authors. A higher\nfraction of strong positive correlations though was found for those with a\nlower number of publications. We also found that reference diversity computed\nat the author-level may impact positively authors' future visibility. The\nanalysis of metrics impacting future interdisciplinarity suggests that\nproductivity may play a role only for low productivity authors. We also found a\nsurprisingly strong positive correlation between references diversity and\ninterdisciplinarity, suggesting that an increase in diverse citing behavior may\nbe related to a future increase in authors interdisciplinarity. Finally,\ninterdisciplinarity and visibility were found to be moderated positively\nassociated: significant positive correlations were observed for 30% of authors\nwith lower productivity.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 02:03:41 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Brito", "Ana C. M.", ""], ["Silva", "Filipi N.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "2011.12626", "submitter": "Wenceslao Arroyo-Machado", "authors": "Daniel Torres-Salinas, Wenceslao Arroyo-Machado, Mike Thelwall", "title": "Exploring WorldCat Identities as an altmetric information source: A\n  library catalog analysis experiment in the field of Scientometrics", "comments": null, "journal-ref": null, "doi": "10.1007/s11192-020-03814-w", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing the impact of scholarly books is a difficult research evaluation\nproblem. Library Catalog Analysis facilitates the quantitative study, at\ndifferent levels, of the impact and diffusion of academic books based on data\nabout their availability in libraries. The WorldCat global catalog collates\ndata on library holdings, offering a range of tools including the novel\nWorldCat Identities. This is based on author profiles and provides indicators\nrelating to the availability of their books in library catalogs. Here, we\ninvestigate this new tool to identify its strengths and weaknesses based on a\nsample of Bibliometrics and Scientometrics authors. We review the problems that\nthis entails and compare Library Catalog Analysis indicators with Google\nScholar and Web of Science citations. The results show that WorldCat Identities\ncan be a useful tool for book impact assessment but the value of its data is\nundermined by the provision of massive collections of ebooks to academic\nlibraries.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:31:26 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Torres-Salinas", "Daniel", ""], ["Arroyo-Machado", "Wenceslao", ""], ["Thelwall", "Mike", ""]]}, {"id": "2011.13091", "submitter": "Kiran Sharma Dr.", "authors": "Kiran Sharma", "title": "Patterns of retractions from 1981-2020 : Does a fraud lead to another\n  fraud?", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misconduct accounts for the majority of retracted scientific publications and\nthis database reveals the disturbing trend in\nscience~\\citep{fang2012misconduct, brainard2018massive}. The objective of the\nstudy is to find the association among the authors' collaboration, the number\nof retracted papers, the number of retracted citations, journal impact factor,\nand research areas. We present a detailed analysis of 12231 research papers\nindexed by Web of Science (WoS) as retracted publications from 1981-2020. The\nstudy demonstrates the collaboration patterns of retracted publications where\n61.5% of authors have only one and 24.6% have two retracted papers; however, 2%\nof authors have more than 10 retracted papers. To study the impact of citing\nretracted papers, we investigated the retracted papers with citations. The\nstudy reveals that 55.2% of retracted papers have been cited at least once,\nwhere 25.4% of papers are such papers where at least one citation turned out to\nbe a retraction. This shows the impact of scientific misconduct or fraud on new\nresearch. The number of retractions is independent of the journal impact factor\nand as compared to high impact papers, low impact papers are attracting more\ncitations. We also investigate the citations received by retracted papers\npublished in higher as well as lower impact factor journals. 1/4th of the\npapers are retracted citations that cited the retracted papers; however, there\nis no significant relationship exists between the higher impact or lower impact\njournals with retractions or citations. Finally, how the average team size and\naverage retracted citations vary among different research areas are studied.\nThe study provides an insight that how a fraud leads to another fraud in the\nscientific world. Also, the rising trend of citations of retracted papers is a\nserious concern.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:08:05 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Sharma", "Kiran", ""]]}, {"id": "2011.13114", "submitter": "Christopher Rauch", "authors": "Mat Kelly (1), Jane Greenberg (1), Christopher B. Rauch (1), Sam\n  Grabus (1), Joan P. Boone (1), John A. Kunze (2), Peter Melville Logan (3)\n  ((1) Drexel University, (2) California Digital Library, (3) Temple\n  University)", "title": "A Computational Approach to Historical Ontologies", "comments": "6 pages, 5 figures. To be published in Proceedings of the 2020 IEEE\n  International Conference on Big Data (IEEE Big Data 2020)", "journal-ref": "2020 IEEE International Conference on Big Data (Big Data),\n  Atlanta, GA, USA, 2020, pp. 1878-1883", "doi": "10.1109/BigData50022.2020.9378268", "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a use case exploring the application of the Archival\nResource Key (ARK) persistent identifier for promoting and maintaining\nontologies. In particular, we look at improving computation with an in-house\nontology server in the context of temporally aligned vocabularies. This effort\ndemonstrates the utility of ARKs in preparing historical ontologies for\ncomputational archival science.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 03:53:56 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Kelly", "Mat", ""], ["Greenberg", "Jane", ""], ["Rauch", "Christopher B.", ""], ["Grabus", "Sam", ""], ["Boone", "Joan P.", ""], ["Kunze", "John A.", ""], ["Logan", "Peter Melville", ""]]}, {"id": "2011.13883", "submitter": "Juste Raimbault", "authors": "C. Cottineau, J. Raimbault, P.-O. Chasset, H. Commenges, A. Banos and\n  D. Pumain", "title": "CybergeoNetworks, an interactive application for the geographical and\n  semantic analysis of scientific publications", "comments": "6 pages, 3 figures. Translated from French", "journal-ref": "In Bouzeghoub M., Mosseri R. (eds.) Les Big Data {\\`a}\n  d{\\'e}couvert, CNRS Editions (EAN: 9782271114648), pp.272-273, 2017", "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in the number of publications has made more difficult for\nauthors to situate their work within previous literature, especially on\nsubjects studied from different disciplinary viewpoints. Besides, new data\nanalysis techniques and new bibliometrics data sources provide an opportunity\nto map and navigate scientific landscapes. We introduce here an open-source and\nopen-access web application designed for the multi-dimensional exploration of a\njournal content, including the mapping of geographical, semantic and citations\nnetworks. The application is profiled and implemented for the geography journal\nCybergeo, a generalist geography journal which receives contributions from\nmultiple sub-disciplines. We suggest that such initiatives are crucial to\npromote open science and reflexivity.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:16:46 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cottineau", "C.", ""], ["Raimbault", "J.", ""], ["Chasset", "P. -O.", ""], ["Commenges", "H.", ""], ["Banos", "A.", ""], ["Pumain", "D.", ""]]}, {"id": "2011.13886", "submitter": "Ivan Heibi", "authors": "Ivan Heibi, Silvio Peroni, Luca Pareschi and Paolo Ferri", "title": "MITAO: a tool for enabling scholars in the Humanities to use Topic\n  Modelling in their studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic text analysis methods, such as Topic Modelling, are gaining much\nattention in Humanities. However, scholars need to have extensive coding skills\nto use such methods appropriately. The need of having this technical expertise\nprevents the broad adoption of these methods in Humanities research. In this\npaper, to help scholars in the Humanities to use Topic Modelling having no or\nlimited coding skills, we introduce MITAO, a web-based tool that allow the\ndefinition of a visual workflow which embeds various automatic text analysis\noperations and allows one to store and share both the workflow and the results\nof its execution to other researchers, which enables the reproducibility of the\nanalysis. We present an example of an application of use of Topic Modelling\nwith MITAO using a collection of English abstracts of the articles published in\n\"Umanistica Digitale\". The results returned by MITAO are shown with dynamic\nweb-based visualizations, which allowed us to have preliminary insights about\nthe evolution of the topics treated over the time in the articles published in\n\"Umanistica Digitale\". All the results along with the defined workflows are\npublished and accessible for further studies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:20:10 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Heibi", "Ivan", ""], ["Peroni", "Silvio", ""], ["Pareschi", "Luca", ""], ["Ferri", "Paolo", ""]]}, {"id": "2011.14646", "submitter": "Ivan Stelmakh", "authors": "Ivan Stelmakh, Nihar B. Shah, Aarti Singh, and Hal Daum\\'e III", "title": "Prior and Prejudice: The Novice Reviewers' Bias against Resubmissions in\n  Conference Peer Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning and computer science conferences are experiencing a\nsurge in the number of submissions that challenges the quality of peer review\nas the number of competent reviewers is growing at a much slower rate. To curb\nthis trend and reduce the burden on reviewers, several conferences have started\nencouraging or even requiring authors to declare the previous submission\nhistory of their papers. Such initiatives have been met with skepticism among\nauthors, who raise the concern about a potential bias in reviewers'\nrecommendations induced by this information. In this work, we investigate\nwhether reviewers exhibit a bias caused by the knowledge that the submission\nunder review was previously rejected at a similar venue, focusing on a\npopulation of novice reviewers who constitute a large fraction of the reviewer\npool in leading machine learning and computer science conferences. We design\nand conduct a randomized controlled trial closely replicating the relevant\ncomponents of the peer-review pipeline with $133$ reviewers (master's, junior\nPhD students, and recent graduates of top US universities) writing reviews for\n$19$ papers. The analysis reveals that reviewers indeed become negatively\nbiased when they receive a signal about paper being a resubmission, giving\nalmost 1 point lower overall score on a 10-point Likert item ($\\Delta = -0.78,\n\\ 95\\% \\ \\text{CI} = [-1.30, -0.24]$) than reviewers who do not receive such a\nsignal. Looking at specific criteria scores (originality, quality, clarity and\nsignificance), we observe that novice reviewers tend to underrate quality the\nmost.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:35:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Stelmakh", "Ivan", ""], ["Shah", "Nihar B.", ""], ["Singh", "Aarti", ""], ["Daum\u00e9", "Hal", "III"]]}]