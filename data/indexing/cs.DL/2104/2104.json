[{"id": "2104.00089", "submitter": "Richard Irving Anderson", "authors": "Richard I. Anderson, Sherry H. Suyu, Antoine M\\'erand", "title": "Maintaining scientific discourse during a global pandemic: ESO's first\n  e-conference #H02020", "comments": "Report on ESO's first e-conference: \"Assessing Uncertainties in\n  Hubble's Constant Across the Universe\" (H0 2020). 9 pages, 5 figures, 2\n  tables. To be submitted to the ESO Messenger", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO astro-ph.GA astro-ph.SR cs.DL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  From 22 to 26 June 2020, we hosted ESO's first live e-conference, #H02020,\nfrom within ESO headquarters in Garching, Germany. Every day, between 200 and\n320 researchers around the globe tuned in to discuss the nature and\nimplications of the discord between precise determinations of the Universe's\nexpansion rate, H0. Originally planned as an in-person meeting, we moved to the\nvirtual domain to maintain strong scientific discourse despite the SARS-CoV-2\n(COVID-19) pandemic. Here, we describe our conference setup, participants\nfeedback gathered before and after the meeting, and lessons learned from this\nunexpected exercise. As e-conferencing will become increasingly common in the\nfuture, we provide our perspective on how e-conferences can make scientific\nexchange more effective and inclusive, in addition to climate friendly.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 20:15:37 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Anderson", "Richard I.", ""], ["Suyu", "Sherry H.", ""], ["M\u00e9rand", "Antoine", ""]]}, {"id": "2104.00948", "submitter": "Angelo Salatino", "authors": "Angelo A. Salatino, Francesco Osborne, Thiviyan Thanapalasingam,\n  Enrico Motta", "title": "The CSO Classifier: Ontology-Driven Detection of Research Topics in\n  Scholarly Articles", "comments": "Conference paper at TPDL 2019", "journal-ref": "In Digital Libraries for Open Knowledge. LNCS, vol 11799.\n  Springer, Cham (2019)", "doi": "10.1007/978-3-030-30760-8_26", "report-no": null, "categories": "cs.IR cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classifying research papers according to their research topics is an\nimportant task to improve their retrievability, assist the creation of smart\nanalytics, and support a variety of approaches for analysing and making sense\nof the research environment. In this paper, we present the CSO Classifier, a\nnew unsupervised approach for automatically classifying research papers\naccording to the Computer Science Ontology (CSO), a comprehensive ontology of\nre-search areas in the field of Computer Science. The CSO Classifier takes as\ninput the metadata associated with a research paper (title, abstract, keywords)\nand returns a selection of research concepts drawn from the ontology. The\napproach was evaluated on a gold standard of manually annotated articles\nyielding a significant improvement over alternative methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 09:02:32 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Salatino", "Angelo A.", ""], ["Osborne", "Francesco", ""], ["Thanapalasingam", "Thiviyan", ""], ["Motta", "Enrico", ""]]}, {"id": "2104.01052", "submitter": "Jacques Fleuriot", "authors": "Carlin MacKenzie, Jacques Fleuriot and James Vaughan", "title": "An Evaluation of the Archive of Formal Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Archive of Formal Proofs (AFP) is an online repository of formal proofs\nfor the Isabelle proof assistant. It serves as a central location for\npublishing, discovering, and viewing libraries of proofs. We conducted an\nonline survey in November 2020 to assess the suitability of the website. In\nthis report, we present and discuss the results, which showed that long-term\nusers of the website are generally satisfied with the AFP but that there are a\nnumber of areas, such as navigation, search and script browsing, that need\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 14:02:39 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["MacKenzie", "Carlin", ""], ["Fleuriot", "Jacques", ""], ["Vaughan", "James", ""]]}, {"id": "2104.01106", "submitter": "Vlad Atanasiu", "authors": "Vlad Atanasiu, Isabelle Marthot-Santaniello", "title": "Legibility Enhancement of Papyri Using Color Processing and Visual\n  Illusions: A Case Study in Critical Vision", "comments": "Article accepted with minor revisions by the International Journal on\n  Document Analysis and Recognition (IJDAR) on 2021.03.11. Open Source software\n  accessible at https://hierax.ch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DL cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Purpose: This article develops theoretical, algorithmic, perceptual, and\ninteraction aspects of script legibility enhancement in the visible light\nspectrum for the purpose of scholarly editing of papyri texts. - Methods: Novel\nlegibility enhancement algorithms based on color processing and visual\nillusions are proposed and compared to classic methods. A user experience\nexperiment was carried out to evaluate the solutions and better understand the\nproblem on an empirical basis. - Results: (1) The proposed methods outperformed\nthe comparison methods. (2) The methods that most successfully enhanced script\nlegibility were those that leverage human perception. (3) Users exhibited a\nbroad behavioral spectrum of text-deciphering strategies, under the influence\nof factors such as personality and social conditioning, tasks and application\ndomains, expertise level and image quality, and affordances of software,\nhardware, and interfaces. No single method satisfied all factor configurations.\nTherefore, using synergetically a range of enhancement methods and interaction\nmodalities is suggested for optimal results and user satisfaction. (4) A\nparadigm of legibility enhancement for critical applications is outlined,\ncomprising the following criteria: interpreting images skeptically; approaching\nenhancement as a system problem; considering all image structures as potential\ninformation; deriving interpretations from connections across distinct spatial\nlocations; and making uncertainty and alternative interpretations explicit,\nboth visually and numerically.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 23:48:17 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Atanasiu", "Vlad", ""], ["Marthot-Santaniello", "Isabelle", ""]]}, {"id": "2104.01239", "submitter": "Stephanie Weirich", "authors": "Stephanie Weirich and Benjamin Pierce", "title": "ICFP 2020 Post-Conference Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document describes the ICFP 2020 virtual conference, including the\nplanning process and the criteria that informed its design, plus feedback from\nthe post-conference survey. It is intended to provide a record of the event and\ngive advice to future organizers of virtual conferences.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 18:15:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Weirich", "Stephanie", ""], ["Pierce", "Benjamin", ""]]}, {"id": "2104.01663", "submitter": "Rongqian Ma", "authors": "Rongqian Ma", "title": "Curating China's Cultural Revolution (1966-1976): CR/10 as a Warburgian\n  Memory Atlas and Digital Humanities Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  CR/10 is a digital oral history platform that aims to collect and preserve\nthe cultural memories of China's Cultural Revolution (1966-1976). This paper\ndiscusses how CR/10 functions as a Warburgian memory atlas and shapes\nmultifaceted narratives of the historical incident. Through ethnographic\nresearch and semi-structured interviews with users within and outside academia,\nI examined the usability of CR/10 among various user groups and proposed design\nopportunities to further empower the interface. This paper offered a strong\ncase on the datafication of cultural memories among cultural heritage\ninstitutions and contributed to digital archiving scholarship with an\ninnovative methodological lens.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 18:55:09 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ma", "Rongqian", ""]]}, {"id": "2104.01729", "submitter": "Yukie Sano", "authors": "Keigo Kusumegi, Yukie Sano", "title": "Citations and gender diversity in reciprocal acknowledgement networks", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acknowledgements in scientific articles suggest not only gratitude, but also\nthe interactions among scientists. In this study, we examine the\nacknowledgement interactions employing data from open-access journals (PLOS\nseries). We built an acknowledgement network where the nodes represent authors\nand acknowledged people, while the links correspond to being mentioned in\nacknowledgements. Employing motif analysis, we showed how acknowledgement\nnetworks have developed, and how reciprocal relationships tend to emerge. To\nbetter understand these reciprocal relationships, we analysed the reciprocal\nsub-graphs of acknowledgement from two perspectives: citations and gender\ndiversity. Firstly, we counted the number of citations, from both reciprocal\nand non-reciprocal authors. We found that reciprocal authors predominantly tend\nto cite other reciprocal authors rather than non-reciprocal ones. For gender\ndiversity, we found that reciprocal pairs that include females tend to emerge\nmore than male-male pairs of reciprocity in various fields, despite the fewer\nnumber of females.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 00:42:21 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kusumegi", "Keigo", ""], ["Sano", "Yukie", ""]]}, {"id": "2104.01794", "submitter": "Paolo Politi", "authors": "Paolo Politi, Satya N. Majumdar, Antonio Politi, Stefano Ruffo", "title": "Some considerations about reviewing and open-access in scientific\n  publishing", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cond-mat.stat-mech physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Scientific research changed profoundly over the last 30 years, in all its\naspects. Scientific publishing has changed as well, mainly because of the\nstrong increased number of submitted papers and because of the appearance of\nOpen Access journals and publishers. We propose some reflections on these\nissues.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 06:50:52 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Politi", "Paolo", ""], ["Majumdar", "Satya N.", ""], ["Politi", "Antonio", ""], ["Ruffo", "Stefano", ""]]}, {"id": "2104.01800", "submitter": "Abdul Syahid", "authors": "Abdul Syahid", "title": "Indonesian Journal of Applied Linguistics: A Bibliometric Portrait of\n  Ten Publication Years", "comments": "23 pages, 4 tables, 9 figures", "journal-ref": "Library Philosophy and Practice (e-journal). 2021. 5178.\n  https://digitalcommons.unl.edu/libphilprac/5178", "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bibliometric portraits of a single journal appear to be rarely taken in the\nfield of applied linguistics. Viewed from the angles of publication, citation,\nand indexation, one of the journals worth a bibliometric portrait is the\nIndonesian Journal of Applied Linguistics. Casting local and regional concerns\non the global applied linguistics, the journal has ranked among the big five\nOpen Access Journals in the Asiatic region since its foundation in 2011.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 07:22:41 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Syahid", "Abdul", ""]]}, {"id": "2104.01821", "submitter": "Li Zhang", "authors": "Li Zhang, Wei Lu, Jinqing Yang", "title": "LAGOS-AND: A Large, Gold Standard Dataset for Scholarly Author Name\n  Disambiguation", "comments": "27 pages, 5 tables, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a method to automatically generate a large-scale\nlabeled dataset for author name disambiguation (AND) in the academic world by\nleveraging authoritative sources, ORCID and DOI. Using the method, we built\nLAGOS-AND, a large, gold standard dataset for AND, which is substantially\ndifferent from existing ones. It contains 7.5M citations authored by 797K\nunique authors and shows close similarities to the entire Microsoft Academic\nGraph (MAG) across six gold standard validations. In building the dataset, we\ninvestigated the long-standing name synonym problem and revealed the degree of\nvariation in the last name for the first time. Evidence from PubMed, MAG, and\nSemantic Scholar all suggests that there are ~7.5% of authorships who have\nvaried their last names from the credible last names in the ORCID system when\nignoring the variants introduced by special characters. Furthermore, we\nprovided a classification-based AND benchmark on the new dataset and released\nour model for disambiguation in general scenarios. If this work is helpful for\nfuture studies, we believe it will challenge (1) the widely accepted\nblock-based disambiguation framework in production environment and, (2) the\nstate-of-the-art methods or models on AND. The code, dataset, and pre-trained\nmodel are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 09:32:29 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhang", "Li", ""], ["Lu", "Wei", ""], ["Yang", "Jinqing", ""]]}, {"id": "2104.01849", "submitter": "Jos\\'e Devezas PhD", "authors": "Jos\\'e Devezas and S\\'ergio Nunes", "title": "Managing Research the Wiki Way: A Systematic Approach to Documenting\n  Research", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a master's student, knowing how to manage your personal research is not\nonly useful for keeping track of your work, but it is also a process that\nshould be learned as a part of your training. As a doctoral student, however,\nresearch management is a fundamental part of your overall methodology and it\nshould be a well-planned process. Long-term research requires a good approach\nto documentation, otherwise you risk getting lost among your many surveyed\npapers, carried experiments, and results. This approach should be systematic,\naccessible (mainly to you), low-effort, and a natural part of your daily\nworkflow - it should be there to help you, and not the other way around. In\nthis article, we describe how we relied on a wiki to organize literature,\ndatasets, experiments and results, and we also show how such a systematic\napproach can lead to better insights through automated meta-analysis. In\naddition to this content, we provide a docker-based installation of a\npreconfigured wiki, with the required templates and extensions, along with some\nexamples pages, as well as a Jupyter notebook to analyze your documented work.\nSo read on.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 10:55:13 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 16:47:24 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Devezas", "Jos\u00e9", ""], ["Nunes", "S\u00e9rgio", ""]]}, {"id": "2104.03338", "submitter": "Fabricio Murai", "authors": "Francisco Galuppo Azevedo and Fabricio Murai", "title": "Evaluating the state-of-the-art in mapping research spaces: a Brazilian\n  case study", "comments": "28 pages, 11 figures", "journal-ref": "PLoS ONE 16(3): e0248724 (2021)", "doi": "10.1371/journal.pone.0248724", "report-no": null, "categories": "cs.DL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scientific knowledge cannot be seen as a set of isolated fields, but as a\nhighly connected network. Understanding how research areas are connected is of\nparamount importance for adequately allocating funding and human resources\n(e.g., assembling teams to tackle multidisciplinary problems). The relationship\nbetween disciplines can be drawn from data on the trajectory of individual\nscientists, as researchers often make contributions in a small set of\ninterrelated areas. Two recent works propose methods for creating research maps\nfrom scientists' publication records: by using a frequentist approach to create\na transition probability matrix; and by learning embeddings (vector\nrepresentations). Surprisingly, these models were evaluated on different\ndatasets and have never been compared in the literature. In this work, we\ncompare both models in a systematic way, using a large dataset of publication\nrecords from Brazilian researchers. We evaluate these models' ability to\npredict whether a given entity (scientist, institution or region) will enter a\nnew field w.r.t. the area under the ROC curve. Moreover, we analyze how\nsensitive each method is to the number of publications and the number of fields\nassociated to one entity. Last, we conduct a case study to showcase how these\nmodels can be used to characterize science dynamics in the context of Brazil.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 18:14:41 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Azevedo", "Francisco Galuppo", ""], ["Murai", "Fabricio", ""]]}, {"id": "2104.04116", "submitter": "Shawn Jones", "authors": "Shawn M. Jones and Valentina Neblitt-Jones and Michele C. Weigle and\n  Martin Klein and Michael L. Nelson", "title": "It's All About The Cards: Sharing on Social Media Probably Encouraged\n  HTML Metadata Growth", "comments": "10 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a perfect world, all articles consistently contain sufficient metadata to\ndescribe the resource. We know this is not the reality, so we are motivated to\ninvestigate the evolution of the metadata that is present when authors and\npublishers supply their own. Because applying metadata takes time, we recognize\nthat each news article author has a limited metadata budget with which to spend\ntheir time and effort. How are they spending this budget? What are the top\nmetadata categories in use? How did they grow over time? What purpose do they\nserve? We also recognize that not all metadata fields are used equally. What is\nthe growth of individual fields over time? Which fields experienced the fastest\nadoption? In this paper, we review 227,726 HTML news articles from 29 outlets\ncaptured by the Internet Archive between 1998 and 2016. Upon reviewing the\nmetadata fields in each article, we discovered that 2010 began a metadata\nrenaissance as publishers embraced metadata for improved search engine ranking,\nsearch engine tracking, social media tracking, and social media sharing. When\nanalyzing individual fields, we find that one application of metadata stands\nout above all others: social cards -- the cards generated by platforms like\nTwitter when one shares a URL. Once a metadata standard was established for\ncards in 2010, its fields were adopted by 20% of articles in the first year and\nreached more than 95% adoption by 2016. This rate of adoption surpasses efforts\nlike Schema.org and Dublin Core by a fair margin. When confronted with these\nresults on how news publishers spend their metadata budget, we must conclude\nthat it is all about the cards.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 23:43:44 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Jones", "Shawn M.", ""], ["Neblitt-Jones", "Valentina", ""], ["Weigle", "Michele C.", ""], ["Klein", "Martin", ""], ["Nelson", "Michael L.", ""]]}, {"id": "2104.04380", "submitter": "Marcia Ferreira", "authors": "Marcia Ferreira, Juan Pablo Bascur, Rodrigo Costas", "title": "Scholars mobility and its impact on the knowledge producers' workforce\n  of European regions", "comments": "Research in Progress Paper in ISSI conference 2019 (Rome), 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge production increasingly relies on mobility. However, its role as a\nmechanism for knowledge recombination and dissemination remains largely\nunknown. Based on 1,244,080 Web of Science publications from 1,435,729 authors\nthat we used to construct a panel dataset, we study the impact of\ninter-regional publishing and scientists' mobility in fostering the workforce\ncomposition of European countries during 2008-2017. Specifically, we collect\ninformation on scientists who have published in one region and then published\nelsewhere, and explore some determinants of regional and international\nmobility. Preliminary findings suggest that while talent pools of researchers\nare increasingly international, their movements seem to be steered by\ngeographical structures. Future research will investigate the impact of\nmobility on the regional structure of scientific fields by accounting for the\nappearance and disappearance of research topics over time.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:09:41 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ferreira", "Marcia", ""], ["Bascur", "Juan Pablo", ""], ["Costas", "Rodrigo", ""]]}, {"id": "2104.04580", "submitter": "Jian Wu", "authors": "Jian Wu, Rajal Nivargi, Sree Sai Teja Lanka, Arjun Manoj Menon, Sai\n  Ajay Modukuri, Nishanth Nakshatri, Xin Wei, Zhuoer Wang, James Caverlee,\n  Sarah M. Rajtmajer, C. Lee Giles", "title": "Predicting the Reproducibility of Social and Behavioral Science Papers\n  Using Supervised Learning Models", "comments": "17 pages, 8 figures, a draft to be submitted to JCDL'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, significant effort has been invested verifying the\nreproducibility and robustness of research claims in social and behavioral\nsciences (SBS), much of which has involved resource-intensive replication\nprojects. In this paper, we investigate prediction of the reproducibility of\nSBS papers using machine learning methods based on a set of features. We\npropose a framework that extracts five types of features from scholarly work\nthat can be used to support assessments of reproducibility of published\nresearch claims. Bibliometric features, venue features, and author features are\ncollected from public APIs or extracted using open source machine learning\nlibraries with customized parsers. Statistical features, such as p-values, are\nextracted by recognizing patterns in the body text. Semantic features, such as\nfunding information, are obtained from public APIs or are extracted using\nnatural language processing models. We analyze pairwise correlations between\nindividual features and their importance for predicting a set of human-assessed\nground truth labels. In doing so, we identify a subset of 9 top features that\nplay relatively more important roles in predicting the reproducibility of SBS\npapers in our corpus. Results are verified by comparing performances of 10\nsupervised predictive classifiers trained on different sets of features.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 00:45:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wu", "Jian", ""], ["Nivargi", "Rajal", ""], ["Lanka", "Sree Sai Teja", ""], ["Menon", "Arjun Manoj", ""], ["Modukuri", "Sai Ajay", ""], ["Nakshatri", "Nishanth", ""], ["Wei", "Xin", ""], ["Wang", "Zhuoer", ""], ["Caverlee", "James", ""], ["Rajtmajer", "Sarah M.", ""], ["Giles", "C. Lee", ""]]}, {"id": "2104.04939", "submitter": "Abdul Wahid", "authors": "Abdul Wahid, Rajesh Sharma, and Chandra Sekhara Rao Annavarapu", "title": "A Graph Convolutional Neural Network based Framework for Estimating\n  Future Citations Count of Research Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific publications play a vital role in the career of a researcher.\nHowever, some articles become more popular than others among the research\ncommunity and subsequently drive future research directions. One of the\nindicative signs of popular articles is the number of citations an article\nreceives. The citation count, which is also the basis with various other\nmetrics, such as the journal impact factor score, the $h$-index, is an\nessential measure for assessing a scientific paper's quality. In this work, we\nproposed a Graph Convolutional Network (GCN) based framework for estimating\nfuture research publication citations for both the short-term (1-year) and\nlong-term (for 5-years and 10-years) duration. We have tested our proposed\napproach over the AMiner dataset, specifically on research articles from the\ncomputer science domain, consisting of more than 0.8 million articles.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 07:20:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wahid", "Abdul", ""], ["Sharma", "Rajesh", ""], ["Annavarapu", "Chandra Sekhara Rao", ""]]}, {"id": "2104.05111", "submitter": "Moritz Schubotz", "authors": "Philipp Scharpf and Moritz Schubotz and Bela Gipp", "title": "Fast Linking of Mathematical Wikidata Entities in Wikipedia Articles\n  Using Annotation Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical information retrieval (MathIR) applications such as semantic\nformula search and question answering systems rely on knowledge-bases that link\nmathematical expressions to their natural language names. For database\npopulation, mathematical formulae need to be annotated and linked to semantic\nconcepts, which is very time-consuming. In this paper, we present our approach\nto structure and speed up this process by supporting annotators with a system\nthat suggests formula names and meanings of mathematical identifiers. We test\nour approach annotating 25 articles on https://en.wikipedia.org. We evaluate\nthe quality and time-savings of the annotation recommendations. Moreover, we\nwatch editor reverts and comments on Wikipedia formula entity links and\nWikidata item creation and population to ground the formula semantics. Our\nevaluation shows that the AI guidance was able to significantly speed up the\nannotation process by a factor of 1.4 for formulae and 2.4 for identifiers. Our\ncontributions were reverted in 12% of the edited Wikipedia articles and 33% of\nthe Wikidata items within a test window of one month. The >>AnnoMathTeX<<\nannotation recommender system is hosted by Wikimedia at\nhttps://annomathtex.wmflabs.org. In the future, our data refinement pipeline is\nready to be integrated seamlessly into the Wikipedia user interface.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 21:18:58 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Scharpf", "Philipp", ""], ["Schubotz", "Moritz", ""], ["Gipp", "Bela", ""]]}, {"id": "2104.05409", "submitter": "Chengzhi Zhang", "authors": "Qingqing Zhou and Chengzhi Zhang", "title": "Breaking Community Boundary: Comparing Academic and Social Communication\n  Preferences regarding Global Pandemics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global spread of COVID-19 has caused pandemics to be widely discussed.\nThis is evident in the large number of scientific articles and the amount of\nuser-generated content on social media. This paper aims to compare academic\ncommunication and social communication about the pandemic from the perspective\nof communication preference differences. It aims to provide information for the\nongoing research on global pandemics, thereby eliminating knowledge barriers\nand information inequalities between the academic and the social communities.\nFirst, we collected the full text and the metadata of pandemic-related articles\nand Twitter data mentioning the articles. Second, we extracted and analyzed the\ntopics and sentiment tendencies of the articles and related tweets. Finally, we\nconducted pandemic-related differential analysis on the academic community and\nthe social community. We mined the resulting data to generate pandemic\ncommunication preferences (e.g., information needs, attitude tendencies) of\nresearchers and the public, respectively. The research results from 50,338\narticles and 927,266 corresponding tweets mentioning the articles revealed\ncommunication differences about global pandemics between the academic and the\nsocial communities regarding the consistency of research recognition and the\npreferences for particular research topics. The analysis of large-scale\npandemic-related tweets also confirmed the communication preference differences\nbetween the two communities.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 12:44:22 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhou", "Qingqing", ""], ["Zhang", "Chengzhi", ""]]}, {"id": "2104.05891", "submitter": "Hideaki Hata", "authors": "Hideaki Hata, Jin L.C. Guo, Raula Gaikovina Kula, Christoph Treude", "title": "Science-Software Linkage: The Challenges of Traceability between\n  Scientific Knowledge and Software Artifacts", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Although computer science papers are often accompanied by software artifacts,\nconnecting research papers to their software artifacts and vice versa is not\nalways trivial. First of all, there is a lack of well-accepted standards for\nhow such links should be provided. Furthermore, the provided links, if any,\noften become outdated: they are affected by link rot when pre-prints are\nremoved, when repositories are migrated, or when papers and repositories evolve\nindependently. In this paper, we summarize the state of the practice of linking\nresearch papers and associated source code, highlighting the recent efforts\ntowards creating and maintaining such links. We also report on the results of\nseveral empirical studies focusing on the relationship between scientific\npapers and associated software artifacts, and we outline challenges related to\ntraceability and opportunities for overcoming these challenges.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 01:50:15 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hata", "Hideaki", ""], ["Guo", "Jin L. C.", ""], ["Kula", "Raula Gaikovina", ""], ["Treude", "Christoph", ""]]}, {"id": "2104.06432", "submitter": "Juli\\'an D. Cort\\'es", "authors": "Julian D. Cortes", "title": "Research on innovation in China and Latin America: Bibliometric insights\n  in the field of business, management and decision sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  China and Latin America (LATAM) are now key players in global research\nproduction. This study presents a comparative study on research on innovation\nin management and decision sciences based on data from Scopus and Web of\nKnowledge (WoS) between China and LATAM. Findings showed significant\ndifferences between regions regarding journals citation dependent measures, and\nbetween the number of authors and journal reputation, public universities have\nbeen leading producers, and China showed a particular interest in research\ntopics such as commerce and industry, while LATAM in sustainable development\nand bio-technology.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:16:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cortes", "Julian D.", ""]]}, {"id": "2104.06437", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes, Xiaolei Lin, Xiaolei Xun", "title": "Research on innovation in business and management about China and Latin\n  America: bibliometrics insights using Google Scholar, Dimensions and\n  Microsoft Academic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Trade and investment between developing regions such as China and Latin\nAmerica (LATAM) are growing prominently. However, insights on crucial factors\nsuch as innovation in business and management (iBM) about both regions have not\nbeen scrutinized. This study presents the research output, impact, and\nstructure of iBM research published about China and LATAM in a comparative\nframework using Google Scholar, Dimensions, and Microsoft Academic. Findings\nshowed i) that iBM topics of both regions were framed within research and\ndevelopment management, and technological development topics, ii) significant\ndifferences in output and impact between regions, and iii) the same case for\nplatforms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:23:12 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cortes", "Julian D.", ""], ["Lin", "Xiaolei", ""], ["Xun", "Xiaolei", ""]]}, {"id": "2104.06440", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes", "title": "Research on Innovation in China and Latin America: bibliometric insights\n  in business, management, accounting, and decision sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study aims to comprehend the structure of RIBM (research on innovation\nin business and management) in China and LAC (Latin America and the Caribbean)\nvia co-word and institutional co-authorship networks using Scopus'\nbibliographic data (1998- 2018). Multiple Correspondence Analysis and Social\nNetwork Analysis were applied. Public institutions are interconnected and\ngenerate most of the advances in RIBM. RIBM boards regional and national STi\npolicies permeated by sustainability-related factors. China is focused on IT\nand knowledge management for supply chain and engineering, while LAC focuses on\ninstitutional perspectives for economic development.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:29:15 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cortes", "Julian D.", ""]]}, {"id": "2104.06454", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes", "title": "Journals Titles and Mission Statements: Lexical structure, diversity and\n  readability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is an established research agenda on dissecting an articles components,\ntitle and abstract readability and diversity, keywords, number references, and\ndetermining their association with bibliometrics performance. Yet, journals\ntitles and their overview, aim and scope (i.e., journals mission statement,\nJMS(s) have not been investigated with the same diligence. This study aims to\nconduct a comprehensive outlook of titles and JMSs lexical structure and\nidentify significant differences between journals prestige and type of access\ngroups and their JMS content in the field of business, management and\naccounting (BMA). Lexical network analysis was used to explore journals title\nstructure. JMS were examined through the Flesch-Kincaid grade level for\nreadability and the Yules K for lexical diversity. Titles and JMS structural\nanalysis reflected current and critical discussion in BMA: an obsession for\ncounterintuitive findings and ICT tools. JMS expressed mostly target customers\nand markets. JMS from reputable journals showed a higher betweenness for key\nterms related to rigorous features, while JMS of lower reputable journals\nhighlighted indexing attributes (i.e., Scopus). Wilcoxon rank sum and Kruskal\nWallis tests showed significant differences in the JMS median diversity\nregarding the journals type of access and best quartiles.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:54:53 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cortes", "Julian D.", ""]]}, {"id": "2104.06495", "submitter": "Silvia Columbu", "authors": "Beniamino Cappelletti-Montano and Silvia Columbu and Stefano Montaldo\n  and Monica Musio", "title": "Interpreting the outcomes of research assessments: a geometrical\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research evaluations and comparison of the assessments of academic\ninstitutions (scientific areas, departments, universities etc.) are among the\nmajor issues in recent years in higher education systems. One method, followed\nby some national evaluation agencies, is to assess the research quality by the\nevaluation of a limited number of publications in a way that each publication\nis rated among $n$ classes. This method produces, for each institution, a\ndistribution of the publications in the $n$ classes. In this paper we introduce\na natural geometric way to compare these assessments by introducing an ad hoc\ndistance from the performance of an institution to the best possible achievable\nassessment. Moreover, to avoid the methodological error of comparing\nnon-homogeneous institutions, we introduce a {\\em geometric score} based on\nsuch a distance. The latter represents the probability that an ideal\ninstitution, with the same configuration as the one under evaluation, performs\nworst. We apply our method, based on the geometric score, to rank, in two\nspecific scientific areas, the Italian universities using the results of the\nevaluation exercise VQR 2011-2014.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:43:14 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cappelletti-Montano", "Beniamino", ""], ["Columbu", "Silvia", ""], ["Montaldo", "Stefano", ""], ["Musio", "Monica", ""]]}, {"id": "2104.06844", "submitter": "Eric Jeangirard", "authors": "Eric Jeangirard", "title": "Monitoring Open Access at a national level: French case study", "comments": null, "journal-ref": "ELPUB 2019 23rd edition of the International Conference on\n  Electronic Publishing, Jun 2019, Marseille, France", "doi": "10.4000/proceedings.elpub.2019.20", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After the launch of multiple plans for Open Science, there is now a need for\nan accurate method or tool to monitor the Open Science trends and in particular\nOpen Access (OA) trends. We address this requirement with a methodology that we\ndeveloped and tested for France, but that could be extended to other countries.\nOnly open data and information available on the Web are used, leveraging as\nmuch as we can large-scale systems such as Unpaywall, HAL (the main open\nrepository in France, part of the CNRS), ORCID and IDRef (referential for\nFrench Higher Education and Research). We used rule-based and machine learning\ntechniques to enrich the metadata of the publications. We estimate that the\noverall OA rate for French affiliated publications ranges from 39% to 42%\nbetween 2013 and 2017. The trend is slightly up, except for the last year, but\nwe gather evidence that shows this is a consequence of the moving nature of the\nOA status. Therefore these figures should be seen as a snapshot rather than\ndefinitive. For the last observed year (2017), we show that the OA rate varies\naccording to the publication type, the publisher and the discipline (more than\n60% in Mathematics while it is about 30% in Medical research which represents\nthe largest share in the number of publications). We describe the main\nchallenges of our method (detection of the publications with a French\naffiliation, metadata enrichment with machine learning, open access status) and\nevaluate the errors of each step. Most of the method is not country-specific\nand could be applied for another perimeter. Our implementation is open sourced\non the repository https://github.com/MinistereSupRecherche/bso .\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 13:23:55 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Jeangirard", "Eric", ""]]}, {"id": "2104.07345", "submitter": "Jamal Al Qundus", "authors": "Jamal Al Qundus, Ralph Sch\\\"afermeier, Naouel Karam, Silvio Peikert,\n  Adrian Paschke", "title": "ROC: An Ontology for Country Responses towards COVID-19", "comments": "10 pages, 3 figures", "journal-ref": "Qurator2021 - Conference on Digital Curation Technologies", "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ROC ontology for country responses to COVID-19 provides a model for\ncollecting, linking and sharing data on the COVID-19 pandemic. It follows\nsemantic standardization (W3C standards RDF, OWL, SPARQL) for the\nrepresentation of concepts and creation of vocabularies. ROC focuses on country\nmeasures and enables the integration of data from heterogeneous data sources.\nThe proposed ontology is intended to facilitate statistical analysis to study\nand evaluate the effectiveness and side effects of government responses to\nCOVID-19 in different countries. The ontology contains data collected by OxCGRT\nfrom publicly available information. This data has been compiled from\ninformation provided by ECDC for most countries, as well as from various\nrepositories used to collect data on COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:12:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Qundus", "Jamal Al", ""], ["Sch\u00e4fermeier", "Ralph", ""], ["Karam", "Naouel", ""], ["Peikert", "Silvio", ""], ["Paschke", "Adrian", ""]]}, {"id": "2104.07543", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes, Mireia Guix, Katerina Bohle Carbonell", "title": "Innovation for Sustainability in the Global South: Bibliometric findings\n  from management & business and STEM (Science, Technology, Engineering and\n  Mathematics) fields in developing countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Research on innovation and sustainability is prolific but fragmented. This\nstudy integrates the research on innovation in management and business and STEM\nfields for sustainability in a unified framework for the case of developing\ncountries (i.e., the Global South). It presents and discusses the output,\nimpact, and structure of such research based on a sample of 14,000+ articles\nand conference proceedings extracted from the bibliographic database Scopus.\nThe findings reveal research output inflections after global announcements such\nas UN-Earth Summits. The study also reveals the indisputable leadership of\nChina in overall output and research agenda-setting. Nonetheless, countries\nsuch as India, Mexico, and Nigeria are either more efficient or impactful. GS\nresearch published in highly reputable journals is still scarce but increasing\nmodestly. Central topic clusters (e.g., knowledge management) remain peripheral\nto the global Sustainable Development Goals (SDGs) research landscape. Finally,\nacademic-corporate collaboration is in its infancy and limited to particular\neconomic sectors: energy, pharmaceuticals, and high-tech.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:48:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Cortes", "Julian D.", ""], ["Guix", "Mireia", ""], ["Carbonell", "Katerina Bohle", ""]]}, {"id": "2104.08087", "submitter": "Domenic Rosati", "authors": "Domenic Rosati", "title": "Citations are not opinions: a corpus linguistics approach to\n  understanding how citations are made", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Citation content analysis seeks to understand citations based on the language\nused during the making of a citation. A key issue in citation content analysis\nis looking for linguistic structures that characterize distinct classes of\ncitations for the purposes of understanding the intent and function of a\ncitation. Previous works have focused on modeling linguistic features first and\ndrawn conclusions on the language structures unique to each class of citation\nfunction based on the performance of a classification task or inter-annotator\nagreement. In this study, we start with a large sample of a pre-classified\ncitation corpus, 2 million citations from each class of the scite Smart\nCitation dataset (supporting, disputing, and mentioning citations), and analyze\nits corpus linguistics in order to reveal the unique and statistically\nsignificant language structures belonging to each type of citation. By\ngenerating comparison tables for each citation type we present a number of\ninteresting linguistic features that uniquely characterize citation type. What\nwe find is that within citation collocates, there is very low correlation\nbetween citation type and sentiment. Additionally, we find that the\nsubjectivity of citation collocates across classes is very low. These findings\nsuggest that the sentiment of collocates is not a predictor of citation\nfunction and that due to their low subjectivity, an opinion-expressing mode of\nunderstanding citations, implicit in previous citation sentiment analysis\nliterature, is inappropriate. Instead, we suggest that citations can be better\nunderstood as claims-making devices where the citation type can be explained by\nunderstanding how two claims are being compared. By presenting this approach,\nwe hope to inspire similar corpus linguistic studies on citations that derive a\nmore robust theory of citation from an empirical basis using citation corpora\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 12:52:27 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Rosati", "Domenic", ""]]}, {"id": "2104.08158", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes, Diego Garcia, Edgar Rodriguez, Diana Pineda", "title": "Governance for Security, Risks, Competition and Cooperation: Mapping the\n  knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The study aims to generate a map of the knowledge based on the research on\ntopics related to governance and security, risks, competition and cooperation\nfor the FDDI (Fudan Development Institute) proceedings publishing project:\n'Reflections on Governance: Security and Risks, Competition and Cooperation.'\nThat mapping exercise would enable a broader audience to delve into the current\nstate, and interdisciplinary pathways of the research published worldwide for\naddressing complex problems of governance. Following this introduction, the\nsecond section presents the bibliometric methods used and the results'\ninterpretation. The third section presents the results, followed by the fourth\nand fifth sections of discussion and conclusion, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:42:33 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Cortes", "Julian D.", ""], ["Garcia", "Diego", ""], ["Rodriguez", "Edgar", ""], ["Pineda", "Diana", ""]]}, {"id": "2104.08359", "submitter": "Owen Lockwood", "authors": "Owen Lockwood", "title": "In Defense of the Paper", "comments": "Accepted (oral) to Rethinking ML Papers - ICLR 2021 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The machine learning publication process is broken, of that there can be no\ndoubt. Many of these flaws are attributed to the current workflow: LaTeX to PDF\nto reviewers to camera ready PDF. This has understandably resulted in the\ndesire for new forms of publications; ones that can increase inclusively,\naccessibility and pedagogical strength. However, this venture fails to address\nthe origins of these inadequacies in the contemporary paper workflow. The\npaper, being the basic unit of academic research, is merely how problems in the\npublication and research ecosystem manifest; but is not itself responsible for\nthem. Not only will simply replacing or augmenting papers with different\nformats not fix existing problems; when used as a band-aid without systemic\nchanges, will likely exacerbate the existing inequities. In this work, we argue\nthat the root cause of hindrances in the accessibility of machine learning\nresearch lies not in the paper workflow but within the misaligned incentives\nbehind the publishing and research processes. We discuss these problems and\nargue that the paper is the optimal workflow. We also highlight some potential\nsolutions for the incentivization problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 20:26:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lockwood", "Owen", ""]]}, {"id": "2104.09018", "submitter": "Alexander Lerch", "authors": "Alexander Lerch, Claire Arthur, Ashis Pati, Siddharth Gururani", "title": "An Interdisciplinary Review of Music Performance Analysis", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.00178", "journal-ref": "Transactions of the International Society for Music Information\n  Retrieval, 3(1), pp.221-245, 2020", "doi": "10.5334/tismir.53", "report-no": null, "categories": "cs.SD cs.DL eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A musical performance renders an acoustic realization of a musical score or\nother representation of a composition. Different performances of the same\ncomposition may vary in terms of performance parameters such as timing or\ndynamics, and these variations may have a major impact on how a listener\nperceives the music. The analysis of music performance has traditionally been a\nperipheral topic for the MIR research community, where often a single audio\nrecording is used as representative of a musical work. This paper surveys the\nfield of Music Performance Analysis (MPA) from several perspectives including\nthe measurement of performance parameters, the relation of those parameters to\nthe actions and intentions of a performer or perceptual effects on a listener,\nand finally the assessment of musical performance. This paper also discusses\nMPA as it relates to MIR, pointing out opportunities for collaboration and\nfuture research in both areas.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 02:21:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lerch", "Alexander", ""], ["Arthur", "Claire", ""], ["Pati", "Ashis", ""], ["Gururani", "Siddharth", ""]]}, {"id": "2104.09138", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall", "title": "Cures, Treatments and Vaccines for Covid-19: International differences\n  in interest on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the Covid-19 pandemic is a global threat to health that few can fully\nescape, it has given a unique opportunity to study international reactions to a\ncommon problem. Such reactions can be partly obtained from public posts to\nTwitter, allowing investigations of changes in interest over time. This study\nanalysed English-language Covid-19 tweets mentioning cures, treatments, or\nvaccines from 1 January 2020 to 8 April 2021, seeking trends and international\ndifferences. The results have methodological limitations but show a tendency\nfor countries with a lower human development index score to tweet more about\ncures, although they were a minor topic for all countries. Vaccines were\ndiscussed about as much as treatments until July 2020, when they generated more\ninterest because of developments in Russia. The November 2020 Pfizer-BioNTech\npreliminary Phase 3 trials results generated an immediate and sustained sharp\nincrease, however, followed by a continuing roughly linear increase in interest\nfor vaccines until at least April 2021. Against this background, national\ndeviations from the average were triggered by country-specific news about\ncures, treatments or vaccines. Nevertheless, interest in vaccines in all\ncountries increased in parallel to some extent, despite substantial\ninternational differences in national regulatory approval and availability. The\nresults also highlight that unsubstantiated claims about alternative medicine\nremedies gained traction in several countries, apparently posing a threat to\npublic health.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:54:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Thelwall", "Mike", ""]]}, {"id": "2104.09471", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes", "title": "Dissension or consensus? Management and Business Research in Latin\n  America and the Caribbean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study presents longitudinal evidence on the dissension of Management and\nBusiness Research (MBR) in Latin America and the Caribbean (LAC). It looks\nafter intellectual bridges linking clusters among such dissension. It was\nimplemented a coword network analysis to a sample of 12,000+ articles published\nby authors from LAC during 1998-2017. Structural network scores showed an\nincreasing number of keywords and mean degree but decreasing modularity and\ndensity. The intellectual bridges were those of the cluster formed by\ndisciplines/fields that tend toward consensus (e.g., mathematical models) and\nnot by core MBR subjects (e.g., strategic planning).\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:33:45 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Cortes", "Julian D.", ""]]}, {"id": "2104.09484", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes, Zaida Chinchilla-Rodriguez, Katerina Bohle-Karbonell", "title": "Science Mapping to study academic knowledge circulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The application of mathematics and statistical methods to scholarly\ncommunication: scientometrics, has facilitated the systematic analysis of the\nmodern digital tide of literature. This chapter reviews three of such\napplications: coauthorship, bibliographic coupling, and coword networks. It\nalso presents an exploratory case of study for the knowledge circulation\nliterature. It was found a diverse geographical production, mainly in the\nGlobal North and Asian institutions with significant intermediation of\nuniversities from USA, Colombia, and Japan. The research fronts identified were\nrelated to science and medicine's history and philosophy; education, health,\npolicy studies; and a set of interdisciplinary topics. Finally, the knowledge\npillars were comprised of urban planning policy, economic geography, and\nhistorical and theoretical perspectives in the Netherlands and Central Europe;\nglobalization and science, technology, and innovation and historical and\ninstitutional frameworks in the UK; and cultural and learning studies in the\nXXI century.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:43:39 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 12:36:03 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Cortes", "Julian D.", ""], ["Chinchilla-Rodriguez", "Zaida", ""], ["Bohle-Karbonell", "Katerina", ""]]}, {"id": "2104.09617", "submitter": "Javier de la Rosa", "authors": "Per E Kummervold, Javier de la Rosa, Freddy Wetjen, Svein Arne\n  Brygfjeld", "title": "Operationalizing a National Digital Library: The Case for a Norwegian\n  Transformer Model", "comments": "Accepted to NoDaLiDa 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we show the process of building a large-scale training set from\ndigital and digitized collections at a national library. The resulting\nBidirectional Encoder Representations from Transformers (BERT)-based language\nmodel for Norwegian outperforms multilingual BERT (mBERT) models in several\ntoken and sequence classification tasks for both Norwegian Bokm{\\aa}l and\nNorwegian Nynorsk. Our model also improves the mBERT performance for other\nlanguages present in the corpus such as English, Swedish, and Danish. For\nlanguages not included in the corpus, the weights degrade moderately while\nkeeping strong multilingual properties. Therefore, we show that building\nhigh-quality models within a memory institution using somewhat noisy optical\ncharacter recognition (OCR) content is feasible, and we hope to pave the way\nfor other memory institutions to follow.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 20:36:24 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Kummervold", "Per E", ""], ["de la Rosa", "Javier", ""], ["Wetjen", "Freddy", ""], ["Brygfjeld", "Svein Arne", ""]]}, {"id": "2104.09622", "submitter": "Arturo Sanchez Pineda", "authors": "Arturo S\\'anchez Pineda", "title": "A proposal for Transversal Computer-related Strategies & Services for\n  Scientific and Training efforts for the LASF4RI", "comments": "The LASF4RI is calling for inputs on the next steps regarding the\n  coordination of resources for large scientific infrastructures among\n  countries in Latin America (https://lasf4ri.org)", "journal-ref": null, "doi": "10.5281/zenodo.3614109", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This schematic proposal is looking to give a first view of the different and\nvital services, protocols, tools and know-how relative to the Scientific\nComputing (SC) and Information Technology (IT) for scientific endeavours and\ncapacity-building projects in the Latin America region. The proposal of\ntransversal services and protocols for the design, development, deployment,\ndistribution, training, publication and citation, proper accreditation and\ndissemination of scientific experiments, data, processes, software,\ndocumentation, results and resources using world-leading protocols and\nindustrial standards under the Open Access philosophy is presented. It shows a\ndedicated review of scenarios and proposals that can be seen under the umbrella\nof a \"SC+IT Hub\". It also gives effective usage of current hybrid spaces\n(physical and virtual) that contains very well known industrial and academic\nresources and practical ideas and how to deploy those for current *diverse* and\nfuture experiments and research teams in the region.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 21:40:34 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Pineda", "Arturo S\u00e1nchez", ""]]}, {"id": "2104.09647", "submitter": "Alexander Spangher", "authors": "Alexander Spangher and Jonathan May", "title": "\\textit{NewsEdits}: A Dataset of Revision Histories for News Articles\n  (Technical Report: Data Processing)", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  News article revision histories have the potential to give us novel insights\nacross varied fields of linguistics and social sciences. In this work, we\npresent, to our knowledge, the first publicly available dataset of news article\nrevision histories, or \\textit{NewsEdits}.\n  Our dataset is multilingual; it contains 1,278,804 articles with 4,609,430\nversions from over 22 English- and French-language newspaper sources based in\nthree countries. Across version pairs, we count 10.9 million added sentences;\n8.9 million changed sentences and 6.8 million removed sentences. Within the\nchanged sentences, we derive 72 million atomic edits. \\textit{NewsEdits} is, to\nour knowledge, the largest corpus of revision histories of any domain.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 21:15:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Spangher", "Alexander", ""], ["May", "Jonathan", ""]]}, {"id": "2104.10263", "submitter": "Alexander Spangher", "authors": "Alexander Spangher and Jonathan May", "title": "\\textit{StateCensusLaws.org}: A Web Application for Consuming and\n  Annotating Legal Discourse Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we create a web application to highlight the output of NLP\nmodels trained to parse and label discourse segments in law text. Our system is\nbuilt primarily with journalists and legal interpreters in mind, and we focus\non state-level law that uses U.S. Census population numbers to allocate\nresources and organize government.\n  Our system exposes a corpus we collect of 6,000 state-level laws that pertain\nto the U.S. census, using 25 scrapers we built to crawl state law websites,\nwhich we release. We also build a novel, flexible annotation framework that can\nhandle span-tagging and relation tagging on an arbitrary input text document\nand be embedded simply into any webpage. This framework allows journalists and\nresearchers to add to our annotation database by correcting and tagging new\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 22:00:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Spangher", "Alexander", ""], ["May", "Jonathan", ""]]}, {"id": "2104.10279", "submitter": "Felber Arroyave", "authors": "Felber Arroyave, Oscar Yandy Romero Goyeneche, Meredith Gore, Gaston\n  Heimeriks, Jeffrey Jenkins, Alexander Petersen", "title": "On the social and cognitive dimensions of wicked environmental problems\n  characterized by conceptual and solution uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a quantitative framework for understanding the class of wicked\nproblems that emerge at the intersections of natural, social, and technological\ncomplex systems. Wicked problems reflect our incomplete understanding of\ninterdependent global systems and the hyper-risk they pose; such problems\nescape solutions because they are often ill-defined and thus mis-identified and\nunder-appreciated by problem-solvers and the communities they constitute.\nBecause cross-boundary problems can be dissected from various viewpoints, such\ndiversity can nevertheless contribute confusion to the collective understanding\nof the problem. We illustrate this paradox by analyzing the development of both\ntopical and scholarly communities within three wicked domains: deforestation,\ninvasive species, and wildlife trade research. Informed by comprehensive\nbibliometric analysis of both topical and collaboration communities emerging\nwithin and around each domain, we identify symptomatic characteristics of\nwicked uncertainty based upon quantitative assessment of consolidation or\ndiversification of knowledge trajectories representing each domain. We argue\nthat such knowledge trajectories are indicative of the underlying uncertainties\nof each research domain, which tend to exacerbate the wickedness of the problem\nitself. Notably, our results indicate that wildlife trade may become a\nneglected wicked problem due to high uncertainty, research paucity, and delayed\nknowledge consolidation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 22:49:32 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Arroyave", "Felber", ""], ["Goyeneche", "Oscar Yandy Romero", ""], ["Gore", "Meredith", ""], ["Heimeriks", "Gaston", ""], ["Jenkins", "Jeffrey", ""], ["Petersen", "Alexander", ""]]}, {"id": "2104.10996", "submitter": "Lukun Zheng", "authors": "Lukun Zheng, Yuhang Jiang", "title": "Combining dissimilarity measure for the study of evolution in scientific\n  fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of scientific fields has been attracting much attention in\nrecent years. One of the key issues in evolution of scientific field is to\nquantify the dissimilarity between two collections of scientific publications\nin literature. Many existing works study the evolution based on one or two\ndissimilarity measures, despite the fact that there are many different\ndissimilarity measures. Finding the appropriate dissimilarity measures among\nsuch a collection of choices is of fundamental importance to the study of\nscientific evolution. In this article, we develop a new measure of the\nevolution combining twelve keyword-based temporal dissimilarities of the\nscientific fields using the method of principal component analysis. To\ndemonstrate the usage of this new measure, we chose four scientific fields:\nenvironmental studies, information science & library science, mechanical\ninformatics, and religion. A database consisting of 274453 bibliographic\nrecords in these four chosen fields from 1991 to 2019 are built. The results\nshow that all these four scientific fields share an overall decreasing trend in\nevolution from 1991 to 2019 and different fields exhibits different evolution\npatterns during different time periods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:34:31 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zheng", "Lukun", ""], ["Jiang", "Yuhang", ""]]}, {"id": "2104.11943", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Tamara Nevill", "title": "Is research with qualitative data more prevalent and impactful now?\n  Interviews, case studies, focus groups and ethnographies", "comments": "This is a preprint before refereeing of an accepted paper to appear\n  in Library and Information Science Research. The data and figures and main\n  findings are identical in the final version after refereeing. Library &\n  Information Science Research (2021)", "journal-ref": null, "doi": "10.1016/j.lisr.2021.101094", "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers, editors, educators and publishers need to understand the mix of\nresearch methods used in their field to guide decision making, with a current\nconcern being that qualitative research is threatened by big data. Although\nthere have been many studies of the prevalence of different methods within\nindividual narrow fields, there have been no systematic studies across\nacademia. In response, this article assesses the prevalence and citation impact\nof academic research 1996-2019 that reports one of four common methods to\ngather qualitative data: interviews; focus groups; case studies; ethnography.\nThe results show that, with minor exceptions, the prevalence of qualitative\ndata has increased, often substantially, since 1996. In addition, all 27 broad\nfields (as classified by Scopus) now publish some qualitative research, with\ninterviewing being by far the most common approach. This suggest that\nqualitative methods teaching and should increase, and researchers, editors and\npublishers should be increasingly open to the value that qualitative data can\nbring.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 12:44:49 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Thelwall", "Mike", ""], ["Nevill", "Tamara", ""]]}, {"id": "2104.12380", "submitter": "Samin Aref", "authors": "Xinyi Zhao, Samin Aref, Emilio Zagheni, and Guy Stecklov", "title": "International Migration in Academia and Citation Performance: An\n  Analysis of German-Affiliated Researchers by Gender and Discipline Using\n  Scopus Publications 1996-2020", "comments": "12 pages; peer-reviewed and accepted author-copy; to appear in the\n  Proceedings of the 18th International Conference on Scientometrics and\n  Informetrics (ISSI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Germany has become a major country of immigration, as well as a research\npowerhouse in Europe. As Germany spends a higher fraction of its GDP on\nresearch and development than most countries with advanced economies, there is\nan expectation that Germany should be able to attract and retain international\nscholars who have high citation performance. Using an exhaustive set of over\neight million Scopus publications, we analyze the trends in international\nmigration to and from Germany among published researchers over the past 24\nyears. We assess changes in institutional affiliations for over one million\nresearchers who have published with a German affiliation address at some point\nduring the 1996-2020 period. We show that while Germany has been highly\nintegrated into the global movement of researchers, with particularly strong\nties to the US, the UK, and Switzerland, the country has been sending more\npublished researchers abroad than it has attracted. While the balance has been\nlargely negative over time, analyses disaggregated by gender, citation\nperformance, and field of research show that compositional differences in\nmigrant flows may help to alleviate persistent gender inequalities in selected\nfields.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 07:37:02 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 04:14:30 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhao", "Xinyi", ""], ["Aref", "Samin", ""], ["Zagheni", "Emilio", ""], ["Stecklov", "Guy", ""]]}, {"id": "2104.12548", "submitter": "Ren\\'e Zandbergen", "authors": "Ren\\'e Zandbergen", "title": "The Cardan grille approach to the Voynich MS taken to the next level", "comments": "17 pages, 7 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Voynich MS is an illustrated 15th century manuscript, whose text is\nwritten in an unknown alphabet, which has not been translated until today. In\n2004 Gordon Rugg published a paper in which he proposed that this text is\nlikely to be meaningless, and could have been composed by an alternative\napplication of a so-called Cardan Grille, namely by moving a piece of cardboard\nwith holes over a large table of word fragments, and writing down the words\nthat thus appear. This paper caused considerable discussion in the circles of\npeople interested in the Voynich MS text, but it has not found many followers,\neven until today. The present paper takes a closer look at the mechanics of\nthis method. Based on this, a more generic method is proposed, which is\nconsiderably simpler, both to set up and to execute. It is shown that the\nunusual word length distribution of the Voynich MS, which is very close to\nbinomial, could be a consequence of the application of such a method.\nFurthermore, it is argued that this method could not only be used to create\nmeaningless text, but also to encode meaningful text. A first high-level\nanalysis looks at whether such a method could indeed have been applied to\ncreate the Voynich MS text, but this is certainly far from conclusive. The main\naim of this paper is to inspire further research of the Voynich MS text into a\nnew direction that has not yet been explored in great detail.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 06:32:15 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zandbergen", "Ren\u00e9", ""]]}, {"id": "2104.12589", "submitter": "Jurian Baas", "authors": "Jurian Baas, Mehdi Dastani, Ad Feelders", "title": "Exploiting Transitivity Constraints for Entity Matching in Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The goal of entity matching in knowledge graphs is to identify entities that\nrefer to the same real-world objects using some similarity metric. The result\nof entity matching can be seen as a set of entity pairs interpreted as the\nsame-as relation. However, the identified set of pairs may fail to satisfy some\nstructural properties, in particular transitivity, that are expected from the\nsame-as relation. In this work, we show that an ad-hoc enforcement of\ntransitivity, i.e. taking the transitive closure, on the identified set of\nentity pairs may decrease precision dramatically. We therefore propose a\nmethodology that starts with a given similarity measure, generates a set of\nentity pairs that are identified as referring to the same real-world objects,\nand applies the cluster editing algorithm to enforce transitivity without\nadding many spurious links, leading to overall improved performance.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:57:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Baas", "Jurian", ""], ["Dastani", "Mehdi", ""], ["Feelders", "Ad", ""]]}, {"id": "2104.12838", "submitter": "S. B. F. Dorch", "authors": "O. Ellegaard and S. B. F. Dorch", "title": "The uniqueness of observatory publications", "comments": "4 pages, 2 figures, 2 tables, to appear in proceedings of IAU\n  Symposium 367, Education and Heritage in the Era of Big Data in Astronomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Observatory publications comprise the work of local astronomers from\nobservatories around the world and are traditionally exchanged between\nobservatories through libraries. However, large collections of observatory\npublications seem to be rare; or at the least rarely digitally described or\naccessible on the Internet. Notable examples to the contrary are the Woodman\nAstronomical Library at Wisconsin-Madison and the Dudley Observatory in\nLoudonville, New York both in the US. Due to the irregularities in receiving\nmaterial, the collections are generally often incomplete both with respect to\nthe observatories included as well as volumes. In order to assess the unique\nproperties of the collections, we summarize and compare observatories present\nin our own as well as the collections from the Woodman Library and the Dudley\nObservatory.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:27:12 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Ellegaard", "O.", ""], ["Dorch", "S. B. F.", ""]]}, {"id": "2104.13091", "submitter": "Ye Sun", "authors": "Ye Sun, Giacomo Livan, Athen Ma and Vito Latora", "title": "Interdisciplinary researchers attain better performance in funding", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interdisciplinary research is fundamental when it comes to tackling complex\nproblems in our highly interlinked world, and is on the rise globally. Yet, it\nis unclear why--in an increasingly competitive academic environment--one should\npursue an interdisciplinary career given its recent negative press. Several\nstudies have indeed shown that interdisciplinary research often achieves lower\nimpact compared to more specialized work, and is less likely to attract\nfunding. We seek to reconcile such evidence by analyzing a dataset of 44,419\nresearch grants awarded between 2006 and 2018 from the seven national research\ncouncils in the UK. We compared the research performance of researchers with an\ninterdisciplinary funding track record with those who have a specialized\nprofile. We found that the former dominates the network of academic\ncollaborations, both in terms of centrality and knowledge brokerage; but such a\ncompetitive advantage does not immediately translate into impact. Indeed, by\nmeans of a matched pair experimental design, we found that researchers who\ntranscend between disciplines on average achieve lower impacts in their\npublications than the subject specialists in the short run, but eventually\noutperform them in funding performance, both in terms of volume and value. Our\nresults suggest that launching an interdisciplinary career may require more\ntime and persistence to overcome extra challenges, but can pave the way for a\nmore successful endeavour.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 10:29:33 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sun", "Ye", ""], ["Livan", "Giacomo", ""], ["Ma", "Athen", ""], ["Latora", "Vito", ""]]}, {"id": "2104.13361", "submitter": "Abigail Mabe", "authors": "Abigail Mabe", "title": "A Chromium-based Memento-aware Web Browser", "comments": "33 pages, 38 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Web browsers provide a user-friendly means of navigating the web. Users rely\non their web browser to provide information about the websites they are\nvisiting, such as the security state. Browsers also provide a user interface\n(UI) with visual cues about each tab that is open, including icons for if the\ntab is playing audio or requires authentication to view. However, current\nbrowsers do not differentiate between the live web and the past web. If a user\nloads an archived webpage, known as a memento, they have to rely on UI elements\npresent within the page itself to inform them that the page they are viewing is\nnot the live web. Additionally, memento-awareness extends beyond recognizing a\npage that has already been archived. The browser should give users the ability\nto archive live webpages, essentially creating mementos of webpages they found\nimportant as they surf the web. In this report, the process to create a\nproof-of-concept browser that is aware of mementos is presented. The browser is\ncreated by adding on to the implementation of the open source web browser by\nGoogle, Chromium. Creating this prototype for a Memento-aware Browser shows\nthat the features implemented fit well into the current Chromium\nimplementation. The user experience is enhanced by adding the\nmemento-awareness, and the changes to the Chromium code base are minimal.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:43:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Mabe", "Abigail", ""]]}, {"id": "2104.13508", "submitter": "Julian D. Cortes", "authors": "Julian D. Cortes", "title": "Top-tier and predatory alike? A lexical structure perspective from the\n  Academy of Management Journal and Espacios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study compares the lexical structure of articles titles and abstracts of\ntwo extremes in MB (management-business research): the AMJ (Academy of\nManagement Journal), one of its most revered periodicals, and Espacios, the one\nthat unveiled a structural problem in Latin-American MB. Results showed\nsignificant differences in the median of titles length and abstracts\nreadability and diversity as AMJ titles length was longer and abstracts both\nmore diverse and readability-demanding.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 23:48:13 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Cortes", "Julian D.", ""]]}, {"id": "2104.13939", "submitter": "Manolis Antonoyiannakis", "authors": "Manolis Antonoyiannakis", "title": "Does Publicity in the Science Press Drive Citations?", "comments": "2 pages, poster for ISSI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how publicity in the science press, in the form of highlighting,\naffects the citations of research papers. Using multiple linear regression, we\nquantify the citation advantage associated with several highlighting platforms\nfor papers published in Physical Review Letters (PRL) from 2008-2018. We thus\nfind that the strongest predictor of citation accrual is a Viewpoint in Physics\nmagazine, followed by a Research Highlight in Nature, an Editors' Suggestion in\nPRL, and a Research Highlight in Nature Physics. A similar hierarchical pattern\nis found when we search for extreme, not average, citation accrual, in the form\na paper being listed among the top-1% cited papers in physics by Clarivate\nAnalytics. The citation advantage of each highlighting platform is stratified\naccording to the degree of vetting for importance that the manuscript received\nduring peer review. This implies that we can view highlighting platforms as\npredictors of citation accrual, with varying degrees of strength that mirror\neach platform's vetting level.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 18:00:07 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Antonoyiannakis", "Manolis", ""]]}, {"id": "2104.14041", "submitter": "Dhruv Patel", "authors": "Dhruv Patel, Alexander C. Nwala, Michael L. Nelson, Michele C. Weigle", "title": "What Did It Look Like: A service for creating website timelapses using\n  the Memento framework", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Popular web pages are archived frequently, which makes it difficult to\nvisualize the progression of the site through the years at web archives. The\nWhat Did It Look Like (WDILL) Twitter bot shows web page transitions by\ncreating a timelapse of a given website using one archived copy from each\ncalendar year. Originally implemented in 2015, we recently added new features\nto WDILL, such as date range requests, diversified memento selection, updated\nvisualizations, and sharing visualizations to Instagram. This would allow\nscholars and the general public to explore the temporal nature of web archives.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 22:49:49 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Patel", "Dhruv", ""], ["Nwala", "Alexander C.", ""], ["Nelson", "Michael L.", ""], ["Weigle", "Michele C.", ""]]}, {"id": "2104.14114", "submitter": "Wumei Du", "authors": "Wumei Du, Zheng Xie, Yiqin Lv", "title": "Predicting publication productivity for authors: Shallow or deep\n  architecture?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Academic administrators and funding agencies must predict the publication\nproductivity of research groups and individuals to assess authors' abilities.\nHowever, such prediction remains an elusive task due to the randomness of\nindividual research and the diversity of authors' productivity patterns. We\napplied two kinds of approaches to this prediction task: deep neural network\nlearning and model-based approaches. We found that a neural network cannot give\na good long-term prediction for groups, while the model-based approaches cannot\nprovide short-term predictions for individuals. We proposed a model that\nintegrates the advantages of both data-driven and model-based approaches, and\nthe effectiveness of this method was validated by applying it to a high-quality\ndblp dataset, demonstrating that the proposed model outperforms the tested\ndata-driven and model-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:20:08 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Du", "Wumei", ""], ["Xie", "Zheng", ""], ["Lv", "Yiqin", ""]]}, {"id": "2104.14800", "submitter": "Eric Jeangirard", "authors": "Eric Jeangirard", "title": "Content-based subject classification at article level in biomedical\n  context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Subject classification is an important task to analyze scholarly\npublications. In general, mainly two kinds of approaches are used:\nclassification at a journal level and classification at the article level. We\npropose a mixed approach, leveraging on embeddings technique in NLP to train\nclassifiers with article metadata (title, abstract, keywords in particular)\nlabelled with the journal-level classification FoR (Fields of Research) and\nthen apply these classifiers at the article level. We use this approach in the\ncontext of biomedical publications using metadata from Pubmed. Fasttext\nclassifiers are trained with FoR codes and used to classify publications based\non their available metadata. Results show that using a stratification sampling\nstrategy for training help reduce the bias due to unbalanced field\ndistribution. An implementation of the method is proposed on the repository\nhttps://github.com/dataesr/scientific_tagger\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 07:36:07 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 12:41:59 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Jeangirard", "Eric", ""]]}, {"id": "2104.14815", "submitter": "Guy Marshall", "authors": "Guy Clarke Marshall and Caroline Jay and Andre Freitas", "title": "Number and quality of diagrams in scholarly publications is associated\n  with number of citations", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Diagrams are often used in scholarly communication. We analyse a corpus of\ndiagrams found in scholarly computational linguistics conference proceedings\n(ACL 2017), and find inclusion of a system diagram to be correlated with higher\nnumbers of citations after 3 years. Inclusion of over three diagrams in this\n8-page limit conference was found to correlate with a lower citation count.\nFocusing on neural network system diagrams, we find a correlation between\nhighly cited papers and \"good diagramming practice\" quantified by level of\ncompliance with a set of diagramming guidelines. Two diagram classification\ntypes (one visually based, one mental model based) were not found to correlate\nwith number of citations, but enabled quantification of heterogeneity in those\ndimensions. Exploring scholarly paper-writing guides, we find diagrams to be a\nneglected media. This study suggests that diagrams may be a useful source of\nquality data for predicting citations, and that \"graphicacy\" is a key skill for\nscholars with insufficient support at present.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:01:30 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Marshall", "Guy Clarke", ""], ["Jay", "Caroline", ""], ["Freitas", "Andre", ""]]}]