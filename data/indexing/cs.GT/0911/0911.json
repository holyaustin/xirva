[{"id": "0911.0257", "submitter": "Alonso Silva Allende", "authors": "Alonso Silva, Hamidou Tembine, Eitan Altman, Merouane Debbah", "title": "Spatial games and global optimization for mobile association problems", "comments": "Part of this work has been presented at the 49th IEEE Conference on\n  Decision and Control 2010. This work has been submitted to IEEE Transactions\n  on Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic optimal transportation problem consists in finding the most\neffective way of moving masses from one location to another, while minimizing\nthe transportation cost. Such concept has been found to be useful to understand\nvarious mathematical, economical, and control theory phenomena, such as\nWitsenhausen's counterexam-ple in stochastic control theory, principal-agent\nproblem in microeco- nomic theory, location and planning problems, etc. In this\nwork, we focus on mobile association problems: the determina-tion of the cells\ncorresponding to each base station, i.e., the locations at which intelligent\nmobile terminals prefer to connect to a given base station rather than to\nothers. This work combines game theory and optimal transport theory to\ncharacterize the solution based on fluid approximations. We characterize the\noptimal solution from both the global network and the mobile user points of\nview.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 08:54:56 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2011 11:33:23 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Silva", "Alonso", ""], ["Tembine", "Hamidou", ""], ["Altman", "Eitan", ""], ["Debbah", "Merouane", ""]]}, {"id": "0911.0874", "submitter": "Paul Cuff", "authors": "Paul Cuff (Princeton University)", "title": "State Information in Bayesian Games", "comments": "Presented at Allerton 2009, 6 pages, 5 eps figures, uses IEEEtran.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.GT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player zero-sum repeated games are well understood. Computing the value\nof such a game is straightforward. Additionally, if the payoffs are dependent\non a random state of the game known to one, both, or neither of the players,\nthe resulting value of the game has been analyzed under the framework of\nBayesian games. This investigation considers the optimal performance in a game\nwhen a helper is transmitting state information to one of the players.\n  Encoding information for an adversarial setting (game) requires a different\nresult than rate-distortion theory provides. Game theory has accentuated the\nimportance of randomization (mixed strategy), which does not find a significant\nrole in most communication modems and source coding codecs. Higher rates of\ncommunication, used in the right way, allow the message to include the\nnecessary random component useful in games.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2009 16:46:13 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Cuff", "Paul", "", "Princeton University"]]}, {"id": "0911.1021", "submitter": "Dimitris Kalles", "authors": "Dimitris Kalles, Ilias Fykouras", "title": "Examples as Interaction: On Humans Teaching a Computer to Play a Game", "comments": "15 pages, 1 figure, 13 tables, submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews an experiment in human-computer interaction, where\ninteraction takes place when humans attempt to teach a computer to play a\nstrategy board game. We show that while individually learned models can be\nshown to improve the playing performance of the computer, their straightforward\ncomposition results in diluting what was earlier learned. This observation\nsuggests that interaction cannot be easily distributed when one hopes to\nharness multiple human experts to develop a quality computer player. This is\nrelated to similar approaches in robot task learning and to classic approaches\nto human learning and reinforces the need to develop tools that facilitate the\nmix of human-based tuition and computer self-learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2009 12:58:46 GMT"}], "update_date": "2009-11-06", "authors_parsed": [["Kalles", "Dimitris", ""], ["Fykouras", "Ilias", ""]]}, {"id": "0911.1383", "submitter": "Marc Harper", "authors": "Marc Harper", "title": "Information Geometry and Evolutionary Game Theory", "comments": "Added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.GT math.DS math.IT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shahshahani geometry of evolutionary game theory is realized as the\ninformation geometry of the simplex, deriving from the Fisher information\nmetric of the manifold of categorical probability distributions. Some essential\nconcepts in evolutionary game theory are realized information-theoretically.\nResults are extended to the Lotka-Volterra equation and to multiple population\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 19:16:22 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["Harper", "Marc", ""]]}, {"id": "0911.1582", "submitter": "Toby Walsh", "authors": "Tyrel Russell and Toby Walsh", "title": "Manipulating Tournaments in Cup and Round Robin Competitions", "comments": "Proceedings of Algorithmic Decision Theory, First International\n  Conference, ADT 2009, Venice, Italy, October 20-23, 2009", "journal-ref": null, "doi": "10.1007/978-3-642-04428-1_3", "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sports competitions, teams can manipulate the result by, for instance,\nthrowing games. We show that we can decide how to manipulate round robin and\ncup competitions, two of the most popular types of sporting competitions in\npolynomial time. In addition, we show that finding the minimal number of games\nthat need to be thrown to manipulate the result can also be determined in\npolynomial time. Finally, we show that there are several different variations\nof standard cup competitions where manipulation remains polynomial.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 03:57:45 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Russell", "Tyrel", ""], ["Walsh", "Toby", ""]]}, {"id": "0911.1619", "submitter": "Paul D\\\"utting", "authors": "Paul D\\\"utting, Monika Henzinger and Ingmar Weber", "title": "On the Pricing of Recommendations and Recommending Strategically", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If you recommend a product to me and I buy it, how much should you be paid by\nthe seller? And if your sole interest is to maximize the amount paid to you by\nthe seller for a sequence of recommendations, how should you recommend\noptimally if I become more inclined to ignore you with each irrelevant\nrecommendation you make? Finding an answer to these questions is a key\nchallenge in all forms of marketing that rely on and explore social ties;\nranging from personal recommendations to viral marketing.\n  In the first part of this paper, we show that there can be no pricing\nmechanism that is \"truthful\" with respect to the seller, and we use solution\nconcepts from coalitional game theory, namely the Core, the Shapley Value, and\nthe Nash Bargaining Solution, to derive provably \"fair\" prices for settings\nwith one or multiple recommenders. We then investigate pricing mechanisms for\nthe setting where recommenders have different \"purchase arguments\". Here we\nshow that it might be beneficial for the recommenders to withhold some of their\narguments, unless anonymity-proof solution concepts, such as the\nanonymity-proof Shapley value, are used.\n  In the second part of this paper, we analyze the setting where the\nrecommendee loses trust in the recommender for each irrelevant recommendation.\nHere we prove that even if the recommendee regains her initial trust on each\nsuccessful recommendation, the expected total profit the recommender can make\nover an infinite period is bounded. This can only be overcome when the\nrecommendee also incrementally regains trust during periods without any\nrecommendation. Here, we see an interesting connection to \"banner blindness\",\nsuggesting that showing fewer ads can lead to a higher long-term profit.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 10:21:42 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["D\u00fctting", "Paul", ""], ["Henzinger", "Monika", ""], ["Weber", "Ingmar", ""]]}, {"id": "0911.1720", "submitter": "Carlos P. Roca", "authors": "Carlos P. Roca, Jos\\'e A. Cuesta and Angel S\\'anchez", "title": "Evolutionary game theory: Temporal and spatial effects beyond replicator\n  dynamics", "comments": "Review, 48 pages, 26 figures", "journal-ref": "Physics of Life Reviews 6, 208-249 (2009)", "doi": "10.1016/j.plrev.2009.08.001", "report-no": null, "categories": "q-bio.PE cs.GT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary game dynamics is one of the most fruitful frameworks for\nstudying evolution in different disciplines, from Biology to Economics. Within\nthis context, the approach of choice for many researchers is the so-called\nreplicator equation, that describes mathematically the idea that those\nindividuals performing better have more offspring and thus their frequency in\nthe population grows. While very many interesting results have been obtained\nwith this equation in the three decades elapsed since it was first proposed, it\nis important to realize the limits of its applicability. One particularly\nrelevant issue in this respect is that of non-mean-field effects, that may\narise from temporal fluctuations or from spatial correlations, both neglected\nin the replicator equation. This review discusses these temporal and spatial\neffects focusing on the non-trivial modifications they induce when compared to\nthe outcome of replicator dynamics. Alongside this question, the hypothesis of\nlinearity and its relation to the choice of the rule for strategy update is\nalso analyzed. The discussion is presented in terms of the emergence of\ncooperation, as one of the current key problems in Biology and in other\ndisciplines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 16:29:47 GMT"}], "update_date": "2009-11-14", "authors_parsed": [["Roca", "Carlos P.", ""], ["Cuesta", "Jos\u00e9 A.", ""], ["S\u00e1nchez", "Angel", ""]]}, {"id": "0911.1767", "submitter": "Yashodhan Kanoria", "authors": "Yashodhan Kanoria, Mohsen Bayati, Christian Borgs, Jennifer Chayes and\n  Andrea Montanari", "title": "A Natural Dynamics for Bargaining on Exchange Networks", "comments": "28 pages, 1 figure, second part of this work with different analysis\n  and stronger results available at arXiv:1004.2079v1 [cs.GT]. This paper\n  unchanged in update.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bargaining networks model the behavior of a set of players that need to reach\npairwise agreements for making profits. Nash bargaining solutions are special\noutcomes of such games that are both stable and balanced. Kleinberg and Tardos\nproved a sharp algorithmic characterization of such outcomes, but left open the\nproblem of how the actual bargaining process converges to them. A partial\nanswer was provided by Azar et al. who proposed a distributed algorithm for\nconstructing Nash bargaining solutions, but without polynomial bounds on its\nconvergence rate. In this paper, we introduce a simple and natural model for\nthis process, and study its convergence rate to Nash bargaining solutions. At\neach time step, each player proposes a deal to each of her neighbors. The\nproposal consists of a share of the potential profit in case of agreement. The\nshare is chosen to be balanced in Nash's sense as far as this is feasible (with\nrespect to the current best alternatives for both players). We prove that,\nwhenever the Nash bargaining solution is unique (and satisfies a positive gap\ncondition) this dynamics converges to it in polynomial time. Our analysis is\nbased on an approximate decoupling phenomenon between the dynamics on different\nsubstructures of the network. This approach may be of general interest for the\nanalysis of local algorithms on networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 00:37:35 GMT"}, {"version": "v2", "created": "Fri, 7 May 2010 18:59:43 GMT"}], "update_date": "2010-05-10", "authors_parsed": [["Kanoria", "Yashodhan", ""], ["Bayati", "Mohsen", ""], ["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Montanari", "Andrea", ""]]}, {"id": "0911.2033", "submitter": "EPTCS", "authors": "Tom\\'a\\v{s} Babiak, Vojt\\v{e}ch \\v{R}eh\\'ak, Jan Strej\\v{c}ek", "title": "Almost Linear B\\\"uchi Automata", "comments": null, "journal-ref": "EPTCS 8, 2009, pp. 16-25", "doi": "10.4204/EPTCS.8.2", "report-no": null, "categories": "cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new fragment of Linear temporal logic (LTL) called LIO and a\nnew class of Buechi automata (BA) called Almost linear Buechi automata (ALBA).\nWe provide effective translations between LIO and ALBA showing that the two\nformalisms are expressively equivalent. While standard translations of LTL into\nBA use some intermediate formalisms, the presented translation of LIO into ALBA\nis direct. As we expect applications of ALBA in model checking, we compare the\nexpressiveness of ALBA with other classes of Buechi automata studied in this\ncontext and we indicate possible applications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2009 00:48:28 GMT"}], "update_date": "2009-11-12", "authors_parsed": [["Babiak", "Tom\u00e1\u0161", ""], ["\u0158eh\u00e1k", "Vojt\u011bch", ""], ["Strej\u010dek", "Jan", ""]]}, {"id": "0911.3108", "submitter": "Emanuel Gluskin", "authors": "Emanuel Gluskin", "title": "On game psychology: an experiment on the chess board/screen, should you\n  always \"do your best\", and why the programs with prescribed weaknesses cannot\n  be our good friends?", "comments": "This is a somewhat contracted (compared to v1,2)version of my\n  original manuscript motivated by observation of a very unusual weakness of a\n  chess program that plays, generally, much stronger than I do, and by the wish\n  to consider chess not just as competition, also as a model for human\n  weaknesses. Some details of the experiment suggest a new version of the game.\n  5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is noted that some unusual moves against a strong chess program greatly\nweaken its ability to see the serious targets of the game, and its whole level\nof play... It is suggested to create programs with different weaknesses in\norder to analyze similar human behavior. Finally, a new version of chess,\n\"Chess Corrida\" is suggested.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 22:15:07 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2010 14:17:24 GMT"}, {"version": "v3", "created": "Fri, 28 Jan 2011 12:11:26 GMT"}], "update_date": "2011-01-31", "authors_parsed": [["Gluskin", "Emanuel", ""]]}, {"id": "0911.3162", "submitter": "Lance Fortnow", "authors": "Lance Fortnow and Rahul Santhanam", "title": "Bounding Rationality by Discounting Time", "comments": "To appear in Proceedings of The First Symposium on Innovations in\n  Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a game where Alice generates an integer and Bob wins if he can\nfactor that integer. Traditional game theory tells us that Bob will always win\nthis game even though in practice Alice will win given our usual assumptions\nabout the hardness of factoring.\n  We define a new notion of bounded rationality, where the payoffs of players\nare discounted by the computation time they take to produce their actions. We\nuse this notion to give a direct correspondence between the existence of\nequilibria where Alice has a winning strategy and the hardness of factoring.\nNamely, under a natural assumption on the discount rates, there is an\nequilibriumwhere Alice has a winning strategy iff there is a linear-time\nsamplable distribution with respect to which Factoring is hard on average.\n  We also give general results for discounted games over countable action\nspaces, including showing that any game with bounded and computable payoffs has\nan equilibrium in our model, even if each player is allowed a countable number\nof actions. It follows, for example, that the Largest Integer game has an\nequilibrium in our model though it has no Nash equilibria or epsilon-Nash\nequilibria.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 21:10:26 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Fortnow", "Lance", ""], ["Santhanam", "Rahul", ""]]}, {"id": "0911.3708", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Manipulability of Single Transferable Vote", "comments": "Proceedings of the CARE'09 International Workshop on Collaborative\n  Agents -- REsearch and Development, Melbourne 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many voting rules, it is NP-hard to compute a successful manipulation.\nHowever, NP-hardness only bounds the worst-case complexity. Recent theoretical\nresults suggest that manipulation may often be easy in practice. We study\nempirically the cost of manipulating the single transferable vote (STV) rule.\nThis was one of the first rules shown to be NP-hard to manipulate. It also\nappears to be one of the harder rules to manipulate since it involves multiple\nrounds and since, unlike many other rules, it is NP-hard for a single agent to\nmanipulate without weights on the votes or uncertainty about how the other\nagents have voted. In almost every election in our experiments, it was easy to\ncompute how a single agent could manipulate the election or to prove that\nmanipulation by a single agent was impossible. It remains an interesting open\nquestion if manipulation by a coalition of agents is hard to compute in\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 06:23:55 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "0911.4150", "submitter": "Rajgopal Kannan", "authors": "Rajgopal Kannan and Costas Busch", "title": "The Impact of Exponential Utility Costs in Bottleneck Routing Games", "comments": "AMS Latex 10 pages 2 Figures", "journal-ref": null, "doi": null, "report-no": "Louisiana State University Tech report LSU-CSC-09-01", "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study bottleneck routing games where the social cost is determined by the\nworst congestion on any edge in the network. Bottleneck games have been studied\nin the literature by having the player's utility costs to be determined by the\nworst congested edge in their paths. However, the Nash equilibria of such games\nare inefficient since the price of anarchy can be very high with respect to the\nparameters of the game. In order to obtain smaller price of anarchy we explore\n{\\em exponential bottleneck games} where the utility costs of the players are\nexponential functions on the congestion of the edges in their paths. We find\nthat exponential bottleneck games are very efficient giving a poly-log bound on\nthe price of anarchy: O(log L log |E|), where L is the largest path length in\nthe players strategy sets and E is the set of edges in the graph.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2009 01:10:39 GMT"}], "update_date": "2009-11-24", "authors_parsed": [["Kannan", "Rajgopal", ""], ["Busch", "Costas", ""]]}, {"id": "0911.4833", "submitter": "Patricia Bouyer-Decitre", "authors": "Patricia Bouyer, Thomas Brihaye, Fabrice Chevalier", "title": "O-Minimal Hybrid Reachability Games", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 1 (January\n  12, 2010) lmcs:1206", "doi": "10.2168/LMCS-6(1:1)2010", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider reachability games over general hybrid systems,\nand distinguish between two possible observation frameworks for those games:\neither the precise dynamics of the system is seen by the players (this is the\nperfect observation framework), or only the starting point and the delays are\nknown by the players (this is the partial observation framework). In the first\nmore classical framework, we show that time-abstract bisimulation is not\nadequate for solving this problem, although it is sufficient in the case of\ntimed automata . That is why we consider an other equivalence, namely the\nsuffix equivalence based on the encoding of trajectories through words. We show\nthat this suffix equivalence is in general a correct abstraction for games. We\napply this result to o-minimal hybrid systems, and get decidability and\ncomputability results in this framework. For the second framework which assumes\na partial observation of the dynamics of the system, we propose another\nabstraction, called the superword encoding, which is suitable to solve the\ngames under that assumption. In that framework, we also provide decidability\nand computability results.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2009 12:33:37 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2010 21:41:23 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bouyer", "Patricia", ""], ["Brihaye", "Thomas", ""], ["Chevalier", "Fabrice", ""]]}, {"id": "0911.5548", "submitter": "Xiaofei Huang", "authors": "Xiaofei Huang", "title": "A Decision-Optimization Approach to Quantum Mechanics and Game Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental laws of quantum world upsets the logical foundation of\nclassic physics. They are completely counter-intuitive with many bizarre\nbehaviors. However, this paper shows that they may make sense from the\nperspective of a general decision-optimization principle for cooperation. This\nprinciple also offers a generalization of Nash equilibrium, a key concept in\ngame theory, for better payoffs and stability of game playing.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2009 16:43:52 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2009 16:58:11 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["Huang", "Xiaofei", ""]]}]