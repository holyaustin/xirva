[{"id": "1308.0173", "submitter": "Parter Merav", "authors": "Michael Dinitz and Merav Parter", "title": "Braess's Paradox in Wireless Networks: The Danger of Improved Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing new wireless technologies, it is common to consider the effect\nthat they have on the capacity of the network (defined as the maximum number of\nsimultaneously satisfiable links). For example, it has been shown that giving\nreceivers the ability to do interference cancellation, or allowing transmitters\nto use power control, never decreases the capacity and can in certain cases\nincrease it by $\\Omega(\\log (\\Delta \\cdot P_{\\max}))$, where $\\Delta$ is the\nratio of the longest link length to the smallest transmitter-receiver distance\nand $P_{\\max}$ is the maximum transmission power. But there is no reason to\nexpect the optimal capacity to be realized in practice, particularly since\nmaximizing the capacity is known to be NP-hard. In reality, we would expect\nlinks to behave as self-interested agents, and thus when introducing a new\ntechnology it makes more sense to compare the values reached at game-theoretic\nequilibria than the optimum values.\n  In this paper we initiate this line of work by comparing various notions of\nequilibria (particularly Nash equilibria and no-regret behavior) when using a\nsupposedly \"better\" technology. We show a version of Braess's Paradox for all\nof them: in certain networks, upgrading technology can actually make the\nequilibria \\emph{worse}, despite an increase in the capacity. We construct\ninstances where this decrease is a constant factor for power control,\ninterference cancellation, and improvements in the SINR threshold ($\\beta$),\nand is $\\Omega(\\log \\Delta)$ when power control is combined with interference\ncancellation. However, we show that these examples are basically tight: the\ndecrease is at most O(1) for power control, interference cancellation, and\nimproved $\\beta$, and is at most $O(\\log \\Delta)$ when power control is\ncombined with interference cancellation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 12:39:34 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2013 08:50:00 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Dinitz", "Michael", ""], ["Parter", "Merav", ""]]}, {"id": "1308.0544", "submitter": "Lane A. Hemaspaandra", "authors": "Zack Fitzsimmons, Edith Hemaspaandra, Lane A. Hemaspaandra", "title": "Control in the Presence of Manipulators: Cooperative and Competitive\n  Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control and manipulation are two of the most studied types of attacks on\nelections. In this paper, we study the complexity of control attacks on\nelections in which there are manipulators. We study both the case where the\n\"chair\" who is seeking to control the election is allied with the manipulators,\nand the case where the manipulators seek to thwart the chair. In the latter\ncase, we see that the order of play substantially influences the complexity. We\nprove upper bounds, holding over every election system with a polynomial-time\nwinner problem, for all standard control cases, and some of these bounds are at\nthe second or third level of the polynomial hierarchy, and we provide matching\nlower bounds to prove these tight. Nonetheless, for important natural systems\nthe complexity can be much lower. We prove that for approval and plurality\nelections, the complexity of even competitive clashes between a controller and\nmanipulators falls far below those high bounds, even as low as polynomial time.\nYet for a Borda-voting case we show that such clashes raise the complexity\nunless NP = coNP.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 15:51:30 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 17:53:43 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 16:46:13 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""]]}, {"id": "1308.0841", "submitter": "Jian Zhao", "authors": "Jian Zhao and Chuan Wu and Zongpeng Li", "title": "Cost Minimization in Multiple IaaS Clouds: A Double Auction Approach", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IaaS clouds invest substantial capital in operating their data centers.\nReducing the cost of resource provisioning, is their forever pursuing goal.\nComputing resource trading among multiple IaaS clouds provide a potential for\nIaaS clouds to utilize cheaper resources to fulfill their jobs, by exploiting\nthe diversities of different clouds' workloads and operational costs. In this\npaper, we focus on studying the IaaS clouds' cost reduction through computing\nresource trading among multiple IaaS clouds. We formulate the global cost\nminimization problem among multiple IaaS clouds under cooperative scenario\nwhere each individual cloud's workload and cost information is known. Taking\ninto consideration jobs with disparate lengths, a non-preemptive approximation\nalgorithm for leftover job migration and new job scheduling is designed. Given\nto the selfishness of individual clouds, we further design a randomized double\nauction mechanism to elicit clouds' truthful bidding for buying or selling\nvirtual machines. We evaluate our algorithms using trace-driven simulations.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2013 19:07:22 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2013 12:53:07 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2013 09:15:59 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Zhao", "Jian", ""], ["Wu", "Chuan", ""], ["Li", "Zongpeng", ""]]}, {"id": "1308.0979", "submitter": "Parinaz Naghizadeh Ardabili", "authors": "Parinaz Naghizadeh and Mingyan Liu", "title": "Closing the Price of Anarchy Gap in the Interdependent Security Game", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliability and security of a user in an interconnected system depends on\nall users' collective effort in security. Consequently, investments in security\ntechnologies by strategic users is typically modeled as a public good problem,\nknown as the Interdependent Security (IDS) game. The equilibria for such games\nare often inefficient, as selfish users free-ride on positive externalities of\nothers' contributions. In this paper, we present a mechanism that implements\nthe socially optimal equilibrium in an IDS game through a message exchange\nprocess, in which users submit proposals about the security investment and\ntax/price profiles of one another. This mechanism is different from existing\nsolutions in that (1) it results in socially optimal levels of investment,\nclosing the Price of Anarchy gap in the IDS game, (2) it is applicable to a\ngeneral model of user interdependencies. We further consider the issue of\nindividual rationality, often a trivial condition to satisfy in many resource\nallocation problems, and argue that with positive externality, the incentive to\nstay out and free-ride on others' investment can make individual rationality\nmuch harder to satisfy in designing a mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 13:35:05 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2014 20:30:45 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Naghizadeh", "Parinaz", ""], ["Liu", "Mingyan", ""]]}, {"id": "1308.0990", "submitter": "Vasilis Syrgkanis", "authors": "Yoram Bachrach, Vasilis Syrgkanis, Milan Vojnovic", "title": "Incentives and Efficiency in Uncertain Collaborative Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider collaborative systems where users make contributions across\nmultiple available projects and are rewarded for their contributions in\nindividual projects according to a local sharing of the value produced. This\nserves as a model of online social computing systems such as online Q&A forums\nand of credit sharing in scientific co-authorship settings. We show that the\nmaximum feasible produced value can be well approximated by simple local\nsharing rules where users are approximately rewarded in proportion to their\nmarginal contributions and that this holds even under incomplete information\nabout the player's abilities and effort constraints. For natural instances we\nshow almost 95% optimality at equilibrium. When players incur a cost for their\neffort, we identify a threshold phenomenon: the efficiency is a constant\nfraction of the optimal when the cost is strictly convex and decreases with the\nnumber of players if the cost is linear.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 14:20:24 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Bachrach", "Yoram", ""], ["Syrgkanis", "Vasilis", ""], ["Vojnovic", "Milan", ""]]}, {"id": "1308.1382", "submitter": "Jinshan Zhang", "authors": "Xiaotie Deng, Paul Goldberg, Yang Sun, Bo Tang and Jinshan Zhang", "title": "Pricing Ad Slots with Consecutive Multi-unit Demand", "comments": "27pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimal pricing problem for a model of the rich media\nadvertisement market, as well as other related applications. In this market,\nthere are multiple buyers (advertisers), and items (slots) that are arranged in\na line such as a banner on a website. Each buyer desires a particular number of\n{\\em consecutive} slots and has a per-unit-quality value $v_i$ (dependent on\nthe ad only) while each slot $j$ has a quality $q_j$ (dependent on the position\nonly such as click-through rate in position auctions). Hence, the valuation of\nthe buyer $i$ for item $j$ is $v_iq_j$. We want to decide the allocations and\nthe prices in order to maximize the total revenue of the market maker.\n  A key difference from the traditional position auction is the advertiser's\nrequirement of a fixed number of consecutive slots. Consecutive slots may be\nneeded for a large size rich media ad. We study three major pricing mechanisms,\nthe Bayesian pricing model, the maximum revenue market equilibrium model and an\nenvy-free solution model. Under the Bayesian model, we design a polynomial time\ncomputable truthful mechanism which is optimum in revenue. For the market\nequilibrium paradigm, we find a polynomial time algorithm to obtain the maximum\nrevenue market equilibrium solution. In envy-free settings, an optimal solution\nis presented when the buyers have the same demand for the number of consecutive\nslots. We conduct a simulation that compares the revenues from the above\nschemes and gives convincing results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 19:22:07 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Deng", "Xiaotie", ""], ["Goldberg", "Paul", ""], ["Sun", "Yang", ""], ["Tang", "Bo", ""], ["Zhang", "Jinshan", ""]]}, {"id": "1308.1481", "submitter": "Stewart Ethier", "authors": "S. N. Ethier and Jiyeon Lee", "title": "The evolution of the game of baccarat", "comments": "13 pages, 0 figures; change in title and emphasis in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of baccarat has evolved from a parlor game played by French\naristocrats in the first half of the 19th century to a casino game that\ngenerated over US\\$41 billion in revenue for the casinos of Macau in 2013. The\nparlor game was originally a three-person zero-sum game. Later in the 19th\ncentury it was simplified to a two-person zero-sum game. Early in the 20th\ncentury the parlor game became a casino game, no longer zero-sum. In the mid\n20th century, the strategic casino game became a nonstrategic game, with\nplayers competing against the house instead of against each other. We argue\nthat this evolution was motivated by both economic and game-theoretic\nconsiderations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 05:40:27 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 21:00:09 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Ethier", "S. N.", ""], ["Lee", "Jiyeon", ""]]}, {"id": "1308.1779", "submitter": "Christoph Lange", "authors": "Marco B. Caminati, Manfred Kerber, Christoph Lange, Colin Rowat", "title": "Proving soundness of combinatorial Vickrey auctions and generating\n  verified executable code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using mechanised reasoning we prove that combinatorial Vickrey auctions are\nsoundly specified in that they associate a unique outcome (allocation and\ntransfers) to any valid input (bids). Having done so, we auto-generate verified\nexecutable code from the formally defined auction. This removes a source of\nerror in implementing the auction design. We intend to use formal methods to\nverify new auction designs. Here, our contribution is to introduce and\ndemonstrate the use of formal methods for auction verification in the familiar\nsetting of a well-known auction.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 08:00:55 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 10:47:25 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Caminati", "Marco B.", ""], ["Kerber", "Manfred", ""], ["Lange", "Christoph", ""], ["Rowat", "Colin", ""]]}, {"id": "1308.1832", "submitter": "Lasse Kliemann", "authors": "Lasse Kliemann", "title": "The Price of Anarchy in Bilateral Network Formation in an Adversary\n  Model", "comments": "6th International Symposium on Algorithmic Game Theory (SAGT 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study network formation with the bilateral link formation rule (Jackson\nand Wolinsky 1996) with $n$ players and link cost $\\alpha>0$. After the network\nis built, an adversary randomly destroys one link according to a certain\nprobability distribution. Cost for player $v$ incorporates the expected number\nof players to which $v$ will become disconnected. This model was previously\nstudied for unilateral link formation (K. 2011).\n  We prove existence of pairwise Nash equilibria under moderate assumptions on\nthe adversary and $n\\geq 9$. As the main result, we prove bounds on the price\nof anarchy for two special adversaries: one destroys a link chosen uniformly at\nrandom, while the other destroys a link that causes a maximum number of player\npairs to be separated. We prove bounds tight up to constants, namely $O(1)$ for\none adversary (if $\\alpha>1/2$), and $\\Theta(n)$ for the other (if $\\alpha>2$\nconsidered constant and $n \\geq 9$). The latter is the worst that can happen\nfor any adversary in this model (if $\\alpha=\\Omega(1)$).\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 12:56:10 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Kliemann", "Lasse", ""]]}, {"id": "1308.1947", "submitter": "Matjaz Perc", "authors": "Zhen Wang, Attila Szolnoki, Matjaz Perc", "title": "Interdependent network reciprocity in evolutionary games", "comments": "7 two-column pages, 6 figures; accepted for publication in Scientific\n  Reports", "journal-ref": "Sci. Rep. 3 (2013) 1183", "doi": "10.1038/srep01183", "report-no": null, "categories": "physics.soc-ph cs.GT cs.SI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides the structure of interactions within networks, also the interactions\nbetween networks are of the outmost importance. We therefore study the outcome\nof the public goods game on two interdependent networks that are connected by\nmeans of a utility function, which determines how payoffs on both networks\njointly influence the success of players in each individual network. We show\nthat an unbiased coupling allows the spontaneous emergence of interdependent\nnetwork reciprocity, which is capable to maintain healthy levels of public\ncooperation even in extremely adverse conditions. The mechanism, however,\nrequires simultaneous formation of correlated cooperator clusters on both\nnetworks. If this does not emerge or if the coordination process is disturbed,\nnetwork reciprocity fails, resulting in the total collapse of cooperation.\nNetwork interdependence can thus be exploited effectively to promote\ncooperation past the limits imposed by isolated networks, but only if the\ncoordination between the interdependent networks is not disturbed.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 19:55:03 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Wang", "Zhen", ""], ["Szolnoki", "Attila", ""], ["Perc", "Matjaz", ""]]}, {"id": "1308.2497", "submitter": "Mona Rahn", "authors": "Mona Rahn, Guido Sch\\\"afer", "title": "Bounding the Inefficiency of Altruism Through Social Contribution Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of games, called social contribution games (SCGs),\nwhere each player's individual cost is equal to the cost he induces on society\nbecause of his presence. Our results reveal that SCGs constitute useful\nabstractions of altruistic games when it comes to the analysis of the robust\nprice of anarchy. We first show that SCGs are altruism-independently smooth,\ni.e., the robust price of anarchy of these games remains the same under\narbitrary altruistic extensions. We then devise a general reduction technique\nthat enables us to reduce the problem of establishing smoothness for an\naltruistic extension of a base game to a corresponding SCG. Our reduction\napplies whenever the base game relates to a canonical SCG by satisfying a\nsimple social contribution boundedness property. As it turns out, several\nwell-known games satisfy this property and are thus amenable to our reduction\ntechnique. Examples include min-sum scheduling games, congestion games, second\nprice auctions and valid utility games. Using our technique, we derive mostly\ntight bounds on the robust price of anarchy of their altruistic extensions. For\nthe majority of the mentioned game classes, the results extend to the more\ndifferentiated friendship setting. As we show, our reduction technique covers\nthis model if the base game satisfies three additional natural properties.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 09:13:07 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Rahn", "Mona", ""], ["Sch\u00e4fer", "Guido", ""]]}, {"id": "1308.2576", "submitter": "Lars Roemheld", "authors": "Lars Roemheld", "title": "Evolutionary Extortion and Mischief: Zero Determinant strategies in\n  iterated 2x2 games", "comments": "Bachelor thesis at Heidelberg University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the mechanisms, implications, and potential applications\nof the recently discovered class of Zero Determinant (ZD) strategies in\niterated 2x2 games. These strategies were reported to successfully extort pure\neconomic maximizers, and to mischievously determine the set of feasible\nlong-term payoffs in iterated Prisoners' Dilemma by enforcing linear\nconstraints on both players' expected average scores.\n  These results are generalized for all symmetric 2x2 games and a general\nBattle of the Sexes, exemplified by four common games. Additionally, a\ncomparison to conventional strategies is made and typical ZD gameplay\nsimulations are analyzed along with convergence speeds. Several response\nstrategies are discussed, including a glance on how time preferences change\nprevious results. Furthermore, a possibility of retaliation is presented: when\nmaximin scores exceed the minimum symmetric payoff, it is possible to extort\nthe extortioner.\n  Finally, a summary of findings from evolutionary game theory shows that\nmischief is limited by its own malice. Nevertheless, this does not challenge\nthe result that mindless economic maximization is subject to extortion: the\nstudy of ZD strategies reveals exciting new perspectives and opportunities in\ngame theory, both evolutionary and classic.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 14:24:49 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Roemheld", "Lars", ""]]}, {"id": "1308.3161", "submitter": "Kevin Schewior", "authors": "Tobias Harks, Martin Hoefer, Kevin Schewior, Alexander Skopalik", "title": "Routing Games with Progressive Filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-min fairness (MMF) is a widely known approach to a fair allocation of\nbandwidth to each of the users in a network. This allocation can be computed by\nuniformly raising the bandwidths of all users without violating capacity\nconstraints. We consider an extension of these allocations by raising the\nbandwidth with arbitrary and not necessarily uniform time-depending velocities\n(allocation rates). These allocations are used in a game-theoretic context for\nrouting choices, which we formalize in progressive filling games (PFGs).\n  We present a variety of results for equilibria in PFGs. We show that these\ngames possess pure Nash and strong equilibria. While computation in general is\nNP-hard, there are polynomial-time algorithms for prominent classes of\nMax-Min-Fair Games (MMFG), including the case when all users have the same\nsource-destination pair. We characterize prices of anarchy and stability for\npure Nash and strong equilibria in PFGs and MMFGs when players have different\nor the same source-destination pairs. In addition, we show that when a designer\ncan adjust allocation rates, it is possible to design games with optimal strong\nequilibria. Some initial results on polynomial-time algorithms in this\ndirection are also derived.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 15:45:51 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2013 09:48:38 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2014 13:26:06 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Harks", "Tobias", ""], ["Hoefer", "Martin", ""], ["Schewior", "Kevin", ""], ["Skopalik", "Alexander", ""]]}, {"id": "1308.3174", "submitter": "Jesse Shore", "authors": "Benjamin Lubin, Jesse Shore and Vatche Ishakian", "title": "Communication Network Design: Balancing Modularity and Mixing via\n  Optimal Graph Spectra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By leveraging information technologies, organizations now have the ability to\ndesign their communication networks and crowdsourcing platforms to pursue\nvarious performance goals, but existing research on network design does not\naccount for the specific features of social networks, such as the notion of\nteams. We fill this gap by demonstrating how desirable aspects of\norganizational structure can be mapped parsimoniously onto the spectrum of the\ngraph Laplacian allowing the specification of structural objectives and build\non recent advances in non-convex programming to optimize them. This design\nframework is general, but we focus here on the problem of creating graphs that\nbalance high modularity and low mixing time, and show how \"liaisons\" rather\nthan brokers maximize this objective.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 16:29:28 GMT"}], "update_date": "2013-08-15", "authors_parsed": [["Lubin", "Benjamin", ""], ["Shore", "Jesse", ""], ["Ishakian", "Vatche", ""]]}, {"id": "1308.3185", "submitter": "Nicholas Mastronarde", "authors": "Nicholas Mastronarde, Viral Patel, Jie Xu, Lingjia Liu, Mihaela van\n  der Schaar", "title": "To Relay or Not to Relay: Learning Device-to-Device Relaying Strategies\n  in Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a cellular network where mobile transceiver devices that are\nowned by self-interested users are incentivized to cooperate with each other\nusing tokens, which they exchange electronically to \"buy\" and \"sell\" downlink\nrelay services, thereby increasing the network's capacity compared to a network\nthat only supports base station-to-device (B2D) communications. We investigate\nhow an individual device in the network can learn its optimal cooperation\npolicy online, which it uses to decide whether or not to provide downlink relay\nservices for other devices in exchange for tokens. We propose a supervised\nlearning algorithm that devices can deploy to learn their optimal cooperation\nstrategies online given their experienced network environment. We then\nsystematically evaluate the learning algorithm in various deployment scenarios.\nOur simulation results suggest that devices have the greatest incentive to\ncooperate when the network contains (i) many devices with high energy budgets\nfor relaying, (ii) many highly mobile users (e.g., users in motor vehicles),\nand (iii) neither too few nor too many tokens. Additionally, within the token\nsystem, self-interested devices can effectively learn to cooperate online, and\nachieve over 20% higher throughput on average than with B2D communications\nalone, all while selfishly maximizing their own utilities.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 02:23:28 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2013 01:32:54 GMT"}, {"version": "v3", "created": "Sat, 13 Dec 2014 21:45:39 GMT"}, {"version": "v4", "created": "Mon, 29 Dec 2014 02:11:48 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Mastronarde", "Nicholas", ""], ["Patel", "Viral", ""], ["Xu", "Jie", ""], ["Liu", "Lingjia", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1308.3258", "submitter": "Jeremy Kun", "authors": "Jeremy Kun, Brian Powers, Lev Reyzin", "title": "Anti-Coordination Games and Stable Graph Colorings", "comments": "Appearing in SAGT 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by understanding non-strict and strict pure strategy equilibria in\nnetwork anti-coordination games, we define notions of stable and, respectively,\nstrictly stable colorings in graphs. We characterize the cases when such\ncolorings exist and when the decision problem is NP-hard. These correspond to\nfinding pure strategy equilibria in the anti-coordination games, whose price of\nanarchy we also analyze. We further consider the directed case, a\ngeneralization that captures both coordination and anti-coordination. We prove\nthe decision problem for non-strict equilibria in directed graphs is NP-hard.\nOur notions also have multiple connections to other combinatorial questions,\nand our results resolve some open problems in these areas, most notably the\ncomplexity of the strictly unfriendly partition problem.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 21:36:45 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Kun", "Jeremy", ""], ["Powers", "Brian", ""], ["Reyzin", "Lev", ""]]}, {"id": "1308.3329", "submitter": "Vittorio Bil\\`o", "authors": "Vittorio Bil\\`o", "title": "On Linear Congestion Games with Altruistic Social Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the issues of existence and inefficiency of pure Nash equilibria in\nlinear congestion games with altruistic social context, in the spirit of the\nmodel recently proposed by de Keijzer {\\em et al.} \\cite{DSAB13}. In such a\nframework, given a real matrix $\\Gamma=(\\gamma_{ij})$ specifying a particular\nsocial context, each player $i$ aims at optimizing a linear combination of the\npayoffs of all the players in the game, where, for each player $j$, the\nmultiplicative coefficient is given by the value $\\gamma_{ij}$. We give a broad\ncharacterization of the social contexts for which pure Nash equilibria are\nalways guaranteed to exist and provide tight or almost tight bounds on their\nprices of anarchy and stability. In some of the considered cases, our\nachievements either improve or extend results previously known in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 07:47:55 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Bil\u00f2", "Vittorio", ""]]}, {"id": "1308.3506", "submitter": "Kevin Waugh", "authors": "Kevin Waugh and Brian D. Ziebart and J. Andrew Bagnell", "title": "Computational Rationalization: The Inverse Equilibrium Problem", "comments": "In submission to JMLR, conference version: arXiv:1103.5254", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the purposeful behavior of imperfect agents from a small number of\nobservations is a challenging task. When restricted to the single-agent\ndecision-theoretic setting, inverse optimal control techniques assume that\nobserved behavior is an approximately optimal solution to an unknown decision\nproblem. These techniques learn a utility function that explains the example\nbehavior and can then be used to accurately predict or imitate future behavior\nin similar observed or unobserved situations.\n  In this work, we consider similar tasks in competitive and cooperative\nmulti-agent domains. Here, unlike single-agent settings, a player cannot\nmyopically maximize its reward; it must speculate on how the other agents may\nact to influence the game's outcome. Employing the game-theoretic notion of\nregret and the principle of maximum entropy, we introduce a technique for\npredicting and generalizing behavior.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 20:43:47 GMT"}], "update_date": "2013-08-19", "authors_parsed": [["Waugh", "Kevin", ""], ["Ziebart", "Brian D.", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1308.3778", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Rafael Pass", "title": "Game Theory with Translucent Players", "comments": "Extended version of a paper that appear in the Conference on\n  Theoretical Aspects of Rationality and Knowledge, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A traditional assumption in game theory is that players are opaque to one\nanother---if a player changes strategies, then this change in strategies does\nnot affect the choice of other players' strategies. In many situations this is\nan unrealistic assumption. We develop a framework for reasoning about games\nwhere the players may be translucent to one another; in particular, a player\nmay believe that if she were to change strategies, then the other player would\nalso change strategies. Translucent players may achieve significantly more\nefficient outcomes than opaque ones.\n  Our main result is a characterization of strategies consistent with\nappropriate analogues of common belief of rationality. Common Counterfactual\nBelief of Rationality (CCBR) holds if (1) everyone is rational, (2) everyone\ncounterfactually believes that everyone else is rational (i.e., all players i\nbelieve that everyone else would still be rational even if $i$ were to switch\nstrategies), (3) everyone counterfactually believes that everyone else is\nrational, and counterfactually believes that everyone else is rational, and so\non. CCBR characterizes the set of strategies surviving iterated removal of\nminimax dominated strategies, where a strategy s for player i is minimax\ndominated by s' if the worst-case payoff for i using s' is better than the best\npossible payoff using s.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2013 12:29:53 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pass", "Rafael", ""]]}, {"id": "1308.3780", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Rafael Pass, and Lior Seeman", "title": "Decision Theory with Resource-Bounded Agents", "comments": "To appear, Topics in Cognitive Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been two major lines of research aimed at capturing\nresource-bounded players in game theory. The first, initiated by Rubinstein,\ncharges an agent for doing costly computation; the second, initiated by Neyman,\ndoes not charge for computation, but limits the computation that agents can do,\ntypically by modeling agents as finite automata. We review recent work on\napplying both approaches in the context of decision theory. For the first\napproach, we take the objects of choice in a decision problem to be Turing\nmachines, and charge players for the ``complexity'' of the Turing machine\nchosen (e.g., its running time). This approach can be used to explain\nwell-known phenomena like first-impression-matters biases (i.e., people tend to\nput more weight on evidence they hear early on) and belief polarization (two\npeople with different prior beliefs, hearing the same evidence, can end up with\ndiametrically opposed conclusions) as the outcomes of quite rational decisions.\nFor the second approach, we model people as finite automata, and provide a\nsimple algorithm that, on a problem that captures a number of settings of\ninterest, provably performs optimally as the number of states in the automaton\nincreases.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2013 12:40:42 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pass", "Rafael", ""], ["Seeman", "Lior", ""]]}, {"id": "1308.4013", "submitter": "Adish Singla", "authors": "Adish Singla and Andreas Krause", "title": "Incentives for Privacy Tradeoff in Community Sensing", "comments": "Extended version of paper to appear in HCOMP'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community sensing, fusing information from populations of privately-held\nsensors, presents a great opportunity to create efficient and cost-effective\nsensing applications. Yet, reasonable privacy concerns often limit the access\nto such data streams. How should systems valuate and negotiate access to\nprivate information, for example in return for monetary incentives? How should\nthey optimally choose the participants from a large population of strategic\nusers with privacy concerns, and compensate them for information shared? In\nthis paper, we address these questions and present a novel mechanism,\nSeqTGreedy, for budgeted recruitment of participants in community sensing. We\nfirst show that privacy tradeoffs in community sensing can be cast as an\nadaptive submodular optimization problem. We then design a budget feasible,\nincentive compatible (truthful) mechanism for adaptive submodular maximization,\nwhich achieves near-optimal utility for a large class of sensing applications.\nThis mechanism is general, and of independent interest. We demonstrate the\neffectiveness of our approach in a case study of air quality monitoring, using\ndata collected from the Mechanical Turk platform. Compared to the state of the\nart, our approach achieves up to 30% reduction in cost in order to achieve a\ndesired level of utility.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 13:23:59 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2013 02:01:32 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Singla", "Adish", ""], ["Krause", "Andreas", ""]]}, {"id": "1308.4049", "submitter": "Georg Ostrovski", "authors": "Georg Ostrovski and Sebastian van Strien", "title": "Payoff Performance of Fictitious Play", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how well continuous-time fictitious play in two-player games\nperforms in terms of average payoff, particularly compared to Nash equilibrium\npayoff. We show that in many games, fictitious play outperforms Nash\nequilibrium on average or even at all times, and moreover that any game is\nlinearly equivalent to one in which this is the case. Conversely, we provide\nconditions under which Nash equilibrium payoff dominates fictitious play\npayoff. A key step in our analysis is to show that fictitious play dynamics\nasymptotically converges the set of coarse correlated equilibria (a fact which\nis implicit in the literature).\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 15:12:34 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 23:11:16 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Ostrovski", "Georg", ""], ["van Strien", "Sebastian", ""]]}, {"id": "1308.4101", "submitter": "Rajgopal Kannan", "authors": "Rajgopal Kannan, Costas Busch and Paul Spirakis", "title": "The Price of Anarchy is Unbounded for Congestion Games with\n  Superpolynomial Latency Costs", "comments": "17 pages, submitted to SODA 14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-cooperative unsplittable congestion games where players share\nresources, and each player's strategy is pure and consists of a subset of the\nresources on which it applies a fixed weight. Such games represent unsplittable\nrouting flow games and also job allocation games. The congestion of a resource\nis the sum of the weights of the players that use it and the player's cost\nfunction is the sum of the utilities of the resources on its strategy. The\nsocial cost is the total weighted sum of the player's costs. The quality of\nNash equilibria is determined by the price of anarchy ($PoA$) which expresses\nhow much worse is the social outcome in the worst equilibrium versus the\noptimal coordinated solution. In the literature the predominant work has only\nbeen on games with polynomial utility costs, where it has been proven that the\nprice of anarchy is bounded by the degree of the polynomial. However, no\nresults exist on general bounds for non-polynomial utility functions.\n  Here, we consider general versions of these games in which the utility of\neach resource is an arbitrary non-decreasing function of the congestion. In\nparticular, we consider a large family of superpolynomial utility functions\nwhich are asymptotically larger than any polynomial. We demonstrate that for\nevery such function there exist games for which the price of anarchy is\nunbounded and increasing with the number of players (even if they have\ninfinitesimal weights) while network resources remain fixed. We give tight\nlower and upper bounds which show this dependence on the number of players.\nFurthermore we provide an exact characterization of the $PoA$ of all congestion\ngames whose utility costs are bounded above by a polynomial function.\nHeretofore such results existed only for games with polynomial cost functions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 19:14:14 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Kannan", "Rajgopal", ""], ["Busch", "Costas", ""], ["Spirakis", "Paul", ""]]}, {"id": "1308.4761", "submitter": "Tri Kurniawan Wijaya", "authors": "Tri Kurniawan Wijaya, Kate Larson and Karl Aberer", "title": "Matching Demand with Supply in the Smart Grid using Agent-Based\n  Multiunit Auction", "comments": null, "journal-ref": "2013 Fifth International Conference on Communication Systems and\n  Networks (COMSNETS), vol., no., pp.1,6, 7-10 Jan. 2013", "doi": "10.1109/COMSNETS.2013.6465595", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has suggested reducing electricity generation cost by cutting the\npeak to average ratio (PAR) without reducing the total amount of the loads.\nHowever, most of these proposals rely on consumer's willingness to act. In this\npaper, we propose an approach to cut PAR explicitly from the supply side. The\nresulting cut loads are then distributed among consumers by the means of a\nmultiunit auction which is done by an intelligent agent on behalf of the\nconsumer. This approach is also in line with the future vision of the smart\ngrid to have the demand side matched with the supply side. Experiments suggest\nthat our approach reduces overall system cost and gives benefit to both\nconsumers and the energy provider.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 04:58:21 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Wijaya", "Tri Kurniawan", ""], ["Larson", "Kate", ""], ["Aberer", "Karl", ""]]}, {"id": "1308.5272", "submitter": "Jugal Garg", "authors": "Jugal Garg and Vijay V. Vazirani", "title": "On Computability of Equilibria in Markets with Production", "comments": "An extended abstract will appear in SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although production is an integral part of the Arrow-Debreu market model,\nmost of the work in theoretical computer science has so far concentrated on\nmarkets without production, i.e., the exchange economy. This paper takes a\nsignificant step towards understanding computational aspects of markets with\nproduction.\n  We first define the notion of separable, piecewise-linear concave (SPLC)\nproduction by analogy with SPLC utility functions. We then obtain a linear\ncomplementarity problem (LCP) formulation that captures exactly the set of\nequilibria for Arrow-Debreu markets with SPLC utilities and SPLC production,\nand we give a complementary pivot algorithm for finding an equilibrium. This\nsettles a question asked by Eaves in 1975 of extending his complementary pivot\nalgorithm to markets with production.\n  Since this is a path-following algorithm, we obtain a proof of membership of\nthis problem in PPAD, using Todd, 1976. We also obtain an elementary proof of\nexistence of equilibrium (i.e., without using a fixed point theorem),\nrationality, and oddness of the number of equilibria. We further give a proof\nof PPAD-hardness for this problem and also for its restriction to markets with\nlinear utilities and SPLC production. Experiments show that our algorithm runs\nfast on randomly chosen examples, and unlike previous approaches, it does not\nsuffer from issues of numerical instability. Additionally, it is strongly\npolynomial when the number of goods or the number of agents and firms is\nconstant. This extends the result of Devanur and Kannan (2008) to markets with\nproduction.\n  Finally, we show that an LCP-based approach cannot be extended to PLC\n(non-separable) production, by constructing an example which has only\nirrational equilibria.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 01:20:22 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2013 18:28:46 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Garg", "Jugal", ""], ["Vazirani", "Vijay V.", ""]]}, {"id": "1308.5835", "submitter": "Sumudu Samarakoon Mr.", "authors": "Sumudu Samarakoon and Mehdi Bennis and Walid Saad and Matti Latva-aho", "title": "Backhaul-Aware Interference Management in the Uplink of Wireless Small\n  Cell Networks", "comments": "14 pages, 9 figures, journal article to be appeared in Transaction of\n  Wireless Communication", "journal-ref": null, "doi": "10.1109/TWC.2013.092413.130221", "report-no": null, "categories": "cs.NI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of distributed mechanisms for interference management is one of\nthe key challenges in emerging wireless small cell networks whose backhaul is\ncapacity limited and heterogeneous (wired, wireless and a mix thereof). In this\npaper, a novel, backhaul-aware approach to interference management in wireless\nsmall cell networks is proposed. The proposed approach enables macrocell user\nequipments (MUEs) to optimize their uplink performance, by exploiting the\npresence of neighboring small cell base stations. The problem is formulated as\na noncooperative game among the MUEs that seek to optimize their delay-rate\ntradeoff, given the conditions of both the radio access network and the --\npossibly heterogeneous -- backhaul. To solve this game, a novel, distributed\nlearning algorithm is proposed using which the MUEs autonomously choose their\noptimal uplink transmission strategies, given a limited amount of available\ninformation. The convergence of the proposed algorithm is shown and its\nproperties are studied. Simulation results show that, under various types of\nbackhauls, the proposed approach yields significant performance gains, in terms\nof both average throughput and delay for the MUEs, when compared to existing\nbenchmark algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 12:02:50 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Saad", "Walid", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1308.6025", "submitter": "Siddharth Barman", "authors": "Yakov Babichenko, Siddharth Barman and Ron Peretz", "title": "Small-Support Approximate Correlated Equilibria", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the existence of approximate correlated equilibrium of support size\npolylogarithmic in the number of players and the number of actions per player.\nIn particular, using the probabilistic method, we show that there exists a\nmultiset of polylogarithmic size such that the uniform distribution over this\nmultiset forms an approximate correlated equilibrium. Along similar lines, we\nestablish the existence of approximate coarse correlated equilibrium with\nlogarithmic support.\n  We complement these results by considering the computational complexity of\ndetermining small-support approximate equilibria. We show that random sampling\ncan be used to efficiently determine an approximate coarse correlated\nequilibrium with logarithmic support. But, such a tight result does not hold\nfor correlated equilibrium, i.e., sampling might generate an approximate\ncorrelated equilibrium of support size \\Omega(m) where m is the number of\nactions per player. Finally, we show that finding an exact correlated\nequilibrium with smallest possible support is NP-hard under Cook reductions,\neven in the case of two-player zero-sum games.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 01:39:05 GMT"}], "update_date": "2013-08-29", "authors_parsed": [["Babichenko", "Yakov", ""], ["Barman", "Siddharth", ""], ["Peretz", "Ron", ""]]}, {"id": "1308.6255", "submitter": "Oskar Skibski", "authors": "Oskar Skibski, Tomasz P. Michalak, Michael Wooldridge", "title": "The Shapley Axiomatization for Values in Partition Function Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the long-debated issues in coalitional game theory is how to extend\nthe Shapley value to games with externalities (partition-function games). When\nexternalities are present, not only can a player's marginal contribution - a\ncentral notion to the Shapley value - be defined in a variety of ways, but it\nis also not obvious which axiomatization should be used. Consequently, a number\nof authors extended the Shapley value using complex and often unintuitive\naxiomatizations. Furthermore, no algorithm to approximate any extension of the\nShapley value to partition-function games has been proposed to date. Given this\nbackground, we prove in this paper that, for any well-defined measure of\nmarginal contribution, Shapley's original four axioms imply a unique value for\ngames with externalities. As an consequence of this general theorem, we show\nthat values proposed by Macho-Stadler et al., McQuillin and Bolger can be\nderived from Shapley's axioms. Building upon our analysis of marginal\ncontribution, we develop a general algorithm to approximate extensions of the\nShapley value to games with externalities using a Monte Carlo simulation\ntechnique.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 19:16:05 GMT"}], "update_date": "2013-08-29", "authors_parsed": [["Skibski", "Oskar", ""], ["Michalak", "Tomasz P.", ""], ["Wooldridge", "Michael", ""]]}, {"id": "1308.6526", "submitter": "Xavier Vila\\c{c}a", "authors": "Xavier Vila\\c{c}a and Lu\\'is Rodrigues", "title": "On the Effectiveness of Punishments in a Repeated Epidemic Dissemination\n  Game", "comments": "76 pages, extended technical report, original paper is expected to\n  appear on Proceedings of the 15th International Symposium on Stabilization,\n  Safety, and Security of Distributed Systems (SSS 2013), corrected typo in\n  abstract, corrected citation to Kreps:82, improved description of the stage\n  game to justify fixed stage strategy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses Game Theory to study the effectiveness of punishments as an\nincentive for rational nodes to follow an epidemic dissemination protocol. The\ndissemination process is modeled as an infinite repetition of a stage game. At\nthe end of each stage, a monitoring mechanism informs each player of the\nactions of other nodes. The effectiveness of a punishing strategy is measured\nas the range of values for the benefit-to-cost ratio that sustain cooperation.\nThis paper studies both public and private monitoring. Under public monitoring,\nwe show that direct reciprocity is not an effective incentive, whereas full\nindirect reciprocity provides a nearly optimal effectiveness. Under private\nmonitoring, we identify necessary conditions regarding the topology of the\ngraph in order for punishments to be effective. When punishments are\ncoordinated, full indirect reciprocity is also effective with private\nmonitoring.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 17:13:00 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2013 17:49:23 GMT"}], "update_date": "2013-09-02", "authors_parsed": [["Vila\u00e7a", "Xavier", ""], ["Rodrigues", "Lu\u00eds", ""]]}, {"id": "1308.6797", "submitter": "Nir Ailon", "authors": "Nir Ailon", "title": "Online Ranking: Discrete Choice, Spearman Correlation and Other Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $V$ of $n$ objects, an online ranking system outputs at each time\nstep a full ranking of the set, observes a feedback of some form and suffers a\nloss. We study the setting in which the (adversarial) feedback is an element in\n$V$, and the loss is the position (0th, 1st, 2nd...) of the item in the\noutputted ranking. More generally, we study a setting in which the feedback is\na subset $U$ of at most $k$ elements in $V$, and the loss is the sum of the\npositions of those elements.\n  We present an algorithm of expected regret $O(n^{3/2}\\sqrt{Tk})$ over a time\nhorizon of $T$ steps with respect to the best single ranking in hindsight. This\nimproves previous algorithms and analyses either by a factor of either\n$\\Omega(\\sqrt{k})$, a factor of $\\Omega(\\sqrt{\\log n})$ or by improving running\ntime from quadratic to $O(n\\log n)$ per round. We also prove a matching lower\nbound. Our techniques also imply an improved regret bound for online rank\naggregation over the Spearman correlation measure, and to other more complex\nranking loss functions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 17:03:16 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 02:18:18 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2013 02:52:39 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2013 22:05:33 GMT"}, {"version": "v5", "created": "Mon, 14 Oct 2013 14:44:41 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Ailon", "Nir", ""]]}]