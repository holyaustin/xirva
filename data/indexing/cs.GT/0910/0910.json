[{"id": "0910.0443", "submitter": "Danupon Nanongkai", "authors": "Parinya Chalermsook, Bundit Laekhanukit, Danupon Nanongkai", "title": "Stackelberg Pricing is Hard to Approximate within $2-\\epsilon$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stackelberg Pricing Games is a two-level combinatorial pricing problem\nstudied in the Economics, Operation Research, and Computer Science communities.\nIn this paper, we consider the decade-old shortest path version of this problem\nwhich is the first and most studied problem in this family.\n  The game is played on a graph (representing a network) consisting of {\\em\nfixed cost} edges and {\\em pricable} or {\\em variable cost} edges. The fixed\ncost edges already have some fixed price (representing the competitor's\nprices). Our task is to choose prices for the variable cost edges. After that,\na client will buy the cheapest path from a node $s$ to a node $t$, using any\ncombination of fixed cost and variable cost edges. The goal is to maximize the\nrevenue on variable cost edges.\n  In this paper, we show that the problem is hard to approximate within\n$2-\\epsilon$, improving the previous \\APX-hardness result by Joret [to appear\nin {\\em Networks}]. Our technique combines the existing ideas with a new\ninsight into the price structure and its relation to the hardness of the\ninstances.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2009 19:54:54 GMT"}], "update_date": "2009-10-05", "authors_parsed": [["Chalermsook", "Parinya", ""], ["Laekhanukit", "Bundit", ""], ["Nanongkai", "Danupon", ""]]}, {"id": "0910.0513", "submitter": "Ye Du", "authors": "Ye Du", "title": "Ranking via Arrow-Debreu Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we establish a connection between ranking theory and general\nequilibrium theory. First of all, we show that the ranking vector of PageRank\nor Invariant method is precisely the equilibrium of a special Cobb-Douglas\nmarket. This gives a natural economic interpretation for the PageRank or\nInvariant method. Furthermore, we propose a new ranking method, the CES\nranking, which is minimally fair, strictly monotone and invariant to reference\nintensity, but not uniform or weakly additive.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2009 05:39:01 GMT"}], "update_date": "2009-10-06", "authors_parsed": [["Du", "Ye", ""]]}, {"id": "0910.0548", "submitter": "Lyubov Positselskaya", "authors": "Lyubov N. Positselskaya", "title": "Noisy fighter-bomber duel", "comments": "Equally detailed English and Russian versions, each 23 pages long.\n  LaTeX 2e, with Babel for the Russian version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a duel-type game in which Player I uses his resource continuously\nand Player II distributes it by discrete portions. Each player knows how much\nresources he and his opponent have at every moment of time. The solution of the\ngame is given in an explicit form.\n  Keywords: noisy duel, payoff, strategy, the value of a game, consumption of\nresource.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2009 15:22:01 GMT"}], "update_date": "2009-10-06", "authors_parsed": [["Positselskaya", "Lyubov N.", ""]]}, {"id": "0910.0880", "submitter": "Sergei Vassilvitskii", "authors": "Arpita Ghosh, Preston McAfee, Kishore Papineni, Sergei Vassilvitskii", "title": "Bidding for Representative Allocations for Display Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Display advertising has traditionally been sold via guaranteed contracts -- a\nguaranteed contract is a deal between a publisher and an advertiser to allocate\na certain number of impressions over a certain period, for a pre-specified\nprice per impression. However, as spot markets for display ads, such as the\nRightMedia Exchange, have grown in prominence, the selection of advertisements\nto show on a given page is increasingly being chosen based on price, using an\nauction. As the number of participants in the exchange grows, the price of an\nimpressions becomes a signal of its value. This correlation between price and\nvalue means that a seller implementing the contract through bidding should\noffer the contract buyer a range of prices, and not just the cheapest\nimpressions necessary to fulfill its demand.\n  Implementing a contract using a range of prices, is akin to creating a mutual\nfund of advertising impressions, and requires {\\em randomized bidding}. We\ncharacterize what allocations can be implemented with randomized bidding,\nnamely those where the desired share obtained at each price is a non-increasing\nfunction of price. In addition, we provide a full characterization of when a\nset of campaigns are compatible and how to implement them with randomized\nbidding strategies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2009 22:53:01 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Ghosh", "Arpita", ""], ["McAfee", "Preston", ""], ["Papineni", "Kishore", ""], ["Vassilvitskii", "Sergei", ""]]}, {"id": "0910.0916", "submitter": "Esteban Arcaute", "authors": "Esteban Arcaute, Sergei Vassilvitskii", "title": "Social Networks and Stable Matchings in the Job Market", "comments": "19 pages. A preliminary version will appear at the 5th International\n  Workshop on Internet and Network Economics, WINE 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most people, social contacts play an integral part in finding a new job.\nAs observed by Granovetter's seminal study, the proportion of jobs obtained\nthrough social contacts is usually large compared to those obtained through\npostings or agencies. At the same time, job markets are a natural example of\ntwo-sided matching markets. An important solution concept in such markets is\nthat of stable matchings, and the use of the celebrated Gale-Shapley algorithm\nto compute them. So far, the literature has evolved separately, either focusing\non the implications of information flowing through a social network, or on\ndeveloping a mathematical theory of job markets through the use of two-sided\nmatching techniques.\n  In this paper we provide a model of the job market that brings both aspects\nof job markets together. To model the social scientists' observations, we\nassume that workers learn only about positions in firms through social\ncontacts. Given that information structure, we study both static properties of\nwhat we call locally stable matchings (i.e., stable matchings subject to\ninformational constraints given by a social network) and dynamic properties\nthrough a reinterpretation of Gale-Shapley's algorithm as myopic best response\ndynamics.\n  We prove that, in general, the set of locally stable matching strictly\ncontains that of stable matchings and it is in fact NP-complete to determine if\nthey are identical. We also show that the lattice structure of stable matchings\nis in general absent. Finally, we focus on myopic best response dynamics\ninspired by the Gale-Shapley algorithm. We study the efficiency loss due to the\ninformational constraints, providing both lower and upper bounds.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 03:04:52 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Arcaute", "Esteban", ""], ["Vassilvitskii", "Sergei", ""]]}, {"id": "0910.0996", "submitter": "Ernie Cohen", "authors": "Ernie Cohen", "title": "Pessimistic Testing", "comments": "2 pages, 3 refrences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to testing conformance to a nondeterministic\nspecification, in which testing proceeds only as long as increased test\ncoverage is guaranteed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 13:58:09 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Cohen", "Ernie", ""]]}, {"id": "0910.1585", "submitter": "Aaron D. Jaggard", "authors": "Aaron D. Jaggard, Michael Schapira, and Rebecca N. Wright", "title": "Distributed Computing with Adaptive Heuristics", "comments": "36 pages, four figures. Expands both technical results and discussion\n  of v1. Revised version will appear in the proceedings of Innovations in\n  Computer Science 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use ideas from distributed computing to study dynamic environments in\nwhich computational nodes, or decision makers, follow adaptive heuristics (Hart\n2005), i.e., simple and unsophisticated rules of behavior, e.g., repeatedly\n\"best replying\" to others' actions, and minimizing \"regret\", that have been\nextensively studied in game theory and economics. We explore when convergence\nof such simple dynamics to an equilibrium is guaranteed in asynchronous\ncomputational environments, where nodes can act at any time. Our research\nagenda, distributed computing with adaptive heuristics, lies on the borderline\nof computer science (including distributed computing and learning) and game\ntheory (including game dynamics and adaptive heuristics). We exhibit a general\nnon-termination result for a broad class of heuristics with bounded\nrecall---that is, simple rules of behavior that depend only on recent history\nof interaction between nodes. We consider implications of our result across a\nwide variety of interesting and timely applications: game theory, circuit\ndesign, social networks, routing and congestion control. We also study the\ncomputational and communication complexity of asynchronous dynamics and present\nsome basic observations regarding the effects of asynchrony on no-regret\ndynamics. We believe that our work opens a new avenue for research in both\ndistributed computing and game theory.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 22:39:39 GMT"}, {"version": "v2", "created": "Tue, 12 Oct 2010 19:35:08 GMT"}], "update_date": "2010-10-13", "authors_parsed": [["Jaggard", "Aaron D.", ""], ["Schapira", "Michael", ""], ["Wright", "Rebecca N.", ""]]}, {"id": "0910.2113", "submitter": "Abhimanu Kumar", "authors": "Abhimanu Kumar, Sanjib Kumar Das", "title": "A real world network pricing game with less severe Braess' Paradox", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet and graphs are very much related. The graphical structure of\ninternet has been studied extensively to provide efficient solutions to routing\nand other problems. But most of these studies assume a central authority which\ncontrols and manages the internet. In the recent years game theoretic models\nhave been proposed which do not require a central authority and the users are\nassumed to be routing their flows selfishly. The existence of Nash Equilibria,\ncongestion and the amount of inefficiency caused by this selfish routing is a\nmajor concern in this field. A type of paradox in the selfish routing networks,\nBraess' Paradox, first discovered by Braess, is a major contributor to\ninefficiency. Several pricing mechanisms have also been provided which give a\ngame theoretical model between users(consumers) and ISPs ({Internet Service\nProviders} or sellers) for the internet.\n  We propose a novel pricing mechanism, based on real world Internet network\narchitecture, which reduces the severity of Braess' Paradox in selfish routing\ngame theoretic networks. It's a pricing mechanism between combinatorial users\nand ISPs. We prove that Nash equilibria exists in this network and provide\nbounds on inefficiency . We use graphical properties of internet to prove our\nresult. Several interesting extensions and future work have also been\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 09:34:27 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Kumar", "Abhimanu", ""], ["Das", "Sanjib Kumar", ""]]}, {"id": "0910.2655", "submitter": "Chinmay Karande", "authors": "Deeparnab Chakrabarty, Chinmay Karande, Ashish Sangwan", "title": "The Effect of Malice on the Social Optimum in Linear Load Balancing\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we consider the following problem to study the effect of\nmalicious players on the social optimum in load balancing games: Consider two\nplayers SOC and MAL controlling (1-f) and f fraction of the flow in a load\nbalancing game. SOC tries to minimize the total cost faced by her players while\nMAL tries to maximize the same.\n  If the latencies are linear, we show that this 2-player zero-sum game has a\npure strategy Nash equilibrium. Moreover, we show that one of the optimal\nstrategies for MAL is to play selfishly: let the f fraction of the flow be sent\nas when the flow was controlled by infinitesimal players playing selfishly and\nreaching a Nash equilibrium. This shows that a malicious player cannot cause\nmore harm in this game than a set of selfish agents.\n  We also introduce the notion of Cost of Malice - the ratio of the cost faced\nby SOC at equilibrium to (1-f)OPT, where OPT is the social optimum minimizing\nthe cost of all the players. In linear load balancing games we bound the cost\nof malice by (1+f/2).\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2009 15:59:39 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2009 23:05:54 GMT"}], "update_date": "2009-10-15", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Karande", "Chinmay", ""], ["Sangwan", "Ashish", ""]]}, {"id": "0910.2891", "submitter": "Ashutosh Trivedi Dr", "authors": "Marcin Jurdzinski and Ashutosh Trivedi", "title": "Average-Time Games on Timed Automata", "comments": null, "journal-ref": "Proc.FSTTCS'08, volume 08004 of Dagstuhl Seminar Proceedings, 2008", "doi": "10.4230/LIPIcs.FSTTCS.2008.1765", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An average-time game is played on the infinite graph of configurations of a\nfinite timed automaton. The two players, Min and Max, construct an infinite run\nof the automaton by taking turns to perform a timed transition. Player Min\nwants to minimise the average time per transition and player Max wants to\nmaximise it. A solution of average-time games is presented using a reduction to\naverage-price game on a finite graph. A direct consequence is an elementary\nproof of determinacy for average-time games. This complements our results for\nreachability-time games and partially solves a problem posed by Bouyer et al.,\nto design an algorithm for solving average-price games on priced timed\nautomata. The paper also establishes the exact computational complexity of\nsolving average-time games: the problem is EXPTIME-complete for timed automata\nwith at least two clocks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2009 14:45:56 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Jurdzinski", "Marcin", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "0910.3348", "submitter": "Harris Georgiou", "authors": "Harris Georgiou", "title": "Algorithms for Image Analysis and Combination of Pattern Classifiers\n  with Application to Medical Diagnosis", "comments": "PhD thesis summary, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GT cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Medical Informatics and the application of modern signal processing in the\nassistance of the diagnostic process in medical imaging is one of the more\nrecent and active research areas today. This thesis addresses a variety of\nissues related to the general problem of medical image analysis, specifically\nin mammography, and presents a series of algorithms and design approaches for\nall the intermediate levels of a modern system for computer-aided diagnosis\n(CAD). The diagnostic problem is analyzed with a systematic approach, first\ndefining the imaging characteristics and features that are relevant to probable\npathology in mammo-grams. Next, these features are quantified and fused into\nnew, integrated radio-logical systems that exhibit embedded digital signal\nprocessing, in order to improve the final result and minimize the radiological\ndose for the patient. In a higher level, special algorithms are designed for\ndetecting and encoding these clinically interest-ing imaging features, in order\nto be used as input to advanced pattern classifiers and machine learning\nmodels. Finally, these approaches are extended in multi-classifier models under\nthe scope of Game Theory and optimum collective deci-sion, in order to produce\nefficient solutions for combining classifiers with minimum computational costs\nfor advanced diagnostic systems. The material covered in this thesis is related\nto a total of 18 published papers, 6 in scientific journals and 12 in\ninternational conferences.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2009 03:31:33 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Georgiou", "Harris", ""]]}, {"id": "0910.4214", "submitter": "Sahand Haji Ali Ahmad", "authors": "Sahand Haji Ali Ahmad, Mingyan Liu, Yunnan Wu", "title": "Congestion games with resource reuse and applications in spectrum\n  sharing", "comments": "9 pages, 3 figures, International Conference on Game Theory for\n  Networks (GameNets), May 2009, Istanbul, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider an extension to the classical definition of\ncongestion games (CG) in which multiple users share the same set of resources\nand their payoff for using any resource is a function of the total number of\nusers sharing it. The classical congestion games enjoy some very appealing\nproperties, including the existence of a Nash equilibrium and that every\nimprovement path is finite and leads to such a NE (also called the finite\nimprovement property or FIP), which is also a local optimum to a potential\nfunction. On the other hand, this class of games does not model well the\ncongestion or resource sharing in a wireless context, a prominent feature of\nwhich is spatial reuse. What this translates to in the context of a congestion\ngame is that a users payoff for using a resource (interpreted as a channel) is\na function of the its number of its interfering users sharing that channel,\nrather than the total number among all users. This makes the problem quite\ndifferent. We will call this the congestion game with resource reuse (CG-RR).\nIn this paper we study intrinsic properties of such a game; in particular, we\nseek to address under what conditions on the underlying network this game\npossesses the FIP or NE. We also discuss the implications of these results when\napplied to wireless spectrum sharing\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2009 01:47:39 GMT"}], "update_date": "2009-10-23", "authors_parsed": [["Ahmad", "Sahand Haji Ali", ""], ["Liu", "Mingyan", ""], ["Wu", "Yunnan", ""]]}, {"id": "0910.4618", "submitter": "Jaeok Park", "authors": "Jaeok Park and Mihaela van der Schaar", "title": "A Game Theoretic Analysis of Incentives in Content Production and\n  Sharing over Peer-to-Peer Networks", "comments": "31 pages, 3 figures, 1 table", "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, vol. 4, no.\n  4, pp. 704-717, Aug. 2010", "doi": "10.1109/JSTSP.2010.2048609", "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated content can be distributed at a low cost using peer-to-peer\n(P2P) networks, but the free-rider problem hinders the utilization of P2P\nnetworks. In order to achieve an efficient use of P2P networks, we investigate\nfundamental issues on incentives in content production and sharing using game\ntheory. We build a basic model to analyze non-cooperative outcomes without an\nincentive scheme and then use different game formulations derived from the\nbasic model to examine five incentive schemes: cooperative, payment, repeated\ninteraction, intervention, and enforced full sharing. The results of this paper\nshow that 1) cooperative peers share all produced content while non-cooperative\npeers do not share at all without an incentive scheme; 2) a cooperative scheme\nallows peers to consume more content than non-cooperative outcomes do; 3) a\ncooperative outcome can be achieved among non-cooperative peers by introducing\nan incentive scheme based on payment, repeated interaction, or intervention;\nand 4) enforced full sharing has ambiguous welfare effects on peers. In\naddition to describing the solutions of different formulations, we discuss\nenforcement and informational requirements to implement each solution, aiming\nto offer a guideline for protocol designers when designing incentive schemes\nfor P2P networks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2009 04:50:31 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2010 19:04:00 GMT"}], "update_date": "2010-08-03", "authors_parsed": [["Park", "Jaeok", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "0910.4699", "submitter": "Ariel  Procaccia", "authors": "Noga Alon, Felix Fischer, Ariel D. Procaccia, Moshe Tennenholtz", "title": "Sum of Us: Strategyproof Selection from the Selectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider directed graphs over a set of n agents, where an edge (i,j) is\ntaken to mean that agent i supports or trusts agent j. Given such a graph and\nan integer k\\leq n, we wish to select a subset of k agents that maximizes the\nsum of indegrees, i.e., a subset of k most popular or most trusted agents. At\nthe same time we assume that each individual agent is only interested in being\nselected, and may misreport its outgoing edges to this end. This problem\nformulation captures realistic scenarios where agents choose among themselves,\nwhich can be found in the context of Internet search, social networks like\nTwitter, or reputation systems like Epinions.\n  Our goal is to design mechanisms without payments that map each graph to a\nk-subset of agents to be selected and satisfy the following two constraints:\nstrategyproofness, i.e., agents cannot benefit from misreporting their outgoing\nedges, and approximate optimality, i.e., the sum of indegrees of the selected\nsubset of agents is always close to optimal. Our first main result is a\nsurprising impossibility: for k \\in {1,...,n-1}, no deterministic strategyproof\nmechanism can provide a finite approximation ratio. Our second main result is a\nrandomized strategyproof mechanism with an approximation ratio that is bounded\nfrom above by four for any value of k, and approaches one as k grows.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2009 02:01:09 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Alon", "Noga", ""], ["Fischer", "Felix", ""], ["Procaccia", "Ariel D.", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "0910.5107", "submitter": "Arno Pauly", "authors": "Arno Pauly", "title": "The Complexity of Iterated Strategy Elimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computational complexity of the question whether a certain\nstrategy can be removed from a game by means of iterated elimination of\ndominated strategies. In particular, we study the influence of different\ndefinitions of domination and of the number of different payoff values. In\naddition, the consequence of restriction to constant-sum games is shown.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2009 12:40:17 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2010 12:12:28 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Pauly", "Arno", ""]]}, {"id": "0910.5426", "submitter": "Alonso Silva Allende", "authors": "Alonso Silva, Eitan Altman, Pierre Bernhard, Merouane Debbah", "title": "Continuum Equilibria and Global Optimization for Routing in Dense Static\n  Ad Hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider massively dense ad hoc networks and study their continuum limits\nas the node density increases and as the graph providing the available routes\nbecomes a continuous area with location and congestion dependent costs. We\nstudy both the global optimal solution as well as the non-cooperative routing\nproblem among a large population of users where each user seeks a path from its\norigin to its destination so as to minimize its individual cost. Finally, we\nseek for a (continuum version of the) Wardrop equilibrium. We first show how to\nderive meaningful cost models as a function of the scaling properties of the\ncapacity of the network and of the density of nodes. We present various\nsolution methodologies for the problem: (1) the viscosity solution of the\nHamilton-Jacobi-Bellman equation, for the global optimization problem, (2) a\nmethod based on Green's Theorem for the least cost problem of an individual,\nand (3) a solution of the Wardrop equilibrium problem using a transformation\ninto an equivalent global optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 16:47:51 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2009 14:11:52 GMT"}], "update_date": "2009-10-29", "authors_parsed": [["Silva", "Alonso", ""], ["Altman", "Eitan", ""], ["Bernhard", "Pierre", ""], ["Debbah", "Merouane", ""]]}, {"id": "0910.5643", "submitter": "Alonso Silva Allende", "authors": "Alonso Silva, Eitan Altman, Merouane Debbah, Giuseppa Alfano", "title": "Magnetworks: how mobility impacts the design of Mobile Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the optimal placement and optimal number of active\nrelay nodes through the traffic density in mobile sensor ad-hoc networks. We\nconsider a setting in which a set of mobile sensor sources is creating data and\na set of mobile sensor destinations receiving that data. We make the assumption\nthat the network is massively dense, i.e., there are so many sources,\ndestinations, and relay nodes, that it is best to describe the network in terms\nof macroscopic parameters, such as their spatial density, rather than in terms\nof microscopic parameters, such as their individual placements.\n  We focus on a particular physical layer model that is characterized by the\nfollowing assumptions: i) the nodes must only transport the data from the\nsources to the destinations, and do not need to sense the data at the sources,\nor deliver them at the destinations once the data arrive at their physical\nlocations, and ii) the nodes have limited bandwidth available to them, but they\nuse it optimally to locally achieve the network capacity.\n  In this setting, the optimal distribution of nodes induces a traffic density\nthat resembles the electric displacement that will be created if we substitute\nthe sources and destinations with positive and negative charges respectively.\nThe analogy between the two settings is very tight and have a direct\ninterpretation in wireless sensor networks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2009 14:02:45 GMT"}], "update_date": "2009-10-30", "authors_parsed": [["Silva", "Alonso", ""], ["Altman", "Eitan", ""], ["Debbah", "Merouane", ""], ["Alfano", "Giuseppa", ""]]}, {"id": "0910.5714", "submitter": "Aaron D. Jaggard", "authors": "Joan Feigenbaum, Aaron D. Jaggard, and Michael Schapira", "title": "Approximate Privacy: Foundations and Quantification", "comments": "33 pages, seven figures, two tables. Changes in version 2 include an\n  expanded discussion of other approaches to approximate privacy and added\n  acknowledgements", "journal-ref": null, "doi": null, "report-no": "DIMACS TR 2009-14", "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing use of computers and networks in business, government, recreation,\nand almost all aspects of daily life has led to a proliferation of online\nsensitive data about individuals and organizations. Consequently, concern about\nthe privacy of these data has become a top priority, particularly those data\nthat are created and used in electronic commerce. There have been many\nformulations of privacy and, unfortunately, many negative results about the\nfeasibility of maintaining privacy of sensitive data in realistic networked\nenvironments. We formulate communication-complexity-based definitions, both\nworst-case and average-case, of a problem's privacy-approximation ratio. We use\nour definitions to investigate the extent to which approximate privacy is\nachievable in two standard problems: the second-price Vickrey auction and the\nmillionaires problem of Yao.\n  For both the second-price Vickrey auction and the millionaires problem, we\nshow that not only is perfect privacy impossible or infeasibly costly to\nachieve, but even close approximations of perfect privacy suffer from the same\nlower bounds. By contrast, we show that, if the values of the parties are drawn\nuniformly at random from {0,...,2^k-1}, then, for both problems, simple and\nnatural communication protocols have privacy-approximation ratios that are\nlinear in k (i.e., logarithmic in the size of the space of possible inputs). We\nconjecture that this improved privacy-approximation ratio is achievable for any\nprobability distribution.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2009 19:48:17 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2010 19:06:59 GMT"}], "update_date": "2010-06-10", "authors_parsed": [["Feigenbaum", "Joan", ""], ["Jaggard", "Aaron D.", ""], ["Schapira", "Michael", ""]]}]