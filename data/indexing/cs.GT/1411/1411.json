[{"id": "1411.0059", "submitter": "Nicolas Stier-Moses", "authors": "E. Nikolova and N. Stier-Moses", "title": "The Burden of Risk Aversion in Mean-Risk Selfish Routing", "comments": "21 pages, 4 figures", "journal-ref": "Proceedings of the Sixteenth ACM Conference on Economics and\n  Computation. Association for Computing Machinery, New York, NY, USA, 489-506,\n  2015", "doi": "10.1145/2764468.2764485", "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering congestion games with uncertain delays, we compute the\ninefficiency introduced in network routing by risk-averse agents. At\nequilibrium, agents may select paths that do not minimize the expected latency\nso as to obtain lower variability. A social planner, who is likely to be more\nrisk neutral than agents because it operates at a longer time-scale, quantifies\nsocial cost with the total expected delay along routes. From that perspective,\nagents may make suboptimal decisions that degrade long-term quality. We define\nthe {\\em price of risk aversion} (PRA) as the worst-case ratio of the social\ncost at a risk-averse Wardrop equilibrium to that where agents are\nrisk-neutral. For networks with general delay functions and a single\nsource-sink pair, we show that the PRA depends linearly on the agents' risk\ntolerance and on the degree of variability present in the network. In contrast\nto the {\\em price of anarchy}, in general the PRA increases when the network\ngets larger but it does not depend on the shape of the delay functions. To get\nthis result we rely on a combinatorial proof that employs alternating paths\nthat are reminiscent of those used in max-flow algorithms. For {\\em\nseries-parallel} (SP) graphs, the PRA becomes independent of the network\ntopology and its size. As a result of independent interest, we prove that for\nSP networks with deterministic delays, Wardrop equilibria {\\em maximize} the\nshortest-path objective among all feasible flows.\n", "versions": [{"version": "v1", "created": "Sat, 1 Nov 2014 03:29:59 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 20:59:23 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Nikolova", "E.", ""], ["Stier-Moses", "N.", ""]]}, {"id": "1411.0198", "submitter": "Flion Tang", "authors": "Changbing Tang, Ang Li, and Xiang Li", "title": "When reputation enforces evolutionary cooperation in unreliable MANETs", "comments": "12pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In self-organized mobile ad hoc networks (MANETs), network functions rely on\ncooperation of self-interested nodes, where a challenge is to enforce their\nmutual cooperation. In this paper, we study cooperative packet forwarding in a\none-hop unreliable channel which results from loss of packets and noisy\nobservation of transmissions. We propose an indirect reciprocity framework\nbased on evolutionary game theory, and enforce cooperation of packet forwarding\nstrategies in both structured and unstructured MANETs. Furthermore, we analyze\nthe evolutionary dynamics of cooperative strategies, and derive the threshold\nof benefit-to-cost ratio to guarantee the convergence of cooperation. The\nnumerical simulations verify that the proposed evolutionary game theoretic\nsolution enforces cooperation when the benefit-to-cost ratio of the altruistic\nexceeds the critical condition. In addition, the network throughput performance\nof our proposed strategy in structured MANETs is measured, which is in close\nagreement with that of the full cooperative strategy.\n", "versions": [{"version": "v1", "created": "Sun, 2 Nov 2014 03:13:23 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Tang", "Changbing", ""], ["Li", "Ang", ""], ["Li", "Xiang", ""]]}, {"id": "1411.0349", "submitter": "Vladimir Gurvcih", "authors": "Vladimir Gurvich and Vladimir Oudalov", "title": "A four-person chess-like game without Nash equilibria in pure stationary\n  strategies", "comments": "9 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we give an example of a four-person finite positional game\nwith perfect information that has no positions of chance and no Nash equilibria\nin pure stationary strategies. The corresponding directed graph has only one\ndirected cycle and only five terminal positions.\n  It remains open: (i) if the number $n$ of the players can be reduced from $4$\nto $3$, (ii) if the number $p$ of the terminals can be reduced from $5$ to $4$,\nand most important, (iii) whether it is possible to get a similar example in\nwhich the outcome $c$ corresponding to all (possibly, more than one) directed\ncycles is worse than every terminal for each player.\n  Yet, it is known that (j) $n$ cannot be reduced to $2$, (jj) $p$ cannot be\nreduced to $3$, and (jjj) there can be no similar example in which each player\nmakes a decision in a unique position.\n  Keywords: stochastic, positional, chess-like, transition-free games with\nperfect information and without moves of chance; Nash equilibrium, directed\ncycles (dicycles), terminal position.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 03:07:33 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Gurvich", "Vladimir", ""], ["Oudalov", "Vladimir", ""]]}, {"id": "1411.0710", "submitter": "Eric Bax", "authors": "Valeria Stourm and Eric Bax", "title": "Incorporating Hidden Costs of Annoying Ads in Display Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media publisher platforms often face an effectiveness-nuisance tradeoff: more\nannoying ads can be more effective for some advertisers because of their\nability to attract attention, but after attracting viewers' attention, their\nnuisance to viewers can decrease engagement with the platform over time. With\nthe rise of mobile technology and ad blockers, many platforms are becoming\nincreasingly concerned about how to improve monetization through digital ads\nwhile improving viewer experience.\n  We study an online ad auction mechanism that incorporates a charge for ad\nimpact on user experience as a criterion for ad selection and pricing. Like a\nPigovian tax, the charge causes advertisers to internalize the hidden cost of\nforegone future platform revenue due to ad impact on user experience. Over\ntime, the mechanism provides an incentive for advertisers to develop ads that\nare effective while offering viewers a more pleasant experience. We show that\nadopting the mechanism can simultaneously benefit the publisher, advertisers,\nand viewers, even in the short term.\n  Incorporating a charge for ad impact can increase expected advertiser profits\nif enough advertisers compete. A stronger effectiveness-nuisance tradeoff,\nmeaning that ad effectiveness is more strongly associated with negative impact\non user experience, increases the amount of competition required for the\nmechanism to benefit advertisers. The findings suggest that the mechanism can\nbenefit the marketplace for ad slots that consistently attract many\nadvertisers.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 21:38:55 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 06:44:28 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Stourm", "Valeria", ""], ["Bax", "Eric", ""]]}, {"id": "1411.0728", "submitter": "Dileep Kalathil", "authors": "Dileep Kalathil, Vivek Borkar, Rahul Jain", "title": "Approachability in Stackelberg Stochastic Games with Vector Costs", "comments": "18 Pages, Submitted to Dynamic Games and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of approachability was introduced by Blackwell [1] in the context\nof vector-valued repeated games. The famous Blackwell's approachability theorem\nprescribes a strategy for approachability, i.e., for `steering' the average\ncost of a given agent towards a given target set, irrespective of the\nstrategies of the other agents. In this paper, motivated by the multi-objective\noptimization/decision making problems in dynamically changing environments, we\naddress the approachability problem in Stackelberg stochastic games with vector\nvalued cost functions. We make two main contributions. Firstly, we give a\nsimple and computationally tractable strategy for approachability for\nStackelberg stochastic games along the lines of Blackwell's. Secondly, we give\na reinforcement learning algorithm for learning the approachable strategy when\nthe transition kernel is unknown. We also recover as a by-product Blackwell's\nnecessary and sufficient condition for approachability for convex sets in this\nset up and thus a complete characterization. We also give sufficient conditions\nfor non-convex sets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 22:59:11 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 18:05:17 GMT"}, {"version": "v3", "created": "Tue, 21 Jun 2016 00:43:57 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Kalathil", "Dileep", ""], ["Borkar", "Vivek", ""], ["Jain", "Rahul", ""]]}, {"id": "1411.0835", "submitter": "Mickael Randour", "authors": "Mickael Randour and Jean-Fran\\c{c}ois Raskin and Ocan Sankur", "title": "Variations on the Stochastic Shortest Path Problem", "comments": "Invited paper for VMCAI 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this invited contribution, we revisit the stochastic shortest path\nproblem, and show how recent results allow one to improve over the classical\nsolutions: we present algorithms to synthesize strategies with multiple\nguarantees on the distribution of the length of paths reaching a given target,\nrather than simply minimizing its expected value. The concepts and algorithms\nthat we propose here are applications of more general results that have been\nobtained recently for Markov decision processes and that are described in a\nseries of recent papers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 09:40:06 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Randour", "Mickael", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""]]}, {"id": "1411.0944", "submitter": "Sascha Kurz", "authors": "Josep Freixas and Sascha Kurz", "title": "The cost of getting local monotonicity", "comments": "26 pages, 2 figures, 1 table", "journal-ref": null, "doi": "10.1016/j.ejor.2015.11.030", "report-no": null, "categories": "cs.GT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manfred Holler introduced the Public Good index as a proposal to divide a\npublic good among players. In its unnormalized version, i.e., the raw measure,\nit counts the number of times that a player belongs to a minimal winning\ncoalition. Unlike the Banzhaf index, it does not count the remaining winning\ncoalitions in which the player is crucial. Holler noticed that his index does\nnot satisfy local monotonicity, a fact that can be seen either as a major\ndrawback or as an advantage.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 15:43:18 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Freixas", "Josep", ""], ["Kurz", "Sascha", ""]]}, {"id": "1411.0998", "submitter": "Justin Hsu", "authors": "Justin Hsu, Zhiyi Huang, Aaron Roth, Zhiwei Steven Wu", "title": "Jointly Private Convex Programming", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611974331.ch43", "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an extremely general method for approximately\nsolving a large family of convex programs where the solution can be divided\nbetween different agents, subject to joint differential privacy. This class\nincludes multi-commodity flow problems, general allocation problems, and\nmulti-dimensional knapsack problems, among other examples. The accuracy of our\nalgorithm depends on the \\emph{number} of constraints that bind between\nindividuals, but crucially, is \\emph{nearly independent} of the number of\nprimal variables and hence the number of agents who make up the problem. As the\nnumber of agents in a problem grows, the error we introduce often becomes\nnegligible.\n  We also consider the setting where agents are strategic and have preferences\nover their part of the solution. For any convex program in this class that\nmaximizes \\emph{social welfare}, there is a generic reduction that makes the\ncorresponding optimization \\emph{approximately dominant strategy truthful} by\ncharging agents prices for resources as a function of the approximately optimal\ndual variables, which are themselves computed under differential privacy. Our\nresults substantially expand the class of problems that are known to be\nsolvable under both privacy and incentive constraints.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 18:46:50 GMT"}, {"version": "v2", "created": "Wed, 5 Nov 2014 18:53:06 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hsu", "Justin", ""], ["Huang", "Zhiyi", ""], ["Roth", "Aaron", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1411.1127", "submitter": "Paul Christiano", "authors": "Paul Christiano", "title": "Provably Manipulation-Resistant Reputation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a community of users who must make periodic decisions about\nwhether to interact with one another. We propose a protocol which allows honest\nusers to reliably interact with each other, while limiting the damage done by\neach malicious or incompetent user. The worst-case cost per user is sublinear\nin the average number of interactions per user and is independent of the number\nof users. Our guarantee holds simultaneously for every group of honest users.\nFor example, multiple groups of users with incompatible tastes or preferences\ncan coexist.\n  As a motivating example, we consider a game where players have periodic\nopportunities to do one another favors but minimal ability to determine when a\nfavor was done. In this setting, our protocol achieves nearly optimal\ncollective welfare while remaining resistant to exploitation.\n  Our results also apply to a collaborative filtering setting where users must\nmake periodic decisions about whether to interact with resources such as movies\nor restaurants. In this setting, we guarantee that any set of honest users\nachieves a payoff nearly as good as if they had identified the optimal set of\nitems in advance and then chosen to interact only with resources from that set.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 01:28:47 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Christiano", "Paul", ""]]}, {"id": "1411.1152", "submitter": "Demian Pouzo", "authors": "Ignacio Esponda and Demian Pouzo", "title": "Berk-Nash Equilibrium: A Framework for Modeling Agents with Misspecified\n  Models", "comments": "The statement of Theorem 3 in the previous version was corrected. We\n  thank Yuichi Yamamoto for pointing out this correction to us", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an equilibrium framework that relaxes the standard assumption that\npeople have a correctly-specified view of their environment. Each player is\ncharacterized by a (possibly misspecified) subjective model, which describes\nthe set of feasible beliefs over payoff-relevant consequences as a function of\nactions. We introduce the notion of a Berk-Nash equilibrium: Each player\nfollows a strategy that is optimal given her belief, and her belief is\nrestricted to be the best fit among the set of beliefs she considers possible.\nThe notion of best fit is formalized in terms of minimizing the\nKullback-Leibler divergence, which is endogenous and depends on the equilibrium\nstrategy profile. Standard solution concepts such as Nash equilibrium and\nself-confirming equilibrium constitute special cases where players have\ncorrectly-specified models. We provide a learning foundation for Berk-Nash\nequilibrium by extending and combining results from the statistics literature\non misspecified learning and the economics literature on learning in games.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 05:03:24 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2015 04:31:29 GMT"}, {"version": "v3", "created": "Sat, 7 May 2016 15:17:12 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 02:34:36 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Esponda", "Ignacio", ""], ["Pouzo", "Demian", ""]]}, {"id": "1411.1367", "submitter": "Xavier Mora", "authors": "Rosa Camps, Xavier Mora, Laia Saumell", "title": "Choosing by means of approval-preferential voting. The path-revised\n  approval choice", "comments": "Some references have been added. Two misprints have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approval-preferential voting is problematical since it combines two different\nkinds of information that could by themselves lead to different choices. This\narticle analyses the problem and studies a new proposal to deal with it. The\nexisting methods are overviewed with special attention to several desirable\nproperties that are not always met. Particular emphasis is made on certain\nrather unknown views of Condorcet about this subject. The proposed procedure\ndefinitely aims for a choice in the spirit of approval voting. However, it\nstill makes use of the preferential information so as to improve the approval\none. This is done by means of the path scores, in common to Schulze's method\nfor preferential voting. The resulting method, that we call path-revised\napproval choice, is shown to enjoy several good properties. In particular, it\nfulfils in a well-defined sense Condorcet's latest view that a surely good\noption should prevail over a doubtfully best one.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 23:55:05 GMT"}, {"version": "v2", "created": "Sun, 8 May 2016 21:33:53 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 15:47:44 GMT"}, {"version": "v4", "created": "Sat, 9 Jan 2021 15:29:54 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Camps", "Rosa", ""], ["Mora", "Xavier", ""], ["Saumell", "Laia", ""]]}, {"id": "1411.1379", "submitter": "Christos Tzamos", "authors": "Christos Tzamos and Christopher A. Wilkens", "title": "The Value of Knowing Your Enemy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many auction settings implicitly or explicitly require that bidders are\ntreated equally ex-ante. This may be because discrimination is philosophically\nor legally impermissible, or because it is practically difficult to implement\nor impossible to enforce. We study so-called {\\em anonymous} auctions to\nunderstand the revenue tradeoffs and to develop simple anonymous auctions that\nare approximately optimal.\n  We consider digital goods settings and show that the optimal anonymous,\ndominant strategy incentive compatible auction has an intuitive structure ---\nimagine that bidders are randomly permuted before the auction, then infer a\nposterior belief about bidder i's valuation from the values of other bidders\nand set a posted price that maximizes revenue given this posterior.\n  We prove that no anonymous mechanism can guarantee an approximation better\nthan O(n) to the optimal revenue in the worst case (or O(log n) for regular\ndistributions) and that even posted price mechanisms match those guarantees.\nUnderstanding that the real power of anonymous mechanisms comes when the\nauctioneer can infer the bidder identities accurately, we show a tight O(k)\napproximation guarantee when each bidder can be confused with at most k \"higher\ntypes\". Moreover, we introduce a simple mechanism based on n target prices that\nis asymptotically optimal and build on this mechanism to extend our results to\nm-unit auctions and sponsored search.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 19:51:50 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Tzamos", "Christos", ""], ["Wilkens", "Christopher A.", ""]]}, {"id": "1411.1381", "submitter": "Balasubramanian Sivan", "authors": "Shuchi Chawla, Nikhil R. Devanur, Anna Karlin, Balasubramanian Sivan", "title": "How to sell an app: pay-per-play or buy-it-now?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider pricing in settings where a consumer discovers his value for a\ngood only as he uses it, and the value evolves with each use. We explore simple\nand natural pricing strategies for a seller in this setting, under the\nassumption that the seller knows the distribution from which the consumer's\ninitial value is drawn, as well as the stochastic process that governs the\nevolution of the value with each use.\n  We consider the differences between up-front or \"buy-it-now\" pricing (BIN),\nand \"pay-per-play\" (PPP) pricing, where the consumer is charged per use. Our\nresults show that PPP pricing can be a very effective mechanism for price\ndiscrimination, and thereby can increase seller revenue. But it can also be\nadvantageous to the buyers, as a way of mitigating risk. Indeed, this\nmitigation of risk can yield a larger pool of buyers. We also show that the\npractice of offering free trials is largely beneficial.\n  We consider two different stochastic processes for how the buyer's value\nevolves: In the first, the key random variable is how long the consumer remains\ninterested in the product. In the second process, the consumer's value evolves\naccording to a random walk or Brownian motion with reflection at 1, and\nabsorption at 0.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 19:53:42 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Chawla", "Shuchi", ""], ["Devanur", "Nikhil R.", ""], ["Karlin", "Anna", ""], ["Sivan", "Balasubramanian", ""]]}, {"id": "1411.1652", "submitter": "Felix Goldberg", "authors": "Felix Goldberg", "title": "Chip-firing may be much faster than you think", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new bound (Theorem \\ref{thm:main}) for the duration of the chip-firing game\nwith $N$ chips on a $n$-vertex graph is obtained, by a careful analysis of the\npseudo-inverse of the discrete Laplacian matrix of the graph. This new bound is\nexpressed in terms of the entries of the pseudo-inverse.\n  It is shown (Section 5) to be always better than the classic bound due to\nBj{\\\"o}rner, Lov\\'{a}sz and Shor. In some cases the improvement is dramatic.\n  For instance: for strongly regular graphs the classic and the new bounds\nreduce to $O(nN)$ and $O(n+N)$, respectively. For dense regular graphs -\n$d=(\\frac{1}{2}+\\epsilon)n$ - the classic and the new bounds reduce to $O(N)$\nand $O(n)$, respectively.\n  This is a snapshot of a work in progress, so further results in this vein are\nin the works.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 16:18:01 GMT"}, {"version": "v2", "created": "Mon, 24 Nov 2014 15:11:45 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Goldberg", "Felix", ""]]}, {"id": "1411.1751", "submitter": "Reshef Meir", "authors": "Reshef Meir, David Parkes", "title": "Playing the Wrong Game: Bounding Externalities in Diverse Populations of\n  Agents", "comments": "full version of a paper accepted to AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of multiagent systems can be affected by mistakes or\nbehavioral biases (e.g., risk-aversion, altruism, toll-sensitivity), with some\nagents playing the \"wrong game.\" This can change the set of equilibria, and may\nin turn harm or improve the social welfare of agents in the system. We are\ninterested in bounding what we call the biased price of anarchy (BPoA) in\npopulations with diverse agent behaviors, which is the ratio between welfare in\nthe \"wrong\" equilibrium and optimal welfare.\n  We study nonatomic routing games, and derive an externality bound that\ndepends on a key topological parameter of the underlying network.\n  We then prove two general BPoA bounds for games with diverse populations: one\nthat relies on the network structure and the average bias of all agents in the\npopulation, and one that is independent of the structure but depends on the\nmaximal bias. Both types of bounds can be combined with known results to derive\nconcrete BPoA bounds for a variety of specific behaviors (e.g., varied levels\nof risk-aversion).\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 19:28:57 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 15:07:54 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2015 19:46:30 GMT"}, {"version": "v4", "created": "Sat, 21 May 2016 19:46:51 GMT"}, {"version": "v5", "created": "Thu, 19 Jan 2017 14:11:06 GMT"}, {"version": "v6", "created": "Tue, 13 Mar 2018 12:41:33 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Meir", "Reshef", ""], ["Parkes", "David", ""]]}, {"id": "1411.2036", "submitter": "Balasubramanian Sivan", "authors": "Moshe Babaioff, Renato Paes Leme, Balasubramanian Sivan", "title": "Price Competition, Fluctuations, and Welfare Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various markets where sellers compete in price, price oscillations are\nobserved rather than convergence to equilibrium. Such fluctuations have been\nempirically observed in the retail market for gasoline, in airline pricing and\nin the online sale of consumer goods. Motivated by this, we study a model of\nprice competition in which an equilibrium rarely exists. We seek to analyze the\nwelfare, despite the nonexistence of an equilibrium, and present welfare\nguarantees as a function of the market power of the sellers.\n  We first study best response dynamics in markets with sellers that provide a\nhomogeneous good, and show that except for a modest number of initial rounds,\nthe welfare is guaranteed to be high. We consider two variations: in the first\nthe sellers have full information about the valuation of the buyer. Here we\nshow that if there are $n$ items available across all sellers and $n_{\\max}$ is\nthe maximum number of items controlled by any given seller, the ratio of the\noptimal welfare to the achieved welfare will be at most\n$\\log(\\frac{n}{n-n_{\\max}+1})+1$. As the market power of the largest seller\ndiminishes, the welfare becomes closer to optimal. In the second variation we\nconsider an extended model where sellers have uncertainty about the buyer's\nvaluation. Here we similarly show that the welfare improves as the market power\nof the largest seller decreases, yet with a worse ratio of\n$\\frac{n}{n-n_{\\max}+1}$. The exponential gap in welfare between the two\nvariations quantifies the value of accurately learning the buyer valuation.\n  Finally, we show that extending our results to heterogeneous goods in general\nis not possible. Even for the simple class of $k$-additive valuations, there\nexists a setting where the welfare approximates the optimal welfare within any\nnon-zero factor only for $O(1/s)$ fraction of the time, where $s$ is the number\nof sellers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 21:16:06 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2015 15:05:46 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Babaioff", "Moshe", ""], ["Leme", "Renato Paes", ""], ["Sivan", "Balasubramanian", ""]]}, {"id": "1411.2079", "submitter": "Nick Gravin", "authors": "Ning Chen, Nick Gravin, Pinyan Lu", "title": "Competitive analysis via benchmark decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a uniform approach for the design and analysis of prior-free\ncompetitive auctions and online auctions. Our philosophy is to view the\nbenchmark function as a variable parameter of the model and study a broad class\nof functions instead of a individual target benchmark. We consider a multitude\nof well-studied auction settings, and improve upon a few previous results.\n  (1) Multi-unit auctions. Given a $\\beta$-competitive unlimited supply\nauction, the best previously known multi-unit auction is $2\\beta$-competitive.\nWe design a $(1+\\beta)$-competitive auction reducing the ratio from $4.84$ to\n$3.24$. These results carry over to matroid and position auctions.\n  (2) General downward-closed environments. We design a $6.5$-competitive\nauction improving upon the ratio of $7.5$. Our auction is noticeably simpler\nthan the previous best one.\n  (3) Unlimited supply online auctions. Our analysis yields an auction with a\ncompetitive ratio of $4.12$, which significantly narrows the margin of\n$[4,4.84]$ previously known for this problem.\n  A particularly important tool in our analysis is a simple decomposition\nlemma, which allows us to bound the competitive ratio against a sum of\nbenchmark functions. We use this lemma in a \"divide and conquer\" fashion by\ndividing the target benchmark into the sum of simpler functions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 04:30:45 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Chen", "Ning", ""], ["Gravin", "Nick", ""], ["Lu", "Pinyan", ""]]}, {"id": "1411.2139", "submitter": "Yuanzhang Xiao", "authors": "Yuanzhang Xiao, Florian D\\\"orfler, Mihaela van der Schaar", "title": "Incentive Design in Peer Review: Rating and Repeated Endogenous Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review (e.g., grading assignments in Massive Open Online Courses\n(MOOCs), academic paper review) is an effective and scalable method to evaluate\nthe products (e.g., assignments, papers) of a large number of agents when the\nnumber of dedicated reviewing experts (e.g., teaching assistants, editors) is\nlimited. Peer review poses two key challenges: 1) identifying the reviewers'\nintrinsic capabilities (i.e., adverse selection) and 2) incentivizing the\nreviewers to exert high effort (i.e., moral hazard). Some works in mechanism\ndesign address pure adverse selection using one-shot matching rules, and pure\nmoral hazard was addressed in repeated games with exogenously given and fixed\nmatching rules. However, in peer review systems exhibiting both adverse\nselection and moral hazard, one-shot or exogenous matching rules do not link\nagents' current behavior with future matches and future payoffs, and as we\nprove, will induce myopic behavior (i.e., exerting the lowest effort) resulting\nin the lowest review quality.\n  In this paper, we propose for the first time a solution that simultaneously\nsolves adverse selection and moral hazard. Our solution exploits the repeated\ninteractions of agents, utilizes ratings to summarize agents' past review\nquality, and designs matching rules that endogenously depend on agents'\nratings. Our proposed matching rules are easy to implement and require no\nknowledge about agents' private information (e.g., their benefit and cost\nfunctions). Yet, they are effective in guiding the system to an equilibrium\nwhere the agents are incentivized to exert high effort and receive ratings that\nprecisely reflect their review quality. Using several illustrative examples, we\nquantify the significant performance gains obtained by our proposed mechanism\nas compared to existing one-shot or exogenous matching rules.\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 17:10:44 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Xiao", "Yuanzhang", ""], ["D\u00f6rfler", "Florian", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1411.2498", "submitter": "Elena Veronica Belmega", "authors": "E. Veronica Belmega, Lalitha Sankar, and H. Vincent Poor", "title": "Enabling Data Exchange in Interactive State Estimation under Privacy\n  Constraints", "comments": "submitted to IEEE Journal of Selected Topics in Signal Processing", "journal-ref": null, "doi": "10.1109/JSTSP.2015.2427775", "report-no": null, "categories": "cs.IT cs.GT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collecting agents in large networks, such as the electric power system,\nneed to share information (measurements) for estimating the system state in a\ndistributed manner. However, privacy concerns may limit or prevent this\nexchange leading to a tradeoff between state estimation fidelity and privacy\n(referred to as competitive privacy). This paper builds upon a recent\ninformation-theoretic result (using mutual information to measure privacy and\nmean-squared error to measure fidelity) that quantifies the region of\nachievable distortion-leakage tuples in a two-agent network. The objective of\nthis paper is to study centralized and decentralized mechanisms that can enable\nand sustain non-trivial data exchanges among the agents. A centralized\nmechanism determines the data sharing policies that optimize a network-wide\nobjective function combining the fidelities and leakages at both agents. Using\ncommon-goal games and best-response analysis, the optimal policies allow for\ndistributed implementation. In contrast, in the decentralized setting, repeated\ndiscounted games are shown to naturally enable data exchange without any\ncentral control nor economic incentives. The effect of repetition is modeled by\na time-averaged payoff function at each agent which combines its fidelity and\nleakage at each interaction stage. For both approaches, it is shown that\nnon-trivial data exchange can be sustained for specific fidelity ranges even\nwhen privacy is a limiting factor.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 16:41:28 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Belmega", "E. Veronica", ""], ["Sankar", "Lalitha", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1411.3320", "submitter": "Luis Ortiz", "authors": "Luis E. Ortiz", "title": "On Sparse Discretization for Graphical Games", "comments": "30 pages. Original research note drafted in Dec. 2002 and posted\n  online Spring'03 (http://www.cis.upenn.\n  edu/~mkearns/teaching/cgt/revised_approx_bnd.pdf) as part of a course on\n  computational game theory taught by Prof. Michael Kearns at the University of\n  Pennsylvania; First major revision sent to WINE'10; Current version sent to\n  JAIR on April 25, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper concerns discretization schemes for representing and\ncomputing approximate Nash equilibria, with emphasis on graphical games, but\nbriefly touching on normal-form and poly-matrix games. The main technical\ncontribution is a representation theorem that informally states that to account\nfor every exact Nash equilibrium using a nearby approximate Nash equilibrium on\na grid over mixed strategies, a uniform discretization size linear on the\ninverse of the approximation quality and natural game-representation parameters\nsuffices. For graphical games, under natural conditions, the discretization is\nlogarithmic in the game-representation size, a substantial improvement over the\nlinear dependency previously required. The paper has five other objectives: (1)\ngiven the venue, to highlight the important, but often ignored, role that work\non constraint networks in AI has in simplifying the derivation and analysis of\nalgorithms for computing approximate Nash equilibria; (2) to summarize the\nstate-of-the-art on computing approximate Nash equilibria, with emphasis on\nrelevance to graphical games; (3) to help clarify the distinction between\nsparse-discretization and sparse-support techniques; (4) to illustrate and\nadvocate for the deliberate mathematical simplicity of the formal proof of the\nrepresentation theorem; and (5) to list and discuss important open problems,\nemphasizing graphical-game generalizations, which the AI community is most\nsuitable to solve.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 20:59:07 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Ortiz", "Luis E.", ""]]}, {"id": "1411.3708", "submitter": "Matjaz Perc", "authors": "Xiaojie Chen, Yanling Zhang, Ting-Zhu Huang, Matjaz Perc", "title": "Solving the collective-risk social dilemma with risky assets in\n  well-mixed and structured populations", "comments": "10 two-column pages, 5 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 90 (2014) 052823", "doi": "10.1103/PhysRevE.90.052823", "report-no": null, "categories": "physics.soc-ph cs.GT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the collective-risk social dilemma, players lose their personal endowments\nif contributions to the common pool are too small. This fact alone, however,\ndoes not always deter selfish individuals from defecting. The temptations to\nfree-ride on the prosocial efforts of others are strong because we are\nhardwired to maximize our own fitness regardless of the consequences this might\nhave for the public good. Here we show that the addition of risky assets to the\npersonal endowments, both of which are lost if the collective target is not\nreached, can contribute to solving the collective-risk social dilemma. In\ninfinite well-mixed populations risky assets introduce new stable and unstable\nmixed steady states, whereby the stable mixed steady state converges to full\ncooperation as either the risk of collective failure or the amount of risky\nassets increases. Similarly, in finite well-mixed populations the introduction\nof risky assets enforces configurations where cooperative behavior thrives. In\nstructured populations cooperation is promoted as well, but the distribution of\nassets amongst the groups is crucial. Surprisingly, we find that the completely\nrational allocation of assets only to the most successful groups is not\noptimal, and this regardless of whether the risk of collective failure is high\nor low. Instead, in low-risk situations bounded rational allocation of assets\nworks best, while in high-risk situations the simplest uniform distribution of\nassets among all the groups is optimal. These results indicate that prosocial\nbehavior depends sensitively on the potential losses individuals are likely to\nendure if they fail to cooperate.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 20:51:41 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Chen", "Xiaojie", ""], ["Zhang", "Yanling", ""], ["Huang", "Ting-Zhu", ""], ["Perc", "Matjaz", ""]]}, {"id": "1411.3747", "submitter": "Sunoo Park", "authors": "Pavel Hub\\'a\\v{c}ek, Sunoo Park", "title": "Cryptographically Blinded Games: Leveraging Players' Limitations for\n  Equilibria and Profit", "comments": "This is a working paper, of which an extended abstract appeared in\n  the 15th ACM Conference on Economics and Computation (EC 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we apply methods from cryptography to enable any number of\nmutually distrusting players to implement broad classes of mediated equilibria\nof strategic games without the need for trusted mediation.\n  Our implementation makes use of a (standard) pre-play \"cheap talk\" phase, in\nwhich players engage in free and non-binding communication prior to playing in\nthe original game. In our cheap talk phase, the players execute a secure\nmulti-party computation protocol to sample an action profile from an\nequilibrium of a \"cryptographically blinded\" version of the original game, in\nwhich actions are encrypted. The essence of our approach is to exploit the\npower of encryption to selectively restrict the information available to\nplayers about sampled action profiles, such that these desirable equilibria can\nbe stably achieved. In contrast to previous applications of cryptography to\ngame theory, this work is the first to employ the paradigm of using encryption\nto allow players to benefit from hiding information \\emph{from themselves},\nrather than from others; and we stress that rational players would\n\\emph{choose} to hide the information from themselves.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 21:32:51 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Hub\u00e1\u010dek", "Pavel", ""], ["Park", "Sunoo", ""]]}, {"id": "1411.4384", "submitter": "Anthony Kim", "authors": "Zhiyi Huang and Anthony Kim", "title": "Welfare Maximization with Production Costs: A Primal Dual Approach", "comments": "To appear in the ACM-SIAM Symposium on Discrete Algorithms (SODA),\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online combinatorial auctions with production costs proposed by Blum\net al. using the online primal dual framework. In this model, buyers arrive\nonline, and the seller can produce multiple copies of each item subject to a\nnon-decreasing marginal cost per copy. The goal is to allocate items to\nmaximize social welfare less total production cost. For arbitrary (strictly\nconvex and differentiable) production cost functions, we characterize the\noptimal competitive ratio achievable by online mechanisms/algorithms. We show\nthat online posted pricing mechanisms, which are incentive compatible, can\nachieve competitive ratios arbitrarily close to the optimal, and construct\nlower bound instances on which no online algorithms, not necessarily incentive\ncompatible, can do better. Our positive results improve or match the results in\nseveral previous work, e.g., Bartal et al., Blum et al., and Buchbinder and\nGonen. Our lower bounds apply to randomized algorithms and resolve an open\nproblem by Buchbinder and Gonen.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 07:34:02 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Huang", "Zhiyi", ""], ["Kim", "Anthony", ""]]}, {"id": "1411.4796", "submitter": "Reino Niskanen", "authors": "Vesa Halava, Tero Harju, Reino Niskanen and Igor Potapov", "title": "Weighted automata on infinite words in the context of Attacker-Defender\n  games", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinite-state Attacker-Defender games with reachability\nobjectives. The results of the paper are twofold. Firstly we prove a new\nlanguage-theoretic result for weighted automata on infinite words and show its\nencoding into the framework of Attacker-Defender games. Secondly we use this\nnovel concept to prove undecidability for checking existence of a winning\nstrategy in several low-dimensional mathematical games including vector\nreachability games, word games and braid games.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 10:24:35 GMT"}, {"version": "v2", "created": "Wed, 28 Jan 2015 10:58:34 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2015 13:35:17 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Halava", "Vesa", ""], ["Harju", "Tero", ""], ["Niskanen", "Reino", ""], ["Potapov", "Igor", ""]]}, {"id": "1411.4916", "submitter": "Brendan Lucier", "authors": "Michal Feldman, Nick Gravin, Brendan Lucier", "title": "Combinatorial Auctions via Posted Prices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study anonymous posted price mechanisms for combinatorial auctions in a\nBayesian framework. In a posted price mechanism, item prices are posted, then\nthe consumers approach the seller sequentially in an arbitrary order, each\npurchasing her favorite bundle from among the unsold items at the posted\nprices. These mechanisms are simple, transparent and trivially dominant\nstrategy incentive compatible (DSIC).\n  We show that when agent preferences are fractionally subadditive (which\nincludes all submodular functions), there always exist prices that, in\nexpectation, obtain at least half of the optimal welfare. Our result is\nconstructive: given black-box access to a combinatorial auction algorithm A,\nsample access to the prior distribution, and appropriate query access to the\nsampled valuations, one can compute, in polytime, prices that guarantee at\nleast half of the expected welfare of A. As a corollary, we obtain the first\npolytime (in n and m) constant-factor DSIC mechanism for Bayesian submodular\ncombinatorial auctions, given access to demand query oracles. Our results also\nextend to valuations with complements, where the approximation factor degrades\nlinearly with the level of complementarity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 17:17:57 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Feldman", "Michal", ""], ["Gravin", "Nick", ""], ["Lucier", "Brendan", ""]]}, {"id": "1411.4943", "submitter": "Reshef Meir", "authors": "Reshef Meir, David Parkes", "title": "Congestion Games with Distance-Based Strict Uncertainty", "comments": "The full version of a paper from AAAI'15 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forward a new model of congestion games where agents have uncertainty\nover the routes used by other agents. We take a non-probabilistic approach,\nassuming that each agent knows that the number of agents using an edge is\nwithin a certain range. Given this uncertainty, we model agents who either\nminimize their worst-case cost (WCC) or their worst-case regret (WCR), and\nstudy implications on equilibrium existence, convergence through adaptive play,\nand efficiency. Under the WCC behavior the game reduces to a modified\ncongestion game, and welfare improves when agents have moderate uncertainty.\nUnder WCR behavior the game is not, in general, a congestion game, but we show\nconvergence and efficiency bounds for a simple class of games.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 18:04:58 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 11:45:47 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Meir", "Reshef", ""], ["Parkes", "David", ""]]}, {"id": "1411.5007", "submitter": "Kevin Waugh", "authors": "Kevin Waugh and J. Andrew Bagnell", "title": "A Unified View of Large-scale Zero-sum Equilibrium Computation", "comments": "AAAI Workshop on Computer Poker and Imperfect Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of computing approximate Nash equilibria in large zero-sum\nextensive-form games has received a tremendous amount of attention due mainly\nto the Annual Computer Poker Competition. Immediately after its inception, two\ncompeting and seemingly different approaches emerged---one an application of\nno-regret online learning, the other a sophisticated gradient method applied to\na convex-concave saddle-point formulation. Since then, both approaches have\ngrown in relative isolation with advancements on one side not effecting the\nother. In this paper, we rectify this by dissecting and, in a sense, unify the\ntwo views.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 20:43:39 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Waugh", "Kevin", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1411.5060", "submitter": "Jugal Garg", "authors": "Jugal Garg and Ruta Mehta and Vijay V. Vazirani and Sadra Yazdanbod", "title": "Settling the Complexity of Arrow-Debreu Markets under Leontief and PLC\n  Utilities, using the Classes FIXP and \\Exists-R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper resolves two of the handful of remaining questions on the\ncomputability of market equilibria, a central theme within algorithmic game\ntheory (AGT). Our results are as follows:\n  1. We show FIXP-hardness of computing equilibria in Arrow-Debreu markets\nunder Leontief utility functions, and Arrow-Debreu markets under linear utility\nfunctions and Leontief production sets. We note that these are the first\nFIXP-hardness results ever since the introduction of the class FIXP and the\nhardness of 3-Nash established therein.\n  2. We note that for the problems stated above, the corresponding results\nshowing membership in FIXP were established after imposing suitable sufficiency\nconditions to render the problems total, as is customary in economics. However,\nif all instances are under consideration, then in both cases we prove that the\nproblem of deciding if a given instance admits an equilibrium is\n\\Exists-R-complete, where \\Exists-R is the class of decision problems which can\nbe reduced in polynomial time to Existential Theory of the Reals.\n  3. For Arrow-Debreu markets under Leontief utility functions and a constant\nnumber of agents, we give a polynomial-time algorithm for computing an\nequilibrium. This settles part of an open problem of Devanur and Kannan\n(FOCS'08).\n  We note that PLC utilities are about the most general utilities of interest\nin economics and several fundamental utility functions studied within AGT are\nspecial cases of it. Several important problems, which have been shown to be in\nFIXP, are waiting for proofs of FIXP-hardness. In this context, our technique\nof reducing from 3-Nash to Multivariate Polynomial Equations and then to the\nproblem is likely to be useful in the future.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 23:04:07 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:23:51 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Garg", "Jugal", ""], ["Mehta", "Ruta", ""], ["Vazirani", "Vijay V.", ""], ["Yazdanbod", "Sadra", ""]]}, {"id": "1411.5302", "submitter": "Arvind Merwaday", "authors": "Arvind Merwaday, Murat Yuksel, Thomas Quint, Ismail Guvenc, Walid\n  Saad, and Naim Kapucu", "title": "Incentivizing Spectrum Sharing via Subsidy Regulations", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional regulatory methods for spectrum licensing have been recently\nidentified as one of the causes for the under-utilization of the valuable radio\nspectrum. Governmental agencies such as the Federal Communications Commission\n(FCC) are seeking ways to remove stringent regulatory barriers and facilitate\nbroader access to the spectrum resources. The goal is to allow for an improved\nand ubiquitous sharing of the precious radio spectrum between commercial\nservice providers.\n  In this paper, we propose a novel noncooperative game theoretic approach, to\nshow how to foster more sharing of the radio spectrum via the use of regulatory\npower. We define a two stage game in which the government regulators move\nfirst, followed by the providers. The providers are incentivized by lower\nspectrum allocation fees from the regulators in return for proof-of-sharing.\nThe providers are offered discounted spectrum bands, potentially at different\nlocations, but will be asked to provide coverage to users that are not\nsubscribed to them so as to maintain their subsidy incentives from the\ngovernment. In a simplification of the model, analytical expressions for the\nproviders' perfect equilibrium strategies are derived, and we argue for the\nexistence of the government's part of a perfect equilibrium. Our analysis shows\nthat through subsidization, the government can provide small service providers\na fair chance to compete with the large providers, thereby avoiding\nmonopolization in the market.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 18:22:36 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2014 01:38:22 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Merwaday", "Arvind", ""], ["Yuksel", "Murat", ""], ["Quint", "Thomas", ""], ["Guvenc", "Ismail", ""], ["Saad", "Walid", ""], ["Kapucu", "Naim", ""]]}, {"id": "1411.5712", "submitter": "Ofir Geri", "authors": "Michal Feldman, Ofir Geri", "title": "Do Capacity Constraints Constrain Coalitions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study strong equilibria in symmetric capacitated cost-sharing games. In\nthese games, a graph with designated source $s$ and sink $t$ is given, and each\nedge is associated with some cost. Each agent chooses strategically an $s$-$t$\npath, knowing that the cost of each edge is shared equally between all agents\nusing it. Two variants of cost-sharing games have been previously studied: (i)\ngames where coalitions can form, and (ii) games where edges are associated with\ncapacities; both variants are inspired by real-life scenarios. In this work we\ncombine these variants and analyze strong equilibria (profiles where no\ncoalition can deviate) in capacitated games. This combination gives rise to new\nphenomena that do not occur in the previous variants. Our contribution is\ntwo-fold. First, we provide a topological characterization of networks that\nalways admit a strong equilibrium. Second, we establish tight bounds on the\nefficiency loss that may be incurred due to strategic behavior, as quantified\nby the strong price of anarchy (and stability) measures. Interestingly, our\nresults are qualitatively different than those obtained in the analysis of each\nvariant alone, and the combination of coalitions and capacities entails the\nintroduction of more refined topology classes than previously studied.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 22:27:27 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2015 09:04:45 GMT"}, {"version": "v3", "created": "Wed, 16 Nov 2016 21:48:15 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Feldman", "Michal", ""], ["Geri", "Ofir", ""]]}, {"id": "1411.5795", "submitter": "Tony", "authors": "Tie Luo and Chen-Khong Tham", "title": "Fairness and Social Welfare in Incentivizing Participatory Sensing", "comments": "Game theory; demand-supply model; network economics; stochastic\n  programming; chance-constrained programming", "journal-ref": "Proc. IEEE SECON, June 2012, pp. 425-433", "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Participatory sensing has emerged recently as a promising approach to\nlarge-scale data collection. However, without incentives for users to regularly\ncontribute good quality data, this method is unlikely to be viable in the long\nrun. In this paper, we link incentive to users' demand for consuming compelling\nservices, as an approach complementary to conventional credit or reputation\nbased approaches. With this demand-based principle, we design two incentive\nschemes, Incentive with Demand Fairness (IDF) and Iterative Tank Filling (ITF),\nfor maximizing fairness and social welfare, respectively. Our study shows that\nthe IDF scheme is max-min fair and can score close to 1 on the Jain's fairness\nindex, while the ITF scheme maximizes social welfare and achieves a unique Nash\nequilibrium which is also Pareto and globally optimal. We adopted a game\ntheoretic approach to derive the optimal service demands. Furthermore, to\naddress practical considerations, we use a stochastic programming technique to\nhandle uncertainty that is often encountered in real life situations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 08:46:55 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Luo", "Tie", ""], ["Tham", "Chen-Khong", ""]]}, {"id": "1411.5820", "submitter": "Dietmar Berwanger", "authors": "Dietmar Berwanger and Anup Basil Mathew", "title": "Infinite games with finite knowledge gaps", "comments": "39 pages; 2nd revision; submitted to Information and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite games where several players seek to coordinate under imperfect\ninformation are deemed to be undecidable, unless the information is\nhierarchically ordered among the players.\n  We identify a class of games for which joint winning strategies can be\nconstructed effectively without restricting the direction of information flow.\nInstead, our condition requires that the players attain common knowledge about\nthe actual state of the game over and over again along every play.\n  We show that it is decidable whether a given game satisfies the condition,\nand prove tight complexity bounds for the strategy synthesis problem under\n$\\omega$-regular winning conditions given by parity automata.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 10:45:02 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 11:40:11 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["Berwanger", "Dietmar", ""], ["Mathew", "Anup Basil", ""]]}, {"id": "1411.6147", "submitter": "Peyman Siyari", "authors": "Peyman Siyari, Hassan Aghaeinia", "title": "Distributed Power Control in Multiuser MIMO Networks with Optimal Linear\n  Precoding", "comments": "6 pages, 3 figures, Presented in 7th International Symposium on\n  Telecommunications (IST 2014)", "journal-ref": null, "doi": "10.1109/ISTEL.2014.7000890", "report-no": null, "categories": "cs.IT cs.GT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contractive interference functions introduced by Feyzmahdavian et al. is the\nnewest approach in the analysis and design of distributed power control laws.\nThis approach can be extended to several cases of distributed power control.\nOne of the distributed power control scenarios wherein the contractive\ninterference functions have not been employed is the power control in MIMO\nsystems. In this paper, this scenario will be analyzed. In addition, the\noptimal linear precoder is employed in each user to achieve maximum\npoint-to-point information rate. In our approach, we use the same amount of\nsignaling as the previous methods did. However, we show that the uniqueness of\nNash equilibria is more probable in our approach, suggesting that our proposed\nmethod improves the convergence performance of distributed power control in\nMIMO systems. We also show that the proposed power control algorithm can be\nimplemented asynchronously, which gives a noticeable flexibility to our\nalgorithm given the practical communication limitations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Nov 2014 17:29:01 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Siyari", "Peyman", ""], ["Aghaeinia", "Hassan", ""]]}, {"id": "1411.6148", "submitter": "Edward Lui", "authors": "Samantha Leung and Edward Lui", "title": "Bayesian Mechanism Design with Efficiency, Privacy, and Approximate\n  Truthfulness", "comments": "A preliminary version of this paper appeared in the 8th Workshop on\n  Internet & Network Economics (WINE 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a number of papers relating mechanism design and\nprivacy (e.g., see \\cite{MT07,Xia11,CCKMV11,NST12,NOS12,HK12}). All of these\npapers consider a worst-case setting where there is no probabilistic\ninformation about the players' types. In this paper, we investigate mechanism\ndesign and privacy in the \\emph{Bayesian} setting, where the players' types are\ndrawn from some common distribution. We adapt the notion of \\emph{differential\nprivacy} to the Bayesian mechanism design setting, obtaining \\emph{Bayesian\ndifferential privacy}. We also define a robust notion of approximate\ntruthfulness for Bayesian mechanisms, which we call \\emph{persistent\napproximate truthfulness}. We give several classes of mechanisms (e.g., social\nwelfare mechanisms and histogram mechanisms) that achieve both Bayesian\ndifferential privacy and persistent approximate truthfulness. These classes of\nmechanisms can achieve optimal (economic) efficiency, and do not use any\npayments. We also demonstrate that by considering the above mechanisms in a\nmodified mechanism design model, the above mechanisms can achieve actual\ntruthfulness.\n", "versions": [{"version": "v1", "created": "Sat, 22 Nov 2014 17:36:26 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Leung", "Samantha", ""], ["Lui", "Edward", ""]]}, {"id": "1411.6322", "submitter": "Ioannis Panageas", "authors": "Ruta Mehta and Ioannis Panageas and Georgios Piliouras and Sadra\n  Yazdanbod", "title": "The Complexity of Genetic Diversity", "comments": "24 pages, 2 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC cs.GT math.DS math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in biological systems is whether genetic diversity persists in\nthe long run under evolutionary competition or whether a single dominant\ngenotype emerges. Classic work by Kalmus in 1945 has established that even in\nsimple diploid species (species with two chromosomes) diversity can be\nguaranteed as long as the heterozygote individuals enjoy a selective advantage.\nDespite the classic nature of the problem, as we move towards increasingly\npolymorphic traits (e.g. human blood types) predicting diversity and\nunderstanding its implications is still not fully understood. Our key\ncontribution is to establish complexity theoretic hardness results implying\nthat even in the textbook case of single locus diploid models predicting\nwhether diversity survives or not given its fitness landscape is\nalgorithmically intractable. We complement our results by establishing that\nunder randomly chosen fitness landscapes diversity survives with significant\nprobability. Our results are structurally robust along several dimensions\n(e.g., choice of parameter distribution, different definitions of\nstability/persistence, restriction to typical subclasses of fitness\nlandscapes). Technically, our results exploit connections between game theory,\nnonlinear dynamical systems, complexity theory and biology and establish\nhardness results for predicting the evolution of a deterministic variant of the\nwell known multiplicative weights update algorithm in symmetric coordination\ngames which could be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 01:35:10 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 14:51:53 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Mehta", "Ruta", ""], ["Panageas", "Ioannis", ""], ["Piliouras", "Georgios", ""], ["Yazdanbod", "Sadra", ""]]}, {"id": "1411.7099", "submitter": "Ittay Eyal", "authors": "Ittay Eyal", "title": "The Miner's Dilemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open distributed system can be secured by requiring participants to\npresent proof of work and rewarding them for participation. The Bitcoin digital\ncurrency introduced this mechanism, which is adopted by almost all contemporary\ndigital currencies and related services.\n  A natural process leads participants of such systems to form pools, where\nmembers aggregate their power and share the rewards. Experience with Bitcoin\nshows that the largest pools are often open, allowing anyone to join. It has\nlong been known that a member can sabotage an open pool by seemingly joining it\nbut never sharing its proofs of work. The pool shares its revenue with the\nattacker, and so each of its participants earns less.\n  We define and analyze a game where pools use some of their participants to\ninfiltrate other pools and perform such an attack. With any number of pools,\nno-pool-attacks is not a Nash equilibrium. With two pools, or any number of\nidentical pools, there exists an equilibrium that constitutes a tragedy of the\ncommons where the pools attack one another and all earn less than they would\nhave if none had attacked.\n  For two pools, the decision whether or not to attack is the miner's dilemma,\nan instance of the iterative prisoner's dilemma. The game is played daily by\nthe active Bitcoin pools, which apparently choose not to attack. If this\nbalance breaks, the revenue of open pools might diminish, making them\nunattractive to participants.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 03:44:21 GMT"}, {"version": "v2", "created": "Thu, 27 Nov 2014 01:43:20 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Eyal", "Ittay", ""]]}, {"id": "1411.7472", "submitter": "Yichong Xu", "authors": "Pingzhong Tang, Yifeng Teng, Zihe Wang, Shenke Xiao, Yichong Xu", "title": "Computational issues in time-inconsistent planning", "comments": "20 pages, 7 figures, submitted to EC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-inconsistency refers to a paradox in decision making where agents\nexhibit inconsistent behaviors over time. Examples are procrastination where\nagents tends to costly postpone easy tasks, and abandonments where agents start\na plan and quit in the middle. These behaviors are undesirable in the sense\nthat agents make clearly suboptimal decisions over optimal ones. To capture\nsuch behaviors and more importantly, to quantify inefficiency caused by such\nbehaviors, [Kleinberg & Oren 2014] propose a graph model which is essentially\nsame as the standard planning model except for the cost structure. Using this\nmodel, they initiate the study of several interesting problems: 1) cost ratio:\nthe worst ratio between the actual cost of the agent and the optimal cost, over\nall graph instances; 2) motivating subgraph: how to motivate the agent to reach\nthe goal by deleting nodes and edges; 3) Intermediate rewards: how to motivate\nagents to reach the goal by placing intermediate rewards. Kleinberg and Oren\ngive partial answers to these questions, but the main problems are still open.\nIn fact, they raise these problems explicitly as open problems in their paper.\nIn this paper, we give answers to all three open problems in [Kleinberg & Oren\n2014]. First, we show a tight upper bound of cost ratio for graphs without\nAkerlof's structure, thus confirm the conjecture by Kleinberg and Oren that\nAkerlof's structure is indeed the worst case for cost ratio. Second, we prove\nthat finding a motivating subgraph is NP-hard, showing that it is generally\ninefficient to motivate agents by deleting nodes and edges in the graph. Last\nbut not least, we show that computing a strategy to place minimum amount of\ntotal reward is also NP-hard. Therefore, it is computational inefficient to\nmotivate agents by placing intermediate rewards. The techniques we use to prove\nthese results are nontrivial and of independent interests.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 05:15:08 GMT"}, {"version": "v2", "created": "Wed, 11 Feb 2015 07:41:27 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2015 14:37:34 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Tang", "Pingzhong", ""], ["Teng", "Yifeng", ""], ["Wang", "Zihe", ""], ["Xiao", "Shenke", ""], ["Xu", "Yichong", ""]]}, {"id": "1411.7812", "submitter": "Piotr Faliszewski", "authors": "Jiehua Chen, Piotr Faliszewski, Rolf Niedermeier, Nimrod Talmon", "title": "Elections with Few Voters: Candidate Control Can Be Easy", "comments": "56 pages, short version presented at AAAI-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of candidate control in elections with\nfew voters, that is, we consider the parameterized complexity of candidate\ncontrol in elections with respect to the number of voters as a parameter. We\nconsider both the standard scenario of adding and deleting candidates, where\none asks whether a given candidate can become a winner (or, in the destructive\ncase, can be precluded from winning) by adding or deleting few candidates, as\nwell as a combinatorial scenario where adding/deleting a candidate\nautomatically means adding or deleting a whole group of candidates. Considering\nseveral fundamental voting rules, our results show that the parameterized\ncomplexity of candidate control, with the number of voters as the parameter, is\nmuch more varied than in the setting with many voters.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 11:09:04 GMT"}, {"version": "v2", "created": "Sat, 18 Mar 2017 11:32:11 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Chen", "Jiehua", ""], ["Faliszewski", "Piotr", ""], ["Niedermeier", "Rolf", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1411.7974", "submitter": "Kevin Waugh", "authors": "Kevin Waugh and Dustin Morrill and J. Andrew Bagnell and Michael\n  Bowling", "title": "Solving Games with Functional Regret Estimation", "comments": "AAAI Conference on Artificial Intelligence 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning method for minimizing regret in large\nextensive-form games. The approach learns a function approximator online to\nestimate the regret for choosing a particular action. A no-regret algorithm\nuses these estimates in place of the true regrets to define a sequence of\npolicies.\n  We prove the approach sound by providing a bound relating the quality of the\nfunction approximation and regret of the algorithm. A corollary being that the\nmethod is guaranteed to converge to a Nash equilibrium in self-play so long as\nthe regrets are ultimately realizable by the function approximator. Our\ntechnique can be understood as a principled generalization of existing work on\nabstraction in large games; in our work, both the abstraction as well as the\nequilibrium are learned during self-play. We demonstrate empirically the method\nachieves higher quality strategies than state-of-the-art abstraction techniques\ngiven the same resources.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 18:45:50 GMT"}, {"version": "v2", "created": "Wed, 31 Dec 2014 23:45:22 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Waugh", "Kevin", ""], ["Morrill", "Dustin", ""], ["Bagnell", "J. Andrew", ""], ["Bowling", "Michael", ""]]}]