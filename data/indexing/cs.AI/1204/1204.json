[{"id": "1204.0033", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, Luke K. McDowell, David W. Aha and Jennifer Neville", "title": "Transforming Graph Representations for Statistical Relational Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data representations have become an increasingly important topic\ndue to the recent proliferation of network datasets (e.g., social, biological,\ninformation networks) and a corresponding increase in the application of\nstatistical relational learning (SRL) algorithms to these domains. In this\narticle, we examine a range of representation issues for graph-based relational\ndata. Since the choice of relational data representation for the nodes, links,\nand features can dramatically affect the capabilities of SRL algorithms, we\nsurvey approaches and opportunities for relational representation\ntransformation designed to improve the performance of these algorithms. This\nleads us to introduce an intuitive taxonomy for data representation\ntransformations in relational domains that incorporates link transformation and\nnode transformation as symmetric representation tasks. In particular, the\ntransformation tasks for both nodes and links include (i) predicting their\nexistence, (ii) predicting their label or type, (iii) estimating their weight\nor importance, and (iv) systematically constructing their relevant features. We\nmotivate our taxonomy through detailed examples and use it to survey and\ncompare competing approaches for each of these tasks. We also discuss general\nconditions for transforming links, nodes, and features. Finally, we highlight\nchallenges that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2012 21:38:52 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Rossi", "Ryan A.", ""], ["McDowell", "Luke K.", ""], ["Aha", "David W.", ""], ["Neville", "Jennifer", ""]]}, {"id": "1204.0181", "submitter": "Youssef Bassil", "authors": "Youssef Bassil", "title": "Expert PC Troubleshooter With Fuzzy-Logic And Self-Learning Support", "comments": "LACSC - Lebanese Association for Computational Sciences,\n  http://www.lacsc.org/; International Journal of Artificial Intelligence &\n  Applications (IJAIA), Vol.3, No.2, March 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert systems use human knowledge often stored as rules within the computer\nto solve problems that generally would entail human intelligence. Today, with\ninformation systems turning out to be more pervasive and with the myriad\nadvances in information technologies, automating computer fault diagnosis is\nbecoming so fundamental that soon every enterprise has to endorse it. This\npaper proposes an expert system called Expert PC Troubleshooter for diagnosing\ncomputer problems. The system is composed of a user interface, a rule-base, an\ninference engine, and an expert interface. Additionally, the system features a\nfuzzy-logic module to troubleshoot POST beep errors, and an intelligent agent\nthat assists in the knowledge acquisition process. The proposed system is meant\nto automate the maintenance, repair, and operations (MRO) process, and free-up\nhuman technicians from manually performing routine, laborious, and\ntimeconsuming maintenance tasks. As future work, the proposed system is to be\nparallelized so as to boost its performance and speed-up its various\noperations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2012 09:08:21 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Bassil", "Youssef", ""]]}, {"id": "1204.0274", "submitter": "Mark Woodward", "authors": "Mark P. Woodward and Robert J. Wood", "title": "Learning from Humans as an I-POMDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactive partially observable Markov decision process (I-POMDP) is a\nrecently developed framework which extends the POMDP to the multi-agent setting\nby including agent models in the state space. This paper argues for formulating\nthe problem of an agent learning interactively from a human teacher as an\nI-POMDP, where the agent \\emph{programming} to be learned is captured by random\nvariables in the agent's state space, all \\emph{signals} from the human teacher\nare treated as observed random variables, and the human teacher, modeled as a\ndistinct agent, is explicitly represented in the agent's state space. The main\nbenefits of this approach are: i. a principled action selection mechanism, ii.\na principled belief update mechanism, iii. support for the most common teacher\n\\emph{signals}, and iv. the anticipated production of complex beneficial\ninteractions. The proposed formulation, its benefits, and several open\nquestions are presented.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2012 22:35:00 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Woodward", "Mark P.", ""], ["Wood", "Robert J.", ""]]}, {"id": "1204.0479", "submitter": "Tobias Buer", "authors": "Tobias Buer and J\\\"org Homberger and Hermann Gehring", "title": "A collaborative ant colony metaheuristic for distributed multi-level\n  lot-sizing", "comments": null, "journal-ref": "International Journal of Production Research 51 (17) 2013,\n  5253-5270", "doi": "10.1080/00207543.2013.802822", "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an ant colony optimization metaheuristic for collaborative\nplanning. Collaborative planning is used to coordinate individual plans of\nself-interested decision makers with private information in order to increase\nthe overall benefit of the coalition. The method consists of a new search graph\nbased on encoded solutions. Distributed and private information is integrated\nvia voting mechanisms and via a simple but effective collaborative local search\nprocedure. The approach is applied to a distributed variant of the multi-level\nlot-sizing problem and evaluated by means of 352 benchmark instances from the\nliterature. The proposed approach clearly outperforms existing approaches on\nthe sets of medium and large sized instances. While the best method in the\nliterature so far achieves an average deviation from the best known\nnon-distributed solutions of 46 percent for the set of the largest instances,\nfor example, the presented approach reduces the average deviation to only 5\npercent.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2012 17:44:45 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Buer", "Tobias", ""], ["Homberger", "J\u00f6rg", ""], ["Gehring", "Hermann", ""]]}, {"id": "1204.0684", "submitter": "Matthias Scholz", "authors": "Matthias Scholz", "title": "Validation of nonlinear PCA", "comments": "12 pages, 5 figures", "journal-ref": "Neural Processing Letters, 2012", "doi": "10.1007/s11063-012-9220-6", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear principal component analysis (PCA) can be extended to a nonlinear PCA\nby using artificial neural networks. But the benefit of curved components\nrequires a careful control of the model complexity. Moreover, standard\ntechniques for model selection, including cross-validation and more generally\nthe use of an independent test set, fail when applied to nonlinear PCA because\nof its inherent unsupervised characteristics. This paper presents a new\napproach for validating the complexity of nonlinear PCA models by using the\nerror in missing data estimation as a criterion for model selection. It is\nmotivated by the idea that only the model of optimal complexity is able to\npredict missing values with the highest accuracy. While standard test set\nvalidation usually favours over-fitted nonlinear PCA models, the proposed model\nvalidation approach correctly selects the optimal model complexity.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 13:22:07 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Scholz", "Matthias", ""]]}, {"id": "1204.0731", "submitter": "Olivier Bailleux", "authors": "Olivier Bailleux", "title": "Unit contradiction versus unit propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some aspects of the result of applying unit resolution on a CNF formula can\nbe formalized as functions with domain a set of partial truth assignments. We\nare interested in two ways for computing such functions, depending on whether\nthe result is the production of the empty clause or the assignment of a\nvariable with a given truth value. We show that these two models can compute\nthe same functions with formulae of polynomially related sizes, and we explain\nhow this result is related to the CNF encoding of Boolean constraints.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 16:44:47 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Bailleux", "Olivier", ""]]}, {"id": "1204.1231", "submitter": "Lirong Xia", "authors": "Lirong Xia", "title": "How Many Vote Operations Are Needed to Manipulate A Voting System?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework to study a general class of strategic\nbehavior in voting, which we call vote operations. We prove the following\ntheorem: if we fix the number of alternatives, generate $n$ votes i.i.d.\naccording to a distribution $\\pi$, and let $n$ go to infinity, then for any\n$\\epsilon >0$, with probability at least $1-\\epsilon$, the minimum number of\noperations that are needed for the strategic individual to achieve her goal\nfalls into one of the following four categories: (1) 0, (2) $\\Theta(\\sqrt n)$,\n(3) $\\Theta(n)$, and (4) $\\infty$. This theorem holds for any set of vote\noperations, any individual vote distribution $\\pi$, and any integer generalized\nscoring rule, which includes (but is not limited to) almost all commonly\nstudied voting rules, e.g., approval voting, all positional scoring rules\n(including Borda, plurality, and veto), plurality with runoff, Bucklin,\nCopeland, maximin, STV, and ranked pairs.\n  We also show that many well-studied types of strategic behavior fall under\nour framework, including (but not limited to) constructive/destructive\nmanipulation, bribery, and control by adding/deleting votes, margin of victory,\nand minimum manipulation coalition size. Therefore, our main theorem naturally\napplies to these problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 14:00:21 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 21:57:04 GMT"}, {"version": "v3", "created": "Tue, 14 Aug 2012 02:47:16 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Xia", "Lirong", ""]]}, {"id": "1204.1277", "submitter": "Vikram Kumar", "authors": "Vikram Kumar, Kamran Niyazi, Swapnil Mahe, Swapnil Vyawahare", "title": "Mouse Simulation Using Two Coloured Tapes", "comments": "5 pages", "journal-ref": "International Journal of Information Sciences and Techniques\n  (IJIST) Vol.2, No.2, March 2012", "doi": "10.5121/ijist.2012.2206", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for Human Computer Interaction\n(HCI) where, we control cursor movement using a real-time camera. Current\nmethods involve changing mouse parts such as adding more buttons or changing\nthe position of the tracking ball. Instead, our method is to use a camera and\ncomputer vision technology, such as image segmentation and gesture recognition,\nto control mouse tasks (left and right clicking, double-clicking, and\nscrolling) and we show how it can perform everything as current mouse devices\ncan. The software will be developed in JAVA language. Recognition and pose\nestimation in this system are user independent and robust as we will be using\ncolour tapes on our finger to perform actions. The software can be used as an\nintuitive input interface to applications that require multi-dimensional\ncontrol e.g. computer games etc.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 17:00:47 GMT"}], "update_date": "2012-04-06", "authors_parsed": [["Kumar", "Vikram", ""], ["Niyazi", "Kamran", ""], ["Mahe", "Swapnil", ""], ["Vyawahare", "Swapnil", ""]]}, {"id": "1204.1576", "submitter": "Sanjeev Jha", "authors": "Sanjeev Kumar Jha", "title": "Development of knowledge Base Expert System for Natural treatment of\n  Diabetes disease", "comments": null, "journal-ref": "International Journal of Advanced Computer Science and\n  Applications(IJACSA)Volume 3 Issue 3 March 2012 Published", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of expert system for treatment of Diabetes disease by using\nnatural methods is new information technology derived from Artificial\nIntelligent research using ESTA (Expert System Text Animation) System. The\nproposed expert system contains knowledge about various methods of natural\ntreatment methods (Massage, Herbal/Proper Nutrition, Acupuncture, Gems) for\nDiabetes diseases of Human Beings. The system is developed in the ESTA (Expert\nSystem shell for Text Animation) which is Visual Prolog 7.3 Application. The\nknowledge for the said system will be acquired from domain experts, texts and\nother related sources.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 22:35:15 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Jha", "Sanjeev Kumar", ""]]}, {"id": "1204.1581", "submitter": "Sara Maalal Mrs", "authors": "Sara Maalal and Malika Addou", "title": "A new approach of designing Multi-Agent Systems", "comments": "10 pages, 12 figures, A practical application of a method of\n  designing multi-agent systems based on the AUML language and the MDA approach\n  at \"the 4th IEEE Workshop on Information Technologies and Communication\n  (WOTIC'11)\", Casablanca, 13 - 15 October 2011, International Journal of\n  Advanced Computer Science and Applications(IJACSA) Volume 2 No. 11 November\n  2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent technology is a software paradigm that permits to implement large and\ncomplex distributed applications. In order to assist analyzing, conception and\ndevelopment or implementation phases of multi-agent systems, we've tried to\npresent a practical application of a generic and scalable method of a MAS with\na component-oriented architecture and agent-based approach that allows MDA to\ngenerate source code from a given model. We've designed on AUML the class\ndiagrams as a class meta-model of different agents of a MAS. Then we generated\nthe source code of the models developed using an open source tool called\nAndroMDA. This agent-based and evolutive approach enhances the modularity and\ngenericity developments and promotes their reusability in future developments.\nThis property distinguishes our design methodology of existing methodologies in\nthat it is constrained by any particular agent-based model while providing a\nlibrary of generic models\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 00:10:33 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Maalal", "Sara", ""], ["Addou", "Malika", ""]]}, {"id": "1204.1596", "submitter": "Mallikharjuna Rao Nuka", "authors": "N. Mallikharjuna Rao", "title": "An Intelligent Location Management approaches in GSM Mobile Network", "comments": "International Journal of Advanced Computer Science and\n  Applications(IJACSA)-IJARAI-2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location management refers to the problem of updating and searching the\ncurrent location of mobile nodes in a wireless network. To make it efficient,\nthe sum of update costs of location database must be minimized. Previous work\nrelying on fixed location databases is unable to fully exploit the knowledge of\nuser mobility patterns in the system so as to achieve this minimization. The\nstudy presents an intelligent location management approach which has interacts\nbetween intelligent information system and knowledge-base technologies, so we\ncan dynamically change the user patterns and reduce the transition between the\nVLR and HLR. The study provides algorithms are ability to handle location\nregistration and call delivery\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 05:48:47 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Rao", "N. Mallikharjuna", ""]]}, {"id": "1204.1637", "submitter": "Mohamed Ali Mahjoub", "authors": "Nabil ghanmy, Mohamed Ali Mahjoub, Najoua Essoukri Ben Amara", "title": "Characterization of Dynamic Bayesian Network", "comments": "9 pages, (IJACSA) International Journal of Advanced Computer Science\n  and Applications, Vol. 2, No. 7, 2011", "journal-ref": null, "doi": null, "report-no": "2156-5570", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we will be interested at Dynamic Bayesian Network (DBNs) as a\nmodel that tries to incorporate temporal dimension with uncertainty. We start\nwith basics of DBN where we especially focus in Inference and Learning concepts\nand algorithms. Then we will present different levels and methods of creating\nDBNs as well as approaches of incorporating temporal dimension in static\nBayesian network.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 13:55:29 GMT"}], "update_date": "2012-04-12", "authors_parsed": [["ghanmy", "Nabil", ""], ["Mahjoub", "Mohamed Ali", ""], ["Amara", "Najoua Essoukri Ben", ""]]}, {"id": "1204.1653", "submitter": "Ali Elouafiq", "authors": "Ali Elouafiq", "title": "Machine Cognition Models: EPAM and GPS", "comments": "EPAM, General Problem solver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through history, the human being tried to relay its daily tasks to other\ncreatures, which was the main reason behind the rise of civilizations. It\nstarted with deploying animals to automate tasks in the field of\nagriculture(bulls), transportation (e.g. horses and donkeys), and even\ncommunication (pigeons). Millenniums after, come the Golden age with\n\"Al-jazari\" and other Muslim inventors, which were the pioneers of automation,\nthis has given birth to industrial revolution in Europe, centuries after. At\nthe end of the nineteenth century, a new era was to begin, the computational\nera, the most advanced technological and scientific development that is driving\nthe mankind and the reason behind all the evolutions of science; such as\nmedicine, communication, education, and physics. At this edge of technology\nengineers and scientists are trying to model a machine that behaves the same as\nthey do, which pushed us to think about designing and implementing \"Things\nthat-Thinks\", then artificial intelligence was. In this work we will cover each\nof the major discoveries and studies in the field of machine cognition, which\nare the \"Elementary Perceiver and Memorizer\"(EPAM) and \"The General Problem\nSolver\"(GPS). The First one focus mainly on implementing the human-verbal\nlearning behavior, while the second one tries to model an architecture that is\nable to solve problems generally (e.g. theorem proving, chess playing, and\narithmetic). We will cover the major goals and the main ideas of each model, as\nwell as comparing their strengths and weaknesses, and finally giving their\nfields of applications. And Finally, we will suggest a real life implementation\nof a cognitive machine.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 16:34:20 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Elouafiq", "Ali", ""]]}, {"id": "1204.1679", "submitter": "Mohamed Ali Mahjoub", "authors": "Khlifia Jayech, Mohamed Ali Mahjoub", "title": "Clustering and Bayesian network for image of faces classification", "comments": "12 pages", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Special Issue on Image processing and Analysis, pp 35-44 May\n  2011", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a content based image classification system, target images are sorted by\nfeature similarities with respect to the query (CBIR). In this paper, we\npropose to use new approach combining distance tangent, k-means algorithm and\nBayesian network for image classification. First, we use the technique of\ntangent distance to calculate several tangent spaces representing the same\nimage. The objective is to reduce the error in the classification phase.\nSecond, we cut the image in a whole of blocks. For each block, we compute a\nvector of descriptors. Then, we use K-means to cluster the low-level features\nincluding color and texture information to build a vector of labels for each\nimage. Finally, we apply five variants of Bayesian networks classifiers\n(Na\\\"ive Bayes, Global Tree Augmented Na\\\"ive Bayes (GTAN), Global Forest\nAugmented Na\\\"ive Bayes (GFAN), Tree Augmented Na\\\"ive Bayes for each class\n(TAN), and Forest Augmented Na\\\"ive Bayes for each class (FAN) to classify the\nimage of faces using the vector of labels. In order to validate the feasibility\nand effectively, we compare the results of GFAN to FAN and to the others\nclassifiers (NB, GTAN, TAN). The results demonstrate FAN outperforms than GFAN,\nNB, GTAN and TAN in the overall classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 20:52:10 GMT"}], "update_date": "2012-04-12", "authors_parsed": [["Jayech", "Khlifia", ""], ["Mahjoub", "Mohamed Ali", ""]]}, {"id": "1204.1681", "submitter": "Mohamed Ali Mahjoub", "authors": "Fradj Ben Lamine, Karim Kalti, Mohamed Ali Mahjoub", "title": "The threshold EM algorithm for parameter learning in bayesian network\n  with incomplete data", "comments": "6 pages", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 2, No. 7, pp 86-90, July 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks (BN) are used in a big range of applications but they have\none issue concerning parameter learning. In real application, training data are\nalways incomplete or some nodes are hidden. To deal with this problem many\nlearning parameter algorithms are suggested foreground EM, Gibbs sampling and\nRBE algorithms. In order to limit the search space and escape from local maxima\nproduced by executing EM algorithm, this paper presents a learning parameter\nalgorithm that is a fusion of EM and RBE algorithms. This algorithm\nincorporates the range of a parameter into the EM algorithm. This range is\ncalculated by the first step of RBE algorithm allowing a regularization of each\nparameter in bayesian network after the maximization step of the EM algorithm.\nThe threshold EM algorithm is applied in brain tumor diagnosis and show some\nadvantages and disadvantages over the EM algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 21:09:48 GMT"}], "update_date": "2012-04-12", "authors_parsed": [["Lamine", "Fradj Ben", ""], ["Kalti", "Karim", ""], ["Mahjoub", "Mohamed Ali", ""]]}, {"id": "1204.1751", "submitter": "Rishabh Singh", "authors": "Rishabh Singh, Sumit Gulwani and Armando Solar-Lezama", "title": "Automated Feedback Generation for Introductory Programming Assignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for automatically providing feedback for introductory\nprogramming problems. In order to use this method, we need a reference\nimplementation of the assignment, and an error model consisting of potential\ncorrections to errors that students might make. Using this information, the\nsystem automatically derives minimal corrections to student's incorrect\nsolutions, providing them with a quantifiable measure of exactly how incorrect\na given solution was, as well as feedback about what they did wrong.\n  We introduce a simple language for describing error models in terms of\ncorrection rules, and formally define a rule-directed translation strategy that\nreduces the problem of finding minimal corrections in an incorrect program to\nthe problem of synthesizing a correct program from a sketch. We have evaluated\nour system on thousands of real student attempts obtained from 6.00 and 6.00x.\nOur results show that relatively simple error models can correct on average 65%\nof all incorrect submissions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2012 18:08:43 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2012 04:29:05 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2012 03:41:50 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2012 06:31:27 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Singh", "Rishabh", ""], ["Gulwani", "Sumit", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1204.1811", "submitter": "Rehan Khan", "authors": "Rehanullah Khan, Asad Maqsood, Zeeshan Khan, Muhammad Ishaq, Arsalan\n  Arif", "title": "Skin-color based videos categorization", "comments": "International Journal of Computer Science Issues (IJCSI), Volume 9,\n  Issue 1, No 3, January 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On dedicated websites, people can upload videos and share it with the rest of\nthe world. Currently these videos are cat- egorized manually by the help of the\nuser community. In this paper, we propose a combination of color spaces with\nthe Bayesian network approach for robust detection of skin color followed by an\nautomated video categorization. Exper- imental results show that our method can\nachieve satisfactory performance for categorizing videos based on skin color.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 06:44:42 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Khan", "Rehanullah", ""], ["Maqsood", "Asad", ""], ["Khan", "Zeeshan", ""], ["Ishaq", "Muhammad", ""], ["Arif", "Arsalan", ""]]}, {"id": "1204.1851", "submitter": "Alexander Artikis", "authors": "Anastasios Skarlatidis, Alexander Artikis, Jason Filippou and Georgios\n  Paliouras", "title": "A Probabilistic Logic Programming Event Calculus", "comments": "Accepted for publication in the Theory and Practice of Logic\n  Programming (TPLP) journal", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 213-245", "doi": "10.1017/S1471068413000690", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for recognising human activity given a symbolic\nrepresentation of video content. The input of our system is a set of\ntime-stamped short-term activities (STA) detected on video frames. The output\nis a set of recognised long-term activities (LTA), which are pre-defined\ntemporal combinations of STA. The constraints on the STA that, if satisfied,\nlead to the recognition of a LTA, have been expressed using a dialect of the\nEvent Calculus. In order to handle the uncertainty that naturally occurs in\nhuman activity recognition, we adapted this dialect to a state-of-the-art\nprobabilistic logic programming framework. We present a detailed evaluation and\ncomparison of the crisp and probabilistic approaches through experimentation on\na benchmark dataset of human surveillance videos.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 10:23:38 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2013 16:15:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Skarlatidis", "Anastasios", ""], ["Artikis", "Alexander", ""], ["Filippou", "Jason", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1204.1909", "submitter": "Long Tran-Thanh", "authors": "Long Tran-Thanh, Archie Chapman, Alex Rogers, Nicholas R. Jennings", "title": "Knapsack based Optimal Policies for Budget-Limited Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In budget-limited multi-armed bandit (MAB) problems, the learner's actions\nare costly and constrained by a fixed budget. Consequently, an optimal\nexploitation policy may not be to pull the optimal arm repeatedly, as is the\ncase in other variants of MAB, but rather to pull the sequence of different\narms that maximises the agent's total reward within the budget. This difference\nfrom existing MABs means that new approaches to maximising the total reward are\nrequired. Given this, we develop two pulling policies, namely: (i) KUBE; and\n(ii) fractional KUBE. Whereas the former provides better performance up to 40%\nin our experimental settings, the latter is computationally less expensive. We\nalso prove logarithmic upper bounds for the regret of both policies, and show\nthat these bounds are asymptotically optimal (i.e. they only differ from the\nbest possible regret by a constant factor).\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 15:56:56 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Tran-Thanh", "Long", ""], ["Chapman", "Archie", ""], ["Rogers", "Alex", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1204.2003", "submitter": "Christopher Quinn", "authors": "Christopher J. Quinn, Negar Kiyavash, and Todd P. Coleman", "title": "Directed Information Graphs", "comments": "41 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a graphical model for representing networks of stochastic\nprocesses, the minimal generative model graph. It is based on reduced\nfactorizations of the joint distribution over time. We show that under\nappropriate conditions, it is unique and consistent with another type of\ngraphical model, the directed information graph, which is based on a\ngeneralization of Granger causality. We demonstrate how directed information\nquantifies Granger causality in a particular sequential prediction setting. We\nalso develop efficient methods to estimate the topological structure from data\nthat obviate estimating the joint statistics. One algorithm assumes\nupper-bounds on the degrees and uses the minimal dimension statistics\nnecessary. In the event that the upper-bounds are not valid, the resulting\ngraph is nonetheless an optimal approximation. Another algorithm uses\nnear-minimal dimension statistics when no bounds are known but the distribution\nsatisfies a certain criterion. Analogous to how structure learning algorithms\nfor undirected graphical models use mutual information estimates, these\nalgorithms use directed information estimates. We characterize the\nsample-complexity of two plug-in directed information estimators and obtain\nconfidence intervals. For the setting when point estimates are unreliable, we\npropose an algorithm that uses confidence intervals to identify the best\napproximation that is robust to estimation error. Lastly, we demonstrate the\neffectiveness of the proposed algorithms through analysis of both synthetic\ndata and real data from the Twitter network. In the latter case, we identify\nwhich news sources influence users in the network by merely analyzing tweet\ntimes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 22:54:59 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 21:44:23 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Quinn", "Christopher J.", ""], ["Kiyavash", "Negar", ""], ["Coleman", "Todd P.", ""]]}, {"id": "1204.2018", "submitter": "Igor Subbotin", "authors": "Igor Ya. Subbotin and Michael Gr. Voskoglou", "title": "Applications of fuzzy logic to Case-Based Reasoning", "comments": null, "journal-ref": "International Journal of Applications of Fuzzy Sets (ISSN\n  2241-1240) Vol. 1 ( 2011), 7-18", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article discusses some applications of fuzzy logic ideas to formalizing\nof the Case-Based Reasoning (CBR) process and to measuring the effectiveness of\nCBR systems\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 00:59:28 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Subbotin", "Igor Ya.", ""], ["Voskoglou", "Michael Gr.", ""]]}, {"id": "1204.2235", "submitter": "Richard Vaughan", "authors": "Richard Vaughan and Jens Wawerla", "title": "Publishing Identifiable Experiment Code And Configuration Is Important,\n  Good and Easy", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": "Simon Fraser University Computing Science Technical Report\n  (RV-2012-1)", "categories": "cs.RO cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We argue for the value of publishing the exact code, configuration and data\nprocessing scripts used to produce empirical work in robotics. In particular,\nwe recommend publishing a unique identifier for the code package in the paper\nitself, as a promise to the reader that this is the relavant code. We review\nsome recent discussion of best practice for reproducibility in various\nprofessional organisations and journals, and discuss the current reward\nstructure for publishing code in robotics, along with some ideas for\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 18:07:39 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Vaughan", "Richard", ""], ["Wawerla", "Jens", ""]]}, {"id": "1204.2248", "submitter": "Jun-Ming Xu", "authors": "Jun-Ming Xu and Aniruddha Bhargava and Robert Nowak and Xiaojin Zhu", "title": "Robust Spatio-Temporal Signal Recovery from Noisy Counts in Social Media", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world phenomena can be represented by a spatio-temporal signal:\nwhere, when, and how much. Social media is a tantalizing data source for those\nwho wish to monitor such signals. Unlike most prior work, we assume that the\ntarget phenomenon is known and we are given a method to count its occurrences\nin social media. However, counting is plagued by sample bias, incomplete data,\nand, paradoxically, data scarcity -- issues inadequately addressed by prior\nwork. We formulate signal recovery as a Poisson point process estimation\nproblem. We explicitly incorporate human population bias, time delays and\nspatial distortions, and spatio-temporal regularization into the model to\naddress the noisy count issues. We present an efficient optimization algorithm\nand discuss its theoretical properties. We show that our model is more accurate\nthan commonly-used baselines. Finally, we present a case study on wildlife\nroadkill monitoring, where our model produces qualitatively convincing results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 18:56:29 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Xu", "Jun-Ming", ""], ["Bhargava", "Aniruddha", ""], ["Nowak", "Robert", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1204.2321", "submitter": "Alex Ter-Sarkissov", "authors": "Aram Ter-Sarkisov and Stephen Marsland", "title": "Derivation of Upper Bounds on Optimization Time of Population-Based\n  Evolutionary Algorithm on a Function with Fitness Plateaus Using Elitism\n  Levels Traverse Mechanism", "comments": "This paper will be replaced by a new version with a different title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article a tool for the analysis of population-based EAs is used to\nderive asymptotic upper bounds on the optimization time of the algorithm\nsolving Royal Roads problem, a test function with plateaus of fitness. In\naddition to this, limiting distribution of a certain subset of the population\nis approximated.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2012 02:25:34 GMT"}, {"version": "v2", "created": "Sun, 6 May 2012 04:35:54 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2012 07:44:06 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2013 22:11:02 GMT"}, {"version": "v5", "created": "Sun, 23 Jun 2013 18:30:22 GMT"}, {"version": "v6", "created": "Fri, 30 Aug 2013 22:11:40 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Ter-Sarkisov", "Aram", ""], ["Marsland", "Stephen", ""]]}, {"id": "1204.2601", "submitter": "Pedro Miramontes", "authors": "C. Calder\\'on, L. Delaye, V. Mireles and P. Miramontes", "title": "Detecting lateral genetic material transfer", "comments": "Submitted to Applied Computational Intelligence and Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bioinformatical methods to detect lateral gene transfer events are mainly\nbased on functional coding DNA characteristics. In this paper, we propose the\nuse of DNA traits not depending on protein coding requirements. We introduce\nseveral semilocal variables that depend on DNA primary sequence and that\nreflect thermodynamic as well as physico-chemical magnitudes that are able to\ntell apart the genome of different organisms. After combining these variables\nin a neural classificator, we obtain results whose power of resolution go as\nfar as to detect the exchange of genomic material between bacteria that are\nphylogenetically close.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 01:45:21 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Calder\u00f3n", "C.", ""], ["Delaye", "L.", ""], ["Mireles", "V.", ""], ["Miramontes", "P.", ""]]}, {"id": "1204.2712", "submitter": "David Vallet David Vallet", "authors": "Sumio Fujita, Georges Dupret and Ricardo Baeza-Yates", "title": "Learning to Rank Query Recommendations by Semantic Similarities", "comments": "2nd International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2012) in the 21st International World Wide Web Conference (WWW2012),\n  Lyon, France, April 17th, 2012", "journal-ref": null, "doi": null, "report-no": "WWW2012USEWOD/2012/fuduba", "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logs of the interactions with a search engine show that users often\nreformulate their queries. Examining these reformulations shows that\nrecommendations that precise the focus of a query are helpful, like those based\non expansions of the original queries. But it also shows that queries that\nexpress some topical shift with respect to the original query can help user\naccess more rapidly the information they need. We propose a method to identify\nfrom the query logs of past users queries that either focus or shift the\ninitial query topic. This method combines various click-based, topic-based and\nsession based ranking strategies and uses supervised learning in order to\nmaximize the semantic similarities between the query and the recommendations,\nwhile at the same diversifying them. We evaluate our method using the\nquery/click logs of a Japanese web search engine and we show that the\ncombination of the three methods proposed is significantly better than any of\nthem taken individually.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 13:15:43 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Fujita", "Sumio", ""], ["Dupret", "Georges", ""], ["Baeza-Yates", "Ricardo", ""]]}, {"id": "1204.2713", "submitter": "Julia Hoxha", "authors": "Julia Hoxha, Martin Junghans and Sudhir Agarwal", "title": "Enabling Semantic Analysis of User Browsing Patterns in the Web of Data", "comments": "2nd International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2012) in the 21st International World Wide Web Conference (WWW2012),\n  Lyon, France, April 17th, 2012", "journal-ref": null, "doi": null, "report-no": "WWW2012USEWOD/2012/hojuag", "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A useful step towards better interpretation and analysis of the usage\npatterns is to formalize the semantics of the resources that users are\naccessing in the Web. We focus on this problem and present an approach for the\nsemantic formalization of usage logs, which lays the basis for eective\ntechniques of querying expressive usage patterns. We also present a query\nanswering approach, which is useful to nd in the logs expressive patterns of\nusage behavior via formulation of semantic and temporal-based constraints. We\nhave processed over 30 thousand user browsing sessions extracted from usage\nlogs of DBPedia and Semantic Web Dog Food. All these events are formalized\nsemantically using respective domain ontologies and RDF representations of the\nWeb resources being accessed. We show the eectiveness of our approach through\nexperimental results, providing in this way an exploratory analysis of the way\nusers browse theWeb of Data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 13:17:01 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 16:54:08 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2012 06:46:51 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Hoxha", "Julia", ""], ["Junghans", "Martin", ""], ["Agarwal", "Sudhir", ""]]}, {"id": "1204.2718", "submitter": "David Vallet David Vallet", "authors": "Andreas Thalhammer, Ioan Toma, Antonio Roa-Valverde and Dieter Fensel", "title": "Leveraging Usage Data for Linked Data Movie Entity Summarization", "comments": "2nd International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2012) in the 21st International World Wide Web Conference (WWW2012),\n  Lyon, France, April 17th, 2012", "journal-ref": null, "doi": null, "report-no": "WWW2012USEWOD/2012/thtorofe", "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel research in the field of Linked Data focuses on the problem of entity\nsummarization. This field addresses the problem of ranking features according\nto their importance for the task of identifying a particular entity. Next to a\nmore human friendly presentation, these summarizations can play a central role\nfor semantic search engines and semantic recommender systems. In current\napproaches, it has been tried to apply entity summarization based on patterns\nthat are inherent to the regarded data.\n  The proposed approach of this paper focuses on the movie domain. It utilizes\nusage data in order to support measuring the similarity between movie entities.\nUsing this similarity it is possible to determine the k-nearest neighbors of an\nentity. This leads to the idea that features that entities share with their\nnearest neighbors can be considered as significant or important for these\nentities. Additionally, we introduce a downgrading factor (similar to TF-IDF)\nin order to overcome the high number of commonly occurring features. We\nexemplify the approach based on a movie-ratings dataset that has been linked to\nFreebase entities.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 13:31:52 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Thalhammer", "Andreas", ""], ["Toma", "Ioan", ""], ["Roa-Valverde", "Antonio", ""], ["Fensel", "Dieter", ""]]}, {"id": "1204.2741", "submitter": "Andrei Barbu", "authors": "Andrei Barbu, Aaron Michaux, Siddharth Narayanaswamy, and Jeffrey Mark\n  Siskind", "title": "Simultaneous Object Detection, Tracking, and Event Recognition", "comments": null, "journal-ref": "Advances in Cognitive Systems, Vol. 2, pp. 203-220, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common internal structure and algorithmic organization of object\ndetection, detection-based tracking, and event recognition facilitates a\ngeneral approach to integrating these three components. This supports\nmultidirectional information flow between these components allowing object\ndetection to influence tracking and event recognition and event recognition to\ninfluence tracking and object detection. The performance of the combination can\nexceed the performance of the components in isolation. This can be done with\nlinear asymptotic complexity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 14:47:41 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Barbu", "Andrei", ""], ["Michaux", "Aaron", ""], ["Narayanaswamy", "Siddharth", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1204.2742", "submitter": "Andrei Barbu", "authors": "Andrei Barbu, Alexander Bridge, Zachary Burchill, Dan Coroian, Sven\n  Dickinson, Sanja Fidler, Aaron Michaux, Sam Mussman, Siddharth Narayanaswamy,\n  Dhaval Salvi, Lara Schmidt, Jiangnan Shangguan, Jeffrey Mark Siskind, Jarrell\n  Waggoner, Song Wang, Jinlian Wei, Yifan Yin, and Zhiqi Zhang", "title": "Video In Sentences Out", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that produces sentential descriptions of video: who did\nwhat to whom, and where and how they did it. Action class is rendered as a\nverb, participant objects as noun phrases, properties of those objects as\nadjectival modifiers in those noun phrases,spatial relations between those\nparticipants as prepositional phrases, and characteristics of the event as\nprepositional-phrase adjuncts and adverbial modifiers. Extracting the\ninformation needed to render these linguistic entities requires an approach to\nevent recognition that recovers object tracks, the track-to-role assignments,\nand changing body posture.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 14:47:44 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Barbu", "Andrei", ""], ["Bridge", "Alexander", ""], ["Burchill", "Zachary", ""], ["Coroian", "Dan", ""], ["Dickinson", "Sven", ""], ["Fidler", "Sanja", ""], ["Michaux", "Aaron", ""], ["Mussman", "Sam", ""], ["Narayanaswamy", "Siddharth", ""], ["Salvi", "Dhaval", ""], ["Schmidt", "Lara", ""], ["Shangguan", "Jiangnan", ""], ["Siskind", "Jeffrey Mark", ""], ["Waggoner", "Jarrell", ""], ["Wang", "Song", ""], ["Wei", "Jinlian", ""], ["Yin", "Yifan", ""], ["Zhang", "Zhiqi", ""]]}, {"id": "1204.2801", "submitter": "Andrei Barbu", "authors": "Siddharth Narayanaswamy, Andrei Barbu, and Jeffrey Mark Siskind", "title": "Seeing Unseeability to See the Unseeable", "comments": null, "journal-ref": "Advances in Cognitive Systems, Vol. 2, pp. 77-94, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that allows an observer to determine occluded portions\nof a structure by finding the maximum-likelihood estimate of those occluded\nportions consistent with visible image evidence and a consistency model. Doing\nthis requires determining which portions of the structure are occluded in the\nfirst place. Since each process relies on the other, we determine a solution to\nboth problems in tandem. We extend our framework to determine confidence of\none's assessment of which portions of an observed structure are occluded, and\nthe estimate of that occluded structure, by determining the sensitivity of\none's assessment to potential new observations. We further extend our framework\nto determine a robotic action whose execution would allow a new observation\nthat would maximally increase one's confidence.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 18:18:35 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Narayanaswamy", "Siddharth", ""], ["Barbu", "Andrei", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1204.3040", "submitter": "Stefan R\\\"ummele", "authors": "Reinhard Pichler, Stefan R\\\"ummele, Stefan Szeider, Stefan Woltran", "title": "Tractable Answer-Set Programming with Weight Constraints: Bounded\n  Treewidth is not Enough", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 141-164", "doi": "10.1017/S1471068412000099", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality constraints or, more generally, weight constraints are well\nrecognized as an important extension of answer-set programming. Clearly, all\ncommon algorithmic tasks related to programs with cardinality or weight\nconstraints - like checking the consistency of a program - are intractable.\nMany intractable problems in the area of knowledge representation and reasoning\nhave been shown to become linear time tractable if the treewidth of the\nprograms or formulas under consideration is bounded by some constant. The goal\nof this paper is to apply the notion of treewidth to programs with cardinality\nor weight constraints and to identify tractable fragments. It will turn out\nthat the straightforward application of treewidth to such class of programs\ndoes not suffice to obtain tractability. However, by imposing further\nrestrictions, tractability can be achieved.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 16:25:30 GMT"}, {"version": "v2", "created": "Tue, 29 May 2012 13:28:54 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Pichler", "Reinhard", ""], ["R\u00fcmmele", "Stefan", ""], ["Szeider", "Stefan", ""], ["Woltran", "Stefan", ""]]}, {"id": "1204.3221", "submitter": "Konstantin Lakhman", "authors": "Konstantin Lakhman and Mikhail Burtsev", "title": "Neuroevolution Results in Emergence of Short-Term Memory for\n  Goal-Directed Behavior", "comments": "Manuscript was submitted to the 12th International Conference on the\n  Simulation of Adaptive Behavior 2012; 10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals behave adaptively in the environment with multiply competing goals.\nUnderstanding of the mechanisms underlying such goal-directed behavior remains\na challenge for neuroscience as well for adaptive system research. To address\nthis problem we developed an evolutionary model of adaptive behavior in the\nmultigoal stochastic environment. Proposed neuroevolutionary algorithm is based\non neuron's duplication as a basic mechanism of agent's recurrent neural\nnetwork development. Results of simulation demonstrate that in the course of\nevolution agents acquire the ability to store the short-term memory and,\ntherefore, use it in behavioral strategies with alternative actions. We found\nthat evolution discovered two mechanisms for short-term memory. The first\nmechanism is integration of sensory signals and ongoing internal neural\nactivity, resulting in emergence of cell groups specialized on alternative\nactions. And the second mechanism is slow neurodynamical processes that makes\npossible to code the previous behavioral choice.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 22:15:39 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Lakhman", "Konstantin", ""], ["Burtsev", "Mikhail", ""]]}, {"id": "1204.3255", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger", "title": "Lower Complexity Bounds for Lifted Inference", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 246-263", "doi": "10.1017/S1471068413000707", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the big challenges in the development of probabilistic relational (or\nprobabilistic logical) modeling and learning frameworks is the design of\ninference techniques that operate on the level of the abstract model\nrepresentation language, rather than on the level of ground, propositional\ninstances of the model. Numerous approaches for such \"lifted inference\"\ntechniques have been proposed. While it has been demonstrated that these\ntechniques will lead to significantly more efficient inference on some specific\nmodels, there are only very recent and still quite restricted results that show\nthe feasibility of lifted inference on certain syntactically defined classes of\nmodels. Lower complexity bounds that imply some limitations for the feasibility\nof lifted inference on more expressive model classes were established early on\nin (Jaeger 2000). However, it is not immediate that these results also apply to\nthe type of modeling languages that currently receive the most attention, i.e.,\nweighted, quantifier-free formulas. In this paper we extend these earlier\nresults, and show that under the assumption that NETIME =/= ETIME, there is no\npolynomial lifted inference algorithm for knowledge bases of weighted,\nquantifier- and function-free formulas. Further strengthening earlier results,\nthis is also shown to hold for approximate inference, and for knowledge bases\nnot containing the equality predicate.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2012 10:59:29 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 15:27:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jaeger", "Manfred", ""]]}, {"id": "1204.3341", "submitter": "Russell Thomas", "authors": "Russell C. Thomas, John S. Gero", "title": "Patterns of Social Influence in a Network of Situated Cognitive Agents", "comments": "Presented at Collective Intelligence conference, 2012\n  (arXiv:1204.2991)", "journal-ref": null, "doi": null, "report-no": "CollectiveIntelligence/2012/30", "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results of computational experiments on the effects\nof social influence on individual and systemic behavior of situated cognitive\nagents in a product-consumer environment. Paired experiments were performed\nwith identical initial conditions to compare social agents with non- social\nagents. Experiment results show that social agents are more productive in\nconsuming available products, both in terms of aggregate unit consumption and\naggregate utility. But this comes at a cost of individual average utility per\nunit consumed. In effect, social interaction achieved higher productivity by\n'lowering the standards' of individual consumers. While still at an early stage\nof development, such an agent-based model laboratory is shown to be an\neffective research tool to investigate rich collective behavior in the context\nof demanding cognitive tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 01:40:01 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Thomas", "Russell C.", ""], ["Gero", "John S.", ""]]}, {"id": "1204.3348", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Symmetry Breaking Constraints: Recent Results", "comments": "To appear in Proceedings of Twenty-Sixth Conference on Artificial\n  Intelligence (AAAI-12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry is an important problem in many combinatorial problems. One way of\ndealing with symmetry is to add constraints that eliminate symmetric solutions.\nWe survey recent results in this area, focusing especially on two common and\nuseful cases: symmetry breaking constraints for row and column symmetry, and\nsymmetry breaking constraints for eliminating value symmetry\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 02:56:16 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1204.3436", "submitter": "Keki Burjorjee", "authors": "Keki M. Burjorjee", "title": "Explaining Adaptation in Genetic Algorithms With Uniform Crossover: The\n  Hyperclimbing Hypothesis", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": "10.1145/2460239.2460244", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyperclimbing hypothesis is a hypothetical explanation for adaptation in\ngenetic algorithms with uniform crossover (UGAs). Hyperclimbing is an\nintuitive, general-purpose, non-local search heuristic applicable to discrete\nproduct spaces with rugged or stochastic cost functions. The strength of this\nheuristic lie in its insusceptibility to local optima when the cost function is\ndeterministic, and its tolerance for noise when the cost function is\nstochastic. Hyperclimbing works by decimating a search space, i.e. by\niteratively fixing the values of small numbers of variables. The hyperclimbing\nhypothesis holds that UGAs work by implementing efficient hyperclimbing. Proof\nof concept for this hypothesis comes from the use of a novel analytic technique\ninvolving the exploitation of algorithmic symmetry. We have also obtained\nexperimental results that show that a simple tweak inspired by the\nhyperclimbing hypothesis dramatically improves the performance of a UGA on\nlarge, random instances of MAX-3SAT and the Sherrington Kirkpatrick Spin\nGlasses problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 10:53:06 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Burjorjee", "Keki M.", ""]]}, {"id": "1204.3516", "submitter": "Yu-An Sun", "authors": "Yu-An Sun and Christopher Dance", "title": "When majority voting fails: Comparing quality assurance methods for\n  noisy human computation environment", "comments": "Presented at Collective Intelligence conference, 2012\n  (arXiv:1204.2991)", "journal-ref": null, "doi": null, "report-no": "CollectiveIntelligence/2012/56", "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality assurance remains a key topic in human computation research. Prior\nwork indicates that majority voting is effective for low difficulty tasks, but\nhas limitations for harder tasks. This paper explores two methods of addressing\nthis problem: tournament selection and elimination selection, which exploit 2-,\n3- and 4-way comparisons between different answers to human computation tasks.\nOur experimental results and statistical analyses show that both methods\nproduce the correct answer in noisy human computation environment more often\nthan majority voting. Furthermore, we find that the use of 4-way comparisons\ncan significantly reduce the cost of quality assurance relative to the use of\n2-way comparisons.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 15:12:22 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Sun", "Yu-An", ""], ["Dance", "Christopher", ""]]}, {"id": "1204.3529", "submitter": "Aritanan Gruber", "authors": "Endre Boros, Aritanan Gruber", "title": "Hardness Results for Approximate Pure Horn CNF Formulae Minimization", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the hardness of approximation of clause minimum and literal minimum\nrepresentations of pure Horn functions in $n$ Boolean variables. We show that\nunless P=NP, it is not possible to approximate in polynomial time the minimum\nnumber of clauses and the minimum number of literals of pure Horn CNF\nrepresentations to within a factor of $2^{\\log^{1-o(1)} n}$. This is the case\neven when the inputs are restricted to pure Horn 3-CNFs with\n$O(n^{1+\\varepsilon})$ clauses, for some small positive constant $\\varepsilon$.\nFurthermore, we show that even allowing sub-exponential time computation, it is\nstill not possible to obtain constant factor approximations for such problems\nunless the Exponential Time Hypothesis turns out to be false.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 15:41:43 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 21:49:23 GMT"}, {"version": "v3", "created": "Tue, 11 Mar 2014 18:21:16 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Boros", "Endre", ""], ["Gruber", "Aritanan", ""]]}, {"id": "1204.3616", "submitter": "Andrei Barbu", "authors": "Andrei Barbu, Alexander Bridge, Dan Coroian, Sven Dickinson, Sam\n  Mussman, Siddharth Narayanaswamy, Dhaval Salvi, Lara Schmidt, Jiangnan\n  Shangguan, Jeffrey Mark Siskind, Jarrell Waggoner, Song Wang, Jinlian Wei,\n  Yifan Yin, and Zhiqi Zhang", "title": "Large-Scale Automatic Labeling of Video Events with Verbs Based on\n  Event-Participant Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to labeling short video clips with English verbs as\nevent descriptions. A key distinguishing aspect of this work is that it labels\nvideos with verbs that describe the spatiotemporal interaction between event\nparticipants, humans and objects interacting with each other, abstracting away\nall object-class information and fine-grained image characteristics, and\nrelying solely on the coarse-grained motion of the event participants. We apply\nour approach to a large set of 22 distinct verb classes and a corpus of 2,584\nvideos, yielding two surprising outcomes. First, a classification accuracy of\ngreater than 70% on a 1-out-of-22 labeling task and greater than 85% on a\nvariety of 1-out-of-10 subsets of this labeling task is independent of the\nchoice of which of two different time-series classifiers we employ. Second, we\nachieve this level of accuracy using a highly impoverished intermediate\nrepresentation consisting solely of the bounding boxes of one or two event\nparticipants as a function of time. This indicates that successful event\nrecognition depends more on the choice of appropriate features that\ncharacterize the linguistic invariants of the event classes than on the\nparticular classifier algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 19:59:15 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Barbu", "Andrei", ""], ["Bridge", "Alexander", ""], ["Coroian", "Dan", ""], ["Dickinson", "Sven", ""], ["Mussman", "Sam", ""], ["Narayanaswamy", "Siddharth", ""], ["Salvi", "Dhaval", ""], ["Schmidt", "Lara", ""], ["Shangguan", "Jiangnan", ""], ["Siskind", "Jeffrey Mark", ""], ["Waggoner", "Jarrell", ""], ["Wang", "Song", ""], ["Wei", "Jinlian", ""], ["Yin", "Yifan", ""], ["Zhang", "Zhiqi", ""]]}, {"id": "1204.3820", "submitter": "Jingjin Yu", "authors": "Jingjin Yu and Steven M. LaValle", "title": "Distance Optimal Formation Control on Graphs with a Tight Convergence\n  Time Guarantee", "comments": "Brought to be in-sync with final version submitted to CDC 2012 with\n  only minor updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the task of moving a set of indistinguishable agents on a connected graph\nwith unit edge distance to an arbitrary set of goal vertices, free of\ncollisions, we propose a fast distance optimal control algorithm that guides\nthe agents into the desired formation. Moreover, we show that the algorithm\nalso provides a tight convergence time guarantee (time optimality and distance\noptimality cannot be simultaneously satisfied). Our generic graph formulation\nallows the algorithm to be applied to scenarios such as grids with holes\n(modeling obstacles) in arbitrary dimensions. Simulations, available online,\nconfirm our theoretical developments.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 15:58:57 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2012 16:13:40 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2012 17:25:27 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Yu", "Jingjin", ""], ["LaValle", "Steven M.", ""]]}, {"id": "1204.3830", "submitter": "Jingjin Yu", "authors": "Jingjin Yu and Steven M. LaValle", "title": "Planning Optimal Paths for Multiple Robots on Graphs", "comments": "Changed \"agents\" to \"robots\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of optimal multi-robot path planning\n(MPP) on graphs. We propose two multiflow based integer linear programming\n(ILP) models that computes minimum last arrival time and minimum total distance\nsolutions for our MPP formulation, respectively. The resulting algorithms from\nthese ILP models are complete and guaranteed to yield true optimal solutions.\nIn addition, our flexible framework can easily accommodate other variants of\nthe MPP problem. Focusing on the time optimal algorithm, we evaluate its\nperformance, both as a stand alone algorithm and as a generic heuristic for\nquickly solving large problem instances. Computational results confirm the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 16:33:56 GMT"}, {"version": "v2", "created": "Thu, 3 May 2012 03:39:18 GMT"}, {"version": "v3", "created": "Thu, 16 Aug 2012 06:13:19 GMT"}, {"version": "v4", "created": "Thu, 17 Jan 2013 17:41:20 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Yu", "Jingjin", ""], ["LaValle", "Steven M.", ""]]}, {"id": "1204.3838", "submitter": "Abdelmalik Moujahid", "authors": "A. Moujahid, A. D'Anjou, F.J. Torrealdea and C. Sarasola", "title": "Energy cost reduction in the synchronization of a pair of nonidentical\n  coupled Hindmarsh-Rose neurons", "comments": null, "journal-ref": "Advances in Intelligent and Soft Computing, 2010, Volume 71/2010,\n  657-664", "doi": "10.1007/978-3-642-12433-4_77", "report-no": null, "categories": "cs.AI nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological processes involve synchronization between nonequivalent\nsystems, i.e, systems where the difference is limited to a rather small\nparameter mismatch. The maintenance of the synchronized regime in this cases is\nenergetically costly \\cite{1}. This work studies the energy implications of\nsynchronization phenomena in a pair of structurally flexible coupled neurons\nthat interact through electrical coupling. We show that the forced\nsynchronization between two nonidentical neurons creates appropriate conditions\nfor an efficient actuation of adaptive laws able to make the neurons\nstructurally approach their behaviours in order to decrease the flow of energy\nrequired to maintain the synchronization regime.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 16:50:25 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Moujahid", "A.", ""], ["D'Anjou", "A.", ""], ["Torrealdea", "F. J.", ""], ["Sarasola", "C.", ""]]}, {"id": "1204.3844", "submitter": "Abdelmalik Moujahid", "authors": "Blanca Cases, Alicia D'Anjou, Abdelmalik Moujahid", "title": "On how percolation threshold affects PSO performance", "comments": null, "journal-ref": "LNCS, 2012, Volume 7208/2012, 509-520", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical evidence of the influence of neighborhood topology on the\nperformance of particle swarm optimization (PSO) algorithms has been shown in\nmany works. However, little has been done about the implications could have the\npercolation threshold in determining the topology of this neighborhood. This\nwork addresses this problem for individuals that, like robots, are able to\nsense in a limited neighborhood around them. Based on the concept of\npercolation threshold, and more precisely, the disk percolation model in 2D, we\nshow that better results are obtained for low values of radius, when\nindividuals occasionally ask others their best visited positions, with the\nconsequent decrease of computational complexity. On the other hand, since\npercolation threshold is a universal measure, it could have a great interest to\ncompare the performance of different hybrid PSO algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 17:00:58 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Cases", "Blanca", ""], ["D'Anjou", "Alicia", ""], ["Moujahid", "Abdelmalik", ""]]}, {"id": "1204.3918", "submitter": "Toby Walsh", "authors": "Jessica Davies and Nina Narodytska and Toby Walsh", "title": "Eliminating the Weakest Link: Making Manipulation Intractable?", "comments": "To appear in Proceedings of Twenty-Sixth Conference on Artificial\n  Intelligence (AAAI-12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successive elimination of candidates is often a route to making manipulation\nintractable to compute. We prove that eliminating candidates does not\nnecessarily increase the computational complexity of manipulation. However, for\nmany voting rules used in practice, the computational complexity increases. For\nexample, it is already known that it is NP-hard to compute how a single voter\ncan manipulate the result of single transferable voting (the elimination\nversion of plurality voting). We show here that it is NP-hard to compute how a\nsingle voter can manipulate the result of the elimination version of veto\nvoting, of the closely related Coombs' rule, and of the elimination versions of\na general class of scoring rules.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 21:08:39 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Davies", "Jessica", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1204.4051", "submitter": "Martin Josef Geiger", "authors": "Thibaut Barth\\'elemy, Martin Josef Geiger, Marc Sevaux", "title": "Solution Representations and Local Search for the bi-objective Inventory\n  Routing Problem", "comments": "Proceedings of EU/ME 2012, Workshop on Metaheuristics for Global\n  Challenges, May 10-11, 2012, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution of the biobjective IRP is rather challenging, even for\nmetaheuristics. We are still lacking a profound understanding of appropriate\nsolution representations and effective neighborhood structures. Clearly, both\nthe delivery volumes and the routing aspects of the alternatives need to be\nreflected in an encoding, and must be modified when searching by means of local\nsearch. Our work contributes to the better understanding of such solution\nrepresentations. On the basis of an experimental investigation, the advantages\nand drawbacks of two encodings are studied and compared.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 11:32:07 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Barth\u00e9lemy", "Thibaut", ""], ["Geiger", "Martin Josef", ""], ["Sevaux", "Marc", ""]]}, {"id": "1204.4116", "submitter": "Benjamin Kuipers", "authors": "Benjamin Kuipers", "title": "An existing, ecologically-successful genus of collectively intelligent\n  artificial creatures", "comments": "Presented at Collective Intelligence conference, 2012\n  (arXiv:1204.2991)", "journal-ref": null, "doi": null, "report-no": "CollectiveIntelligence/2012/57", "categories": "cs.SI cs.AI cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People sometimes worry about the Singularity [Vinge, 1993; Kurzweil, 2005],\nor about the world being taken over by artificially intelligent robots. I\nbelieve the risks of these are very small. However, few people recognize that\nwe already share our world with artificial creatures that participate as\nintelligent agents in our society: corporations. Our planet is inhabited by two\ndistinct kinds of intelligent beings --- individual humans and corporate\nentities --- whose natures and interests are intimately linked. To co-exist\nwell, we need to find ways to define the rights and responsibilities of both\nindividual humans and corporate entities, and to find ways to ensure that\ncorporate entities behave as responsible members of society.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 16:02:59 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Kuipers", "Benjamin", ""]]}, {"id": "1204.4141", "submitter": "Youhei Akimoto", "authors": "Youhei Akimoto (INRIA Saclay - Ile de France)", "title": "Analysis of a Natural Gradient Algorithm on Monotonic\n  Convex-Quadratic-Composite Functions", "comments": "Presented in Genetic and Evolutionary Computation Conference (GECCO\n  2012) (2012). Some errata have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the convergence properties of a variant of the\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES). Our study is based on\nthe recent theoretical foundation that the pure rank-mu update CMA-ES performs\nthe natural gradient descent on the parameter space of Gaussian distributions.\nWe derive a novel variant of the natural gradient method where the parameters\nof the Gaussian distribution are updated along the natural gradient to improve\na newly defined function on the parameter space. We study this algorithm on\ncomposites of a monotone function with a convex quadratic function. We prove\nthat our algorithm adapts the covariance matrix so that it becomes proportional\nto the inverse of the Hessian of the original objective function. We also show\nthe speed of covariance matrix adaptation and the speed of convergence of the\nparameters. We introduce a stochastic algorithm that approximates the natural\ngradient with finite samples and present some simulated results to evaluate how\nprecisely the stochastic algorithm approximates the deterministic, ideal one\nunder finite samples and to see how similarly our algorithm and the CMA-ES\nperform.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 17:12:23 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 01:03:07 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Akimoto", "Youhei", "", "INRIA Saclay - Ile de France"]]}, {"id": "1204.4200", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Discrete Dynamical Genetic Programming in XCS", "comments": "arXiv admin note: substantial text overlap with arXiv:1201.5604", "journal-ref": "In Proceedings of the 11th annual conference on genetic and\n  evolutionary computation, GECCO '09, pp. 1299-1306. ACM, 2009", "doi": "10.1145/1569901.1570075", "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of representation schemes have been presented for use within\nLearning Classifier Systems, ranging from binary encodings to neural networks.\nThis paper presents results from an investigation into using a discrete\ndynamical system representation within the XCS Learning Classifier System. In\nparticular, asynchronous random Boolean networks are used to represent the\ntraditional condition-action production system rules. It is shown possible to\nuse self-adaptive, open-ended evolution to design an ensemble of such discrete\ndynamical systems within XCS to solve a number of well-known test problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 20:30:23 GMT"}, {"version": "v2", "created": "Sat, 18 Oct 2014 12:20:46 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1204.4202", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Fuzzy Dynamical Genetic Programming in XCSF", "comments": "2 page GECCO 2011 poster paper", "journal-ref": "In Proceedings of the 13th annual conference companion on genetic\n  and evolutionary computation, GECCO '11, pp. 167-168. ACM, 2011", "doi": "10.1145/2001858.2001952", "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of representation schemes have been presented for use within\nLearning Classifier Systems, ranging from binary encodings to Neural Networks,\nand more recently Dynamical Genetic Programming (DGP). This paper presents\nresults from an investigation into using a fuzzy DGP representation within the\nXCSF Learning Classifier System. In particular, asynchronous Fuzzy Logic\nNetworks are used to represent the traditional condition-action production\nsystem rules. It is shown possible to use self-adaptive, open-ended evolution\nto design an ensemble of such fuzzy dynamical systems within XCSF to solve\nseveral well-known continuous-valued test problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 20:40:18 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1204.4294", "submitter": "Brijnesh Jain", "authors": "Brijnesh J. Jain and Klaus Obermayer", "title": "Learning in Riemannian Orbifolds", "comments": "arXiv admin note: substantial text overlap with arXiv:1001.0921", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in Riemannian orbifolds is motivated by existing machine learning\nalgorithms that directly operate on finite combinatorial structures such as\npoint patterns, trees, and graphs. These methods, however, lack statistical\njustification. This contribution derives consistency results for learning\nproblems in structured domains and thereby generalizes learning in vector\nspaces and manifolds.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 09:29:10 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Jain", "Brijnesh J.", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1204.4307", "submitter": "Andino Maseleno", "authors": "Andino Maseleno, Md. Mahmud Hasan", "title": "Avian Influenza (H5N1) Warning System using Dempster-Shafer Theory and\n  Web Mapping", "comments": "International Seminar Indonesian Students in ASEAN \"Green Technology,\n  Social Work and Public Health for the Development of Indonesia\", 28 - 29\n  October 2011, Bangkok, Thailand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Based on Cumulative Number of Confirmed Human Cases of Avian Influenza (H5N1)\nReported to World Health Organization (WHO) in the 2011 from 15 countries,\nIndonesia has the largest number death because Avian Influenza which 146\ndeaths. In this research, the researcher built a Web Mapping and\nDempster-Shafer theory as early warning system of avian influenza. Early\nwarning is the provision of timely and effective information, through\nidentified institutions, that allows individuals exposed to a hazard to take\naction to avoid or reduce their risk and prepare for effective response. In\nthis paper as example we use five symptoms as major symptoms which include\ndepression, combs, wattle, bluish face region, swollen face region, narrowness\nof eyes, and balance disorders. Research location is in the Lampung Province,\nSouth Sumatera. The researcher reason to choose Lampung Province in South\nSumatera on the basis that has a high poultry population. Geographically,\nLampung province is located at 103040' to 105050' East Longitude and 6045' -\n3045' South latitude, confined with: South Sumatera and Bengkulu on North Side,\nSunda Strait on the Side, Java Sea on the East Side, Indonesia Ocean on the\nWest Side. Our approach uses Dempster Shafer theory to combine beliefs in\ncertain hypotheses under conditions of uncertainty and ignorance, and allows\nquantitative measurement of the belief and plausibility in our identification\nresult. Web Mapping is also used for displaying maps on a screen to visualize\nthe result of the identification process. The result reveal that avian\ninfluenza warning system has successfully identified the existence of avian\ninfluenza and the maps can be displayed as the visualization.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 10:55:14 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Maseleno", "Andino", ""], ["Hasan", "Md. Mahmud", ""]]}, {"id": "1204.4311", "submitter": "Andino Maseleno", "authors": "Andino Maseleno, Md. Mahmud Hasan", "title": "Avian Influenza (H5N1) Expert System using Dempster-Shafer Theory", "comments": "International Conference on Informatics for Development 2011, 26\n  November 2011, Yogyakarta, Indonesia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Based on Cumulative Number of Confirmed Human Cases of Avian Influenza (H5N1)\nReported to World Health Organization (WHO) in the 2011 from 15 countries,\nIndonesia has the largest number death because Avian Influenza which 146\ndeaths. In this research, the researcher built an Avian Influenza (H5N1) Expert\nSystem for identifying avian influenza disease and displaying the result of\nidentification process. In this paper, we describe five symptoms as major\nsymptoms which include depression, combs, wattle, bluish face region, swollen\nface region, narrowness of eyes, and balance disorders. We use chicken as\nresearch object. Research location is in the Lampung Province, South Sumatera.\nThe researcher reason to choose Lampung Province in South Sumatera on the basis\nthat has a high poultry population. Dempster-Shafer theory to quantify the\ndegree of belief as inference engine in expert system, our approach uses\nDempster-Shafer theory to combine beliefs under conditions of uncertainty and\nignorance, and allows quantitative measurement of the belief and plausibility\nin our identification result. The result reveal that Avian Influenza (H5N1)\nExpert System has successfully identified the existence of avian influenza and\ndisplaying the result of identification process.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 11:12:43 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Maseleno", "Andino", ""], ["Hasan", "Md. Mahmud", ""]]}, {"id": "1204.4541", "submitter": "Patrick Taillandier", "authors": "Patrick Taillandier (UMMISCO), Julien Gaffuri (COGIT)", "title": "Automatic Sampling of Geographic objects", "comments": null, "journal-ref": "GIScience, Zurich : Switzerland (2010)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, one's disposes of large datasets composed of thousands of geographic\nobjects. However, for many processes, which require the appraisal of an expert\nor much computational time, only a small part of these objects can be taken\ninto account. In this context, robust sampling methods become necessary. In\nthis paper, we propose a sampling method based on clustering techniques. Our\nmethod consists in dividing the objects in clusters, then in selecting in each\ncluster, the most representative objects. A case-study in the context of a\nprocess dedicated to knowledge revision for geographic data generalisation is\npresented. This case-study shows that our method allows to select relevant\nsamples of objects.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 06:35:41 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Taillandier", "Patrick", "", "UMMISCO"], ["Gaffuri", "Julien", "", "COGIT"]]}, {"id": "1204.4805", "submitter": "Janna Hastings", "authors": "Janna Hastings and Colin Batchelor and Fabian Neuhaus and Christoph\n  Steinbeck", "title": "What's in an `is about' link? Chemical diagrams and the Information\n  Artifact Ontology", "comments": "10 pages, 5 figures, presented at the 2nd International Conference on\n  Biomedical Ontology (ICBO) 2011", "journal-ref": "CEUR-WS Volume 833, 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The Information Artifact Ontology is an ontology in the domain of information\nentities. Core to the definition of what it is to be an information entity is\nthe claim that an information entity must be `about' something, which is\nencoded in an axiom expressing that all information entities are about some\nentity. This axiom comes into conflict with ontological realism, since many\ninformation entities seem to be about non-existing entities, such as\nhypothetical molecules. We discuss this problem in the context of diagrams of\nmolecules, a kind of information entity pervasively used throughout\ncomputational chemistry. We then propose a solution that recognizes that\ninformation entities such as diagrams are expressions of diagrammatic\nlanguages. In so doing, we not only address the problem of classifying diagrams\nthat seem to be about non-existing entities but also allow a more sophisticated\ncategorisation of information entities.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2012 12:00:16 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Hastings", "Janna", ""], ["Batchelor", "Colin", ""], ["Neuhaus", "Fabian", ""], ["Steinbeck", "Christoph", ""]]}, {"id": "1204.4914", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Sandro Sozzo", "title": "Quantum Interference in Cognition: Structural Aspects of the Brain", "comments": "15 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1004.2530", "journal-ref": "In V. Ovchinnikov and P. Dini (Eds.), IARIA, Proceedings of the\n  Sixth International Conference on Quantum, Nano and Micro Technologies, pp.\n  33-41, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify the presence of typically quantum effects, namely 'superposition'\nand 'interference', in what happens when human concepts are combined, and\nprovide a quantum model in complex Hilbert space that represents faithfully\nexperimental data measuring the situation of combining concepts. Our model\nshows how 'interference of concepts' explains the effects of underextension and\noverextension when two concepts combine to the disjunction of these two\nconcepts. This result supports our earlier hypothesis that human thought has a\nsuperposed two-layered structure, one layer consisting of 'classical logical\nthought' and a superposed layer consisting of 'quantum conceptual thought'.\nPossible connections with recent findings of a 'grid-structure' for the brain\nare analyzed, and influences on the mind/brain relation, and consequences on\napplied disciplines, such as artificial intelligence and quantum computation,\nare considered.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2012 17:17:56 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Aerts", "Diederik", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1204.4927", "submitter": "Casey Bennett", "authors": "Casey Bennett, Tom Doub, Rebecca Selove", "title": "EHRs Connect Research and Practice: Where Predictive Modeling,\n  Artificial Intelligence, and Clinical Decision Support Intersect", "comments": "Keywords: Data Mining; Decision Support Systems, Clinical; Electronic\n  Health Records; Implementation; Evidence-Based Medicine; Data Warehouse;\n  (2012). EHRs Connect Research and Practice: Where Predictive Modeling,\n  Artificial Intelligence, and Clinical Decision Support Intersect. Health\n  Policy and Technology. arXiv admin note: substantial text overlap with\n  arXiv:1112.1668", "journal-ref": "Health Policy and Technology 1(2): 105-114 (2012)", "doi": "10.1016/j.hlpt.2012.03.001", "report-no": null, "categories": "cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: Electronic health records (EHRs) are only a first step in\ncapturing and utilizing health-related data - the challenge is turning that\ndata into useful information. Furthermore, EHRs are increasingly likely to\ninclude data relating to patient outcomes, functionality such as clinical\ndecision support, and genetic information as well, and, as such, can be seen as\nrepositories of increasingly valuable information about patients' health\nconditions and responses to treatment over time. Methods: We describe a case\nstudy of 423 patients treated by Centerstone within Tennessee and Indiana in\nwhich we utilized electronic health record data to generate predictive\nalgorithms of individual patient treatment response. Multiple models were\nconstructed using predictor variables derived from clinical, financial and\ngeographic data. Results: For the 423 patients, 101 deteriorated, 223 improved\nand in 99 there was no change in clinical condition. Based on modeling of\nvarious clinical indicators at baseline, the highest accuracy in predicting\nindividual patient response ranged from 70-72% within the models tested. In\nterms of individual predictors, the Centerstone Assessment of Recovery Level -\nAdult (CARLA) baseline score was most significant in predicting outcome over\ntime (odds ratio 4.1 + 2.27). Other variables with consistently significant\nimpact on outcome included payer, diagnostic category, location and provision\nof case management services. Conclusions: This approach represents a promising\navenue toward reducing the current gap between research and practice across\nhealthcare, developing data-driven clinical decision support based on\nreal-world populations, and serving as a component of embedded clinical\nartificial intelligences that \"learn\" over time.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2012 19:24:40 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Bennett", "Casey", ""], ["Doub", "Tom", ""], ["Selove", "Rebecca", ""]]}, {"id": "1204.4989", "submitter": "Patrick Taillandier", "authors": "Patrick Taillandier (COGIT, UMMISCO), C\\'ecile Duch\\^ene (COGIT),\n  Alexis Drogoul (UMMISCO, MSI)", "title": "Using Belief Theory to Diagnose Control Knowledge Quality. Application\n  to cartographic generalisation", "comments": "Best paper award, International Conference on Computing and\n  Communication Technologies (IEEE-RIVF), Danang : Viet Nam (2009)", "journal-ref": null, "doi": "10.1109/RIVF.2009.5174663", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both humans and artificial systems frequently use trial and error methods to\nproblem solving. In order to be effective, this type of strategy implies having\nhigh quality control knowledge to guide the quest for the optimal solution.\nUnfortunately, this control knowledge is rarely perfect. Moreover, in\nartificial systems-as in humans-self-evaluation of one's own knowledge is often\ndifficult. Yet, this self-evaluation can be very useful to manage knowledge and\nto determine when to revise it. The objective of our work is to propose an\nautomated approach to evaluate the quality of control knowledge in artificial\nsystems based on a specific trial and error strategy, namely the informed tree\nsearch strategy. Our revision approach consists in analysing the system's\nexecution logs, and in using the belief theory to evaluate the global quality\nof the knowledge. We present a real-world industrial application in the form of\nan experiment using this approach in the domain of cartographic generalisation.\nThus far, the results of using our approach have been encouraging.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 08:01:48 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Taillandier", "Patrick", "", "COGIT, UMMISCO"], ["Duch\u00eane", "C\u00e9cile", "", "COGIT"], ["Drogoul", "Alexis", "", "UMMISCO, MSI"]]}, {"id": "1204.4990", "submitter": "Patrick Taillandier", "authors": "Patrick Taillandier (UMMISCO), Julien Gaffuri (COGIT)", "title": "Objective Function Designing Led by User Preferences Acquisition", "comments": "International Conference on Information Technology and Applications,\n  Hanoi : Viet Nam (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world problems can be defined as optimisation problems in which the\naim is to maximise an objective function. The quality of obtained solution is\ndirectly linked to the pertinence of the used objective function. However,\ndesigning such function, which has to translate the user needs, is usually\nfastidious. In this paper, a method to help user objective functions designing\nis proposed. Our approach, which is highly interactive, is based on man machine\ndialogue and more particularly on the comparison of problem instance solutions\nby the user. We propose an experiment in the domain of cartographic\ngeneralisation that shows promising results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 08:02:19 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Taillandier", "Patrick", "", "UMMISCO"], ["Gaffuri", "Julien", "", "COGIT"]]}, {"id": "1204.4991", "submitter": "Patrick Taillandier", "authors": "Patrick Taillandier (COGIT, UMMISCO), C\\'ecile Duch\\^ene (COGIT),\n  Alexis Drogoul (UMMISCO, MSI)", "title": "Knowledge revision in systems based on an informed tree search strategy\n  : application to cartographic generalisation", "comments": "Knowledge Revision; Problem Solving; Informed Tree Search Strategy;\n  Cartographic Generalisation., Paris : France (2008)", "journal-ref": null, "doi": "10.1145/1456223.1456281", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world problems can be expressed as optimisation problems. Solving\nthis kind of problems means to find, among all possible solutions, the one that\nmaximises an evaluation function. One approach to solve this kind of problem is\nto use an informed search strategy. The principle of this kind of strategy is\nto use problem-specific knowledge beyond the definition of the problem itself\nto find solutions more efficiently than with an uninformed strategy. This kind\nof strategy demands to define problem-specific knowledge (heuristics). The\nefficiency and the effectiveness of systems based on it directly depend on the\nused knowledge quality. Unfortunately, acquiring and maintaining such knowledge\ncan be fastidious. The objective of the work presented in this paper is to\npropose an automatic knowledge revision approach for systems based on an\ninformed tree search strategy. Our approach consists in analysing the system\nexecution logs and revising knowledge based on these logs by modelling the\nrevision problem as a knowledge space exploration problem. We present an\nexperiment we carried out in an application domain where informed search\nstrategies are often used: cartographic generalisation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 08:03:06 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Taillandier", "Patrick", "", "COGIT, UMMISCO"], ["Duch\u00eane", "C\u00e9cile", "", "COGIT"], ["Drogoul", "Alexis", "", "UMMISCO, MSI"]]}, {"id": "1204.5213", "submitter": "Bart de Keijzer", "authors": "Bart de Keijzer and Tomas B. Klos and Yingqian Zhang", "title": "Solving Weighted Voting Game Design Problems Optimally: Representations,\n  Synthesis, and Enumeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the inverse power index problem for weighted voting games: the\nproblem of finding a weighted voting game in which the power of the players is\nas close as possible to a certain target distribution. Our goal is to find\nalgorithms that solve this problem exactly. Thereto, we study various\nsubclasses of simple games, and their associated representation methods. We\nsurvey algorithms and impossibility results for the synthesis problem, i.e.,\nconverting a representation of a simple game into another representation.\n  We contribute to the synthesis problem by showing that it is impossible to\ncompute in polynomial time the list of ceiling coalitions (also known as\nshift-maximal losing coalitions) of a game from its list of roof coalitions\n(also known as shift-minimal winning coalitions), and vice versa.\n  Then, we proceed by studying the problem of enumerating the set of weighted\nvoting games. We present first a naive algorithm for this, running in doubly\nexponential time. Using our knowledge of the synthesis problem, we then improve\non this naive algorithm, and we obtain an enumeration algorithm that runs in\nquadratic exponential time (that is, O(2^(n^2) p(n)) for a polynomial p).\nMoreover, we show that this algorithm runs in output-polynomial time, making it\nthe best possible enumeration algorithm up to a polynomial factor.\n  Finally, we propose an exact anytime algorithm for the inverse power index\nproblem that runs in exponential time. This algorithm is straightforward and\ngeneral: it computes the error for each game enumerated, and outputs the game\nthat minimizes this error. By the genericity of our approach, our algorithm can\nbe used to find a weighted voting game that optimizes any exponential time\ncomputable function. We implement our algorithm for the case of the normalized\nBanzhaf index, and we perform experiments in order to study performance and\nerror convergence.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 21:35:00 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 14:57:18 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2013 11:58:03 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["de Keijzer", "Bart", ""], ["Klos", "Tomas B.", ""], ["Zhang", "Yingqian", ""]]}, {"id": "1204.5316", "submitter": "Maxime Lefrancois", "authors": "Maxime Lefran\\c{c}ois (INRIA Sophia Antipolis), Fabien Gandon (INRIA\n  Sophia Antipolis)", "title": "ILexicOn: toward an ECD-compliant interlingual lexical ontology\n  described with semantic web formalisms", "comments": null, "journal-ref": "MTT - 5th International Conference on Meaning-Text Theory - 2011\n  (2011) 155-164", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in bridging the world of natural language and the world of\nthe semantic web in particular to support natural multilingual access to the\nweb of data. In this paper we introduce a new type of lexical ontology called\ninterlingual lexical ontology (ILexicOn), which uses semantic web formalisms to\nmake each interlingual lexical unit class (ILUc) support the projection of its\nsemantic decomposition on itself. After a short overview of existing lexical\nontologies, we briefly introduce the semantic web formalisms we use. We then\npresent the three layered architecture of our approach: i) the interlingual\nlexical meta-ontology (ILexiMOn); ii) the ILexicOn where ILUcs are formally\ndefined; iii) the data layer. We illustrate our approach with a standalone\nILexicOn, and introduce and explain a concise human-readable notation to\nrepresent ILexicOns. Finally, we show how semantic web formalisms enable the\nprojection of a semantic decomposition on the decomposed ILUc.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 09:13:59 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Lefran\u00e7ois", "Maxime", "", "INRIA Sophia Antipolis"], ["Gandon", "Fabien", "", "INRIA\n  Sophia Antipolis"]]}, {"id": "1204.5357", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Learning AMP Chain Graphs under Faithfulness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with chain graphs under the alternative\nAndersson-Madigan-Perlman (AMP) interpretation. In particular, we present a\nconstraint based algorithm for learning an AMP chain graph a given probability\ndistribution is faithful to. We also show that the extension of Meek's\nconjecture to AMP chain graphs does not hold, which compromises the development\nof efficient and correct score+search learning algorithms under assumptions\nweaker than faithfulness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 12:49:47 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1204.5661", "submitter": "Yoshiharu Maeno", "authors": "Yoshiharu Maeno, Satoshi Morinaga, Hirokazu Matsushima, Kenichi Amagai", "title": "Transmission of distress in a bank credit network", "comments": "presented at the 4th World Congress on Social Simulation, Taipei,\n  September 2012", "journal-ref": "presented at the 4th World Congress on Social Simulation, Taipei,\n  September 2012", "doi": null, "report-no": null, "categories": "q-fin.RM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The European sovereign debt crisis has impaired many European banks. The\ndistress on the European banks may transmit worldwide, and result in a\nlarge-scale knock-on default of financial institutions. This study presents a\ncomputer simulation model to analyze the risk of insolvency of banks and\ndefaults in a bank credit network. Simulation experiments reproduce the\nknock-on default, and quantify the impact which is imposed on the number of\nbank defaults by heterogeneity of the bank credit network, the equity capital\nratio of banks, and the capital surcharge on big banks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 14:07:22 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2012 08:59:47 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Maeno", "Yoshiharu", ""], ["Morinaga", "Satoshi", ""], ["Matsushima", "Hirokazu", ""], ["Amagai", "Kenichi", ""]]}, {"id": "1204.5805", "submitter": "Chathuranga Widanapathirana", "authors": "C. Widanapathirana, J. Li, Y.A. Sekercioglu, M. Ivanovich, and P.\n  Fitzpatrick", "title": "Intelligent Automated Diagnosis of Client Device Bottlenecks in Private\n  Clouds", "comments": "2011 Fourth IEEE International Conference on Utility and Cloud\n  Computing (UCC)", "journal-ref": "Fourth IEEE International Conference on Utility and Cloud\n  Computing (UCC), 2011", "doi": "10.1109/UCC.2011.42", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an automated solution for rapid diagnosis of client device\nproblems in private cloud environments: the Intelligent Automated Client\nDiagnostic (IACD) system. Clients are diagnosed with the aid of Transmission\nControl Protocol (TCP) packet traces, by (i) observation of anomalous artifacts\noccurring as a result of each fault and (ii) subsequent use of the inference\ncapabilities of soft-margin Support Vector Machine (SVM) classifiers. The IACD\nsystem features a modular design and is extendible to new faults, with\ndetection capability unaffected by the TCP variant used at the client.\nExperimental evaluation of the IACD system in a controlled environment\ndemonstrated an overall diagnostic accuracy of 98%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 01:49:57 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Widanapathirana", "C.", ""], ["Li", "J.", ""], ["Sekercioglu", "Y. A.", ""], ["Ivanovich", "M.", ""], ["Fitzpatrick", "P.", ""]]}, {"id": "1204.5859", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore and Marco Schaerf", "title": "On the Complexity of Finding Second-Best Abductive Explanations", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijar.2015.05.009", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While looking for abductive explanations of a given set of manifestations, an\nordering between possible solutions is often assumed. The complexity of\nfinding/verifying optimal solutions is already known. In this paper we consider\nthe computational complexity of finding second-best solutions. We consider\ndifferent orderings, and consider also different possible definitions of what a\nsecond-best solution is.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 08:18:38 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 17:15:55 GMT"}, {"version": "v3", "created": "Thu, 14 May 2015 13:11:02 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Liberatore", "Paolo", ""], ["Schaerf", "Marco", ""]]}, {"id": "1204.5920", "submitter": "Christoph Benzmueller", "authors": "Christoph Benzmueller and Valerio Genovese", "title": "Quantified Conditional Logics are Fragments of HOL", "comments": "This work has been presented at the conference on Non-classical Modal\n  and Predicate Logics 2011, Guangzhou (Canton), China, 5-9 December 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semantic embedding of (constant domain) quantified conditional logic in\nclassical higher-order logic is presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 13:51:09 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Benzmueller", "Christoph", ""], ["Genovese", "Valerio", ""]]}, {"id": "1204.5981", "submitter": "Barnaby Martin", "authors": "Florent Madelaine and Barnaby Martin", "title": "Containment, Equivalence and Coreness from CSP to QCSP and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) and its quantified extensions,\nwhether without (QCSP) or with disjunction (QCSP_or), correspond naturally to\nthe model checking problem for three increasingly stronger fragments of\npositive first-order logic. Their complexity is often studied when\nparameterised by a fixed model, the so-called template.\n  It is a natural question to ask when two templates are equivalent, or more\ngenerally when one \"contain\" another, in the sense that a satisfied instance of\nthe first will be necessarily satisfied in the second. One can also ask for a\nsmallest possible equivalent template: this is known as the core for CSP.\n  We recall and extend previous results on containment, equivalence and\n\"coreness\" for QCSP_or before initiating a preliminary study of cores for QCSP\nwhich we characterise for certain structures and which turns out to be more\nelusive.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 16:46:25 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Madelaine", "Florent", ""], ["Martin", "Barnaby", ""]]}, {"id": "1204.6233", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Stefan Szeider", "title": "Strong Backdoors to Bounded Treewidth SAT", "comments": "arXiv admin note: substantial text overlap with arXiv:1202.4331", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are various approaches to exploiting \"hidden structure\" in instances of\nhard combinatorial problems to allow faster algorithms than for general\nunstructured or random instances. For SAT and its counting version #SAT, hidden\nstructure has been exploited in terms of decomposability and strong backdoor\nsets. Decomposability can be considered in terms of the treewidth of a graph\nthat is associated with the given CNF formula, for instance by considering\nclauses and variables as vertices of the graph, and making a variable adjacent\nwith all the clauses it appears in. On the other hand, a strong backdoor set of\na CNF formula is a set of variables such that each possible partial assignment\nto this set moves the formula into a fixed class for which (#)SAT can be solved\nin polynomial time.\n  In this paper we combine the two above approaches. In particular, we study\nthe algorithmic question of finding a small strong backdoor set into the class\nW_t of CNF formulas whose associated graphs have treewidth at most t. The main\nresults are positive:\n  (1) There is a cubic-time algorithm that, given a CNF formula F and two\nconstants k,t\\ge 0, either finds a strong W_t-backdoor set of size at most 2^k,\nor concludes that F has no strong W_t-backdoor set of size at most k.\n  (2) There is a cubic-time algorithm that, given a CNF formula F, computes the\nnumber of satisfying assignments of F or concludes that sb_t(F)>k, for any pair\nof constants k,t\\ge 0. Here, sb_t(F) denotes the size of a smallest strong\nW_t-backdoor set of F.\n  The significance of our results lies in the fact that they allow us to\nexploit algorithmically a hidden structure in formulas that is not accessible\nby any one of the two approaches (decomposability, backdoors) alone. Already a\nbackdoor size 1 on top of treewidth 1 (i.e., sb_1(F)=1) entails formulas of\narbitrarily large treewidth and arbitrarily large cycle cutsets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2012 14:51:23 GMT"}], "update_date": "2012-04-30", "authors_parsed": [["Gaspers", "Serge", ""], ["Szeider", "Stefan", ""]]}, {"id": "1204.6284", "submitter": "Romain Boulet", "authors": "Pierre Mazzega (LMTG), Dani\\`ele Bourcier (CERSA), Romain Boulet\n  (LMTG)", "title": "The Network of French Legal Codes", "comments": null, "journal-ref": "12th International Conference on Artificial Intelligence and Law\n  (ICAIL 2009), Barcelona : Espagne (2009)", "doi": "10.1145/1568234.1568271", "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an analysis of the codified Law of France as a structured system.\nFifty two legal codes are selected on the basis of explicit legal criteria and\nconsidered as vertices with their mutual quotations forming the edges in a\nnetwork which properties are analyzed relying on graph theory. We find that a\ngroup of 10 codes are simultaneously the most citing and the most cited by\nother codes, and are also strongly connected together so forming a \"rich club\"\nsub-graph. Three other code communities are also found that somewhat partition\nthe legal field is distinct thematic sub-domains. The legal interpretation of\nthis partition is opening new untraditional lines of research. We also\nconjecture that many legal systems are forming such new kind of networks that\nshare some properties in common with small worlds but are far denser. We\npropose to call \"concentrated world\".\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2011 07:56:00 GMT"}], "update_date": "2012-04-30", "authors_parsed": [["Mazzega", "Pierre", "", "LMTG"], ["Bourcier", "Dani\u00e8le", "", "CERSA"], ["Boulet", "Romain", "", "LMTG"]]}, {"id": "1204.6346", "submitter": "Mario Alviano", "authors": "Mario Alviano, Wolfgang Faber, Gianluigi Greco, and Nicola Leone", "title": "Magic Sets for Disjunctive Datalog Programs", "comments": "67 pages, 19 figures, preprint submitted to Artificial Intelligence", "journal-ref": null, "doi": "10.1007/978-3-642-28148-8_5", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new technique for the optimization of (partially) bound\nqueries over disjunctive Datalog programs with stratified negation is\npresented. The technique exploits the propagation of query bindings and extends\nthe Magic Set (MS) optimization technique.\n  An important feature of disjunctive Datalog is nonmonotonicity, which calls\nfor nondeterministic implementations, such as backtracking search. A\ndistinguishing characteristic of the new method is that the optimization can be\nexploited also during the nondeterministic phase. In particular, after some\nassumptions have been made during the computation, parts of the program may\nbecome irrelevant to a query under these assumptions. This allows for dynamic\npruning of the search space. In contrast, the effect of the previously defined\nMS methods for disjunctive Datalog is limited to the deterministic portion of\nthe process. In this way, the potential performance gain by using the proposed\nmethod can be exponential, as could be observed empirically.\n  The correctness of MS is established thanks to a strong relationship between\nMS and unfounded sets that has not been studied in the literature before. This\nknowledge allows for extending the method also to programs with stratified\nnegation in a natural way.\n  The proposed method has been implemented in DLV and various experiments have\nbeen conducted. Experimental results on synthetic data confirm the utility of\nMS for disjunctive Datalog, and they highlight the computational gain that may\nbe obtained by the new method w.r.t. the previously proposed MS methods for\ndisjunctive Datalog programs. Further experiments on real-world data show the\nbenefits of MS within an application scenario that has received considerable\nattention in recent years, the problem of answering user queries over possibly\ninconsistent databases originating from integration of autonomous sources of\ninformation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2012 23:17:00 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Alviano", "Mario", ""], ["Faber", "Wolfgang", ""], ["Greco", "Gianluigi", ""], ["Leone", "Nicola", ""]]}, {"id": "1204.6415", "submitter": "Michael  Gr. Voskoglou Prof. Dr.", "authors": "Michael Gr. Voskoglou", "title": "A Fuzzy Model for Analogical Problem Solving", "comments": "10 pages, 1 Table", "journal-ref": "International Journal of Fuzzy Logic Systems Vol. 2, No. 1, pp.\n  1-10, February 2012", "doi": "10.5121/ijfls.2012.2101", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a fuzzy model for the description of the process of\nAnalogical Reasoning by representing its main steps as fuzzy subsets of a set\nof linguistic labels characterizing the individuals' performance in each step\nand we use the Shannon- Wiener diversity index as a measure of the individuals'\nabilities in analogical problem solving. This model is compared with a\nstochastic model presented in author's earlier papers by introducing a finite\nMarkov chain on the steps of the process of Analogical Reasoning. A classroom\nexperiment is also presented to illustrate the use of our results in practice.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2012 16:16:46 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Voskoglou", "Michael Gr.", ""]]}, {"id": "1204.6529", "submitter": "Oliver Kullmann", "authors": "Matthew Gwynne and Oliver Kullmann", "title": "Generalising unit-refutation completeness and SLUR via nested input\n  resolution", "comments": "41 pages; second version improved formulations and added examples,\n  and more details regarding future directions, third version further examples,\n  improved and extended explanations, and more on SLUR, fourth version various\n  additional remarks and editorial improvements, fifth version more\n  explanations and references, typos corrected, improved wording", "journal-ref": "Journal of Automated Reasoning 52(1): 31-65 (2014)", "doi": "10.1007/s10817-013-9275-8", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two hierarchies of clause-sets, SLUR_k and UC_k, based on the\nclasses SLUR (Single Lookahead Unit Refutation), introduced in 1995, and UC\n(Unit refutation Complete), introduced in 1994.\n  The class SLUR, introduced in [Annexstein et al, 1995], is the class of\nclause-sets for which unit-clause-propagation (denoted by r_1) detects\nunsatisfiability, or where otherwise iterative assignment, avoiding obviously\nfalse assignments by look-ahead, always yields a satisfying assignment. It is\nnatural to consider how to form a hierarchy based on SLUR. Such investigations\nwere started in [Cepek et al, 2012] and [Balyo et al, 2012]. We present what we\nconsider the \"limit hierarchy\" SLUR_k, based on generalising r_1 by r_k, that\nis, using generalised unit-clause-propagation introduced in [Kullmann, 1999,\n2004].\n  The class UC, studied in [Del Val, 1994], is the class of Unit refutation\nComplete clause-sets, that is, those clause-sets for which unsatisfiability is\ndecidable by r_1 under any falsifying assignment. For unsatisfiable clause-sets\nF, the minimum k such that r_k determines unsatisfiability of F is exactly the\n\"hardness\" of F, as introduced in [Ku 99, 04]. For satisfiable F we use now an\nextension mentioned in [Ansotegui et al, 2008]: The hardness is the minimum k\nsuch that after application of any falsifying partial assignments, r_k\ndetermines unsatisfiability. The class UC_k is given by the clause-sets which\nhave hardness <= k. We observe that UC_1 is exactly UC.\n  UC_k has a proof-theoretic character, due to the relations between hardness\nand tree-resolution, while SLUR_k has an algorithmic character. The\ncorrespondence between r_k and k-times nested input resolution (or tree\nresolution using clause-space k+1) means that r_k has a dual nature: both\nalgorithmic and proof theoretic. This corresponds to a basic result of this\npaper, namely SLUR_k = UC_k.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 23:56:03 GMT"}, {"version": "v2", "created": "Tue, 29 May 2012 00:49:31 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2012 13:06:52 GMT"}, {"version": "v4", "created": "Thu, 25 Oct 2012 16:32:59 GMT"}, {"version": "v5", "created": "Mon, 21 Jan 2013 03:45:05 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Gwynne", "Matthew", ""], ["Kullmann", "Oliver", ""]]}, {"id": "1204.6552", "submitter": "Rajesh Chitnis", "authors": "Rajesh Chitnis, MohammadTaghi Hajiaghayi, Jonathan Katz, Koyel\n  Mukherjee", "title": "A Game-Theoretic Model Motivated by the DARPA Network Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a game-theoretic model to analyze events similar to\nthe 2009 \\emph{DARPA Network Challenge}, which was organized by the Defense\nAdvanced Research Projects Agency (DARPA) for exploring the roles that the\nInternet and social networks play in incentivizing wide-area collaborations.\nThe challenge was to form a group that would be the first to find the locations\nof ten moored weather balloons across the United States. We consider a model in\nwhich $N$ people (who can form groups) are located in some topology with a\nfixed coverage volume around each person's geographical location. We consider\nvarious topologies where the players can be located such as the Euclidean\n$d$-dimension space and the vertices of a graph. A balloon is placed in the\nspace and a group wins if it is the first one to report the location of the\nballoon. A larger team has a higher probability of finding the balloon, but we\nassume that the prize money is divided equally among the team members. Hence\nthere is a competing tension to keep teams as small as possible.\n  \\emph{Risk aversion} is the reluctance of a person to accept a bargain with\nan uncertain payoff rather than another bargain with a more certain, but\npossibly lower, expected payoff. In our model we consider the \\emph{isoelastic}\nutility function derived from the Arrow-Pratt measure of relative risk\naversion. The main aim is to analyze the structures of the groups in Nash\nequilibria for our model. For the $d$-dimensional Euclidean space ($d\\geq 1$)\nand the class of bounded degree regular graphs we show that in any Nash\nEquilibrium the \\emph{richest} group (having maximum expected utility per\nperson) covers a constant fraction of the total volume.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 05:38:46 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 05:02:06 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Katz", "Jonathan", ""], ["Mukherjee", "Koyel", ""]]}]