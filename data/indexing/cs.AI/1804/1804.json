[{"id": "1804.00038", "submitter": "Hang Ma", "authors": "Hang Ma, Wolfgang H\\\"onig, Liron Cohen, Tansel Uras, Hong Xu, T. K.\n  Satish Kumar, Nora Ayanian, Sven Koenig", "title": "Overview: A Hierarchical Framework for Plan Generation and Execution in\n  Multi-Robot Systems", "comments": null, "journal-ref": "IEEE Intelligent Systems, vol. 32, no. 6, pp. 6-12,\n  November/December 2017", "doi": "10.1109/MIS.2017.4531217", "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors present an overview of a hierarchical framework for coordinating\ntask- and motion-level operations in multirobot systems. Their framework is\nbased on the idea of using simple temporal networks to simultaneously reason\nabout precedence/causal constraints required for task-level coordination and\nsimple temporal constraints required to take some kinematic constraints of\nrobots into account. In the plan-generation phase, the framework provides a\ncomputationally scalable method for generating plans that achieve high-level\ntasks for groups of robots and take some of their kinematic constraints into\naccount. In the plan-execution phase, the framework provides a method for\nabsorbing an imperfect plan execution to avoid time-consuming re-planning in\nmany cases. The authors use the multirobot path-planning problem as a case\nstudy to present the key ideas behind their framework for the long-term\nautonomy of multirobot systems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 19:20:23 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Ma", "Hang", ""], ["H\u00f6nig", "Wolfgang", ""], ["Cohen", "Liron", ""], ["Uras", "Tansel", ""], ["Xu", "Hong", ""], ["Kumar", "T. K. Satish", ""], ["Ayanian", "Nora", ""], ["Koenig", "Sven", ""]]}, {"id": "1804.00062", "submitter": "Chris Paxton", "authors": "Chris Paxton, Yotam Barnoy, Kapil Katyal, Raman Arora, Gregory D.\n  Hager", "title": "Visual Robot Task Planning", "comments": "8 pages, IEEE format, currently in review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prospection, the act of predicting the consequences of many possible futures,\nis intrinsic to human planning and action, and may even be at the root of\nconsciousness. Surprisingly, this idea has been explored comparatively little\nin robotics. In this work, we propose a neural network architecture and\nassociated planning algorithm that (1) learns a representation of the world\nuseful for generating prospective futures after the application of high-level\nactions, (2) uses this generative model to simulate the result of sequences of\nhigh-level actions in a variety of environments, and (3) uses this same\nrepresentation to evaluate these actions and perform tree search to find a\nsequence of high-level actions in a new environment. Models are trained via\nimitation learning on a variety of domains, including navigation,\npick-and-place, and a surgical robotics task. Our approach allows us to\nvisualize intermediate motion goals and learn to plan complex activity from\nvisual information.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 21:52:49 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Paxton", "Chris", ""], ["Barnoy", "Yotam", ""], ["Katyal", "Kapil", ""], ["Arora", "Raman", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1804.00064", "submitter": "Jyh-Jing Hwang", "authors": "Jyh-Jing Hwang, Sergei Azernikov, Alexei A. Efros, and Stella X. Yu", "title": "Learning Beyond Human Expertise with Generative Models for Dental\n  Restorations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision has advanced significantly that many discriminative\napproaches such as object recognition are now widely used in real applications.\nWe present another exciting development that utilizes generative models for the\nmass customization of medical products such as dental crowns. In the dental\nindustry, it takes a technician years of training to design synthetic crowns\nthat restore the function and integrity of missing teeth. Each crown must be\ncustomized to individual patients, and it requires human expertise in a\ntime-consuming and labor-intensive process, even with computer-assisted design\nsoftware. We develop a fully automatic approach that learns not only from human\ndesigns of dental crowns, but also from natural spatial profiles between\nopposing teeth. The latter is hard to account for by technicians but important\nfor proper biting and chewing functions. Built upon a Generative Adversar-ial\nNetwork architecture (GAN), our deep learning model predicts the customized\ncrown-filled depth scan from the crown-missing depth scan and opposing depth\nscan. We propose to incorporate additional space constraints and statistical\ncompatibility into learning. Our automatic designs exceed human technicians'\nstandards for good morphology and functionality, and our algorithm is being\ntested for production use.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 21:56:38 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Hwang", "Jyh-Jing", ""], ["Azernikov", "Sergei", ""], ["Efros", "Alexei A.", ""], ["Yu", "Stella X.", ""]]}, {"id": "1804.00109", "submitter": "Jiankai Sun", "authors": "Jiankai Sun and Sobhan Moosavi and Rajiv Ramnath and Srinivasan\n  Parthasarathy", "title": "QDEE: Question Difficulty and Expertise Estimation in Community Question\n  Answering Sites", "comments": "Accepted in the Proceedings of the 12th International AAAI Conference\n  on Web and Social Media (ICWSM 2018). June 2018. Stanford, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a framework for Question Difficulty and Expertise\nEstimation (QDEE) in Community Question Answering sites (CQAs) such as Yahoo!\nAnswers and Stack Overflow, which tackles a fundamental challenge in\ncrowdsourcing: how to appropriately route and assign questions to users with\nthe suitable expertise. This problem domain has been the subject of much\nresearch and includes both language-agnostic as well as language conscious\nsolutions. We bring to bear a key language-agnostic insight: that users gain\nexpertise and therefore tend to ask as well as answer more difficult questions\nover time. We use this insight within the popular competition (directed) graph\nmodel to estimate question difficulty and user expertise by identifying key\nhierarchical structure within said model. An important and novel contribution\nhere is the application of \"social agony\" to this problem domain. Difficulty\nlevels of newly posted questions (the cold-start problem) are estimated by\nusing our QDEE framework and additional textual features. We also propose a\nmodel to route newly posted questions to appropriate users based on the\ndifficulty level of the question and the expertise of the user. Extensive\nexperiments on real world CQAs such as Yahoo! Answers and Stack Overflow data\ndemonstrate the improved efficacy of our approach over contemporary\nstate-of-the-art models. The QDEE framework also allows us to characterize user\nexpertise in novel ways by identifying interesting patterns and roles played by\ndifferent users in such CQAs.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 02:56:19 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 18:16:59 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Sun", "Jiankai", ""], ["Moosavi", "Sobhan", ""], ["Ramnath", "Rajiv", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1804.00168", "submitter": "Piotr Mirowski", "authors": "Piotr Mirowski, Matthew Koichi Grimes, Mateusz Malinowski, Karl Moritz\n  Hermann, Keith Anderson, Denis Teplyashin, Karen Simonyan, Koray Kavukcuoglu,\n  Andrew Zisserman, Raia Hadsell", "title": "Learning to Navigate in Cities Without a Map", "comments": "17 pages, 16 figures, published at NeurIPS 2018", "journal-ref": "Neural Information Processing Systems 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating through unstructured environments is a basic capability of\nintelligent creatures, and thus is of fundamental interest in the study and\ndevelopment of artificial intelligence. Long-range navigation is a complex\ncognitive task that relies on developing an internal representation of space,\ngrounded by recognisable landmarks and robust visual processing, that can\nsimultaneously support continuous self-localisation (\"I am here\") and a\nrepresentation of the goal (\"I am going there\"). Building upon recent research\nthat applies deep reinforcement learning to maze navigation problems, we\npresent an end-to-end deep reinforcement learning approach that can be applied\non a city scale. Recognising that successful navigation relies on integration\nof general policies with locale-specific knowledge, we propose a dual pathway\narchitecture that allows locale-specific features to be encapsulated, while\nstill enabling transfer to multiple cities. We present an interactive\nnavigation environment that uses Google StreetView for its photographic content\nand worldwide coverage, and demonstrate that our learning method allows agents\nto learn to navigate multiple cities and to traverse to target destinations\nthat may be kilometres away. The project webpage http://streetlearn.cc contains\na video summarising our research and showing the trained agent in diverse city\nenvironments and on the transfer task, the form to request the StreetLearn\ndataset and links to further resources. The StreetLearn environment code is\navailable at https://github.com/deepmind/streetlearn\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 12:58:12 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 11:14:06 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2019 00:37:15 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Mirowski", "Piotr", ""], ["Grimes", "Matthew Koichi", ""], ["Malinowski", "Mateusz", ""], ["Hermann", "Karl Moritz", ""], ["Anderson", "Keith", ""], ["Teplyashin", "Denis", ""], ["Simonyan", "Karen", ""], ["Kavukcuoglu", "Koray", ""], ["Zisserman", "Andrew", ""], ["Hadsell", "Raia", ""]]}, {"id": "1804.00198", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Sharada P. Mohanty, Carmichael Ong, Jennifer L.\n  Hicks, Sean F. Carroll, Sergey Levine, Marcel Salath\\'e, Scott L. Delp", "title": "Learning to Run challenge: Synthesizing physiologically accurate motion\n  using deep reinforcement learning", "comments": "16 pages, 8 figures, a competition at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing physiologically-accurate human movement in a variety of\nconditions can help practitioners plan surgeries, design experiments, or\nprototype assistive devices in simulated environments, reducing time and costs\nand improving treatment outcomes. Because of the large and complex solution\nspaces of biomechanical models, current methods are constrained to specific\nmovements and models, requiring careful design of a controller and hindering\nmany possible applications. We sought to discover if modern optimization\nmethods efficiently explore these complex spaces. To do this, we posed the\nproblem as a competition in which participants were tasked with developing a\ncontroller to enable a physiologically-based human model to navigate a complex\nobstacle course as quickly as possible, without using any experimental data.\nThey were provided with a human musculoskeletal model and a physics-based\nsimulation environment. In this paper, we discuss the design of the\ncompetition, technical difficulties, results, and analysis of the top\ncontrollers. The challenge proved that deep reinforcement learning techniques,\ndespite their high computational cost, can be successfully employed as an\noptimization method for synthesizing physiologically feasible motion in\nhigh-dimensional biomechanical systems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 17:56:28 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Mohanty", "Sharada P.", ""], ["Ong", "Carmichael", ""], ["Hicks", "Jennifer L.", ""], ["Carroll", "Sean F.", ""], ["Levine", "Sergey", ""], ["Salath\u00e9", "Marcel", ""], ["Delp", "Scott L.", ""]]}, {"id": "1804.00211", "submitter": "Lakhdar Sais", "authors": "Abdelhamid Boudane, Said Jabbour, Badran Raddaoui, and Lakhdar Sais", "title": "Efficient Encodings of Conditional Cardinality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the encoding of many real-world problems to propositional satisfiability,\nthe cardinality constraint is a recurrent constraint that needs to be managed\neffectively. Several efficient encodings have been proposed while missing that\nsuch a constraint can be involved in a more general propositional formulation.\nTo avoid combinatorial explosion, Tseitin principle usually used to translate\nsuch general propositional formula to Conjunctive Normal Form (CNF), introduces\nfresh propositional variables to represent sub-formulas and/or complex\ncontraints. Thanks to Plaisted and Greenbaum improvement, the polarity of the\nsub-formula $\\Phi$ is taken into account leading to conditional constraints of\nthe form $y\\rightarrow \\Phi$, or $\\Phi\\rightarrow y$, where $y$ is a fresh\npropositional variable. In the case where $\\Phi$ represents a cardinality\nconstraint, such translation leads to conditional cardinality constraints\nsubject of the present paper. We first show that when all the clauses encoding\nthe cardinality constraint are augmented with an additional new variable, most\nof the well-known encodings cease to maintain the generalized arc consistency\nproperty. Then, we consider some of these encodings and show how they can be\nextended to recover such important property. An experimental validation is\nconducted on a SAT-based pattern mining application, where such conditional\ncardinality constraints is a cornerstone, showing the relevance of our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 20:29:07 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Boudane", "Abdelhamid", ""], ["Jabbour", "Said", ""], ["Raddaoui", "Badran", ""], ["Sais", "Lakhdar", ""]]}, {"id": "1804.00245", "submitter": "Sara Bunian", "authors": "Sara Bunian, Alessandro Canossa, Randy Colvin, Magy Seif El-Nasr", "title": "Modeling Individual Differences in Game Behavior using HMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Player modeling is an important concept that has gained much attention in\ngame research due to its utility in developing adaptive techniques to target\nbetter designs for engagement and retention. Previous work has explored\nmodeling individual differences using machine learning algorithms per- formed\non aggregated game actions. However, players' individual differences may be\nbetter manifested through sequential patterns of the in-game player's actions.\nWhile few works have explored sequential analysis of player data, none have\nexplored the use of Hidden Markov Models (HMM) to model individual differences,\nwhich is the topic of this paper. In par- ticular, we developed a modeling\napproach using data col- lected from players playing a Role-Playing Game (RPG).\nOur proposed approach is two fold: 1. We present a Hidden Markov Model (HMM) of\nplayer in-game behaviors to model individual differences, and 2. using the\noutput of the HMM, we generate behavioral features used to classify real world\nplayers' characteristics, including game expertise and the big five personality\ntraits. Our results show predictive power for some of personality traits, such\nas game expertise and conscientiousness, but the most influential factor was\ngame expertise.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 01:43:48 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Bunian", "Sara", ""], ["Canossa", "Alessandro", ""], ["Colvin", "Randy", ""], ["El-Nasr", "Magy Seif", ""]]}, {"id": "1804.00293", "submitter": "Kien Do", "authors": "Kien Do, Truyen Tran, Thin Nguyen, Svetha Venkatesh", "title": "Attentional Multilabel Learning over Graphs: A Message Passing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a largely open problem of multilabel classification over graphs.\nUnlike traditional vector input, a graph has rich variable-size substructures\nwhich are related to the labels in some ways. We believe that uncovering these\nrelations might hold the key to classification performance and explainability.\nWe introduce GAML (Graph Attentional Multi-Label learning), a novel graph\nneural network that can handle this problem effectively. GAML regards labels as\nauxiliary nodes and models them in conjunction with the input graph. By\napplying message passing and attention mechanisms to both the label nodes and\nthe input nodes iteratively, GAML can capture the relations between the labels\nand the input subgraphs at various resolution scales. Moreover, our model can\ntake advantage of explicit label dependencies. It also scales linearly with the\nnumber of labels and graph size thanks to our proposed hierarchical attention.\nWe evaluate GAML on an extensive set of experiments with both graph-structured\ninputs and classical unstructured inputs. The results show that GAML\nsignificantly outperforms other competing methods. Importantly, GAML enables\nintuitive visualizations for better understanding of the label-substructure\nrelations and explanation of the model behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 13:01:24 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 07:19:29 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Nguyen", "Thin", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1804.00325", "submitter": "James Lucas", "authors": "James Lucas, Shengyang Sun, Richard Zemel, Roger Grosse", "title": "Aggregated Momentum: Stability Through Passive Damping", "comments": "11 primary pages, 11 supplementary pages, 12 figures total", "journal-ref": "International Conference on Learning Representations, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum is a simple and widely used trick which allows gradient-based\noptimizers to pick up speed along low curvature directions. Its performance\ndepends crucially on a damping coefficient $\\beta$. Large $\\beta$ values can\npotentially deliver much larger speedups, but are prone to oscillations and\ninstability; hence one typically resorts to small values such as 0.5 or 0.9. We\npropose Aggregated Momentum (AggMo), a variant of momentum which combines\nmultiple velocity vectors with different $\\beta$ parameters. AggMo is trivial\nto implement, but significantly dampens oscillations, enabling it to remain\nstable even for aggressive $\\beta$ values such as 0.999. We reinterpret\nNesterov's accelerated gradient descent as a special case of AggMo and analyze\nrates of convergence for quadratic objectives. Empirically, we find that AggMo\nis a suitable drop-in replacement for other momentum methods, and frequently\ndelivers faster convergence.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 17:53:03 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 16:49:44 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 14:09:52 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Lucas", "James", ""], ["Sun", "Shengyang", ""], ["Zemel", "Richard", ""], ["Grosse", "Roger", ""]]}, {"id": "1804.00361", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Sharada Prasanna Mohanty, Carmichael Ong,\n  Zhewei Huang, Shuchang Zhou, Anton Pechenko, Adam Stelmaszczyk, Piotr\n  Jarosik, Mikhail Pavlov, Sergey Kolesnikov, Sergey Plis, Zhibo Chen, Zhizheng\n  Zhang, Jiale Chen, Jun Shi, Zhuobin Zheng, Chun Yuan, Zhihui Lin, Henryk\n  Michalewski, Piotr Mi{\\l}o\\'s, B{\\l}a\\.zej Osi\\'nski, Andrew Melnik, Malte\n  Schilling, Helge Ritter, Sean Carroll, Jennifer Hicks, Sergey Levine, Marcel\n  Salath\\'e, Scott Delp", "title": "Learning to Run challenge solutions: Adapting reinforcement learning\n  methods for neuromusculoskeletal environments", "comments": "27 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the NIPS 2017 Learning to Run challenge, participants were tasked with\nbuilding a controller for a musculoskeletal model to make it run as fast as\npossible through an obstacle course. Top participants were invited to describe\ntheir algorithms. In this work, we present eight solutions that used deep\nreinforcement learning approaches, based on algorithms such as Deep\nDeterministic Policy Gradient, Proximal Policy Optimization, and Trust Region\nPolicy Optimization. Many solutions use similar relaxations and heuristics,\nsuch as reward shaping, frame skipping, discretization of the action space,\nsymmetry, and policy blending. However, each of the eight teams implemented\ndifferent modifications of the known algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 00:19:31 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Mohanty", "Sharada Prasanna", ""], ["Ong", "Carmichael", ""], ["Huang", "Zhewei", ""], ["Zhou", "Shuchang", ""], ["Pechenko", "Anton", ""], ["Stelmaszczyk", "Adam", ""], ["Jarosik", "Piotr", ""], ["Pavlov", "Mikhail", ""], ["Kolesnikov", "Sergey", ""], ["Plis", "Sergey", ""], ["Chen", "Zhibo", ""], ["Zhang", "Zhizheng", ""], ["Chen", "Jiale", ""], ["Shi", "Jun", ""], ["Zheng", "Zhuobin", ""], ["Yuan", "Chun", ""], ["Lin", "Zhihui", ""], ["Michalewski", "Henryk", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["Osi\u0144ski", "B\u0142a\u017cej", ""], ["Melnik", "Andrew", ""], ["Schilling", "Malte", ""], ["Ritter", "Helge", ""], ["Carroll", "Sean", ""], ["Hicks", "Jennifer", ""], ["Levine", "Sergey", ""], ["Salath\u00e9", "Marcel", ""], ["Delp", "Scott", ""]]}, {"id": "1804.00373", "submitter": "Amey Karkare", "authors": "Saksham Sharma, Pallav Agarwal, Parv Mor, Amey Karkare", "title": "TipsC: Tips and Corrections for programming MOOCs", "comments": "Full paper for the poster accepted at AIED 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of MOOCs in academic institutions, it has become\nimperative to come up with better techniques to solve the tutoring and grading\nproblems posed by programming courses. Programming being the new 'writing', it\nbecomes a challenge to ensure that a large section of the society is exposed to\nprogramming. Due to the gradient in learning abilities of students, the course\ninstructor must ensure that everyone can cope up with the material, and receive\nadequate help in completing assignments while learning along the way. We\nintroduce TipsC for this task. By analyzing a large number of correct\nsubmissions, TipsC can search for correct codes resembling a given incorrect\nsolution. Without revealing the actual code, TipsC then suggests changes in the\nincorrect code to help the student fix logical runtime errors. In addition,\nthis also serves as a cluster visualization tool for the instructor, revealing\ndifferent patterns in user submissions. We evaluated the effectiveness of\nTipsC's clustering algorithm on data collected from previous offerings of an\nintroductory programming course conducted at IIT Kanpur where the grades were\ngiven by human TAs. The results show the weighted average variance of marks for\nclusters when similar submissions are grouped together is 47% less compared to\nthe case when all programs are grouped together.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 02:17:53 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Sharma", "Saksham", ""], ["Agarwal", "Pallav", ""], ["Mor", "Parv", ""], ["Karkare", "Amey", ""]]}, {"id": "1804.00421", "submitter": "Michael Gr. Voskoglou Prof. Dr.", "authors": "Michael Gr. Voskoglou", "title": "A Study of Student Learning Skills Using Fuzzy Relation Equations", "comments": "8 pages, 1 Table", "journal-ref": "Egyptian Computer Science Journal, 42(1), 80-87, 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy relation equations (FRE)are associated with the composition of binary\nfuzzy relations. In the present work FRE are used as a tool for studying the\nprocess of learning a new subject matter by a student class. A classroom\napplication and other csuitable examples connected to the student learning of\nthe derivative are also presented illustrating our results and useful\nconclusions are obtained.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 07:31:34 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Voskoglou", "Michael Gr.", ""]]}, {"id": "1804.00423", "submitter": "Michael Gr. Voskoglou Prof. Dr.", "authors": "Michael Gr. Voskoglou, Yiannis Theodorou", "title": "Application of Grey Numbers to Assessment Processes", "comments": null, "journal-ref": "International Journal of Applications of Fuzzy Sets and Artificial\n  Intelligence, 7, 273-280, 2017", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of grey systems plays an important role in science,engineering and\nin the everyday life in general for handling approximate data. In the present\npaper grey numbers are used as a tool for assessing with linguistic expressions\nthe mean performance of a group of objects participating in a certain activity.\nTwo applications to student and football player assessment are also presented\nillustrating our results.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 07:45:55 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Voskoglou", "Michael Gr.", ""], ["Theodorou", "Yiannis", ""]]}, {"id": "1804.00432", "submitter": "Jong Chul Ye", "authors": "Dongwook Lee, Jaejun Yoo, Sungho Tak and Jong Chul Ye", "title": "Deep Residual Learning for Accelerated MRI using Magnitude and Phase\n  Networks", "comments": "This paper will appear in IEEE Trans. Biomedical Engineering, Special\n  Section on Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerated magnetic resonance (MR) scan acquisition with compressed sensing\n(CS) and parallel imaging is a powerful method to reduce MR imaging scan time.\nHowever, many reconstruction algorithms have high computational costs. To\naddress this, we investigate deep residual learning networks to remove aliasing\nartifacts from artifact corrupted images. The proposed deep residual learning\nnetworks are composed of magnitude and phase networks that are separately\ntrained. If both phase and magnitude information are available, the proposed\nalgorithm can work as an iterative k-space interpolation algorithm using\nframelet representation. When only magnitude data is available, the proposed\napproach works as an image domain post-processing algorithm. Even with strong\ncoherent aliasing artifacts, the proposed network successfully learned and\nremoved the aliasing artifacts, whereas current parallel and CS reconstruction\nmethods were unable to remove these artifacts. Comparisons using single and\nmultiple coil show that the proposed residual network provides good\nreconstruction results with orders of magnitude faster computational time than\nexisting compressed sensing methods. The proposed deep learning framework may\nhave a great potential for accelerated MR reconstruction by generating accurate\nresults immediately.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 09:08:02 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Lee", "Dongwook", ""], ["Yoo", "Jaejun", ""], ["Tak", "Sungho", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1804.00456", "submitter": "Oleksii Zhelo", "authors": "Oleksii Zhelo, Jingwei Zhang, Lei Tai, Ming Liu, Wolfram Burgard", "title": "Curiosity-driven Exploration for Mapless Navigation with Deep\n  Reinforcement Learning", "comments": "5 pages, 4 figures; to be published in MLPC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates exploration strategies of Deep Reinforcement Learning\n(DRL) methods to learn navigation policies for mobile robots. In particular, we\naugment the normal external reward for training DRL algorithms with intrinsic\nreward signals measured by curiosity. We test our approach in a mapless\nnavigation setting, where the autonomous agent is required to navigate without\nthe occupancy map of the environment, to targets whose relative locations can\nbe easily acquired through low-cost solutions (e.g., visible light\nlocalization, Wi-Fi signal localization). We validate that the intrinsic\nmotivation is crucial for improving DRL performance in tasks with challenging\nexploration requirements. Our experimental results show that our proposed\nmethod is able to more effectively learn navigation policies, and has better\ngeneralization capabilities in previously unseen environments. A video of our\nexperimental results can be found at https://goo.gl/pWbpcF.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 11:40:00 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:08:26 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhelo", "Oleksii", ""], ["Zhang", "Jingwei", ""], ["Tai", "Lei", ""], ["Liu", "Ming", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1804.00492", "submitter": "Shruti Mittal", "authors": "Shruti Mittal and Dattaraj Rao", "title": "Regional Priority Based Anomaly Detection using Autoencoders", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "2018TDS0001", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent times, autoencoders, besides being used for compression, have\nbeen proven quite useful even for regenerating similar images or help in image\ndenoising. They have also been explored for anomaly detection in a few cases.\nHowever, due to location invariance property of convolutional neural network,\nautoencoders tend to learn from or search for learned features in the complete\nimage. This creates issues when all the items in the image are not equally\nimportant and their location matters. For such cases, a semi supervised\nsolution - regional priority based autoencoder (RPAE) has been proposed. In\nthis model, similar to object detection models, a region proposal network\nidentifies the relevant areas in the images as belonging to one of the\npredefined categories and then those bounding boxes are fed into appropriate\ndecoder based on the category they belong to. Finally, the error scores from\nall the decoders are combined based on their importance to provide total\nreconstruction error.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 13:49:01 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Mittal", "Shruti", ""], ["Rao", "Dattaraj", ""]]}, {"id": "1804.00499", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini and Radha Poovendran", "title": "Semantic Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to be vulnerable to adversarial examples,\ni.e., images that are maliciously perturbed to fool the model. Generating\nadversarial examples has been mostly limited to finding small perturbations\nthat maximize the model prediction error. Such images, however, contain\nartificial perturbations that make them somewhat distinguishable from natural\nimages. This property is used by several defense methods to counter adversarial\nexamples by applying denoising filters or training the model to be robust to\nsmall perturbations.\n  In this paper, we introduce a new class of adversarial examples, namely\n\"Semantic Adversarial Examples,\" as images that are arbitrarily perturbed to\nfool the model, but in such a way that the modified image semantically\nrepresents the same object as the original image. We formulate the problem of\ngenerating such images as a constrained optimization problem and develop an\nadversarial transformation based on the shape bias property of human cognitive\nsystem. In our method, we generate adversarial images by first converting the\nRGB image into the HSV (Hue, Saturation and Value) color space and then\nrandomly shifting the Hue and Saturation components, while keeping the Value\ncomponent the same. Our experimental results on CIFAR10 dataset show that the\naccuracy of VGG16 network on adversarial color-shifted images is 5.7%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 18:02:14 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Hosseini", "Hossein", ""], ["Poovendran", "Radha", ""]]}, {"id": "1804.00506", "submitter": "Mengnan Du", "authors": "Mengnan Du, Ninghao Liu, Qingquan Song, Xia Hu", "title": "Towards Explanation of DNN-based Prediction with Guided Feature\n  Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks (DNN) have become an effective computational tool,\nthe prediction results are often criticized by the lack of interpretability,\nwhich is essential in many real-world applications such as health informatics.\nExisting attempts based on local interpretations aim to identify relevant\nfeatures contributing the most to the prediction of DNN by monitoring the\nneighborhood of a given input. They usually simply ignore the intermediate\nlayers of the DNN that might contain rich information for interpretation. To\nbridge the gap, in this paper, we propose to investigate a guided feature\ninversion framework for taking advantage of the deep architectures towards\neffective interpretation. The proposed framework not only determines the\ncontribution of each feature in the input but also provides insights into the\ndecision-making process of DNN models. By further interacting with the neuron\nof the target category at the output layer of the DNN, we enforce the\ninterpretation result to be class-discriminative. We apply the proposed\ninterpretation model to different CNN architectures to provide explanations for\nimage data and conduct extensive experiments on ImageNet and PASCAL VOC07\ndatasets. The interpretation results demonstrate the effectiveness of our\nproposed framework in providing class-discriminative interpretation for\nDNN-based prediction.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:35:26 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 04:47:32 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Song", "Qingquan", ""], ["Hu", "Xia", ""]]}, {"id": "1804.00532", "submitter": "Zhou Xing Dr", "authors": "Zhou Xing, Fei Xiao", "title": "Predictions of short-term driving intention using recurrent neural\n  network on sequential data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions of driver's intentions and their behaviors using the road is of\ngreat importance for planning and decision making processes of autonomous\ndriving vehicles. In particular, relatively short-term driving intentions are\nthe fundamental units that constitute more sophisticated driving goals,\nbehaviors, such as overtaking the slow vehicle in front, exit or merge onto a\nhigh way, etc. While it is not uncommon that most of the time human driver can\nrationalize, in advance, various on-road behaviors, intentions, as well as the\nassociated risks, aggressiveness, reciprocity characteristics, etc., such\nreasoning skills can be challenging and difficult for an autonomous driving\nsystem to learn. In this article, we demonstrate a disciplined methodology that\ncan be used to build and train a predictive drive system, therefore to learn\nthe on-road characteristics aforementioned.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:14:50 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Xing", "Zhou", ""], ["Xiao", "Fei", ""]]}, {"id": "1804.00538", "submitter": "Wei Zhao", "authors": "Wei Zhao, Jianbo Ye, Min Yang, Zeyang Lei, Suofei Zhang, Zhou Zhao", "title": "Investigating Capsule Networks with Dynamic Routing for Text\n  Classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we explore capsule networks with dynamic routing for text\nclassification. We propose three strategies to stabilize the dynamic routing\nprocess to alleviate the disturbance of some noise capsules which may contain\n\"background\" information or have not been successfully trained. A series of\nexperiments are conducted with capsule networks on six text classification\nbenchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets,\nwhich shows the effectiveness of capsule networks for text classification. We\nadditionally show that capsule networks exhibit significant improvement when\ntransfer single-label to multi-label text classification over strong baseline\nmethods. To the best of our knowledge, this is the first work that capsule\nnetworks have been empirically investigated for text modeling.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 02:27:42 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 09:02:46 GMT"}, {"version": "v3", "created": "Wed, 20 Jun 2018 09:06:09 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 09:58:52 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhao", "Wei", ""], ["Ye", "Jianbo", ""], ["Yang", "Min", ""], ["Lei", "Zeyang", ""], ["Zhang", "Suofei", ""], ["Zhao", "Zhou", ""]]}, {"id": "1804.00595", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier, Cezary Kaliszyk, Josef Urban", "title": "Learning to Reason with HOL4 tactics", "comments": "LPAR-21. 21st International Conference on Logic for Programming,\n  Artificial Intelligence and Reasoning. EasyChair 2017", "journal-ref": null, "doi": "10.29007/ntlb", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques combining machine learning with translation to automated reasoning\nhave recently become an important component of formal proof assistants. Such\n\"hammer\" tech- niques complement traditional proof assistant automation as\nimplemented by tactics and decision procedures. In this paper we present a\nunified proof assistant automation approach which attempts to automate the\nselection of appropriate tactics and tactic-sequences com- bined with an\noptimized small-scale hammering approach. We implement the technique as a\ntactic-level automation for HOL4: TacticToe. It implements a modified\nA*-algorithm directly in HOL4 that explores different tactic-level proof paths,\nguiding their selection by learning from a large number of previous\ntactic-level proofs. Unlike the existing hammer methods, TacticToe avoids\ntranslation to FOL, working directly on the HOL level. By combining tactic\nprediction and premise selection, TacticToe is able to re-prove 39 percent of\n7902 HOL4 theorems in 5 seconds whereas the best single HOL(y)Hammer strategy\nsolves 32 percent in the same amount of time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 15:41:09 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Gauthier", "Thibault", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1804.00596", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier, Cezary Kaliszyk, Josef Urban, Ramana Kumar, Michael\n  Norrish", "title": "Learning to Prove with Tactics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a automated tactical prover TacticToe on top of the HOL4\ninteractive theorem prover. TacticToe learns from human proofs which\nmathematical technique is suitable in each proof situation. This knowledge is\nthen used in a Monte Carlo tree search algorithm to explore promising\ntactic-level proof paths. On a single CPU, with a time limit of 60 seconds,\nTacticToe proves 66.4 percent of the 7164 theorems in HOL4's standard library,\nwhereas E prover with auto-schedule solves 34.5 percent. The success rate rises\nto 69.0 percent by combining the results of TacticToe and E prover.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 15:43:17 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Gauthier", "Thibault", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Kumar", "Ramana", ""], ["Norrish", "Michael", ""]]}, {"id": "1804.00617", "submitter": "Ario Santoso", "authors": "Ario Santoso", "title": "Specification-Driven Multi-Perspective Predictive Business Process\n  Monitoring (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive analysis in business process monitoring aims at forecasting the\nfuture information of a running business process. The prediction is typically\nmade based on the model extracted from historical process execution logs (event\nlogs). In practice, different business domains might require different kinds of\npredictions. Hence, it is important to have a means for properly specifying the\ndesired prediction tasks, and a mechanism to deal with these various prediction\ntasks. Although there have been many studies in this area, they mostly focus on\na specific prediction task. This work introduces a language for specifying the\ndesired prediction tasks, and this language allows us to express various kinds\nof prediction tasks. This work also presents a mechanism for automatically\ncreating the corresponding prediction model based on the given specification.\nThus, different from previous studies, our approach enables us to deal with\nvarious kinds of prediction tasks based on the given specification. A prototype\nimplementing our approach has been developed and experiments using a real-life\nevent log have been conducted.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 16:26:35 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 17:37:58 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Santoso", "Ario", ""]]}, {"id": "1804.00645", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Allan Jabri, Pieter Abbeel, Sergey Levine, Chelsea\n  Finn", "title": "Universal Planning Networks", "comments": "Videos available at https://sites.google.com/view/upn-public/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:51:53 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 17:36:36 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Srinivas", "Aravind", ""], ["Jabri", "Allan", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1804.00732", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Zhuo Chen, Yong Zhao, Vadim Mazalov, Yifan Gong,\n  Biing-Hwang (Fred) Juang", "title": "Speaker-Invariant Training via Adversarial Learning", "comments": "5 pages, 3 figures, ICASSP 2018", "journal-ref": "2018 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Calgary, Canada", "doi": "10.1109/ICASSP.2018.8461932", "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adversarial multi-task learning scheme, aiming at actively\ncurtailing the inter-talker feature variability while maximizing its senone\ndiscriminability so as to enhance the performance of a deep neural network\n(DNN) based ASR system. We call the scheme speaker-invariant training (SIT). In\nSIT, a DNN acoustic model and a speaker classifier network are jointly\noptimized to minimize the senone (tied triphone state) classification loss, and\nsimultaneously mini-maximize the speaker classification loss. A\nspeaker-invariant and senone-discriminative deep feature is learned through\nthis adversarial multi-task learning. With SIT, a canonical DNN acoustic model\nwith significantly reduced variance in its output probabilities is learned with\nno explicit speaker-independent (SI) transformations or speaker-specific\nrepresentations used in training or testing. Evaluated on the CHiME-3 dataset,\nthe SIT achieves 4.99% relative word error rate (WER) improvement over the\nconventional SI acoustic model. With additional unsupervised speaker\nadaptation, the speaker-adapted (SA) SIT model achieves 4.86% relative WER gain\nover the SA SI acoustic model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 21:09:30 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 07:43:31 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 15:35:29 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Chen", "Zhuo", "", "Fred"], ["Zhao", "Yong", "", "Fred"], ["Mazalov", "Vadim", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1804.00768", "submitter": "Mohammad Hasanzadeh Mofrad", "authors": "Mohammad Hasanzadeh Mofrad and S. K. Chang", "title": "A Bi-population Particle Swarm Optimizer for Learning Automata based\n  Slow Intelligent System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Swarm Optimization (PSO) is an Evolutionary Algorithm (EA) that\nutilizes a swarm of particles to solve an optimization problem. Slow\nIntelligence System (SIS) is a learning framework which slowly learns the\nsolution to a problem performing a series of operations. Moreover, Learning\nAutomata (LA) are minuscule but effective decision making entities which are\nbest suited to act as a controller component. In this paper, we combine two\nisolate populations of PSO to forge the Adaptive Intelligence Optimizer (AIO)\nwhich harnesses the advantages of a bi-population PSO to escape from the local\nminimum and avoid premature convergence. Furthermore, using the rich framework\nof SIS and the nifty control theory that LA derived from, we find the perfect\nmatching between SIS and LA where acting slowly is the pillar of both of them.\nBoth SIS and LA need time to converge to the optimal decision where this\nenables AIO to outperform standard PSO having an incomparable performance on\nevolutionary optimization benchmark functions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 00:12:07 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Mofrad", "Mohammad Hasanzadeh", ""], ["Chang", "S. K.", ""]]}, {"id": "1804.00810", "submitter": "Kun Shao", "authors": "Kun Shao, Yuanheng Zhu, Dongbin Zhao", "title": "StarCraft Micromanagement with Reinforcement Learning and Curriculum\n  Transfer Learning", "comments": "12 pages, 14 figures, accepted to IEEE Transactions on Emerging\n  Topics in Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time strategy games have been an important field of game artificial\nintelligence in recent years. This paper presents a reinforcement learning and\ncurriculum transfer learning method to control multiple units in StarCraft\nmicromanagement. We define an efficient state representation, which breaks down\nthe complexity caused by the large state space in the game environment. Then a\nparameter sharing multi-agent gradientdescent Sarsa({\\lambda}) (PS-MAGDS)\nalgorithm is proposed to train the units. The learning policy is shared among\nour units to encourage cooperative behaviors. We use a neural network as a\nfunction approximator to estimate the action-value function, and propose a\nreward function to help units balance their move and attack. In addition, a\ntransfer learning method is used to extend our model to more difficult\nscenarios, which accelerates the training process and improves the learning\nperformance. In small scale scenarios, our units successfully learn to combat\nand defeat the built-in AI with 100% win rates. In large scale scenarios,\ncurriculum transfer learning method is used to progressively train a group of\nunits, and shows superior performance over some baseline methods in target\nscenarios. With reinforcement learning and curriculum transfer learning, our\nunits are able to learn appropriate strategies in StarCraft micromanagement\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:57:02 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Shao", "Kun", ""], ["Zhu", "Yuanheng", ""], ["Zhao", "Dongbin", ""]]}, {"id": "1804.00823", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, and\n  Vadim Sheinin", "title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks", "comments": "16 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Sequence to Sequence learning (Seq2Seq) technique and its\nnumerous variants achieve excellent performance on many tasks. However, many\nmachine learning tasks have inputs naturally represented as graphs; existing\nSeq2Seq models face a significant challenge in achieving accurate conversion\nfrom graph form to the appropriate sequence. To address this challenge, we\nintroduce a novel general end-to-end graph-to-sequence neural encoder-decoder\nmodel that maps an input graph to a sequence of vectors and uses an\nattention-based LSTM method to decode the target sequence from these vectors.\nOur method first generates the node and graph embeddings using an improved\ngraph-based neural network with a novel aggregation strategy to incorporate\nedge direction information in the node embeddings. We further introduce an\nattention mechanism that aligns node embeddings and the decoding sequence to\nbetter cope with large graphs. Experimental results on bAbI, Shortest Path, and\nNatural Language Generation tasks demonstrate that our model achieves\nstate-of-the-art performance and significantly outperforms existing graph\nneural networks, Seq2Seq, and Tree2Seq models; using the proposed\nbi-directional node embedding aggregation strategy, the model can converge\nrapidly to the optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:47:22 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 11:58:25 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 06:13:54 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 16:43:37 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Feng", "Yansong", ""], ["Witbrock", "Michael", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1804.00846", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Albert Zhao, Aadyot Bhatnagar, Yisong Yue,\n  Masahiro Ono", "title": "Learning to Search via Retrospective Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a good search policy for combinatorial\nsearch spaces. We propose retrospective imitation learning, which, after\ninitial training by an expert, improves itself by learning from\n\\textit{retrospective inspections} of its own roll-outs. That is, when the\npolicy eventually reaches a feasible solution in a combinatorial search tree\nafter making mistakes and backtracks, it retrospectively constructs an improved\nsearch trace to the solution by removing backtracks, which is then used to\nfurther train the policy. A key feature of our approach is that it can\niteratively scale up, or transfer, to larger problem sizes than those solved by\nthe initial expert demonstrations, thus dramatically expanding its\napplicability beyond that of conventional imitation learning. We showcase the\neffectiveness of our approach on a range of tasks, including synthetic maze\nsolving and combinatorial problems expressed as integer programs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 06:52:09 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 22:33:54 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 07:57:21 GMT"}, {"version": "v4", "created": "Sun, 23 Jun 2019 17:23:11 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Zhao", "Albert", ""], ["Bhatnagar", "Aadyot", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "1804.00857", "submitter": "Tao Shen", "authors": "Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Bi-Directional Block Self-Attention for Fast and Memory-Efficient\n  Sequence Modeling", "comments": "18 pages, 7 figures; Accepted in ICLR-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNN), convolutional neural networks (CNN) and\nself-attention networks (SAN) are commonly used to produce context-aware\nrepresentations. RNN can capture long-range dependency but is hard to\nparallelize and not time-efficient. CNN focuses on local dependency but does\nnot perform well on some tasks. SAN can model both such dependencies via highly\nparallelizable computation, but memory requirement grows rapidly in line with\nsequence length. In this paper, we propose a model, called \"bi-directional\nblock self-attention network (Bi-BloSAN)\", for RNN/CNN-free sequence encoding.\nIt requires as little memory as RNN but with all the merits of SAN. Bi-BloSAN\nsplits the entire sequence into blocks, and applies an intra-block SAN to each\nblock for modeling local context, then applies an inter-block SAN to the\noutputs for all blocks to capture long-range dependency. Thus, each SAN only\nneeds to process a short sequence, and only a small amount of memory is\nrequired. Additionally, we use feature-level attention to handle the variation\nof contexts around the same word, and use forward/backward masks to encode\ntemporal order information. On nine benchmark datasets for different NLP tasks,\nBi-BloSAN achieves or improves upon state-of-the-art accuracy, and shows better\nefficiency-memory trade-off than existing RNN/CNN/SAN.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 07:41:10 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1804.00946", "submitter": "Wenjie Pei", "authors": "Wenjie Pei, David M.J. Tax", "title": "Unsupervised Learning of Sequence Representations by Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence data is challenging for machine learning approaches, because the\nlengths of the sequences may vary between samples. In this paper, we present an\nunsupervised learning model for sequence data, called the Integrated Sequence\nAutoencoder (ISA), to learn a fixed-length vectorial representation by\nminimizing the reconstruction error. Specifically, we propose to integrate two\nclassical mechanisms for sequence reconstruction which takes into account both\nthe global silhouette information and the local temporal dependencies.\nFurthermore, we propose a stop feature that serves as a temporal stamp to guide\nthe reconstruction process, which results in a higher-quality representation.\nThe learned representation is able to effectively summarize not only the\napparent features, but also the underlying and high-level style information.\nTake for example a speech sequence sample: our ISA model can not only recognize\nthe spoken text (apparent feature), but can also discriminate the speaker who\nutters the audio (more high-level style). One promising application of the ISA\nmodel is that it can be readily used in the semi-supervised learning scenario,\nin which a large amount of unlabeled data is leveraged to extract high-quality\nsequence representations and thus to improve the performance of the subsequent\nsupervised learning tasks on limited labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 13:12:45 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 22:31:09 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Pei", "Wenjie", ""], ["Tax", "David M. J.", ""]]}, {"id": "1804.00987", "submitter": "Kyle Richardson", "authors": "Kyle Richardson", "title": "A Language for Function Signature Representations", "comments": "short note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work by (Richardson and Kuhn, 2017a,b; Richardson et al., 2018) looks\nat semantic parser induction and question answering in the domain of source\ncode libraries and APIs. In this brief note, we formalize the representations\nbeing learned in these studies and introduce a simple domain specific language\nand a systematic translation from this language to first-order logic. By\nrecasting the target representations in terms of classical logic, we aim to\nbroaden the applicability of existing code datasets for investigating more\ncomplex natural language understanding and reasoning problems in the software\ndomain.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 13:01:29 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 13:23:03 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Richardson", "Kyle", ""]]}, {"id": "1804.01000", "submitter": "Vishal Sunder", "authors": "Karamjit Singh and Vishal Sunder", "title": "CIKM AnalytiCup 2017 Lazada Product Title Quality Challenge An Ensemble\n  of Deep and Shallow Learning to predict the Quality of Product Titles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach where two different models (Deep and Shallow) are\ntrained separately on the data and a weighted average of the outputs is taken\nas the final result. For the Deep approach, we use different combinations of\nmodels like Convolution Neural Network, pretrained word2vec embeddings and\nLSTMs to get representations which are then used to train a Deep Neural\nNetwork. For Clarity prediction, we also use an Attentive Pooling approach for\nthe pooling operation so as to be aware of the Title-Category pair. For the\nshallow approach, we use boosting technique LightGBM on features generated\nusing title and categories. We find that an ensemble of these approaches does a\nbetter job than using them alone suggesting that the results of the deep and\nshallow approach are highly complementary\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 13:02:57 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Singh", "Karamjit", ""], ["Sunder", "Vishal", ""]]}, {"id": "1804.01077", "submitter": "Krishna Kumar Singh", "authors": "Krishna Kumar Singh, Santosh Divvala, Ali Farhadi, Yong Jae Lee", "title": "DOCK: Detecting Objects by transferring Common-sense Knowledge", "comments": null, "journal-ref": "ECCV, 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable approach for Detecting Objects by transferring\nCommon-sense Knowledge (DOCK) from source to target categories. In our setting,\nthe training data for the source categories have bounding box annotations,\nwhile those for the target categories only have image-level annotations.\nCurrent state-of-the-art approaches focus on image-level visual or semantic\nsimilarity to adapt a detector trained on the source categories to the new\ntarget categories. In contrast, our key idea is to (i) use similarity not at\nthe image-level, but rather at the region-level, and (ii) leverage richer\ncommon-sense (based on attribute, spatial, etc.) to guide the algorithm towards\nlearning the correct detections. We acquire such common-sense cues\nautomatically from readily-available knowledge bases without any extra human\neffort. On the challenging MS COCO dataset, we find that common-sense knowledge\ncan substantially improve detection performance over existing transfer-learning\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 17:41:53 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 06:42:30 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Singh", "Krishna Kumar", ""], ["Divvala", "Santosh", ""], ["Farhadi", "Ali", ""], ["Lee", "Yong Jae", ""]]}, {"id": "1804.01110", "submitter": "Helge Rhodin", "authors": "Helge Rhodin and Mathieu Salzmann and Pascal Fua", "title": "Unsupervised Geometry-Aware Representation for 3D Human Pose Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern 3D human pose estimation techniques rely on deep networks, which\nrequire large amounts of training data. While weakly-supervised methods require\nless supervision, by utilizing 2D poses or multi-view imagery without\nannotations, they still need a sufficiently large set of samples with 3D\nannotations for learning to succeed.\n  In this paper, we propose to overcome this problem by learning a\ngeometry-aware body representation from multi-view images without annotations.\nTo this end, we use an encoder-decoder that predicts an image from one\nviewpoint given an image from another viewpoint. Because this representation\nencodes 3D geometry, using it in a semi-supervised setting makes it easier to\nlearn a mapping from it to 3D human pose. As evidenced by our experiments, our\napproach significantly outperforms fully-supervised methods given the same\namount of labeled data, and improves over other semi-supervised methods while\nusing as little as 1% of the labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:01:54 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Rhodin", "Helge", ""], ["Salzmann", "Mathieu", ""], ["Fua", "Pascal", ""]]}, {"id": "1804.01128", "submitter": "Luis Piloto", "authors": "Luis Piloto, Ari Weinstein, Dhruva TB, Arun Ahuja, Mehdi Mirza, Greg\n  Wayne, David Amos, Chia-chun Hung, Matt Botvinick", "title": "Probing Physics Knowledge Using Tools from Developmental Psychology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to build agents with a rich understanding of their environment, one\nkey objective is to endow them with a grasp of intuitive physics; an ability to\nreason about three-dimensional objects, their dynamic interactions, and\nresponses to forces. While some work on this problem has taken the approach of\nbuilding in components such as ready-made physics engines, other research aims\nto extract general physical concepts directly from sensory data. In the latter\ncase, one challenge that arises is evaluating the learning system. Research on\nintuitive physics knowledge in children has long employed a violation of\nexpectations (VOE) method to assess children's mastery of specific physical\nconcepts. We take the novel step of applying this method to artificial learning\nsystems. In addition to introducing the VOE technique, we describe a set of\nprobe datasets inspired by classic test stimuli from developmental psychology.\nWe test a baseline deep learning system on this battery, as well as on a\nphysics learning dataset (\"IntPhys\") recently posed by another research group.\nOur results show how the VOE technique may provide a useful tool for tracking\nphysics knowledge in future research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:47:46 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Piloto", "Luis", ""], ["Weinstein", "Ari", ""], ["TB", "Dhruva", ""], ["Ahuja", "Arun", ""], ["Mirza", "Mehdi", ""], ["Wayne", "Greg", ""], ["Amos", "David", ""], ["Hung", "Chia-chun", ""], ["Botvinick", "Matt", ""]]}, {"id": "1804.01144", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson, Vito Trianni, Justin Werfel, and Hiroki Sayama", "title": "Self-Organization and Artificial Life: A Review", "comments": "8 pages, submitted to ALife 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI cs.MA cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-organization has been an important concept within a number of\ndisciplines, which Artificial Life (ALife) also has heavily utilized since its\ninception. The term and its implications, however, are often confusing or\nmisinterpreted. In this work, we provide a mini-review of self-organization and\nits relationship with ALife, aiming at initiating discussions on this important\ntopic with the interested audience. We first articulate some fundamental\naspects of self-organization, outline its usage, and review its applications to\nALife within its soft, hard, and wet domains. We also provide perspectives for\nfurther research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:44:09 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Gershenson", "Carlos", ""], ["Trianni", "Vito", ""], ["Werfel", "Justin", ""], ["Sayama", "Hiroki", ""]]}, {"id": "1804.01186", "submitter": "Oleksandr Polozov", "authors": "Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra, Prateek\n  Jain, Sumit Gulwani", "title": "Neural-Guided Deductive Search for Real-Time Program Synthesis from\n  Examples", "comments": "Published in ICLR 2018, International Conference on Learning\n  Representations (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing user-intended programs from a small number of input-output\nexamples is a challenging problem with several important applications like\nspreadsheet manipulation, data wrangling and code refactoring. Existing\nsynthesis systems either completely rely on deductive logic techniques that are\nextensively hand-engineered or on purely statistical models that need massive\namounts of data, and in general fail to provide real-time synthesis on\nchallenging benchmarks. In this work, we propose Neural Guided Deductive Search\n(NGDS), a hybrid synthesis technique that combines the best of both symbolic\nlogic techniques and statistical models. Thus, it produces programs that\nsatisfy the provided specifications by construction and generalize well on\nunseen examples, similar to data-driven systems. Our technique effectively\nutilizes the deductive search framework to reduce the learning problem of the\nneural component to a simple supervised learning setup. Further, this allows us\nto both train on sparingly available real-world data and still leverage\npowerful recurrent neural network encoders. We demonstrate the effectiveness of\nour method by evaluating on real-world customer scenarios by synthesizing\naccurate programs with up to 12x speed-up compared to state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 22:37:08 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 21:32:49 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Kalyan", "Ashwin", ""], ["Mohta", "Abhishek", ""], ["Polozov", "Oleksandr", ""], ["Batra", "Dhruv", ""], ["Jain", "Prateek", ""], ["Gulwani", "Sumit", ""]]}, {"id": "1804.01193", "submitter": "Bart Jacobs", "authors": "Bart Jacobs, Fabio Zanasi", "title": "The Logical Essentials of Bayesian Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter offers an accessible introduction to the channel-based approach\nto Bayesian probability theory. This framework rests on algebraic and logical\nfoundations, inspired by the methodologies of programming language semantics.\nIt offers a uniform, structured and expressive language for describing Bayesian\nphenomena in terms of familiar programming concepts, like channel, predicate\ntransformation and state transformation. The introduction also covers inference\nin Bayesian networks, which will be modelled by a suitable calculus of string\ndiagrams.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 23:55:41 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 16:49:41 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Jacobs", "Bart", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1804.01256", "submitter": "Thomas Guyet", "authors": "Thomas Guyet (LACODAM), Ren\\'e Quiniou (LACODAM)", "title": "NegPSpan: efficient extraction of negative sequential patterns with\n  embedding constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining frequent sequential patterns consists in extracting recurrent\nbehaviors, modeled as patterns, in a big sequence dataset. Such patterns inform\nabout which events are frequently observed in sequences, i.e. what does really\nhappen. Sometimes, knowing that some specific event does not happen is more\ninformative than extracting a lot of observed events. Negative sequential\npatterns (NSP) formulate recurrent behaviors by patterns containing both\nobserved events and absent events. Few approaches have been proposed to mine\nsuch NSPs. In addition, the syntax and semantics of NSPs differ in the\ndifferent methods which makes it difficult to compare them. This article\nprovides a unified framework for the formulation of the syntax and the\nsemantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts\nNSPs using a PrefixSpan depth-first scheme and enabling maxgap constraints that\nother approaches do not take into account. The formal framework allows for\nhighlighting the differences between the proposed approach wrt to the methods\nfrom the literature, especially wrt the state of the art approach eNSP.\nIntensive experiments on synthetic and real datasets show that NegPSpan can\nextract meaningful NSPs and that it can process bigger datasets than eNSP\nthanks to significantly lower memory requirements and better computation times.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 06:47:32 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 13:42:47 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Guyet", "Thomas", "", "LACODAM"], ["Quiniou", "Ren\u00e9", "", "LACODAM"]]}, {"id": "1804.01396", "submitter": "Tarique Anwer", "authors": "Jahanzaib Shabbir, and Tarique Anwer", "title": "Artificial Intelligence and its Role in Near Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI technology has a long history which is actively and constantly changing\nand growing. It focuses on intelligent agents, which contain devices that\nperceive the environment and based on which takes actions in order to maximize\ngoal success chances. In this paper, we will explain the modern AI basics and\nvarious representative applications of AI. In the context of the modern\ndigitalized world, AI is the property of machines, computer programs, and\nsystems to perform the intellectual and creative functions of a person,\nindependently find ways to solve problems, be able to draw conclusions and make\ndecisions. Most artificial intelligence systems have the ability to learn,\nwhich allows people to improve their performance over time. The recent research\non AI tools, including machine learning, deep learning and predictive analysis\nintended toward increasing the planning, learning, reasoning, thinking and\naction taking ability. Based on which, the proposed research intends towards\nexploring on how the human intelligence differs from the artificial\nintelligence. Moreover, we critically analyze what AI of today is capable of\ndoing, why it still cannot reach human intelligence and what are the open\nchallenges existing in front of AI to reach and outperform human level of\nintelligence. Furthermore, it will explore the future predictions for\nartificial intelligence and based on which potential solution will be\nrecommended to solve it within next decades.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 23:12:30 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Shabbir", "Jahanzaib", ""], ["Anwer", "Tarique", ""]]}, {"id": "1804.01405", "submitter": "Manuel Namici", "authors": "Manuel Namici", "title": "R2RML Mappings in OBDA Systems: Enabling Comparison among OBDA Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's large enterprises there is a significant increasing trend in the\namount of data that has to be stored and processed. To complicate this scenario\nthe complexity of organizing and managing a large collection of data,\nstructured according to a single, unified schema, makes so that there is almost\nnever a single place where to look to satisfy an information need.\n  The Ontology-Based Data Access (OBDA) paradigm aims at mitigating this\nphenomenon by providing to the users of the system a unified and shared\nconceptual view of the domain of interest (ontology), while still enabling the\ndata to be stored in different data sources, which are managed by a relational\ndatabase. In an OBDA system the link between the data stored at the sources and\nthe ontology is provided through a declarative specification given in terms of\na set of mappings.\n  In this work we focus on comparing two of the available systems for OBDA,\nnamely, Mastro and Ontop, by adopting OBDA specifications based on W3C\nrecommendations. We first show how support for R2RML mappings has been\nintegrated in Mastro, which was the last feature missing in order to enable the\nsystem to use specifications based solely on W3C recommendations relevant to\nOBDA. We then proceed in performing a comparison between these systems over two\nOBDA specifications, the NPD Benchmark and the ACI specification.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 13:43:21 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Namici", "Manuel", ""]]}, {"id": "1804.01486", "submitter": "Andrew Beam", "authors": "Andrew L. Beam, Benjamin Kompa, Allen Schmaltz, Inbar Fried, Griffin\n  Weber, Nathan P. Palmer, Xu Shi, Tianxi Cai, Isaac S. Kohane", "title": "Clinical Concept Embeddings Learned from Massive Sources of Multimodal\n  Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a popular approach to unsupervised learning of word\nrelationships that are widely used in natural language processing. In this\narticle, we present a new set of embeddings for medical concepts learned using\nan extremely large collection of multimodal medical data. Leaning on recent\ntheoretical insights, we demonstrate how an insurance claims database of 60\nmillion members, a collection of 20 million clinical notes, and 1.7 million\nfull text biomedical journal articles can be combined to embed concepts into a\ncommon space, resulting in the largest ever set of embeddings for 108,477\nmedical concepts. To evaluate our approach, we present a new benchmark\nmethodology based on statistical power specifically designed to test embeddings\nof medical concepts. Our approach, called cui2vec, attains state-of-the-art\nperformance relative to previous methods in most instances. Finally, we provide\na downloadable set of pre-trained embeddings for other researchers to use, as\nwell as an online tool for interactive exploration of the cui2vec embeddings\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:02:54 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 19:25:31 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 00:32:33 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Beam", "Andrew L.", ""], ["Kompa", "Benjamin", ""], ["Schmaltz", "Allen", ""], ["Fried", "Inbar", ""], ["Weber", "Griffin", ""], ["Palmer", "Nathan P.", ""], ["Shi", "Xu", ""], ["Cai", "Tianxi", ""], ["Kohane", "Isaac S.", ""]]}, {"id": "1804.01503", "submitter": "Garrett Honke PhD", "authors": "Paul Azunre, Craig Corcoran, David Sullivan, Garrett Honke, Rebecca\n  Ruppel, Sandeep Verma, Jonathon Morgan", "title": "Abstractive Tabular Dataset Summarization via Knowledge Base Semantic\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an abstractive summarization method for tabular data\nwhich employs a knowledge base semantic embedding to generate the summary.\nAssuming the dataset contains descriptive text in headers, columns and/or some\naugmenting metadata, the system employs the embedding to recommend a\nsubject/type for each text segment. Recommendations are aggregated into a small\ncollection of super types considered to be descriptive of the dataset by\nexploiting the hierarchy of types in a pre-specified ontology. Using February\n2015 Wikipedia as the knowledge base, and a corresponding DBpedia ontology as\ntypes, we present experimental results on open data taken from several\nsources--OpenML, CKAN and data.world--to illustrate the effectiveness of the\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:45:04 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 14:57:10 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Azunre", "Paul", ""], ["Corcoran", "Craig", ""], ["Sullivan", "David", ""], ["Honke", "Garrett", ""], ["Ruppel", "Rebecca", ""], ["Verma", "Sandeep", ""], ["Morgan", "Jonathon", ""]]}, {"id": "1804.01508", "submitter": "Ole-Christoffer Granmo", "authors": "Ole-Christoffer Granmo", "title": "The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to\n  Optimal Pattern Recognition with Propositional Logic", "comments": "42 pages, 14 figures, further formalizing key concepts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although simple individually, artificial neurons provide state-of-the-art\nperformance when interconnected in deep networks. Arguably, the Tsetlin\nAutomaton is an even simpler and more versatile learning mechanism, capable of\nsolving the multi-armed bandit problem. Merely by means of a single integer as\nmemory, it learns the optimal action in stochastic environments through\nincrement and decrement operations. In this paper, we introduce the Tsetlin\nMachine, which solves complex pattern recognition problems with propositional\nformulas, composed by a collective of Tsetlin Automata. To eliminate the\nlongstanding problem of vanishing signal-to-noise ratio, the Tsetlin Machine\norchestrates the automata using a novel game. Further, both inputs, patterns,\nand outputs are expressed as bits, while recognition and learning rely on bit\nmanipulation, simplifying computation. Our theoretical analysis establishes\nthat the Nash equilibria of the game align with the propositional formulas that\nprovide optimal pattern recognition accuracy. This translates to learning\nwithout local optima, only global ones. In five benchmarks, the Tsetlin Machine\nprovides competitive accuracy compared with SVMs, Decision Trees, Random\nForests, Naive Bayes Classifier, Logistic Regression, and Neural Networks. We\nfurther demonstrate how the propositional formulas facilitate interpretation.\nIn conclusion, we believe the combination of high accuracy, interpretability,\nand computational simplicity makes the Tsetlin Machine a promising tool for a\nwide range of domains.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:52:34 GMT"}, {"version": "v10", "created": "Tue, 15 Jan 2019 17:29:40 GMT"}, {"version": "v11", "created": "Mon, 4 Feb 2019 12:00:26 GMT"}, {"version": "v12", "created": "Thu, 23 Apr 2020 16:17:31 GMT"}, {"version": "v13", "created": "Thu, 11 Jun 2020 08:09:55 GMT"}, {"version": "v14", "created": "Thu, 3 Dec 2020 13:02:37 GMT"}, {"version": "v15", "created": "Sat, 2 Jan 2021 00:51:08 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 15:19:24 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 14:33:17 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2018 16:42:33 GMT"}, {"version": "v5", "created": "Wed, 11 Apr 2018 16:26:27 GMT"}, {"version": "v6", "created": "Mon, 16 Apr 2018 13:33:49 GMT"}, {"version": "v7", "created": "Mon, 23 Apr 2018 12:51:28 GMT"}, {"version": "v8", "created": "Mon, 7 Jan 2019 13:01:31 GMT"}, {"version": "v9", "created": "Thu, 10 Jan 2019 17:11:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Granmo", "Ole-Christoffer", ""]]}, {"id": "1804.01523", "submitter": "Alex Lee", "authors": "Alex X. Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea\n  Finn, Sergey Levine", "title": "Stochastic Adversarial Video Prediction", "comments": "Website: https://alexlee-gk.github.io/video_prediction/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to predict what may happen in the future requires an in-depth\nunderstanding of the physical and causal rules that govern the world. A model\nthat is able to do so has a number of appealing applications, from robotic\nplanning to representation learning. However, learning to predict raw future\nobservations, such as frames in a video, is exceedingly challenging -- the\nambiguous nature of the problem can cause a naively designed model to average\ntogether possible futures into a single, blurry prediction. Recently, this has\nbeen addressed by two distinct approaches: (a) latent variational variable\nmodels that explicitly model underlying stochasticity and (b)\nadversarially-trained models that aim to produce naturalistic images. However,\na standard latent variable model can struggle to produce realistic results, and\na standard adversarially-trained model underutilizes latent variables and fails\nto produce diverse predictions. We show that these distinct methods are in fact\ncomplementary. Combining the two produces predictions that look more realistic\nto human raters and better cover the range of possible futures. Our method\noutperforms prior and concurrent work in these aspects.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 17:55:40 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Lee", "Alex X.", ""], ["Zhang", "Richard", ""], ["Ebert", "Frederik", ""], ["Abbeel", "Pieter", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1804.01640", "submitter": "Sai Vikneshwar Mani Jayaraman", "authors": "Aarthy Shivram Arun, Sai Vikneshwar Mani Jayaraman, Christopher R\\'e\n  and Atri Rudra", "title": "Hypertree Decompositions Revisited for PGMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the classical problem of exact inference on probabilistic\ngraphical models (PGMs). Our algorithm is based on recent worst-case optimal\ndatabase join algorithms, which can be asymptotically faster than traditional\ndata processing methods. We present the first empirical evaluation of these new\nalgorithms via JoinInfer, a new exact inference engine. We empirically explore\nthe properties of the data for which our engine can be expected to outperform\ntraditional inference engines refining current theoretical notions. Further,\nJoinInfer outperforms existing state-of-the-art inference engines (ACE, IJGP\nand libDAI) on some standard benchmark datasets by up to a factor of 630x.\nFinally, we propose a promising data-driven heuristic that extends JoinInfer to\nautomatically tailor its parameters and/or switch to the traditional inference\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 01:05:34 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Arun", "Aarthy Shivram", ""], ["Jayaraman", "Sai Vikneshwar Mani", ""], ["R\u00e9", "Christopher", ""], ["Rudra", "Atri", ""]]}, {"id": "1804.01660", "submitter": "Christoph Adami", "authors": "Arend Hintze, Douglas Kirkpatrick, and Christoph Adami (Michigan State\n  University)", "title": "The structure of evolved representations across different substrates for\n  artificial intelligence", "comments": "8 pages, 13 figures. Submitted to Artificial Life Conference (Tokyo,\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs), while exceptionally useful for\nclassification, are vulnerable to misdirection. Small amounts of noise can\nsignificantly affect their ability to correctly complete a task. Instead of\ngeneralizing concepts, ANNs seem to focus on surface statistical regularities\nin a given task. Here we compare how recurrent artificial neural networks, long\nshort-term memory units, and Markov Brains sense and remember their\nenvironments. We show that information in Markov Brains is localized and\nsparsely distributed, while the other neural network substrates \"smear\"\ninformation about the environment across all nodes, which makes them vulnerable\nto noise.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 03:10:37 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Hintze", "Arend", "", "Michigan State\n  University"], ["Kirkpatrick", "Douglas", "", "Michigan State\n  University"], ["Adami", "Christoph", "", "Michigan State\n  University"]]}, {"id": "1804.01712", "submitter": "Aditya Grover", "authors": "Aditya Grover, Ramki Gummadi, Miguel Lazaro-Gredilla, Dale Schuurmans,\n  Stefano Ermon", "title": "Variational Rejection Sampling", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent variable models with stochastic variational inference is\nchallenging when the approximate posterior is far from the true posterior, due\nto high variance in the gradient estimates. We propose a novel rejection\nsampling step that discards samples from the variational posterior which are\nassigned low likelihoods by the model. Our approach provides an arbitrarily\naccurate approximation of the true posterior at the expense of extra\ncomputation. Using a new gradient estimator for the resulting unnormalized\nproposal distribution, we achieve average improvements of 3.71 nats and 0.21\nnats over state-of-the-art single-sample and multi-sample alternatives\nrespectively for estimating marginal log-likelihoods using sigmoid belief\nnetworks on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:53:41 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Grover", "Aditya", ""], ["Gummadi", "Ramki", ""], ["Lazaro-Gredilla", "Miguel", ""], ["Schuurmans", "Dale", ""], ["Ermon", "Stefano", ""]]}, {"id": "1804.01756", "submitter": "Yan Wu", "authors": "Yan Wu, Greg Wayne, Alex Graves, Timothy Lillicrap", "title": "The Kanerva Machine: A Generative Distributed Memory", "comments": "Published as a conference paper at ICLR 2018 (corrected typos in\n  revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:07:05 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:23:40 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 09:52:40 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Wu", "Yan", ""], ["Wayne", "Greg", ""], ["Graves", "Alex", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.01793", "submitter": "Saumya Jetley", "authors": "Saumya Jetley, Naila Murray, Eleonora Vig", "title": "End-to-End Saliency Mapping via Probability Distribution Prediction", "comments": null, "journal-ref": "Proceedings of IEEE Conference on Computer Vision and Pattern\n  Recognition 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most saliency estimation methods aim to explicitly model low-level\nconspicuity cues such as edges or blobs and may additionally incorporate\ntop-down cues using face or text detection. Data-driven methods for training\nsaliency models using eye-fixation data are increasingly popular, particularly\nwith the introduction of large-scale datasets and deep architectures. However,\ncurrent methods in this latter paradigm use loss functions designed for\nclassification or regression tasks whereas saliency estimation is evaluated on\ntopographical maps. In this work, we introduce a new saliency map model which\nformulates a map as a generalized Bernoulli distribution. We then train a deep\narchitecture to predict such maps using novel loss functions which pair the\nsoftmax activation function with measures designed to compute distances between\nprobability distributions. We show in extensive experiments the effectiveness\nof such loss functions over standard ones on four public benchmark datasets,\nand demonstrate improved performance over state-of-the-art saliency methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 11:59:01 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Jetley", "Saumya", ""], ["Murray", "Naila", ""], ["Vig", "Eleonora", ""]]}, {"id": "1804.01874", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Saeid Nahavandi, Thanh Nguyen", "title": "A Human Mixed Strategy Approach to Deep Reinforcement Learning", "comments": null, "journal-ref": "2018 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC)", "doi": "10.1109/SMC.2018.00682", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, Google's DeepMind announced an advancement in creating an autonomous\nagent based on deep reinforcement learning (DRL) that could beat a professional\nplayer in a series of 49 Atari games. However, the current manifestation of DRL\nis still immature, and has significant drawbacks. One of DRL's imperfections is\nits lack of \"exploration\" during the training process, especially when working\nwith high-dimensional problems. In this paper, we propose a mixed strategy\napproach that mimics behaviors of human when interacting with environment, and\ncreate a \"thinking\" agent that allows for more efficient exploration in the DRL\ntraining process. The simulation results based on the Breakout game show that\nour scheme achieves a higher probability of obtaining a maximum score than does\nthe baseline DRL algorithm, i.e., the asynchronous advantage actor-critic\nmethod. The proposed scheme therefore can be applied effectively to solving a\ncomplicated task in a real-world application.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 14:24:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nahavandi", "Saeid", ""], ["Nguyen", "Thanh", ""]]}, {"id": "1804.02047", "submitter": "Yu Cheng", "authors": "Xi Ouyang, Yu Cheng, Yifan Jiang, Chun-Liang Li, Pan Zhou", "title": "Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and\n  Beyond", "comments": "v2.0,adding supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art pedestrian detection models have achieved great success in\nmany benchmarks. However, these models require lots of annotation information\nand the labeling process usually takes much time and efforts. In this paper, we\npropose a method to generate labeled pedestrian data and adapt them to support\nthe training of pedestrian detectors. The proposed framework is built on the\nGenerative Adversarial Network (GAN) with multiple discriminators, trying to\nsynthesize realistic pedestrians and learn the background context\nsimultaneously. To handle the pedestrians of different sizes, we adopt the\nSpatial Pyramid Pooling (SPP) layer in the discriminator. We conduct\nexperiments on two benchmarks. The results show that our framework can smoothly\nsynthesize pedestrians on background images of variations and different levels\nof details. To quantitatively evaluate our approach, we add the generated\nsamples into training data of the baseline pedestrian detectors and show the\nsynthetic images are able to improve the detectors' performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 20:22:01 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 07:19:28 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ouyang", "Xi", ""], ["Cheng", "Yu", ""], ["Jiang", "Yifan", ""], ["Li", "Chun-Liang", ""], ["Zhou", "Pan", ""]]}, {"id": "1804.02077", "submitter": "Dmytro Bobkov", "authors": "Dmytro Bobkov, Sili Chen, Ruiqing Jian, Muhammad Iqbal, Eckehard\n  Steinbach", "title": "Noise-resistant Deep Learning for Object Classification in 3D Point\n  Clouds Using a Point Pair Descriptor", "comments": "8 pages", "journal-ref": "IEEE Robotics and Automation Letters 2018 Volume 3, Issue 2 IEEE\n  Robotics and Automation Letters IEEE Robotics and Automation Letters", "doi": "10.1109/LRA.2018.2792681", "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object retrieval and classification in point cloud data is challenged by\nnoise, irregular sampling density and occlusion. To address this issue, we\npropose a point pair descriptor that is robust to noise and occlusion and\nachieves high retrieval accuracy. We further show how the proposed descriptor\ncan be used in a 4D convolutional neural network for the task of object\nclassification. We propose a novel 4D convolutional layer that is able to learn\nclass-specific clusters in the descriptor histograms. Finally, we provide\nexperimental validation on 3 benchmark datasets, which confirms the superiority\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 23:19:55 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Bobkov", "Dmytro", ""], ["Chen", "Sili", ""], ["Jian", "Ruiqing", ""], ["Iqbal", "Muhammad", ""], ["Steinbach", "Eckehard", ""]]}, {"id": "1804.02099", "submitter": "Xiaojiang Du", "authors": "Xi Chen, Zonghang Li, Yupeng Zhang, Ruiming Long, Hongfang Yu,\n  Xiaojiang Du, Mohsen Guizani", "title": "Reinforcement Learning based QoS/QoE-aware Service Function Chaining in\n  Software-Driven 5G Slices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever growing diversity of devices and applications that will be\nconnected to 5G networks, flexible and agile service orchestration with\nacknowledged QoE that satisfies end-user's functional and QoS requirements is\nnecessary. SDN (Software-Defined Networking) and NFV (Network Function\nVirtualization) are considered key enabling technologies for 5G core networks.\nIn this regard, this paper proposes a reinforcement learning based\nQoS/QoE-aware Service Function Chaining (SFC) in SDN/NFV-enabled 5G slices.\nFirst, it implements a lightweight QoS information collector based on LLDP,\nwhich works in a piggyback fashion on the southbound interface of the SDN\ncontroller, to enable QoS-awareness. Then, a DQN (Deep Q Network) based agent\nframework is designed to support SFC in the context of NFV. The agent takes\ninto account the QoE and QoS as key aspects to formulate the reward so that it\nis expected to maximize QoE while respecting QoS constraints. The experiment\nresults show that this framework exhibits good performance in QoE provisioning\nand QoS requirements maintenance for SFC in dynamic network environments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 01:07:53 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Chen", "Xi", ""], ["Li", "Zonghang", ""], ["Zhang", "Yupeng", ""], ["Long", "Ruiming", ""], ["Yu", "Hongfang", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1804.02257", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Nick Cheney, Francesco Corucci, and Josh C. Bongard", "title": "Interoceptive robustness through environment-mediated morphological\n  development", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205529", "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, AI researchers and roboticists try to realize intelligent behavior\nin machines by tuning parameters of a predefined structure (body plan and/or\nneural network architecture) using evolutionary or learning algorithms. Another\nbut not unrelated longstanding property of these systems is their brittleness\nto slight aberrations, as highlighted by the growing deep learning literature\non adversarial examples. Here we show robustness can be achieved by evolving\nthe geometry of soft robots, their control systems, and how their material\nproperties develop in response to one particular interoceptive stimulus\n(engineering stress) during their lifetimes. By doing so we realized robots\nthat were equally fit but more robust to extreme material defects (such as\nmight occur during fabrication or by damage thereafter) than robots that did\nnot develop during their lifetimes, or developed in response to a different\ninteroceptive stimulus (pressure). This suggests that the interplay between\nchanges in the containing systems of agents (body plan and/or neural\narchitecture) at different temporal scales (evolutionary and developmental)\nalong different modalities (geometry, material properties, synaptic weights)\nand in response to different signals (interoceptive and external perception)\nall dictate those agents' abilities to evolve or learn capable and robust\nstrategies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:33:37 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 01:39:25 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Kriegman", "Sam", ""], ["Cheney", "Nick", ""], ["Corucci", "Francesco", ""], ["Bongard", "Josh C.", ""]]}, {"id": "1804.02276", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "End-to-End Learning of Communications Systems Without a Channel Model", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of end-to-end learning of communications systems through neural\nnetwork -based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm iterates between\nsupervised training of the receiver and reinforcement learning -based training\nof the transmitter. We demonstrate that this approach works as well as fully\nsupervised methods on additive white Gaussian noise (AWGN) and Rayleigh\nblock-fading (RBF) channels. Surprisingly, while our method converges slower on\nAWGN channels than supervised training, it converges faster on RBF channels.\nOur results are a first step towards learning of communications systems over\nany type of channel without prior assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 14:01:00 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 16:38:32 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 12:24:21 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1804.02322", "submitter": "A Mani", "authors": "A Mani", "title": "Comparing Dependencies in Probability Theory and General Rough Sets:\n  Part-A", "comments": "69 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.IT cs.LO math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of comparing concepts of dependence in general rough sets with\nthose in probability theory had been initiated by the present author in some of\nher recent papers. This problem relates to the identification of the\nlimitations of translating between the methodologies and possibilities in the\nidentification of concepts. Comparison of ideas of dependence in the approaches\nhad been attempted from a set-valuation based minimalist perspective by the\npresent author. The deviant probability framework has been the result of such\nan approach. Other Bayesian reasoning perspectives (involving numeric\nvaluations) and frequentist approaches are also known. In this research,\nduality results are adapted to demonstrate the possibility of improved\ncomparisons across implications between ontologically distinct concepts in a\ncommon logic-based framework by the present author. Both positive and negative\nresults are proved that delimit possible comparisons in a clearer way by her.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 15:26:36 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Mani", "A", ""]]}, {"id": "1804.02341", "submitter": "Edward Choi", "authors": "Edward Choi, Angeliki Lazaridou, Nando de Freitas", "title": "Compositional Obverter Communication Learning From Raw Visual Input", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:12:51 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Choi", "Edward", ""], ["Lazaridou", "Angeliki", ""], ["de Freitas", "Nando", ""]]}, {"id": "1804.02391", "submitter": "Saumya Jetley", "authors": "Saumya Jetley, Nicholas A. Lord, Namhoon Lee, Philip H.S. Torr", "title": "Learn To Pay Attention", "comments": "International Conference on Learning Representations 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end-trainable attention module for convolutional neural\nnetwork (CNN) architectures built for image classification. The module takes as\ninput the 2D feature vector maps which form the intermediate representations of\nthe input image at different stages in the CNN pipeline, and outputs a 2D\nmatrix of scores for each map. Standard CNN architectures are modified through\nthe incorporation of this module, and trained under the constraint that a\nconvex combination of the intermediate 2D feature vectors, as parameterised by\nthe score matrices, must \\textit{alone} be used for classification.\nIncentivised to amplify the relevant and suppress the irrelevant or misleading,\nthe scores thus assume the role of attention values. Our experimental\nobservations provide clear evidence to this effect: the learned attention maps\nneatly highlight the regions of interest while suppressing background clutter.\nConsequently, the proposed function is able to bootstrap standard CNN\narchitectures for the task of image classification, demonstrating superior\ngeneralisation over 6 unseen benchmark datasets. When binarised, our attention\nmaps outperform other CNN-based attention maps, traditional saliency maps, and\ntop object proposals for weakly supervised segmentation as demonstrated on the\nObject Discovery dataset. We also demonstrate improved robustness against the\nfast gradient sign method of adversarial attack.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 10:47:26 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 14:33:56 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Jetley", "Saumya", ""], ["Lord", "Nicholas A.", ""], ["Lee", "Namhoon", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1804.02393", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Kai-Uwe K\\\"uhnberger", "title": "Formal Ways for Measuring Relations between Concepts in Conceptual\n  Spaces", "comments": "Submitted to a special issue of the Journal \"Expert Systems\"\n  (https://onlinelibrary.wiley.com/journal/14680394). arXiv admin note:\n  substantial text overlap with arXiv:1707.02292, arXiv:1801.03929,\n  arXiv:1707.05165, arXiv:1708.05263, arXiv:1706.06366", "journal-ref": null, "doi": "10.1111/exsy.12348", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The highly influential framework of conceptual spaces provides a geometric\nway of representing knowledge. Instances are represented by points in a\nhigh-dimensional space and concepts are represented by regions in this space.\nIn this article, we extend our recent mathematical formalization of this\nframework by providing quantitative mathematical definitions for measuring\nrelations between concepts: We develop formal ways for computing concept size,\nsubsethood, implication, similarity, and betweenness. This considerably\nincreases the representational capabilities of our formalization and makes it\nthe most thorough and comprehensive formalization of conceptual spaces\ndeveloped so far.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:06:01 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bechberger", "Lucas", ""], ["K\u00fchnberger", "Kai-Uwe", ""]]}, {"id": "1804.02422", "submitter": "Fabrizio Maria Maggi", "authors": "Chiara Di Francescomarino and Chiara Ghidini and Fabrizio Maria Maggi\n  and Fredrik Milani", "title": "Predictive Process Monitoring Methods: Which One Suits Me Best?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring has recently gained traction in academia and is\nmaturing also in companies. However, with the growing body of research, it\nmight be daunting for companies to navigate in this domain in order to find,\nprovided certain data, what can be predicted and what methods to use. The main\nobjective of this paper is developing a value-driven framework for classifying\nexisting work on predictive process monitoring. This objective is achieved by\nsystematically identifying, categorizing, and analyzing existing approaches for\npredictive process monitoring. The review is then used to develop a\nvalue-driven framework that can support organizations to navigate in the\npredictive process monitoring field and help them to find value and exploit the\nopportunities enabled by these analysis techniques.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 18:45:54 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Di Francescomarino", "Chiara", ""], ["Ghidini", "Chiara", ""], ["Maggi", "Fabrizio Maria", ""], ["Milani", "Fredrik", ""]]}, {"id": "1804.02477", "submitter": "Abhinav Verma", "authors": "Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli,\n  Swarat Chaudhuri", "title": "Programmatically Interpretable Reinforcement Learning", "comments": "Published at The 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "PMLR 80:5045-5054", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning framework, called Programmatically\nInterpretable Reinforcement Learning (PIRL), that is designed to generate\ninterpretable and verifiable agent policies. Unlike the popular Deep\nReinforcement Learning (DRL) paradigm, which represents policies by neural\nnetworks, PIRL represents policies using a high-level, domain-specific\nprogramming language. Such programmatic policies have the benefits of being\nmore easily interpreted than neural networks, and being amenable to\nverification by symbolic methods. We propose a new method, called Neurally\nDirected Program Search (NDPS), for solving the challenging nonsmooth\noptimization problem of finding a programmatic policy with maximal reward. NDPS\nworks by first learning a neural policy network using DRL, and then performing\na local search over programmatic policies that seeks to minimize a distance\nfrom this neural \"oracle\". We evaluate NDPS on the task of learning to drive a\nsimulated car in the TORCS car-racing environment. We demonstrate that NDPS is\nable to discover human-readable policies that pass some significant performance\nbars. We also show that PIRL policies can have smoother trajectories, and can\nbe more easily transferred to environments not encountered during training,\nthan corresponding policies discovered by DRL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:17:18 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 02:27:26 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 09:09:46 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Verma", "Abhinav", ""], ["Murali", "Vijayaraghavan", ""], ["Singh", "Rishabh", ""], ["Kohli", "Pushmeet", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1804.02512", "submitter": "Yuexin Ma", "authors": "Yuexin Ma, Dinesh Manocha, Wenping Wang", "title": "Efficient Reciprocal Collision Avoidance between Heterogeneous Agents\n  Using CTMAT", "comments": "International Conference on Autonomous Agents and Multiagent Systems\n  (AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel algorithm for reciprocal collision avoidance between\nheterogeneous agents of different shapes and sizes. We present a novel CTMAT\nrepresentation based on medial axis transform to compute a tight fitting\nbounding shape for each agent. Each CTMAT is represented using tuples, which\nare composed of circular arcs and line segments. Based on the reciprocal\nvelocity obstacle formulation, we reduce the problem to solving a\nlow-dimensional linear programming between each pair of tuples belonging to\nadjacent agents. We precompute the Minkowski Sums of tuples to accelerate the\nruntime performance. Finally, we provide an efficient method to update the\norientation of each agent in a local manner. We have implemented the algorithm\nand highlight its performance on benchmarks corresponding to road traffic\nscenarios and different vehicles. The overall runtime performance is comparable\nto prior multi-agent collision avoidance algorithms that use circular or\nelliptical agents. Our approach is less conservative and results in fewer false\ncollisions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 05:44:19 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ma", "Yuexin", ""], ["Manocha", "Dinesh", ""], ["Wang", "Wenping", ""]]}, {"id": "1804.02528", "submitter": "Iraklis Klampanos", "authors": "Iraklis A. Klampanos, Athanasios Davvetas, Antonis Koukourikos,\n  Vangelis Karkaletsis", "title": "ANNETT-O: An Ontology for Describing Artificial Neural Network\n  Evaluation, Topology and Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models, while effective and versatile, are becoming\nincreasingly complex, often including multiple overlapping networks of\narbitrary depths, multiple objectives and non-intuitive training methodologies.\nThis makes it increasingly difficult for researchers and practitioners to\ndesign, train and understand them. In this paper we present ANNETT-O, a\nmuch-needed, generic and computer-actionable vocabulary for researchers and\npractitioners to describe their deep learning configurations, training\nprocedures and experiments. The proposed ontology focuses on topological,\ntraining and evaluation aspects of complex deep neural configurations, while\nkeeping peripheral entities more succinct. Knowledge bases implementing\nANNETT-O can support a wide variety of queries, providing relevant insights to\nusers. In addition to a detailed description of the ontology, we demonstrate\nits suitability to the task via a number of hypothetical use-cases of\nincreasing complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 07:56:29 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 09:04:59 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Klampanos", "Iraklis A.", ""], ["Davvetas", "Athanasios", ""], ["Koukourikos", "Antonis", ""], ["Karkaletsis", "Vangelis", ""]]}, {"id": "1804.02573", "submitter": "Sankalp Arora", "authors": "Sankalp Arora, Sanjiban Choudhury and Sebastian Scherer", "title": "Hindsight is Only 50/50: Unsuitability of MDP based Approximate POMDP\n  Solvers for Multi-resolution Information Gathering", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Partially Observable Markov Decision Processes (POMDPs) offer an elegant\nframework to model sequential decision making in uncertain environments.\nSolving POMDPs online is an active area of research and given the size of\nreal-world problems approximate solvers are used. Recently, a few approaches\nhave been suggested for solving POMDPs by using MDP solvers in conjunction with\nimitation learning. MDP based POMDP solvers work well for some cases, while\ncatastrophically failing for others. The main failure point of such solvers is\nthe lack of motivation for MDP solvers to gain information, since under their\nassumption the environment is either already known as much as it can be or the\nuncertainty will disappear after the next step. However for solving POMDP\nproblems gaining information can lead to efficient solutions. In this paper we\nderive a set of conditions where MDP based POMDP solvers are provably\nsub-optimal. We then use the well-known tiger problem to demonstrate such\nsub-optimality. We show that multi-resolution, budgeted information gathering\ncannot be addressed using MDP based POMDP solvers. The contribution of the\npaper helps identify the properties of a POMDP problem for which the use of MDP\nbased POMDP solvers is inappropriate, enabling better design choices.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 16:27:33 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Arora", "Sankalp", ""], ["Choudhury", "Sanjiban", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1804.02596", "submitter": "Vivek Kulkarni", "authors": "Vivek Kulkarni and William Yang Wang", "title": "Simple Models for Word Formation in English Slang", "comments": "10 pages, 5 figures, 6 tables. Accepted at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose generative models for three types of extra-grammatical word\nformation phenomena abounding in English slang: Blends, Clippings, and\nReduplicatives. Adopting a data-driven approach coupled with linguistic\nknowledge, we propose simple models with state of the art performance on human\nannotated gold standard datasets. Overall, our models reveal insights into the\ngenerative processes of word formation in slang -- insights which are\nincreasingly relevant in the context of the rising prevalence of slang and\nnon-standard varieties on the Internet.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 21:59:46 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Kulkarni", "Vivek", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.02620", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura and Takashi Yamaguchi", "title": "A Proposal of Interactive Growing Hierarchical SOM", "comments": "6 pages, 11 figures, Proc. of 2011 IEEE International Conference on\n  Systems, Man, and Cybernetics (IEEE SMC 2011). arXiv admin note: text overlap\n  with arXiv:cs/0405030 by other authors", "journal-ref": null, "doi": "10.1109/ICSMC.2011.6084144", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self Organizing Map is trained using unsupervised learning to produce a\ntwo-dimensional discretized representation of input space of the training\ncases. Growing Hierarchical SOM is an architecture which grows both in a\nhierarchical way representing the structure of data distribution and in a\nhorizontal way representation the size of each individual maps. The control\nmethod of the growing degree of GHSOM by pruning off the redundant branch of\nhierarchy in SOM is proposed in this paper. Moreover, the interface tool for\nthe proposed method called interactive GHSOM is developed. We discuss the\ncomputation results of Iris data by using the developed tool.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 03:37:36 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Ichimura", "Takumi", ""], ["Yamaguchi", "Takashi", ""]]}, {"id": "1804.02628", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Shin Kamada", "title": "Clustering and Retrieval Method of Immunological Memory Cell in Clonal\n  Selection Algorithm", "comments": "6 pages, 9 figures, Proc. of the 6th International conference on Soft\n  Computing and Intelligent Systems and The 13th International Symposium on\n  Advanced Intelligent Systems(SCIS-ISIS 2012)", "journal-ref": null, "doi": "10.1109/SCIS-ISIS.2012.6505049", "report-no": null, "categories": "cs.NE cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clonal selection principle explains the basic features of an adaptive\nimmune response to a antigenic stimulus. It established the idea that only\nthose cells that recognize the antigens are selected to proliferate and\ndifferentiate. This paper explains a computational implementation of the clonal\nselection principle that explicitly takes into account the affinity maturation\nof the immune response. Antibodies generated by the clonal selection algorithm\nare clustered in some categories according to the affinity maturation, so that\nimmunological memory cells which respond to the specified pathogen are created.\nExperimental results to classify the medical database of Coronary Heart Disease\ndatabases are reported. For the dataset, our proposed method shows the 99.6\\%\nclassification capability of training data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 04:27:09 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Kamada", "Shin", ""]]}, {"id": "1804.02657", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Issei Tachibana", "title": "Emotion Orientated Recommendation System for Hiroshima Tourist by Fuzzy\n  Petri Net", "comments": "6 pages, 10 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013)", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624776", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed an Android Smartophone application software for tourist\ninformation system. Especially, the agent system recommends the sightseeing\nspot and local hospitality corresponding to the current feelings. The system\nsuch as concierge can estimate user's emotion and mood by Emotion Generating\nCalculations and Mental State Transition Network. In this paper, the system\ndecides the next candidates for spots and foods by the reasoning of fuzzy Petri\nNet in order to make more smooth communication between human and smartphone.\nThe system was developed for Hiroshima Tourist Information and described some\nhospitality about the concierge system.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 09:18:56 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tachibana", "Issei", ""]]}, {"id": "1804.02698", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Daisuke Igaue", "title": "Hierarchical Modular Reinforcement Learning Method and Knowledge\n  Acquisition of State-Action Rule for Multi-target Problem", "comments": "6pages, 10 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013)", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624799", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 14:39:13 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Igaue", "Daisuke", ""]]}, {"id": "1804.02717", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Pieter Abbeel, Sergey Levine, Michiel van de Panne", "title": "DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based\n  Character Skills", "comments": null, "journal-ref": null, "doi": "10.1145/3197517.3201311", "report-no": null, "categories": "cs.GR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding goal in character animation is to combine data-driven\nspecification of behavior with a system that can execute a similar behavior in\na physical simulation, thus enabling realistic responses to perturbations and\nenvironmental variation. We show that well-known reinforcement learning (RL)\nmethods can be adapted to learn robust control policies capable of imitating a\nbroad range of example motion clips, while also learning complex recoveries,\nadapting to changes in morphology, and accomplishing user-specified goals. Our\nmethod handles keyframed motions, highly-dynamic actions such as\nmotion-captured flips and spins, and retargeted motions. By combining a\nmotion-imitation objective with a task objective, we can train characters that\nreact intelligently in interactive settings, e.g., by walking in a desired\ndirection or throwing a ball at a user-specified target. This approach thus\ncombines the convenience and motion quality of using motion clips to define the\ndesired style and appearance, with the flexibility and generality afforded by\nRL methods and physics-based animation. We further explore a number of methods\nfor integrating multiple clips into the learning process to develop\nmulti-skilled agents capable of performing a rich repertoire of diverse skills.\nWe demonstrate results using multiple characters (human, Atlas robot, bipedal\ndinosaur, dragon) and a large variety of skills, including locomotion,\nacrobatics, and martial arts.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 17:04:58 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 20:48:52 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 03:44:10 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Peng", "Xue Bin", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["van de Panne", "Michiel", ""]]}, {"id": "1804.02747", "submitter": "Krzysztof Chalupka", "authors": "Krzysztof Chalupka, Pietro Perona, Frederick Eberhardt", "title": "Fast Conditional Independence Test for Vector Variables with Large\n  Sample Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate the Fast (conditional) Independence Test (FIT) -- a\nnonparametric conditional independence test. The test is based on the idea that\nwhen $P(X \\mid Y, Z) = P(X \\mid Y)$, $Z$ is not useful as a feature to predict\n$X$, as long as $Y$ is also a regressor. On the contrary, if $P(X \\mid Y, Z)\n\\neq P(X \\mid Y)$, $Z$ might improve prediction results. FIT applies to\nthousand-dimensional random variables with a hundred thousand samples in a\nfraction of the time required by alternative methods. We provide an extensive\nevaluation that compares FIT to six extant nonparametric independence tests.\nThe evaluation shows that FIT has low probability of making both Type I and\nType II errors compared to other tests, especially as the number of available\nsamples grows. Our implementation of FIT is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 20:03:07 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Perona", "Pietro", ""], ["Eberhardt", "Frederick", ""]]}, {"id": "1804.02759", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Order Effects for Queries in Intelligent Systems", "comments": "11 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": "Plenary Lecture, TSC2018 (East-West Forum), Tucson, April 2, 2018", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines common assumptions regarding the decision-making internal\nenvironment for intelligent agents and investigates issues related to\nprocessing of memory and belief states to help obtain better understanding of\nthe responses. In specific, we consider order effects and discuss both\nclassical and non-classical explanations for them. We also consider implicit\ncognition and explore if certain inaccessible states may be best modeled as\nquantum states. We propose that the hypothesis that quantum states are at the\nbasis of order effects be tested on large databases such as those related to\nmedical treatment and drug efficacy. A problem involving a maze network is\nconsidered and comparisons made between classical and quantum decision\nscenarios for it.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 21:18:55 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1804.02772", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Cengiz \\\"Oztireli, Stephan Mandt, Giampiero Salvi", "title": "Active Mini-Batch Sampling using Repulsive Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence speed of stochastic gradient descent (SGD) can be improved by\nactively selecting mini-batches. We explore sampling schemes where similar data\npoints are less likely to be selected in the same mini-batch. In particular, we\nprove that such repulsive sampling schemes lowers the variance of the gradient\nestimator. This generalizes recent work on using Determinantal Point Processes\n(DPPs) for mini-batch diversification (Zhang et al., 2017) to the broader class\nof repulsive point processes. We first show that the phenomenon of variance\nreduction by diversified sampling generalizes in particular to non-stationary\npoint processes. We then show that other point processes may be computationally\nmuch more efficient than DPPs. In particular, we propose and investigate\nPoisson Disk sampling---frequently encountered in the computer graphics\ncommunity---for this task. We show empirically that our approach improves over\nstandard SGD both in terms of convergence speed as well as final model\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 22:48:20 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 15:12:20 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Zhang", "Cheng", ""], ["\u00d6ztireli", "Cengiz", ""], ["Mandt", "Stephan", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1804.02792", "submitter": "Zeyu Chen", "authors": "Jiaxuan Zhuo, Zeyu Chen, Jianhuang Lai, Guangcong Wang", "title": "Occluded Person Re-identification", "comments": "6 pages, 7 figures, IEEE International Conference of Multimedia and\n  Expo 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (re-id) suffers from a serious occlusion problem\nwhen applied to crowded public places. In this paper, we propose to retrieve a\nfull-body person image by using a person image with occlusions. This differs\nsignificantly from the conventional person re-id problem where it is assumed\nthat person images are detected without any occlusion. We thus call this new\nproblem the occluded person re-identitification. To address this new problem,\nwe propose a novel Attention Framework of Person Body (AFPB) based on deep\nlearning, consisting of 1) an Occlusion Simulator (OS) which automatically\ngenerates artificial occlusions for full-body person images, and 2) multi-task\nlosses that force the neural network not only to discriminate a person's\nidentity but also to determine whether a sample is from the occluded data\ndistribution or the full-body data distribution. Experiments on a new occluded\nperson re-id dataset and three existing benchmarks modified to include\nfull-body person images and occluded person images show the superiority of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 01:56:53 GMT"}, {"version": "v2", "created": "Sun, 15 Apr 2018 02:00:47 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 14:22:34 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Zhuo", "Jiaxuan", ""], ["Chen", "Zeyu", ""], ["Lai", "Jianhuang", ""], ["Wang", "Guangcong", ""]]}, {"id": "1804.02808", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, Sergey Levine", "title": "Latent Space Policies for Hierarchical Reinforcement Learning", "comments": "ICML 2018; Videos: https://sites.google.com/view/latent-space-deep-rl\n  Code: https://github.com/haarnoja/sac", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning hierarchical deep neural network policies\nfor reinforcement learning. In contrast to methods that explicitly restrict or\ncripple lower layers of a hierarchy to force them to use higher-level\nmodulating signals, each layer in our framework is trained to directly solve\nthe task, but acquires a range of diverse strategies via a maximum entropy\nreinforcement learning objective. Each layer is also augmented with latent\nrandom variables, which are sampled from a prior distribution during the\ntraining of that layer. The maximum entropy objective causes these latent\nvariables to be incorporated into the layer's policy, and the higher level\nlayer can directly control the behavior of the lower layer through this latent\nspace. Furthermore, by constraining the mapping from latent variables to\nactions to be invertible, higher layers retain full expressivity: neither the\nhigher layers nor the lower layers are constrained in their behavior. Our\nexperimental evaluation demonstrates that we can improve on the performance of\nsingle-layer policies on standard benchmark tasks simply by adding additional\nlayers, and that our method can solve more complex sparse-reward tasks by\nlearning higher-level policies on top of high-entropy skills optimized for\nsimple low-level objectives.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:00:30 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 19:24:16 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Hartikainen", "Kristian", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1804.02816", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura", "title": "A Generation Method of Immunological Memory in Clonal Selection\n  Algorithm by using Restricted Boltzmann Machines", "comments": "6 pages, 10 figures, Proc. of 2015 IEEE International Conference on\n  Systems, Man, and Cybernetics(IEEE SMC 2015)", "journal-ref": null, "doi": "10.1109/SMC.2015.465", "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a high technique of image processing is required to extract the\nimage features in real time. In our research, the tourist subject data are\ncollected from the Mobile Phone based Participatory Sensing (MPPS) system. Each\nrecord consists of image files with GPS, geographic location name, user's\nnumerical evaluation, and comments written in natural language at sightseeing\nspots where a user really visits. In our previous research, the famous\nlandmarks in sightseeing spot can be detected by Clonal Selection Algorithm\nwith Immunological Memory Cell (CSAIM). However, some landmarks was not\ndetected correctly by the previous method because they didn't have enough\namount of information for the feature extraction. In order to improve the\nweakness, we propose the generation method of immunological memory by\nRestricted Boltzmann Machines. To verify the effectiveness of the method, some\nexperiments for classification of the subjective data are executed by using\nmachine learning tools for Deep Learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 05:14:26 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""]]}, {"id": "1804.02851", "submitter": "Bing Zeng", "authors": "Bing Zeng, Xinyu Li, Liang Gao, Yuyan Zhang, Haozhen Dong", "title": "Whale swarm algorithm with the mechanism of identifying and escaping\n  from extreme points for multimodal function optimization", "comments": "28 pages, 11 figures, 9 tables, 39 references", "journal-ref": null, "doi": "10.1007/s00521-018-3949-4", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world optimization problems often come with multiple global optima\nor local optima. Therefore, increasing niching metaheuristic algorithms, which\ndevote to finding multiple optima in a single run, are developed to solve these\nmultimodal optimization problems. However, there are two difficulties urgently\nto be solved for most existing niching metaheuristic algorithms: how to set the\noptimal values of niching parameters for different optimization problems, and\nhow to jump out of the local optima efficiently. These two difficulties limited\ntheir practicality largely. Based on Whale Swarm Algorithm (WSA) we proposed\npreviously, this paper presents a new multimodal optimizer named WSA with\nIterative Counter (WSA-IC) to address these two difficulties. In the one hand,\nWSA-IC improves the iteration rule of the original WSA for multimodal\noptimization, which removes the need of specifying different values of\nattenuation coefficient for different problems to form multiple subpopulations,\nwithout introducing any niching parameter. In the other hand, WSA-IC enables\nthe identification of extreme point during iterations relying on two new\nparameters (i.e., stability threshold Ts and fitness threshold Tf), to jump out\nof the located extreme point. Moreover, the convergence of WSA-IC is proved.\nFinally, the proposed WSA-IC is compared with several niching metaheuristic\nalgorithms on CEC2015 niching benchmark test functions and five additional\nclassical multimodal functions with high dimensions. The experimental results\ndemonstrate that WSA-IC statistically outperforms other niching metaheuristic\nalgorithms on most test functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 07:29:33 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 00:44:46 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 04:59:24 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Zeng", "Bing", ""], ["Li", "Xinyu", ""], ["Gao", "Liang", ""], ["Zhang", "Yuyan", ""], ["Dong", "Haozhen", ""]]}, {"id": "1804.02884", "submitter": "Duc Thien Nguyen", "authors": "Duc Thien Nguyen and Akshat Kumar and Hoong Chuin Lau", "title": "Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 09:45:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Nguyen", "Duc Thien", ""], ["Kumar", "Akshat", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1804.02929", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and Xavier Parent", "title": "First Experiments with a Flexible Infrastructure for Normative Reasoning", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flexible infrastructure for normative reasoning is outlined. A small-scale\ndemonstrator version of the envisioned system has been implemented in the proof\nassistant Isabelle/HOL by utilising the first authors universal logical\nreasoning approach based on shallow semantical embeddings in meta-logic HOL.\nThe need for such a flexible reasoning infrastructure is motivated and\nillustrated with a contrary-to-duty example scenario selected from the General\nData Protection Regulation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 11:55:22 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Parent", "Xavier", ""]]}, {"id": "1804.02952", "submitter": "J.H. van Hateren", "authors": "J. H. van Hateren", "title": "A theory of consciousness: computation, algorithm, and neurobiological\n  realization", "comments": "minor revision, 21 pages, 10 figures, 1 table", "journal-ref": "Biological Cybernetics 113, 357-372 (2019)", "doi": "10.1007/s00422-019-00803-y", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most enigmatic aspect of consciousness is the fact that it is felt, as a\nsubjective sensation. The theory proposed here aims to explain this particular\naspect. The theory encompasses both the computation that is presumably involved\nand the way in which that computation may be realized in the brain's\nneurobiology. It is assumed that the brain makes an internal estimate of an\nindividual's own evolutionary fitness, which can be shown to produce a special,\ndistinct form of causation. Communicating components of the fitness estimate\n(either for external or internal use) requires inverting them. Such inversion\ncan be performed by the thalamocortical feedback loop in the mammalian brain,\nif that loop is operating in a switched, dual-stage mode. A first\n(nonconscious) stage produces forward estimates, whereas the second (conscious)\nstage inverts those estimates. It is argued that inversion produces another\nspecial, distinct form of causation, which is spatially localized and is\nplausibly sensed as the feeling of consciousness.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 13:02:35 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 09:44:18 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 10:39:29 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2019 09:00:48 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["van Hateren", "J. H.", ""]]}, {"id": "1804.02969", "submitter": "Tomas Kliegr", "authors": "Tom\\'a\\v{s} Kliegr, \\v{S}t\\v{e}p\\'an Bahn\\'ik, Johannes F\\\"urnkranz", "title": "A review of possible effects of cognitive biases on the interpretation\n  of rule-based machine learning models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the interpretability of machine learning models is often equated with\ntheir mere syntactic comprehensibility, we think that interpretability goes\nbeyond that, and that human interpretability should also be investigated from\nthe point of view of cognitive science. In particular, the goal of this paper\nis to discuss to what extent cognitive biases may affect human understanding of\ninterpretable machine learning models, in particular of logical rules\ndiscovered from data. Twenty cognitive biases are covered, as are possible\ndebiasing techniques that can be adopted by designers of machine learning\nalgorithms and software. Our review transfers results obtained in cognitive\npsychology to the domain of machine learning, aiming to bridge the current gap\nbetween these two areas. It needs to be followed by empirical studies\nspecifically focused on the machine learning domain.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 13:28:56 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 06:31:38 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 06:43:29 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2019 08:44:37 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 09:13:13 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 17:42:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kliegr", "Tom\u00e1\u0161", ""], ["Bahn\u00edk", "\u0160t\u011bp\u00e1n", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1804.03022", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Pedro Vicente, Atabak Dehban, Lorenzo Jamone,\n  Alexandre Bernardino, Jos\\'e Santos-Victor", "title": "Learning at the Ends: From Hand to Tool Affordances in Humanoid Robots", "comments": "dataset available at htts://vislab.isr.tecnico.ulisboa.pt/, IEEE\n  International Conference on Development and Learning and on Epigenetic\n  Robotics (ICDL-EpiRob 2017)", "journal-ref": null, "doi": "10.1109/DEVLRN.2017.8329826", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the open challenges in designing robots that operate successfully in\nthe unpredictable human environment is how to make them able to predict what\nactions they can perform on objects, and what their effects will be, i.e., the\nability to perceive object affordances. Since modeling all the possible world\ninteractions is unfeasible, learning from experience is required, posing the\nchallenge of collecting a large amount of experiences (i.e., training data).\nTypically, a manipulative robot operates on external objects by using its own\nhands (or similar end-effectors), but in some cases the use of tools may be\ndesirable, nevertheless, it is reasonable to assume that while a robot can\ncollect many sensorimotor experiences using its own hands, this cannot happen\nfor all possible human-made tools.\n  Therefore, in this paper we investigate the developmental transition from\nhand to tool affordances: what sensorimotor skills that a robot has acquired\nwith its bare hands can be employed for tool use? By employing a visual and\nmotor imagination mechanism to represent different hand postures compactly, we\npropose a probabilistic model to learn hand affordances, and we show how this\nmodel can generalize to estimate the affordances of previously unseen tools,\nultimately supporting planning, decision-making and tool selection tasks in\nhumanoid robots. We present experimental results with the iCub humanoid robot,\nand we publicly release the collected sensorimotor data in the form of a hand\nposture affordances dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 14:28:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Vicente", "Pedro", ""], ["Dehban", "Atabak", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1804.03048", "submitter": "Cagatay Demiralp", "authors": "Marco Cavallo and \\c{C}a\\u{g}atay Demiralp", "title": "Clustrophile 2: Guided Visual Clustering Analysis", "comments": "IEEE VIS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data clustering is a common unsupervised learning method frequently used in\nexploratory data analysis. However, identifying relevant structures in\nunlabeled, high-dimensional data is nontrivial, requiring iterative\nexperimentation with clustering parameters as well as data features and\ninstances. The number of possible clusterings for a typical dataset is vast,\nand navigating in this vast space is also challenging. The absence of\nground-truth labels makes it impossible to define an optimal solution, thus\nrequiring user judgment to establish what can be considered a satisfiable\nclustering result. Data scientists need adequate interactive tools to\neffectively explore and navigate the large clustering space so as to improve\nthe effectiveness of exploratory clustering analysis. We introduce\n\\textit{Clustrophile~2}, a new interactive tool for guided clustering analysis.\n\\textit{Clustrophile~2} guides users in clustering-based exploratory analysis,\nadapts user feedback to improve user guidance, facilitates the interpretation\nof clusters, and helps quickly reason about differences between clusterings. To\nthis end, \\textit{Clustrophile~2} contributes a novel feature, the Clustering\nTour, to help users choose clustering parameters and assess the quality of\ndifferent clustering results in relation to current analysis goals and user\nexpectations. We evaluate \\textit{Clustrophile~2} through a user study with 12\ndata scientists, who used our tool to explore and interpret sub-cohorts in a\ndataset of Parkinson's disease patients. Results suggest that\n\\textit{Clustrophile~2} improves the speed and effectiveness of exploratory\nclustering analysis for both experts and non-experts.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 15:05:56 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 04:25:02 GMT"}, {"version": "v3", "created": "Sat, 8 Sep 2018 02:57:14 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Cavallo", "Marco", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "1804.03065", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Parikshit Gopalan, Udi Wieder", "title": "Efficient Anomaly Detection via Matrix Sketching", "comments": "Updates for NeurIPS'18 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding anomalies in high-dimensional data using\npopular PCA based anomaly scores. The naive algorithms for computing these\nscores explicitly compute the PCA of the covariance matrix which uses space\nquadratic in the dimensionality of the data. We give the first streaming\nalgorithms that use space that is linear or sublinear in the dimension. We\nprove general results showing that \\emph{any} sketch of a matrix that satisfies\na certain operator norm guarantee can be used to approximate these scores. We\ninstantiate these results with powerful matrix sketching techniques such as\nFrequent Directions and random projections to derive efficient and practical\nalgorithms for these problems, which we validate over real-world data sets. Our\nmain technical contribution is to prove matrix perturbation inequalities for\noperators arising in the computation of these measures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 15:47:36 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 16:46:19 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Sharan", "Vatsal", ""], ["Gopalan", "Parikshit", ""], ["Wieder", "Udi", ""]]}, {"id": "1804.03115", "submitter": "Jiri Fajtl", "authors": "Jiri Fajtl, Vasileios Argyriou, Dorothy Monekosso, Paolo Remagnino", "title": "AMNet: Memorability Estimation with Attention", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the design and evaluation of an end-to-end\ntrainable, deep neural network with a visual attention mechanism for\nmemorability estimation in still images. We analyze the suitability of transfer\nlearning of deep models from image classification to the memorability task.\nFurther on we study the impact of the attention mechanism on the memorability\nestimation and evaluate our network on the SUN Memorability and the LaMem\ndatasets. Our network outperforms the existing state of the art models on both\ndatasets in terms of the Spearman's rank correlation as well as the mean\nsquared error, closely matching human consistency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:28:00 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Fajtl", "Jiri", ""], ["Argyriou", "Vasileios", ""], ["Monekosso", "Dorothy", ""], ["Remagnino", "Paolo", ""]]}, {"id": "1804.03124", "submitter": "Jing Qian", "authors": "Jing Qian, Mai ElSherief, Elizabeth M. Belding, William Yang Wang", "title": "Leveraging Intra-User and Inter-User Representation Learning for\n  Automated Hate Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech detection is a critical, yet challenging problem in Natural\nLanguage Processing (NLP). Despite the existence of numerous studies dedicated\nto the development of NLP hate speech detection approaches, the accuracy is\nstill poor. The central problem is that social media posts are short and noisy,\nand most existing hate speech detection solutions take each post as an isolated\ninput instance, which is likely to yield high false positive and negative\nrates. In this paper, we radically improve automated hate speech detection by\npresenting a novel model that leverages intra-user and inter-user\nrepresentation learning for robust hate speech detection on Twitter. In\naddition to the target Tweet, we collect and analyze the user's historical\nposts to model intra-user Tweet representations. To suppress the noise in a\nsingle Tweet, we also model the similar Tweets posted by all other users with\nreinforced inter-user representation learning techniques. Experimentally, we\nshow that leveraging these two representations can significantly improve the\nf-score of a strong bidirectional LSTM baseline model by 10.1%.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:46:33 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 02:31:25 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Belding", "Elizabeth M.", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.03126", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Victor Dibia and \\c{C}a\\u{g}atay Demiralp", "title": "Data2Vis: Automatic Generation of Data Visualizations Using Sequence to\n  Sequence Recurrent Neural Networks", "comments": "IEEE VDS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly creating effective visualizations using expressive grammars is\nchallenging for users who have limited time and limited skills in statistics\nand data visualization. Even high-level, dedicated visualization tools often\nrequire users to manually select among data attributes, decide which\ntransformations to apply, and specify mappings between visual encoding\nvariables and raw or transformed attributes.\n  In this paper we introduce Data2Vis, a neural translation model for\nautomatically generating visualizations from given datasets. We formulate\nvisualization generation as a sequence to sequence translation problem where\ndata specifications are mapped to visualization specifications in a declarative\nlanguage (Vega-Lite). To this end, we train a multilayered attention-based\nrecurrent neural network (RNN) with long short-term memory (LSTM) units on a\ncorpus of visualization specifications.\n  Qualitative results show that our model learns the vocabulary and syntax for\na valid visualization specification, appropriate transformations (count, bins,\nmean) and how to use common data selection patterns that occur within data\nvisualizations. Data2Vis generates visualizations that are comparable to\nmanually-created visualizations in a fraction of the time, with potential to\nlearn more complex visualization strategies at scale.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:48:23 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 05:18:37 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 22:02:37 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Dibia", "Victor", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "1804.03235", "submitter": "Rohan Anil", "authors": "Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George\n  E. Dahl and Geoffrey E. Hinton", "title": "Large scale distributed neural network training through online\n  distillation", "comments": "Clarify that implementations should use available parallelism in\n  pseudo-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques such as ensembling and distillation promise model quality\nimprovements when paired with almost any base model. However, due to increased\ntest-time cost (for ensembles) and increased complexity of the training\npipeline (for distillation), these techniques are challenging to use in\nindustrial settings. In this paper we explore a variant of distillation which\nis relatively straightforward to use as it does not require a complicated\nmulti-stage setup or many new hyperparameters. Our first claim is that online\ndistillation enables us to use extra parallelism to fit very large datasets\nabout twice as fast. Crucially, we can still speed up training even after we\nhave already reached the point at which additional parallelism provides no\nbenefit for synchronous or asynchronous stochastic gradient descent. Two neural\nnetworks trained on disjoint subsets of the data can share knowledge by\nencouraging each model to agree with the predictions the other model would have\nmade. These predictions can come from a stale version of the other model so\nthey can be safely computed using weights that only rarely get transmitted. Our\nsecond claim is that online distillation is a cost-effective way to make the\nexact predictions of a model dramatically more reproducible. We support our\nclaims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,\nand the largest to-date dataset used for neural language modeling, containing\n$6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 20:56:03 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 22:04:36 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Anil", "Rohan", ""], ["Pereyra", "Gabriel", ""], ["Passos", "Alexandre", ""], ["Ormandi", "Robert", ""], ["Dahl", "George E.", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1804.03282", "submitter": "Saba Heidari Gheshlaghi", "authors": "Saba Heidari Gheshlaghi, Abolfazl Madani, AmirAbolfazl Suratgar,\n  Fardin Faraji", "title": "Segmentation of Multiple Sclerosis lesion in brain MR images using Fuzzy\n  C-Means", "comments": null, "journal-ref": null, "doi": "10.5121/ijaia.2018.9203", "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance images (MRI) play an important role in supporting and\nsubstituting clinical information in the diagnosis of multiple sclerosis (MS)\ndisease by presenting lesion in brain MR images. In this paper, an algorithm\nfor MS lesion segmentation from Brain MR Images has been presented. We revisit\nthe modification of properties of fuzzy -c means algorithms and the canny edge\ndetection. By changing and reformed fuzzy c-means clustering algorithms, and\napplying canny contraction principle, a relationship between MS lesions and\nedge detection is established. For the special case of FCM, we derive a\nsufficient condition and clustering parameters, allowing identification of them\nas (local) minima of the objective function.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 04:36:58 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gheshlaghi", "Saba Heidari", ""], ["Madani", "Abolfazl", ""], ["Suratgar", "AmirAbolfazl", ""], ["Faraji", "Fardin", ""]]}, {"id": "1804.03301", "submitter": "Daniel Buehrer", "authors": "Daniel J. Buehrer", "title": "A Mathematical Framework for Superintelligent Machines", "comments": "submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a class calculus that is expressive enough to describe and\nimprove its own learning process. It can design and debug programs that satisfy\ngiven input/output constraints, based on its ontology of previously learned\nprograms. It can improve its own model of the world by checking the actual\nresults of the actions of its robotic activators. For instance, it could check\nthe black box of a car crash to determine if it was probably caused by electric\nfailure, a stuck electronic gate, dark ice, or some other condition that it\nmust add to its ontology in order to meet its sub-goal of preventing such\ncrashes in the future. Class algebra basically defines the eval/eval-1 Galois\nconnection between the residuated Boolean algebras of 1. equivalence classes\nand super/sub classes of class algebra type expressions, and 2. a residual\nBoolean algebra of biclique relationships. It distinguishes which formulas are\nequivalent, entailed, or unrelated, based on a simplification algorithm that\nmay be thought of as producing a unique pair of Karnaugh maps that describe the\nrough sets of maximal bicliques of relations. Such maps divide the\nn-dimensional space of up to 2n-1 conjunctions of up to n propositions into\nclopen (i.e. a closed set of regions and their boundaries) causal sets. This\nclass algebra is generalized to type-2 fuzzy class algebra by using relative\nfrequencies as probabilities. It is also generalized to a class calculus\ninvolving assignments that change the states of programs.\n  INDEX TERMS 4-valued Boolean Logic, Artificial Intelligence, causal sets,\nclass algebra, consciousness, intelligent design, IS-A hierarchy, mathematical\nlogic, meta-theory, pointless topological space, residuated lattices, rough\nsets, type-2 fuzzy sets\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:26:00 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Buehrer", "Daniel J.", ""]]}, {"id": "1804.03317", "submitter": "Yingqi Qu", "authors": "Yingqi Qu, Jie Liu, Liangyi Kang, Qinfeng Shi, Dan Ye", "title": "Question Answering over Freebase via Attentive RNN with Similarity\n  Matrix based CNN", "comments": "The experiments need to improve and add strategy for multi-relation\n  questions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of knowledge bases (KBs), question answering over\nknowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of\nthe existing KBQA methods follow so called encoder-compare framework. They map\nthe question and the KB facts to a common embedding space, in which the\nsimilarity between the question vector and the fact vectors can be conveniently\ncomputed. This, however, inevitably loses original words interaction\ninformation. To preserve more original information, we propose an attentive\nrecurrent neural network with similarity matrix based convolutional neural\nnetwork (AR-SMCNN) model, which is able to capture comprehensive hierarchical\ninformation utilizing the advantages of both RNN and CNN. We use RNN to capture\nsemantic-level correlation by its sequential modeling nature, and use an\nattention mechanism to keep track of the entities and relations simultaneously.\nMeanwhile, we use a similarity matrix based CNN with two-directions pooling to\nextract literal-level words interaction matching utilizing CNNs strength of\nmodeling spatial correlation among data. Moreover, we have developed a new\nheuristic extension method for entity detection, which significantly decreases\nthe effect of noise. Our method has outperformed the state-of-the-arts on\nSimpleQuestion benchmark in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 02:39:41 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 09:26:44 GMT"}, {"version": "v3", "created": "Sun, 27 May 2018 13:36:15 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Qu", "Yingqi", ""], ["Liu", "Jie", ""], ["Kang", "Liangyi", ""], ["Shi", "Qinfeng", ""], ["Ye", "Dan", ""]]}, {"id": "1804.03342", "submitter": "Naveen Sundar Govindarajulu", "authors": "John Angel, Naveen Sundar Govindarajulu, and Selmer Bringsjord", "title": "Toward Formalizing Teleportation of Pedagogical Artificial Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paradigm for the use of artificial agents to teach requires among other\nthings that they persist through time in their interaction with human students,\nin such a way that they \"teleport\" or \"migrate\" from an embodiment at one time\nt to a different embodiment at later time t'. In this short paper, we report on\ninitial steps toward the formalization of such teleportation, in order to\nenable an overseeing AI system to establish, mechanically, and verifiably, that\nthe human students in question will likely believe that the very same\nartificial agent has persisted across such times despite the different\nembodiments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 05:27:49 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Angel", "John", ""], ["Govindarajulu", "Naveen Sundar", ""], ["Bringsjord", "Selmer", ""]]}, {"id": "1804.03396", "submitter": "Lin Qiu", "authors": "Lin Qiu, Hao Zhou, Yanru Qu, Weinan Zhang, Suoheng Li, Shu Rong,\n  Dongyu Ru, Lihua Qian, Kewei Tu and Yong Yu", "title": "QA4IE: A Question Answering based Framework for Information Extraction", "comments": "Accepted by 17th International Semantic Web Conference (ISWC'18)", "journal-ref": null, "doi": "10.1007/978-3-030-00671-6_12", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Extraction (IE) refers to automatically extracting structured\nrelation tuples from unstructured texts. Common IE solutions, including\nRelation Extraction (RE) and open IE systems, can hardly handle cross-sentence\ntuples, and are severely restricted by limited relation types as well as\ninformal relation specifications (e.g., free-text based relation tuples). In\norder to overcome these weaknesses, we propose a novel IE framework named\nQA4IE, which leverages the flexible question answering (QA) approaches to\nproduce high quality relation triples across sentences. Based on the framework,\nwe develop a large IE benchmark with high quality human evaluation. This\nbenchmark contains 293K documents, 2M golden relation triples, and 636 relation\ntypes. We compare our system with some IE baselines on our benchmark and the\nresults show that our system achieves great improvements.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 08:31:03 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 12:38:21 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Qiu", "Lin", ""], ["Zhou", "Hao", ""], ["Qu", "Yanru", ""], ["Zhang", "Weinan", ""], ["Li", "Suoheng", ""], ["Rong", "Shu", ""], ["Ru", "Dongyu", ""], ["Qian", "Lihua", ""], ["Tu", "Kewei", ""], ["Yu", "Yong", ""]]}, {"id": "1804.03424", "submitter": "Yookoon Park", "authors": "Yookoon Park, Jaemin Cho and Gunhee Kim", "title": "A Hierarchical Latent Structure for Variational Conversation Modeling", "comments": "Published in NAACL 2018 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) combined with hierarchical RNNs have emerged\nas a powerful framework for conversation modeling. However, they suffer from\nthe notorious degeneration problem, where the decoders learn to ignore latent\nvariables and reduce to vanilla RNNs. We empirically show that this degeneracy\noccurs mostly due to two reasons. First, the expressive power of hierarchical\nRNN decoders is often high enough to model the data using only its decoding\ndistributions without relying on the latent variables. Second, the conditional\nVAE structure whose generation process is conditioned on a context, makes the\nrange of training targets very sparse; that is, the RNN decoders can easily\noverfit to the training data ignoring the latent variables. To solve the\ndegeneration problem, we propose a novel model named Variational Hierarchical\nConversation RNNs (VHCR), involving two key ideas of (1) using a hierarchical\nstructure of latent variables, and (2) exploiting an utterance drop\nregularization. With evaluations on two datasets of Cornell Movie Dialog and\nUbuntu Dialog Corpus, we show that our VHCR successfully utilizes latent\nvariables and outperforms state-of-the-art models for conversation generation.\nMoreover, it can perform several new utterance control tasks, thanks to its\nhierarchical latent structure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:00:36 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 06:02:24 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Park", "Yookoon", ""], ["Cho", "Jaemin", ""], ["Kim", "Gunhee", ""]]}, {"id": "1804.03437", "submitter": "Wojciech Skaba", "authors": "Wojciech Skaba", "title": "The AGINAO Self-Programming Engine", "comments": "Journal of Artificial General Intelligence", "journal-ref": "Journal of Artificial General Intelligence 3(3) 2012", "doi": "10.2478/v10229-011-0018-0", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The AGINAO is a project to create a human-level artificial general\nintelligence system (HL AGI) embodied in the Aldebaran Robotics' NAO humanoid\nrobot. The dynamical and open-ended cognitive engine of the robot is\nrepresented by an embedded and multi-threaded control program, that is\nself-crafted rather than hand-crafted, and is executed on a simulated Universal\nTuring Machine (UTM). The actual structure of the cognitive engine emerges as a\nresult of placing the robot in a natural preschool-like environment and running\na core start-up system that executes self-programming of the cognitive layer on\ntop of the core layer. The data from the robot's sensory devices supplies the\ntraining samples for the machine learning methods, while the commands sent to\nactuators enable testing hypotheses and getting a feedback. The individual\nself-created subroutines are supposed to reflect the patterns and concepts of\nthe real world, while the overall program structure reflects the spatial and\ntemporal hierarchy of the world dependencies. This paper focuses on the details\nof the self-programming approach, limiting the discussion of the applied\ncognitive architecture to a necessary minimum.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:29:14 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Skaba", "Wojciech", ""]]}, {"id": "1804.03439", "submitter": "Wojciech Skaba", "authors": "Wojciech Skaba", "title": "Evaluating Actuators in a Purely Information-Theory Based Reward Model", "comments": "IEEE SSCI 2013, Singapore", "journal-ref": "IEEE SSCI 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AGINAO builds its cognitive engine by applying self-programming techniques to\ncreate a hierarchy of interconnected codelets - the tiny pieces of code\nexecuted on a virtual machine. These basic processing units are evaluated for\ntheir applicability and fitness with a notion of reward calculated from\nself-information gain of binary partitioning of the codelet's input\nstate-space. This approach, however, is useless for the evaluation of\nactuators. Instead, a model is proposed in which actuators are evaluated by\nmeasuring the impact that an activation of an effector, and consequently the\nfeedback from the robot sensors, has on average reward received by the\nprocessing units.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:34:36 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Skaba", "Wojciech", ""]]}, {"id": "1804.03487", "submitter": "Yu Liu", "authors": "Yu Liu, Fangyin Wei, Jing Shao, Lu Sheng, Junjie Yan, Xiaogang Wang", "title": "Exploring Disentangled Feature Representation Beyond Face Identification", "comments": "Accepted by CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes learning disentangled but complementary face features\nwith minimal supervision by face identification. Specifically, we construct an\nidentity Distilling and Dispelling Autoencoder (D2AE) framework that\nadversarially learns the identity-distilled features for identity verification\nand the identity-dispelled features to fool the verification system. Thanks to\nthe design of two-stream cues, the learned disentangled features represent not\nonly the identity or attribute but the complete input image. Comprehensive\nevaluations further demonstrate that the proposed features not only maintain\nstate-of-the-art identity verification performance on LFW, but also acquire\ncompetitive discriminative power for face attribute recognition on CelebA and\nLFWA. Moreover, the proposed system is ready to semantically control the face\ngeneration/editing based on various identities and attributes in an\nunsupervised manner.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 12:59:53 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Liu", "Yu", ""], ["Wei", "Fangyin", ""], ["Shao", "Jing", ""], ["Sheng", "Lu", ""], ["Yan", "Junjie", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1804.03578", "submitter": "Zihao Xiao", "authors": "Zihao Xiao, Jianfei Chen, Jun Zhu", "title": "Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip\n  Systems", "comments": "Accepted by AAAI-18, oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic topic models are popular unsupervised learning methods,\nincluding probabilistic latent semantic indexing (pLSI) and latent Dirichlet\nallocation (LDA). By now, their training is implemented on general purpose\ncomputers (GPCs), which are flexible in programming but energy-consuming.\nTowards low-energy implementations, this paper investigates their training on\nan emerging hardware technology called the neuromorphic multi-chip systems\n(NMSs). NMSs are very effective for a family of algorithms called spiking\nneural networks (SNNs). We present three SNNs to train topic models. The first\nSNN is a batch algorithm combining the conventional collapsed Gibbs sampling\n(CGS) algorithm and an inference SNN to train LDA. The other two SNNs are\nonline algorithms targeting at both energy- and storage-limited environments.\nThe two online algorithms are equivalent with training LDA by using\nmaximum-a-posterior estimation and maximizing the semi-collapsed likelihood,\nrespectively. They use novel, tailored ordinary differential equations for\nstochastic optimization. We simulate the new algorithms and show that they are\ncomparable with the GPC algorithms, while being suitable for NMS\nimplementation. We also propose an extension to train pLSI and a method to\nprune the network to obey the limited fan-in of some NMSs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:01:50 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Xiao", "Zihao", ""], ["Chen", "Jianfei", ""], ["Zhu", "Jun", ""]]}, {"id": "1804.03592", "submitter": "Ali el Hassouni", "authors": "Ali el Hassouni, Mark Hoogendoorn, Martijn van Otterlo, A. E. Eiben,\n  Vesa Muhonen, Eduardo Barbaro", "title": "A clustering-based reinforcement learning approach for tailored\n  personalization of e-Health interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is very powerful in improving the effectiveness of health\ninterventions. Reinforcement learning (RL) algorithms are suitable for learning\nthese tailored interventions from sequential data collected about individuals.\nHowever, learning can be very fragile. The time to learn intervention policies\nis limited as disengagement from the user can occur quickly. Also, in e-Health\nintervention timing can be crucial before the optimal window passes. We present\nan approach that learns tailored personalization policies for groups of users\nby combining RL and clustering. The benefits are two-fold: speeding up the\nlearning to prevent disengagement while maintaining a high level of\npersonalization. Our clustering approach utilizes dynamic time warping to\ncompare user trajectories consisting of states and rewards. We apply online and\nbatch RL to learn policies over clusters of individuals and introduce our\nself-developed and publicly available simulator for e-Health interventions to\nevaluate our approach. We compare our methods with an e-Health intervention\nbenchmark. We demonstrate that batch learning outperforms online learning for\nour setting. Furthermore, our proposed clustering approach for RL finds\nnear-optimal clusterings which lead to significantly better policies in terms\nof cumulative reward compared to learning a policy per individual or learning\none non-personalized policy across all individuals. Our findings also indicate\nthat the learned policies accurately learn to send interventions at the right\nmoments and that the users workout more and at the right times of the day.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:38:59 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 21:33:35 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 05:10:36 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Hassouni", "Ali el", ""], ["Hoogendoorn", "Mark", ""], ["van Otterlo", "Martijn", ""], ["Eiben", "A. E.", ""], ["Muhonen", "Vesa", ""], ["Barbaro", "Eduardo", ""]]}, {"id": "1804.03599", "submitter": "Christopher Burgess", "authors": "Christopher P. Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick\n  Watters, Guillaume Desjardins, Alexander Lerchner", "title": "Understanding disentangling in $\\beta$-VAE", "comments": "Presented at the 2017 NIPS Workshop on Learning Disentangled\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new intuitions and theoretical assessments of the emergence of\ndisentangled representation in variational autoencoders. Taking a\nrate-distortion theory perspective, we show the circumstances under which\nrepresentations aligned with the underlying generative factors of variation of\ndata emerge when optimising the modified ELBO bound in $\\beta$-VAE, as training\nprogresses. From these insights, we propose a modification to the training\nregime of $\\beta$-VAE, that progressively increases the information capacity of\nthe latent code during training. This modification facilitates the robust\nlearning of disentangled representations in $\\beta$-VAE, without the previous\ntrade-off in reconstruction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:48:18 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Burgess", "Christopher P.", ""], ["Higgins", "Irina", ""], ["Pal", "Arka", ""], ["Matthey", "Loic", ""], ["Watters", "Nick", ""], ["Desjardins", "Guillaume", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1804.03611", "submitter": "Wojciech Skaba", "authors": "Wojciech Skaba", "title": "Binary Space Partitioning as Intrinsic Reward", "comments": "AGI 2012", "journal-ref": "J. Bach, B. Goertzel, and M. Ikle (Eds.): AGI 2012, LNAI 7716, pp.\n  242-251, 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autonomous agent embodied in a humanoid robot, in order to learn from the\noverwhelming flow of raw and noisy sensory, has to effectively reduce the high\nspatial-temporal data dimensionality. In this paper we propose a novel method\nof unsupervised feature extraction and selection with binary space\npartitioning, followed by a computation of information gain that is interpreted\nas intrinsic reward, then applied as immediate-reward signal for the\nreinforcement-learning. The space partitioning is executed by tiny codelets\nrunning on a simulated Turing Machine. The features are represented by concept\nnodes arranged in a hierarchy, in which those of a lower level become the input\nvectors of a higher level.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 16:03:16 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Skaba", "Wojciech", ""]]}, {"id": "1804.03758", "submitter": "Chen Ma", "authors": "Chen Ma, Junfeng Wen, Yoshua Bengio", "title": "Universal Successor Representations for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of transfer reinforcement learning is to generalize from a set\nof previous tasks to unseen new tasks. In this work, we focus on the transfer\nscenario where the dynamics among tasks are the same, but their goals differ.\nAlthough general value function (Sutton et al., 2011) has been shown to be\nuseful for knowledge transfer, learning a universal value function can be\nchallenging in practice. To attack this, we propose (1) to use universal\nsuccessor representations (USR) to represent the transferable knowledge and (2)\na USR approximator (USRA) that can be trained by interacting with the\nenvironment. Our experiments show that USR can be effectively applied to new\ntasks, and the agent initialized by the trained USRA can achieve the goal\nconsiderably faster than random initialization.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 00:06:36 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Ma", "Chen", ""], ["Wen", "Junfeng", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.03782", "submitter": "Sidi Lu", "authors": "Sidi Lu and Lantao Yu and Siyuan Feng and Yaoming Zhu and Weinan Zhang\n  and Yong Yu", "title": "CoT: Cooperative Training for Generative Modeling of Discrete Data", "comments": "Appearing as a Conference Paper on ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generative models of sequential discrete data. To\ntackle the exposure bias problem inherent in maximum likelihood estimation\n(MLE), generative adversarial networks (GANs) are introduced to penalize the\nunrealistic generated samples. To exploit the supervision signal from the\ndiscriminator, most previous models leverage REINFORCE to address the\nnon-differentiable problem of sequential discrete data. However, because of the\nunstable property of the training signal during the dynamic process of\nadversarial training, the effectiveness of REINFORCE, in this case, is hardly\nguaranteed. To deal with such a problem, we propose a novel approach called\nCooperative Training (CoT) to improve the training of sequence generative\nmodels. CoT transforms the min-max game of GANs into a joint maximization\nframework and manages to explicitly estimate and optimize Jensen-Shannon\ndivergence. Moreover, CoT works without the necessity of pre-training via MLE,\nwhich is crucial to the success of previous methods. In the experiments,\ncompared to existing state-of-the-art methods, CoT shows superior or at least\ncompetitive performance on sample quality, diversity, as well as training\nstability.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 02:10:55 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 05:38:27 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 04:44:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lu", "Sidi", ""], ["Yu", "Lantao", ""], ["Feng", "Siyuan", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1804.03799", "submitter": "Rashmi Gangadharaiah", "authors": "Rashmi Gangadharaiah, Balakrishnan Narayanaswamy, Charles Elkan", "title": "Achieving Fluency and Coherency in Task-oriented Dialog", "comments": "Workshop on Conversational AI, NIPS 2017, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider real world task-oriented dialog settings, where agents need to\ngenerate both fluent natural language responses and correct external actions\nlike database queries and updates. We demonstrate that, when applied to\ncustomer support chat transcripts, Sequence to Sequence (Seq2Seq) models often\ngenerate short, incoherent and ungrammatical natural language responses that\nare dominated by words that occur with high frequency in the training data.\nThese phenomena do not arise in synthetic datasets such as bAbI, where we show\nSeq2Seq models are nearly perfect. We develop techniques to learn embeddings\nthat succinctly capture relevant information from the dialog history, and\ndemonstrate that nearest neighbor based approaches in this learned neural\nembedding space generate more fluent responses. However, we see that these\nmethods are not able to accurately predict when to execute an external action.\nWe show how to combine nearest neighbor and Seq2Seq methods in a hybrid model,\nwhere nearest neighbor is used to generate fluent responses and Seq2Seq type\nmodels ensure dialog coherency and generate accurate external actions. We show\nthat this approach is well suited for customer support scenarios, where agents'\nresponses are typically script-driven, and correct external actions are\ncritically important. The hybrid model on the customer support data achieves a\n78% relative improvement in fluency scores, and a 130% improvement in accuracy\nof external calls.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 03:49:22 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Gangadharaiah", "Rashmi", ""], ["Narayanaswamy", "Balakrishnan", ""], ["Elkan", "Charles", ""]]}, {"id": "1804.03824", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Omri Abend", "title": "Reference-less Measure of Faithfulness for Grammatical Error Correction", "comments": "Final version for NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose USim, a semantic measure for Grammatical Error Correction (GEC)\nthat measures the semantic faithfulness of the output to the source, thereby\ncomplementing existing reference-less measures (RLMs) for measuring the\noutput's grammaticality. USim operates by comparing the semantic symbolic\nstructure of the source and the correction, without relying on manually-curated\nreferences. Our experiments establish the validity of USim, by showing that (1)\nsemantic annotation can be consistently applied to ungrammatical text; (2)\nvalid corrections obtain a high USim similarity score to the source; and (3)\ninvalid corrections obtain a lower score.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 06:10:48 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 14:41:08 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 05:24:00 GMT"}, {"version": "v4", "created": "Wed, 9 May 2018 13:56:12 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Choshen", "Leshem", ""], ["Abend", "Omri", ""]]}, {"id": "1804.03954", "submitter": "Julia Freitas", "authors": "Julia C. Freitas and Puca Huachi V. Penna", "title": "A Variable Neighborhood Search for Flying Sidekick Traveling Salesman\n  Problem", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency and dynamism of Unmanned Aerial Vehicles (UAVs), or drones,\npresent substantial application opportunities in several industries in the last\nyears. Notably, the logistic companies gave close attention to these vehicles\nenvisioning reduce delivery time and operational cost. A variant of the\nTraveling Salesman Problem (TSP) called Flying Sidekick Traveling Salesman\nProblem (FSTSP) was introduced involving drone-assisted parcel delivery. The\ndrone is launched from the truck, proceeds to deliver parcels to a customer and\nthen is recovered by the truck in a third location. While the drone travels\nthrough a trip, the truck delivers parcels to other customers as long as the\ndrone has enough battery to hover waiting for the truck. This work proposes a\nhybrid heuristic that the initial solution is created from the optimal TSP\nsolution reached by a TSP solver. Next, an implementation of the General\nVariable Neighborhood Search is used to obtain the delivery routes of truck and\ndrone. Computational experiments show the potential of the algorithm to improve\nthe delivery time significantly. Furthermore, we provide a new set of instances\nbased on well-known TSPLIB instances.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 12:21:18 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 16:31:52 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Freitas", "Julia C.", ""], ["Penna", "Puca Huachi V.", ""]]}, {"id": "1804.03967", "submitter": "Fabrizio Maria Maggi", "authors": "Chiara Di Francescomarino, Chiara Ghidini, Fabrizio Maria Maggi,\n  Williams Rizzi, Cosimo Damiano Persia", "title": "Incremental Predictive Process Monitoring: How to Deal with the\n  Variability of Real Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A characteristic of existing predictive process monitoring techniques is to\nfirst construct a predictive model based on past process executions, and then\nuse it to predict the future of new ongoing cases, without the possibility of\nupdating it with new cases when they complete their execution. This can make\npredictive process monitoring too rigid to deal with the variability of\nprocesses working in real environments that continuously evolve and/or exhibit\nnew variant behaviors over time. As a solution to this problem, we propose the\nuse of algorithms that allow the incremental construction of the predictive\nmodel. These incremental learning algorithms update the model whenever new\ncases become available so that the predictive model evolves over time to fit\nthe current circumstances. The algorithms have been implemented using different\ncase encoding strategies and evaluated on a number of real and synthetic\ndatasets. The results provide a first evidence of the potential of incremental\nlearning strategies for predicting process monitoring in real environments, and\nof the impact of different case encoding strategies in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:08:26 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Di Francescomarino", "Chiara", ""], ["Ghidini", "Chiara", ""], ["Maggi", "Fabrizio Maria", ""], ["Rizzi", "Williams", ""], ["Persia", "Cosimo Damiano", ""]]}, {"id": "1804.03973", "submitter": "Cumhur Erkan Tuncali", "authors": "Cumhur Erkan Tuncali, James Kapinski, Hisahiro Ito and Jyotirmoy V.\n  Deshmukh", "title": "Reasoning about Safety of Learning-Enabled Components in Autonomous\n  Cyber-physical Systems", "comments": "Invited paper in conference: Design Automation Conference (DAC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simulation-based approach for generating barrier certificate\nfunctions for safety verification of cyber-physical systems (CPS) that contain\nneural network-based controllers. A linear programming solver is utilized to\nfind a candidate generator function from a set of simulation traces obtained by\nrandomly selecting initial states for the CPS model. A level set of the\ngenerator function is then selected to act as a barrier certificate for the\nsystem, meaning it demonstrates that no unsafe system states are reachable from\na given set of initial states. The barrier certificate properties are verified\nwith an SMT solver. This approach is demonstrated on a case study in which a\nDubins car model of an autonomous vehicle is controlled by a neural network to\nfollow a given path.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:28:07 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Tuncali", "Cumhur Erkan", ""], ["Kapinski", "James", ""], ["Ito", "Hisahiro", ""], ["Deshmukh", "Jyotirmoy V.", ""]]}, {"id": "1804.03980", "submitter": "Kris Cao", "authors": "Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls,\n  Stephen Clark", "title": "Emergent Communication through Negotiation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:48:08 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Cao", "Kris", ""], ["Lazaridou", "Angeliki", ""], ["Lanctot", "Marc", ""], ["Leibo", "Joel Z", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.03984", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls, Stephen Clark", "title": "Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input", "comments": "To appear at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:51:19 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Hermann", "Karl Moritz", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.03994", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Kousuke Tanabe", "title": "An Estimation of Favorite Value in Emotion Generating Calculation by\n  Fuzzy Petri Net", "comments": "6 pages, 7 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013). arXiv admin note:\n  substantial text overlap with arXiv:1804.02657; text overlap with\n  arXiv:1804.02813", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624777", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion Generating Calculations (EGC) method based on the Emotion Eliciting\nCondition Theory can decide whether an event arouses pleasure or not and\nquantify the degree under the event. An event in the form of Case Frame\nrepresentation is classified into 12 types of calculations. However, the weak\npoint in EGC is Favorite Value (FV) as the personal taste information. In order\nto improve the problem, this paper challenges to establish a learning method to\nlearn speaker's taste information from dialog. Especially, the learning method\nemploys Fuzzy Petri Net to find an appropriate FV to a word which has the\nunknown FV. This paper discusses the effective learning method to improve a\nweak point of EGC when a missing value of FV exists.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 02:43:35 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tanabe", "Kousuke", ""]]}, {"id": "1804.04012", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Lior Fox and Yonatan Loewenstein", "title": "DORA The Explorer: Directed Outreaching Reinforcement Action-Selection", "comments": "Final version for ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a fundamental aspect of Reinforcement Learning, typically\nimplemented using stochastic action-selection. Exploration, however, can be\nmore efficient if directed toward gaining new world knowledge. Visit-counters\nhave been proven useful both in practice and in theory for directed\nexploration. However, a major limitation of counters is their locality. While\nthere are a few model-based solutions to this shortcoming, a model-free\napproach is still missing. We propose $E$-values, a generalization of counters\nthat can be used to evaluate the propagating exploratory value over\nstate-action trajectories. We compare our approach to commonly used RL\ntechniques, and show that using $E$-values improves learning and performance\nover traditional counters. We also show how our method can be implemented with\nfunction approximation to efficiently learn continuous MDPs. We demonstrate\nthis by showing that our approach surpasses state of the art performance in the\nFreeway Atari 2600 game.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 14:21:53 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Choshen", "Leshem", ""], ["Fox", "Lior", ""], ["Loewenstein", "Yonatan", ""]]}, {"id": "1804.04095", "submitter": "Nikolaos Aletras", "authors": "Nikolaos Aletras and Benjamin Paul Chamberlain", "title": "Predicting Twitter User Socioeconomic Attributes with Network and\n  Language Information", "comments": "Accepted at ACM HT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Inferring socioeconomic attributes of social media users such as occupation\nand income is an important problem in computational social science. Automated\ninference of such characteristics has applications in personalised recommender\nsystems, targeted computational advertising and online political campaigning.\nWhile previous work has shown that language features can reliably predict\nsocioeconomic attributes on Twitter, employing information coming from users'\nsocial networks has not yet been explored for such complex user\ncharacteristics. In this paper, we describe a method for predicting the\noccupational class and the income of Twitter users given information extracted\nfrom their extended networks by learning a low-dimensional vector\nrepresentation of users, i.e. graph embeddings. We use this representation to\ntrain predictive models for occupational class and income. Results on two\npublicly available datasets show that our method consistently outperforms the\nstate-of-the-art methods in both tasks. We also obtain further significant\nimprovements when we combine graph embeddings with textual features,\ndemonstrating that social network and language information are complementary.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 17:00:27 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Aletras", "Nikolaos", ""], ["Chamberlain", "Benjamin Paul", ""]]}, {"id": "1804.04216", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, John Fearnley, Rahul Savani and Andreas Koukorinis", "title": "Market Making via Reinforcement Learning", "comments": "10 pages, 5 figures, AAMAS2018 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market making is a fundamental trading problem in which an agent provides\nliquidity by continually offering to buy and sell a security. The problem is\nchallenging due to inventory risk, the risk of accumulating an unfavourable\nposition and ultimately losing money. In this paper, we develop a high-fidelity\nsimulation of limit order book markets, and use it to design a market making\nagent using temporal-difference reinforcement learning. We use a linear\ncombination of tile codings as a value function approximator, and design a\ncustom reward function that controls inventory risk. We demonstrate the\neffectiveness of our approach by showing that our agent outperforms both simple\nbenchmark strategies and a recent online learning approach from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:46:33 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Spooner", "Thomas", ""], ["Fearnley", "John", ""], ["Savani", "Rahul", ""], ["Koukorinis", "Andreas", ""]]}, {"id": "1804.04225", "submitter": "Yue Liu", "authors": "Yue Liu, Tao Ge, Kusum S. Mathews, Heng Ji, Deborah L. McGuinness", "title": "Exploiting Task-Oriented Resources to Learn Word Embeddings for Clinical\n  Abbreviation Expansion", "comments": "Proceedings of BioNLP 15", "journal-ref": null, "doi": "10.18653/v1/W15-3810", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the medical domain, identifying and expanding abbreviations in clinical\ntexts is a vital task for both better human and machine understanding. It is a\nchallenging task because many abbreviations are ambiguous especially for\nintensive care medicine texts, in which phrase abbreviations are frequently\nused. Besides the fact that there is no universal dictionary of clinical\nabbreviations and no universal rules for abbreviation writing, such texts are\ndifficult to acquire, expensive to annotate and even sometimes, confusing to\ndomain experts. This paper proposes a novel and effective approach - exploiting\ntask-oriented resources to learn word embeddings for expanding abbreviations in\nclinical notes. We achieved 82.27% accuracy, close to expert human performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:16:39 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Liu", "Yue", ""], ["Ge", "Tao", ""], ["Mathews", "Kusum S.", ""], ["Ji", "Heng", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1804.04235", "submitter": "Noam Shazeer", "authors": "Noam Shazeer and Mitchell Stern", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several recently proposed stochastic optimization methods (e.g. RMSProp,\nAdam, Adadelta), parameter updates are scaled by the inverse square roots of\nexponential moving averages of squared past gradients. Maintaining these\nper-parameter second-moment estimators requires memory equal to the number of\nparameters. For the case of neural network weight matrices, we propose\nmaintaining only the per-row and per-column sums of these moving averages, and\nestimating the per-parameter second moments based on these sums. We demonstrate\nempirically that this method produces similar results to the baseline.\nSecondly, we show that adaptive methods can produce larger-than-desired updates\nwhen the decay rate of the second moment accumulator is too slow. We propose\nupdate clipping and a gradually increasing decay rate scheme as remedies.\nCombining these methods and dropping momentum, we achieve comparable results to\nthe published Adam regime in training the Transformer model on the WMT 2014\nEnglish-German machine translation task, while using very little auxiliary\nstorage in the optimizer. Finally, we propose scaling the parameter updates\nbased on the scale of the parameters themselves.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:42:32 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Shazeer", "Noam", ""], ["Stern", "Mitchell", ""]]}, {"id": "1804.04241", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde and Ulas Bagci", "title": "Capsules for Object Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have shown remarkable results over the\nlast several years for a wide range of computer vision tasks. A new\narchitecture recently introduced by Sabour et al., referred to as a capsule\nnetworks with dynamic routing, has shown great initial results for digit\nrecognition and small image classification. The success of capsule networks\nlies in their ability to preserve more information about the input by replacing\nmax-pooling layers with convolutional strides and dynamic routing, allowing for\npreservation of part-whole relationships in the data. This preservation of the\ninput is demonstrated by reconstructing the input from the output capsule\nvectors. Our work expands the use of capsule networks to the task of object\nsegmentation for the first time in the literature. We extend the idea of\nconvolutional capsules with locally-connected routing and propose the concept\nof deconvolutional capsules. Further, we extend the masked reconstruction to\nreconstruct the positive input class. The proposed\nconvolutional-deconvolutional capsule network, called SegCaps, shows strong\nresults for the task of object segmentation with substantial decrease in\nparameter space. As an example application, we applied the proposed SegCaps to\nsegment pathological lungs from low dose CT scans and compared its accuracy and\nefficiency with other U-Net-based architectures. SegCaps is able to handle\nlarge image sizes (512 x 512) as opposed to baseline capsules (typically less\nthan 32 x 32). The proposed SegCaps reduced the number of parameters of U-Net\narchitecture by 95.4% while still providing a better segmentation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:57:57 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["LaLonde", "Rodney", ""], ["Bagci", "Ulas", ""]]}, {"id": "1804.04268", "submitter": "Dylan Hadfield-Menell", "authors": "Dylan Hadfield-Menell, Gillian Hadfield", "title": "Incomplete Contracting and AI Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest that the analysis of incomplete contracting developed by law and\neconomics researchers can provide a useful framework for understanding the AI\nalignment problem and help to generate a systematic approach to finding\nsolutions. We first provide an overview of the incomplete contracting\nliterature and explore parallels between this work and the problem of AI\nalignment. As we emphasize, misalignment between principal and agent is a core\nfocus of economic analysis. We highlight some technical results from the\neconomics literature on incomplete contracts that may provide insights for AI\nalignment researchers. Our core contribution, however, is to bring to bear an\ninsight that economists have been urged to absorb from legal scholars and other\nbehavioral scientists: the fact that human contracting is supported by\nsubstantial amounts of external structure, such as generally available\ninstitutions (culture, law) that can supply implied terms to fill the gaps in\nincomplete contracts. We propose a research agenda for AI alignment work that\nfocuses on the problem of how to build AI that can replicate the human\ncognitive processes that connect individual incomplete contracts with this\nsupporting external structure.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 01:22:50 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Hadfield-Menell", "Dylan", ""], ["Hadfield", "Gillian", ""]]}, {"id": "1804.04286", "submitter": "Sam Kriegman", "authors": "Shawn L.E. Beaulieu, Sam Kriegman, Josh C. Bongard", "title": "Combating catastrophic forgetting with developmental compression", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205615", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generally intelligent agents exhibit successful behavior across problems in\nseveral settings. Endemic in approaches to realize such intelligence in\nmachines is catastrophic forgetting: sequential learning corrupts knowledge\nobtained earlier in the sequence, or tasks antagonistically compete for system\nresources. Methods for obviating catastrophic forgetting have sought to\nidentify and preserve features of the system necessary to solve one problem\nwhen learning to solve another, or to enforce modularity such that minimally\noverlapping sub-functions contain task specific knowledge. While successful,\nboth approaches scale poorly because they require larger architectures as the\nnumber of training instances grows, causing different parts of the system to\nspecialize for separate subsets of the data. Here we present a method for\naddressing catastrophic forgetting called developmental compression. It\nexploits the mild impacts of developmental mutations to lessen adverse changes\nto previously-evolved capabilities and `compresses' specialized neural networks\ninto a generalized one. In the absence of domain knowledge, developmental\ncompression produces systems that avoid overt specialization, alleviating the\nneed to engineer a bespoke system for every task permutation and suggesting\nbetter scalability than existing approaches. We validate this method on a robot\ncontrol problem and hope to extend this approach to other machine learning\ndomains in the future.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 02:20:47 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Beaulieu", "Shawn L. E.", ""], ["Kriegman", "Sam", ""], ["Bongard", "Josh C.", ""]]}, {"id": "1804.04316", "submitter": "Makoto Naruse", "authors": "Nicolas Chauvet, David Jegouso, Beno\\^it Boulanger, Hayato Saigo,\n  Kazuya Okamura, Hirokazu Hori, Aur\\'elien Drezet, Serge Huant, Guillaume\n  Bachelier, Makoto Naruse", "title": "Entangled-photon decision maker", "comments": null, "journal-ref": "Scientific Reports, Vol. 9, Article number 12229 (2019)", "doi": "10.1038/s41598-019-48647-7", "report-no": null, "categories": "physics.optics cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competitive multi-armed bandit (CMAB) problem is related to social issues\nsuch as maximizing total social benefits while preserving equality among\nindividuals by overcoming conflicts between individual decisions, which could\nseriously decrease social benefits. The study described herein provides\nexperimental evidence that entangled photons physically resolve the CMAB in the\n2-arms 2-players case, maximizing the social rewards while ensuring equality.\nMoreover, we demonstrated that deception, or outperforming the other player by\nreceiving a greater reward, cannot be accomplished in a\npolarization-entangled-photon-based system, while deception is achievable in\nsystems based on classical polarization-correlated photons with fixed\npolarizations. Besides, random polarization-correlated photons have been\nstudied numerically and shown to ensure equality between players and deception\nprevention as well, although the CMAB maximum performance is reduced as\ncompared with entangled photon experiments. Autonomous alignment schemes for\npolarization bases were also experimentally demonstrated based only on decision\nconflict information observed by an individual without communications between\nplayers. This study paves a way for collective decision making in uncertain\ndynamically changing environments based on entangled quantum states, a crucial\nstep toward utilizing quantum systems for intelligent functionalities.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 05:04:34 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 07:23:40 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Chauvet", "Nicolas", ""], ["Jegouso", "David", ""], ["Boulanger", "Beno\u00eet", ""], ["Saigo", "Hayato", ""], ["Okamura", "Kazuya", ""], ["Hori", "Hirokazu", ""], ["Drezet", "Aur\u00e9lien", ""], ["Huant", "Serge", ""], ["Bachelier", "Guillaume", ""], ["Naruse", "Makoto", ""]]}, {"id": "1804.04318", "submitter": "Yale Song", "authors": "Yale Song and Mohammad Soleymani", "title": "Cross-Modal Retrieval with Implicit Concept Association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional cross-modal retrieval assumes explicit association of concepts\nacross modalities, where there is no ambiguity in how the concepts are linked\nto each other, e.g., when we do the image search with a query \"dogs\", we expect\nto see dog images. In this paper, we consider a different setting for\ncross-modal retrieval where data from different modalities are implicitly\nlinked via concepts that must be inferred by high-level reasoning; we call this\nsetting implicit concept association. To foster future research in this\nsetting, we present a new dataset containing 47K pairs of animated GIFs and\nsentences crawled from the web, in which the GIFs depict physical or emotional\nreactions to the scenarios described in the text (called \"reaction GIFs\"). We\nreport on a user study showing that, despite the presence of implicit concept\nassociation, humans are able to identify video-sentence pairs with matching\nconcepts, suggesting the feasibility of our task. Furthermore, we propose a\nnovel visual-semantic embedding network based on multiple instance learning.\nUnlike traditional approaches, we compute multiple embeddings from each\nmodality, each representing different concepts, and measure their similarity by\nconsidering all possible combinations of visual-semantic embeddings in the\nframework of multiple instance learning. We evaluate our approach on two\nvideo-sentence datasets with explicit and implicit concept association and\nreport competitive results compared to existing approaches on cross-modal\nretrieval.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 05:10:33 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 16:30:57 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Song", "Yale", ""], ["Soleymani", "Mohammad", ""]]}, {"id": "1804.04326", "submitter": "Yuya Yoshikawa", "authors": "Yuya Yoshikawa, Jiaqing Lin, Akikazu Takeuchi", "title": "STAIR Actions: A Video Dataset of Everyday Home Actions", "comments": "STAIR Actions dataset can be downloaded from\n  http://actions.stair.center", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new large-scale video dataset for human action recognition, called STAIR\nActions is introduced. STAIR Actions contains 100 categories of action labels\nrepresenting fine-grained everyday home actions so that it can be applied to\nresearch in various home tasks such as nursing, caring, and security. In STAIR\nActions, each video has a single action label. Moreover, for each action\ncategory, there are around 1,000 videos that were obtained from YouTube or\nproduced by crowdsource workers. The duration of each video is mostly five to\nsix seconds. The total number of videos is 102,462. We explain how we\nconstructed STAIR Actions and show the characteristics of STAIR Actions\ncompared to existing datasets for human action recognition. Experiments with\nthree major models for action recognition show that STAIR Actions can train\nlarge models and achieve good performance. STAIR Actions can be downloaded from\nhttp://actions.stair.center\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 05:48:06 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 03:26:54 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 05:40:42 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Yoshikawa", "Yuya", ""], ["Lin", "Jiaqing", ""], ["Takeuchi", "Akikazu", ""]]}, {"id": "1804.04327", "submitter": "Lucas Vinh Tran", "authors": "Lucas Vinh Tran, Tuan-Anh Nguyen Pham, Yi Tay, Yiding Liu, Gao Cong,\n  Xiaoli Li", "title": "Interact and Decide: Medley of Sub-Attention Networks for Effective\n  Group Recommendation", "comments": "Accepted at SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Medley of Sub-Attention Networks (MoSAN), a new novel\nneural architecture for the group recommendation task. Group-level\nrecommendation is known to be a challenging task, in which intricate group\ndynamics have to be considered. As such, this is to be contrasted with the\nstandard recommendation problem where recommendations are personalized with\nrespect to a single user. Our proposed approach hinges upon the key intuition\nthat the decision making process (in groups) is generally dynamic, i.e., a\nuser's decision is highly dependent on the other group members. All in all, our\nkey motivation manifests in a form of an attentive neural model that captures\nfine-grained interactions between group members. In our MoSAN model, each\nsub-attention module is representative of a single member, which models a\nuser's preference with respect to all other group members. Subsequently, a\nMedley of Sub-Attention modules is then used to collectively make the group's\nfinal decision. Overall, our proposed model is both expressive and effective.\nVia a series of extensive experiments, we show that MoSAN not only achieves\nstate-of-the-art performance but also improves standard baselines by a\nconsiderable margin.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 05:54:13 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 09:45:35 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 03:15:39 GMT"}, {"version": "v4", "created": "Sat, 23 Nov 2019 05:12:52 GMT"}, {"version": "v5", "created": "Thu, 28 Nov 2019 10:08:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Tran", "Lucas Vinh", ""], ["Pham", "Tuan-Anh Nguyen", ""], ["Tay", "Yi", ""], ["Liu", "Yiding", ""], ["Cong", "Gao", ""], ["Li", "Xiaoli", ""]]}, {"id": "1804.04353", "submitter": "Rohith Aralikatti", "authors": "Rohith Aralikatti, Dilip Margam, Tanay Sharma, Thanda Abhinav, Shankar\n  M Venkatesan", "title": "Global SNR Estimation of Speech Signals using Entropy and Uncertainty\n  Estimates from Dropout Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates two novel methods to estimate the global SNR of\nspeech signals. In both methods, Deep Neural Network-Hidden Markov Model\n(DNN-HMM) acoustic model used in speech recognition systems is leveraged for\nthe additional task of SNR estimation. In the first method, the entropy of the\nDNN-HMM output is computed. Recent work on bayesian deep learning has shown\nthat a DNN-HMM trained with dropout can be used to estimate model uncertainty\nby approximating it as a deep Gaussian process. In the second method, this\napproximation is used to obtain model uncertainty estimates. Noise specific\nregressors are used to predict the SNR from the entropy and model uncertainty.\nThe DNN-HMM is trained on GRID corpus and tested on different noise profiles\nfrom the DEMAND noise database at SNR levels ranging from -10 dB to 30 dB.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 07:15:20 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Aralikatti", "Rohith", ""], ["Margam", "Dilip", ""], ["Sharma", "Tanay", ""], ["Abhinav", "Thanda", ""], ["Venkatesan", "Shankar M", ""]]}, {"id": "1804.04367", "submitter": "Olivier Cur\\'e", "authors": "Xiangnan Ren and Olivier Cur\\'e and Hubert Naacke and Guohui Xiao", "title": "BigSR: an empirical study of real-time expressive RDF stream reasoning\n  on modern Big Data platforms", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trade-off between language expressiveness and system scalability (E&S) is\na well-known problem in RDF stream reasoning. Higher expressiveness supports\nmore complex reasoning logic, however, it may also hinder system scalability.\nCurrent research mainly focuses on logical frameworks suitable for stream\nreasoning as well as the implementation and the evaluation of prototype\nsystems. These systems are normally developed in a centralized setting which\nsuffer from inherent limited scalability, while an in-depth study of applying\ndistributed solutions to cover E&S is still missing. In this paper, we aim to\nexplore the feasibility of applying modern distributed computing frameworks to\nmeet E&S all together. To do so, we first propose BigSR, a technical\ndemonstrator that supports a positive fragment of the LARS framework. For the\nsake of generality and to cover a wide variety of use cases, BigSR relies on\nthe two main execution models adopted by major distributed execution\nframeworks: Bulk Synchronous Processing (BSP) and Record-at-A-Time (RAT).\nAccordingly, we implement BigSR on top of Apache Spark Streaming (BSP model)\nand Apache Flink (RAT model). In order to conclude on the impacts of BSP and\nRAT on E&S, we analyze the ability of the two models to support distributed\nstream reasoning and identify several types of use cases characterized by their\nlevels of support. This classification allows for quantifying the E&S trade-off\nby assessing the scalability of each type of use case \\wrt its level of\nexpressiveness. Then, we conduct a series of experiments with 15 queries from 4\ndifferent datasets. Our experiments show that BigSR over both BSP and RAT\ngenerally scales up to high throughput beyond million-triples per second (with\nor without recursion), and RAT attains sub-millisecond delay for stateless\nquery operators.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 08:15:17 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Ren", "Xiangnan", ""], ["Cur\u00e9", "Olivier", ""], ["Naacke", "Hubert", ""], ["Xiao", "Guohui", ""]]}, {"id": "1804.04421", "submitter": "Bruno Ordozgoiti", "authors": "Bruno Ordozgoiti, Alberto Mozo, Jes\\'us Garc\\'ia L\\'opez de Lacalle", "title": "Regularized Greedy Column Subset Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Column Subset Selection Problem provides a natural framework for\nunsupervised feature selection. Despite being a hard combinatorial optimization\nproblem, there exist efficient algorithms that provide good approximations. The\ndrawback of the problem formulation is that it incorporates no form of\nregularization, and is therefore very sensitive to noise when presented with\nscarce data. In this paper we propose a regularized formulation of this\nproblem, and derive a correct greedy algorithm that is similar in efficiency to\nexisting greedy methods for the unregularized problem. We study its adequacy\nfor feature selection and propose suitable formulations. Additionally, we\nderive a lower bound for the error of the proposed problems. Through various\nnumerical experiments on real and synthetic data, we demonstrate the\nsignificantly increased robustness and stability of our method, as well as the\nimproved conditioning of its output, all while remaining efficient for\npractical use.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 10:56:44 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Ordozgoiti", "Bruno", ""], ["Mozo", "Alberto", ""], ["de Lacalle", "Jes\u00fas Garc\u00eda L\u00f3pez", ""]]}, {"id": "1804.04452", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Constantin A. Rothkopf, Frank J\\\"akel", "title": "Solving Bongard Problems with a Visual Language and Pragmatic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 50 years ago Bongard introduced 100 visual concept learning\nproblems as a testbed for intelligent vision systems. These problems are now\nknown as Bongard problems. Although they are well known in the cognitive\nscience and AI communities only moderate progress has been made towards\nbuilding systems that can solve a substantial subset of them. In the system\npresented here, visual features are extracted through image processing and then\ntranslated into a symbolic visual vocabulary. We introduce a formal language\nthat allows representing complex visual concepts based on this vocabulary.\nUsing this language and Bayesian inference, complex visual concepts can be\ninduced from the examples that are provided in each Bongard problem. Contrary\nto other concept learning problems the examples from which concepts are induced\nare not random in Bongard problems, instead they are carefully chosen to\ncommunicate the concept, hence requiring pragmatic reasoning. Taking pragmatic\nreasoning into account we find good agreement between the concepts with high\nposterior probability and the solutions formulated by Bongard himself. While\nthis approach is far from solving all Bongard problems, it solves the biggest\nfraction yet.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:05:28 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Depeweg", "Stefan", ""], ["Rothkopf", "Constantin A.", ""], ["J\u00e4kel", "Frank", ""]]}, {"id": "1804.04458", "submitter": "Daniel Worrall", "authors": "Daniel Worrall and Gabriel Brostow", "title": "CubeNet: Equivariance to 3D Rotation and Translation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Convolutional Neural Networks are sensitive to transformations applied to\ntheir input. This is a problem because a voxelized version of a 3D object, and\nits rotated clone, will look unrelated to each other after passing through to\nthe last layer of a network. Instead, an idealized model would preserve a\nmeaningful representation of the voxelized object, while explaining the\npose-difference between the two inputs. An equivariant representation vector\nhas two components: the invariant identity part, and a discernable encoding of\nthe transformation. Models that can't explain pose-differences risk \"diluting\"\nthe representation, in pursuit of optimizing a classification or regression\nloss function.\n  We introduce a Group Convolutional Neural Network with linear equivariance to\ntranslations and right angle rotations in three dimensions. We call this\nnetwork CubeNet, reflecting its cube-like symmetry. By construction, this\nnetwork helps preserve a 3D shape's global and local signature, as it is\ntransformed through successive layers. We apply this network to a variety of 3D\ninference problems, achieving state-of-the-art on the ModelNet10 classification\nchallenge, and comparable performance on the ISBI 2012 Connectome Segmentation\nBenchmark. To the best of our knowledge, this is the first 3D rotation\nequivariant CNN for voxel representations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:14:18 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Worrall", "Daniel", ""], ["Brostow", "Gabriel", ""]]}, {"id": "1804.04603", "submitter": "Zhenxin Wang", "authors": "Zhenxin Wang, Sayan Sarcar, Jingxin Liu, Yilin Zheng, Xiangshi Ren", "title": "Outline Objects using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation needs both local boundary position information and global\nobject context information. The performance of the recent state-of-the-art\nmethod, fully convolutional networks, reaches a bottleneck due to the neural\nnetwork limit after balancing between the two types of information\nsimultaneously in an end-to-end training style. To overcome this problem, we\ndivide the semantic image segmentation into temporal subtasks. First, we find a\npossible pixel position of some object boundary; then trace the boundary at\nsteps within a limited length until the whole object is outlined. We present\nthe first deep reinforcement learning approach to semantic image segmentation,\ncalled DeepOutline, which outperforms other algorithms in Coco detection\nleaderboard in the middle and large size person category in Coco val2017\ndataset. Meanwhile, it provides an insight into a divide and conquer way by\nreinforcement learning on computer vision problems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 03:25:31 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 07:10:44 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Wang", "Zhenxin", ""], ["Sarcar", "Sayan", ""], ["Liu", "Jingxin", ""], ["Zheng", "Yilin", ""], ["Ren", "Xiangshi", ""]]}, {"id": "1804.04604", "submitter": "Daniel Harari", "authors": "Daniel Harari, Joshua B. Tenenbaum and Shimon Ullman", "title": "Discovery and usage of joint attention in images", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint visual attention is characterized by two or more individuals looking at\na common target at the same time. The ability to identify joint attention in\nscenes, the people involved, and their common target, is fundamental to the\nunderstanding of social interactions, including others' intentions and goals.\nIn this work we deal with the extraction of joint attention events, and the use\nof such events for image descriptions. The work makes two novel contributions.\nFirst, our extraction algorithm is the first which identifies joint visual\nattention in single static images. It computes 3D gaze direction, identifies\nthe gaze target by combining gaze direction with a 3D depth map computed for\nthe image, and identifies the common gaze target. Second, we use a human study\nto demonstrate the sensitivity of humans to joint attention, suggesting that\nthe detection of such a configuration in an image can be useful for\nunderstanding the image, including the goals of the agents and their joint\nactivity, and therefore can contribute to image captioning and related tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 07:04:19 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Harari", "Daniel", ""], ["Tenenbaum", "Joshua B.", ""], ["Ullman", "Shimon", ""]]}, {"id": "1804.04635", "submitter": "Colin Lockard", "authors": "Colin Lockard, Xin Luna Dong, Arash Einolghozati, Prashant Shiralkar", "title": "CERES: Distantly Supervised Relation Extraction from the Semi-Structured\n  Web", "comments": "Expanded version of paper under review for VLDB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web contains countless semi-structured websites, which can be a rich\nsource of information for populating knowledge bases. Existing methods for\nextracting relations from the DOM trees of semi-structured webpages can achieve\nhigh precision and recall only when manual annotations for each website are\navailable. Although there have been efforts to learn extractors from\nautomatically-generated labels, these methods are not sufficiently robust to\nsucceed in settings with complex schemas and information-rich websites.\n  In this paper we present a new method for automatic extraction from\nsemi-structured websites based on distant supervision. We automatically\ngenerate training labels by aligning an existing knowledge base with a web page\nand leveraging the unique structural characteristics of semi-structured\nwebsites. We then train a classifier based on the potentially noisy and\nincomplete labels to predict new relation instances. Our method can compete\nwith annotation-based techniques in the literature in terms of extraction\nquality. A large-scale experiment on over 400,000 pages from dozens of\nmulti-lingual long-tail websites harvested 1.25 million facts at a precision of\n90%.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 17:19:36 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Lockard", "Colin", ""], ["Dong", "Xin Luna", ""], ["Einolghozati", "Arash", ""], ["Shiralkar", "Prashant", ""]]}, {"id": "1804.04696", "submitter": "Shaojun Zhu", "authors": "Shaojun Zhu, David Surovik, Kostas E. Bekris and Abdeslam Boularias", "title": "Efficient Model Identification for Tensegrity Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to identify in a practical manner unknown physical\nparameters, such as mechanical models of actuated robot links, which are\ncritical in dynamical robotic tasks. Key features include the use of an\noff-the-shelf physics engine and the Bayesian optimization framework. The task\nbeing considered is locomotion with a high-dimensional, compliant Tensegrity\nrobot. A key insight, in this case, is the need to project the model\nidentification challenge into an appropriate lower dimensional space for\nefficiency. Comparisons with alternatives indicate that the proposed method can\nidentify the parameters more accurately within the given time budget, which\nalso results in more precise locomotion control.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 19:15:34 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Zhu", "Shaojun", ""], ["Surovik", "David", ""], ["Bekris", "Kostas E.", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "1804.04789", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried, Austin Nowak, Joannier Pinales", "title": "Successful Nash Equilibrium Agent for a 3-Player Imperfect-Information\n  Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating strong agents for games with more than two players is a major open\nproblem in AI. Common approaches are based on approximating game-theoretic\nsolution concepts such as Nash equilibrium, which have strong theoretical\nguarantees in two-player zero-sum games, but no guarantees in non-zero-sum\ngames or in games with more than two players. We describe an agent that is able\nto defeat a variety of realistic opponents using an exact Nash equilibrium\nstrategy in a 3-player imperfect-information game. This shows that, despite a\nlack of theoretical guarantees, agents based on Nash equilibrium strategies can\nbe successful in multiplayer games after all.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 05:15:28 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ganzfried", "Sam", ""], ["Nowak", "Austin", ""], ["Pinales", "Joannier", ""]]}, {"id": "1804.04946", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Issei Tachibana", "title": "Affective Recommendation System for Tourists by Using Emotion Generating\n  Calculations", "comments": "6 pages, 10 figures. arXiv admin note: substantial text overlap with\n  arXiv:1804.02657 and arXiv:1804.03994", "journal-ref": "Proc. of IEEE 7th International Workshop on Computational\n  Intelligence and Applications (IWCIA2014)", "doi": "10.1109/IWCIA.2014.6987727", "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emotion orientated intelligent interface consists of Emotion Generating\nCalculations (EGC) and Mental State Transition Network (MSTN). We have\ndeveloped the Android EGC application software which the agent works to\nevaluate the feelings in the conversation. In this paper, we develop the\ntourist information system which can estimate the user's feelings at the\nsightseeing spot. The system can recommend the sightseeing spot and the local\nfood corresponded to the user's feeling. The system calculates the\nrecommendation list by the estimate function which consists of Google search\nresults, the important degree of a term at the sightseeing website, and the the\naroused emotion by EGC. In order to show the effectiveness, this paper\ndescribes the experimental results for some situations during Hiroshima\nsightseeing.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:55:27 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tachibana", "Issei", ""]]}, {"id": "1804.05002", "submitter": "Roman V\\'aclav\\'ik", "authors": "Roman V\\'aclav\\'ik, P\\v{r}emysl \\v{S}\\r{u}cha, Zden\\v{e}k Hanz\\'alek", "title": "Roster Evaluation Based on Classifiers for the Nurse Rostering Problem", "comments": null, "journal-ref": null, "doi": "10.1007/s10732-016-9314-9", "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The personnel scheduling problem is a well-known NP-hard combinatorial\nproblem. Due to the complexity of this problem and the size of the real-world\ninstances, it is not possible to use exact methods, and thus heuristics,\nmeta-heuristics, or hyper-heuristics must be employed. The majority of\nheuristic approaches are based on iterative search, where the quality of\nintermediate solutions must be calculated. Unfortunately, this is\ncomputationally highly expensive because these problems have many constraints\nand some are very complex. In this study, we propose a machine learning\ntechnique as a tool to accelerate the evaluation phase in heuristic approaches.\nThe solution is based on a simple classifier, which is able to determine\nwhether the changed solution (more precisely, the changed part of the solution)\nis better than the original or not. This decision is made much faster than a\nstandard cost-oriented evaluation process. However, the classification process\ncannot guarantee 100% correctness. Therefore, our approach, which is\nillustrated using a tabu search algorithm in this study, includes a filtering\nmechanism, where the classifier rejects the majority of the potentially bad\nsolutions and the remaining solutions are then evaluated in a standard manner.\nWe also show how the boosting algorithms can improve the quality of the final\nsolution compared with a simple classifier. We verified our proposed approach\nand premises, based on standard and real-world benchmark instances, to\ndemonstrate the significant speedup obtained with comparable solution quality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 15:47:00 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["V\u00e1clav\u00edk", "Roman", ""], ["\u0160\u016fcha", "P\u0159emysl", ""], ["Hanz\u00e1lek", "Zden\u011bk", ""]]}, {"id": "1804.05012", "submitter": "Phil Long", "authors": "Peter L. Bartlett, Steven N. Evans and Philip M. Long", "title": "Representing smooth functions as compositions of near-identity functions\n  with implications for deep network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any smooth bi-Lipschitz $h$ can be represented exactly as a\ncomposition $h_m \\circ ... \\circ h_1$ of functions $h_1,...,h_m$ that are close\nto the identity in the sense that each $\\left(h_i-\\mathrm{Id}\\right)$ is\nLipschitz, and the Lipschitz constant decreases inversely with the number $m$\nof functions composed. This implies that $h$ can be represented to any accuracy\nby a deep residual network whose nonlinear layers compute functions with a\nsmall Lipschitz constant. Next, we consider nonlinear regression with a\ncomposition of near-identity nonlinear maps. We show that, regarding Fr\\'echet\nderivatives with respect to the $h_1,...,h_m$, any critical point of a\nquadratic criterion in this near-identity region must be a global minimizer. In\ncontrast, if we consider derivatives with respect to parameters of a fixed-size\nresidual network with sigmoid activation functions, we show that there are\nnear-identity critical points that are suboptimal, even in the realizable case.\nInformally, this means that functional gradient methods for residual networks\ncannot get stuck at suboptimal critical points corresponding to near-identity\nlayers, whereas parametric gradient methods for sigmoidal residual networks\nsuffer from suboptimal critical points in the near-identity region.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:24:17 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 17:07:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Evans", "Steven N.", ""], ["Long", "Philip M.", ""]]}, {"id": "1804.05044", "submitter": "Tobias K\\\"afer", "authors": "Tobias K\\\"afer and Andreas Harth", "title": "Specifying, Monitoring, and Executing Workflows in Linked Data\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an ontology for representing workflows over components with\nRead-Write Linked Data interfaces and give an operational semantics to the\nontology via a rule language. Workflow languages have been successfully applied\nfor modelling behaviour in enterprise information systems, in which the data is\noften managed in a relational database. Linked Data interfaces have been widely\ndeployed on the web to support data integration in very diverse domains,\nincreasingly also in scenarios involving the Internet of Things, in which\napplication behaviour is often specified using imperative programming\nlanguages. With our work we aim to combine workflow languages, which allow for\nthe high-level specification of application behaviour by non-expert users, with\nLinked Data, which allows for decentralised data publication and integrated\ndata access. We show that our ontology is expressive enough to cover the basic\nworkflow patterns and demonstrate the applicability of our approach with a\nprototype system that observes pilots carrying out tasks in a mixed-reality\naircraft cockpit. On a synthetic benchmark from the building automation domain,\nthe runtime scales linearly with the size of the number of Internet of Things\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 17:22:17 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 13:37:43 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 18:36:54 GMT"}, {"version": "v4", "created": "Thu, 19 Apr 2018 16:32:28 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["K\u00e4fer", "Tobias", ""], ["Harth", "Andreas", ""]]}, {"id": "1804.05092", "submitter": "Saman Sadeghyan", "authors": "Saman Sadeghyan", "title": "A new robust feature selection method using variance-based sensitivity\n  analysis", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excluding irrelevant features in a pattern recognition task plays an\nimportant role in maintaining a simpler machine learning model and optimizing\nthe computational efficiency. Nowadays with the rise of large scale datasets,\nfeature selection is in great demand as it becomes a central issue when facing\nhigh-dimensional datasets. The present study provides a new measure of saliency\nfor features by employing a Sensitivity Analysis (SA) technique called the\nextended Fourier amplitude sensitivity test, and a well-trained Feedforward\nNeural Network (FNN) model, which ultimately leads to the selection of a\npromising optimal feature subset. Ideas of the paper are mainly demonstrated\nbased on adopting FNN model for feature selection in classification problems.\nBut in the end, a generalization framework is discussed in order to give\ninsights into the usage in regression problems as well as expressing how other\nfunction approximate models can be deployed. Effectiveness of the proposed\nmethod is verified by result analysis and data visualization for a series of\nexperiments over several well-known datasets drawn from UCI machine learning\nrepository.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 19:29:40 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Sadeghyan", "Saman", ""]]}, {"id": "1804.05184", "submitter": "Muhammad Rizwan Saeed", "authors": "Muhammad Rizwan Saeed, Charalampos Chelmis, Viktor K. Prasanna", "title": "Not all Embeddings are created Equal: Extracting Entity-specific\n  Substructures for RDF Graph Embedding", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) are becoming essential to information systems that\nrequire access to structured data. Several approaches have been recently\nproposed, for obtaining vector representations of KGs suitable for Machine\nLearning tasks, based on identifying and extracting relevant graph\nsubstructures using uniform and biased random walks. However, such approaches\nlead to representations comprising mostly \"popular\", instead of \"relevant\",\nentities in the KG. In KGs, in which different types of entities often exist\n(such as in Linked Open Data), a given target entity may have its own distinct\nset of most \"relevant\" nodes and edges. We propose specificity as an accurate\nmeasure of identifying most relevant, entity-specific, nodes and edges. We\ndevelop a scalable method based on bidirectional random walks to compute\nspecificity. Our experimental evaluation results show that specificity-based\nbiased random walks extract more \"meaningful\" (in terms of size and relevance)\nRDF substructures compared to the state-of-the-art and, the graph embedding\nlearned from the extracted substructures, outperform existing techniques in the\ntask of entity recommendation in DBpedia.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 08:27:41 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Saeed", "Muhammad Rizwan", ""], ["Chelmis", "Charalampos", ""], ["Prasanna", "Viktor K.", ""]]}, {"id": "1804.05212", "submitter": "Avi Segal", "authors": "Avi Segal, Yossi Ben David, Joseph Jay Williams, Kobi Gal, Yaar Shalom", "title": "Combining Difficulty Ranking with Multi-Armed Bandits to Sequence\n  Educational Content", "comments": null, "journal-ref": null, "doi": "10.1016/j.physletb.2019.04.047", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As e-learning systems become more prevalent, there is a growing need for them\nto accommodate individual differences between students. This paper addresses\nthe problem of how to personalize educational content to students in order to\nmaximize their learning gains over time. We present a new computational\napproach to this problem called MAPLE (Multi-Armed Bandits based\nPersonalization for Learning Environments) that combines difficulty ranking\nwith multi-armed bandits. Given a set of target questions MAPLE estimates the\nexpected learning gains for each question and uses an exploration-exploitation\nstrategy to choose the next question to pose to the student. It maintains a\npersonalized ranking over the difficulties of question in the target set which\nis used in two ways: First, to obtain initial estimates over the learning gains\nfor the set of questions. Second, to update the estimates over time based on\nthe students responses. We show in simulations that MAPLE was able to improve\nstudents' learning gains compared to approaches that sequence questions in\nincreasing level of difficulty, or rely on content experts. When implemented in\na live e-learning system in the wild, MAPLE showed promising results. This work\ndemonstrates the efficacy of using stochastic approaches to the sequencing\nproblem when augmented with information about question difficulty.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 12:36:00 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Segal", "Avi", ""], ["David", "Yossi Ben", ""], ["Williams", "Joseph Jay", ""], ["Gal", "Kobi", ""], ["Shalom", "Yaar", ""]]}, {"id": "1804.05260", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Vincent Atanasov, Takanori Maehara, Ken-ichi\n  Kawarabayashi", "title": "ClassiNet -- Predicting Missing Features for Short-Text Classification", "comments": "Accepted to ACM TKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental problem in short-text classification is \\emph{feature\nsparseness} -- the lack of feature overlap between a trained model and a test\ninstance to be classified. We propose \\emph{ClassiNet} -- a network of\nclassifiers trained for predicting missing features in a given instance, to\novercome the feature sparseness problem. Using a set of unlabeled training\ninstances, we first learn binary classifiers as feature predictors for\npredicting whether a particular feature occurs in a given instance. Next, each\nfeature predictor is represented as a vertex $v_i$ in the ClassiNet where a\none-to-one correspondence exists between feature predictors and vertices. The\nweight of the directed edge $e_{ij}$ connecting a vertex $v_i$ to a vertex\n$v_j$ represents the conditional probability that given $v_i$ exists in an\ninstance, $v_j$ also exists in the same instance. We show that ClassiNets\ngeneralize word co-occurrence graphs by considering implicit co-occurrences\nbetween features. We extract numerous features from the trained ClassiNet to\novercome feature sparseness. In particular, for a given instance $\\vec{x}$, we\nfind similar features from ClassiNet that did not appear in $\\vec{x}$, and\nappend those features in the representation of $\\vec{x}$. Moreover, we propose\na method based on graph propagation to find features that are indirectly\nrelated to a given short-text. We evaluate ClassiNets on several benchmark\ndatasets for short-text classification. Our experimental results show that by\nusing ClassiNet, we can statistically significantly improve the accuracy in\nshort-text classification tasks, without having to use any external resources\nsuch as thesauri for finding related features.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 18:24:06 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bollegala", "Danushka", ""], ["Atanasov", "Vincent", ""], ["Maehara", "Takanori", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1804.05283", "submitter": "Shiyong Ma", "authors": "Shiyong Ma, Zhen Zhang", "title": "OmicsMapNet: Transforming omics data to take advantage of Deep\n  Convolutional Neural Network for discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed OmicsMapNet approach to take advantage of existing deep leaning\nframeworks to analyze high-dimensional omics data as 2-dimensional images. The\nomics data of individual samples were first rearranged into 2D images in which\nmolecular features related in functions, ontologies, or other relationships\nwere organized in spatially adjacent and patterned locations. Deep learning\nneural networks were trained to classify the images. Molecular features\ninformative of classes of different phenotypes were subsequently identified. As\nan example, we used the KEGG BRITE database to rearrange RNA-Seq expression\ndata of TCGA diffuse glioma samples as treemaps to capture the functional\nhierarchical structure of genes in 2D images. Deep Convolutional Neural\nNetworks (CNN) were derived using tools from TensorFlow to learn the grade of\nTCGA LGG and GBM samples with relatively high accuracy. The most contributory\nfeatures in the trained CNN were confirmed in pathway analysis for their\nplausible functional involvement.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 22:22:21 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:46:16 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ma", "Shiyong", ""], ["Zhang", "Zhen", ""]]}, {"id": "1804.05320", "submitter": "Indrasis Chakraborty", "authors": "Indrasis Chakraborty, Rudrasis Chakraborty, Draguna Vrabie", "title": "Generative Adversarial Network based Autoencoder: Application to fault\n  detection problem for closed loop dynamical systems", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault detection problem for closed loop uncertain dynamical systems, is\ninvestigated in this paper, using different deep learning based methods.\nTraditional classifier based method does not perform well, because of the\ninherent difficulty of detecting system level faults for closed loop dynamical\nsystem. Specifically, acting controller in any closed loop dynamical system,\nworks to reduce the effect of system level faults. A novel Generative\nAdversarial based deep Autoencoder is designed to classify datasets under\nnormal and faulty operating conditions. This proposed network performs\nsignificantly well when compared to any available classifier based methods, and\nmoreover, does not require labeled fault incorporated datasets for training\npurpose. Finally, this aforementioned network's performance is tested on a high\ncomplexity building energy system dataset.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 08:28:15 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 03:21:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Chakraborty", "Indrasis", ""], ["Chakraborty", "Rudrasis", ""], ["Vrabie", "Draguna", ""]]}, {"id": "1804.05348", "submitter": "Ursula Challita", "authors": "Ursula Challita, Aidin Ferdowsi, Mingzhe Chen, Walid Saad", "title": "Machine Learning for Wireless Connectivity and Security of\n  Cellular-Connected UAVs", "comments": "This manuscript has been accepted for publication in IEEE Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular-connected unmanned aerial vehicles (UAVs) will inevitably be\nintegrated into future cellular networks as new aerial mobile users. Providing\ncellular connectivity to UAVs will enable a myriad of applications ranging from\nonline video streaming to medical delivery. However, to enable a reliable\nwireless connectivity for the UAVs as well as a secure operation, various\nchallenges need to be addressed such as interference management, mobility\nmanagement and handover, cyber-physical attacks, and authentication. In this\npaper, the goal is to expose the wireless and security challenges that arise in\nthe context of UAV-based delivery systems, UAV-based real-time multimedia\nstreaming, and UAV-enabled intelligent transportation systems. To address such\nchallenges, artificial neural network (ANN) based solution schemes are\nintroduced. The introduced approaches enable the UAVs to adaptively exploit the\nwireless system resources while guaranteeing a secure operation, in real-time.\nPreliminary simulation results show the benefits of the introduced solutions\nfor each of the aforementioned cellular-connected UAV application use case.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 12:33:55 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 20:23:08 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 22:06:32 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Challita", "Ursula", ""], ["Ferdowsi", "Aidin", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""]]}, {"id": "1804.05374", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Dmitriy Serdyuk, Yoshua Bengio", "title": "Twin Regularization for online speech recognition", "comments": "Accepted at INTESPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 15:52:16 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:00:03 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Serdyuk", "Dmitriy", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.05435", "submitter": "Peter Clark", "authors": "Peter Clark, Bhavana Dalvi, Niket Tandon", "title": "What Happened? Leveraging VerbNet to Predict the Effects of Actions in\n  Procedural Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to answer questions about paragraphs describing processes (e.g.,\nphotosynthesis). Texts of this genre are challenging because the effects of\nactions are often implicit (unstated), requiring background knowledge and\ninference to reason about the changing world states. To supply this knowledge,\nwe leverage VerbNet to build a rulebase (called the Semantic Lexicon) of the\npreconditions and effects of actions, and use it along with commonsense\nknowledge of persistence to answer questions about change. Our evaluation shows\nthat our system, ProComp, significantly outperforms two strong reading\ncomprehension (RC) baselines. Our contributions are two-fold: the Semantic\nLexicon rulebase itself, and a demonstration of how a simulation-based approach\nto machine reading can outperform RC methods that rely on surface cues alone.\n  Since this work was performed, we have developed neural systems that\noutperform ProComp, described elsewhere (Dalvi et al., NAACL'18). However, the\nSemantic Lexicon remains a novel and potentially useful resource, and its\nintegration with neural systems remains a currently unexplored opportunity for\nfurther improvements in machine reading about processes.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:48:28 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Clark", "Peter", ""], ["Dalvi", "Bhavana", ""], ["Tandon", "Niket", ""]]}, {"id": "1804.05448", "submitter": "Xin Wang", "authors": "Xin Wang, Yuan-Fang Wang, William Yang Wang", "title": "Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal\n  Attentions for Video Captioning", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge for video captioning is to combine audio and visual cues.\nExisting multi-modal fusion methods have shown encouraging results in video\nunderstanding. However, the temporal structures of multiple modalities at\ndifferent granularities are rarely explored, and how to selectively fuse the\nmulti-modal representations at different levels of details remains uncharted.\nIn this paper, we propose a novel hierarchically aligned cross-modal attention\n(HACA) framework to learn and selectively fuse both global and local temporal\ndynamics of different modalities. Furthermore, for the first time, we validate\nthe superior performance of the deep audio features on the video captioning\ntask. Finally, our HACA model significantly outperforms the previous best\nsystems and achieves new state-of-the-art results on the widely used MSR-VTT\ndataset.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 23:04:57 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Wang", "Xin", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.05560", "submitter": "Naman Goel", "authors": "Naman Goel, Boi Faltings", "title": "Deep Bayesian Trust : A Dominant and Fair Incentive Mechanism for Crowd", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important class of game-theoretic incentive mechanisms for eliciting\neffort from a crowd are the peer based mechanisms, in which workers are paid by\nmatching their answers with one another. The other classic mechanism is to have\nthe workers solve some gold standard tasks and pay them according to their\naccuracy on gold tasks. This mechanism ensures stronger incentive compatibility\nthan the peer based mechanisms but assigning gold tasks to all workers becomes\ninefficient at large scale. We propose a novel mechanism that assigns gold\ntasks to only a few workers and exploits transitivity to derive accuracy of the\nrest of the workers from their peers' accuracy. We show that the resulting\nmechanism ensures a dominant notion of incentive compatibility and fairness.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 09:04:11 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 22:26:16 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Goel", "Naman", ""], ["Faltings", "Boi", ""]]}, {"id": "1804.05655", "submitter": "Ishan Rastogi", "authors": "Ishan Rastogi, Aditya Kanade and Shirish Shevade", "title": "Active Learning for Efficient Testing of Student Programs", "comments": "14 pages, 6 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an automated method to identify semantic bugs in\nstudent programs, called ATAS, which builds upon the recent advances in both\nsymbolic execution and active learning. Symbolic execution is a program\nanalysis technique which can generate test cases through symbolic constraint\nsolving. Our method makes use of a reference implementation of the task as its\nsole input. We compare our method with a symbolic execution-based baseline on 6\nprogramming tasks retrieved from CodeForces comprising a total of 23K student\nsubmissions. We show an average improvement of over 2.5x over the baseline in\nterms of runtime (thus making it more suitable for online evaluation), without\na significant degradation in evaluation accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 06:53:00 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Rastogi", "Ishan", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "1804.05697", "submitter": "Antonio Luca Alfeo", "authors": "Antonio L. Alfeo, Mario G. C. A. Cimino, Sara Egidi, Bruno Lepri,\n  Gigliola Vaglini", "title": "A stigmergy-based analysis of city hotspots to discover trends and\n  anomalies in urban transportation usage", "comments": "Preprint", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, IEEE,\n  Vol. 19, Issue 7, Pages 2258-2267, 2018, (ISSN 1524-9050)", "doi": "10.1109/TITS.2018.2817558", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A key aspect of a sustainable urban transportation system is the\neffectiveness of transportation policies. To be effective, a policy has to\nconsider a broad range of elements, such as pollution emission, traffic flow,\nand human mobility. Due to the complexity and variability of these elements in\nthe urban area, to produce effective policies remains a very challenging task.\nWith the introduction of the smart city paradigm, a widely available amount of\ndata can be generated in the urban spaces. Such data can be a fundamental\nsource of knowledge to improve policies because they can reflect the\nsustainability issues underlying the city. In this context, we propose an\napproach to exploit urban positioning data based on stigmergy, a bio-inspired\nmechanism providing scalar and temporal aggregation of samples. By employing\nstigmergy, samples in proximity with each other are aggregated into a\nfunctional structure called trail. The trail summarizes relevant dynamics in\ndata and allows matching them, providing a measure of their similarity.\nMoreover, this mechanism can be specialized to unfold specific dynamics.\nSpecifically, we identify high-density urban areas (i.e hotspots), analyze\ntheir activity over time, and unfold anomalies. Moreover, by matching activity\npatterns, a continuous measure of the dissimilarity with respect to the typical\nactivity pattern is provided. This measure can be used by policy makers to\nevaluate the effect of policies and change them dynamically. As a case study,\nwe analyze taxi trip data gathered in Manhattan from 2013 to 2015.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 14:19:06 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 15:27:45 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Alfeo", "Antonio L.", ""], ["Cimino", "Mario G. C. A.", ""], ["Egidi", "Sara", ""], ["Lepri", "Bruno", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1804.05741", "submitter": "Chris Norval", "authors": "Jatinder Singh, Jennifer Cobbe, Chris Norval", "title": "Decision Provenance: Harnessing data flow for accountable systems", "comments": "Published in IEEE Access, vol. 9, pp. 6562-6574, 2019", "journal-ref": "in IEEE Access, vol. 9, pp. 6562-6574, 2019", "doi": "10.1109/ACCESS.2018.2887201", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand is growing for more accountability regarding the technological systems\nthat increasingly occupy our world. However, the complexity of many of these\nsystems - often systems-of-systems - poses accountability challenges. A key\nreason for this is because the details and nature of the information flows that\ninterconnect and drive systems, which often occur across technical and\norganisational boundaries, tend to be invisible or opaque. This paper argues\nthat data provenance methods show much promise as a technical means for\nincreasing the transparency of these interconnected systems. Specifically,\ngiven the concerns regarding ever-increasing levels of automated and\nalgorithmic decision-making, and so-called 'algorithmic systems' in general, we\npropose decision provenance as a concept showing much promise. Decision\nprovenance entails using provenance methods to provide information exposing\ndecision pipelines: chains of inputs to, the nature of, and the flow-on effects\nfrom the decisions and actions taken (at design and run-time) throughout\nsystems. This paper introduces the concept of decision provenance, and takes an\ninterdisciplinary (tech-legal) exploration into its potential for assisting\naccountability in algorithmic systems. We argue that decision provenance can\nhelp facilitate oversight, audit, compliance, risk mitigation, and user\nempowerment, and we also indicate the implementation considerations and areas\nfor research necessary for realising its vision. More generally, we make the\ncase that considerations of data flow, and systems more broadly, are important\nto discussions of accountability, and complement the considerable attention\nalready given to algorithmic specifics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 15:32:39 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 11:12:16 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 09:38:03 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 11:06:10 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Singh", "Jatinder", ""], ["Cobbe", "Jennifer", ""], ["Norval", "Chris", ""]]}, {"id": "1804.05788", "submitter": "Samarth Tripathi", "authors": "Samarth Tripathi, Sarthak Tripathi and Homayoon Beigi", "title": "Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition has become an important field of research in Human\nComputer Interactions as we improve upon the techniques for modelling the\nvarious aspects of behaviour. With the advancement of technology our\nunderstanding of emotions are advancing, there is a growing need for automatic\nemotion recognition systems. One of the directions the research is heading is\nthe use of Neural Networks which are adept at estimating complex functions that\ndepend on a large number and diverse source of input data. In this paper we\nattempt to exploit this effectiveness of Neural networks to enable us to\nperform multimodal Emotion recognition on IEMOCAP dataset using data from\nSpeech, Text, and Motion capture data from face expressions, rotation and hand\nmovements. Prior research has concentrated on Emotion detection from Speech on\nthe IEMOCAP dataset, but our approach is the first that uses the multiple modes\nof data offered by IEMOCAP for a more robust and accurate emotion detection.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 16:58:37 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 08:46:57 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 20:10:26 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Tripathi", "Samarth", ""], ["Tripathi", "Sarthak", ""], ["Beigi", "Homayoon", ""]]}, {"id": "1804.05796", "submitter": "Mathias Strufe", "authors": "Julian Ahrens, Mathias Strufe, Lia Ahrens, Hans D. Schotten", "title": "An AI-driven Malfunction Detection Concept for NFV Instances in 5G", "comments": "Submitted to 23. VDE/ITG Fachtagung Mobilkommunikation, 5G, SON, AI,\n  ML, NFV, SDN, WAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient network management is one of the key challenges of the constantly\ngrowing and increasingly complex wide area networks (WAN). The paradigm shift\ntowards virtualized (NFV) and software defined networks (SDN) in the next\ngeneration of mobile networks (5G), as well as the latest scientific insights\nin the field of Artificial Intelligence (AI) enable the transition from\nmanually managed networks nowadays to fully autonomic and dynamic\nself-organized networks (SON). This helps to meet the KPIs and reduce at the\nsame time operational costs (OPEX). In this paper, an AI driven concept is\npresented for the malfunction detection in NFV applications with the help of\nsemi-supervised learning. For this purpose, a profile of the application under\ntest is created. This profile then is used as a reference to detect abnormal\nbehaviour. For example, if there is a bug in the updated version of the app, it\nis now possible to react autonomously and roll-back the NFV app to a previous\nversion in order to avoid network outages.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:12:31 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ahrens", "Julian", ""], ["Strufe", "Mathias", ""], ["Ahrens", "Lia", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1804.05804", "submitter": "Lucas Janson", "authors": "Lucas Janson, Tommy Hu, Marco Pavone", "title": "Safe Motion Planning in Unknown Environments: Optimality Benchmarks and\n  Tractable Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of planning a safe (i.e., collision-free)\ntrajectory from an initial state to a goal region when the obstacle space is\na-priori unknown and is incrementally revealed online, e.g., through\nline-of-sight perception. Despite its ubiquitous nature, this formulation of\nmotion planning has received relatively little theoretical investigation, as\nopposed to the setup where the environment is assumed known. A fundamental\nchallenge is that, unlike motion planning with known obstacles, it is not even\nclear what an optimal policy to strive for is. Our contribution is threefold.\nFirst, we present a notion of optimality for safe planning in unknown\nenvironments in the spirit of comparative (as opposed to competitive) analysis,\nwith the goal of obtaining a benchmark that is, at least conceptually,\nattainable. Second, by leveraging this theoretical benchmark, we derive a\npseudo-optimal class of policies that can seamlessly incorporate any amount of\nprior or learned information while still guaranteeing the robot never collides.\nFinally, we demonstrate the practicality of our algorithmic approach in\nnumerical experiments using a range of environment types and dynamics,\nincluding a comparison with a state of the art method. A key aspect of our\nframework is that it automatically and implicitly weighs exploration versus\nexploitation in a way that is optimal with respect to the information\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:24:26 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Janson", "Lucas", ""], ["Hu", "Tommy", ""], ["Pavone", "Marco", ""]]}, {"id": "1804.05834", "submitter": "Xiaolin Wang", "authors": "Xiaolin Wang", "title": "CytonRL: an Efficient Reinforcement Learning Open-source Toolkit\n  Implemented in C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an open-source enforcement learning toolkit named CytonRL\n(https://github.com/arthurxlw/cytonRL). The toolkit implements four recent\nadvanced deep Q-learning algorithms from scratch using C++ and NVIDIA's\nGPU-accelerated libraries. The code is simple and elegant, owing to an\nopen-source general-purpose neural network library named CytonLib. Benchmark\nshows that the toolkit achieves competitive performances on the popular Atari\ngame of Breakout.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 23:17:07 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Wang", "Xiaolin", ""]]}, {"id": "1804.05839", "submitter": "Jason (Jinquan) Dai", "authors": "Jason Dai, Yiheng Wang, Xin Qiu, Ding Ding, Yao Zhang, Yanzhang Wang,\n  Xianyan Jia, Cherry Zhang, Yan Wan, Zhichao Li, Jiao Wang, Shengsheng Huang,\n  Zhongyuan Wu, Yang Wang, Yuhao Yang, Bowen She, Dongjie Shi, Qi Lu, Kai\n  Huang, Guoqiong Song", "title": "BigDL: A Distributed Deep Learning Framework for Big Data", "comments": "In ACM Symposium of Cloud Computing conference (SoCC) 2019", "journal-ref": null, "doi": "10.1145/3357223.3362707", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents BigDL (a distributed deep learning framework for Apache\nSpark), which has been used by a variety of users in the industry for building\ndeep learning applications on production big data platforms. It allows deep\nlearning applications to run on the Apache Hadoop/Spark cluster so as to\ndirectly process the production data, and as a part of the end-to-end data\nanalysis pipeline for deployment and management. Unlike existing deep learning\nframeworks, BigDL implements distributed, data parallel training directly on\ntop of the functional compute model (with copy-on-write and coarse-grained\noperations) of Spark. We also share real-world experience and \"war stories\" of\nusers that have adopted BigDL to address their challenges(i.e., how to easily\nbuild end-to-end data analysis and deep learning pipelines for their production\ndata).\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 12:04:03 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 03:21:14 GMT"}, {"version": "v3", "created": "Mon, 25 Jun 2018 02:57:37 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 13:12:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Dai", "Jason", ""], ["Wang", "Yiheng", ""], ["Qiu", "Xin", ""], ["Ding", "Ding", ""], ["Zhang", "Yao", ""], ["Wang", "Yanzhang", ""], ["Jia", "Xianyan", ""], ["Zhang", "Cherry", ""], ["Wan", "Yan", ""], ["Li", "Zhichao", ""], ["Wang", "Jiao", ""], ["Huang", "Shengsheng", ""], ["Wu", "Zhongyuan", ""], ["Wang", "Yang", ""], ["Yang", "Yuhao", ""], ["She", "Bowen", ""], ["Shi", "Dongjie", ""], ["Lu", "Qi", ""], ["Huang", "Kai", ""], ["Song", "Guoqiong", ""]]}, {"id": "1804.05906", "submitter": "Zhen Peng", "authors": "Zhen Peng, Tim Genewein, Felix Leibfried, Daniel A. Braun", "title": "An information-theoretic on-line update principle for perception-action\n  coupling", "comments": "8 pages, 2017 IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by findings of sensorimotor coupling in humans and animals, there\nhas recently been a growing interest in the interaction between action and\nperception in robotic systems [Bogh et al., 2016]. Here we consider perception\nand action as two serial information channels with limited\ninformation-processing capacity. We follow [Genewein et al., 2015] and\nformulate a constrained optimization problem that maximizes utility under\nlimited information-processing capacity in the two channels. As a solution we\nobtain an optimal perceptual channel and an optimal action channel that are\ncoupled such that perceptual information is optimized with respect to\ndownstream processing in the action module. The main novelty of this study is\nthat we propose an online optimization procedure to find bounded-optimal\nperception and action channels in parameterized serial perception-action\nsystems. In particular, we implement the perceptual channel as a multi-layer\nneural network and the action channel as a multinomial distribution. We\nillustrate our method in a NAO robot simulator with a simplified cup lifting\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 19:33:39 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Peng", "Zhen", ""], ["Genewein", "Tim", ""], ["Leibfried", "Felix", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1804.05917", "submitter": "Ramon Fraga Pereira", "authors": "Ramon Fraga Pereira and Felipe Meneguzzi", "title": "Heuristic Approaches for Goal Recognition in Incomplete Domain Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to goal recognition have progressively relaxed the\nassumptions about the amount and correctness of domain knowledge and available\nobservations, yielding accurate and efficient algorithms. These approaches,\nhowever, assume completeness and correctness of the domain theory against which\ntheir algorithms match observations: this is too strong for most real-world\ndomains. In this paper, we develop goal recognition techniques that are capable\nof recognizing goals using \\textit{incomplete} (and possibly incorrect) domain\ntheories. We show the efficiency and accuracy of our approaches empirically\nagainst a large dataset of goal and plan recognition problems with incomplete\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:00:41 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Pereira", "Ramon Fraga", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "1804.05929", "submitter": "Fang Liu", "authors": "Fang Liu, Sinong Wang, Swapna Buccapatnam and Ness Shroff", "title": "UCBoost: A Boosting Approach to Tame Complexity and Optimality for\n  Stochastic Bandits", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the open problem of finding low-complexity\nnear-optimal multi-armed bandit algorithms for sequential decision making\nproblems. Existing bandit algorithms are either sub-optimal and computationally\nsimple (e.g., UCB1) or optimal and computationally complex (e.g., kl-UCB). We\npropose a boosting approach to Upper Confidence Bound based algorithms for\nstochastic bandits, that we call UCBoost. Specifically, we propose two types of\nUCBoost algorithms. We show that UCBoost($D$) enjoys $O(1)$ complexity for each\narm per round as well as regret guarantee that is $1/e$-close to that of the\nkl-UCB algorithm. We propose an approximation-based UCBoost algorithm,\nUCBoost($\\epsilon$), that enjoys a regret guarantee $\\epsilon$-close to that of\nkl-UCB as well as $O(\\log(1/\\epsilon))$ complexity for each arm per round.\nHence, our algorithms provide practitioners a practical way to trade optimality\nwith computational complexity. Finally, we present numerical results which show\nthat UCBoost($\\epsilon$) can achieve the same regret performance as the\nstandard kl-UCB while incurring only $1\\%$ of the computational cost of kl-UCB.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:44:28 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Liu", "Fang", ""], ["Wang", "Sinong", ""], ["Buccapatnam", "Swapna", ""], ["Shroff", "Ness", ""]]}, {"id": "1804.05950", "submitter": "Shuai Ma", "authors": "Shuai Ma, Jia Yuan Yu", "title": "State-Augmentation Transformations for Risk-Sensitive Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of MDP, although the general reward function takes three\narguments-current state, action, and successor state; it is often simplified to\na function of two arguments-current state and action. The former is called a\ntransition-based reward function, whereas the latter is called a state-based\nreward function. When the objective involves the expected cumulative reward\nonly, this simplification works perfectly. However, when the objective is\nrisk-sensitive, this simplification leads to an incorrect value. We present\nstate-augmentation transformations (SATs), which preserve the reward sequences\nas well as the reward distributions and the optimal policy in risk-sensitive\nreinforcement learning. In risk-sensitive scenarios, firstly we prove that, for\nevery MDP with a stochastic transition-based reward function, there exists an\nMDP with a deterministic state-based reward function, such that for any given\n(randomized) policy for the first MDP, there exists a corresponding policy for\nthe second MDP, such that both Markov reward processes share the same reward\nsequence. Secondly we illustrate that two situations require the proposed SATs\nin an inventory control problem. One could be using Q-learning (or other\nlearning methods) on MDPs with transition-based reward functions, and the other\ncould be using methods, which are for the Markov processes with a deterministic\nstate-based reward functions, on the Markov processes with general reward\nfunctions. We show the advantage of the SATs by considering Value-at-Risk as an\nexample, which is a risk measure on the reward distribution instead of the\nmeasures (such as mean and variance) of the distribution. We illustrate the\nerror in the reward distribution estimation from the direct use of Q-learning,\nand show how the SATs enable a variance formula to work on Markov processes\nwith general reward functions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 21:38:40 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 22:40:11 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Ma", "Shuai", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1804.05997", "submitter": "Vernon Asuncion Va", "authors": "Vernon Asuncion and Yan Zhang", "title": "A New Decidable Class of Tuple Generating Dependencies: The\n  Triangularly-Guarded Class", "comments": "Resubmission for Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new class of tuple-generating dependencies\n(TGDs) called triangularly-guarded TGDs, which are TGDs with certain\nrestrictions on the atomic derivation track embedded in the underlying rule\nset. We show that conjunctive query answering under this new class of TGDs is\ndecidable. We further show that this new class strictly contains some other\ndecidable classes such as weak-acyclic, guarded, sticky and shy, which, to the\nbest of our knowledge, provides a unified representation of all these\naforementioned classes.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 01:05:45 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 11:30:51 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Asuncion", "Vernon", ""], ["Zhang", "Yan", ""]]}, {"id": "1804.06020", "submitter": "Qiang Ning", "authors": "Qiang Ning, Hao Wu, Haoruo Peng, Dan Roth", "title": "Improving Temporal Relation Extraction with a Globally Acquired\n  Statistical Resource", "comments": "13 pages, 3 figures, accepted by NAACL'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting temporal relations (before, after, overlapping, etc.) is a key\naspect of understanding events described in natural language. We argue that\nthis task would gain from the availability of a resource that provides prior\nknowledge in the form of the temporal order that events usually follow. This\npaper develops such a resource -- a probabilistic knowledge base acquired in\nthe news domain -- by extracting temporal relations between events from the New\nYork Times (NYT) articles over a 20-year span (1987--2007). We show that\nexisting temporal extraction systems can be improved via this resource. As a\nbyproduct, we also show that interesting statistics can be retrieved from this\nresource, which can potentially benefit other time-aware tasks. The proposed\nsystem and resource are both publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 02:52:30 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Ning", "Qiang", ""], ["Wu", "Hao", ""], ["Peng", "Haoruo", ""], ["Roth", "Dan", ""]]}, {"id": "1804.06078", "submitter": "Haodi Hou", "authors": "Haodi Hou, Jing Huo, Yang Gao", "title": "Cross-Domain Adversarial Auto-Encoder", "comments": "Under review as a conference paper of KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Cross-Domain Adversarial Auto-Encoder (CDAAE)\nto address the problem of cross-domain image inference, generation and\ntransformation. We make the assumption that images from different domains share\nthe same latent code space for content, while having separate latent code space\nfor style. The proposed framework can map cross-domain data to a latent code\nvector consisting of a content part and a style part. The latent code vector is\nmatched with a prior distribution so that we can generate meaningful samples\nfrom any part of the prior space. Consequently, given a sample of one domain,\nour framework can generate various samples of the other domain with the same\ncontent of the input. This makes the proposed framework different from the\ncurrent work of cross-domain transformation. Besides, the proposed framework\ncan be trained with both labeled and unlabeled data, which makes it also\nsuitable for domain adaptation. Experimental results on data sets SVHN, MNIST\nand CASIA show the proposed framework achieved visually appealing performance\nfor image generation task. Besides, we also demonstrate the proposed method\nachieved superior results for domain adaptation. Code of our experiments is\navailable in https://github.com/luckycallor/CDAAE.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:12:58 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Hou", "Haodi", ""], ["Huo", "Jing", ""], ["Gao", "Yang", ""]]}, {"id": "1804.06087", "submitter": "Wei Wang", "authors": "Wei Wang and Sheng Wang and Jinyang Gao and Meihui Zhang and Gang Chen\n  and Teck Khim Ng and Beng Chin Ooi", "title": "Rafiki: Machine Learning as an Analytics Service System", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data analytics is gaining massive momentum in the last few years.\nApplying machine learning models to big data has become an implicit requirement\nor an expectation for most analysis tasks, especially on high-stakes\napplications.Typical applications include sentiment analysis against reviews\nfor analyzing on-line products, image classification in food logging\napplications for monitoring user's daily intake and stock movement prediction.\nExtending traditional database systems to support the above analysis is\nintriguing but challenging. First, it is almost impossible to implement all\nmachine learning models in the database engines. Second, expertise knowledge is\nrequired to optimize the training and inference procedures in terms of\nefficiency and effectiveness, which imposes heavy burden on the system users.\nIn this paper, we develop and present a system, called Rafiki, to provide the\ntraining and inference service of machine learning models, and facilitate\ncomplex analytics on top of cloud platforms. Rafiki provides distributed\nhyper-parameter tuning for the training service, and online ensemble modeling\nfor the inference service which trades off between latency and accuracy.\nExperimental results confirm the efficiency, effectiveness, scalability and\nusability of Rafiki.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:54:55 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Wang", "Wei", ""], ["Wang", "Sheng", ""], ["Gao", "Jinyang", ""], ["Zhang", "Meihui", ""], ["Chen", "Gang", ""], ["Ng", "Teck Khim", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "1804.06088", "submitter": "Shengcai Liu", "authors": "Shengcai Liu, Ke Tang, Xin Yao", "title": "Automatic Construction of Parallel Portfolios via Explicit Instance\n  Grouping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneously utilizing several complementary solvers is a simple yet\neffective strategy for solving computationally hard problems. However, manually\nbuilding such solver portfolios typically requires considerable domain\nknowledge and plenty of human effort. As an alternative, automatic construction\nof parallel portfolios (ACPP) aims at automatically building effective parallel\nportfolios based on a given problem instance set and a given rich design space.\nOne promising way to solve the ACPP problem is to explicitly group the\ninstances into different subsets and promote a component solver to handle each\nof them.This paper investigates solving ACPP from this perspective, and\nespecially studies how to obtain a good instance grouping.The experimental\nresults showed that the parallel portfolios constructed by the proposed method\ncould achieve consistently superior performances to the ones constructed by the\nstate-of-the-art ACPP methods,and could even rival sophisticated hand-designed\nparallel solvers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:56:15 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Liu", "Shengcai", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1804.06111", "submitter": "Biao Xiang", "authors": "Biao Xiang, Ziqi Liu, Jun Zhou, Xiaolong Li", "title": "Feature Propagation on Graph: A New Perspective to Graph Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study feature propagation on graph, an inference process involved in graph\nrepresentation learning tasks. It's to spread the features over the whole graph\nto the $t$-th orders, thus to expand the end's features. The process has been\nsuccessfully adopted in graph embedding or graph neural networks, however few\nworks studied the convergence of feature propagation. Without convergence\nguarantees, it may lead to unexpected numerical overflows and task failures. In\nthis paper, we first define the concept of feature propagation on graph\nformally, and then study its convergence conditions to equilibrium states. We\nfurther link feature propagation to several established approaches such as\nnode2vec and structure2vec. In the end of this paper, we extend existing\napproaches from represent nodes to edges (edge2vec) and demonstrate its\napplications on fraud transaction detection in real world scenario. Experiments\nshow that it is quite competitive.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 08:54:19 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Xiang", "Biao", ""], ["Liu", "Ziqi", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1804.06188", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang, Steven Schockaert", "title": "VC-Dimension Based Generalization Bounds for Relational Learning", "comments": "Longer version of paper accepted at ECML PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of relational learning, the available data can be seen\nas a sample from a larger relational structure (e.g. we may be given a small\nfragment from some social network). In this paper we are particularly concerned\nwith scenarios in which we can assume that (i) the domain elements appearing in\nthe given sample have been uniformly sampled without replacement from the\n(unknown) full domain and (ii) the sample is complete for these domain elements\n(i.e. it is the full substructure induced by these elements). Within this\nsetting, we study bounds on the error of sufficient statistics of relational\nmodels that are estimated on the available data. As our main result, we prove a\nbound based on a variant of the Vapnik-Chervonenkis dimension which is suitable\nfor relational data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:09:02 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 13:14:25 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""], ["Schockaert", "Steven", ""]]}, {"id": "1804.06201", "submitter": "Herbert Hu", "authors": "Guangneng Hu, Yu Zhang, Qiang Yang", "title": "LCMR: Local and Centralized Memories for Collaborative Filtering with\n  Unstructured Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is the key technique for recommender systems.\nPure CF approaches exploit the user-item interaction data (e.g., clicks, likes,\nand views) only and suffer from the sparsity issue. Items are usually\nassociated with content information such as unstructured text (e.g., abstracts\nof articles and reviews of products). CF can be extended to leverage text. In\nthis paper, we develop a unified neural framework to exploit interaction data\nand content information seamlessly. The proposed framework, called LCMR, is\nbased on memory networks and consists of local and centralized memories for\nexploiting content information and interaction data, respectively. By modeling\ncontent information as local memories, LCMR attentively learns what to exploit\nwith the guidance of user-item interaction. On real-world datasets, LCMR shows\nbetter performance by comparing with various baselines in terms of the hit\nratio and NDCG metrics. We further conduct analyses to understand how local and\ncentralized memories work for the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:32:23 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:23:00 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guangneng", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.06264", "submitter": "Yingjun Ye", "authors": "Yingjun Ye, Xiaohui Zhang, Jian Sun", "title": "Automated vehicle's behavior decision making using deep reinforcement\n  learning and high-fidelity simulation environment", "comments": "22 pages, 13 figures, CICTP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated vehicles are deemed to be the key element for the intelligent\ntransportation system in the future. Many studies have been made to improve the\nAutomated vehicles' ability of environment recognition and vehicle control,\nwhile the attention paid to decision making is not enough though the decision\nalgorithms so far are very preliminary. Therefore, a framework of the\ndecision-making training and learning is put forward in this paper. It consists\nof two parts: the deep reinforcement learning training program and the\nhigh-fidelity virtual simulation environment. Then the basic microscopic\nbehavior, car-following, is trained within this framework. In addition,\ntheoretical analysis and experiments were conducted on setting reward function\nfor accelerating training using deep reinforcement learning. The results show\nthat on the premise of driving comfort, the efficiency of the trained Automated\nvehicle increases 7.9% compared to the classical traffic model, intelligent\ndriver model. Later on, on a more complex three-lane section, we trained the\nintegrated model combines both car-following and lane-changing behavior, the\naverage speed further grows 2.4%. It indicates that our framework is effective\nfor Automated vehicle's decision-making learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:58:04 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Ye", "Yingjun", ""], ["Zhang", "Xiaohui", ""], ["Sun", "Jian", ""]]}, {"id": "1804.06318", "submitter": "Misha Denil", "authors": "Brandon Amos, Laurent Dinh, Serkan Cabi, Thomas Roth\\\"orl, Sergio\n  G\\'omez Colmenarejo, Alistair Muldal, Tom Erez, Yuval Tassa, Nando de\n  Freitas, Misha Denil", "title": "Learning Awareness Models", "comments": "Accepted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of an agent with a fixed body interacting with an\nunknown and uncertain external world. We show that models trained to predict\nproprioceptive information about the agent's body come to represent objects in\nthe external world. In spite of being trained with only internally available\nsignals, these dynamic body models come to represent external objects through\nthe necessity of predicting their effects on the agent's own body. That is, the\nmodel learns holistic persistent representations of objects in the world, even\nthough the only training signals are body signals. Our dynamics model is able\nto successfully predict distributions over 132 sensor readings over 100 steps\ninto the future and we demonstrate that even when the body is no longer in\ncontact with an object, the latent variables of the dynamics model continue to\nrepresent its shape. We show that active data collection by maximizing the\nentropy of predictions about the body---touch sensors, proprioception and\nvestibular information---leads to learning of dynamic models that show superior\nperformance when used for control. We also collect data from a real robotic\nhand and show that the same models can be used to answer questions about\nproperties of objects in the real world. Videos with qualitative results of our\nmodels are available at https://goo.gl/mZuqAV.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:28:01 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Amos", "Brandon", ""], ["Dinh", "Laurent", ""], ["Cabi", "Serkan", ""], ["Roth\u00f6rl", "Thomas", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Muldal", "Alistair", ""], ["Erez", "Tom", ""], ["Tassa", "Yuval", ""], ["de Freitas", "Nando", ""], ["Denil", "Misha", ""]]}, {"id": "1804.06331", "submitter": "Hong Thuy Nguyen", "authors": "Thuy Hong Nguyen", "title": "Simplifying the minimax disparity model for determining OWA weights in\n  large-scale problems", "comments": "Submitted to International Conference on Optimization and Decision\n  Science - ODS2018;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of multicriteria decision making, the ordered weighted\naveraging (OWA) functions play a crucial role in aggregating multiple criteria\nevaluations into an overall assessment supporting the decision makers' choice.\nDetermining OWA weights, therefore, is an essential part of this process.\nAvailable methods for determining OWA weights, however, often require heavy\ncomputational loads in real-life large-scale optimization problems. In this\npaper, we propose a new approach to simplify the well-known minimax disparity\nmodel for determining OWA weights. For this purpose, we use to the binomial\ndecomposition framework in which natural constraints can be imposed on the\nlevel of complexity of the weight distribution. The original problem of\ndetermining OWA weights is thereby transformed into a smaller scale\noptimization problem, formulated in terms of the coefficients in the binomial\ndecomposition. Our preliminary results show that a small set of these\ncoefficients can encode for an appropriate full-dimensional set of OWA weights.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:47:37 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Nguyen", "Thuy Hong", ""]]}, {"id": "1804.06424", "submitter": "Glen Berseth", "authors": "Glen Berseth, Xue Bin Peng, Michiel van de Panne", "title": "Terrain RL Simulator", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide $89$ challenging simulation environments that range in difficulty.\nThe difficulty of solving a task is linked not only to the number of dimensions\nin the action space but also to the size and shape of the distribution of\nconfigurations the agent experiences. Therefore, we are releasing a number of\nsimulation environments that include randomly generated terrain. The library\nalso provides simple mechanisms to create new environments with different agent\nmorphologies and the option to modify the distribution of generated terrain. We\nbelieve using these and other more complex simulations will help push the field\ncloser to creating human-level intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 18:26:00 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Berseth", "Glen", ""], ["Peng", "Xue Bin", ""], ["van de Panne", "Michiel", ""]]}, {"id": "1804.06439", "submitter": "Nicolas Fiorini", "authors": "Nicolas Fiorini, Zhiyong Lu", "title": "Personalized neural language models for real-world query auto completion", "comments": "To appear in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query auto completion (QAC) systems are a standard part of search engines in\nindustry, helping users formulate their query. Such systems update their\nsuggestions after the user types each character, predicting the user's intent\nusing various signals - one of the most common being popularity. Recently, deep\nlearning approaches have been proposed for the QAC task, to specifically\naddress the main limitation of previous popularity-based methods: the inability\nto predict unseen queries. In this work we improve previous methods based on\nneural language modeling, with the goal of building an end-to-end system. We\nparticularly focus on using real-world data by integrating user information for\npersonalized suggestions when possible. We also make use of time information\nand study how to increase diversity in the suggestions while studying the\nimpact on scalability. Our empirical results demonstrate a marked improvement\non two separate datasets over previous best methods in both accuracy and\nscalability, making a step towards neural query auto-completion in production\nsearch engines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:11:14 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 13:58:40 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 16:16:25 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Fiorini", "Nicolas", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1804.06451", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Reward Reinforced Summarization with Saliency and Entailment", "comments": "NAACL 2018 (9 pages; added human evaluation and more analysis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization is the task of compressing and rewriting a\nlong document into a short summary while maintaining saliency, directed logical\nentailment, and non-redundancy. In this work, we address these three important\naspects of a good summary via a reinforcement learning approach with two novel\nreward functions: ROUGESal and Entail, on top of a coverage-based baseline. The\nROUGESal reward modifies the ROUGE metric by up-weighting the salient\nphrases/words detected via a keyphrase classifier. The Entail reward gives high\n(length-normalized) scores to logically-entailed summaries using an entailment\nclassifier. Further, we show superior performance improvement when these\nrewards are combined with traditional metric (ROUGE) based rewards, via our\nnovel and effective multi-reward approach of optimizing multiple rewards\nsimultaneously in alternate mini-batches. Our method achieves the new\nstate-of-the-art results (including human evaluation) on the CNN/Daily Mail\ndataset as well as strong improvements in a test-only transfer setup on\nDUC-2002.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:39:26 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 14:45:28 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06458", "submitter": "Martin Hirzel", "authors": "Guillaume Baudart, Martin Hirzel, Louis Mandel", "title": "Deep Probabilistic Programming Languages: A Qualitative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep probabilistic programming languages try to combine the advantages of\ndeep learning with those of probabilistic programming languages. If successful,\nthis would be a big step forward in machine learning and programming languages.\nUnfortunately, as of now, this new crop of languages is hard to use and\nunderstand. This paper addresses this problem directly by explaining deep\nprobabilistic programming languages and indirectly by characterizing their\ncurrent strengths and weaknesses.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:03:25 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Baudart", "Guillaume", ""], ["Hirzel", "Martin", ""], ["Mandel", "Louis", ""]]}, {"id": "1804.06459", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Junhyuk Oh, Satinder Singh", "title": "On Learning Intrinsic Rewards for Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequential decision making tasks, it is challenging to design reward\nfunctions that help an RL agent efficiently learn behavior that is considered\ngood by the agent designer. A number of different formulations of the\nreward-design problem, or close variants thereof, have been proposed in the\nliterature. In this paper we build on the Optimal Rewards Framework of Singh\net.al. that defines the optimal intrinsic reward function as one that when used\nby an RL agent achieves behavior that optimizes the task-specifying or\nextrinsic reward function. Previous work in this framework has shown how good\nintrinsic reward functions can be learned for lookahead search based planning\nagents. Whether it is possible to learn intrinsic reward functions for learning\nagents remains an open problem. In this paper we derive a novel algorithm for\nlearning intrinsic rewards for policy-gradient based learning agents. We\ncompare the performance of an augmented agent that uses our algorithm to\nprovide additive intrinsic rewards to an A2C-based policy learner (for Atari\ngames) and a PPO-based policy learner (for Mujoco domains) with a baseline\nagent that uses the same policy learners but with only extrinsic rewards. Our\nresults show improved performance on most but not all of the domains.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:04:09 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 17:50:24 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Zheng", "Zeyu", ""], ["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""]]}, {"id": "1804.06461", "submitter": "Gang Chen", "authors": "Gang Chen and Yiming Peng and Mengjie Zhang", "title": "An Adaptive Clipping Approach for Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recently proximal policy optimization (PPO) algorithms have been\nproposed as first-order optimization methods for effective reinforcement\nlearning. While PPO is inspired by the same learning theory that justifies\ntrust region policy optimization (TRPO), PPO substantially simplifies algorithm\ndesign and improves data efficiency by performing multiple epochs of\n\\emph{clipped policy optimization} from sampled data. Although clipping in PPO\nstands for an important new mechanism for efficient and reliable policy update,\nit may fail to adaptively improve learning performance in accordance with the\nimportance of each sampled state. To address this issue, a new surrogate\nlearning objective featuring an adaptive clipping mechanism is proposed in this\npaper, enabling us to develop a new algorithm, known as PPO-$\\lambda$.\nPPO-$\\lambda$ optimizes policies repeatedly based on a theoretical target for\nadaptive policy improvement. Meanwhile, destructively large policy update can\nbe effectively prevented through both clipping and adaptive control of a\nhyperparameter $\\lambda$ in PPO-$\\lambda$, ensuring high learning reliability.\nPPO-$\\lambda$ enjoys the same simple and efficient design as PPO. Empirically\non several Atari game playing tasks and benchmark control tasks, PPO-$\\lambda$\nalso achieved clearly better performance than PPO.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:24:27 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Chen", "Gang", ""], ["Peng", "Yiming", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1804.06620", "submitter": "Giuseppe Casalicchio", "authors": "Giuseppe Casalicchio, Christoph Molnar, Bernd Bischl", "title": "Visualizing the Feature Importance for Black Box Models", "comments": "To Appear in Machine Learning and Knowledge Discovery in Databases:\n  European Conference, ECML PKDD 2018, Dublin, Ireland, September 10 to 14,\n  2018, Proceedings, Part I", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2018. Lecture Notes in Computer Science, vol 11051", "doi": "10.1007/978-3-030-10925-7_40", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a large amount of model-agnostic methods to improve the\ntransparency, trustability and interpretability of machine learning models have\nbeen developed. We introduce local feature importance as a local version of a\nrecent model-agnostic global feature importance method. Based on local feature\nimportance, we propose two visual tools: partial importance (PI) and individual\nconditional importance (ICI) plots which visualize how changes in a feature\naffect the model performance on average, as well as for individual\nobservations. Our proposed methods are related to partial dependence (PD) and\nindividual conditional expectation (ICE) plots, but visualize the expected\n(conditional) feature importance instead of the expected (conditional)\nprediction. Furthermore, we show that averaging ICI curves across observations\nyields a PI curve, and integrating the PI curve with respect to the\ndistribution of the considered feature results in the global feature\nimportance. Another contribution of our paper is the Shapley feature\nimportance, which fairly distributes the overall performance of a model among\nthe features according to the marginal contributions and which can be used to\ncompare the feature importance across different models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 09:35:38 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 14:30:25 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 15:54:54 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Casalicchio", "Giuseppe", ""], ["Molnar", "Christoph", ""], ["Bischl", "Bernd", ""]]}, {"id": "1804.06647", "submitter": "Sven Linker", "authors": "Maryam Kamali, Sven Linker, Michael Fisher", "title": "Modular Verification of Vehicle Platooning with Respect to Decisions,\n  Space and Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of autonomous systems into safety-critical areas has increased the\ndemand for their formal verification, not only due to stronger certification\nrequirements but also to public uncertainty over these new technologies.\nHowever, the complex nature of such systems, for example, the intricate\ncombination of discrete and continuous aspects, ensures that whole system\nverification is often infeasible. This motivates the need for novel analysis\napproaches that modularise the problem, allowing us to restrict our analysis to\none particular aspect of the system while abstracting away from others. For\ninstance, while verifying the real-time properties of an autonomous system we\nmight hide the details of the internal decision-making components. In this\npaper we describe verification of a range of properties across distinct\ndimesnions on a practical hybrid agent architecture. This allows us to verify\nthe autonomous decision-making, real-time aspects, and spatial aspects of an\nautonomous vehicle platooning system. This modular approach also illustrates\nhow both algorithmic and deductive verification techniques can be applied for\nthe analysis of different system subcomponents.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 10:50:57 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Kamali", "Maryam", ""], ["Linker", "Sven", ""], ["Fisher", "Michael", ""]]}, {"id": "1804.06748", "submitter": "Stefan L\\\"udtke", "authors": "Stefan L\\\"udtke, Max Schr\\\"oder, Frank Kr\\\"uger, Sebastian Bader,\n  Thomas Kirste", "title": "State-Space Abstractions for Probabilistic Inference: A Systematic\n  Review", "comments": null, "journal-ref": null, "doi": "10.1613/jair.1.11261", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks such as social network analysis, human behavior recognition, or\nmodeling biochemical reactions, can be solved elegantly by using the\nprobabilistic inference framework. However, standard probabilistic inference\nalgorithms work at a propositional level, and thus cannot capture the\nsymmetries and redundancies that are present in these tasks. Algorithms that\nexploit those symmetries have been devised in different research fields, for\nexample by the lifted inference-, multiple object tracking-, and modeling and\nsimulation-communities. The common idea, that we call state space abstraction,\nis to perform inference over compact representations of sets of symmetric\nstates. Although they are concerned with a similar topic, the relationship\nbetween these approaches has not been investigated systematically. This survey\nprovides the following contributions. We perform a systematic literature review\nto outline the state of the art in probabilistic inference methods exploiting\nsymmetries. From an initial set of more than 4,000 papers, we identify 116\nrelevant papers. Furthermore, we provide new high-level categories that\nclassify the approaches, based on common properties of the approaches. The\nresearch areas underlying each of the categories are introduced concisely.\nResearchers from different fields that are confronted with a state space\nexplosion problem in a probabilistic system can use this classification to\nidentify possible solutions. Finally, based on this conceptualization, we\nidentify potentials for future research, as some relevant application domains\nare not addressed by current approaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:10:10 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 07:18:59 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 08:51:35 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["L\u00fcdtke", "Stefan", ""], ["Schr\u00f6der", "Max", ""], ["Kr\u00fcger", "Frank", ""], ["Bader", "Sebastian", ""], ["Kirste", "Thomas", ""]]}, {"id": "1804.06760", "submitter": "Cumhur Erkan Tuncali", "authors": "Cumhur Erkan Tuncali, Georgios Fainekos, Hisahiro Ito, James Kapinski", "title": "Simulation-based Adversarial Test Generation for Autonomous Vehicles\n  with Machine Learning Components", "comments": "This is a modified version of a paper presented at the 29th IEEE\n  Intelligent Vehicles Symposium (IV 2018). Source code is available at\n  https://cpslab.assembla.com/spaces/sim-atav", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many organizations are developing autonomous driving systems, which are\nexpected to be deployed at a large scale in the near future. Despite this,\nthere is a lack of agreement on appropriate methods to test, debug, and certify\nthe performance of these systems. One of the main challenges is that many\nautonomous driving systems have machine learning components, such as deep\nneural networks, for which formal properties are difficult to characterize. We\npresent a testing framework that is compatible with test case generation and\nautomatic falsification methods, which are used to evaluate cyber-physical\nsystems. We demonstrate how the framework can be used to evaluate closed-loop\nproperties of an autonomous driving system model that includes the ML\ncomponents, all within a virtual environment. We demonstrate how to use test\ncase generation methods, such as covering arrays, as well as requirement\nfalsification methods to automatically identify problematic test scenarios. The\nresulting framework can be used to increase the reliability of autonomous\ndriving systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:32:35 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 20:01:05 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 20:36:46 GMT"}, {"version": "v4", "created": "Mon, 7 Jan 2019 20:58:40 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Tuncali", "Cumhur Erkan", ""], ["Fainekos", "Georgios", ""], ["Ito", "Hisahiro", ""], ["Kapinski", "James", ""]]}, {"id": "1804.06763", "submitter": "Sanjay Modgil", "authors": "Sanjay Modgil and Henry Prakken", "title": "A General Account of Argumentation with Preferences", "comments": "This paper contains correction to errors in the original paper which\n  appears in the journal Artificial Intelligence", "journal-ref": "S. Modgil, H. Prakken. A General Account of Argumentation and\n  Preferences. In: Artificial Intelligence (AIJ) . 195(0), 361 - 397, 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on the recent ASPIC+ formalism, to develop a general\nframework for argumentation with preferences. We motivate a revised definition\nof conflict free sets of arguments, adapt ASPIC+ to accommodate a broader range\nof instantiating logics, and show that under some assumptions, the resulting\nframework satisfies key properties and rationality postulates. We then show\nthat the generalised framework accommodates Tarskian logic instantiations\nextended with preferences, and then study instantiations of the framework by\nclassical logic approaches to argumentation. We conclude by arguing that\nASPIC+'s modelling of defeasible inference rules further testifies to the\ngenerality of the framework, and then examine and counter recent critiques of\nDung's framework and its extensions to accommodate preferences.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:33:44 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Modgil", "Sanjay", ""], ["Prakken", "Henry", ""]]}, {"id": "1804.06764", "submitter": "Ioannis Christou Ph.D.", "authors": "Ioannis T. Christou, Emmanouil Amolochitis, Zheng-Hua Tan", "title": "A Parallel/Distributed Algorithmic Framework for Mining All Quantitative\n  Association Rules", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present QARMA, an efficient novel parallel algorithm for mining all\nQuantitative Association Rules in large multidimensional datasets where items\nare required to have at least a single common attribute to be specified in the\nrules single consequent item. Given a minimum support level and a set of\nthreshold criteria of interestingness measures such as confidence, conviction\netc. our algorithm guarantees the generation of all non-dominated Quantitative\nAssociation Rules that meet the minimum support and interestingness\nrequirements. Such rules can be of great importance to marketing departments\nseeking to optimize targeted campaigns, or general market segmentation. They\ncan also be of value in medical applications, financial as well as predictive\nmaintenance domains. We provide computational results showing the scalability\nof our algorithm, and its capability to produce all rules to be found in large\nscale synthetic and real world datasets such as Movie Lens, within a few\nseconds or minutes of computational time on commodity hardware.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:34:08 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Christou", "Ioannis T.", ""], ["Amolochitis", "Emmanouil", ""], ["Tan", "Zheng-Hua", ""]]}, {"id": "1804.06769", "submitter": "Herbert Hu", "authors": "Guangneng Hu, Yu Zhang, Qiang Yang", "title": "CoNet: Collaborative Cross Networks for Cross-Domain Recommendation", "comments": "Deep transfer learning for recommender systems", "journal-ref": "CIKM 2018", "doi": "10.1145/3269206.3271684", "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cross-domain recommendation technique is an effective way of alleviating\nthe data sparse issue in recommender systems by leveraging the knowledge from\nrelevant domains. Transfer learning is a class of algorithms underlying these\ntechniques. In this paper, we propose a novel transfer learning approach for\ncross-domain recommendation by using neural networks as the base model. In\ncontrast to the matrix factorization based cross-domain techniques, our method\nis deep transfer learning, which can learn complex user-item interaction\nrelationships. We assume that hidden layers in two base networks are connected\nby cross mappings, leading to the collaborative cross networks (CoNet). CoNet\nenables dual knowledge transfer across domains by introducing cross connections\nfrom one base network to another and vice versa. CoNet is achieved in\nmulti-layer feedforward networks by adding dual connections and joint loss\nfunctions, which can be trained efficiently by back-propagation. The proposed\nmodel is thoroughly evaluated on two large real-world datasets. It outperforms\nbaselines by relative improvements of 7.84\\% in NDCG. We demonstrate the\nnecessity of adaptively selecting representations to transfer. Our model can\nreduce tens of thousands training examples comparing with non-transfer methods\nand still has the competitive performance with them.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:48:21 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 17:12:11 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 14:00:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hu", "Guangneng", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.06774", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Tetsuya Ogata and Angelo Cangelosi", "title": "Encoding Longer-term Contextual Multi-modal Information in a Predictive\n  Coding Model", "comments": "Submitted to ICDL/EpiRob 2018 (8th Joint IEEE International\n  Conference on Development and Learning and on Epigenetic Robotics )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies suggest that within the hierarchical architecture, the topological\nhigher level possibly represents a conscious category of the current sensory\nevents with slower changing activities. They attempt to predict the activities\non the lower level by relaying the predicted information. On the other hand,\nthe incoming sensory information corrects such prediction of the events on the\nhigher level by the novel or surprising signal. We propose a predictive\nhierarchical artificial neural network model that examines this hypothesis on\nneurorobotic platforms, based on the AFA-PredNet model. In this neural network\nmodel, there are different temporal scales of predictions exist on different\nlevels of the hierarchical predictive coding, which are defined in the temporal\nparameters in the neurons. Also, both the fast and the slow-changing neural\nactivities are modulated by the active motor activities. A neurorobotic\nexperiment based on the architecture was also conducted based on the data\ncollected from the VRep simulator.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:47:33 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Zhong", "Junpei", ""], ["Ogata", "Tetsuya", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1804.06819", "submitter": "Sao Mai Nguyen", "authors": "Sao Mai Nguyen and Pierre-Yves Oudeyer", "title": "Active choice of teachers, learning strategies and goals for a socially\n  guided intrinsic motivation learner", "comments": null, "journal-ref": "Paladyn, Springer Verlag, 2012, 3 (3), pp.136-146", "doi": "10.2478/s13230-013-0110-z", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an active learning architecture that allows a robot to actively\nlearn which data collection strategy is most efficient for acquiring motor\nskills to achieve multiple outcomes, and generalise over its experience to\nachieve new outcomes. The robot explores its environment both via interactive\nlearning and goal-babbling. It learns at the same time when, who and what to\nactively imitate from several available teachers, and learns when not to use\nsocial guidance but use active goal-oriented self-exploration. This is\nformalised in the framework of life-long strategic learning. The proposed\narchitecture, called Socially Guided Intrinsic Motivation with Active Choice of\nTeacher and Strategy (SGIM-ACTS), relies on hierarchical active decisions of\nwhat and how to learn driven by empirical evaluation of learning progress for\neach learning strategy. We illustrate with an experiment where a simulated\nrobot learns to control its arm for realising two kinds of different outcomes.\nIt has to choose actively and hierarchically at each learning episode: 1) what\nto learn: which outcome is most interesting to select as a goal to focus on for\ngoal-directed exploration; 2) how to learn: which data collection strategy to\nuse among self-exploration, mimicry and emulation; 3) once he has decided when\nand what to imitate by choosing mimicry or emulation, then he has to choose who\nto imitate, from a set of different teachers. We show that SGIM-ACTS learns\nsignificantly more efficiently than using single learning strategies, and\ncoherently selects the best strategy with respect to the chosen outcome, taking\nadvantage of the available teachers (with different levels of skills).\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 17:11:29 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nguyen", "Sao Mai", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1804.06870", "submitter": "Hao Tan", "authors": "Hao Tan, Mohit Bansal", "title": "Object Ordering with Bidirectional Matchings for Visual Reasoning", "comments": "NAACL 2018 (8 pages; added pointer-ordering examples)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual reasoning with compositional natural language instructions, e.g.,\nbased on the newly-released Cornell Natural Language Visual Reasoning (NLVR)\ndataset, is a challenging task, where the model needs to have the ability to\ncreate an accurate mapping between the diverse phrases and the several objects\nplaced in complex arrangements in the image. Further, this mapping needs to be\nprocessed to answer the question in the statement given the ordering and\nrelationship of the objects across three similar images. In this paper, we\npropose a novel end-to-end neural model for the NLVR task, where we first use\njoint bidirectional attention to build a two-way conditioning between the\nvisual information and the language phrases. Next, we use an RL-based pointer\nnetwork to sort and process the varying number of unordered objects (so as to\nmatch the order of the statement phrases) in each of the three images and then\npool over the three decisions. Our model achieves strong improvements (of 4-6%\nabsolute) over the state-of-the-art on both the structured representation and\nraw image versions of the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:39:17 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 16:56:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06876", "submitter": "Mark Yatskar", "authors": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang", "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods", "comments": "NAACL '18 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new benchmark, WinoBias, for coreference resolution focused on\ngender bias. Our corpus contains Winograd-schema style sentences with entities\ncorresponding to people referred by their occupation (e.g. the nurse, the\ndoctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a\nneural coreference system all link gendered pronouns to pro-stereotypical\nentities with higher accuracy than anti-stereotypical entities, by an average\ndifference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation\napproach that, in combination with existing word-embedding debiasing\ntechniques, removes the bias demonstrated by these systems in WinoBias without\nsignificantly affecting their performance on existing coreference benchmark\ndatasets. Our dataset and code are available at http://winobias.org.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:51:00 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Zhao", "Jieyu", ""], ["Wang", "Tianlu", ""], ["Yatskar", "Mark", ""], ["Ordonez", "Vicente", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1804.06894", "submitter": "Carsten Lutz", "authors": "Andre Hernich, Carsten Lutz, Fabio Papacchini, Frank Wolter", "title": "Dichotomies in Ontology-Mediated Querying with the Guarded Fragment", "comments": null, "journal-ref": null, "doi": "10.1145/3034786.3056108", "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of ontology-mediated querying when ontologies are\nformulated in the guarded fragment of first-order logic (GF). Our general aim\nis to classify the data complexity on the level of ontologies where query\nevaluation w.r.t. an ontology O is considered to be in PTime if all (unions of\nconjunctive) queries can be evaluated in PTime w.r.t. O and coNP-hard if at\nleast one query is coNP-hard w.r.t. O. We identify several large and relevant\nfragments of GF that enjoy a dichotomy between PTime and coNP, some of them\nadditionally admitting a form of counting. In fact, almost all ontologies in\nthe BioPortal repository fall into these fragments or can easily be rewritten\nto do so. We then establish a variation of Ladner's Theorem on the existence of\nNP-intermediate problems and use this result to show that for other fragments,\nthere is provably no such dichotomy. Again for other fragments (such as full\nGF), establishing a dichotomy implies the Feder-Vardi conjecture on the\ncomplexity of constraint satisfaction problems. We also link these results to\nDatalog-rewritability and study the decidability of whether a given ontology\nenjoys PTime query evaluation, presenting both positive and negative results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 19:49:15 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hernich", "Andre", ""], ["Lutz", "Carsten", ""], ["Papacchini", "Fabio", ""], ["Wolter", "Frank", ""]]}, {"id": "1804.06896", "submitter": "Lu Duan", "authors": "Lu Duan, Haoyuan Hu, Yu Qian, Yu Gong, Xiaodong Zhang, Yinghui Xu,\n  Jiangwen Wei", "title": "A Multi-task Selected Learning Approach for Solving 3D Flexible Bin\n  Packing Problem", "comments": "8 pages, 34figures. arXiv admin note: text overlap with\n  arXiv:1708.05930", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 3D flexible bin packing problem (3D-FBPP) arises from the process of\nwarehouse packing in e-commerce. An online customer's order usually contains\nseveral items and needs to be packed as a whole before shipping. In particular,\n5% of tens of millions of packages are using plastic wrapping as outer\npackaging every day, which brings pressure on the plastic surface minimization\nto save traditional logistics costs. Because of the huge practical\nsignificance, we focus on the issue of packing cuboid-shaped items orthogonally\ninto a least-surface-area bin. The existing heuristic methods for classic 3D\nbin packing don't work well for this particular NP-hard problem and designing a\ngood problem-specific heuristic is non-trivial. In this paper, rather than\ndesigning heuristics, we propose a novel multi-task framework based on Selected\nLearning to learn a heuristic-like policy that generates the sequence and\norientations of items to be packed simultaneously. Through comprehensive\nexperiments on a large scale real-world transaction order dataset and online AB\ntests, we show: 1) our selected learning method trades off the imbalance and\ncorrelation among the tasks and significantly outperforms the single task\nPointer Network and the multi-task network without selected learning; 2) our\nmethod obtains an average 5.47% cost reduction than the well-designed greedy\nalgorithm which is previously used in our online production system.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:00:42 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 02:52:27 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 06:20:39 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Duan", "Lu", ""], ["Hu", "Haoyuan", ""], ["Qian", "Yu", ""], ["Gong", "Yu", ""], ["Zhang", "Xiaodong", ""], ["Xu", "Yinghui", ""], ["Wei", "Jiangwen", ""]]}, {"id": "1804.06898", "submitter": "Youmna Farag", "authors": "Youmna Farag, Helen Yannakoudakis, Ted Briscoe", "title": "Neural Automated Essay Scoring and Coherence Modeling for Adversarially\n  Crafted Input", "comments": "9, NAACL 2018", "journal-ref": "The 16th Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that current state-of-the-art approaches to Automated Essay\nScoring (AES) are not well-suited to capturing adversarially crafted input of\ngrammatical but incoherent sequences of sentences. We develop a neural model of\nlocal coherence that can effectively learn connectedness features between\nsentences, and propose a framework for integrating and jointly training the\nlocal coherence model with a state-of-the-art AES model. We evaluate our\napproach against a number of baselines and experimentally demonstrate its\neffectiveness on both the AES task and the task of flagging adversarial input,\nfurther contributing to the development of an approach that strengthens the\nvalidity of neural essay scoring models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 19:55:18 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 00:27:43 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 17:28:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Farag", "Youmna", ""], ["Yannakoudakis", "Helen", ""], ["Briscoe", "Ted", ""]]}, {"id": "1804.06907", "submitter": "Carsten Lutz", "authors": "Peter Hansen and Carsten Lutz", "title": "Computing FO-Rewritings in EL in Practice: from Atomic to Conjunctive\n  Queries", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-68288-4_21", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prominent approach to implementing ontology-mediated queries (OMQs) is to\nrewrite into a first-order query, which is then executed using a conventional\nSQL database system. We consider the case where the ontology is formulated in\nthe description logic EL and the actual query is a conjunctive query and show\nthat rewritings of such OMQs can be efficiently computed in practice, in a\nsound and complete way. Our approach combines a reduction with a decomposed\nbackwards chaining algorithm for OMQs that are based on the simpler atomic\nqueries, also illuminating the relationship between first-order rewritings of\nOMQs based on conjunctive and on atomic queries. Experiments with real-world\nontologies show promising results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 20:27:45 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hansen", "Peter", ""], ["Lutz", "Carsten", ""]]}, {"id": "1804.06943", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Dayvid V. R. Oliveira, George D. C. Cavalcanti, Thyago N. Porpino,\n  Rafael M. O. Cruz and Robert Sabourin", "title": "K-Nearest Oracles Borderline Dynamic Classifier Ensemble Selection", "comments": "Paper accepted for publication on IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489737", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Ensemble Selection (DES) techniques aim to select locally competent\nclassifiers for the classification of each new test sample. Most DES techniques\nestimate the competence of classifiers using a given criterion over the region\nof competence of the test sample (its the nearest neighbors in the validation\nset). The K-Nearest Oracles Eliminate (KNORA-E) DES selects all classifiers\nthat correctly classify all samples in the region of competence of the test\nsample, if such classifier exists, otherwise, it removes from the region of\ncompetence the sample that is furthest from the test sample, and the process\nrepeats. When the region of competence has samples of different classes,\nKNORA-E can reduce the region of competence in such a way that only samples of\na single class remain in the region of competence, leading to the selection of\nlocally incompetent classifiers that classify all samples in the region of\ncompetence as being from the same class. In this paper, we propose two DES\ntechniques: K-Nearest Oracles Borderline (KNORA-B) and K-Nearest Oracles\nBorderline Imbalanced (KNORA-BI). KNORA-B is a DES technique based on KNORA-E\nthat reduces the region of competence but maintains at least one sample from\neach class that is in the original region of competence. KNORA-BI is a\nvariation of KNORA-B for imbalance datasets that reduces the region of\ncompetence but maintains at least one minority class sample if there is any in\nthe original region of competence. Experiments are conducted comparing the\nproposed techniques with 19 DES techniques from the literature using 40\ndatasets. The results show that the proposed techniques achieved interesting\nresults, with KNORA-BI outperforming state-of-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 23:11:05 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Oliveira", "Dayvid V. R.", ""], ["Cavalcanti", "George D. C.", ""], ["Porpino", "Thyago N.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1804.07006", "submitter": "Peng Gao", "authors": "Peng Gao, Yipeng Ma, Ke Song, Chao Li, Fei Wang, Liyi Xiao", "title": "Large Margin Structured Convolution Operator for Thermal Infrared Object\n  Tracking", "comments": "Accepted as contributed paper in ICPR'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with visible object tracking, thermal infrared (TIR) object tracking\ncan track an arbitrary target in total darkness since it cannot be influenced\nby illumination variations. However, there are many unwanted attributes that\nconstrain the potentials of TIR tracking, such as the absence of visual color\npatterns and low resolutions. Recently, structured output support vector\nmachine (SOSVM) and discriminative correlation filter (DCF) have been\nsuccessfully applied to visible object tracking, respectively. Motivated by\nthese, in this paper, we propose a large margin structured convolution operator\n(LMSCO) to achieve efficient TIR object tracking. To improve the tracking\nperformance, we employ the spatial regularization and implicit interpolation to\nobtain continuous deep feature maps, including deep appearance features and\ndeep motion features, of the TIR targets. Finally, a collaborative optimization\nstrategy is exploited to significantly update the operators. Our approach not\nonly inherits the advantage of the strong discriminative capability of SOSVM\nbut also achieves accurate and robust tracking with higher-dimensional features\nand more dense samples. To the best of our knowledge, we are the first to\nincorporate the advantages of DCF and SOSVM for TIR object tracking.\nComprehensive evaluations on two thermal infrared tracking benchmarks, i.e.\nVOT-TIR2015 and VOT-TIR2016, clearly demonstrate that our LMSCO tracker\nachieves impressive results and outperforms most state-of-the-art trackers in\nterms of accuracy and robustness with sufficient frame rate.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 06:12:02 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 08:21:20 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Gao", "Peng", ""], ["Ma", "Yipeng", ""], ["Song", "Ke", ""], ["Li", "Chao", ""], ["Wang", "Fei", ""], ["Xiao", "Liyi", ""]]}, {"id": "1804.07013", "submitter": "Yuncong Li", "authors": "Yuncong Li, Hankz Hankui Zhuo", "title": "An Integrated Development Environment for Planning Domain Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make the task, description of planning domains and problems, more\ncomprehensive for non-experts in planning, the visual representation has been\nused in planning domain modeling in recent years. However, current knowledge\nengineering tools with visual modeling, like itSIMPLE (Vaquero et al. 2012) and\nVIZ (Vodr\\'a\\v{z}ka and Chrpa 2010), are less efficient than the traditional\nmethod of hand-coding by a PDDL expert using a text editor, and rarely involved\nin finetuning planning domains depending on the plan validation. Aim at this,\nwe present an integrated development environment KAVI for planning domain\nmodeling inspired by itSIMPLE and VIZ. KAVI using an abstract domain knowledge\nbase to improve the efficiency of planning domain visual modeling. By\nintegrating planners and a plan validator, KAVI proposes a method to fine-tune\nplanning domains based on the plan validation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 06:39:49 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Li", "Yuncong", ""], ["Zhuo", "Hankz Hankui", ""]]}, {"id": "1804.07031", "submitter": "Alexander Svozil", "authors": "Krishnendu Chatterjee, Wolfgang Dvo\\v{r}\\'ak, Monika Henzinger and\n  Alexander Svozil", "title": "Algorithms and Conditional Lower Bounds for Planning Problems", "comments": "Accepted at ICAPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider planning problems for graphs, Markov decision processes (MDPs),\nand games on graphs. While graphs represent the most basic planning model, MDPs\nrepresent interaction with nature and games on graphs represent interaction\nwith an adversarial environment. We consider two planning problems where there\nare k different target sets, and the problems are as follows: (a) the coverage\nproblem asks whether there is a plan for each individual target set, and (b)\nthe sequential target reachability problem asks whether the targets can be\nreached in sequence. For the coverage problem, we present a linear-time\nalgorithm for graphs and quadratic conditional lower bound for MDPs and games\non graphs. For the sequential target problem, we present a linear-time\nalgorithm for graphs, a sub-quadratic algorithm for MDPs, and a quadratic\nconditional lower bound for games on graphs. Our results with conditional lower\nbounds establish (i) model-separation results showing that for the coverage\nproblem MDPs and games on graphs are harder than graphs and for the sequential\nreachability problem games on graphs are harder than MDPs and graphs; (ii)\nobjective-separation results showing that for MDPs the coverage problem is\nharder than the sequential target problem.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 08:12:50 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Svozil", "Alexander", ""]]}, {"id": "1804.07047", "submitter": "Leye Wang", "authors": "Leye Wang, Wenbin Liu, Daqing Zhang, Yasha Wang, En Wang, Yongjian\n  Yang", "title": "Cell Selection with Deep Reinforcement Learning in Sparse Mobile\n  Crowdsensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Mobile CrowdSensing (MCS) is a novel MCS paradigm where data inference\nis incorporated into the MCS process for reducing sensing costs while its\nquality is guaranteed. Since the sensed data from different cells (sub-areas)\nof the target sensing area will probably lead to diverse levels of inference\ndata quality, cell selection (i.e., choose which cells of the target area to\ncollect sensed data from participants) is a critical issue that will impact the\ntotal amount of data that requires to be collected (i.e., data collection\ncosts) for ensuring a certain level of quality. To address this issue, this\npaper proposes a Deep Reinforcement learning based Cell selection mechanism for\nSparse MCS, called DR-Cell. First, we properly model the key concepts in\nreinforcement learning including state, action, and reward, and then propose to\nuse a deep recurrent Q-network for learning the Q-function that can help decide\nwhich cell is a better choice under a certain state during cell selection.\nFurthermore, we leverage the transfer learning techniques to reduce the amount\nof data required for training the Q-function if there are multiple correlated\nMCS tasks that need to be conducted in the same target area. Experiments on\nvarious real-life sensing datasets verify the effectiveness of DR-Cell over the\nstate-of-the-art cell selection mechanisms in Sparse MCS by reducing up to 15%\nof sensed cells with the same data inference quality guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:21:06 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 06:18:41 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Wang", "Leye", ""], ["Liu", "Wenbin", ""], ["Zhang", "Daqing", ""], ["Wang", "Yasha", ""], ["Wang", "En", ""], ["Yang", "Yongjian", ""]]}, {"id": "1804.07088", "submitter": "George Baryannis", "authors": "George Baryannis, Ilias Tachmazidis, Sotiris Batsakis, Grigoris\n  Antoniou, Mario Alviano, Timos Sellis, Pei-Wei Tsai", "title": "A Trajectory Calculus for Qualitative Spatial Reasoning Using Answer Set\n  Programming", "comments": "Paper presented at the 34th International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018, 20 pages,\n  LaTeX, 16 figures", "journal-ref": "Theory and Practice of Logic Programming 18 (2018) 355-371", "doi": "10.1017/S147106841800011X", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial information is often expressed using qualitative terms such as\nnatural language expressions instead of coordinates; reasoning over such terms\nhas several practical applications, such as bus routes planning. Representing\nand reasoning on trajectories is a specific case of qualitative spatial\nreasoning that focuses on moving objects and their paths. In this work, we\npropose two versions of a trajectory calculus based on the allowed properties\nover trajectories, where trajectories are defined as a sequence of\nnon-overlapping regions of a partitioned map. More specifically, if a given\ntrajectory is allowed to start and finish at the same region, 6 base relations\nare defined (TC-6). If a given trajectory should have different start and\nfinish regions but cycles are allowed within, 10 base relations are defined\n(TC-10). Both versions of the calculus are implemented as ASP programs; we\npropose several different encodings, including a generalised program capable of\nencoding any qualitative calculus in ASP. All proposed encodings are\nexperimentally evaluated using a real-world dataset. Experiment results show\nthat the best performing implementation can scale up to an input of 250\ntrajectories for TC-6 and 150 trajectories for TC-10 for the problem of\ndiscovering a consistent configuration, a significant improvement compared to\nprevious ASP implementations for similar qualitative spatial and temporal\ncalculi. This manuscript is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:16:22 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Baryannis", "George", ""], ["Tachmazidis", "Ilias", ""], ["Batsakis", "Sotiris", ""], ["Antoniou", "Grigoris", ""], ["Alviano", "Mario", ""], ["Sellis", "Timos", ""], ["Tsai", "Pei-Wei", ""]]}, {"id": "1804.07090", "submitter": "Amartya Sanyal", "authors": "Amartya Sanyal, Varun Kanade, Philip H. S. Torr, Puneet K. Dokania", "title": "Robustness via Deep Low-Rank Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of the dimensionality of the representations\nlearned in Deep Neural Networks (DNNs) on their robustness to input\nperturbations, both adversarial and random. To achieve low dimensionality of\nlearned representations, we propose an easy-to-use, end-to-end trainable,\nlow-rank regularizer (LR) that can be applied to any intermediate layer\nrepresentation of a DNN. This regularizer forces the feature representations to\n(mostly) lie in a low-dimensional linear subspace. We perform a wide range of\nexperiments that demonstrate that the LR indeed induces low rank on the\nrepresentations, while providing modest improvements to accuracy as an added\nbenefit. Furthermore, the learned features make the trained model significantly\nmore robust to input perturbations such as Gaussian and adversarial noise (even\nwithout adversarial training). Lastly, the low-dimensionality means that the\nlearned features are highly compressible; thus discriminative features of the\ndata can be stored using very little memory. Our experiments indicate that\nmodels trained using the LR learn robust classifiers by discovering subspaces\nthat avoid non-robust features. Algorithmically, the LR is scalable, generic,\nand straightforward to implement into existing deep learning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:17:41 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 09:58:25 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 07:37:02 GMT"}, {"version": "v4", "created": "Thu, 21 Mar 2019 14:56:14 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2020 17:37:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Sanyal", "Amartya", ""], ["Kanade", "Varun", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "1804.07099", "submitter": "Vernon Asuncion Va", "authors": "Vernon Asuncion, Yan Zhang, Heng Zhang, Yun Bai and Weisheng Si", "title": "Loop Restricted Existential Rules and First-order Rewritability for\n  Query Answering", "comments": "Full paper version of extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ontology-based data access (OBDA), the classical database is enhanced with\nan ontology in the form of logical assertions generating new intensional\nknowledge. A powerful form of such logical assertions is the tuple-generating\ndependencies (TGDs), also called existential rules, where Horn rules are\nextended by allowing existential quantifiers to appear in the rule heads. In\nthis paper we introduce a new language called loop restricted (LR) TGDs\n(existential rules), which are TGDs with certain restrictions on the loops\nembedded in the underlying rule set. We study the complexity of this new\nlanguage. We show that the conjunctive query answering (CQA) under the LR TGDs\nis decid- able. In particular, we prove that this language satisfies the\nso-called bounded derivation-depth prop- erty (BDDP), which implies that the\nCQA is first-order rewritable, and its data complexity is in AC0 . We also\nprove that the combined complexity of the CQA is EXPTIME complete, while the\nlanguage membership is PSPACE complete. Then we extend the LR TGDs language to\nthe generalised loop restricted (GLR) TGDs language, and prove that this class\nof TGDs still remains to be first-order rewritable and properly contains most\nof other first-order rewritable TGDs classes discovered in the literature so\nfar.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:45:14 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 01:48:26 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Asuncion", "Vernon", ""], ["Zhang", "Yan", ""], ["Zhang", "Heng", ""], ["Bai", "Yun", ""], ["Si", "Weisheng", ""]]}, {"id": "1804.07121", "submitter": "Jose Hernandez-Orallo", "authors": "Jose Hernandez-Orallo, Jan Arne Telle", "title": "Finite Biased Teaching with Infinite Concept Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the teaching of infinite concept classes through the effect of\nthe learning bias (which is used by the learner to prefer some concepts over\nothers and by the teacher to devise the teaching examples) and the sampling\nbias (which determines how the concepts are sampled from the class). We analyse\ntwo important classes: Turing machines and finite-state machines. We derive\nbounds for the biased teaching dimension when the learning bias is derived from\na complexity measure (Kolmogorov complexity and minimal number of states\nrespectively) and analyse the sampling distributions that lead to finite\nexpected biased teaching dimensions. We highlight the existing trade-off\nbetween the bound and the representativeness of the sample, and its\nimplications for the understanding of what teaching rich concepts to machines\nentails.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 12:48:52 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hernandez-Orallo", "Jose", ""], ["Telle", "Jan Arne", ""]]}, {"id": "1804.07152", "submitter": "Liu Weiyi", "authors": "Weiyi Liu, Zhining Liu, Toyotaro Suzumura, Guangmin Hu", "title": "Scalable attribute-aware network embedding with locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding attributes for nodes to network embedding helps to improve the ability\nof the learned joint representation to depict features from topology and\nattributes simultaneously. Recent research on the joint embedding has exhibited\na promising performance on a variety of tasks by jointly embedding the two\nspaces. However, due to the indispensable requirement of globality based\ninformation, present approaches contain a flaw of in-scalability. Here we\npropose \\emph{SANE}, a scalable attribute-aware network embedding algorithm\nwith locality, to learn the joint representation from topology and attributes.\nBy enforcing the alignment of a local linear relationship between each node and\nits K-nearest neighbors in topology and attribute space, the joint embedding\nrepresentations are more informative comparing with a single representation\nfrom topology or attributes alone. And we argue that the locality in\n\\emph{SANE} is the key to learning the joint representation at scale. By using\nseveral real-world networks from diverse domains, We demonstrate the efficacy\nof \\emph{SANE} in performance and scalability aspect. Overall, for performance\non label classification, SANE successfully reaches up to the highest F1-score\non most datasets, and even closer to the baseline method that needs label\ninformation as extra inputs, compared with other state-of-the-art joint\nrepresentation algorithms. What's more, \\emph{SANE} has an up to 71.4\\%\nperformance gain compared with the single topology-based algorithm. For\nscalability, we have demonstrated the linearly time complexity of \\emph{SANE}.\nIn addition, we intuitively observe that when the network size scales to\n100,000 nodes, the \"learning joint embedding\" step of \\emph{SANE} only takes\n$\\approx10$ seconds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:59:50 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 00:40:08 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Liu", "Weiyi", ""], ["Liu", "Zhining", ""], ["Suzumura", "Toyotaro", ""], ["Hu", "Guangmin", ""]]}, {"id": "1804.07178", "submitter": "Cinjon Resnick", "authors": "Cinjon Resnick, Ilya Kulikov, Kyunghyun Cho, Jason Weston", "title": "Vehicle Communication Strategies for Simulated Highway Driving", "comments": "NIPS 2017 Workshop on Emergent Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in emergent communication has recently surged in Machine Learning.\nThe focus of this interest has largely been either on investigating the\nproperties of the learned protocol or on utilizing emergent communication to\nbetter solve problems that already have a viable solution. Here, we consider\nself-driving cars coordinating with each other and focus on how communication\ninfluences the agents' collective behavior. Our main result is that\ncommunication helps (most) with adverse conditions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:02:07 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 12:35:41 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Resnick", "Cinjon", ""], ["Kulikov", "Ilya", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""]]}, {"id": "1804.07193", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Dipendra Misra, Michael L. Littman", "title": "Lipschitz Continuity in Model-based Reinforcement Learning", "comments": "Accepted for the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the impact of learning Lipschitz continuous models in the context\nof model-based reinforcement learning. We provide a novel bound on multi-step\nprediction error of Lipschitz models where we quantify the error using the\nWasserstein metric. We go on to prove an error bound for the value-function\nestimate arising from Lipschitz models and show that the estimated value\nfunction is itself Lipschitz. We conclude with empirical results that show the\nbenefits of controlling the Lipschitz constant of neural-network models.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:29:41 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 04:02:26 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 12:40:44 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Asadi", "Kavosh", ""], ["Misra", "Dipendra", ""], ["Littman", "Michael L.", ""]]}, {"id": "1804.07269", "submitter": "Sao Mai Nguyen", "authors": "Sao Mai Nguyen, Pierre-Yves Oudeyer", "title": "Socially Guided Intrinsic Motivation for Robot Learning of Motor Skills", "comments": null, "journal-ref": "Autonomous Robots, Springer Verlag, 2014, 36 (3), pp.273-294", "doi": "10.1007/s10514-013-9339-y", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technical approach to robot learning of motor skills\nwhich combines active intrinsically motivated learning with imitation learning.\nOur architecture, called SGIM-D, allows efficient learning of high-dimensional\ncontinuous sensorimotor inverse models in robots, and in particular learns\ndistributions of parameterised motor policies that solve a corresponding\ndistribution of parameterised goals/tasks. This is made possible by the\ntechnical integration of imitation learning techniques within an algorithm for\nlearning inverse models that relies on active goal babbling. After reviewing\nsocial learning and intrinsic motivation approaches to action learning, we\ndescribe the general framework of our algorithm, before detailing its\narchitecture. In an experiment where a robot arm has to learn to use a flexible\nfishing line , we illustrate that SGIM-D efficiently combines the advantages of\nsocial learning and intrinsic motivation and benefits from human demonstration\nproperties to learn how to produce varied outcomes in the environment, while\ndeveloping more precise control policies in large spaces.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:47:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nguyen", "Sao Mai", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1804.07274", "submitter": "Cristina Feier", "authors": "David Carral, Cristina Feier, Pascal Hitzler", "title": "A Practical Acyclicity Notion for Query Answering over Horn-SRIQ\n  Ontologies", "comments": null, "journal-ref": "The Semantic Web - ISWC 2016 - 15th International Semantic Web\n  Conference, Kobe, Japan. Proceedings, Part I, volume 9981 of LNCS, 70-85,\n  October 2016. Springer", "doi": "10.1007/978-3-319-46523-4_5", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjunctive query answering over expressive Horn Description Logic ontologies\nis a relevant and challenging problem which, in some cases, can be addressed by\napplication of the chase algorithm. In this paper, we define a novel acyclicity\nnotion which provides a sufficient condition for termination of the restricted\nchase over Horn-SRIQ TBoxes. We show that this notion generalizes most of the\nexisting acyclicity conditions (both theoretically and empirically).\nFurthermore, this new acyclicity notion gives rise to a very efficient\nreasoning procedure. We provide evidence for this by providing a\nmaterialization based reasoner for acyclic ontologies which outperforms other\nstate-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:57:25 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Carral", "David", ""], ["Feier", "Cristina", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1804.07331", "submitter": "Murali Raghu Babu Balusu", "authors": "Murali Raghu Babu Balusu and Taha Merghani and Jacob Eisenstein", "title": "Stylistic Variation in Social Media Part-of-Speech Tagging", "comments": "9 pages, Published in Proceedings of NAACL workshop on stylistic\n  variation (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media features substantial stylistic variation, raising new challenges\nfor syntactic analysis of online writing. However, this variation is often\naligned with author attributes such as age, gender, and geography, as well as\nmore readily-available social network metadata. In this paper, we report new\nevidence on the link between language and social networks in the task of\npart-of-speech tagging. We find that tagger error rates are correlated with\nnetwork structure, with high accuracy in some parts of the network, and lower\naccuracy elsewhere. As a result, tagger accuracy depends on training from a\nbalanced sample of the network, rather than training on texts from a narrow\nsubcommunity. We also describe our attempts to add robustness to stylistic\nvariation, by building a mixture-of-experts model in which each expert is\nassociated with a region of the social network. While prior work found that\nsimilar approaches yield performance improvements in sentiment analysis and\nentity linking, we were unable to obtain performance improvements in\npart-of-speech tagging, despite strong evidence for the link between\npart-of-speech error rates and social network structure.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 18:37:40 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Balusu", "Murali Raghu Babu", ""], ["Merghani", "Taha", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1804.07404", "submitter": "Mayukh Das", "authors": "Mayukh Das, Phillip Odom, Md. Rakibul Islam, Janardhan Rao (Jana)\n  Doppa, Dan Roth, Sriraam Natarajan", "title": "Preference-Guided Planning: An Active Elicitation Approach", "comments": "Under Review at Knowledge-Based Systems (Elsevier); \"Extended\n  Abstract\" accepted and to appear at AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning with preferences has been employed extensively to quickly generate\nhigh-quality plans. However, it may be difficult for the human expert to supply\nthis information without knowledge of the reasoning employed by the planner and\nthe distribution of planning problems. We consider the problem of actively\neliciting preferences from a human expert during the planning process.\nSpecifically, we study this problem in the context of the Hierarchical Task\nNetwork (HTN) planning framework as it allows easy interaction with the human.\nOur experimental results on several diverse planning domains show that the\npreferences gathered using the proposed approach improve the quality and speed\nof the planner, while reducing the burden on the human expert.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 23:30:37 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Das", "Mayukh", "", "Jana"], ["Odom", "Phillip", "", "Jana"], ["Islam", "Md. Rakibul", "", "Jana"], ["Rao", "Janardhan", "", "Jana"], ["Doppa", "", ""], ["Roth", "Dan", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1804.07419", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Felipe N. Walmsley, George D. C. Cavalcanti, Dayvid V. R. Oliveira,\n  Rafael M. O. Cruz and Robert Sabourin", "title": "An Ensemble Generation Method Based on Instance Hardness", "comments": "Paper accepted for publication on IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489269", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning, ensemble methods have been receiving a great deal of\nattention. Techniques such as Bagging and Boosting have been successfully\napplied to a variety of problems. Nevertheless, such techniques are still\nsusceptible to the effects of noise and outliers in the training data. We\npropose a new method for the generation of pools of classifiers based on\nBagging, in which the probability of an instance being selected during the\nresampling process is inversely proportional to its instance hardness, which\ncan be understood as the likelihood of an instance being misclassified,\nregardless of the choice of classifier. The goal of the proposed method is to\nremove noisy data without sacrificing the hard instances which are likely to be\nfound on class boundaries. We evaluate the performance of the method in\nnineteen public data sets, and compare it to the performance of the Bagging and\nRandom Subspace algorithms. Our experiments show that in high noise scenarios\nthe accuracy of our method is significantly better than that of Bagging.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 01:29:47 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 07:18:12 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Walmsley", "Felipe N.", ""], ["Cavalcanti", "George D. C.", ""], ["Oliveira", "Dayvid V. R.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1804.07464", "submitter": "Juan Afanador", "authors": "Juan Afanador, Nir Oren, Murilo S. Baptista", "title": "Delegating via Quitting Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delegation allows an agent to request that another agent completes a task. In\nmany situations the task may be delegated onwards, and this process can repeat\nuntil it is eventually, successfully or unsuccessfully, performed. We consider\npolicies to guide an agent in choosing who to delegate to when such recursive\ninteractions are possible. These policies, based on quitting games and\nmulti-armed bandits, were empirically tested for effectiveness. Our results\nindicate that the quitting game based policies outperform those which do not\nexplicitly account for the recursive nature of delegation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:45:28 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Afanador", "Juan", ""], ["Oren", "Nir", ""], ["Baptista", "Murilo S.", ""]]}, {"id": "1804.07691", "submitter": "Kaixiang Mo", "authors": "Kaixiang Mo, Yu Zhang, Qiang Yang, Pascale Fung", "title": "Cross-domain Dialogue Policy Transfer via Simultaneous Speech-act and\n  Slot Alignment", "comments": "v7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy transfer enables us to build dialogue policies in a target\ndomain with little data by leveraging knowledge from a source domain with\nplenty of data. Dialogue sentences are usually represented by speech-acts and\ndomain slots, and the dialogue policy transfer is usually achieved by assigning\na slot mapping matrix based on human heuristics. However, existing dialogue\npolicy transfer methods cannot transfer across dialogue domains with different\nspeech-acts, for example, between systems built by different companies. Also,\nthey depend on either common slots or slot entropy, which are not available\nwhen the source and target slots are totally disjoint and no database is\navailable to calculate the slot entropy. To solve this problem, we propose a\nPolicy tRansfer across dOMaIns and SpEech-acts (PROMISE) model, which is able\nto transfer dialogue policies across domains with different speech-acts and\ndisjoint slots. The PROMISE model can learn to align different speech-acts and\nslots simultaneously, and it does not require common slots or the calculation\nof the slot entropy. Experiments on both real-world dialogue data and\nsimulations demonstrate that PROMISE model can effectively transfer dialogue\npolicies across domains with different speech-acts and disjoint slots.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:51:14 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mo", "Kaixiang", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""], ["Fung", "Pascale", ""]]}, {"id": "1804.07757", "submitter": "Shuangtao Li", "authors": "Shuangtao Li, Yuanke Chen, Yanlin Peng, Lin Bai", "title": "Learning More Robust Features with Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, it has been found that neural networks can be easily fooled\nby adversarial examples, which is a potential safety hazard in some\nsafety-critical applications. Many researchers have proposed various method to\nmake neural networks more robust to white-box adversarial attacks, but an\neffective method have not been found so far. In this short paper, we focus on\nthe robustness of the features learned by neural networks. We show that the\nfeatures learned by neural networks are not robust, and find that the\nrobustness of the learned features is closely related to the resistance against\nadversarial examples of neural networks. We also find that adversarial training\nagainst fast gradients sign method (FGSM) does not make the leaned features\nvery robust, even if it can make the trained networks very resistant to FGSM\nattack. Then we propose a method, which can be seen as an extension of\nadversarial training, to train neural networks to learn more robust features.\nWe perform experiments on MNIST and CIFAR-10 to evaluate our method, and the\nexperiment results show that this method greatly improves the robustness of the\nlearned features and the resistance to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 05:07:14 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Li", "Shuangtao", ""], ["Chen", "Yuanke", ""], ["Peng", "Yanlin", ""], ["Bai", "Lin", ""]]}, {"id": "1804.07758", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Elektra Kypridemou", "title": "Mapping Images to Psychological Similarity Spaces Using Neural Networks", "comments": "Accepted to AIC 2018 (http://aic2018.pa.icar.cnr.it/), see\n  http://ceur-ws.org/Vol-2418/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive framework of conceptual spaces bridges the gap between symbolic\nand subsymbolic AI by proposing an intermediate conceptual layer where\nknowledge is represented geometrically. There are two main approaches for\nobtaining the dimensions of this conceptual similarity space: using similarity\nratings from psychological experiments and using machine learning techniques.\nIn this paper, we propose a combination of both approaches by using\npsychologically derived similarity ratings to constrain the machine learning\nprocess. This way, a mapping from stimuli to conceptual spaces can be learned\nthat is both supported by psychological data and allows generalization to\nunseen stimuli. The results of a first feasibility study support our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:29:05 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 07:54:46 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Bechberger", "Lucas", ""], ["Kypridemou", "Elektra", ""]]}, {"id": "1804.07759", "submitter": "Gengyu Lyu", "authors": "Gengyu Lyu, Songhe Feng, Congyang Lang", "title": "A Self-paced Regularization Framework for Partial-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label learning (PLL) aims to solve the problem where each training\ninstance is associated with a set of candidate labels, one of which is the\ncorrect label. Most PLL algorithms try to disambiguate the candidate label set,\nby either simply treating each candidate label equally or iteratively\nidentifying the true label. Nonetheless, existing algorithms usually treat all\nlabels and instances equally, and the complexities of both labels and instances\nare not taken into consideration during the learning stage. Inspired by the\nsuccessful application of self-paced learning strategy in machine learning\nfield, we integrate the self-paced regime into the partial label learning\nframework and propose a novel Self-Paced Partial-Label Learning (SP-PLL)\nalgorithm, which could control the learning process to alleviate the problem by\nranking the priorities of the training examples together with their candidate\nlabels during each learning iteration. Extensive experiments and comparisons\nwith other baseline methods demonstrate the effectiveness and robustness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:04:32 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 08:49:25 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Lyu", "Gengyu", ""], ["Feng", "Songhe", ""], ["Lang", "Congyang", ""]]}, {"id": "1804.07777", "submitter": "Per Ola Kristensson", "authors": "Emli-Mari Nel, Per Ola Kristensson, David J.C. MacKay", "title": "The Statistical Model for Ticker, an Adaptive Single-Switch Text-Entry\n  Method for Visually Impaired Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the statistical model for Ticker [1], a novel\nprobabilistic stereophonic single-switch text entry method for\nvisually-impaired users with motor disabilities who rely on single-switch\nscanning systems to communicate. All terminology and notation are defined in\n[1].\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:04:37 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Nel", "Emli-Mari", ""], ["Kristensson", "Per Ola", ""], ["MacKay", "David J. C.", ""]]}, {"id": "1804.07779", "submitter": "Daoming Lyu", "authors": "Fangkai Yang, Daoming Lyu, Bo Liu, Steven Gustafson", "title": "PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement\n  Learning for Robust Decision-Making", "comments": "conference version accepted by IJCAI-ECAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and symbolic planning have both been used to build\nintelligent autonomous agents. Reinforcement learning relies on learning from\ninteractions with real world, which often requires an unfeasibly large amount\nof experience. Symbolic planning relies on manually crafted symbolic knowledge,\nwhich may not be robust to domain uncertainties and changes. In this paper we\npresent a unified framework {\\em PEORL} that integrates symbolic planning with\nhierarchical reinforcement learning (HRL) to cope with decision-making in a\ndynamic environment with uncertainties.\n  Symbolic plans are used to guide the agent's task execution and learning, and\nthe learned experience is fed back to symbolic knowledge to improve planning.\nThis method leads to rapid policy search and robust symbolic plans in complex\ndomains. The framework is tested on benchmark domains of HRL.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:16:43 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 16:46:13 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 20:38:43 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Yang", "Fangkai", ""], ["Lyu", "Daoming", ""], ["Liu", "Bo", ""], ["Gustafson", "Steven", ""]]}, {"id": "1804.07789", "submitter": "Anirban Laha", "authors": "Preksha Nema, Shreyas Shetty, Parag Jain, Anirban Laha, Karthik\n  Sankaranarayanan, Mitesh M. Khapra", "title": "Generating Descriptions from Structured Data Using a Bifocal Attention\n  Mechanism and Gated Orthogonalization", "comments": "Accepted in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the task of generating natural language\ndescriptions from a structured table of facts containing fields (such as\nnationality, occupation, etc) and values (such as Indian, actor, director,\netc). One simple choice is to treat the table as a sequence of fields and\nvalues and then use a standard seq2seq model for this task. However, such a\nmodel is too generic and does not exploit task-specific characteristics. For\nexample, while generating descriptions from a table, a human would attend to\ninformation at two levels: (i) the fields (macro level) and (ii) the values\nwithin the field (micro level). Further, a human would continue attending to a\nfield for a few timesteps till all the information from that field has been\nrendered and then never return back to this field (because there is nothing\nleft to say about it). To capture this behavior we use (i) a fused bifocal\nattention mechanism which exploits and combines this micro and macro level\ninformation and (ii) a gated orthogonalization mechanism which tries to ensure\nthat a field is remembered for a few time steps and then forgotten. We\nexperiment with a recently released dataset which contains fact tables about\npeople and their corresponding one line biographical descriptions in English.\nIn addition, we also introduce two similar datasets for French and German. Our\nexperiments show that the proposed model gives 21% relative improvement over a\nrecently proposed state of the art method and 10% relative improvement over\nbasic seq2seq models. The code and the datasets developed as a part of this\nwork are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:30:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nema", "Preksha", ""], ["Shetty", "Shreyas", ""], ["Jain", "Parag", ""], ["Laha", "Anirban", ""], ["Sankaranarayanan", "Karthik", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1804.07790", "submitter": "Anirban Laha", "authors": "Parag Jain, Anirban Laha, Karthik Sankaranarayanan, Preksha Nema,\n  Mitesh M. Khapra, Shreyas Shetty", "title": "A Mixed Hierarchical Attention based Encoder-Decoder Approach for\n  Standard Table Summarization", "comments": "Accepted in NAACL-HLT 2018 (Short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured data summarization involves generation of natural language\nsummaries from structured input data. In this work, we consider summarizing\nstructured data occurring in the form of tables as they are prevalent across a\nwide variety of domains. We formulate the standard table summarization problem,\nwhich deals with tables conforming to a single predefined schema. To this end,\nwe propose a mixed hierarchical attention based encoder-decoder model which is\nable to leverage the structure in addition to the content of the tables. Our\nexperiments on the publicly available WEATHERGOV dataset show around 18 BLEU (~\n30%) improvement over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:31:29 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jain", "Parag", ""], ["Laha", "Anirban", ""], ["Sankaranarayanan", "Karthik", ""], ["Nema", "Preksha", ""], ["Khapra", "Mitesh M.", ""], ["Shetty", "Shreyas", ""]]}, {"id": "1804.07805", "submitter": "Carsten Lutz", "authors": "Elena Botoeva and Boris Konev and Carsten Lutz and Vladislav Ryzhikov\n  and Frank Wolter and Michael Zakharyaschev", "title": "Inseparability and Conservative Extensions of Description Logic\n  Ontologies: A Survey", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-49493-7_2", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question whether an ontology can safely be replaced by another, possibly\nsimpler, one is fundamental for many ontology engineering and maintenance\ntasks. It underpins, for example, ontology versioning, ontology modularization,\nforgetting, and knowledge exchange. What safe replacement means depends on the\nintended application of the ontology. If, for example, it is used to query\ndata, then the answers to any relevant ontology-mediated query should be the\nsame over any relevant data set; if, in contrast, the ontology is used for\nconceptual reasoning, then the entailed subsumptions between concept\nexpressions should coincide. This gives rise to different notions of ontology\ninseparability such as query inseparability and concept inseparability, which\ngeneralize corresponding notions of conservative extensions. We survey results\non various notions of inseparability in the context of description logic\nontologies, discussing their applications, useful model-theoretic\ncharacterizations, algorithms for determining whether two ontologies are\ninseparable (and, sometimes, for computing the difference between them if they\nare not), and the computational complexity of this problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 19:17:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Botoeva", "Elena", ""], ["Konev", "Boris", ""], ["Lutz", "Carsten", ""], ["Ryzhikov", "Vladislav", ""], ["Wolter", "Frank", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1804.07819", "submitter": "Erik Altman", "authors": "Erik Altman", "title": "Understanding AI Data Repositories with Automatic Query Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a set of techniques to generate queries automatically based on\none or more ingested, input corpuses. These queries require no a priori domain\nknowledge, and hence no human domain experts. Thus, these auto-generated\nqueries help address the epistemological question of how we know what we know,\nor more precisely in this case, how an AI system with ingested data knows what\nit knows. These auto-generated queries can also be used to identify and remedy\nproblem areas in ingested material -- areas for which the knowledge of the AI\nsystem is incomplete or even erroneous. Similarly, the proposed techniques\nfacilitate tests of AI capability -- both in terms of coverage and accuracy. By\nremoving humans from the main learning loop, our approach also allows more\neffective scaling of AI and cognitive capabilities to provide (1) broader\ncoverage in a single domain such as health or geology; and (2) more rapid\ndeployment to new domains. The proposed techniques also allow ingested\nknowledge to be extended naturally. Our investigations are early, and this\npaper provides a description of the techniques. Assessment of their efficacy is\nour next step for future work.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 20:44:09 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Altman", "Erik", ""]]}, {"id": "1804.07855", "submitter": "Xiujun Li", "authors": "Da Tang and Xiujun Li and Jianfeng Gao and Chong Wang and Lihong Li\n  and Tony Jebara", "title": "Subgoal Discovery for Hierarchical Dialogue Policy Learning", "comments": "11 pages, 6 figures, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing agents to engage in complex goal-oriented dialogues is challenging\npartly because the main learning signals are very sparse in long conversations.\nIn this paper, we propose a divide-and-conquer approach that discovers and\nexploits the hidden structure of the task to enable efficient policy learning.\nFirst, given successful example dialogues, we propose the Subgoal Discovery\nNetwork (SDN) to divide a complex goal-oriented task into a set of simpler\nsubgoals in an unsupervised fashion. We then use these subgoals to learn a\nmulti-level policy by hierarchical reinforcement learning. We demonstrate our\nmethod by building a dialogue agent for the composite task of travel planning.\nExperiments with simulated and real users show that our approach performs\ncompetitively against a state-of-the-art method that requires human-defined\nsubgoals. Moreover, we show that the learned subgoals are often human\ncomprehensible.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 23:06:44 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 22:20:26 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 22:46:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Tang", "Da", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Wang", "Chong", ""], ["Li", "Lihong", ""], ["Jebara", "Tony", ""]]}, {"id": "1804.07875", "submitter": "Lifu Huang", "authors": "Lifu Huang, Kyunghyun Cho, Boliang Zhang, Heng Ji, Kevin Knight", "title": "Multi-lingual Common Semantic Space Construction via Cluster-consistent\n  Word Embedding", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We construct a multilingual common semantic space based on distributional\nsemantics, where words from multiple languages are projected into a shared\nspace to enable knowledge and resource transfer across languages. Beyond word\nalignment, we introduce multiple cluster-level alignments and enforce the word\nclusters to be consistently distributed across multiple languages. We exploit\nthree signals for clustering: (1) neighbor words in the monolingual word\nembedding space; (2) character-level information; and (3) linguistic properties\n(e.g., apposition, locative suffix) derived from linguistic structure knowledge\nbases available for thousands of languages. We introduce a new\ncluster-consistent correlational neural network to construct the common\nsemantic space by aligning words as well as clusters. Intrinsic evaluation on\nmonolingual and multilingual QVEC tasks shows our approach achieves\nsignificantly higher correlation with linguistic features than state-of-the-art\nmulti-lingual embedding learning methods do. Using low-resource language name\ntagging as a case study for extrinsic evaluation, our approach achieves up to\n24.5\\% absolute F-score gain over the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 01:48:38 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Huang", "Lifu", ""], ["Cho", "Kyunghyun", ""], ["Zhang", "Boliang", ""], ["Ji", "Heng", ""], ["Knight", "Kevin", ""]]}, {"id": "1804.07882", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Hiba H. Zakane, Robert Sabourin and George D. C.\n  Cavalcanti", "title": "Dynamic Ensemble Selection VS K-NN: why and when Dynamic Selection\n  obtains higher classification performance?", "comments": "Paper published on IPTA 2017", "journal-ref": null, "doi": "10.1109/IPTA.2017.8310100", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple classifier systems focus on the combination of classifiers to obtain\nbetter performance than a single robust one. These systems unfold three major\nphases: pool generation, selection and integration. One of the most promising\nMCS approaches is Dynamic Selection (DS), which relies on finding the most\ncompetent classifier or ensemble of classifiers to predict each test sample.\nThe majority of the DS techniques are based on the K-Nearest Neighbors (K-NN)\ndefinition, and the quality of the neighborhood has a huge impact on the\nperformance of DS methods. In this paper, we perform an analysis comparing the\nclassification results of DS techniques and the K-NN classifier under different\nconditions. Experiments are performed on 18 state-of-the-art DS techniques over\n30 classification datasets and results show that DS methods present a\nsignificant boost in classification accuracy even though they use the same\nneighborhood as the K-NN. The reasons behind the outperformance of DS\ntechniques over the K-NN classifier reside in the fact that DS techniques can\ndeal with samples with a high degree of instance hardness (samples that are\nlocated close to the decision border) as opposed to the K-NN. In this paper,\nnot only we explain why DS techniques achieve higher classification performance\nthan the K-NN but also when DS should be used.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 03:15:25 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Zakane", "Hiba H.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1804.07918", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig and Jonathan Berant", "title": "Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a semantic parser quickly in a new domain is a fundamental challenge\nfor conversational interfaces, as current semantic parsers require expensive\nsupervision and lack the ability to generalize to new domains. In this paper,\nwe introduce a zero-shot approach to semantic parsing that can parse utterances\nin unseen domains while only being trained on examples in other source domains.\nFirst, we map an utterance to an abstract, domain-independent, logical form\nthat represents the structure of the logical form, but contains slots instead\nof KB constants. Then, we replace slots with KB constants via lexical alignment\nscores and global inference. Our model reaches an average accuracy of 53.4% on\n7 domains in the Overnight dataset, substantially better than other zero-shot\nbaselines, and performs as good as a parser trained on over 30% of the target\ndomain examples.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 08:27:14 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 09:07:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Herzig", "Jonathan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1804.07946", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo and Stanley Jungkyu Choi", "title": "Extrofitting: Enriching Word Representation and its Vector Space with\n  Semantic Lexicons", "comments": "In Proceedings of the 3rd ACL Workshop on Representation Learning for\n  NLP (RepL4NLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose post-processing method for enriching not only word representation\nbut also its vector space using semantic lexicons, which we call extrofitting.\nThe method consists of 3 steps as follows: (i) Expanding 1 or more dimension(s)\non all the word vectors, filling with their representative value. (ii)\nTransferring semantic knowledge by averaging each representative values of\nsynonyms and filling them in the expanded dimension(s). These two steps make\nrepresentations of the synonyms close together. (iii) Projecting the vector\nspace using Linear Discriminant Analysis, which eliminates the expanded\ndimension(s) with semantic knowledge. When experimenting with GloVe, we find\nthat our method outperforms Faruqui's retrofitting on some of word similarity\ntask. We also report further analysis on our method in respect to word vector\ndimensions, vocabulary size as well as other well-known pretrained word vectors\n(e.g., Word2Vec, Fasttext).\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 11:17:26 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 08:35:28 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Jo", "Hwiyeol", ""], ["Choi", "Stanley Jungkyu", ""]]}, {"id": "1804.07995", "submitter": "Xin-She Yang", "authors": "Xingshi He, Xin-She Yang, Mehmet Karamanoglu, Yuxin Zhao", "title": "Global Convergence Analysis of the Flower Pollination Algorithm: A\n  Discrete-Time Markov Chain Approach", "comments": "8th Workshop on Computational Optimization, Modelling and Simulation\n  at ICCS2017", "journal-ref": "Procedia Computer Science, vol. 108, 1354-1364 (2017)", "doi": "10.1016/j.procs.2017.05.020", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flower pollination algorithm is a recent metaheuristic algorithm for solving\nnonlinear global optimization problems. The algorithm has also been extended to\nsolve multiobjective optimization with promising results. In this work, we\nanalyze this algorithm mathematically and prove its convergence properties by\nusing Markov chain theory. By constructing the appropriate transition\nprobability for a population of flower pollen and using the homogeneity\nproperty, it can be shown that the constructed stochastic sequences can\nconverge to the optimal set. Under the two proper conditions for convergence,\nit is proved that the simplified flower pollination algorithm can indeed\nsatisfy these convergence conditions and thus the global convergence of this\nalgorithm can be guaranteed. Numerical experiments are used to demonstrate that\nthe flower pollination algorithm can converge quickly in practice and can thus\nachieve global optimality efficiently.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 16:32:07 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["He", "Xingshi", ""], ["Yang", "Xin-She", ""], ["Karamanoglu", "Mehmet", ""], ["Zhao", "Yuxin", ""]]}, {"id": "1804.08010", "submitter": "Qibin Zheng", "authors": "Qibin Zheng, Xingchun Diao, Jianjun Cao, Xiaolei Zhou, Yi Liu, and\n  Hongmei Li", "title": "Multi-Modal Coreference Resolution with the Correlation between Space\n  Structures", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal data is becoming more common in big data background. Finding the\nsemantically similar objects from different modality is one of the heart\nproblems of multi-modal learning. Most of the current methods try to learn the\ninter-modal correlation with extrinsic supervised information, while intrinsic\nstructural information of each modality is neglected. The performance of these\nmethods heavily depends on the richness of training samples. However, obtaining\nthe multi-modal training samples is still a labor and cost intensive work. In\nthis paper, we bring a extrinsic correlation between the space structures of\neach modalities in coreference resolution. With this correlation, a\nsemi-supervised learning model for multi-modal coreference resolution is\nproposed. We firstly extract high-level features of images and text, then\ncompute the distances of each object from some reference points to build the\nspace structure of each modality. With a shared reference point set, the space\nstructures of each modality are correlated. We employ the correlation to build\na commonly shared space that the semantic distance between multi-modal objects\ncan be computed directly. The experiments on two multi-modal datasets show that\nour model performs better than the existing methods with insufficient training\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 19:15:19 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 12:33:13 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zheng", "Qibin", ""], ["Diao", "Xingchun", ""], ["Cao", "Jianjun", ""], ["Zhou", "Xiaolei", ""], ["Liu", "Yi", ""], ["Li", "Hongmei", ""]]}, {"id": "1804.08032", "submitter": "Bart Jacobs", "authors": "Bart Jacobs", "title": "A Channel-based Exact Inference Algorithm for Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new algorithm for exact Bayesian inference that is\nbased on a recently proposed compositional semantics of Bayesian networks in\nterms of channels. The paper concentrates on the ideas behind this algorithm,\ninvolving a linearisation (`stretching') of the Bayesian network, followed by a\ncombination of forward state transformation and backward predicate\ntransformation, while evidence is accumulated along the way. The performance of\na prototype implementation of the algorithm in Python is briefly compared to a\nstandard implementation (pgmpy): first results show competitive performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 21:59:24 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Jacobs", "Bart", ""]]}, {"id": "1804.08033", "submitter": "Xavier Amatriain", "authors": "Murali Ravuri, Anitha Kannan, Geoffrey J. Tso, Xavier Amatriain", "title": "Learning from the experts: From expert systems to machine-learned\n  diagnosis models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert diagnostic support systems have been extensively studied. The\npractical applications of these systems in real-world scenarios have been\nsomewhat limited due to well-understood shortcomings, such as lack of\nextensibility. More recently, machine-learned models for medical diagnosis have\ngained momentum, since they can learn and generalize patterns found in very\nlarge datasets like electronic health records. These models also have\nshortcomings - in particular, there is no easy way to incorporate prior\nknowledge from existing literature or experts. In this paper, we present a\nmethod to merge both approaches by using expert systems as generative models\nthat create simulated data on which models can be learned. We demonstrate that\nsuch a learned model not only preserves the original properties of the expert\nsystems but also addresses some of their limitations. Furthermore, we show how\nthis approach can also be used as the starting point to combine expert\nknowledge with knowledge extracted from other data sources, such as electronic\nhealth records.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 22:01:19 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 05:24:54 GMT"}, {"version": "v3", "created": "Tue, 14 Aug 2018 04:45:23 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Ravuri", "Murali", ""], ["Kannan", "Anitha", ""], ["Tso", "Geoffrey J.", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1804.08052", "submitter": "Anahita Hosseini", "authors": "Anahita Hosseini, Ting Chen, Wenjun Wu, Yizhou Sun, Majid Sarrafzadeh", "title": "HeteroMed: Heterogeneous Information Network for Medical Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent availability of Electronic Health Records (EHR) and great\nopportunities they offer for advancing medical informatics, there has been\ngrowing interest in mining EHR for improving quality of care. Disease diagnosis\ndue to its sensitive nature, huge costs of error, and complexity has become an\nincreasingly important focus of research in past years. Existing studies model\nEHR by capturing co-occurrence of clinical events to learn their latent\nembeddings. However, relations among clinical events carry various semantics\nand contribute differently to disease diagnosis which gives precedence to a\nmore advanced modeling of heterogeneous data types and relations in EHR data\nthan existing solutions. To address these issues, we represent how\nhigh-dimensional EHR data and its rich relationships can be suitably translated\ninto HeteroMed, a heterogeneous information network for robust medical\ndiagnosis. Our modeling approach allows for straightforward handling of missing\nvalues and heterogeneity of data. HeteroMed exploits metapaths to capture\nhigher level and semantically important relations contributing to disease\ndiagnosis. Furthermore, it employs a joint embedding framework to tailor\nclinical event representations to the disease diagnosis goal. To the best of\nour knowledge, this is the first study to use Heterogeneous Information Network\nfor modeling clinical data and disease diagnosis. Experimental results of our\nstudy show superior performance of HeteroMed compared to prior methods in\nprediction of exact diagnosis codes and general disease cohorts. Moreover,\nHeteroMed outperforms baseline models in capturing similarities of clinical\nevents which are examined qualitatively through case studies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 00:53:20 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Hosseini", "Anahita", ""], ["Chen", "Ting", ""], ["Wu", "Wenjun", ""], ["Sun", "Yizhou", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1804.08062", "submitter": "Karthik Abinav Sankararaman", "authors": "Brian Brubach and Karthik Abinav Sankararaman and Aravind Srinivasan\n  and Pan Xu", "title": "Attenuate Locally, Win Globally: An Attenuation-based Framework for\n  Online Stochastic Matching with Timeouts", "comments": "A short version appeared in AAMAS-2017. This version fixes some bugs\n  in the camera-ready version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online matching problems have garnered significant attention in recent years\ndue to numerous applications in e-commerce, online advertisements,\nride-sharing, etc. Many of them capture the uncertainty in the real world by\nincluding stochasticity in both the arrival process and the matching process.\nThe Online Stochastic Matching with Timeouts problem introduced by Bansal, et\nal., (Algorithmica, 2012) models matching markets (e.g., E-Bay, Amazon). Buyers\narrive from an independent and identically distributed (i.i.d.) known\ndistribution on buyer profiles and can be shown a list of items one at a time.\nEach buyer has some probability of purchasing each item and a limit (timeout)\non the number of items they can be shown.\n  Bansal et al., (Algorithmica, 2012) gave a 0.12-competitive algorithm which\nwas improved by Adamczyk, et al., (ESA, 2015) to 0.24. We present an online\nattenuation framework that uses an algorithm for offline stochastic matching as\na black box. On the upper bound side, we show that this framework, combined\nwith a black-box adapted from Bansal et al., (Algorithmica, 2012), yields an\nonline algorithm which nearly doubles the ratio to 0.46. On the lower bound\nside, we show that no algorithm can achieve a ratio better than 0.632 using the\nstandard LP for this problem. This framework has a high potential for further\nimprovements since new algorithms for offline stochastic matching can directly\nimprove the ratio for the online problem.\n  Our online framework also has the potential for a variety of extensions. For\nexample, we introduce a natural generalization: Online Stochastic Matching with\nTwo-sided Timeouts in which both online and offline vertices have timeouts. Our\nframework provides the first algorithm for this problem achieving a ratio of\n0.30. We once again use the algorithm of Adamczyk et al., (ESA, 2015) as a\nblack-box and plug-it into our framework.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 03:20:56 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 16:16:21 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Brubach", "Brian", ""], ["Sankararaman", "Karthik Abinav", ""], ["Srinivasan", "Aravind", ""], ["Xu", "Pan", ""]]}, {"id": "1804.08069", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Kyusong Lee and Maxine Eskenazi", "title": "Unsupervised Discrete Sentence Representation Learning for Interpretable\n  Neural Dialog Generation", "comments": "Accepted as a long paper in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder dialog model is one of the most prominent methods used to\nbuild dialog systems in complex domains. Yet it is limited because it cannot\noutput interpretable actions as in traditional systems, which hinders humans\nfrom understanding its generation process. We present an unsupervised discrete\nsentence representation learning method that can integrate with any existing\nencoder-decoder dialog models for interpretable response generation. Building\nupon variational autoencoders (VAEs), we present two novel models, DI-VAE and\nDI-VST that improve VAEs and can discover interpretable semantics via either\nauto encoding or context predicting. Our methods have been validated on\nreal-world dialog datasets to discover semantic representations and enhance\nencoder-decoder models with interpretable generation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 05:08:52 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Lee", "Kyusong", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1804.08096", "submitter": "Xin-She Yang", "authors": "F. De Rango, N. Palmieri, X.S. Yang, S. Marano", "title": "Swarm robotics in wireless distributed protocol design for coordinating\n  robots involved in cooperative tasks", "comments": "Soft Computing, 2017", "journal-ref": null, "doi": "10.1007/s00500-017-2819-9", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mine detection in an unexplored area is an optimization problem where\nmultiple mines, randomly distributed throughout an area, need to be discovered\nand disarmed in a minimum amount of time. We propose a strategy to explore an\nunknown area, using a stigmergy approach based on ants behavior, and a novel\nswarm based protocol to recruit and coordinate robots for disarming the mines\ncooperatively. Simulation tests are presented to show the effectiveness of our\nproposed Ant-based Task Robot Coordination (ATRC) with only the exploration\ntask and with both exploration and recruiting strategies. Multiple minimization\nobjectives have been considered: the robots' recruiting time and the overall\narea exploration time. We discuss, through simulation, different cases under\ndifferent network and field conditions, performed by the robots. The results\nhave shown that the proposed decentralized approaches enable the swarm of\nrobots to perform cooperative tasks intelligently without any central control.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 11:08:07 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["De Rango", "F.", ""], ["Palmieri", "N.", ""], ["Yang", "X. S.", ""], ["Marano", "S.", ""]]}, {"id": "1804.08117", "submitter": "Masatoshi Tsuchiya", "authors": "Masatoshi Tsuchiya", "title": "Performance Impact Caused by Hidden Bias of Training Data for\n  Recognizing Textual Entailment", "comments": "Proceedings of the 11th International Conference on Language\n  Resources and Evaluation (LREC2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of training data is one of the crucial problems when a\nlearning-centered approach is employed. This paper proposes a new method to\ninvestigate the quality of a large corpus designed for the recognizing textual\nentailment (RTE) task. The proposed method, which is inspired by a statistical\nhypothesis test, consists of two phases: the first phase is to introduce the\npredictability of textual entailment labels as a null hypothesis which is\nextremely unacceptable if a target corpus has no hidden bias, and the second\nphase is to test the null hypothesis using a Naive Bayes model. The\nexperimental result of the Stanford Natural Language Inference (SNLI) corpus\ndoes not reject the null hypothesis. Therefore, it indicates that the SNLI\ncorpus has a hidden bias which allows prediction of textual entailment labels\nfrom hypothesis sentences even if no context information is given by a premise\nsentence. This paper also presents the performance impact of NN models for RTE\ncaused by this hidden bias.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 14:26:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Tsuchiya", "Masatoshi", ""]]}, {"id": "1804.08138", "submitter": "Umberto Michieli", "authors": "Umberto Michieli", "title": "Complex Network Analysis of Men Single ATP Tennis Matches", "comments": "Dataset:\n  https://drive.google.com/open?id=1mCxZfkkpIC9o-nxZ1yW3GBBdvBOPW6mQ 12 pages,\n  15 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Who are the most significant players in the history of men tennis? Is the\nofficial ATP ranking system fair in evaluating players scores? Which players\ndeserved the most contemplation looking at their match records? Which players\nhave never faced yet and are likely to play against in the future? Those are\njust some of the questions developed in this paper supported by data updated at\nApril 2018. In order to give an answer to the aforementioned questions, complex\nnetwork science techniques have been applied to some representations of the\nnetwork of men singles tennis matches. Additionally, a new predictive algorithm\nis proposed in order to forecast the winner of a match.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 17:05:51 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Michieli", "Umberto", ""]]}, {"id": "1804.08139", "submitter": "Xipeng Qiu", "authors": "Renjie Zheng, Junkun Chen, Xipeng Qiu", "title": "Same Representation, Different Attentions: Shareable Sentence\n  Representation Learning from Multiple Tasks", "comments": "7 pages", "journal-ref": "IJCAI 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representation plays an important role in deep learning based\nnatural language processing. However, the representation of a sentence often\nvaries in different tasks, which is usually learned from scratch and suffers\nfrom the limited amounts of training data. In this paper, we claim that a good\nsentence representation should be invariant and can benefit the various\nsubsequent tasks. To achieve this purpose, we propose a new scheme of\ninformation sharing for multi-task learning. More specifically, all tasks share\nthe same sentence representation and each task can select the task-specific\ninformation from the shared sentence representation with attention mechanism.\nThe query vector of each task's attention could be either static parameters or\ngenerated dynamically. We conduct extensive experiments on 16 different text\nclassification tasks, which demonstrate the benefits of our architecture.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 17:13:06 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zheng", "Renjie", ""], ["Chen", "Junkun", ""], ["Qiu", "Xipeng", ""]]}, {"id": "1804.08150", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei, Masoud Ghodrati, Saeed Reza Kheradpisheh,\n  Timothee Masquelier, Anthony S. Maida", "title": "Deep Learning in Spiking Neural Networks", "comments": null, "journal-ref": "Neural Networks (2018)", "doi": "10.1016/j.neunet.2018.12.002", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has been a revolution in the field of machine\nlearning, for computer vision in particular. In this approach, a deep\n(multilayer) artificial neural network (ANN) is trained in a supervised manner\nusing backpropagation. Huge amounts of labeled examples are required, but the\nresulting classification accuracy is truly impressive, sometimes outperforming\nhumans. Neurons in an ANN are characterized by a single, static,\ncontinuous-valued activation. Yet biological neurons use discrete spikes to\ncompute and transmit information, and the spike times, in addition to the spike\nrates, matter. Spiking neural networks (SNNs) are thus more biologically\nrealistic than ANNs, and arguably the only viable option if one wants to\nunderstand how the brain computes. SNNs are also more hardware friendly and\nenergy-efficient than ANNs, and are thus appealing for technology, especially\nfor portable devices. However, training deep SNNs remains a challenge. Spiking\nneurons' transfer function is usually non-differentiable, which prevents using\nbackpropagation. Here we review recent supervised and unsupervised methods to\ntrain deep SNNs, and compare them in terms of accuracy, but also computational\ncost and hardware friendliness. The emerging picture is that SNNs still lag\nbehind ANNs in terms of accuracy, but the gap is decreasing, and can even\nvanish on some tasks, while the SNNs typically require much fewer operations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 18:27:34 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 02:48:45 GMT"}, {"version": "v3", "created": "Sat, 1 Sep 2018 14:43:38 GMT"}, {"version": "v4", "created": "Sun, 20 Jan 2019 14:30:40 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Ghodrati", "Masoud", ""], ["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timothee", ""], ["Maida", "Anthony S.", ""]]}, {"id": "1804.08187", "submitter": "Yi Fan", "authors": "Yi Fan, Nan Li, Chengqian Li, Zongjie Ma, Longin Jan Latecki, Kaile Su", "title": "Advancing Tabu and Restart in Local Search for Maximum Weight Cliques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tabu and restart are two fundamental strategies for local search. In this\npaper, we improve the local search algorithms for solving the Maximum Weight\nClique (MWC) problem by introducing new tabu and restart strategies. Both the\ntabu and restart strategies proposed are based on the notion of a local search\nscenario, which involves not only a candidate solution but also the tabu status\nand unlocking relationship. Compared to the strategy of configuration checking,\nour tabu mechanism discourages forming a cycle of unlocking operations. Our new\nrestart strategy is based on the re-occurrence of a local search scenario\ninstead of that of a candidate solution. Experimental results show that the\nresulting MWC solver outperforms several state-of-the-art solvers on the\nDIMACS, BHOSLIB, and two benchmarks from practical applications.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 22:36:00 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Fan", "Yi", ""], ["Li", "Nan", ""], ["Li", "Chengqian", ""], ["Ma", "Zongjie", ""], ["Latecki", "Longin Jan", ""], ["Su", "Kaile", ""]]}, {"id": "1804.08204", "submitter": "Jatin Ganhotra", "authors": "Jatin Ganhotra, Lazaros Polymenakos", "title": "Knowledge-based end-to-end memory networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end dialog systems have become very popular because they hold the\npromise of learning directly from human to human dialog interaction. Retrieval\nand Generative methods have been explored in this area with mixed results. A\nkey element that is missing so far, is the incorporation of a-priori knowledge\nabout the task at hand. This knowledge may exist in the form of structured or\nunstructured information. As a first step towards this direction, we present a\nnovel approach, Knowledge based end-to-end memory networks (KB-memN2N), which\nallows special handling of named entities for goal-oriented dialog tasks. We\npresent results on two datasets, DSTC6 challenge dataset and dialog bAbI tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 00:47:48 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Ganhotra", "Jatin", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1804.08208", "submitter": "Peng Gao", "authors": "Peng Gao, Yipeng Ma, Ke Song, Chao Li, Fei Wang, Liyi Xiao, Yan Zhang", "title": "High Performance Visual Tracking with Circular and Structural Operators", "comments": "Accepted to Knowledge-Based SYSTEMS", "journal-ref": null, "doi": "10.1016/j.knosys.2018.08.008", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel circular and structural operator tracker (CSOT) is\nproposed for high performance visual tracking, it not only possesses the\npowerful discriminative capability of SOSVM but also efficiently inherits the\nsuperior computational efficiency of DCF. Based on the proposed circular and\nstructural operators, a set of primal confidence score maps can be obtained by\ncircular correlating feature maps with their corresponding structural\ncorrelation filters. Furthermore, an implicit interpolation is applied to\nconvert the multi-resolution feature maps to the continuous domain and make all\nprimal confidence score maps have the same spatial resolution. Then, we exploit\nan efficient ensemble post-processor based on relative entropy, which can\ncoalesce primal confidence score maps and create an optimal confidence score\nmap for more accurate localization. The target is localized on the peak of the\noptimal confidence score map. Besides, we introduce a collaborative\noptimization strategy to update circular and structural operators by\niteratively training structural correlation filters, which significantly\nreduces computational complexity and improves robustness. Experimental results\ndemonstrate that our approach achieves state-of-the-art performance in mean AUC\nscores of 71.5% and 69.4% on the OTB-2013 and OTB-2015 benchmarks respectively,\nand obtains a third-best expected average overlap (EAO) score of 29.8% on the\nVOT-2017 benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 01:08:43 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 08:34:03 GMT"}, {"version": "v3", "created": "Sat, 13 Oct 2018 07:06:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Gao", "Peng", ""], ["Ma", "Yipeng", ""], ["Song", "Ke", ""], ["Li", "Chao", ""], ["Wang", "Fei", ""], ["Xiao", "Liyi", ""], ["Zhang", "Yan", ""]]}, {"id": "1804.08219", "submitter": "Dicong Qiu", "authors": "Dicong Qiu and Karthik Paga", "title": "Adaptive Performance Assessment For Drivers Through Behavioral Advantage", "comments": "10 pages, 3 figures. Appeared in the Proceedings of the 1st Hackauton\n  Machine Learning Hackathon (Hackauton 2018), Pittsburgh, United States, 2018.\n  First Place Winner (Fuel Efficiency Problem); Most Innovative Prize", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential positive impact of autonomous driving and driver assistance\ntechnolo- gies have been a major impetus over the last decade. On the flip\nside, it has been a challenging problem to analyze the performance of human\ndrivers or autonomous driving agents quantitatively. In this work, we propose a\ngeneric method that compares the performance of drivers or autonomous driving\nagents even if the environmental conditions are different, by using the driver\nbehavioral advantage instead of absolute metrics, which efficiently removes the\nenvironmental factors. A concrete application of the method is also presented,\nwhere the performance of more than 100 truck drivers was evaluated and ranked\nin terms of fuel efficiency, covering more than 90,000 trips spanning an\naverage of 300 miles in a variety of driving conditions and environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 01:57:30 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 17:04:48 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Qiu", "Dicong", ""], ["Paga", "Karthik", ""]]}, {"id": "1804.08229", "submitter": "Shiqi Zhang", "authors": "Yuqian Jiang and Shiqi Zhang and Piyush Khandelwal and Peter Stone", "title": "Task Planning in Robotics: an Empirical Comparison of PDDL-based and\n  ASP-based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots need task planning algorithms to sequence actions toward accomplishing\ngoals that are impossible through individual actions. Off-the-shelf task\nplanners can be used by intelligent robotics practitioners to solve a variety\nof planning problems. However, many different planners exist, each with\ndifferent strengths and weaknesses, and there are no general rules for which\nplanner would be best to apply to a given problem.\n  In this article, we empirically compare the performance of state-of-the-art\nplanners that use either the Planning Domain Description Language (PDDL), or\nAnswer Set Programming (ASP) as the underlying action language. PDDL is\ndesigned for task planning, and PDDL-based planners are widely used for a\nvariety of planning problems. ASP is designed for knowledge-intensive\nreasoning, but can also be used for solving task planning problems. Given\ndomain encodings that are as similar as possible, we find that PDDL-based\nplanners perform better on problems with longer solutions, and ASP-based\nplanners are better on tasks with a large number of objects or in which complex\nreasoning is required to reason about action preconditions and effects. The\nresulting analysis can inform selection among general purpose planning systems\nfor particular robot task planning domains.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 02:46:36 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 04:29:32 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 23:28:49 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Jiang", "Yuqian", ""], ["Zhang", "Shiqi", ""], ["Khandelwal", "Piyush", ""], ["Stone", "Peter", ""]]}, {"id": "1804.08256", "submitter": "Jiagao Hu", "authors": "Jiagao Hu, Zhengxing Sun, Yunhan Sun, Jinlong Shi", "title": "Progressive refinement: a method of coarse-to-fine image parsing using\n  stacked network", "comments": "Accepted for presentation in an ORAL session at ICME 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To parse images into fine-grained semantic parts, the complex fine-grained\nelements will put it in trouble when using off-the-shelf semantic segmentation\nnetworks. In this paper, for image parsing task, we propose to parse images\nfrom coarse to fine with progressively refined semantic classes. It is achieved\nby stacking the segmentation layers in a segmentation network several times.\nThe former segmentation module parses images at a coarser-grained level, and\nthe result will be feed to the following one to provide effective contextual\nclues for the finer-grained parsing. To recover the details of small\nstructures, we add skip connections from shallow layers of the network to\nfine-grained parsing modules. As for the network training, we merge classes in\ngroundtruth to get coarse-to-fine label maps, and train the stacked network\nwith these hierarchical supervision end-to-end. Our coarse-to-fine stacked\nframework can be injected into many advanced neural networks to improve the\nparsing results. Extensive evaluations on several public datasets including\nface parsing and human parsing well demonstrate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 06:33:53 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Hu", "Jiagao", ""], ["Sun", "Zhengxing", ""], ["Sun", "Yunhan", ""], ["Shi", "Jinlong", ""]]}, {"id": "1804.08299", "submitter": "Antonio Lieto", "authors": "Antonio Chella, Marcello Frixione, Antonio Lieto", "title": "Representational Issues in the Debate on the Standard Model of the Mind", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": "Paper is published in the 2017 AAAI Fall Symposium Series, FS-17-05,\n  pp. 302-307", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss some of the issues concerning the Memory and Content\naspects in the recent debate on the identification of a Standard Model of the\nMind (Laird, Lebiere, and Rosenbloom in press). In particular, we focus on the\nrepresentational models concerning the Declarative Memories of current\nCognitive Architectures (CAs). In doing so we outline some of the main problems\naffecting the current CAs and suggest that the Conceptual Spaces, a\nrepresentational framework developed by Gardenfors, is worth-considering to\naddress such problems. Finally, we briefly analyze the alternative\nrepresentational assumptions employed in the three CAs constituting the current\nbaseline for the Standard Model (i.e. SOAR, ACT-R and Sigma). In doing so, we\npoint out the respective differences and discuss their implications in the\nlight of the analyzed problems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 09:06:08 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Chella", "Antonio", ""], ["Frixione", "Marcello", ""], ["Lieto", "Antonio", ""]]}, {"id": "1804.08316", "submitter": "Josu Goikoetxea", "authors": "J.Goikoetxea, A.Soroa, E.Agirre", "title": "Bilingual Embeddings with Random Walks over Multilingual Wordnets", "comments": "Preprint version, Knowledge-Based Systems (ISSN: 0950-7051). (2018)", "journal-ref": null, "doi": "10.1016/j.knosys.2018.03.017", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual word embeddings represent words of two languages in the same space,\nand allow to transfer knowledge from one language to the other without machine\ntranslation. The main approach is to train monolingual embeddings first and\nthen map them using bilingual dictionaries. In this work, we present a novel\nmethod to learn bilingual embeddings based on multilingual knowledge bases (KB)\nsuch as WordNet. Our method extracts bilingual information from multilingual\nwordnets via random walks and learns a joint embedding space in one go. We\nfurther reinforce cross-lingual equivalence adding bilingual con- straints in\nthe loss function of the popular skipgram model. Our experiments involve twelve\ncross-lingual word similarity and relatedness datasets in six lan- guage pairs\ncovering four languages, and show that: 1) random walks over mul- tilingual\nwordnets improve results over just using dictionaries; 2) multilingual wordnets\non their own improve over text-based systems in similarity datasets; 3) the\ngood results are consistent for large wordnets (e.g. English, Spanish), smaller\nwordnets (e.g. Basque) or loosely aligned wordnets (e.g. Italian); 4) the\ncombination of wordnets and text yields the best results, above mapping-based\napproaches. Our method can be applied to richer KBs like DBpedia or Babel- Net,\nand can be easily extended to multilingual embeddings. All software and\nresources are open source.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 10:02:29 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Goikoetxea", "J.", ""], ["Soroa", "A.", ""], ["Agirre", "E.", ""]]}, {"id": "1804.08328", "submitter": "Amir Zamir", "authors": "Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra\n  Malik, Silvio Savarese", "title": "Taskonomy: Disentangling Task Transfer Learning", "comments": "CVPR 2018 (Oral). See project website and live demos at\n  http://taskonomy.vision/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do visual tasks have a relationship, or are they unrelated? For instance,\ncould having surface normals simplify estimating the depth of an image?\nIntuition answers these questions positively, implying existence of a structure\namong visual tasks. Knowing this structure has notable values; it is the\nconcept underlying transfer learning and provides a principled way for\nidentifying redundancies across tasks, e.g., to seamlessly reuse supervision\namong related tasks or solve many tasks in one system without piling up the\ncomplexity.\n  We proposes a fully computational approach for modeling the structure of\nspace of visual tasks. This is done via finding (first and higher-order)\ntransfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,\nand semantic tasks in a latent space. The product is a computational taxonomic\nmap for task transfer learning. We study the consequences of this structure,\ne.g. nontrivial emerged relationships, and exploit them to reduce the demand\nfor labeled data. For example, we show that the total number of labeled\ndatapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3\n(compared to training independently) while keeping the performance nearly the\nsame. We provide a set of tools for computing and probing this taxonomical\nstructure including a solver that users can employ to devise efficient\nsupervision policies for their use cases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 10:46:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zamir", "Amir", ""], ["Sax", "Alexander", ""], ["Shen", "William", ""], ["Guibas", "Leonidas", ""], ["Malik", "Jitendra", ""], ["Savarese", "Silvio", ""]]}, {"id": "1804.08378", "submitter": "Nicolas Weber", "authors": "Nicolas Weber, Florian Schmidt, Mathias Niepert, Felipe Huici", "title": "BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First\n  Parallelism", "comments": "Technical Report, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CV cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network frameworks such as PyTorch and TensorFlow are the workhorses\nof numerous machine learning applications ranging from object recognition to\nmachine translation. While these frameworks are versatile and straightforward\nto use, the training of and inference in deep neural networks is resource\n(energy, compute, and memory) intensive. In contrast to recent works focusing\non algorithmic enhancements, we introduce BrainSlug, a framework that\ntransparently accelerates neural network workloads by changing the default\nlayer-by-layer processing to a depth-first approach, reducing the amount of\ndata required by the computations and thus improving the performance of the\navailable hardware caches. BrainSlug achieves performance improvements of up to\n41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the\nuser as they do not require hardware changes and only need tiny adjustments to\nthe software.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:49:04 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Weber", "Nicolas", ""], ["Schmidt", "Florian", ""], ["Niepert", "Mathias", ""], ["Huici", "Felipe", ""]]}, {"id": "1804.08426", "submitter": "G\\\"unter Neumann GN", "authors": "Tyler Renslow and G\\\"unter Neumann", "title": "LightRel SemEval-2018 Task 7: Lightweight and Fast Relation\n  Classification", "comments": "SemEval-2018 task 7 Semantic Relation Extraction and Classification\n  in Scientific Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LightRel, a lightweight and fast relation classifier. Our goal is\nto develop a high baseline for different relation extraction tasks. By defining\nonly very few data-internal, word-level features and external knowledge sources\nin the form of word clusters and word embeddings, we train a fast and simple\nlinear classifier.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:42:01 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Renslow", "Tyler", ""], ["Neumann", "G\u00fcnter", ""]]}, {"id": "1804.08454", "submitter": "Akilesh Badrinaaraayanan", "authors": "Akilesh B, Abhishek Sinha, Mausoom Sarkar, Balaji Krishnamurthy", "title": "Attention Based Natural Language Grounding by Navigating Virtual\n  Environment", "comments": "Accepted at WACV 2019. Also at NeurIPS 2017 workshop on\n  Visually-Grounded Interaction and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of grounding language by training an\nagent to follow a set of natural language instructions and navigate to a target\nobject in an environment. The agent receives visual information through raw\npixels and a natural language instruction telling what task needs to be\nachieved and is trained in an end-to-end way. We develop an attention mechanism\nfor multi-modal fusion of visual and textual modalities that allows the agent\nto learn to complete the task and achieve language grounding. Our experimental\nresults show that our attention mechanism outperforms the existing multi-modal\nfusion mechanisms proposed for both 2D and 3D environments in order to solve\nthe above-mentioned task in terms of both speed and success rate. We show that\nthe learnt textual representations are semantically meaningful as they follow\nvector arithmetic in the embedding space. The effectiveness of our attention\napproach over the contemporary fusion mechanisms is also highlighted from the\ntextual embeddings learnt by the different approaches. We also show that our\nmodel generalizes effectively to unseen scenarios and exhibit zero-shot\ngeneralization capabilities both in 2D and 3D environments. The code for our 2D\nenvironment as well as the models that we developed for both 2D and 3D are\navailable at https://github.com/rl-lang-grounding/rl-lang-ground.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:11:17 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 19:00:54 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["B", "Akilesh", ""], ["Sinha", "Abhishek", ""], ["Sarkar", "Mausoom", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1804.08473", "submitter": "Bei Liu", "authors": "Bei Liu, Jianlong Fu, Makoto P. Kato, Masatoshi Yoshikawa", "title": "Beyond Narrative Description: Generating Poetry from Images by\n  Multi-Adversarial Training", "comments": null, "journal-ref": null, "doi": "10.1145/3240508.3240587", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of natural language from images has attracted extensive\nattention. In this paper, we take one step further to investigate generation of\npoetic language (with multiple lines) to an image for automatic poetry\ncreation. This task involves multiple challenges, including discovering poetic\nclues from the image (e.g., hope from green), and generating poems to satisfy\nboth relevance to the image and poeticness in language level. To solve the\nabove challenges, we formulate the task of poem generation into two correlated\nsub-tasks by multi-adversarial training via policy gradient, through which the\ncross-modal relevance and poetic language style can be ensured. To extract\npoetic clues from images, we propose to learn a deep coupled visual-poetic\nembedding, in which the poetic representation from objects, sentiments and\nscenes in an image can be jointly learned. Two discriminative networks are\nfurther introduced to guide the poem generation, including a multi-modal\ndiscriminator and a poem-style discriminator. To facilitate the research, we\nhave released two poem datasets by human annotators with two distinct\nproperties: 1) the first human annotated image-to-poem pair dataset (with 8,292\npairs in total), and 2) to-date the largest public English poem corpus dataset\n(with 92,265 different poems in total). Extensive experiments are conducted\nwith 8K images, among which 1.5K image are randomly picked for evaluation. Both\nobjective and subjective evaluations show the superior performances against the\nstate-of-the-art methods for poem generation from images. Turing test carried\nout with over 500 human subjects, among which 30 evaluators are poetry experts,\ndemonstrates the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:35:59 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 06:45:53 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2018 07:35:26 GMT"}, {"version": "v4", "created": "Wed, 10 Oct 2018 03:23:38 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Liu", "Bei", ""], ["Fu", "Jianlong", ""], ["Kato", "Makoto P.", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "1804.08497", "submitter": "Rana Hanocka", "authors": "Rana Hanocka, Noa Fish, Zhenhua Wang, Raja Giryes, Shachar Fleishman\n  and Daniel Cohen-Or", "title": "ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning", "comments": "To be presented at SIGGRAPH Asia 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of aligning a pair of shapes is a fundamental operation in\ncomputer graphics. Traditional approaches rely heavily on matching\ncorresponding points or features to guide the alignment, a paradigm that\nfalters when significant shape portions are missing. These techniques generally\ndo not incorporate prior knowledge about expected shape characteristics, which\ncan help compensate for any misleading cues left by inaccuracies exhibited in\nthe input shapes. We present an approach based on a deep neural network,\nleveraging shape datasets to learn a shape-aware prior for source-to-target\nalignment that is robust to shape incompleteness. In the absence of ground\ntruth alignments for supervision, we train a network on the task of shape\nalignment using incomplete shapes generated from full shapes for\nself-supervision. Our network, called ALIGNet, is trained to warp complete\nsource shapes to incomplete targets, as if the target shapes were complete,\nthus essentially rendering the alignment partial-shape agnostic. We aim for the\nnetwork to develop specialized expertise over the common characteristics of the\nshapes in each dataset, thereby achieving a higher-level understanding of the\nexpected shape space to which a local approach would be oblivious. We constrain\nALIGNet through an anisotropic total variation identity regularization to\npromote piecewise smooth deformation fields, facilitating both partial-shape\nagnosticism and post-deformation applications. We demonstrate that ALIGNet\nlearns to align geometrically distinct shapes, and is able to infer plausible\nmappings even when the target shape is significantly incomplete. We show that\nour network learns the common expected characteristics of shape collections,\nwithout over-fitting or memorization, enabling it to produce plausible\ndeformations on unseen data during test time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 15:17:26 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:26:39 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Hanocka", "Rana", ""], ["Fish", "Noa", ""], ["Wang", "Zhenhua", ""], ["Giryes", "Raja", ""], ["Fleishman", "Shachar", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1804.08597", "submitter": "Artur Garcez", "authors": "Artur d'Avila Garcez and Aimore Resende Riquetti Dutra and Eduardo\n  Alonso", "title": "Towards Symbolic Reinforcement Learning with Common Sense", "comments": "15 pages, 13 figures, 26 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (deep RL) has made several breakthroughs in\nrecent years in applications ranging from complex control tasks in unmanned\nvehicles to game playing. Despite their success, deep RL still lacks several\nimportant capacities of human intelligence, such as transfer learning,\nabstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)\nseeks to incorporate such capacities to deep Q-networks (DQN) by learning a\nrelevant symbolic representation prior to using Q-learning. In this paper, we\npropose a novel extension of DSRL, which we call Symbolic Reinforcement\nLearning with Common Sense (SRL+CS), offering a better balance between\ngeneralization and specialization, inspired by principles of common sense when\nassigning rewards and aggregating Q-values. Experiments reported in this paper\nshow that SRL+CS learns consistently faster than Q-learning and DSRL, achieving\nalso a higher accuracy. In the hardest case, where agents were trained in a\ndeterministic environment and tested in a random environment, SRL+CS achieves\nnearly 100% average accuracy compared to DSRL's 70% and DQN's 50% accuracy. To\nthe best of our knowledge, this is the first case of near perfect zero-shot\ntransfer learning using Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:44:29 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Garcez", "Artur d'Avila", ""], ["Dutra", "Aimore Resende Riquetti", ""], ["Alonso", "Eduardo", ""]]}, {"id": "1804.08606", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Parsa Mahmoudieh, Guanghao Luo, Pulkit Agrawal, Dian\n  Chen, Yide Shentu, Evan Shelhamer, Jitendra Malik, Alexei A. Efros, Trevor\n  Darrell", "title": "Zero-Shot Visual Imitation", "comments": "Oral presentation at ICLR 2018. Website at\n  https://pathak22.github.io/zeroshot-imitation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current dominant paradigm for imitation learning relies on strong\nsupervision of expert actions to learn both 'what' and 'how' to imitate. We\npursue an alternative paradigm wherein an agent first explores the world\nwithout any expert supervision and then distills its experience into a\ngoal-conditioned skill policy with a novel forward consistency loss. In our\nframework, the role of the expert is only to communicate the goals (i.e., what\nto imitate) during inference. The learned policy is then employed to mimic the\nexpert (i.e., how to imitate) after seeing just a sequence of images\ndemonstrating the desired task. Our method is 'zero-shot' in the sense that the\nagent never has access to expert actions during training or for the task\ndemonstration at inference. We evaluate our zero-shot imitator in two\nreal-world settings: complex rope manipulation with a Baxter robot and\nnavigation in previously unseen office environments with a TurtleBot. Through\nfurther experiments in VizDoom simulation, we provide evidence that better\nmechanisms for exploration lead to learning a more capable policy which in turn\nimproves end task performance. Videos, models, and more details are available\nat https://pathak22.github.io/zeroshot-imitation/\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:58:26 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Pathak", "Deepak", ""], ["Mahmoudieh", "Parsa", ""], ["Luo", "Guanghao", ""], ["Agrawal", "Pulkit", ""], ["Chen", "Dian", ""], ["Shentu", "Yide", ""], ["Shelhamer", "Evan", ""], ["Malik", "Jitendra", ""], ["Efros", "Alexei A.", ""], ["Darrell", "Trevor", ""]]}, {"id": "1804.08607", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov, Adi Makmal, Hans J. Briegel", "title": "Benchmarking projective simulation in navigation problems", "comments": "8 pages, 10 figures", "journal-ref": "IEEE Access 6, 64639 (2018)", "doi": "10.1109/ACCESS.2018.2876494", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projective simulation (PS) is a model for intelligent agents with a\ndeliberation capacity that is based on episodic memory. The model has been\nshown to provide a flexible framework for constructing reinforcement-learning\nagents, and it allows for quantum mechanical generalization, which leads to a\nspeed-up in deliberation time. PS agents have been applied successfully in the\ncontext of complex skill learning in robotics, and in the design of\nstate-of-the-art quantum experiments. In this paper, we study the performance\nof projective simulation in two benchmarking problems in navigation, namely the\ngrid world and the mountain car problem. The performance of PS is compared to\nstandard tabular reinforcement learning approaches, Q-learning and SARSA. Our\ncomparison demonstrates that the performance of PS and standard learning\napproaches are qualitatively and quantitatively similar, while it is much\neasier to choose optimal model parameters in case of projective simulation,\nwith a reduced computational effort of one to two orders of magnitude. Our\nresults show that the projective simulation model stands out for its simplicity\nin terms of the number of model parameters, which makes it simple to set up the\nlearning agent in unknown task environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:58:27 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Makmal", "Adi", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1804.08617", "submitter": "Matthew W. Hoffman", "authors": "Gabriel Barth-Maron, Matthew W. Hoffman, David Budden, Will Dabney,\n  Dan Horgan, Dhruva TB, Alistair Muldal, Nicolas Heess, Timothy Lillicrap", "title": "Distributed Distributional Deterministic Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work adopts the very successful distributional perspective on\nreinforcement learning and adapts it to the continuous control setting. We\ncombine this within a distributed framework for off-policy learning in order to\ndevelop what we call the Distributed Distributional Deep Deterministic Policy\nGradient algorithm, D4PG. We also combine this technique with a number of\nadditional, simple improvements such as the use of $N$-step returns and\nprioritized experience replay. Experimentally we examine the contribution of\neach of these individual components, and show how they interact, as well as\ntheir combined contributions. Our results show that across a wide variety of\nsimple control tasks, difficult manipulation tasks, and a set of hard\nobstacle-based locomotion tasks the D4PG algorithm achieves state of the art\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:57:21 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Barth-Maron", "Gabriel", ""], ["Hoffman", "Matthew W.", ""], ["Budden", "David", ""], ["Dabney", "Will", ""], ["Horgan", "Dan", ""], ["TB", "Dhruva", ""], ["Muldal", "Alistair", ""], ["Heess", "Nicolas", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.08619", "submitter": "Weichao Li", "authors": "Weichao Li, Fuxian Huang, Xi Li, Gang Pan and Fei Wu", "title": "State Distribution-aware Sampling for Deep Q-learning", "comments": "this paper has been submitted to neural processing letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical and challenging problem in reinforcement learning is how to learn\nthe state-action value function from the experience replay buffer and\nsimultaneously keep sample efficiency and faster convergence to a high quality\nsolution. In prior works, transitions are uniformly sampled at random from the\nreplay buffer or sampled based on their priority measured by\ntemporal-difference (TD) error. However, these approaches do not fully take\ninto consideration the intrinsic characteristics of transition distribution in\nthe state space and could result in redundant and unnecessary TD updates,\nslowing down the convergence of the learning procedure. To overcome this\nproblem, we propose a novel state distribution-aware sampling method to balance\nthe replay times for transitions with skew distribution, which takes into\naccount both the occurrence frequencies of transitions and the uncertainty of\nstate-action values. Consequently, our approach could reduce the unnecessary TD\nupdates and increase the TD updates for state-action value with more\nuncertainty, making the experience replay more effective and efficient.\nExtensive experiments are conducted on both classic control tasks and Atari\n2600 games based on OpenAI gym platform and the experimental results\ndemonstrate the effectiveness of our approach in comparison with the standard\nDQN approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:22:22 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Li", "Weichao", ""], ["Huang", "Fuxian", ""], ["Li", "Xi", ""], ["Pan", "Gang", ""], ["Wu", "Fei", ""]]}, {"id": "1804.08667", "submitter": "Daniel Fu", "authors": "Daniel Y. Fu, Emily S. Wang, Peter M. Krafft, Barbara J. Grosz", "title": "Influencing Flock Formation in Low-Density Settings", "comments": "9 pages, 5 figures, accepted to AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flocking is a coordinated collective behavior that results from local sensing\nbetween individual agents that have a tendency to orient towards each other.\nFlocking is common among animal groups and might also be useful in robotic\nswarms. In the interest of learning how to control flocking behavior, recent\nwork in the multiagent systems literature has explored the use of influencing\nagents for guiding flocking agents to face a target direction. The existing\nwork in this domain has focused on simulation settings of small areas with\ntoroidal shapes. In such settings, agent density is high, so interactions are\ncommon, and flock formation occurs easily. In our work, we study new\nenvironments with lower agent density, wherein interactions are more rare. We\nstudy the efficacy of placement strategies and influencing agent behaviors\ndrawn from the literature, and find that the behaviors that have been shown to\nwork well in high-density conditions tend to be much less effective in lower\ndensity environments. The source of this ineffectiveness is that the\ninfluencing agents explored in prior work tended to face directions optimized\nfor maximal influence, but which actually separate the influencing agents from\nthe flock. We find that in low-density conditions maintaining a connection to\nthe flock is more important than rushing to orient towards the desired\ndirection. We use these insights to propose new influencing agent behaviors,\nwhich we dub \"follow-then-influence\"; agents act like normal members of the\nflock to achieve positions that allow for control and then exert their\ninfluence. This strategy overcomes the difficulties posed by low density\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:55:05 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Fu", "Daniel Y.", ""], ["Wang", "Emily S.", ""], ["Krafft", "Peter M.", ""], ["Grosz", "Barbara J.", ""]]}, {"id": "1804.08748", "submitter": "Sobhan Moosavi", "authors": "Sobhan Moosavi, Arnab Nandi, Rajiv Ramnath", "title": "Discovery of Driving Patterns by Trajectory Segmentation", "comments": "Accepted in the 3rd PhD workshop, ACM SIGSPATIAL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telematics data is becoming increasingly available due to the ubiquity of\ndevices that collect data during drives, for different purposes, such as usage\nbased insurance (UBI), fleet management, navigation of connected vehicles, etc.\nConsequently, a variety of data-analytic applications have become feasible that\nextract valuable insights from the data. In this paper, we address the\nespecially challenging problem of discovering behavior-based driving patterns\nfrom only externally observable phenomena (e.g. vehicle's speed). We present a\ntrajectory segmentation approach capable of discovering driving patterns as\nseparate segments, based on the behavior of drivers. This segmentation approach\nincludes a novel transformation of trajectories along with a dynamic\nprogramming approach for segmentation. We apply the segmentation approach on a\nreal-word, rich dataset of personal car trajectories provided by a major\ninsurance company based in Columbus, Ohio. Analysis and preliminary results\nshow the applicability of approach for finding significant driving patterns.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:28:04 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 06:02:17 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Moosavi", "Sobhan", ""], ["Nandi", "Arnab", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1804.08750", "submitter": "Aditya Chindhade", "authors": "Aditya Chindhade, Abhijeet Alshi, Aakash Bhatia, Kedar Dabhadkar,\n  Pranav Sivadas Menon", "title": "A machine learning model for identifying cyclic alternating patterns in\n  the sleeping brain", "comments": "Presented at HackAuton, Auton Lab, Carnegie Mellon University.\n  Problem credits: Philips", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is a method to record the electrical signals in\nthe brain. Recognizing the EEG patterns in the sleeping brain gives insights\ninto the understanding of sleeping disorders. The dataset under consideration\ncontains EEG data points associated with various physiological conditions. This\nstudy attempts to generalize the detection of particular patterns associated\nwith the Non-Rapid Eye Movement (NREM) sleep cycle of the brain using a machine\nlearning model. The proposed model uses additional feature engineering to\nincorporate sequential information for training a classifier to predict the\noccurrence of Cyclic Alternating Pattern (CAP) sequences in the sleep cycle,\nwhich are often associated with sleep disorders.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:29:56 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Chindhade", "Aditya", ""], ["Alshi", "Abhijeet", ""], ["Bhatia", "Aakash", ""], ["Dabhadkar", "Kedar", ""], ["Menon", "Pranav Sivadas", ""]]}, {"id": "1804.08798", "submitter": "Michael Petrochuk", "authors": "Michael Petrochuk and Luke Zettlemoyer", "title": "SimpleQuestions Nearly Solved: A New Upperbound and Baseline Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SimpleQuestions dataset is one of the most commonly used benchmarks for\nstudying single-relation factoid questions. In this paper, we present new\nevidence that this benchmark can be nearly solved by standard methods. First we\nshow that ambiguity in the data bounds performance on this benchmark at 83.4%;\nthere are often multiple answers that cannot be disambiguated from the\nlinguistic signal alone. Second we introduce a baseline that sets a new\nstate-of-the-art performance level at 78.1% accuracy, despite using standard\nmethods. Finally, we report an empirical analysis showing that the upperbound\nis loose; roughly a third of the remaining errors are also not resolvable from\nthe linguistic signal. Together, these results suggest that the SimpleQuestions\ndataset is nearly solved.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 01:24:35 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Petrochuk", "Michael", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1804.08833", "submitter": "Suchismit Mahapatra", "authors": "Suchismit Mahapatra, Varun Chandola", "title": "Learning Manifolds from Non-stationary Streaming Data", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming adaptations of manifold learning based dimensionality reduction\nmethods, such as Isomap, are based on the assumption that a small initial batch\nof observations is enough for exact learning of the manifold, while remaining\nstreaming data instances can be cheaply mapped to this manifold. However, there\nare no theoretical results to show that this core assumption is valid.\nMoreover, such methods typically assume that the underlying data distribution\nis stationary. Such methods are not equipped to detect, or handle, sudden\nchanges or gradual drifts in the distribution that may occur when the data is\nstreaming. We present theoretical results to show that the quality of a\nmanifold asymptotically converges as the size of data increases. We then show\nthat a Gaussian Process Regression (GPR) model, that uses a manifold-specific\nkernel function and is trained on an initial batch of sufficient size, can\nclosely approximate the state-of-art streaming Isomap algorithms. The\npredictive variance obtained from the GPR prediction is then shown to be an\neffective detector of changes in the underlying data distribution. Results on\nseveral synthetic and real data sets show that the resulting algorithm can\neffectively learn lower dimensional representation of high dimensional data in\na streaming setting, while identifying shifts in the generative distribution.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 03:59:48 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 22:25:12 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 19:38:30 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Mahapatra", "Suchismit", ""], ["Chandola", "Varun", ""]]}, {"id": "1804.08834", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Measuring and Computing Database Inconsistency via Repairs", "comments": "Submission as short paper; to appear in Proc. Scalable Uncertainty\n  Management, SUM 2018. Abstract and keywords added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic numerical measure of inconsistency of a database with\nrespect to a set of integrity constraints. It is based on an abstract repair\nsemantics. A particular inconsistency measure associated to cardinality-repairs\nis investigated; and we show that it can be computed via answer-set programs.\n  Keywords: Integrity constraints in databases, inconsistent databases,\ndatabase repairs, inconsistency measure.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 04:04:27 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 01:50:28 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2018 20:42:04 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "1804.08924", "submitter": "Guillermo P\\'erez", "authors": "Jan K\\v{r}et\\'insk\\'y, Guillermo A. P\\'erez, Jean-Fran\\c{c}ois Raskin", "title": "Learning-Based Mean-Payoff Optimization in an Unknown MDP under\n  Omega-Regular Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the problem of maximizing the mean-payoff value with high\nprobability while satisfying a parity objective in a Markov decision process\n(MDP) with unknown probabilistic transition function and unknown reward\nfunction. Assuming the support of the unknown transition function and a lower\nbound on the minimal transition probability are known in advance, we show that\nin MDPs consisting of a single end component, two combinations of guarantees on\nthe parity and mean-payoff objectives can be achieved depending on how much\nmemory one is willing to use. (i) For all $\\epsilon$ and $\\gamma$ we can\nconstruct an online-learning finite-memory strategy that almost-surely\nsatisfies the parity objective and which achieves an $\\epsilon$-optimal mean\npayoff with probability at least $1 - \\gamma$. (ii) Alternatively, for all\n$\\epsilon$ and $\\gamma$ there exists an online-learning infinite-memory\nstrategy that satisfies the parity objective surely and which achieves an\n$\\epsilon$-optimal mean payoff with probability at least $1 - \\gamma$. We\nextend the above results to MDPs consisting of more than one end component in a\nnatural way. Finally, we show that the aforementioned guarantees are tight,\ni.e. there are MDPs for which stronger combinations of the guarantees cannot be\nensured.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 09:35:27 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 12:04:19 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 07:54:50 GMT"}, {"version": "v4", "created": "Thu, 23 Aug 2018 15:24:36 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1804.08984", "submitter": "Amir Kafshdar Goharshady", "authors": "Krishnendu Chatterjee, Hongfei Fu, Amir Kafshdar Goharshady, Nastaran\n  Okati", "title": "Computational Approaches for Stochastic Shortest Path on Succinct MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic shortest path (SSP) problem for succinct Markov\ndecision processes (MDPs), where the MDP consists of a set of variables, and a\nset of nondeterministic rules that update the variables. First, we show that\nseveral examples from the AI literature can be modeled as succinct MDPs. Then\nwe present computational approaches for upper and lower bounds for the SSP\nproblem: (a)~for computing upper bounds, our method is polynomial-time in the\nimplicit description of the MDP; (b)~for lower bounds, we present a\npolynomial-time (in the size of the implicit description) reduction to\nquadratic programming. Our approach is applicable even to infinite-state MDPs.\nFinally, we present experimental results to demonstrate the effectiveness of\nour approach on several classical examples from the AI literature.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 12:26:37 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 10:37:41 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2018 09:27:59 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Fu", "Hongfei", ""], ["Goharshady", "Amir Kafshdar", ""], ["Okati", "Nastaran", ""]]}, {"id": "1804.09021", "submitter": "Zhenghui Wang", "authors": "Zhenghui Wang, Yanru Qu, Liheng Chen, Jian Shen, Weinan Zhang,\n  Shaodian Zhang, Yimei Gao, Gen Gu, Ken Chen, Yong Yu", "title": "Label-aware Double Transfer Learning for Cross-Specialty Medical Named\n  Entity Recognition", "comments": "NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of named entity recognition (NER) from electronic\nmedical records, which is one of the most fundamental and critical problems for\nmedical text mining. Medical records which are written by clinicians from\ndifferent specialties usually contain quite different terminologies and writing\nstyles. The difference of specialties and the cost of human annotation makes it\nparticularly difficult to train a universal medical NER system. In this paper,\nwe propose a label-aware double transfer learning framework (La-DTL) for\ncross-specialty NER, so that a medical NER system designed for one specialty\ncould be conveniently applied to another one with minimal annotation efforts.\nThe transferability is guaranteed by two components: (i) we propose label-aware\nMMD for feature representation transfer, and (ii) we perform parameter transfer\nwith a theoretical upper bound which is also label aware. We conduct extensive\nexperiments on 12 cross-specialty NER tasks. The experimental results\ndemonstrate that La-DTL provides consistent accuracy improvement over strong\nbaselines. Besides, the promising experimental results on non-medical NER\nscenarios indicate that La-DTL is potential to be seamlessly adapted to a wide\nrange of NER tasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:35:11 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 09:46:39 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Wang", "Zhenghui", ""], ["Qu", "Yanru", ""], ["Chen", "Liheng", ""], ["Shen", "Jian", ""], ["Zhang", "Weinan", ""], ["Zhang", "Shaodian", ""], ["Gao", "Yimei", ""], ["Gu", "Gen", ""], ["Chen", "Ken", ""], ["Yu", "Yong", ""]]}, {"id": "1804.09066", "submitter": "Mohammadreza Zolfaghari", "authors": "Mohammadreza Zolfaghari, Kamaljeet Singh, Thomas Brox", "title": "ECO: Efficient Convolutional Network for Online Video Understanding", "comments": "Submitted to ECCV 2018. 17 pages, 7 figures, Supplementary Material,\n  https://github.com/mzolfaghari/ECO-efficient-video-understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in video understanding suffers from two problems: (1)\nThe major part of reasoning is performed locally in the video, therefore, it\nmisses important relationships within actions that span several seconds. (2)\nWhile there are local methods with fast per-frame processing, the processing of\nthe whole video is not efficient and hampers fast video retrieval or online\nclassification of long-term activities. In this paper, we introduce a network\narchitecture that takes long-term content into account and enables fast\nper-video processing at the same time. The architecture is based on merging\nlong-term content already in the network rather than in a post-hoc fusion.\nTogether with a sampling strategy, which exploits that neighboring frames are\nlargely redundant, this yields high-quality action classification and video\ncaptioning at up to 230 videos per second, where each video can consist of a\nfew hundred frames. The approach achieves competitive performance across all\ndatasets while being 10x to 80x faster than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 14:30:56 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 09:46:08 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zolfaghari", "Mohammadreza", ""], ["Singh", "Kamaljeet", ""], ["Brox", "Thomas", ""]]}, {"id": "1804.09133", "submitter": "Zhiguang Wang", "authors": "Mehul Parsana, Krishna Poola, Yajun Wang, Zhiguang Wang", "title": "Improving Native Ads CTR Prediction by Large Scale Event Embedding and\n  Recurrent Networks", "comments": "This version has some language error, and the authors all agree to\n  withdraw it at the moment to further edit and update with some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click through rate (CTR) prediction is very important for Native\nadvertisement but also hard as there is no direct query intent. In this paper\nwe propose a large-scale event embedding scheme to encode the each user\nbrowsing event by training a Siamese network with weak supervision on the\nusers' consecutive events. The CTR prediction problem is modeled as a\nsupervised recurrent neural network, which naturally model the user history as\na sequence of events. Our proposed recurrent models utilizing pretrained event\nembedding vectors and an attention layer to model the user history. Our\nexperiments demonstrate that our model significantly outperforms the baseline\nand some variants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 16:50:54 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 07:30:11 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Parsana", "Mehul", ""], ["Poola", "Krishna", ""], ["Wang", "Yajun", ""], ["Wang", "Zhiguang", ""]]}, {"id": "1804.09153", "submitter": "Pier Luca Lanzi", "authors": "Antonio Umberto Aramini, Pier Luca Lanzi, Daniele Loiacono", "title": "An Integrated Framework for AI Assisted Level Design in 2D Platformers", "comments": "Submitted to the IEEE Game Entertainment and Media Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of video game levels is a complex and critical task. Levels need\nto elicit fun and challenge while avoiding frustration at all costs. In this\npaper, we present a framework to assist designers in the creation of levels for\n2D platformers. Our framework provides designers with a toolbox (i) to create\n2D platformer levels, (ii) to estimate the difficulty and probability of\nsuccess of single jump actions (the main mechanics of platformer games), and\n(iii) a set of metrics to evaluate the difficulty and probability of completion\nof entire levels. At the end, we present the results of a set of experiments we\ncarried out with human players to validate the metrics included in our\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:20:36 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Aramini", "Antonio Umberto", ""], ["Lanzi", "Pier Luca", ""], ["Loiacono", "Daniele", ""]]}, {"id": "1804.09160", "submitter": "Xin Wang", "authors": "Xin Wang, Wenhu Chen, Yuan-Fang Wang, William Yang Wang", "title": "No Metrics Are Perfect: Adversarial Reward Learning for Visual\n  Storytelling", "comments": "ACL 2018. 15 pages, 10 figures, 4 tables, with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though impressive results have been achieved in visual captioning, the task\nof generating abstract stories from photo streams is still a little-tapped\nproblem. Different from captions, stories have more expressive language styles\nand contain many imaginary concepts that do not appear in the images. Thus it\nposes challenges to behavioral cloning algorithms. Furthermore, due to the\nlimitations of automatic metrics on evaluating story quality, reinforcement\nlearning methods with hand-crafted rewards also face difficulties in gaining an\noverall performance boost. Therefore, we propose an Adversarial REward Learning\n(AREL) framework to learn an implicit reward function from human\ndemonstrations, and then optimize policy search with the learned reward\nfunction. Though automatic eval- uation indicates slight performance boost over\nstate-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation\nshows that our approach achieves significant improvement in generating more\nhuman-like stories than SOTA systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:41:24 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 00:15:14 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wang", "Xin", ""], ["Chen", "Wenhu", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.09238", "submitter": "Haitian Sun", "authors": "Haitian Sun, William W. Cohen, Lidong Bing", "title": "Semi-Supervised Learning with Declaratively Specified Entropy\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique for declaratively specifying strategies for\nsemi-supervised learning (SSL). The proposed method can be used to specify\nensembles of semi-supervised learning, as well as agreement constraints and\nentropic regularization constraints between these learners, and can be used to\nmodel both well-known heuristics such as co-training and novel domain-specific\nheuristics. In addition to representing individual SSL heuristics, we show that\nmultiple heuristics can also be automatically combined using Bayesian\noptimization methods. We show consistent improvements on a suite of\nwell-studied SSL benchmarks, including a new state-of-the-art result on a\ndifficult relation extraction task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 20:19:09 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 04:22:50 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Sun", "Haitian", ""], ["Cohen", "William W.", ""], ["Bing", "Lidong", ""]]}, {"id": "1804.09299", "submitter": "Alexander M. Rush", "authors": "Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer,\n  Hanspeter Pfister, Alexander M. Rush", "title": "Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models", "comments": "VAST - IEEE VIS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Sequence-to-Sequence models have proven to be accurate and robust for\nmany sequence prediction tasks, and have become the standard approach for\nautomatic translation of text. The models work in a five stage blackbox process\nthat involves encoding a source sequence to a vector space and then decoding\nout to a new target sequence. This process is now standard, but like many deep\nlearning methods remains quite difficult to understand or debug. In this work,\nwe present a visual analysis tool that allows interaction with a trained\nsequence-to-sequence model through each stage of the translation process. The\naim is to identify which patterns have been learned and to detect model errors.\nWe demonstrate the utility of our tool through several real-world large-scale\nsequence-to-sequence use cases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 00:32:45 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 15:59:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""], ["Behrisch", "Michael", ""], ["Perer", "Adam", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1804.09304", "submitter": "Habib Karbasian", "authors": "Habib Karbasian, Hemant Purohit, Rajat Handa, Aqdas Malik and Aditya\n  Johri", "title": "Real-Time Inference of User Types to Assist with More Inclusive Social\n  Media Activism Campaigns", "comments": "7 pages, has been accepted in AAAI:AIES 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media provides a mechanism for people to engage with social causes\nacross a range of issues. It also provides a strategic tool to those looking to\nadvance a cause to exchange, promote or publicize their ideas. In such\ninstances, AI can be either an asset if used appropriately or a barrier. One of\nthe key issues for a workforce diversity campaign is to understand in real-time\nwho is participating - specifically, whether the participants are individuals\nor organizations, and in case of individuals, whether they are male or female.\nIn this paper, we present a study to demonstrate a case for AI for social good\nthat develops a model to infer in real-time the different user types\nparticipating in a cause-driven hashtag campaign on Twitter,\nILookLikeAnEngineer (ILLAE). A generic framework is devised to classify a\nTwitter user into three classes: organization, male and female in a real-time\nmanner. The framework is tested against two datasets (ILLAE and a general\ndataset) and outperforms the baseline binary classifiers for categorizing\norganization/individual and male/female. The proposed model can be applied to\nfuture social cause-driven campaigns to get real-time insights on the\nmacro-level social behavior of participants.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 00:56:41 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Karbasian", "Habib", ""], ["Purohit", "Hemant", ""], ["Handa", "Rajat", ""], ["Malik", "Aqdas", ""], ["Johri", "Aditya", ""]]}, {"id": "1804.09399", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong and Yi-Hsuan Yang", "title": "Convolutional Generative Adversarial Networks with Binary Neurons for\n  Polyphonic Music Generation", "comments": "A preliminary version of this paper appeared in ISMIR 2018. In this\n  version, we added an appendix to provide figures of sample results and\n  remarks on the end-to-end models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown recently that deep convolutional generative adversarial\nnetworks (GANs) can learn to generate music in the form of piano-rolls, which\nrepresent music by binary-valued time-pitch matrices. However, existing models\ncan only generate real-valued piano-rolls and require further post-processing,\nsuch as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final\nbinary-valued results. In this paper, we study whether we can have a\nconvolutional GAN model that directly creates binary-valued piano-rolls by\nusing binary neurons. Specifically, we propose to append to the generator an\nadditional refiner network, which uses binary neurons at the output layer. The\nwhole network is trained in two stages. Firstly, the generator and the\ndiscriminator are pretrained. Then, the refiner network is trained along with\nthe discriminator to learn to binarize the real-valued piano-rolls the\npretrained generator creates. Experimental results show that using binary\nneurons instead of HT or BS indeed leads to better results in a number of\nobjective measures. Moreover, deterministic binary neurons perform better than\nstochastic ones in both objective measures and a subjective test. The source\ncode, training data and audio examples of the generated results can be found at\nhttps://salu133445.github.io/bmusegan/ .\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:35:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 16:13:12 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2018 15:08:20 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1804.09400", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicolas Duchateau, Nicholas Ayache", "title": "3D Consistent & Robust Segmentation of Cardiac Images by Deep Learning\n  with Spatial Propagation", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method based on deep learning to perform cardiac segmentation on\nshort axis MRI image stacks iteratively from the top slice (around the base) to\nthe bottom slice (around the apex). At each iteration, a novel variant of U-net\nis applied to propagate the segmentation of a slice to the adjacent slice below\nit. In other words, the prediction of a segmentation of a slice is dependent\nupon the already existing segmentation of an adjacent slice. 3D-consistency is\nhence explicitly enforced. The method is trained on a large database of 3078\ncases from UK Biobank. It is then tested on 756 different cases from UK Biobank\nand three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with\n30 cases, RVSC with 16 cases). Results comparable or even better than the\nstate-of-the-art in terms of distance measures are achieved. They also\nemphasize the assets of our method, namely enhanced spatial consistency\n(currently neither considered nor achieved by the state-of-the-art), and the\ngeneralization ability to unseen cases even from other databases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:39:36 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Duchateau", "Nicolas", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1804.09465", "submitter": "Shabnam Sadeghi Esfahlani", "authors": "Shabnam Sadeghi Esfahlani and Tommy Thompson", "title": "Intelligent Physiotherapy Through Procedural Content Generation", "comments": "4 pages; 3 figures AAAI Publications, Twelfth Artificial Intelligence\n  and Interactive Digital Entertainment Conference", "journal-ref": "Papers from the AIIDE Workshop 2016 AAAI Technical Report WS-16-22", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes an avenue for artificial and computational intelligence\ntechniques applied within games research to be deployed for purposes of\nphysical therapy. We provide an overview of prototypical research focussed on\nthe application of motion sensor input devices and virtual reality equipment\nfor rehabilitation of motor impairment an issue typical of patient's of\ntraumatic brain injuries. We highlight how advances in procedural content\ngeneration and player modelling can stimulate development in this area by\nimproving quality of rehabilitation programmes and measuring patient\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 10:24:41 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Esfahlani", "Shabnam Sadeghi", ""], ["Thompson", "Tommy", ""]]}, {"id": "1804.09473", "submitter": "Mark Kaminski", "authors": "Mark Kaminski, Bernardo Cuenca Grau, Egor V. Kostylev, Boris Motik,\n  Ian Horrocks", "title": "Stratified Negation in Limit Datalog Programs", "comments": "14 pages; full version of a paper accepted at IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been an increasing interest in declarative data analysis,\nwhere analytic tasks are specified using a logical language, and their\nimplementation and optimisation are delegated to a general-purpose query\nengine. Existing declarative languages for data analysis can be formalised as\nvariants of logic programming equipped with arithmetic function symbols and/or\naggregation, and are typically undecidable. In prior work, the language of\n$\\mathit{limit\\ programs}$ was proposed, which is sufficiently powerful to\ncapture many analysis tasks and has decidable entailment problem. Rules in this\nlanguage, however, do not allow for negation. In this paper, we study an\nextension of limit programs with stratified negation-as-failure. We show that\nthe additional expressive power makes reasoning computationally more demanding,\nand provide tight data complexity bounds. We also identify a fragment with\ntractable data complexity and sufficient expressivity to capture many relevant\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 10:40:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kaminski", "Mark", ""], ["Grau", "Bernardo Cuenca", ""], ["Kostylev", "Egor V.", ""], ["Motik", "Boris", ""], ["Horrocks", "Ian", ""]]}, {"id": "1804.09502", "submitter": "Zejian Li", "authors": "Zejian Li, Yongchuan Tang, Yongxing He", "title": "Unsupervised Disentangled Representation Learning with Analogical\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the disentangled representation of interpretable generative factors\nof data is one of the foundations to allow artificial intelligence to think\nlike people. In this paper, we propose the analogical training strategy for the\nunsupervised disentangled representation learning in generative models. The\nanalogy is one of the typical cognitive processes, and our proposed strategy is\nbased on the observation that sample pairs in which one is different from the\nother in one specific generative factor show the same analogical relation.\nThus, the generator is trained to generate sample pairs from which a designed\nclassifier can identify the underlying analogical relation. In addition, we\npropose a disentanglement metric called the subspace score, which is inspired\nby subspace learning methods and does not require supervised information.\nExperiments show that our proposed training strategy allows the generative\nmodels to find the disentangled factors, and that our methods can give\ncompetitive performances as compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 12:09:01 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Li", "Zejian", ""], ["Tang", "Yongchuan", ""], ["He", "Yongxing", ""]]}, {"id": "1804.09521", "submitter": "Arpita Biswas", "authors": "Siddharth Barman and Arpita Biswas", "title": "Fair Division Under Cardinality Constraints", "comments": "22 pages. A part of these results is accepted at the 27th\n  International Joint Conference on Artificial Intelligence (IJCAI), 2018. The\n  proof of Lemma 5 in the earlier version had a bug. To address the issue and\n  in lieu of general matroids, the current version provides a proof of this\n  result specialized for Laminar matroids", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fairly allocating indivisible goods, among agents,\nunder cardinality constraints and additive valuations. In this setting, we are\ngiven a partition of the entire set of goods---i.e., the goods are\ncategorized---and a limit is specified on the number of goods that can be\nallocated from each category to any agent. The objective here is to find a fair\nallocation in which the subset of goods assigned to any agent satisfies the\ngiven cardinality constraints. This problem naturally captures a number of\nresource-allocation applications, and is a generalization of the well-studied\n(unconstrained) fair division problem.\n  The two central notions of fairness, in the context of fair division of\nindivisible goods, are envy freeness up to one good (EF1) and the (approximate)\nmaximin share guarantee (MMS). We show that the existence and algorithmic\nguarantees established for these solution concepts in the unconstrained setting\ncan essentially be achieved under cardinality constraints. Specifically, we\ndevelop efficient algorithms which compute EF1 and approximately MMS\nallocations in the constrained setting.\n  Furthermore, focusing on the case wherein all the agents have the same\nadditive valuation, we establish that EF1 allocations exist and can be computed\nefficiently even under laminar matroid constraints.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 12:38:06 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 15:21:43 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 17:48:29 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Barman", "Siddharth", ""], ["Biswas", "Arpita", ""]]}, {"id": "1804.09540", "submitter": "Jatin Ganhotra", "authors": "Janarthanan Rajendran, Jatin Ganhotra, Xiaoxiao Guo, Mo Yu, Satinder\n  Singh, Lazaros Polymenakos", "title": "NE-Table: A Neural key-value table for Named Entities", "comments": "RANLP 2019 - http://lml.bas.bg/ranlp2019/accepted.php . Datasets are\n  available at - https://github.com/IBM/ne-table-datasets/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many Natural Language Processing (NLP) tasks depend on using Named Entities\n(NEs) that are contained in texts and in external knowledge sources. While this\nis easy for humans, the present neural methods that rely on learned word\nembeddings may not perform well for these NLP tasks, especially in the presence\nof Out-Of-Vocabulary (OOV) or rare NEs. In this paper, we propose a solution\nfor this problem, and present empirical evaluations on: a) a structured\nQuestion-Answering task, b) three related Goal-Oriented dialog tasks, and c) a\nReading-Comprehension task, which show that the proposed method can be\neffective in dealing with both in-vocabulary and OOV NEs. We create extended\nversions of dialog bAbI tasks 1,2 and 4 and OOV versions of the CBT test set\navailable at - https://github.com/IBM/ne-table-datasets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 20:09:13 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 22:27:48 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rajendran", "Janarthanan", ""], ["Ganhotra", "Jatin", ""], ["Guo", "Xiaoxiao", ""], ["Yu", "Mo", ""], ["Singh", "Satinder", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1804.09541", "submitter": "Adams Wei Yu", "authors": "Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen,\n  Mohammad Norouzi, Quoc V. Le", "title": "QANet: Combining Local Convolution with Global Self-Attention for\n  Reading Comprehension", "comments": "Published as full paper in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current end-to-end machine reading and question answering (Q\\&A) models are\nprimarily based on recurrent neural networks (RNNs) with attention. Despite\ntheir success, these models are often slow for both training and inference due\nto the sequential nature of RNNs. We propose a new Q\\&A architecture called\nQANet, which does not require recurrent networks: Its encoder consists\nexclusively of convolution and self-attention, where convolution models local\ninteractions and self-attention models global interactions. On the SQuAD\ndataset, our model is 3x to 13x faster in training and 4x to 9x faster in\ninference, while achieving equivalent accuracy to recurrent models. The\nspeed-up gain allows us to train the model with much more data. We hence\ncombine our model with data generated by backtranslation from a neural machine\ntranslation model. On the SQuAD dataset, our single model, trained with\naugmented data, achieves 84.6 F1 score on the test set, which is significantly\nbetter than the best published F1 score of 81.8.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:33:43 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Yu", "Adams Wei", ""], ["Dohan", "David", ""], ["Luong", "Minh-Thang", ""], ["Zhao", "Rui", ""], ["Chen", "Kai", ""], ["Norouzi", "Mohammad", ""], ["Le", "Quoc V.", ""]]}, {"id": "1804.09558", "submitter": "Raquel P\\'erez-Arnal", "authors": "Raquel P\\'erez-Arnal, Armand Vilalta, Dario Garcia-Gasulla, Ulises\n  Cort\\'es, Eduard Ayguad\\'e, Jesus Labarta", "title": "A Visual Distance for WordNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:34:33 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 09:17:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["P\u00e9rez-Arnal", "Raquel", ""], ["Vilalta", "Armand", ""], ["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Ulises", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jesus", ""]]}, {"id": "1804.09635", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang and Waleed Ammar and Bhavana Dalvi and Madeleine van\n  Zuylen and Sebastian Kohlmeier and Eduard Hovy and Roy Schwartz", "title": "A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP\n  Applications", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer reviewing is a central component in the scientific publishing process.\nWe present the first public dataset of scientific peer reviews available for\nresearch purposes (PeerRead v1) providing an opportunity to study this\nimportant artifact. The dataset consists of 14.7K paper drafts and the\ncorresponding accept/reject decisions in top-tier venues including ACL, NIPS\nand ICLR. The dataset also includes 10.7K textual peer reviews written by\nexperts for a subset of the papers. We describe the data collection process and\nreport interesting observed phenomena in the peer reviews. We also propose two\nnovel NLP tasks based on this dataset and provide simple baseline models. In\nthe first task, we show that simple models can predict whether a paper is\naccepted with up to 21% error reduction compared to the majority baseline. In\nthe second task, we predict the numerical scores of review aspects and show\nthat simple models can outperform the mean baseline for aspects with high\nvariance such as 'originality' and 'impact'.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:41:15 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kang", "Dongyeop", ""], ["Ammar", "Waleed", ""], ["Dalvi", "Bhavana", ""], ["van Zuylen", "Madeleine", ""], ["Kohlmeier", "Sebastian", ""], ["Hovy", "Eduard", ""], ["Schwartz", "Roy", ""]]}, {"id": "1804.09690", "submitter": "Tewodros Habtegebrial", "authors": "Tewodros Habtegebrial, Kiran Varanasi, Christian Bailer, Didier\n  Stricker", "title": "Fast View Synthesis with Deep Stereo Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Novel view synthesis is an important problem in computer vision and graphics.\nOver the years a large number of solutions have been put forward to solve the\nproblem. However, the large-baseline novel view synthesis problem is far from\nbeing \"solved\". Recent works have attempted to use Convolutional Neural\nNetworks (CNNs) to solve view synthesis tasks. Due to the difficulty of\nlearning scene geometry and interpreting camera motion, CNNs are often unable\nto generate realistic novel views. In this paper, we present a novel view\nsynthesis approach based on stereo-vision and CNNs that decomposes the problem\ninto two sub-tasks: view dependent geometry estimation and texture inpainting.\nBoth tasks are structured prediction problems that could be effectively learned\nwith CNNs. Experiments on the KITTI Odometry dataset show that our approach is\nmore accurate and significantly faster than the current state-of-the-art. The\ncode and supplementary material will be publicly available. Results could be\nfound here https://youtu.be/5pzS9jc-5t0\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 17:35:50 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 11:54:58 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Habtegebrial", "Tewodros", ""], ["Varanasi", "Kiran", ""], ["Bailer", "Christian", ""], ["Stricker", "Didier", ""]]}, {"id": "1804.09817", "submitter": "Ermo Wei", "authors": "Ermo Wei, Drew Wicke, David Freelan and Sean Luke", "title": "Multiagent Soft Q-Learning", "comments": "Accepted in AAAI 18 Spring Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are often applied to reinforcement learning in\ncontinuous multiagent games. These methods perform local search in the\njoint-action space, and as we show, they are susceptable to a game-theoretic\npathology known as relative overgeneralization. To resolve this issue, we\npropose Multiagent Soft Q-learning, which can be seen as the analogue of\napplying Q-learning to continuous controls. We compare our method to MADDPG, a\nstate-of-the-art approach, and show that our method achieves better\ncoordination in multiagent cooperative tasks, converging to better local optima\nin the joint action space.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:03:27 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Wei", "Ermo", ""], ["Wicke", "Drew", ""], ["Freelan", "David", ""], ["Luke", "Sean", ""]]}, {"id": "1804.09843", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun and Andrew Gordon Wilson", "title": "Hierarchical Density Order Embeddings", "comments": "Published at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing words with probability densities rather than point vectors,\nprobabilistic word embeddings can capture rich and interpretable semantic\ninformation and uncertainty. The uncertainty information can be particularly\nmeaningful in capturing entailment relationships -- whereby general words such\nas \"entity\" correspond to broad distributions that encompass more specific\nwords such as \"animal\" or \"instrument\". We introduce density order embeddings,\nwhich learn hierarchical representations through encapsulation of probability\ndensities. In particular, we propose simple yet effective loss functions and\ndistance metrics, as well as graph-based schemes to select negative samples to\nbetter learn hierarchical density representations. Our approach provides\nstate-of-the-art performance on the WordNet hypernym relationship prediction\ntask and the challenging HyperLex lexical entailment dataset -- while retaining\na rich and interpretable density representation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 00:43:49 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1804.09849", "submitter": "Orhan Firat", "authors": "Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang\n  Macherey, George Foster, Llion Jones, Niki Parmar, Mike Schuster, Zhifeng\n  Chen, Yonghui Wu, Macduff Hughes", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past year has witnessed rapid advances in sequence-to-sequence (seq2seq)\nmodeling for Machine Translation (MT). The classic RNN-based approaches to MT\nwere first out-performed by the convolutional seq2seq model, which was then\nout-performed by the more recent Transformer model. Each of these new\napproaches consists of a fundamental architecture accompanied by a set of\nmodeling and training techniques that are in principle applicable to other\nseq2seq architectures. In this paper, we tease apart the new architectures and\ntheir accompanying techniques in two ways. First, we identify several key\nmodeling and training techniques, and apply them to the RNN architecture,\nyielding a new RNMT+ model that outperforms all of the three fundamental\narchitectures on the benchmark WMT'14 English to French and English to German\ntasks. Second, we analyze the properties of each fundamental seq2seq\narchitecture and devise new hybrid architectures intended to combine their\nstrengths. Our hybrid models obtain further improvements, outperforming the\nRNMT+ model on both benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 01:24:39 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 02:31:16 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Chen", "Mia Xu", ""], ["Firat", "Orhan", ""], ["Bapna", "Ankur", ""], ["Johnson", "Melvin", ""], ["Macherey", "Wolfgang", ""], ["Foster", "George", ""], ["Jones", "Llion", ""], ["Parmar", "Niki", ""], ["Schuster", "Mike", ""], ["Chen", "Zhifeng", ""], ["Wu", "Yonghui", ""], ["Hughes", "Macduff", ""]]}, {"id": "1804.09855", "submitter": "Daniela Inclezan", "authors": "Daniela Inclezan, Qinglin Zhang, Marcello Balduccini and Ankush\n  Israney", "title": "An ASP Methodology for Understanding Narratives about Stereotypical\n  Activities", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 3 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an application of Answer Set Programming to the understanding of\nnarratives about stereotypical activities, demonstrated via question answering.\nSubstantial work in this direction was done by Erik Mueller, who modeled\nstereotypical activities as scripts. His systems were able to understand a good\nnumber of narratives, but could not process texts describing exceptional\nscenarios. We propose addressing this problem by using a theory of intentions\ndeveloped by Blount, Gelfond, and Balduccini. We present a methodology in which\nwe substitute scripts by activities (i.e., hierarchical plans associated with\ngoals) and employ the concept of an intentional agent to reason about both\nnormal and exceptional scenarios. We exemplify the application of this\nmethodology by answering questions about a number of restaurant stories. This\npaper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:10:05 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Inclezan", "Daniela", ""], ["Zhang", "Qinglin", ""], ["Balduccini", "Marcello", ""], ["Israney", "Ankush", ""]]}, {"id": "1804.09856", "submitter": "Lakshmi Nair", "authors": "Lakshmi Nair and Sonia Chernova", "title": "Action Categorization for Computationally Improved Task Learning and\n  Planning", "comments": "10 pages, 13 figures, 3 tables. Extended abstract of the paper\n  accepted to AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of task learning and planning, contributing\nthe Action-Category Representation (ACR) to improve computational performance\nof both Planning and Reinforcement Learning (RL). ACR is an algorithm-agnostic,\nabstract data representation that maps objects to action categories (groups of\nactions), inspired by the psychological concept of action codes. We validate\nour approach in StarCraft and Lightworld domains; our results demonstrate\nseveral benefits of ACR relating to improved computational performance of\nplanning and RL, by reducing the action space for the agent.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:10:22 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Nair", "Lakshmi", ""], ["Chernova", "Sonia", ""]]}, {"id": "1804.09997", "submitter": "Jinyang  Gao", "authors": "Jinyang Gao, Wei Wang, Meihui Zhang, Gang Chen, H.V. Jagadish,\n  Guoliang Li, Teck Khim Ng, Beng Chin Ooi, Sheng Wang, Jingren Zhou", "title": "PANDA: Facilitating Usable AI Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence (AI) and machine learning have\ncreated a general perception that AI could be used to solve complex problems,\nand in some situations over-hyped as a tool that can be so easily used.\nUnfortunately, the barrier to realization of mass adoption of AI on various\nbusiness domains is too high because most domain experts have no background in\nAI. Developing AI applications involves multiple phases, namely data\npreparation, application modeling, and product deployment. The effort of AI\nresearch has been spent mostly on new AI models (in the model training stage)\nto improve the performance of benchmark tasks such as image recognition. Many\nother factors such as usability, efficiency and security of AI have not been\nwell addressed, and therefore form a barrier to democratizing AI. Further, for\nmany real world applications such as healthcare and autonomous driving,\nlearning via huge amounts of possibility exploration is not feasible since\nhumans are involved. In many complex applications such as healthcare, subject\nmatter experts (e.g. Clinicians) are the ones who appreciate the importance of\nfeatures that affect health, and their knowledge together with existing\nknowledge bases are critical to the end results. In this paper, we take a new\nperspective on developing AI solutions, and present a solution for making AI\nusable. We hope that this resolution will enable all subject matter experts\n(eg. Clinicians) to exploit AI like data scientists.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 11:37:03 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Gao", "Jinyang", ""], ["Wang", "Wei", ""], ["Zhang", "Meihui", ""], ["Chen", "Gang", ""], ["Jagadish", "H. V.", ""], ["Li", "Guoliang", ""], ["Ng", "Teck Khim", ""], ["Ooi", "Beng Chin", ""], ["Wang", "Sheng", ""], ["Zhou", "Jingren", ""]]}, {"id": "1804.10001", "submitter": "Taro Sekiyama", "authors": "Taro Sekiyama, Takashi Imamichi, Haruki Imai, Rudy Raymond", "title": "Profile-guided memory optimization for deep neural networks", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen deep neural networks (DNNs) becoming wider and deeper\nto achieve better performance in many applications of AI. Such DNNs however\nrequire huge amounts of memory to store weights and intermediate results (e.g.,\nactivations, feature maps, etc.) in propagation. This requirement makes it\ndifficult to run the DNNs on devices with limited, hard-to-extend memory,\ndegrades the running time performance, and restricts the design of network\nmodels. We address this challenge by developing a novel profile-guided memory\noptimization to efficiently and quickly allocate memory blocks during the\npropagation in DNNs. The optimization utilizes a simple and fast heuristic\nalgorithm based on the two-dimensional rectangle packing problem. Experimenting\nwith well-known neural network models, we confirm that our method not only\nreduces the memory consumption by up to $49.5\\%$ but also accelerates training\nand inference by up to a factor of four thanks to the rapidity of the memory\nallocation and the ability to use larger mini-batch sizes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 11:42:39 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Sekiyama", "Taro", ""], ["Imamichi", "Takashi", ""], ["Imai", "Haruki", ""], ["Raymond", "Rudy", ""]]}, {"id": "1804.10028", "submitter": "John Klein", "authors": "John Klein, Mahmoud Albardan, Benjamin Guedj and Olivier Colot", "title": "Decentralized learning with budgeted network load using Gaussian copulas\n  and classifier ensembles", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-43823-4_26", "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a network of learners which address the same classification task\nbut must learn from different data sets. The learners cannot share data but\ninstead share their models. Models are shared only one time so as to preserve\nthe network load. We introduce DELCO (standing for Decentralized Ensemble\nLearning with COpulas), a new approach allowing to aggregate the predictions of\nthe classifiers trained by each learner. The proposed method aggregates the\nbase classifiers using a probabilistic model relying on Gaussian copulas.\nExperiments on logistic regressor ensembles demonstrate competing accuracy and\nincreased robustness in case of dependent classifiers. A companion python\nimplementation can be downloaded at https://github.com/john-klein/DELCO\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:53:58 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 07:33:39 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 07:38:13 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Klein", "John", ""], ["Albardan", "Mahmoud", ""], ["Guedj", "Benjamin", ""], ["Colot", "Olivier", ""]]}, {"id": "1804.10188", "submitter": "Sahil Garg", "authors": "Sahil Garg, Irina Rish, Guillermo Cecchi, Palash Goyal, Sarik\n  Ghazarian, Shuyang Gao, Greg Ver Steeg, Aram Galstyan", "title": "Modeling Psychotherapy Dialogues with Kernelized Hashcode\n  Representations: A Nonparametric Information-Theoretic Approach", "comments": "Response generative based model added, along with human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel dialogue modeling framework, the first-ever nonparametric\nkernel functions based approach for dialogue modeling, which learns kernelized\nhashcodes as compressed text representations; unlike traditional deep learning\nmodels, it handles well relatively small datasets, while also scaling to large\nones. We also derive a novel lower bound on mutual information, used as a\nmodel-selection criterion favoring representations with better alignment\nbetween the utterances of participants in a collaborative dialogue setting, as\nwell as higher predictability of the generated responses. As demonstrated on\nthree real-life datasets, including prominently psychotherapy sessions, the\nproposed approach significantly outperforms several state-of-art neural network\nbased dialogue systems, both in terms of computational efficiency, reducing\ntraining time from days or weeks to hours, and the response quality, achieving\nan order of magnitude improvement over competitors in frequency of being chosen\nas the best model by human evaluators.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:39:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:32:09 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 03:58:19 GMT"}, {"version": "v4", "created": "Fri, 6 Jul 2018 14:54:22 GMT"}, {"version": "v5", "created": "Thu, 18 Oct 2018 15:23:28 GMT"}, {"version": "v6", "created": "Fri, 8 Mar 2019 02:16:21 GMT"}, {"version": "v7", "created": "Mon, 9 Sep 2019 19:43:38 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Garg", "Sahil", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Goyal", "Palash", ""], ["Ghazarian", "Sarik", ""], ["Gao", "Shuyang", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1804.10200", "submitter": "Y Cooper", "authors": "Y Cooper", "title": "The loss landscape of overparameterized neural networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore some mathematical features of the loss landscape of\noverparameterized neural networks. A priori one might imagine that the loss\nfunction looks like a typical function from $\\mathbb{R}^n$ to $\\mathbb{R}$ - in\nparticular, nonconvex, with discrete global minima. In this paper, we prove\nthat in at least one important way, the loss function of an overparameterized\nneural network does not look like a typical function. If a neural net has $n$\nparameters and is trained on $d$ data points, with $n>d$, we show that the\nlocus $M$ of global minima of $L$ is usually not discrete, but rather an $n-d$\ndimensional submanifold of $\\mathbb{R}^n$. In practice, neural nets commonly\nhave orders of magnitude more parameters than data points, so this observation\nimplies that $M$ is typically a very high-dimensional subset of $\\mathbb{R}^n$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:58:45 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Cooper", "Y", ""]]}, {"id": "1804.10201", "submitter": "Anis Davoudi", "authors": "Anis Davoudi, Kumar Rohit Malhotra, Benjamin Shickel, Scott Siegel,\n  Seth Williams, Matthew Ruppert, Emel Bihorac, Tezcan Ozrazgat-Baslanti,\n  Patrick J. Tighe, Azra Bihorac, Parisa Rashidi", "title": "The Intelligent ICU Pilot Study: Using Artificial Intelligence\n  Technology for Autonomous Patient Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many critical care indices are repetitively assessed and recorded\nby overburdened nurses, e.g. physical function or facial pain expressions of\nnonverbal patients. In addition, many essential information on patients and\ntheir environment are not captured at all, or are captured in a non-granular\nmanner, e.g. sleep disturbance factors such as bright light, loud background\nnoise, or excessive visitations. In this pilot study, we examined the\nfeasibility of using pervasive sensing technology and artificial intelligence\nfor autonomous and granular monitoring of critically ill patients and their\nenvironment in the Intensive Care Unit (ICU). As an exemplar prevalent\ncondition, we also characterized delirious and non-delirious patients and their\nenvironment. We used wearable sensors, light and sound sensors, and a\nhigh-resolution camera to collected data on patients and their environment. We\nanalyzed collected data using deep learning and statistical analysis. Our\nsystem performed face detection, face recognition, facial action unit\ndetection, head pose detection, facial expression recognition, posture\nrecognition, actigraphy analysis, sound pressure and light level detection, and\nvisitation frequency detection. We were able to detect patient's face (Mean\naverage precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their\npostures (F1=0.94). We also found that all facial expressions, 11 activity\nfeatures, visitation frequency during the day, visitation frequency during the\nnight, light levels, and sound pressure levels during the night were\nsignificantly different between delirious and non-delirious patients\n(p-value<0.05). In summary, we showed that granular and autonomous monitoring\nof critically ill patients and their environment is feasible and can be used\nfor characterizing critical care conditions and related environment factors.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 21:24:46 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 18:25:32 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Davoudi", "Anis", ""], ["Malhotra", "Kumar Rohit", ""], ["Shickel", "Benjamin", ""], ["Siegel", "Scott", ""], ["Williams", "Seth", ""], ["Ruppert", "Matthew", ""], ["Bihorac", "Emel", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Tighe", "Patrick J.", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1804.10202", "submitter": "Hao Fang", "authors": "Hao Fang, Hao Cheng, Maarten Sap, Elizabeth Clark, Ari Holtzman, Yejin\n  Choi, Noah A. Smith, Mari Ostendorf", "title": "Sounding Board: A User-Centric and Content-Driven Social Chatbot", "comments": "5 pages, 3 figures, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Sounding Board, a social chatbot that won the 2017 Amazon Alexa\nPrize. The system architecture consists of several components including spoken\nlanguage processing, dialogue management, language generation, and content\nmanagement, with emphasis on user-centric and content-driven design. We also\nshare insights gained from large-scale online logs based on 160,000\nconversations with real-world users.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 08:11:16 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Fang", "Hao", ""], ["Cheng", "Hao", ""], ["Sap", "Maarten", ""], ["Clark", "Elizabeth", ""], ["Holtzman", "Ari", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1804.10227", "submitter": "Torsten Schaub", "authors": "Pedro Cabalar, Roland Kaminski, Torsten Schaub, Anna Schuhmann", "title": "Temporal Answer Set Programming on Finite Traces", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 15 pages,\n  LaTeX, 0 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an alternative approach to Temporal Answer Set\nProgramming that relies on a variation of Temporal Equilibrium Logic (TEL) for\nfinite traces. This approach allows us to even out the expressiveness of TEL\nover infinite traces with the computational capacity of (incremental) Answer\nSet Programming (ASP). Also, we argue that finite traces are more natural when\nreasoning about action and change. As a result, our approach is readily\nimplementable via multi-shot ASP systems and benefits from an extension of\nASP's full-fledged input language with temporal operators. This includes future\nas well as past operators whose combination offers a rich temporal modeling\nlanguage. For computation, we identify the class of temporal logic programs and\nprove that it constitutes a normal form for our approach. Finally, we outline\ntwo implementations, a generic one and an extension of clingo.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 18:22:02 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Cabalar", "Pedro", ""], ["Kaminski", "Roland", ""], ["Schaub", "Torsten", ""], ["Schuhmann", "Anna", ""]]}, {"id": "1804.10247", "submitter": "Torsten Schaub", "authors": "Martin Gebser, Philipp Obermeier, Thomas Otto, Torsten Schaub, Orkunt\n  Sabuncu, Van Nguyen, Tran Cao Son", "title": "Experimenting with robotic intra-logistics domains", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 8 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the asprilo [1] framework to facilitate experimental studies of\napproaches addressing complex dynamic applications. For this purpose, we have\nchosen the domain of robotic intra-logistics. This domain is not only highly\nrelevant in the context of today's fourth industrial revolution but it moreover\ncombines a multitude of challenging issues within a single uniform framework.\nThis includes multi-agent planning, reasoning about action, change, resources,\nstrategies, etc. In return, asprilo allows users to study alternative solutions\nas regards effectiveness and scalability. Although asprilo relies on Answer Set\nProgramming and Python, it is readily usable by any system complying with its\nfact-oriented interface format. This makes it attractive for benchmarking and\nteaching well beyond logic programming. More precisely, asprilo consists of a\nversatile benchmark generator, solution checker and visualizer as well as a\nbunch of reference encodings featuring various ASP techniques. Importantly, the\nvisualizer's animation capabilities are indispensable for complex scenarios\nlike intra-logistics in order to inspect valid as well as invalid solution\ncandidates. Also, it allows for graphically editing benchmark layouts that can\nbe used as a basis for generating benchmark suites.\n  [1] asprilo stands for Answer Set Programming for robotic intra-logistics\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 19:05:30 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Gebser", "Martin", ""], ["Obermeier", "Philipp", ""], ["Otto", "Thomas", ""], ["Schaub", "Torsten", ""], ["Sabuncu", "Orkunt", ""], ["Nguyen", "Van", ""], ["Son", "Tran Cao", ""]]}, {"id": "1804.10332", "submitter": "Jie Tan", "authors": "Jie Tan, Tingnan Zhang, Erwin Coumans, Atil Iscen, Yunfei Bai, Danijar\n  Hafner, Steven Bohez, Vincent Vanhoucke", "title": "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots", "comments": "Accompanying video: https://www.youtube.com/watch?v=lUZUr7jxoqM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agile locomotion for quadruped robots often requires extensive\nexpertise and tedious manual tuning. In this paper, we present a system to\nautomate this process by leveraging deep reinforcement learning techniques. Our\nsystem can learn quadruped locomotion from scratch using simple reward signals.\nIn addition, users can provide an open loop reference to guide the learning\nprocess when more control over the learned gait is needed. The control policies\nare learned in a physics simulator and then deployed on real robots. In\nrobotics, policies trained in simulation often do not transfer to the real\nworld. We narrow this reality gap by improving the physics simulator and\nlearning robust policies. We improve the simulation using system\nidentification, developing an accurate actuator model and simulating latency.\nWe learn robust controllers by randomizing the physical environments, adding\nperturbations and designing a compact observation space. We evaluate our system\non two agile locomotion gaits: trotting and galloping. After learning in\nsimulation, a quadruped robot can successfully perform both gaits in the real\nworld.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 03:42:55 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 20:35:34 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Tan", "Jie", ""], ["Zhang", "Tingnan", ""], ["Coumans", "Erwin", ""], ["Iscen", "Atil", ""], ["Bai", "Yunfei", ""], ["Hafner", "Danijar", ""], ["Bohez", "Steven", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1804.10392", "submitter": "Shabnam Sadeghi Esfahlani", "authors": "Shabnam Sadeghi Esfahlani, Silvia Cirstea, Alireza Sanaei, George\n  Wilson", "title": "An adaptive self-organizing fuzzy logic controller in a serious game for\n  motor impairment rehabilitation", "comments": "8 pages, 7 figures, 17096690", "journal-ref": "19-21 June 2017; 978-1-5090-1412-5; 978-1-5090-1413-2; 2163-5145", "doi": "10.1109/ISIE.2017.8001435", "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rehabilitation robotics combined with video game technology provides a means\nof assisting in the rehabilitation of patients with neuromuscular disorders by\nperforming various facilitation movements. The current work presents ReHabGame,\na serious game using a fusion of implemented technologies that can be easily\nused by patients and therapists to assess and enhance sensorimotor performance\nand also increase the activities in the daily lives of patients. The game\nallows a player to control avatar movements through a Kinect Xbox, Myo armband\nand rudder foot pedal, and involves a series of reach-grasp-collect tasks whose\ndifficulty levels are learnt by a fuzzy interface. The orientation, angular\nvelocity, head and spine tilts and other data generated by the player are\nmonitored and saved, whilst the task completion is calculated by solving an\ninverse kinematics algorithm which orientates the upper limb joints of the\navatar. The different values in upper body quantities of movement provide fuzzy\ninput from which crisp output is determined and used to generate an appropriate\nsubsequent rehabilitation game level. The system can thus provide personalised,\nautonomously-learnt rehabilitation programmes for patients with neuromuscular\ndisorders with superior predictions to guide the development of improved\nclinical protocols compared to traditional theraputic activities.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 08:39:43 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Esfahlani", "Shabnam Sadeghi", ""], ["Cirstea", "Silvia", ""], ["Sanaei", "Alireza", ""], ["Wilson", "George", ""]]}, {"id": "1804.10437", "submitter": "Martin Gebser", "authors": "Martin Gebser, Philipp Obermeier, Michel Ratsch-Heitmann, Mario Runge,\n  Torsten Schaub", "title": "Routing Driverless Transport Vehicles in Car Assembly with Answer Set\n  Programming", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018; 15 pages,\n  LaTeX, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated storage and retrieval systems are principal components of modern\nproduction and warehouse facilities. In particular, automated guided vehicles\nnowadays substitute human-operated pallet trucks in transporting production\nmaterials between storage locations and assembly stations. While low-level\ncontrol systems take care of navigating such driverless vehicles along\nprogrammed routes and avoid collisions even under unforeseen circumstances, in\nthe common case of multiple vehicles sharing the same operation area, the\nproblem remains how to set up routes such that a collection of transport tasks\nis accomplished most effectively. We address this prevalent problem in the\ncontext of car assembly at Mercedes-Benz Ludwigsfelde GmbH, a large-scale\nproducer of commercial vehicles, where routes for automated guided vehicles\nused in the production process have traditionally been hand-coded by human\nengineers. Such ad-hoc methods may suffice as long as a running production\nprocess remains in place, while any change in the factory layout or production\ntargets necessitates tedious manual reconfiguration, not to mention the missing\nportability between different production plants. Unlike this, we propose a\ndeclarative approach based on Answer Set Programming to optimize the routes\ntaken by automated guided vehicles for accomplishing transport tasks. The\nadvantages include a transparent and executable problem formalization, provable\noptimality of routes relative to objective criteria, as well as elaboration\ntolerance towards particular factory layouts and production targets. Moreover,\nwe demonstrate that our approach is efficient enough to deal with the transport\ntasks evolving in realistic production processes at the car factory of\nMercedes-Benz Ludwigsfelde GmbH.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:00:54 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Gebser", "Martin", ""], ["Obermeier", "Philipp", ""], ["Ratsch-Heitmann", "Michel", ""], ["Runge", "Mario", ""], ["Schaub", "Torsten", ""]]}, {"id": "1804.10447", "submitter": "Giuseppe Sanfilippo", "authors": "Angelo Gilio and Giuseppe Sanfilippo", "title": "Generalized Logical Operations among Conditional Events", "comments": null, "journal-ref": "Applied Intelligent 2018", "doi": "10.1007/s10489-018-1229-8", "report-no": null, "categories": "math.PR cs.AI math.AC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize, by a progressive procedure, the notions of conjunction and\ndisjunction of two conditional events to the case of $n$ conditional events. In\nour coherence-based approach, conjunctions and disjunctions are suitable\nconditional random quantities. We define the notion of negation, by verifying\nDe Morgan's Laws. We also show that conjunction and disjunction satisfy the\nassociative and commutative properties, and a monotonicity property. Then, we\ngive some results on coherence of prevision assessments for some families of\ncompounded conditionals; in particular we examine the Fr\\'echet-Hoeffding\nbounds. Moreover, we study the reverse probabilistic inference from the\nconjunction $\\mathcal{C}_{n+1}$ of $n+1$ conditional events to the family\n$\\{\\mathcal{C}_{n},E_{n+1}|H_{n+1}\\}$. We consider the relation with the notion\nof quasi-conjunction and we examine in detail the coherence of the prevision\nassessments related with the conjunction of three conditional events. Based on\nconjunction, we also give a characterization of p-consistency and of\np-entailment, with applications to several inference rules in probabilistic\nnonmonotonic reasoning. Finally, we examine some non p-valid inference rules;\nthen, we illustrate by an example two methods which allow to suitably modify\nnon p-valid inference rules in order to get inferences which are p-valid.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:32:49 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Gilio", "Angelo", ""], ["Sanfilippo", "Giuseppe", ""]]}, {"id": "1804.10467", "submitter": "Jens Schulz", "authors": "Jens Schulz, Constantin Hubmann, Julian L\\\"ochner, Darius Burschka", "title": "Interaction-Aware Probabilistic Behavior Prediction in Urban\n  Environments", "comments": "Accepted paper at IEEE IROS 2018. $\\copyright$ 2018 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning for autonomous driving in complex, urban scenarios requires accurate\nprediction of the trajectories of surrounding traffic participants. Their\nfuture behavior depends on their route intentions, the road-geometry, traffic\nrules and mutual interaction, resulting in interdependencies between their\ntrajectories. We present a probabilistic prediction framework based on a\ndynamic Bayesian network, which represents the state of the complete scene\nincluding all agents and respects the aforementioned dependencies. We propose\nMarkovian, context-dependent motion models to define the interaction-aware\nbehavior of drivers. At first, the state of the dynamic Bayesian network is\nestimated over time by tracking the single agents via sequential Monte Carlo\ninference. Secondly, we perform a probabilistic forward simulation of the\nnetwork's estimated belief state to generate the different combinatorial scene\ndevelopments. This provides the corresponding trajectories for the set of\npossible, future scenes. Our framework can handle various road layouts and\nnumber of traffic participants. We evaluate the approach in online simulations\nand real-world scenarios. It is shown that our interaction-aware prediction\noutperforms interaction-unaware physics- and map-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 12:34:24 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 11:48:38 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Schulz", "Jens", ""], ["Hubmann", "Constantin", ""], ["L\u00f6chner", "Julian", ""], ["Burschka", "Darius", ""]]}, {"id": "1804.10544", "submitter": "Sahil Garg", "authors": "Sahil Garg and Nora Ayanian", "title": "Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a\n  Small Team of Robots", "comments": "Robotics Science and Systems, 2014 (RSS-14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a solution for persistent monitoring of real-world\nstochastic phenomena, where the underlying covariance structure changes sharply\nacross time, using a small number of mobile robot sensors. We propose an\nadaptive solution for the problem where stochastic real-world dynamics are\nmodeled as a Gaussian Process (GP). The belief on the underlying covariance\nstructure is learned from recently observed dynamics as a Gaussian Mixture (GM)\nin the low-dimensional hyper-parameters space of the GP and adapted across time\nusing Sequential Monte Carlo methods. Each robot samples a belief point from\nthe GM and locally optimizes a set of informative regions by greedy\nmaximization of the submodular entropy function. The key contributions of this\npaper are threefold: adapting the belief on the covariance using Markov Chain\nMonte Carlo (MCMC) sampling such that particles survive even under sharp\ncovariance changes across time; exploiting the belief to transform the problem\nof entropy maximization into a decentralized one; and developing an\napproximation algorithm to maximize entropy on a set of informative regions in\nthe continuous space. We illustrate the application of the proposed solution\nthrough extensive simulations using an artificial dataset and multiple real\ndatasets from fixed sensor deployments, and compare it to three competing\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 14:55:38 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Ayanian", "Nora", ""]]}, {"id": "1804.10587", "submitter": "Sebastian Bock", "authors": "Sebastian Bock, Josef Goppold, Martin Wei{\\ss}", "title": "An improvement of the convergence proof of the ADAM-Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common way to train neural networks is the Backpropagation. This algorithm\nincludes a gradient descent method, which needs an adaptive step size. In the\narea of neural networks, the ADAM-Optimizer is one of the most popular adaptive\nstep size methods. It was invented in \\cite{Kingma.2015} by Kingma and Ba. The\n$5865$ citations in only three years shows additionally the importance of the\ngiven paper. We discovered that the given convergence proof of the optimizer\ncontains some mistakes, so that the proof will be wrong. In this paper we give\nan improvement to the convergence proof of the ADAM-Optimizer.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 16:53:51 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Bock", "Sebastian", ""], ["Goppold", "Josef", ""], ["Wei\u00df", "Martin", ""]]}, {"id": "1804.10601", "submitter": "Petr Novotn\\'y", "authors": "Krishnendu Chatterjee, Adri\\'an Elgy\\\"utt, Petr Novotn\\'y, Owen\n  Rouill\\'e", "title": "Expectation Optimization with Probabilistic Guarantees in POMDPs with\n  Discounted-sum Objectives", "comments": "Full version of a paper published at IJCAI/ECAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially-observable Markov decision processes (POMDPs) with discounted-sum\npayoff are a standard framework to model a wide range of problems related to\ndecision making under uncertainty. Traditionally, the goal has been to obtain\npolicies that optimize the expectation of the discounted-sum payoff. A key\ndrawback of the expectation measure is that even low probability events with\nextreme payoff can significantly affect the expectation, and thus the obtained\npolicies are not necessarily risk-averse. An alternate approach is to optimize\nthe probability that the payoff is above a certain threshold, which allows\nobtaining risk-averse policies, but ignores optimization of the expectation. We\nconsider the expectation optimization with probabilistic guarantee (EOPG)\nproblem, where the goal is to optimize the expectation ensuring that the payoff\nis above a given threshold with at least a specified probability. We present\nseveral results on the EOPG problem, including the first algorithm to solve it.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 17:34:05 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 11:52:15 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Elgy\u00fctt", "Adri\u00e1n", ""], ["Novotn\u00fd", "Petr", ""], ["Rouill\u00e9", "Owen", ""]]}, {"id": "1804.10669", "submitter": "Karl Ni", "authors": "Jeff Hetherly, Paul Gamble, Maria Barrios, Cory Stephenson, Karl Ni", "title": "Deep Speech Denoising with Vector Space Projections", "comments": "arXiv admin note: text overlap with arXiv:1705.04662", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an algorithm to denoise speakers from a single microphone in the\npresence of non-stationary and dynamic noise. Our approach is inspired by the\nrecent success of neural network models separating speakers from other speakers\nand singers from instrumental accompaniment. Unlike prior art, we leverage\nembedding spaces produced with source-contrastive estimation, a technique\nderived from negative sampling techniques in natural language processing, while\nsimultaneously obtaining a continuous inference mask. Our embedding space\ndirectly optimizes for the discrimination of speaker and noise by jointly\nmodeling their characteristics. This space is generalizable in that it is not\nspeaker or noise specific and is capable of denoising speech even if the model\nhas not seen the speaker in the training set. Parameters are trained with dual\nobjectives: one that promotes a selective bandpass filter that eliminates noise\nat time-frequency positions that exceed signal power, and another that\nproportionally splits time-frequency content between signal and noise. We\ncompare to state of the art algorithms as well as traditional sparse\nnon-negative matrix factorization solutions. The resulting algorithm avoids\nsevere computational burden by providing a more intuitive and easily optimized\napproach, while achieving competitive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 20:08:38 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Hetherly", "Jeff", ""], ["Gamble", "Paul", ""], ["Barrios", "Maria", ""], ["Stephenson", "Cory", ""], ["Ni", "Karl", ""]]}, {"id": "1804.10689", "submitter": "Amy Zhang", "authors": "Amy Zhang, Harsh Satija and Joelle Pineau", "title": "Decoupling Dynamics and Reward for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning (RL) methods can successfully learn single\ntasks but often generalize poorly to modest perturbations in task domain or\ntraining procedure. In this work, we present a decoupled learning strategy for\nRL that creates a shared representation space where knowledge can be robustly\ntransferred. We separate learning the task representation, the forward\ndynamics, the inverse dynamics and the reward function of the domain, and show\nthat this decoupling improves performance within the task, transfers well to\nchanges in dynamics and reward, and can be effectively used for online\nplanning. Empirical results show good performance in both continuous and\ndiscrete RL domains.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:16:40 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 02:02:28 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhang", "Amy", ""], ["Satija", "Harsh", ""], ["Pineau", "Joelle", ""]]}, {"id": "1804.10711", "submitter": "Pritish Yuvraj", "authors": "Pritish Yuvraj, Suneetha K. R", "title": "Modified Apriori Graph Algorithm for Frequent Pattern Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web Usage Mining is an application of Data Mining Techniques to discover\ninteresting usage patterns from web data in order to understand and better\nserve the needs of web-based applications. The paper proposes an algorithm for\nfinding these usage patterns using a modified version of Apriori Algorithm\ncalled Apriori-Graph. These rules will help service providers to predict, which\nweb pages, the user is likely to visit next. This will optimize the website in\nterms of efficiency, bandwidth and will have positive economic benefits for\nthem. The proposed Apriori Graph Algorithm O((V)(E)) works faster compared to\nthe existing Apriori Algorithm and is well suitable for real-time application.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 23:15:20 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Yuvraj", "Pritish", ""], ["R", "Suneetha K.", ""]]}, {"id": "1804.10718", "submitter": "Benjamin Robaidek", "authors": "Benjamin Robaidek, Rik Koncel-Kedziorski, Hannaneh Hajishirzi", "title": "Data-Driven Methods for Solving Algebra Word Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore contemporary, data-driven techniques for solving math word\nproblems over recent large-scale datasets. We show that well-tuned neural\nequation classifiers can outperform more sophisticated models such as sequence\nto sequence and self-attention across these datasets. Our error analysis\nindicates that, while fully data driven models show some promise, semantic and\nworld knowledge is necessary for further advances.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 01:19:51 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Robaidek", "Benjamin", ""], ["Koncel-Kedziorski", "Rik", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1804.10764", "submitter": "Christian Wachinger", "authors": "Christian Wachinger and Benjamin Gutierrez Becker and Anna Rieckmann", "title": "Detect, Quantify, and Incorporate Dataset Bias: A Neuroimaging Analysis\n  on 12,207 Individuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging datasets keep growing in size to address increasingly complex\nmedical questions. However, even the largest datasets today alone are too small\nfor training complex models or for finding genome wide associations. A solution\nis to grow the sample size by merging data across several datasets. However,\nbias in datasets complicates this approach and includes additional sources of\nvariation in the data instead. In this work, we combine 15 large neuroimaging\ndatasets to study bias. First, we detect bias by demonstrating that scans can\nbe correctly assigned to a dataset with 73.3% accuracy. Next, we introduce\nmetrics to quantify the compatibility across datasets and to create embeddings\nof neuroimaging sites. Finally, we incorporate the presence of bias for the\nselection of a training set for predicting autism. For the quantification of\nthe dataset bias, we introduce two metrics: the Bhattacharyya distance between\ndatasets and the age prediction error. The presented embedding of neuroimaging\nsites provides an interesting new visualization about the similarity of\ndifferent sites. This could be used to guide the merging of data sources, while\nlimiting the introduction of unwanted variation. Finally, we demonstrate a\nclear performance increase when incorporating dataset bias for training set\nselection in autism prediction. Overall, we believe that the growing amount of\nneuroimaging data necessitates to incorporate data-driven methods for\nquantifying dataset bias in future analyses.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 09:11:34 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Wachinger", "Christian", ""], ["Becker", "Benjamin Gutierrez", ""], ["Rieckmann", "Anna", ""]]}, {"id": "1804.10765", "submitter": "Rolf Schwitter", "authors": "Rolf Schwitter", "title": "Specifying and Verbalising Answer Set Programs in Controlled Natural\n  Language", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018, 15 pages,\n  LaTeX, (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how a bi-directional grammar can be used to specify and verbalise\nanswer set programs in controlled natural language. We start from a program\nspecification in controlled natural language and translate this specification\nautomatically into an executable answer set program. The resulting answer set\nprogram can be modified following certain naming conventions and the revised\nversion of the program can then be verbalised in the same subset of natural\nlanguage that was used as specification language. The bi-directional grammar is\nparametrised for processing and generation, deals with referring expressions,\nand exploits symmetries in the data structure of the grammar rules whenever\nthese grammar rules need to be duplicated. We demonstrate that verbalisation\nrequires sentence planning in order to aggregate similar structures with the\naim to improve the readability of the generated specification. Without\nmodifications, the generated specification is always semantically equivalent to\nthe original one; our bi-directional grammar is the first one that allows for\nsemantic round-tripping in the context of controlled natural language\nprocessing. This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 09:12:38 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Schwitter", "Rolf", ""]]}, {"id": "1804.10817", "submitter": "Virginia Dignum", "authors": "Virginia Dignum and Frank Dignum", "title": "A Logic of Agent Organizations", "comments": null, "journal-ref": "Logic Journal of the IGPL, vol. 20, no. 1, pp. 283-316, Feb. 2012", "doi": "10.1093/jigpal/jzr041", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organization concepts and models are increasingly being adopted for the\ndesign and specification of multi-agent systems. Agent organizations can be\nseen as mechanisms of social order, created to achieve global (or\norganizational) objectives by more or less autonomous agents. In order to\ndevelop a theory on the relation between organizational structures,\norganizational objectives and the actions of agents fulfilling roles in the\norganization a theoretical framework is needed to describe organizational\nstructures and actions of (groups of) agents. Current logical formalisms focus\non specific aspects of organizations (e.g. power, delegation, agent actions, or\nnormative issues) but a framework that integrates and relates different aspects\nis missing. Given the amount of aspects involved and the subsequent complexity\nof a formalism encompassing them all, it is difficult to realize. In this\npaper, a first step is taken to solve this problem. We present a generic formal\nmodel that enables to specify and relate the main concepts of an organization\n(including, activity, structure, environment and others) so that organizations\ncan be analyzed at a high level of abstraction. However, for some aspects we\nuse a simplified model in order to avoid the complexity of combining many\ndifferent types of (modal) operators.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 15:09:10 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dignum", "Virginia", ""], ["Dignum", "Frank", ""]]}, {"id": "1804.10822", "submitter": "Raphael Abreu", "authors": "Raphael Abreu, Joel dos Santos and Eduardo Bezerra", "title": "A Bimodal Learning Approach to Assist Multi-sensory Effects\n  Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In mulsemedia applications, traditional media content (text, image, audio,\nvideo, etc.) can be related to media objects that target other human senses\n(e.g., smell, haptics, taste). Such applications aim at bridging the virtual\nand real worlds through sensors and actuators. Actuators are responsible for\nthe execution of sensory effects (e.g., wind, heat, light), which produce\nsensory stimulations on the users. In these applications sensory stimulation\nmust happen in a timely manner regarding the other traditional media content\nbeing presented. For example, at the moment in which an explosion is presented\nin the audiovisual content, it may be adequate to activate actuators that\nproduce heat and light. It is common to use some declarative multimedia\nauthoring language to relate the timestamp in which each media object is to be\npresented to the execution of some sensory effect. One problem in this setting\nis that the synchronization of media objects and sensory effects is done\nmanually by the author(s) of the application, a process which is time-consuming\nand error prone. In this paper, we present a bimodal neural network\narchitecture to assist the synchronization task in mulsemedia applications. Our\napproach is based on the idea that audio and video signals can be used\nsimultaneously to identify the timestamps in which some sensory effect should\nbe executed. Our learning architecture combines audio and video signals for the\nprediction of scene components. For evaluation purposes, we construct a dataset\nbased on Google's AudioSet. We provide experiments to validate our bimodal\narchitecture. Our results show that the bimodal approach produces better\nresults when compared to several variants of unimodal architectures.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 15:37:41 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Abreu", "Raphael", ""], ["Santos", "Joel dos", ""], ["Bezerra", "Eduardo", ""]]}, {"id": "1804.10829", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana", "title": "Formal Security Analysis of Neural Networks using Symbolic Intervals", "comments": "Accepted to USENIX Security 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing deployment of Deep Neural Networks (DNNs) in real-world\nsecurity-critical domains including autonomous vehicles and collision avoidance\nsystems, formally checking security properties of DNNs, especially under\ndifferent attacker capabilities, is becoming crucial. Most existing security\ntesting techniques for DNNs try to find adversarial examples without providing\nany formal security guarantees about the non-existence of such adversarial\nexamples. Recently, several projects have used different types of\nSatisfiability Modulo Theory (SMT) solvers to formally check security\nproperties of DNNs. However, all of these approaches are limited by the high\noverhead caused by the solver.\n  In this paper, we present a new direction for formally checking security\nproperties of DNNs without using SMT solvers. Instead, we leverage interval\narithmetic to compute rigorous bounds on the DNN outputs. Our approach, unlike\nexisting solver-based approaches, is easily parallelizable. We further present\nsymbolic interval analysis along with several other optimizations to minimize\noverestimations of output bounds.\n  We design, implement, and evaluate our approach as part of ReluVal, a system\nfor formally checking security properties of Relu-based DNNs. Our extensive\nempirical results show that ReluVal outperforms Reluplex, a state-of-the-art\nsolver-based system, by 200 times on average. On a single 8-core machine\nwithout GPUs, within 4 hours, ReluVal is able to verify a security property\nthat Reluplex deemed inconclusive due to timeout after running for more than 5\ndays. Our experiments demonstrate that symbolic interval analysis is a\npromising new direction towards rigorously analyzing different security\nproperties of DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 16:37:01 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 04:57:23 GMT"}, {"version": "v3", "created": "Sun, 1 Jul 2018 17:33:53 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "Shiqi", ""], ["Pei", "Kexin", ""], ["Whitehouse", "Justin", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""]]}, {"id": "1804.10850", "submitter": "Tengfei Ma", "authors": "Tengfei Ma, Cao Xiao, Jiayu Zhou, Fei Wang", "title": "Drug Similarity Integration Through Attentive Multi-view Graph\n  Auto-Encoders", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug similarity has been studied to support downstream clinical tasks such as\ninferring novel properties of drugs (e.g. side effects, indications,\ninteractions) from known properties. The growing availability of new types of\ndrug features brings the opportunity of learning a more comprehensive and\naccurate drug similarity that represents the full spectrum of underlying drug\nrelations. However, it is challenging to integrate these heterogeneous, noisy,\nnonlinear-related information to learn accurate similarity measures especially\nwhen labels are scarce. Moreover, there is a trade-off between accuracy and\ninterpretability. In this paper, we propose to learn accurate and interpretable\nsimilarity measures from multiple types of drug features. In particular, we\nmodel the integration using multi-view graph auto-encoders, and add attentive\nmechanism to determine the weights for each view with respect to corresponding\ntasks and features for better interpretability. Our model has flexible design\nfor both semi-supervised and unsupervised settings. Experimental results\ndemonstrated significant predictive accuracy improvement. Case studies also\nshowed better model capacity (e.g. embed node features) and interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 22:14:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ma", "Tengfei", ""], ["Xiao", "Cao", ""], ["Zhou", "Jiayu", ""], ["Wang", "Fei", ""]]}, {"id": "1804.10899", "submitter": "Bowen Wu", "authors": "Bowen Wu, Huaming Wu, Monica M.Y. Zhang", "title": "Scalable Angular Discriminative Deep Metric Learning for Face\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of deep learning, Deep Metric Learning (DML) has\nachieved great improvements in face recognition. Specifically, the widely used\nsoftmax loss in the training process often bring large intra-class variations,\nand feature normalization is only exploited in the testing process to compute\nthe pair similarities. To bridge the gap, we impose the intra-class cosine\nsimilarity between the features and weight vectors in softmax loss larger than\na margin in the training step, and extend it from four aspects. First, we\nexplore the effect of a hard sample mining strategy. To alleviate the human\nlabor of adjusting the margin hyper-parameter, a self-adaptive margin updating\nstrategy is proposed. Then, a normalized version is given to take full\nadvantage of the cosine similarity constraint. Furthermore, we enhance the\nformer constraint to force the intra-class cosine similarity larger than the\nmean inter-class cosine similarity with a margin in the exponential feature\nprojection space. Extensive experiments on Labeled Face in the Wild (LFW),\nYoutube Faces (YTF) and IARPA Janus Benchmark A (IJB-A) datasets demonstrate\nthat the proposed methods outperform the mainstream DML methods and approach\nthe state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 09:40:46 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 01:30:56 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Wu", "Bowen", ""], ["Wu", "Huaming", ""], ["Zhang", "Monica M. Y.", ""]]}, {"id": "1804.10922", "submitter": "Fatima Zohra Smaili", "authors": "Fatima Zohra Smaili, Xin Gao and Robert Hoehndorf", "title": "OPA2Vec: combining formal and informal content of biomedical ontologies\n  to improve similarity-based prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Ontologies are widely used in biology for data annotation,\nintegration, and analysis. In addition to formally structured axioms,\nontologies contain meta-data in the form of annotation axioms which provide\nvaluable pieces of information that characterize ontology classes. Annotations\ncommonly used in ontologies include class labels, descriptions, or synonyms.\nDespite being a rich source of semantic information, the ontology meta-data are\ngenerally unexploited by ontology-based analysis methods such as semantic\nsimilarity measures. Results: We propose a novel method, OPA2Vec, to generate\nvector representations of biological entities in ontologies by combining formal\nontology axioms and annotation axioms from the ontology meta-data. We apply a\nWord2Vec model that has been pre-trained on PubMed abstracts to produce feature\nvectors from our collected data. We validate our method in two different ways:\nfirst, we use the obtained vector representations of proteins as a similarity\nmeasure to predict protein-protein interaction (PPI) on two different datasets.\nSecond, we evaluate our method on predicting gene-disease associations based on\nphenotype similarity by generating vector representations of genes and diseases\nusing a phenotype ontology, and applying the obtained vectors to predict\ngene-disease associations. These two experiments are just an illustration of\nthe possible applications of our method. OPA2Vec can be used to produce vector\nrepresentations of any biomedical entity given any type of biomedical ontology.\nAvailability: https://github.com/bio-ontology-research-group/opa2vec Contact:\nrobert.hoehndorf@kaust.edu.sa and xin.gao@kaust.edu.sa.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 12:49:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Smaili", "Fatima Zohra", ""], ["Gao", "Xin", ""], ["Hoehndorf", "Robert", ""]]}, {"id": "1804.10938", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Panagiotis Tzirakis, Mihalis A. Nicolaou,\n  Athanasios Papaioannou, Guoying Zhao, Bj\\\"orn Schuller, Irene Kotsia,\n  Stefanos Zafeiriou", "title": "Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge,\n  Deep Architectures, and Beyond", "comments": null, "journal-ref": null, "doi": "10.1007/s11263-019-01158-4", "report-no": null, "categories": "cs.CV cs.AI cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of human affect using visual signals is of great\nimportance in everyday human-machine interactions. Appraising human emotional\nstates, behaviors and reactions displayed in real-world settings, can be\naccomplished using latent continuous dimensions (e.g., the circumplex model of\naffect). Valence (i.e., how positive or negative is an emotion) & arousal\n(i.e., power of the activation of the emotion) constitute popular and effective\naffect representations. Nevertheless, the majority of collected datasets this\nfar, although containing naturalistic emotional states, have been captured in\nhighly controlled recording conditions. In this paper, we introduce the\nAff-Wild benchmark for training and evaluating affect recognition algorithms.\nWe also report on the results of the First Affect-in-the-wild Challenge that\nwas organized in conjunction with CVPR 2017 on the Aff-Wild database and was\nthe first ever challenge on the estimation of valence and arousal in-the-wild.\nFurthermore, we design and extensively train an end-to-end deep neural\narchitecture which performs prediction of continuous emotion dimensions based\non visual cues. The proposed deep learning architecture, AffWildNet, includes\nconvolutional & recurrent neural network layers, exploiting the invariant\nproperties of convolutional features, while also modeling temporal dynamics\nthat arise in human behavior via the recurrent layers. The AffWildNet produced\nstate-of-the-art results on the Aff-Wild Challenge. We then exploit the AffWild\ndatabase for learning features, which can be used as priors for achieving best\nperformances both for dimensional, as well as categorical emotion recognition,\nusing the RECOLA, AFEW-VA and EmotiW datasets, compared to all other methods\ndesigned for the same goal. The database and emotion recognition models are\navailable at http://ibug.doc.ic.ac.uk/resources/first-affect-wild-challenge.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 14:18:07 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 01:27:00 GMT"}, {"version": "v3", "created": "Tue, 8 May 2018 09:50:53 GMT"}, {"version": "v4", "created": "Sat, 1 Sep 2018 13:26:39 GMT"}, {"version": "v5", "created": "Fri, 1 Feb 2019 12:39:52 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Tzirakis", "Panagiotis", ""], ["Nicolaou", "Mihalis A.", ""], ["Papaioannou", "Athanasios", ""], ["Zhao", "Guoying", ""], ["Schuller", "Bj\u00f6rn", ""], ["Kotsia", "Irene", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1804.10960", "submitter": "Daniel Hein", "authors": "Daniel Hein, Steffen Udluft, Thomas A. Runkler", "title": "Generating Interpretable Fuzzy Controllers using Particle Swarm\n  Optimization and Genetic Programming", "comments": "Accepted at Genetic and Evolutionary Computation Conference 2018\n  (GECCO '18)", "journal-ref": null, "doi": "10.1145/3205651.3208277", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomously training interpretable control strategies, called policies,\nusing pre-existing plant trajectory data is of great interest in industrial\napplications. Fuzzy controllers have been used in industry for decades as\ninterpretable and efficient system controllers. In this study, we introduce a\nfuzzy genetic programming (GP) approach called fuzzy GP reinforcement learning\n(FGPRL) that can select the relevant state features, determine the size of the\nrequired fuzzy rule set, and automatically adjust all the controller parameters\nsimultaneously. Each GP individual's fitness is computed using model-based\nbatch reinforcement learning (RL), which first trains a model using available\nsystem samples and subsequently performs Monte Carlo rollouts to predict each\npolicy candidate's performance. We compare FGPRL to an extended version of a\nrelated method called fuzzy particle swarm reinforcement learning (FPSRL),\nwhich uses swarm intelligence to tune the fuzzy policy parameters. Experiments\nusing an industrial benchmark show that FGPRL is able to autonomously learn\ninterpretable fuzzy policies with high control performance.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 16:18:12 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Hein", "Daniel", ""], ["Udluft", "Steffen", ""], ["Runkler", "Thomas A.", ""]]}, {"id": "1804.10969", "submitter": "Evgenii Zheltonozhskii", "authors": "Chaim Baskin, Eli Schwartz, Evgenii Zheltonozhskii, Natan Liss, Raja\n  Giryes, Alex M. Bronstein, Avi Mendelson", "title": "UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3444943", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel method for neural network quantization that emulates a\nnon-uniform $k$-quantile quantizer, which adapts to the distribution of the\nquantized parameters. Our approach provides a novel alternative to the existing\nuniform quantization techniques for neural networks. We suggest to compare the\nresults as a function of the bit-operations (BOPS) performed, assuming a\nlook-up table availability for the non-uniform case. In this setup, we show the\nadvantages of our strategy in the low computational budget regime. While the\nproposed solution is harder to implement in hardware, we believe it sets a\nbasis for new alternatives to neural networks quantization.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 17:38:20 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 20:11:25 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 20:19:13 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Baskin", "Chaim", ""], ["Schwartz", "Eli", ""], ["Zheltonozhskii", "Evgenii", ""], ["Liss", "Natan", ""], ["Giryes", "Raja", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1804.10992", "submitter": "Qifeng Chen", "authors": "Xiaojuan Qi, Qifeng Chen, Jiaya Jia, and Vladlen Koltun", "title": "Semi-parametric Image Synthesis", "comments": "Published at the Conference on Computer Vision and Pattern\n  Recognition (CVPR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semi-parametric approach to photographic image synthesis from\nsemantic layouts. The approach combines the complementary strengths of\nparametric and nonparametric techniques. The nonparametric component is a\nmemory bank of image segments constructed from a training set of images. Given\na novel semantic layout at test time, the memory bank is used to retrieve\nphotographic references that are provided as source material to a deep network.\nThe synthesis is performed by a deep network that draws on the provided\nphotographic material. Experiments on multiple semantic segmentation datasets\nshow that the presented approach yields considerably more realistic images than\nrecent purely parametric techniques. The results are shown in the supplementary\nvideo at https://youtu.be/U4Q98lenGLQ\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 21:20:43 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Qi", "Xiaojuan", ""], ["Chen", "Qifeng", ""], ["Jia", "Jiaya", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1804.11002", "submitter": "Edmon Begoli", "authors": "Edmon Begoli, Jim Brase, Bambi DeLaRosa, Penelope Jones, Dimitri\n  Kusnezov, Jason Paragas, Rick Stevens, Fred Streitz, Georgia Tourassi", "title": "Precision Medicine as an Accelerator for Next Generation Cognitive\n  Supercomputing", "comments": null, "journal-ref": "SUPERCOMPUTING FRONTIERS AND INNOVATIONS, 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past several years, we have taken advantage of a number of\nopportunities to advance the intersection of next generation high-performance\ncomputing AI and big data technologies through partnerships in precision\nmedicine. Today we are in the throes of piecing together what is likely the\nmost unique convergence of medical data and computer technologies. But more\ndeeply, we observe that the traditional paradigm of computer simulation and\nprediction needs fundamental revision. This is the time for a number of\nreasons. We will review what the drivers are, why now, how this has been\napproached over the past several years, and where we are heading.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 23:14:29 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Begoli", "Edmon", ""], ["Brase", "Jim", ""], ["DeLaRosa", "Bambi", ""], ["Jones", "Penelope", ""], ["Kusnezov", "Dimitri", ""], ["Paragas", "Jason", ""], ["Stevens", "Rick", ""], ["Streitz", "Fred", ""], ["Tourassi", "Georgia", ""]]}, {"id": "1804.11022", "submitter": "Yevgeniy Vorobeychik", "authors": "Amin Ghafouri and Yevgeniy Vorobeychik and Xenofon Koutsoukos", "title": "Adversarial Regression for Detecting Attacks in Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks in cyber-physical systems (CPS) which manipulate sensor readings can\ncause enormous physical damage if undetected. Detection of attacks on sensors\nis crucial to mitigate this issue. We study supervised regression as a means to\ndetect anomalous sensor readings, where each sensor's measurement is predicted\nas a function of other sensors. We show that several common learning approaches\nin this context are still vulnerable to \\emph{stealthy attacks}, which\ncarefully modify readings of compromised sensors to cause desired damage while\nremaining undetected. Next, we model the interaction between the CPS defender\nand attacker as a Stackelberg game in which the defender chooses detection\nthresholds, while the attacker deploys a stealthy attack in response. We\npresent a heuristic algorithm for finding an approximately optimal threshold\nfor the defender in this game, and show that it increases system resilience to\nattacks without significantly increasing the false alarm rate.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 02:09:25 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ghafouri", "Amin", ""], ["Vorobeychik", "Yevgeniy", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "1804.11044", "submitter": "Eric Mjolsness", "authors": "Eric Mjolsness", "title": "Prospects for Declarative Mathematical Modeling of Complex Biological\n  Systems", "comments": null, "journal-ref": "Bull. Math. Biol. (2019)", "doi": "10.1007/s11538-019-00628-7", "report-no": null, "categories": "q-bio.QM cs.AI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Declarative modeling uses symbolic expressions to represent models. With such\nexpressions one can formalize high-level mathematical computations on models\nthat would be difficult or impossible to perform directly on a lower-level\nsimulation program, in a general-purpose programming language. Examples of such\ncomputations on models include model analysis, relatively general-purpose\nmodel-reduction maps, and the initial phases of model implementation, all of\nwhich should preserve or approximate the mathematical semantics of a complex\nbiological model. The potential advantages are particularly relevant in the\ncase of developmental modeling, wherein complex spatial structures exhibit\ndynamics at molecular, cellular, and organogenic levels to relate genotype to\nmulticellular phenotype. Multiscale modeling can benefit from both the\nexpressive power of declarative modeling languages and the application of model\nreduction methods to link models across scale. Based on previous work, here we\ndefine declarative modeling of complex biological systems by defining the\noperator algebra semantics of an increasingly powerful series of declarative\nmodeling languages including reaction-like dynamics of parameterized and\nextended objects; we define semantics-preserving implementation and\nsemantics-approximating model reduction transformations; and we outline a\n\"meta-hierarchy\" for organizing declarative models and the mathematical methods\nthat can fruitfully manipulate them.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 04:33:09 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 16:38:59 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mjolsness", "Eric", ""]]}, {"id": "1804.11049", "submitter": "Ming Dong", "authors": "M. Dong, P. C. M. Meira, W. Xu and C. Y. Chung", "title": "Non-Intrusive Signature Extraction for Major Residential Loads", "comments": "10 pages, 10 figures", "journal-ref": "IEEE Transactions on Smart Grid, vol. 4, no. 3, pp. 1421-1430,\n  Sept. 2013", "doi": "10.1109/TSG.2013.2245926", "report-no": null, "categories": "eess.SP cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data collected by smart meters contain a lot of useful information. One\npotential use of the data is to track the energy consumptions and operating\nstatuses of major home appliances.The results will enable homeowners to make\nsound decisions on how to save energy and how to participate in demand response\nprograms. This paper presents a new method to breakdown the total power demand\nmeasured by a smart meter to those used by individual appliances. A unique\nfeature of the proposed method is that it utilizes diverse signatures\nassociated with the entire operating window of an appliance for identification.\nAs a result, appliances with complicated middle process can be tracked. A novel\nappliance registration device and scheme is also proposed to automate the\ncreation of appliance signature database and to eliminate the need of massive\ntraining before identification. The software and system have been developed and\ndeployed to real houses in order to verify the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 05:04:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Dong", "M.", ""], ["Meira", "P. C. M.", ""], ["Xu", "W.", ""], ["Chung", "C. Y.", ""]]}, {"id": "1804.11067", "submitter": "Trung Ngo Trong", "authors": "Trung Ngo Trong and Ville Hautam\\\"aki and Kristiina Jokinen", "title": "Staircase Network: structural language identification via hierarchical\n  attentive units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 07:55:55 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Trong", "Trung Ngo", ""], ["Hautam\u00e4ki", "Ville", ""], ["Jokinen", "Kristiina", ""]]}, {"id": "1804.11105", "submitter": "Asan Agibetov", "authors": "Asan Agibetov, Matthias Samwald", "title": "Fast and scalable learning of neuro-symbolic representations of\n  biomedical knowledge", "comments": "Accepted to workshop on Deep Learning for Knowledge Graphs and\n  Semantic Technologies (DL4KGS) at ESWC 2018, June 2018, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we address the problem of fast and scalable learning of\nneuro-symbolic representations for general biological knowledge. Based on a\nrecently published comprehensive biological knowledge graph (Alshahrani, 2017)\nthat was used for demonstrating neuro-symbolic representation learning, we show\nhow to train fast (under 1 minute) log-linear neural embeddings of the\nentities. We utilize these representations as inputs for machine learning\nclassifiers to enable important tasks such as biological link prediction.\nClassifiers are trained by concatenating learned entity embeddings to represent\nentity relations, and training classifiers on the concatenated embeddings to\ndiscern true relations from automatically generated negative examples. Our\nsimple embedding methodology greatly improves on classification error compared\nto previously published state-of-the-art results, yielding a maximum increase\nof $+0.28$ F-measure and $+0.22$ ROC AUC scores for the most difficult\nbiological link prediction problem. Finally, our embedding approach is orders\nof magnitude faster to train ($\\leq$ 1 minute vs. hours), much more economical\nin terms of embedding dimensions ($d=50$ vs. $d=512$), and naturally encodes\nthe directionality of the asymmetric biological relations, that can be\ncontrolled by the order with which we concatenate the embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 09:54:12 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "1804.11109", "submitter": "Arpit Mittal", "authors": "Andrew Hopkinson and Amit Gurdasani and Dave Palfrey and Arpit Mittal", "title": "Demand-Weighted Completeness Prediction for a Knowledge Base", "comments": "To appear in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the notion of Demand-Weighted Completeness,\nallowing estimation of the completeness of a knowledge base with respect to how\nit is used. Defining an entity by its classes, we employ usage data to predict\nthe distribution over relations for that entity. For example, instances of\nperson in a knowledge base may require a birth date, name and nationality to be\nconsidered complete. These predicted relation distributions enable detection of\nimportant gaps in the knowledge base, and define the required facts for unseen\nentities. Such characterisation of the knowledge base can also quantify how\nusage and completeness change over time. We demonstrate a method to measure\nDemand-Weighted Completeness, and show that a simple neural network model\nperforms well at this prediction task.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 10:06:46 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Hopkinson", "Andrew", ""], ["Gurdasani", "Amit", ""], ["Palfrey", "Dave", ""], ["Mittal", "Arpit", ""]]}, {"id": "1804.11130", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Damien Vincent, Ilya Tolstikhin, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf", "title": "Competitive Training of Mixtures of Independent Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in causal modeling posits that the data is generated by a\nset of independent mechanisms, and algorithms should aim to recover this\nstructure. Standard unsupervised learning, however, is often concerned with\ntraining a single model to capture the overall distribution or aspects thereof.\nInspired by clustering approaches, we consider mixtures of implicit generative\nmodels that ``disentangle'' the independent generative mechanisms underlying\nthe data. Relying on an additional set of discriminators, we propose a\ncompetitive training procedure in which the models only need to capture the\nportion of the data distribution from which they can produce realistic samples.\nAs a by-product, each model is simpler and faster to train. We empirically show\nthat our approach splits the training distribution in a sensible way and\nincreases the quality of the generated samples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:41:48 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 09:06:42 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 08:29:20 GMT"}, {"version": "v4", "created": "Sun, 3 Mar 2019 11:20:02 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Locatello", "Francesco", ""], ["Vincent", "Damien", ""], ["Tolstikhin", "Ilya", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1804.11192", "submitter": "Yongfeng Zhang", "authors": "Yongfeng Zhang and Xu Chen", "title": "Explainable Recommendation: A Survey and New Perspectives", "comments": "101 pages, published in Foundations and Trends in Information\n  Retrieval, 14(1), pp.1-101 (2020)", "journal-ref": "Foundations and Trends in Information Retrieval, 14(1), pp.1-101\n  (2020)", "doi": "10.1561/1500000066", "report-no": null, "categories": "cs.IR cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable recommendation attempts to develop models that generate not only\nhigh-quality recommendations but also intuitive explanations. The explanations\nmay either be post-hoc or directly come from an explainable model (also called\ninterpretable or transparent model in some contexts). Explainable\nrecommendation tries to address the problem of why: by providing explanations\nto users or system designers, it helps humans to understand why certain items\nare recommended by the algorithm, where the human can either be users or system\ndesigners. Explainable recommendation helps to improve the transparency,\npersuasiveness, effectiveness, trustworthiness, and satisfaction of\nrecommendation systems. It also facilitates system designers for better system\ndebugging. In recent years, a large number of explainable recommendation\napproaches -- especially model-based methods -- have been proposed and applied\nin real-world systems.\n  In this survey, we provide a comprehensive review for the explainable\nrecommendation research. We first highlight the position of explainable\nrecommendation in recommender system research by categorizing recommendation\nproblems into the 5W, i.e., what, when, who, where, and why. We then conduct a\ncomprehensive survey of explainable recommendation on three perspectives: 1) We\nprovide a chronological research timeline of explainable recommendation. 2) We\nprovide a two-dimensional taxonomy to classify existing explainable\nrecommendation research. 3) We summarize how explainable recommendation applies\nto different recommendation tasks. We also devote a chapter to discuss the\nexplanation perspectives in broader IR and AI/ML research. We end the survey by\ndiscussing potential future directions to promote the explainable\nrecommendation research area and beyond.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 13:49:44 GMT"}, {"version": "v10", "created": "Sun, 13 Sep 2020 03:17:09 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 22:17:18 GMT"}, {"version": "v3", "created": "Sun, 13 May 2018 05:45:50 GMT"}, {"version": "v4", "created": "Tue, 4 Sep 2018 02:22:46 GMT"}, {"version": "v5", "created": "Wed, 24 Jul 2019 17:10:28 GMT"}, {"version": "v6", "created": "Mon, 12 Aug 2019 22:27:04 GMT"}, {"version": "v7", "created": "Thu, 15 Aug 2019 15:28:16 GMT"}, {"version": "v8", "created": "Wed, 1 Jan 2020 17:04:33 GMT"}, {"version": "v9", "created": "Fri, 20 Mar 2020 17:06:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Yongfeng", ""], ["Chen", "Xu", ""]]}, {"id": "1804.11214", "submitter": "Yiming Xu", "authors": "Yiming Xu, Diego Klabjan", "title": "k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural\n  Networks and Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-Nearest Neighbors is one of the most fundamental but effective\nclassification models. In this paper, we propose two families of models built\non a sequence to sequence model and a memory network model to mimic the\nk-Nearest Neighbors model, which generate a sequence of labels, a sequence of\nout-of-sample feature vectors and a final label for classification, and thus\nthey could also function as oversamplers. We also propose 'out-of-core'\nversions of our models which assume that only a small portion of data can be\nloaded into memory. Computational experiments show that our models on\nstructured datasets outperform k-Nearest Neighbors, a feed-forward neural\nnetwork, XGBoost, lightGBM, random forest and a memory network, due to the fact\nthat our models must produce additional output and not just the label. On image\nand text datasets, the performance of our model is close to many\nstate-of-the-art deep models. As an oversampler on imbalanced datasets, the\nsequence to sequence kNN model often outperforms Synthetic Minority\nOver-sampling Technique and Adaptive Synthetic Sampling.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:13:29 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 19:19:19 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 19:31:51 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 00:16:11 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Xu", "Yiming", ""], ["Klabjan", "Diego", ""]]}]