[{"id": "2004.00048", "submitter": "Jo\\~ao Abrantes", "authors": "Jo\\~ao P. Abrantes, Arnaldo J. Abrantes, Frans A. Oliehoek", "title": "Mimicking Evolution with Reinforcement Learning", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution gave rise to human and animal intelligence here on Earth. We argue\nthat the path to developing artificial human-like-intelligence will pass\nthrough mimicking the evolutionary process in a nature-like simulation. In\nNature, there are two processes driving the development of the brain: evolution\nand learning. Evolution acts slowly, across generations, and amongst other\nthings, it defines what agents learn by changing their internal reward\nfunction. Learning acts fast, across one's lifetime, and it quickly updates\nagents' policy to maximise pleasure and minimise pain. The reward function is\nslowly aligned with the fitness function by evolution, however, as agents\nevolve the environment and its fitness function also change, increasing the\nmisalignment between reward and fitness. It is extremely computationally\nexpensive to replicate these two processes in simulation. This work proposes\nEvolution via Evolutionary Reward (EvER) that allows learning to\nsingle-handedly drive the search for policies with increasingly evolutionary\nfitness by ensuring the alignment of the reward function with the fitness\nfunction. In this search, EvER makes use of the whole state-action trajectories\nthat agents go through their lifetime. In contrast, current evolutionary\nalgorithms discard this information and consequently limit their potential\nefficiency at tackling sequential decision problems. We test our algorithm in\ntwo simple bio-inspired environments and show its superiority at generating\nmore capable agents at surviving and reproducing their genes when compared with\na state-of-the-art evolutionary algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:16:53 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:08:43 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Abrantes", "Jo\u00e3o P.", ""], ["Abrantes", "Arnaldo J.", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "2004.00055", "submitter": "Simon DeDeo", "authors": "Scott Viteri and Simon DeDeo", "title": "Explosive Proofs of Mathematical Truths", "comments": "16 pages, 5 figures. Comments solicited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.AI math.HO physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical proofs are both paradigms of certainty and some of the most\nexplicitly-justified arguments that we have in the cultural record. Their very\nexplicitness, however, leads to a paradox, because their probability of error\ngrows exponentially as the argument expands. Here we show that under a\ncognitively-plausible belief formation mechanism that combines deductive and\nabductive reasoning, mathematical arguments can undergo what we call an\nepistemic phase transition: a dramatic and rapidly-propagating jump from\nuncertainty to near-complete confidence at reasonable levels of claim-to-claim\nerror rates. To show this, we analyze an unusual dataset of forty-eight\nmachine-aided proofs from the formalized reasoning system Coq, including major\ntheorems ranging from ancient to 21st Century mathematics, along with four\nhand-constructed cases from Euclid, Apollonius, Spinoza, and Andrew Wiles. Our\nresults bear both on recent work in the history and philosophy of mathematics,\nand on a question, basic to cognitive science, of how we form beliefs, and\njustify them to others.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:39:56 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Viteri", "Scott", ""], ["DeDeo", "Simon", ""]]}, {"id": "2004.00058", "submitter": "Larissa Albantakis", "authors": "Larissa Albantakis, Francesco Massari, Maggie Beheler-Amass and Giulio\n  Tononi", "title": "A macro agent and its actions", "comments": "18 pages, 5 figures; to appear as a chapter in \"Top-Down Causation\n  and Emergence\" published by Springer as part of the Synthese Library Book\n  Series; F.M. and M.B. contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In science, macro level descriptions of the causal interactions within\ncomplex, dynamical systems are typically deemed convenient, but ultimately\nreducible to a complete causal account of the underlying micro constituents.\nYet, such a reductionist perspective is hard to square with several issues\nrelated to autonomy and agency: (1) agents require (causal) borders that\nseparate them from the environment, (2) at least in a biological context,\nagents are associated with macroscopic systems, and (3) agents are supposed to\nact upon their environment. Integrated information theory (IIT) (Oizumi et al.,\n2014) offers a quantitative account of causation based on a set of causal\nprinciples, including notions such as causal specificity, composition, and\nirreducibility, that challenges the reductionist perspective in multiple ways.\nFirst, the IIT formalism provides a complete account of a system's causal\nstructure, including irreducible higher-order mechanisms constituted of\nmultiple system elements. Second, a system's amount of integrated information\n($\\Phi$) measures the causal constraints a system exerts onto itself and can\npeak at a macro level of description (Hoel et al., 2016; Marshall et al.,\n2018). Finally, the causal principles of IIT can also be employed to identify\nand quantify the actual causes of events (\"what caused what\"), such as an\nagent's actions (Albantakis et al., 2019). Here, we demonstrate this framework\nby example of a simulated agent, equipped with a small neural network, that\nforms a maximum of $\\Phi$ at a macro scale.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:51:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Albantakis", "Larissa", ""], ["Massari", "Francesco", ""], ["Beheler-Amass", "Maggie", ""], ["Tononi", "Giulio", ""]]}, {"id": "2004.00061", "submitter": "Marco Valentino", "authors": "Marco Valentino, Mokanarangan Thayaparan, Andr\\'e Freitas", "title": "Unification-based Reconstruction of Multi-hop Explanations for Science\n  Questions", "comments": "Accepted at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework for reconstructing multi-hop\nexplanations in science Question Answering (QA). While existing approaches for\nmulti-hop reasoning build explanations considering each question in isolation,\nwe propose a method to leverage explanatory patterns emerging in a corpus of\nscientific explanations. Specifically, the framework ranks a set of atomic\nfacts by integrating lexical relevance with the notion of unification power,\nestimated analysing explanations for similar questions in the corpus.\n  An extensive evaluation is performed on the Worldtree corpus, integrating\nk-NN clustering and Information Retrieval (IR) techniques. We present the\nfollowing conclusions: (1) The proposed method achieves results competitive\nwith Transformers, yet being orders of magnitude faster, a feature that makes\nit scalable to large explanatory corpora (2) The unification-based mechanism\nhas a key role in reducing semantic drift, contributing to the reconstruction\nof many hops explanations (6 or more facts) and the ranking of complex\ninference facts (+12.0 Mean Average Precision) (3) Crucially, the constructed\nexplanations can support downstream QA models, improving the accuracy of BERT\nby up to 10% overall.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:07:51 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 09:32:05 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Valentino", "Marco", ""], ["Thayaparan", "Mokanarangan", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2004.00071", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi and Mohammed J. Zaki", "title": "Personal Health Knowledge Graphs for Patients", "comments": "3 pages, workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing patient data analytics platforms fail to incorporate information\nthat has context, is personal, and topical to patients. For a recommendation\nsystem to give a suitable response to a query or to derive meaningful insights\nfrom patient data, it should consider personal information about the patient's\nhealth history, including but not limited to their preferences, locations, and\nlife choices that are currently applicable to them. In this review paper, we\ncritique existing literature in this space and also discuss the various\nresearch challenges that come with designing, building, and operationalizing a\npersonal health knowledge graph (PHKG) for patients.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:35:14 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 10:40:21 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "2004.00094", "submitter": "Bram Renting", "authors": "Bram M. Renting (1), Holger H. Hoos (2), Catholijn M. Jonker (1 and 2)\n  ((1) Delft University of Technology, (2) Leiden University)", "title": "Automated Configuration of Negotiation Strategies", "comments": "Appears in Proceedings of the 19th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2020)", "journal-ref": "http://ifaamas.org/Proceedings/aamas2020/pdfs/p1116.pdf", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidding and acceptance strategies have a substantial impact on the outcome of\nnegotiations in scenarios with linear additive and nonlinear utility functions.\nOver the years, it has become clear that there is no single best strategy for\nall negotiation settings, yet many fixed strategies are still being developed.\nWe envision a shift in the strategy design question from: What is a good\nstrategy?, towards: What could be a good strategy? For this purpose, we\ndeveloped a method leveraging automated algorithm configuration to find the\nbest strategies for a specific set of negotiation settings. By empowering\nautomated negotiating agents using automated algorithm configuration, we obtain\na flexible negotiation agent that can be configured automatically for a rich\nspace of opponents and negotiation scenarios.\n  To critically assess our approach, the agent was tested in an ANAC-like\nbilateral automated negotiation tournament setting against past competitors. We\nshow that our automatically configured agent outperforms all other agents, with\na 5.1% increase in negotiation payoff compared to the next-best agent. We note\nthat without our agent in the tournament, the top-ranked agent wins by a margin\nof only 0.01%.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:31:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Renting", "Bram M.", "", "Delft University of Technology"], ["Hoos", "Holger H.", "", "Leiden University"], ["Jonker", "Catholijn M.", "", "1 and 2"]]}, {"id": "2004.00100", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Saayan Mitra, Somdeb Sarkhel, Viswanathan Swaminathan", "title": "Optimal Bidding Strategy without Exploration in Real-time Bidding", "comments": "SIAM SDM 2020. Added supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing utility with a budget constraint is the primary goal for\nadvertisers in real-time bidding (RTB) systems. The policy maximizing the\nutility is referred to as the optimal bidding strategy. Earlier works on\noptimal bidding strategy apply model-based batch reinforcement learning methods\nwhich can not generalize to unknown budget and time constraint. Further, the\nadvertiser observes a censored market price which makes direct evaluation\ninfeasible on batch test datasets. Previous works ignore the losing auctions to\nalleviate the difficulty with censored states; thus significantly modifying the\ntest distribution. We address the challenge of lacking a clear evaluation\nprocedure as well as the error propagated through batch reinforcement learning\nmethods in RTB systems. We exploit two conditional independence structures in\nthe sequential bidding process that allow us to propose a novel practical\nframework using the maximum entropy principle to imitate the behavior of the\ntrue distribution observed in real-time traffic. Moreover, the framework allows\nus to train a model that can generalize to the unseen budget conditions than\nlimit only to those observed in history. We compare our methods on two\nreal-world RTB datasets with several baselines and demonstrate significantly\nimproved performance under various budget settings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:43:28 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ghosh", "Aritra", ""], ["Mitra", "Saayan", ""], ["Sarkhel", "Somdeb", ""], ["Swaminathan", "Viswanathan", ""]]}, {"id": "2004.00151", "submitter": "Jacob Schrum", "authors": "Jacob Schrum, Jake Gutierrez, Vanessa Volz, Jialin Liu, Simon Lucas,\n  and Sebastian Risi", "title": "Interactive Evolution and Exploration Within Latent Level-Design Space\n  of Generative Adversarial Networks", "comments": "GECCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are an emerging form of indirect\nencoding. The GAN is trained to induce a latent space on training data, and a\nreal-valued evolutionary algorithm can search that latent space. Such Latent\nVariable Evolution (LVE) has recently been applied to game levels. However, it\nis hard for objective scores to capture level features that are appealing to\nplayers. Therefore, this paper introduces a tool for interactive LVE of\ntile-based levels for games. The tool also allows for direct exploration of the\nlatent dimensions, and allows users to play discovered levels. The tool works\nfor a variety of GAN models trained for both Super Mario Bros. and The Legend\nof Zelda, and is easily generalizable to other games. A user study shows that\nboth the evolution and latent space exploration features are appreciated, with\na slight preference for direct exploration, but combining these features allows\nusers to discover even better levels. User feedback also indicates how this\nsystem could eventually grow into a commercial design tool, with the addition\nof a few enhancements.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 22:52:17 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Schrum", "Jacob", ""], ["Gutierrez", "Jake", ""], ["Volz", "Vanessa", ""], ["Liu", "Jialin", ""], ["Lucas", "Simon", ""], ["Risi", "Sebastian", ""]]}, {"id": "2004.00204", "submitter": "Thi Kim Phung Lai", "authors": "Phung Lai, NhatHai Phan, Han Hu, Anuja Badeti, David Newman, Dejing\n  Dou", "title": "Ontology-based Interpretable Machine Learning for Textual Data", "comments": "Accepted by IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel interpreting framework that learns an\ninterpretable model based on an ontology-based sampling technique to explain\nagnostic prediction models. Different from existing approaches, our algorithm\nconsiders contextual correlation among words, described in domain knowledge\nontologies, to generate semantic explanations. To narrow down the search space\nfor explanations, which is a major problem of long and complicated text data,\nwe design a learnable anchor algorithm, to better extract explanations locally.\nA set of regulations is further introduced, regarding combining learned\ninterpretable representations with anchors to generate comprehensible semantic\nexplanations. An extensive experiment conducted on two real-world datasets\nshows that our approach generates more precise and insightful explanations\ncompared with baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:51:57 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lai", "Phung", ""], ["Phan", "NhatHai", ""], ["Hu", "Han", ""], ["Badeti", "Anuja", ""], ["Newman", "David", ""], ["Dou", "Dejing", ""]]}, {"id": "2004.00225", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, Tom Goldstein", "title": "MetaPoison: Practical General-purpose Clean-label Data Poisoning", "comments": "Conference paper at NeurIPS 2020. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning -- the process by which an attacker takes control of a model\nby making imperceptible changes to a subset of the training data -- is an\nemerging threat in the context of neural networks. Existing attacks for data\npoisoning neural networks have relied on hand-crafted heuristics, because\nsolving the poisoning problem directly via bilevel optimization is generally\nthought of as intractable for deep models. We propose MetaPoison, a first-order\nmethod that approximates the bilevel problem via meta-learning and crafts\npoisons that fool neural networks. MetaPoison is effective: it outperforms\nprevious clean-label poisoning methods by a large margin. MetaPoison is robust:\npoisoned data made for one model transfer to a variety of victim models with\nunknown training settings and architectures. MetaPoison is general-purpose, it\nworks not only in fine-tuning scenarios, but also for end-to-end training from\nscratch, which till now hasn't been feasible for clean-label attacks with deep\nnets. MetaPoison can achieve arbitrary adversary goals -- like using poisons of\none class to make a target image don the label of another arbitrarily chosen\nclass. Finally, MetaPoison works in the real-world. We demonstrate for the\nfirst time successful data poisoning of models trained on the black-box Google\nCloud AutoML API. Code and premade poisons are provided at\nhttps://github.com/wronnyhuang/metapoison\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 04:23:20 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 02:40:40 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Huang", "W. Ronny", ""], ["Geiping", "Jonas", ""], ["Fowl", "Liam", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "2004.00235", "submitter": "Michelle Blom", "authors": "Michelle Blom, Andrew Conway, Dan King, Laurent Sandrolini, Philip B.\n  Stark, Peter J. Stuckey and Vanessa Teague", "title": "You can do RLAs for IRV", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The City and County of San Francisco, CA, has used Instant Runoff Voting\n(IRV) for some elections since 2004. This report describes the first ever\nprocess pilot of Risk Limiting Audits for IRV, for the San Francisco District\nAttorney's race in November, 2019. We found that the vote-by-mail outcome could\nbe efficiently audited to well under the 0.05 risk limit given a sample of only\n200 ballots. All the software we developed for the pilot is open source.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 05:05:37 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Blom", "Michelle", ""], ["Conway", "Andrew", ""], ["King", "Dan", ""], ["Sandrolini", "Laurent", ""], ["Stark", "Philip B.", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""]]}, {"id": "2004.00377", "submitter": "Aske Plaat", "authors": "Matthias Muller-Brockhausen, Mike Preuss, Aske Plaat", "title": "A New Challenge: Approaching Tetris Link with AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Decades of research have been invested in making computer programs for\nplaying games such as Chess and Go. This paper focuses on a new game, Tetris\nLink, a board game that is still lacking any scientific analysis. Tetris Link\nhas a large branching factor, hampering a traditional heuristic planning\napproach. We explore heuristic planning and two other approaches: Reinforcement\nLearning, Monte Carlo tree search. We document our approach and report on their\nrelative performance in a tournament. Curiously, the heuristic approach is\nstronger than the planning/learning approaches. However, experienced human\nplayers easily win the majority of the matches against the heuristic planning\nAIs. We, therefore, surmise that Tetris Link is more difficult than expected.\nWe offer our findings to the community as a challenge to improve upon.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:25:36 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Muller-Brockhausen", "Matthias", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "2004.00384", "submitter": "Dongdong Yang", "authors": "Dongdong Yang, Kevin Dyer, Senzhang Wang", "title": "Interpretable Deep Learning Model for Online Multi-touch Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, users may be exposed to a range of different\nadvertising campaigns, such as natural search or referral or organic search,\nbefore leading to a final transaction. Estimating the contribution of\nadvertising campaigns on the user's journey is very meaningful and crucial. A\nmarketer could observe each customer's interaction with different marketing\nchannels and modify their investment strategies accordingly. Existing methods\nincluding both traditional last-clicking methods and recent data-driven\napproaches for the multi-touch attribution (MTA) problem lack enough\ninterpretation on why the methods work. In this paper, we propose a novel model\ncalled DeepMTA, which combines deep learning model and additive feature\nexplanation model for interpretable online multi-touch attribution. DeepMTA\nmainly contains two parts, the phased-LSTMs based conversion prediction model\nto catch different time intervals, and the additive feature attribution model\ncombined with shaley values. Additive feature attribution is explanatory that\ncontains a linear function of binary variables. As the first interpretable deep\nlearning model for MTA, DeepMTA considers three important features in the\ncustomer journey: event sequence order, event frequency and time-decay effect\nof the event. Evaluation on a real dataset shows the proposed conversion\nprediction model achieves 91\\% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 23:21:40 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yang", "Dongdong", ""], ["Dyer", "Kevin", ""], ["Wang", "Senzhang", ""]]}, {"id": "2004.00387", "submitter": "Yang Gao", "authors": "Yang Gao, Yi-Fan Li, Yu Lin, Hang Gao, Latifur Khan", "title": "Deep Learning on Knowledge Graph for Recommender System: A Survey", "comments": "6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in research have demonstrated the effectiveness of knowledge\ngraphs (KG) in providing valuable external knowledge to improve recommendation\nsystems (RS). A knowledge graph is capable of encoding high-order relations\nthat connect two objects with one or multiple related attributes. With the help\nof the emerging Graph Neural Networks (GNN), it is possible to extract both\nobject characteristics and relations from KG, which is an essential factor for\nsuccessful recommendations. In this paper, we provide a comprehensive survey of\nthe GNN-based knowledge-aware deep recommender systems. Specifically, we\ndiscuss the state-of-the-art frameworks with a focus on their core component,\ni.e., the graph embedding module, and how they address practical recommendation\nissues such as scalability, cold-start and so on. We further summarize the\ncommonly-used benchmark datasets, evaluation metrics as well as open-source\ncodes. Finally, we conclude the survey and propose potential research\ndirections in this rapidly growing field.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:53:14 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gao", "Yang", ""], ["Li", "Yi-Fan", ""], ["Lin", "Yu", ""], ["Gao", "Hang", ""], ["Khan", "Latifur", ""]]}, {"id": "2004.00425", "submitter": "H\\'ector Cancela", "authors": "Joaqu\\'in Vel\\'azquez, H\\'ector Cancela, Pedro Pi\\~neyro", "title": "A hybrid optimization procedure for solving a tire curing scheduling\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a lot-sizing and scheduling problem variant arising from\nthe study of the curing process of a tire factory. The aim is to find the\nminimum makespan needed for producing enough tires to meet the demand\nrequirements on time, considering the availability and compatibility of\ndifferent resources involved. To solve this problem, we suggest a hybrid\napproach that consists in first applying a heuristic to obtain an estimated\nvalue of the makespan and then solving a mathematical model to determine the\nminimum value. We note that the size of the model (number of variables and\nconstraints) depends significantly on the estimated makespan. Extensive\nnumerical experiments over different instances based on real data are presented\nto evaluate the effectiveness of the hybrid procedure proposed. From the\nresults obtained we can note that the hybrid approach is able to achieve the\noptimal makespan for many of the instances, even large ones, since the results\nprovided by the heuristic allow to reduce significantly the size of the\nmathematical model.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 18:37:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Vel\u00e1zquez", "Joaqu\u00edn", ""], ["Cancela", "H\u00e9ctor", ""], ["Pi\u00f1eyro", "Pedro", ""]]}, {"id": "2004.00427", "submitter": "Movses Musaelian", "authors": "Movses Musaelian, Anane Boateng, Md Zakirul Alam Bhuiyan", "title": "A Semi-Dynamic Bus Routing Infrastructure based on MBTA Bus Data", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation is quickly evolving in the emerging smart city ecosystem with\npersonalized ride sharing services quickly advancing. Yet, the public bus\ninfrastructure has been slow to respond to these trends. With our research, we\npropose a semi-dynamic bus routing framework that is data-driven and responsive\nto relevant parameters in bus transport. We use newly published bus event data\nfrom a bus line in Boston and several algorithmic heuristics to create this\nframework and demonstrate the capabilities and results. We find that this\napproach yields a very promising routing infrastructure that is smarter and\nmore dynamic than the existing system.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 13:07:37 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Musaelian", "Movses", ""], ["Boateng", "Anane", ""], ["Bhuiyan", "Md Zakirul Alam", ""]]}, {"id": "2004.00470", "submitter": "Jianyu Su", "authors": "Jianyu Su, Stephen Adams, and Peter A. Beling", "title": "Counterfactual Multi-Agent Reinforcement Learning with Graph Convolution\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fully cooperative multi-agent system where agents cooperate to\nmaximize a system's utility in a partial-observable environment. We propose\nthat multi-agent systems must have the ability to (1) communicate and\nunderstand the inter-plays between agents and (2) correctly distribute rewards\nbased on an individual agent's contribution. In contrast, most work in this\nsetting considers only one of the above abilities. In this study, we develop an\narchitecture that allows for communication among agents and tailors the\nsystem's reward for each individual agent. Our architecture represents agent\ncommunication through graph convolution and applies an existing credit\nassignment structure, counterfactual multi-agent policy gradient (COMA), to\nassist agents to learn communication by back-propagation. The flexibility of\nthe graph structure enables our method to be applicable to a variety of\nmulti-agent systems, e.g. dynamic systems that consist of varying numbers of\nagents and static systems with a fixed number of agents. We evaluate our method\non a range of tasks, demonstrating the advantage of marrying communication with\ncredit assignment. In the experiments, our proposed method yields better\nperformance than the state-of-art methods, including COMA. Moreover, we show\nthat the communication strategies offers us insights and interpretability of\nthe system's cooperative policies.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:36:13 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 00:57:59 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Su", "Jianyu", ""], ["Adams", "Stephen", ""], ["Beling", "Peter A.", ""]]}, {"id": "2004.00499", "submitter": "Shengbin Jia", "authors": "Shengbin Jia", "title": "Unique Chinese Linguistic Phenomena", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistics holds unique characteristics of generality, stability, and\nnationality, which will affect the formulation of extraction strategies and\nshould be incorporated into the relation extraction. Chinese open relation\nextraction is not well-established, because of the complexity of Chinese\nlinguistics makes it harder to operate, and the methods for English are not\ncompatible with that for Chinese. The diversities between Chinese and English\nlinguistics are mainly reflected in morphology and syntax.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 12:13:48 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 10:00:08 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 06:07:07 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Jia", "Shengbin", ""]]}, {"id": "2004.00530", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, Bo Dai, and Jiayu Zhou", "title": "Learning Sparse Rewarded Tasks from Sub-Optimal Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) has demonstrated its superiority\non many complex sequential decision-making problems. However, heavy dependence\non dense rewards and high sample-complexity impedes the wide adoption of these\nmethods in real-world scenarios. On the other hand, imitation learning (IL)\nlearns effectively in sparse-rewarded tasks by leveraging the existing expert\ndemonstrations. In practice, collecting a sufficient amount of expert\ndemonstrations can be prohibitively expensive, and the quality of\ndemonstrations typically limits the performance of the learning policy. In this\nwork, we propose Self-Adaptive Imitation Learning (SAIL) that can achieve\n(near) optimal performance given only a limited number of sub-optimal\ndemonstrations for highly challenging sparse reward tasks. SAIL bridges the\nadvantages of IL and RL to reduce the sample complexity substantially, by\neffectively exploiting sup-optimal demonstrations and efficiently exploring the\nenvironment to surpass the demonstrated performance. Extensive empirical\nresults show that not only does SAIL significantly improve the\nsample-efficiency but also leads to much better final performance across\ndifferent continuous control tasks, comparing to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:57:15 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Dai", "Bo", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2004.00567", "submitter": "Marco Pleines", "authors": "Marco Pleines, Jenia Jitsev, Mike Preuss, and Frank Zimmer", "title": "Obstacle Tower Without Human Demonstrations: How Far a Deep Feed-Forward\n  Network Goes with Reinforcement Learning", "comments": "8 pages, 9 figures, 2 tables, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Obstacle Tower Challenge is the task to master a procedurally generated\nchain of levels that subsequently get harder to complete. Whereas the most top\nperforming entries of last year's competition used human demonstrations or\nreward shaping to learn how to cope with the challenge, we present an approach\nthat performed competitively (placed 7th) but starts completely from scratch by\nmeans of Deep Reinforcement Learning with a relatively simple feed-forward deep\nnetwork structure. We especially look at the generalization performance of the\ntaken approach concerning different seeds and various visual themes that have\nbecome available after the competition, and investigate where the agent fails\nand why. Note that our approach does not possess a short-term memory like\nemploying recurrent hidden states. With this work, we hope to contribute to a\nbetter understanding of what is possible with a relatively simple, flexible\nsolution that can be applied to learning in environments featuring complex 3D\nvisual input where the abstract task structure itself is still fairly simple.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:55:51 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:07:52 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pleines", "Marco", ""], ["Jitsev", "Jenia", ""], ["Preuss", "Mike", ""], ["Zimmer", "Frank", ""]]}, {"id": "2004.00600", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Bilal Kartal, Pablo Hernandez-Leal, and Matthew E.\n  Taylor", "title": "Work in Progress: Temporally Extended Auxiliary Tasks", "comments": "Accepted for the Adaptive and Learning Agents (ALA) Workshop at AAMAS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive auxiliary tasks have been shown to improve performance in numerous\nreinforcement learning works, however, this effect is still not well\nunderstood. The primary purpose of the work presented here is to investigate\nthe impact that an auxiliary task's prediction timescale has on the agent's\npolicy performance. We consider auxiliary tasks which learn to make on-policy\npredictions using temporal difference learning. We test the impact of\nprediction timescale using a specific form of auxiliary task in which the input\nimage is used as the prediction target, which we refer to as temporal\ndifference autoencoders (TD-AE). We empirically evaluate the effect of TD-AE on\nthe A2C algorithm in the VizDoom environment using different prediction\ntimescales. While we do not observe a clear relationship between the prediction\ntimescale on performance, we make the following observations: 1) using\nauxiliary tasks allows us to reduce the trajectory length of the A2C algorithm,\n2) in some cases temporally extended TD-AE performs better than a straight\nautoencoder, 3) performance with auxiliary tasks is sensitive to the weight\nplaced on the auxiliary loss, 4) despite this sensitivity, auxiliary tasks\nimproved performance without extensive hyper-parameter tuning. Our overall\nconclusions are that TD-AE increases the robustness of the A2C algorithm to the\ntrajectory length and while promising, further study is required to fully\nunderstand the relationship between auxiliary task prediction timescale and the\nagent's performance.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:36:14 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 22:45:14 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 21:42:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Sherstan", "Craig", ""], ["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2004.00603", "submitter": "Andrea Celli", "authors": "Andrea Celli, Alberto Marchesi, Gabriele Farina, Nicola Gatti", "title": "No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of simple, uncoupled no-regret dynamics that converge to\ncorrelated equilibria in normal-form games is a celebrated result in the theory\nof multi-agent systems. Specifically, it has been known for more than 20 years\nthat when all players seek to minimize their internal regret in a repeated\nnormal-form game, the empirical frequency of play converges to a normal-form\ncorrelated equilibrium. Extensive-form (that is, tree-form) games generalize\nnormal-form games by modeling both sequential and simultaneous moves, as well\nas private information. Because of the sequential nature and presence of\npartial information in the game, extensive-form correlation has significantly\ndifferent properties than the normal-form counterpart, many of which are still\nopen research directions. Extensive-form correlated equilibrium (EFCE) has been\nproposed as the natural extensive-form counterpart to normal-form correlated\nequilibrium. However, it was currently unknown whether EFCE emerges as the\nresult of uncoupled agent dynamics. In this paper, we give the first uncoupled\nno-regret dynamics that converge to the set of EFCEs in $n$-player general-sum\nextensive-form games with perfect recall. First, we introduce a notion of\ntrigger regret in extensive-form games, which extends that of internal regret\nin normal-form games. When each player has low trigger regret, the empirical\nfrequency of play is close to an EFCE. Then, we give an efficient\nno-trigger-regret algorithm. Our algorithm decomposes trigger regret into local\nsubproblems at each decision point for the player, and constructs a global\nstrategy of the player from the local solutions at each decision point.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:39:00 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 08:54:26 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 16:00:40 GMT"}, {"version": "v4", "created": "Sat, 20 Jun 2020 09:32:36 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Celli", "Andrea", ""], ["Marchesi", "Alberto", ""], ["Farina", "Gabriele", ""], ["Gatti", "Nicola", ""]]}, {"id": "2004.00646", "submitter": "Dietmar Jannach", "authors": "Dietmar Jannach, Ahtsham Manzoor, Wanling Cai, and Li Chen", "title": "A Survey on Conversational Recommender Systems", "comments": "35 pages, 5 figures", "journal-ref": "ACM Computing Surveys, Volume 54, Issue 5, 2021", "doi": "10.1145/3453154", "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are software applications that help users to find items\nof interest in situations of information overload. Current research often\nassumes a one-shot interaction paradigm, where the users' preferences are\nestimated based on past observed behavior and where the presentation of a\nranked list of suggestions is the main, one-directional form of user\ninteraction. Conversational recommender systems (CRS) take a different approach\nand support a richer set of interactions. These interactions can, for example,\nhelp to improve the preference elicitation process or allow the user to ask\nquestions about the recommendations and to give feedback. The interest in CRS\nhas significantly increased in the past few years. This development is mainly\ndue to the significant progress in the area of natural language processing, the\nemergence of new voice-controlled home assistants, and the increased use of\nchatbot technology. With this paper, we provide a detailed survey of existing\napproaches to conversational recommendation. We categorize these approaches in\nvarious dimensions, e.g., in terms of the supported user intents or the\nknowledge they use in the background. Moreover, we discuss technological\napproaches, review how CRS are evaluated, and finally identify a number of gaps\nthat deserve more research in the future.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:00:47 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 06:16:57 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jannach", "Dietmar", ""], ["Manzoor", "Ahtsham", ""], ["Cai", "Wanling", ""], ["Chen", "Li", ""]]}, {"id": "2004.00686", "submitter": "Virginia Dignum", "authors": "Thomas Hellstr\\\"om, Virginia Dignum, Suna Bensch", "title": "Bias in Machine Learning -- What is it Good for?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In public media as well as in scientific publications, the term \\emph{bias}\nis used in conjunction with machine learning in many different contexts, and\nwith many different meanings. This paper proposes a taxonomy of these different\nmeanings, terminology, and definitions by surveying the, primarily scientific,\nliterature on machine learning. In some cases, we suggest extensions and\nmodifications to promote a clear terminology and completeness. The survey is\nfollowed by an analysis and discussion on how different types of biases are\nconnected and depend on each other. We conclude that there is a complex\nrelation between bias occurring in the machine learning pipeline that leads to\na model, and the eventual bias of the model (which is typically related to\nsocial discrimination). The former bias may or may not influence the latter, in\na sometimes bad, and sometime good way.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 20:00:20 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 12:41:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hellstr\u00f6m", "Thomas", ""], ["Dignum", "Virginia", ""], ["Bensch", "Suna", ""]]}, {"id": "2004.00689", "submitter": "David Robb", "authors": "David A. Robb, Muneeb I. Ahmad, Carlo Tiseo, Simona Aracri, Alistair\n  C. McConnell, Vincent Page, Christian Dondrup, Francisco J. Chiyah Garcia,\n  Hai-Nguyen Nguyen, \\`Eric Pairet, Paola Ard\\'on Ram\\'irez, Tushar Semwal,\n  Hazel M. Taylor, Lindsay J. Wilson, David Lane, Helen Hastie, Katrin Lohan", "title": "Robots in the Danger Zone: Exploring Public Perception through\n  Engagement", "comments": "Accepted in HRI 2020, Keywords: Human robot interaction, robotics,\n  artificial intelligence, public engagement, public perceptions of robots,\n  robotics and society", "journal-ref": "In Human-Robot Interaction HRI 2020, ACM, NY, USA, 10 pages", "doi": "10.1145/3319502.3374789", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public perceptions of Robotics and Artificial Intelligence (RAI) are\nimportant in the acceptance, uptake, government regulation and research funding\nof this technology. Recent research has shown that the public's understanding\nof RAI can be negative or inaccurate. We believe effective public engagement\ncan help ensure that public opinion is better informed. In this paper, we\ndescribe our first iteration of a high throughput in-person public engagement\nactivity. We describe the use of a light touch quiz-format survey instrument to\nintegrate in-the-wild research participation into the engagement, allowing us\nto probe both the effectiveness of our engagement strategy, and public\nperceptions of the future roles of robots and humans working in dangerous\nsettings, such as in the off-shore energy sector. We critique our methods and\nshare interesting results into generational differences within the public's\nview of the future of Robotics and AI in hazardous environments. These findings\ninclude that older peoples' views about the future of robots in hazardous\nenvironments were not swayed by exposure to our exhibit, while the views of\nyounger people were affected by our exhibit, leading us to consider carefully\nin future how to more effectively engage with and inform older people.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 20:10:53 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Robb", "David A.", ""], ["Ahmad", "Muneeb I.", ""], ["Tiseo", "Carlo", ""], ["Aracri", "Simona", ""], ["McConnell", "Alistair C.", ""], ["Page", "Vincent", ""], ["Dondrup", "Christian", ""], ["Garcia", "Francisco J. Chiyah", ""], ["Nguyen", "Hai-Nguyen", ""], ["Pairet", "\u00c8ric", ""], ["Ram\u00edrez", "Paola Ard\u00f3n", ""], ["Semwal", "Tushar", ""], ["Taylor", "Hazel M.", ""], ["Wilson", "Lindsay J.", ""], ["Lane", "David", ""], ["Hastie", "Helen", ""], ["Lohan", "Katrin", ""]]}, {"id": "2004.00716", "submitter": "Ya-Yen Tsai", "authors": "Ya-Yen Tsai, Bo Xiao, Edward Johns, Guang-Zhong Yang", "title": "Constrained-Space Optimization and Reinforcement Learning for Complex\n  Tasks", "comments": "Accepted for publication in RA-Letters and at ICRA 2020", "journal-ref": "IEEE Robotics and Automation Letters, 5(2) (2020) 682-689", "doi": "10.1109/LRA.2020.2965392", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Demonstration is increasingly used for transferring operator\nmanipulation skills to robots. In practice, it is important to cater for\nlimited data and imperfect human demonstrations, as well as underlying safety\nconstraints. This paper presents a constrained-space optimization and\nreinforcement learning scheme for managing complex tasks. Through interactions\nwithin the constrained space, the reinforcement learning agent is trained to\noptimize the manipulation skills according to a defined reward function. After\nlearning, the optimal policy is derived from the well-trained reinforcement\nlearning agent, which is then implemented to guide the robot to conduct tasks\nthat are similar to the experts' demonstrations. The effectiveness of the\nproposed method is verified with a robotic suturing task, demonstrating that\nthe learned policy outperformed the experts' demonstrations in terms of the\nsmoothness of the joint motion and end-effector trajectories, as well as the\noverall task completion time.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 21:50:11 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Tsai", "Ya-Yen", ""], ["Xiao", "Bo", ""], ["Johns", "Edward", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "2004.00768", "submitter": "Justin Gottschlich", "authors": "Roshni G. Iyer, Yizhou Sun, Wei Wang, Justin Gottschlich", "title": "Software Language Comprehension using a Program-Derived Semantics Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional code transformation structures, such as abstract syntax trees\n(ASTs), conteXtual flow graphs (XFGs), and more generally, compiler\nintermediate representations (IRs), may have limitations in extracting\nhigher-order semantics from code. While work has already begun on higher-order\nsemantics lifting (e.g., Aroma's simplified parse tree (SPT), verified\nlifting's lambda calculi, and Halide's intentional domain specific language\n(DSL)), research in this area is still immature. To continue to advance this\nresearch, we present the program-derived semantics graph, a new graphical\nstructure to capture semantics of code. The PSG is designed to provide a single\nstructure for capturing program semantics at multiple levels of abstraction.\nThe PSG may be in a class of emerging structural representations that cannot be\nbuilt from a traditional set of predefined rules and instead must be learned.\nIn this paper, we describe the PSG and its fundamental structural differences\ncompared to state-of-the-art structures. Although our exploration into the PSG\nis in its infancy, our early results and architectural analysis indicate it is\na promising new research direction to automatically extract program semantics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 01:37:57 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 18:29:39 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 17:48:56 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Iyer", "Roshni G.", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""], ["Gottschlich", "Justin", ""]]}, {"id": "2004.00801", "submitter": "Riku Arakawa", "authors": "Riku Arakawa and Shintaro Shiba", "title": "Exploration of Reinforcement Learning for Event Camera using Car-like\n  Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first reinforcement-learning application for robots\nequipped with an event camera. Because of the considerably lower latency of the\nevent camera, it is possible to achieve much faster control of robots compared\nwith the existing vision-based reinforcement-learning applications using\nstandard cameras. To handle a stream of events for reinforcement learning, we\nintroduced an image-like feature and demonstrated the feasibility of training\nan agent in a simulator for two tasks: fast collision avoidance and obstacle\ntracking. Finally, we set up a robot with an event camera in the real world and\nthen transferred the agent trained in the simulator, resulting in successful\nfast avoidance of randomly thrown objects. Incorporating event camera into\nreinforcement learning opens new possibilities for various robotics\napplications that require swift control, such as autonomous vehicles and\ndrones, through end-to-end learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 03:52:03 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Arakawa", "Riku", ""], ["Shiba", "Shintaro", ""]]}, {"id": "2004.00817", "submitter": "Tai Vu", "authors": "Tai Vu", "title": "Combating The Machine Ethics Crisis: An Educational Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the availability of massive data sets and improved computing\npower have driven the advent of cutting-edge machine learning algorithms.\nHowever, this trend has triggered growing concerns associated with its ethical\nissues. In response to such a phenomenon, this study proposes a feasible\nsolution that combines ethics and computer science materials in artificial\nintelligent classrooms. In addition, the paper presents several arguments and\nevidence in favor of the necessity and effectiveness of this integrated\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 05:04:33 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Vu", "Tai", ""]]}, {"id": "2004.00915", "submitter": "Sebastien Gros Prof.", "authors": "Sebastien Gros, Mario Zanon, Alberto Bemporad", "title": "Safe Reinforcement Learning via Projection on a Safe Set: How to Achieve\n  Optimality?", "comments": "Accepted at IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For all its successes, Reinforcement Learning (RL) still struggles to deliver\nformal guarantees on the closed-loop behavior of the learned policy. Among\nother things, guaranteeing the safety of RL with respect to safety-critical\nsystems is a very active research topic. Some recent contributions propose to\nrely on projections of the inputs delivered by the learned policy into a safe\nset, ensuring that the system safety is never jeopardized. Unfortunately, it is\nunclear whether this operation can be performed without disrupting the learning\nprocess. This paper addresses this issue. The problem is analysed in the\ncontext of $Q$-learning and policy gradient techniques. We show that the\nprojection approach is generally disruptive in the context of $Q$-learning\nthough a simple alternative solves the issue, while simple corrections can be\nused in the context of policy gradient methods in order to ensure that the\npolicy gradients are unbiased. The proposed results extend to safe projections\nbased on robust MPC techniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:11:30 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Gros", "Sebastien", ""], ["Zanon", "Mario", ""], ["Bemporad", "Alberto", ""]]}, {"id": "2004.00945", "submitter": "Yong-Lu Li", "authors": "Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Shiyi Wang,\n  Hao-Shu Fang, Ze Ma, Mingyang Chen, Cewu Lu", "title": "PaStaNet: Toward Human Activity Knowledge Engine", "comments": "Accepted to CVPR 2020, supplementary materials included, code\n  available: http://hake-mvig.cn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing image-based activity understanding methods mainly adopt direct\nmapping, i.e. from image to activity concepts, which may encounter performance\nbottleneck since the huge gap. In light of this, we propose a new path: infer\nhuman part states first and then reason out the activities based on part-level\nsemantics. Human Body Part States (PaSta) are fine-grained action semantic\ntokens, e.g. <hand, hold, something>, which can compose the activities and help\nus step toward human activity knowledge engine. To fully utilize the power of\nPaSta, we build a large-scale knowledge base PaStaNet, which contains 7M+ PaSta\nannotations. And two corresponding models are proposed: first, we design a\nmodel named Activity2Vec to extract PaSta features, which aim to be general\nrepresentations for various activities. Second, we use a PaSta-based Reasoning\nmethod to infer activities. Promoted by PaStaNet, our method achieves\nsignificant improvements, e.g. 6.4 and 13.9 mAP on full and one-shot sets of\nHICO in supervised learning, and 3.2 and 4.2 mAP on V-COCO and images-based AVA\nin transfer learning. Code and data are available at http://hake-mvig.cn/.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 11:35:59 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 11:55:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Yong-Lu", ""], ["Xu", "Liang", ""], ["Liu", "Xinpeng", ""], ["Huang", "Xijie", ""], ["Xu", "Yue", ""], ["Wang", "Shiyi", ""], ["Fang", "Hao-Shu", ""], ["Ma", "Ze", ""], ["Chen", "Mingyang", ""], ["Lu", "Cewu", ""]]}, {"id": "2004.00963", "submitter": "Luc Libralesso", "authors": "Luc Libralesso, Florian Fontan", "title": "An anytime tree search algorithm for the 2018 ROADEF/EURO challenge\n  glass cutting problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present the anytime tree search algorithm we designed for\nthe 2018 ROADEF/EURO challenge glass cutting problem proposed by the French\ncompany Saint-Gobain. The resulting program was ranked first among 64\nparticipants. Its key components are: a new search algorithm called Memory\nBounded A* (MBA*) with guide functions, a symmetry breaking strategy, and a\npseudo-dominance rule. We perform a comprehensive study of these components\nshowing that each of them contributes to the algorithm global performances. In\naddition, we designed a second tree search algorithm fully based on the\npseudo-dominance rule and dedicated to some of the challenge instances with\nstrong precedence constraints. On these instances, it finds the best-known\nsolutions very quickly.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 12:51:26 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Libralesso", "Luc", ""], ["Fontan", "Florian", ""]]}, {"id": "2004.00980", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Christian Scheller, Ville Hautam\\\"aki", "title": "Action Space Shaping in Deep Reinforcement Learning", "comments": "To appear in IEEE Conference on Games 2020. Experiment code is\n  available at https://github.com/Miffyli/rl-action-space-shaping", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been successful in training agents in various\nlearning environments, including video-games. However, such work modifies and\nshrinks the action space from the game's original. This is to avoid trying\n\"pointless\" actions and to ease the implementation. Currently, this is mostly\ndone based on intuition, with little systematic research supporting the design\ndecisions. In this work, we aim to gain insight on these action space\nmodifications by conducting extensive experiments in video-game environments.\nOur results show how domain-specific removal of actions and discretization of\ncontinuous actions can be crucial for successful learning. With these insights,\nwe hope to ease the use of RL in new environments, by clarifying what\naction-spaces are easy to learn.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 13:25:55 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 09:25:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Scheller", "Christian", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2004.00981", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Joonas Pussinen, Ville Hautam\\\"aki", "title": "Benchmarking End-to-End Behavioural Cloning on Video Games", "comments": "To appear in IEEE Conference on Games 2020. Experiment code available\n  at https://github.com/joonaspu/video-game-behavioural-cloning and\n  https://github.com/joonaspu/ViControl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioural cloning, where a computer is taught to perform a task based on\ndemonstrations, has been successfully applied to various video games and\nrobotics tasks, with and without reinforcement learning. This also includes\nend-to-end approaches, where a computer plays a video game like humans do: by\nlooking at the image displayed on the screen, and sending keystrokes to the\ngame. As a general approach to playing video games, this has many inviting\nproperties: no need for specialized modifications to the game, no lengthy\ntraining sessions and the ability to re-use the same tools across different\ngames. However, related work includes game-specific engineering to achieve the\nresults. We take a step towards a general approach and study the general\napplicability of behavioural cloning on twelve video games, including six\nmodern video games (published after 2010), by using human demonstrations as\ntraining data. Our results show that these agents cannot match humans in raw\nperformance but do learn basic dynamics and rules. We also demonstrate how the\nquality of the data matters, and how recording data from humans is subject to a\nstate-action mismatch, due to human reflexes.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 13:31:51 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:50:11 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Pussinen", "Joonas", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2004.00993", "submitter": "Xiao Lei Zhang", "authors": "Xiao Lei Zhang, Anish Agarwal", "title": "Augmented Q Imitation Learning (AQIL)", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of unsupervised learning can be generally divided into two\ncategories: imitation learning and reinforcement learning. In imitation\nlearning the machine learns by mimicking the behavior of an expert system\nwhereas in reinforcement learning the machine learns via direct environment\nfeedback. Traditional deep reinforcement learning takes a significant time\nbefore the machine starts to converge to an optimal policy. This paper proposes\nAugmented Q-Imitation-Learning, a method by which deep reinforcement learning\nconvergence can be accelerated by applying Q-imitation-learning as the initial\ntraining process in traditional Deep Q-learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:08:23 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 17:16:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Xiao Lei", ""], ["Agarwal", "Anish", ""]]}, {"id": "2004.00994", "submitter": "Uri Shaham", "authors": "Uri Shaham, Tom Zahavy, Cesar Caraballo, Shiwani Mahajan, Daisy\n  Massey, Harlan Krumholz", "title": "Learning to Ask Medical Questions using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reinforcement learning-based approach for adaptive and\niterative feature selection. Given a masked vector of input features, a\nreinforcement learning agent iteratively selects certain features to be\nunmasked, and uses them to predict an outcome when it is sufficiently\nconfident. The algorithm makes use of a novel environment setting,\ncorresponding to a non-stationary Markov Decision Process. A key component of\nour approach is a guesser network, trained to predict the outcome from the\nselected features and parametrizing the reward function. Applying our method to\na national survey dataset, we show that it not only outperforms strong\nbaselines when requiring the prediction to be made based on a small number of\ninput features, but is also highly more interpretable. Our code is publicly\navailable at \\url{https://github.com/ushaham/adaptiveFS}.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:21:46 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 08:13:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Shaham", "Uri", ""], ["Zahavy", "Tom", ""], ["Caraballo", "Cesar", ""], ["Mahajan", "Shiwani", ""], ["Massey", "Daisy", ""], ["Krumholz", "Harlan", ""]]}, {"id": "2004.01056", "submitter": "Luciano Cavalcante Siebert", "authors": "Luciano Cavalcante Siebert, Rijk Mercuur, Virginia Dignum, Jeroen van\n  den Hoven, Catholijn Jonker", "title": "Improving Confidence in the Estimation of Values and Norms", "comments": "16 pages, 3 figures, pre-print for the International Workshop on\n  Coordination, Organizations, Institutions, Norms and Ethics for Governance of\n  Multi-Agent Systems (COINE), co-located with AAMAS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-72376-7_6", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents (AA) will increasingly be interacting with us in our daily\nlives. While we want the benefits attached to AAs, it is essential that their\nbehavior is aligned with our values and norms. Hence, an AA will need to\nestimate the values and norms of the humans it interacts with, which is not a\nstraightforward task when solely observing an agent's behavior. This paper\nanalyses to what extent an AA is able to estimate the values and norms of a\nsimulated human agent (SHA) based on its actions in the ultimatum game. We\npresent two methods to reduce ambiguity in profiling the SHAs: one based on\nsearch space exploration and another based on counterfactual analysis. We found\nthat both methods are able to increase the confidence in estimating human\nvalues and norms, but differ in their applicability, the latter being more\nefficient when the number of interactions with the agent is to be minimized.\nThese insights are useful to improve the alignment of AAs with human values and\nnorms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:03:03 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Siebert", "Luciano Cavalcante", ""], ["Mercuur", "Rijk", ""], ["Dignum", "Virginia", ""], ["Hoven", "Jeroen van den", ""], ["Jonker", "Catholijn", ""]]}, {"id": "2004.01098", "submitter": "Weichao Mao", "authors": "Weichao Mao, Kaiqing Zhang, Erik Miehling, Tamer Ba\\c{s}ar", "title": "Information State Embedding in Partially Observable Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "Accepted to CDC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) under partial observability has\nlong been considered challenging, primarily due to the requirement for each\nagent to maintain a belief over all other agents' local histories -- a domain\nthat generally grows exponentially over time. In this work, we investigate a\npartially observable MARL problem in which agents are cooperative. To enable\nthe development of tractable algorithms, we introduce the concept of an\ninformation state embedding that serves to compress agents' histories. We\nquantify how the compression error influences the resulting value functions for\ndecentralized control. Furthermore, we propose an instance of the embedding\nbased on recurrent neural networks (RNNs). The embedding is then used as an\napproximate information state, and can be fed into any MARL algorithm. The\nproposed embed-then-learn pipeline opens the black-box of existing (partially\nobservable) MARL algorithms, allowing us to establish some theoretical\nguarantees (error bounds of value functions) while still achieving competitive\nperformance with many end-to-end approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:03:42 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 16:35:16 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 03:55:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mao", "Weichao", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2004.01167", "submitter": "Francisco Javier D\\'iez", "authors": "Iago Par\\'is, Raquel S\\'anchez-Cauce, Francisco Javier D\\'iez", "title": "Sum-product networks: A survey", "comments": "24 pages, 6 figures, 97 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sum-product network (SPN) is a probabilistic model, based on a rooted\nacyclic directed graph, in which terminal nodes represent univariate\nprobability distributions and non-terminal nodes represent convex combinations\n(weighted sums) and products of probability functions. They are closely related\nto probabilistic graphical models, in particular to Bayesian networks with\nmultiple context-specific independencies. Their main advantage is the\npossibility of building tractable models from data, i.e., models that can\nperform several inference tasks in time proportional to the number of links in\nthe graph. They are somewhat similar to neural networks and can address the\nsame kinds of problems, such as image processing and natural language\nunderstanding. This paper offers a survey of SPNs, including their definition,\nthe main algorithms for inference and learning from data, the main\napplications, a brief review of software libraries, and a comparison with\nrelated models\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:46:29 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Par\u00eds", "Iago", ""], ["S\u00e1nchez-Cauce", "Raquel", ""], ["D\u00edez", "Francisco Javier", ""]]}, {"id": "2004.01168", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra, Edgar Meij", "title": "Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy\n  Link Prediction", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Little is known about the trustworthiness of predictions made by knowledge\ngraph embedding (KGE) models. In this paper we take initial steps toward this\ndirection by investigating the calibration of KGE models, or the extent to\nwhich they output confidence scores that reflect the expected correctness of\npredicted knowledge graph triples. We first conduct an evaluation under the\nstandard closed-world assumption (CWA), in which predicted triples not already\nin the knowledge graph are considered false, and show that existing calibration\ntechniques are effective for KGE under this common but narrow assumption. Next,\nwe introduce the more realistic but challenging open-world assumption (OWA), in\nwhich unobserved predictions are not considered true or false until\nground-truth labels are obtained. Here, we show that existing calibration\ntechniques are much less effective under the OWA than the CWA, and provide\nexplanations for this discrepancy. Finally, to motivate the utility of\ncalibration for KGE from a practitioner's perspective, we conduct a unique case\nstudy of human-AI collaboration, showing that calibrated predictions can\nimprove human performance in a knowledge graph completion task.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:46:47 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:02:54 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 09:31:15 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""], ["Meij", "Edgar", ""]]}, {"id": "2004.01218", "submitter": "Eli Sherman", "authors": "Eli Sherman, David Arbour, Ilya Shpitser", "title": "General Identification of Dynamic Treatment Regimes Under Interference", "comments": "2020 Conference on Artificial Intelligence and Statistics (AIStats)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applied fields, researchers are often interested in tailoring\ntreatments to unit-level characteristics in order to optimize an outcome of\ninterest. Methods for identifying and estimating treatment policies are the\nsubject of the dynamic treatment regime literature. Separately, in many\nsettings the assumption that data are independent and identically distributed\ndoes not hold due to inter-subject dependence. The phenomenon where a subject's\noutcome is dependent on his neighbor's exposure is known as interference. These\nareas intersect in myriad real-world settings. In this paper we consider the\nproblem of identifying optimal treatment policies in the presence of\ninterference. Using a general representation of interference, via\nLauritzen-Wermuth-Freydenburg chain graphs (Lauritzen and Richardson, 2002), we\nformalize a variety of policy interventions under interference and extend\nexisting identification theory (Tian, 2008; Sherman and Shpitser, 2018).\nFinally, we illustrate the efficacy of policy maximization under interference\nin a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:22:59 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Sherman", "Eli", ""], ["Arbour", "David", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2004.01223", "submitter": "Ramtin Keramati", "authors": "Ramtin Keramati, Emma Brunskill", "title": "Value Driven Representation for Human-in-the-Loop Reinforcement Learning", "comments": null, "journal-ref": "UMAP 2019, 27th ACM Conference on User Modeling, Adaptation and\n  Personalization", "doi": "10.1145/3320435.3320471", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive adaptive systems powered by Reinforcement Learning (RL) have many\npotential applications, such as intelligent tutoring systems. In such systems\nthere is typically an external human system designer that is creating,\nmonitoring and modifying the interactive adaptive system, trying to improve its\nperformance on the target outcomes. In this paper we focus on algorithmic\nfoundation of how to help the system designer choose the set of sensors or\nfeatures to define the observation space used by reinforcement learning agent.\nWe present an algorithm, value driven representation (VDR), that can\niteratively and adaptively augment the observation space of a reinforcement\nlearning agent so that is sufficient to capture a (near) optimal policy. To do\nso we introduce a new method to optimistically estimate the value of a policy\nusing offline simulated Monte Carlo rollouts. We evaluate the performance of\nour approach on standard RL benchmarks with simulated humans and demonstrate\nsignificant improvement over prior baselines.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:45:45 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Keramati", "Ramtin", ""], ["Brunskill", "Emma", ""]]}, {"id": "2004.01251", "submitter": "Ran Wang", "authors": "Ran Wang, Kun Tao, Dingjie Song, Zhilong Zhang, Xiao Ma, Xi'ao Su,\n  Xinyu Dai", "title": "R3: A Reading Comprehension Benchmark Requiring Reasoning Processes", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing question answering systems can only predict answers without explicit\nreasoning processes, which hinder their explainability and make us overestimate\ntheir ability of understanding and reasoning over natural language. In this\nwork, we propose a novel task of reading comprehension, in which a model is\nrequired to provide final answers and reasoning processes. To this end, we\nintroduce a formalism for reasoning over unstructured text, namely Text\nReasoning Meaning Representation (TRMR). TRMR consists of three phrases, which\nis expressive enough to characterize the reasoning process to answer reading\ncomprehension questions. We develop an annotation platform to facilitate TRMR's\nannotation, and release the R3 dataset, a \\textbf{R}eading comprehension\nbenchmark \\textbf{R}equiring \\textbf{R}easoning processes. R3 contains over 60K\npairs of question-answer pairs and their TRMRs. Our dataset is available at:\n\\url{http://anonymous}.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 20:39:12 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wang", "Ran", ""], ["Tao", "Kun", ""], ["Song", "Dingjie", ""], ["Zhang", "Zhilong", ""], ["Ma", "Xiao", ""], ["Su", "Xi'ao", ""], ["Dai", "Xinyu", ""]]}, {"id": "2004.01274", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Does Comma Selection Help To Cope With Local Optima", "comments": "36 pages. Full version of a paper that appeared at GECCO 2020", "journal-ref": null, "doi": "10.1145/3377930.3389823", "report-no": null, "categories": "cs.NE cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One hope when using non-elitism in evolutionary computation is that the\nability to abandon the current-best solution aids leaving local optima. To\nimprove our understanding of this mechanism, we perform a rigorous runtime\nanalysis of a basic non-elitist evolutionary algorithm (EA), the\n$(\\mu,\\lambda)$ EA, on the most basic benchmark function with a local optimum,\nthe jump function. We prove that for all reasonable values of the parameters\nand the problem, the expected runtime of the $(\\mu,\\lambda)$~EA is, apart from\nlower order terms, at least as large as the expected runtime of its elitist\ncounterpart, the $(\\mu+\\lambda)$~EA (for which we conduct the first runtime\nanalysis on jump functions to allow this comparison). Consequently, the ability\nof the $(\\mu,\\lambda)$~EA to leave local optima to inferior solutions does not\nlead to a runtime advantage.\n  We complement this lower bound with an upper bound that, for broad ranges of\nthe parameters, is identical to our lower bound apart from lower order terms.\nThis is the first runtime result for a non-elitist algorithm on a multi-modal\nproblem that is tight apart from lower order terms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 21:39:33 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 11:47:10 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "2004.01387", "submitter": "Supriyo Ghosh", "authors": "Supriyo Ghosh, Sean Laguna, Shiau Hong Lim, Laura Wynter and Hasan\n  Poonawala", "title": "A Deep Ensemble Multi-Agent Reinforcement Learning Approach for Air\n  Traffic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic control is an example of a highly challenging operational problem\nthat is readily amenable to human expertise augmentation via decision support\ntechnologies. In this paper, we propose a new intelligent decision making\nframework that leverages multi-agent reinforcement learning (MARL) to\ndynamically suggest adjustments of aircraft speeds in real-time. The goal of\nthe system is to enhance the ability of an air traffic controller to provide\neffective guidance to aircraft to avoid air traffic congestion, near-miss\nsituations, and to improve arrival timeliness. We develop a novel deep ensemble\nMARL method that can concisely capture the complexity of the air traffic\ncontrol problem by learning to efficiently arbitrate between the decisions of a\nlocal kernel-based RL model and a wider-reaching deep MARL model. The proposed\nmethod is trained and evaluated on an open-source air traffic management\nsimulator developed by Eurocontrol. Extensive empirical results on a real-world\ndataset including thousands of aircraft demonstrate the feasibility of using\nmulti-agent RL for the problem of en-route air traffic control and show that\nour proposed deep ensemble MARL method significantly outperforms three\nstate-of-the-art benchmark approaches.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 06:03:53 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ghosh", "Supriyo", ""], ["Laguna", "Sean", ""], ["Lim", "Shiau Hong", ""], ["Wynter", "Laura", ""], ["Poonawala", "Hasan", ""]]}, {"id": "2004.01430", "submitter": "Sebastien Gros Prof.", "authors": "Sebastien Gros, Mario Zanon", "title": "Reinforcement Learning for Mixed-Integer Problems Based on MPC", "comments": "Accepted at IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model Predictive Control has been recently proposed as policy approximation\nfor Reinforcement Learning, offering a path towards safe and explainable\nReinforcement Learning. This approach has been investigated for Q-learning and\nactor-critic methods, both in the context of nominal Economic MPC and Robust\n(N)MPC, showing very promising results. In that context, actor-critic methods\nseem to be the most reliable approach. Many applications include a mixture of\ncontinuous and integer inputs, for which the classical actor-critic methods\nneed to be adapted. In this paper, we present a policy approximation based on\nmixed-integer MPC schemes, and propose a computationally inexpensive technique\nto generate exploration in the mixed-integer input space that ensures a\nsatisfaction of the constraints. We then propose a simple compatible advantage\nfunction approximation for the proposed policy, that allows one to build the\ngradient of the mixed-integer MPC-based policy.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 08:43:27 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Gros", "Sebastien", ""], ["Zanon", "Mario", ""]]}, {"id": "2004.01431", "submitter": "Zina Ibrahim", "authors": "Zina Ibrahim, Honghan Wu, Richard Dobson", "title": "Modeling Rare Interactions in Time Series Data Through Qualitative\n  Change: Application to Outcome Prediction in Intensive Care Units", "comments": "8 pages, 3 figures. Accepted for publication in the European\n  Conference of Artificial Intelligence (ECAI 2020)", "journal-ref": "European Conference on Artificial Intelligence 325(2020) 1826-1833", "doi": "10.3233/FAIA200298", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many areas of research are characterised by the deluge of large-scale\nhighly-dimensional time-series data. However, using the data available for\nprediction and decision making is hampered by the current lag in our ability to\nuncover and quantify true interactions that explain the outcomes.We are\ninterested in areas such as intensive care medicine, which are characterised by\ni) continuous monitoring of multivariate variables and non-uniform sampling of\ndata streams, ii) the outcomes are generally governed by interactions between a\nsmall set of rare events, iii) these interactions are not necessarily definable\nby specific values (or value ranges) of a given group of variables, but rather,\nby the deviations of these values from the normal state recorded over time, iv)\nthe need to explain the predictions made by the model. Here, while numerous\ndata mining models have been formulated for outcome prediction, they are unable\nto explain their predictions.\n  We present a model for uncovering interactions with the highest likelihood of\ngenerating the outcomes seen from highly-dimensional time series data.\nInteractions among variables are represented by a relational graph structure,\nwhich relies on qualitative abstractions to overcome non-uniform sampling and\nto capture the semantics of the interactions corresponding to the changes and\ndeviations from normality of variables of interest over time. Using the\nassumption that similar templates of small interactions are responsible for the\noutcomes (as prevalent in the medical domains), we reformulate the discovery\ntask to retrieve the most-likely templates from the data.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 08:49:40 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ibrahim", "Zina", ""], ["Wu", "Honghan", ""], ["Dobson", "Richard", ""]]}, {"id": "2004.01521", "submitter": "Zvezdin Besarabov", "authors": "Zvezdin Besarabov, Todor Kolev", "title": "Trustless parallel local search for effective distributed algorithm\n  discovery", "comments": "Submitted to IEEE Blockchain: From Technology to Marketplaces. arXiv\n  admin note: text overlap with arXiv:1909.03848", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metaheuristic search strategies have proven their effectiveness against\nman-made solutions in various contexts. They are generally effective in local\nsearch area exploitation, and their overall performance is largely impacted by\nthe balance between exploration and exploitation.\n  Recent developments in parallel local search explore methods to take\nadvantage of the efficient local exploitation of searches and reach impressive\nresults. This however restricts the scaling potential to nodes within a\nprivate, trusted computer cluster.\n  In this research we propose a novel blockchain protocol that allows parallel\nlocal search to scale to untrusted and anonymous computational nodes. The\nprotocol introduces publicly verifiable performance evaluation of the local\noptima reported by each node, creating a competitive environment between the\nlocal searches. That is strengthened with economical stimuli for producing good\nsolutions, that provide coordination between the nodes, as every node tries to\nexplore different sections of the search space to beat their competition.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 12:03:38 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Besarabov", "Zvezdin", ""], ["Kolev", "Todor", ""]]}, {"id": "2004.01608", "submitter": "Paulo Roberto de Oliveira da Costa", "authors": "Paulo R. de O. da Costa, Jason Rhuggenaath, Yingqian Zhang, Alp Akcay", "title": "Learning 2-opt Heuristics for the Traveling Salesman Problem via Deep\n  Reinforcement Learning", "comments": "To appear in Proceedings Machine Learning Research - ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works using deep learning to solve the Traveling Salesman Problem\n(TSP) have focused on learning construction heuristics. Such approaches find\nTSP solutions of good quality but require additional procedures such as beam\nsearch and sampling to improve solutions and achieve state-of-the-art\nperformance. However, few studies have focused on improvement heuristics, where\na given solution is improved until reaching a near-optimal one. In this work,\nwe propose to learn a local search heuristic based on 2-opt operators via deep\nreinforcement learning. We propose a policy gradient algorithm to learn a\nstochastic policy that selects 2-opt operations given a current solution.\nMoreover, we introduce a policy neural network that leverages a pointing\nattention mechanism, which unlike previous works, can be easily extended to\nmore general k-opt moves. Our results show that the learned policies can\nimprove even over random initial solutions and approach near-optimal solutions\nat a faster rate than previous state-of-the-art deep learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:51:54 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 09:50:53 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 16:20:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Rhuggenaath", "Jason", ""], ["Zhang", "Yingqian", ""], ["Akcay", "Alp", ""]]}, {"id": "2004.01694", "submitter": "Samuel L\\\"aubli", "authors": "Samuel L\\\"aubli and Sheila Castilho and Graham Neubig and Rico\n  Sennrich and Qinlan Shen and Antonio Toral", "title": "A Set of Recommendations for Assessing Human-Machine Parity in Language\n  Translation", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 67 (2020) 653-672", "doi": "10.1613/jair.1.11371", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of machine translation has increased remarkably over the past\nyears, to the degree that it was found to be indistinguishable from\nprofessional human translation in a number of empirical investigations. We\nreassess Hassan et al.'s 2018 investigation into Chinese to English news\ntranslation, showing that the finding of human-machine parity was owed to\nweaknesses in the evaluation design - which is currently considered best\npractice in the field. We show that the professional human translations\ncontained significantly fewer errors, and that perceived quality in human\nevaluation depends on the choice of raters, the availability of linguistic\ncontext, and the creation of reference translations. Our results call for\nrevisiting current best practices to assess strong machine translation systems\nin general and human-machine parity in particular, for which we offer a set of\nrecommendations based on our empirical findings.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:49:56 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["L\u00e4ubli", "Samuel", ""], ["Castilho", "Sheila", ""], ["Neubig", "Graham", ""], ["Sennrich", "Rico", ""], ["Shen", "Qinlan", ""], ["Toral", "Antonio", ""]]}, {"id": "2004.01697", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez, Jose Font, Julian Togelius", "title": "Designer Modeling through Design Style Clustering", "comments": "10 pages, Submitted to IEEE Transactions on Games (TOG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose modeling designer style in mixed-initiative game content creation\ntools as archetypical design traces. These design traces are formulated as\ntransitions between design styles; these design styles are in turn found\nthrough clustering all intermediate designs along the way to making a complete\ndesign. This method is implemented in the Evolutionary Dungeon Designer, a\nresearch platform for mixed-initiative systems to create roguelike games. We\npresent results both in the form of design styles for rooms, which can be\nanalyzed to better understand the kind of rooms designed by users, and in the\nform of archetypical sequences between these rooms. We further discuss how the\nresults here can be used to create style-sensitive suggestions. Such\nsuggestions would allow the system to be one step ahead of the designer,\noffering suggestions for the next cluster, assuming that the designer will\nfollow one of the archetypical design traces.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:57:41 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 13:41:35 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alvarez", "Alberto", ""], ["Font", "Jose", ""], ["Togelius", "Julian", ""]]}, {"id": "2004.01703", "submitter": "Jacob Schrum", "authors": "Jacob Schrum and Vanessa Volz and Sebastian Risi", "title": "CPPN2GAN: Combining Compositional Pattern Producing Networks and GANs\n  for Large-scale Pattern Generation", "comments": "GECCO 2020. arXiv admin note: text overlap with arXiv:2004.00151", "journal-ref": null, "doi": "10.1145/3377930.3389822", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are proving to be a powerful indirect\ngenotype-to-phenotype mapping for evolutionary search, but they have\nlimitations. In particular, GAN output does not scale to arbitrary dimensions,\nand there is no obvious way of combining multiple GAN outputs into a cohesive\nwhole, which would be useful in many areas, such as the generation of video\ngame levels. Game levels often consist of several segments, sometimes repeated\ndirectly or with variation, organized into an engaging pattern. Such patterns\ncan be produced with Compositional Pattern Producing Networks (CPPNs).\nSpecifically, a CPPN can define latent vector GAN inputs as a function of\ngeometry, which provides a way to organize level segments output by a GAN into\na complete level. This new CPPN2GAN approach is validated in both Super Mario\nBros. and The Legend of Zelda. Specifically, divergent search via MAP-Elites\ndemonstrates that CPPN2GAN can better cover the space of possible levels. The\nlayouts of the resulting levels are also more cohesive and aesthetically\nconsistent.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 04:29:43 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Schrum", "Jacob", ""], ["Volz", "Vanessa", ""], ["Risi", "Sebastian", ""]]}, {"id": "2004.01740", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Shruthi Bannur, Prateek Jain, Srujana Merugu", "title": "COVID-19: Strategies for Allocation of Test Kits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing spread of COVID-19, it is important to systematically\ntest more and more people. The current strategy for test-kit allocation is\nmostly rule-based, focusing on individuals having (a) symptoms for COVID-19,\n(b) travel history or (c) contact history with confirmed COVID-19 patients.\nSuch testing strategy may miss out on detecting asymptomatic individuals who\ngot infected via community spread. Thus, it is important to allocate a separate\nbudget of test-kits per day targeted towards preventing community spread and\ndetecting new cases early on.\n  In this report, we consider the problem of allocating test-kits and discuss\nsome solution approaches. We believe that these approaches will be useful to\ncontain community spread and detect new cases early on. Additionally, these\napproaches would help in collecting unbiased data which can then be used to\nimprove the accuracy of machine learning models trained to predict COVID-19\ninfections.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 19:02:59 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Biswas", "Arpita", ""], ["Bannur", "Shruthi", ""], ["Jain", "Prateek", ""], ["Merugu", "Srujana", ""]]}, {"id": "2004.01768", "submitter": "Michael Cook", "authors": "Michael Cook", "title": "Generative Forensics: Procedural Generation and Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural generation is used across game design to achieve a wide variety of\nends, and has led to the creation of several game subgenres by injecting\nvariance, surprise or unpredictability into otherwise static designs.\nInformation games are a type of mystery game in which the player is tasked with\ngathering knowledge and developing an understanding of an event or system.\nTheir reliance on player knowledge leaves them vulnerable to spoilers and hard\nto replay. In this paper we introduce the notion of generative forensics games,\na subgenre of information games that challenge the player to understand the\noutput of a generative system. We introduce information games, show how\ngenerative forensics develops the idea, report on two prototype games we\ncreated, and evaluate our work on generative forensics so far from a player and\na designer perspective.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:51:16 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Cook", "Michael", ""]]}, {"id": "2004.01770", "submitter": "Michael Cook", "authors": "Michael Cook", "title": "Software Engineering For Automated Game Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we develop more assistive and automated game design systems, the question\nof how these systems should be integrated into game development workflows, and\nhow much adaptation may be required, becomes increasingly important. In this\npaper we explore the impact of software engineering decisions on the ability of\nan automated game design system to understand a game's codebase, generate new\ngame code, and evaluate its work. We argue that a new approach to software\nengineering may be required in order for game developers to fully benefit from\nautomated game designers.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:56:51 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Cook", "Michael", ""]]}, {"id": "2004.01781", "submitter": "Daniel Reissner", "authors": "Daniel Rei{\\ss}ner, Abel Armas-Cervantes, Marcello La Rosa", "title": "Efficient Conformance Checking using Alignment Computation with Tandem\n  Repeats", "comments": "arXiv admin note: text overlap with arXiv:1910.09767", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformance checking encompasses a body of process mining techniques which\naim to find and describe the differences between a process model capturing the\nexpected process behavior and a corresponding event log recording the observed\nbehavior. Alignments are an established technique to compute the distance\nbetween a trace in the event log and the closest execution trace of a\ncorresponding process model. Given a cost function, an alignment is optimal\nwhen it contains the least number of mismatches between a log trace and a model\ntrace. Determining optimal alignments, however, is computationally expensive,\nespecially in light of the growing size and complexity of event logs from\npractice, which can easily exceed one million events with traces of several\nhundred activities. A common limitation of existing alignment techniques is the\ninability to exploit repetitions in the log. By exploiting a specific form of\nsequential pattern in traces, namely tandem repeats, we propose a novel\ntechnique that uses pre- and post-processing steps to compress the length of a\ntrace and recomputes the alignment cost while guaranteeing that the cost result\nnever under-approximates the optimal cost. In an extensive empirical evaluation\nwith 50 real-life model-log pairs and against five state-of-the-art alignment\ntechniques, we show that the proposed compression approach systematically\noutperforms the baselines by up to an order of magnitude in the presence of\ntraces with repetitions, and that the cost over-approximation, when it occurs,\nis negligible.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 03:50:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Rei\u00dfner", "Daniel", ""], ["Armas-Cervantes", "Abel", ""], ["La Rosa", "Marcello", ""]]}, {"id": "2004.01909", "submitter": "Jimmy Lin", "authors": "Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai,\n  Chuan-Ju Wang, Jimmy Lin", "title": "Conversational Question Reformulation via Sequence-to-Sequence\n  Architectures and Pretrained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical study of conversational question\nreformulation (CQR) with sequence-to-sequence architectures and pretrained\nlanguage models (PLMs). We leverage PLMs to address the strong token-to-token\nindependence assumption made in the common objective, maximum likelihood\nestimation, for the CQR task. In CQR benchmarks of task-oriented dialogue\nsystems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset\nas an in-domain task and validate the models using data from the TREC 2019 CAsT\nTrack as an out-domain task. Examining a variety of architectures with\ndifferent numbers of parameters, we demonstrate that the recent text-to-text\ntransfer transformer (T5) achieves the best results both on CANARD and CAsT\nwith fewer parameters, compared to similar transformer architectures.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 11:07:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lin", "Sheng-Chieh", ""], ["Yang", "Jheng-Hong", ""], ["Nogueira", "Rodrigo", ""], ["Tsai", "Ming-Feng", ""], ["Wang", "Chuan-Ju", ""], ["Lin", "Jimmy", ""]]}, {"id": "2004.01949", "submitter": "Vinoth Pandian Sermuga Pandian", "authors": "Vinoth Pandian Sermuga Pandian, Sarah Suleri", "title": "BlackBox Toolkit: Intelligent Assistance to UI Design", "comments": "Workshop position paper for CHI'20, Workshop on Artificial\n  Intelligence for HCI: A Modern Approach; 4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  User Interface (UI) design is an creative process that involves considerable\nreiteration and rework. Designers go through multiple iterations of different\nprototyping fidelities to create a UI design. In this research, we propose to\nmodify the UI design process by assisting it with artificial intelligence (AI).\nWe propose to enable AI to perform repetitive tasks for the designer while\nallowing the designer to take command of the creative process. This approach\nmakes the machine act as a black box that intelligently assists the designers\nin creating UI design. We believe this approach would greatly benefit designers\nin co-creating design solutions with AI.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 14:50:26 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 13:30:41 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Pandian", "Vinoth Pandian Sermuga", ""], ["Suleri", "Sarah", ""]]}, {"id": "2004.01980", "submitter": "Di Jin", "authors": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, Lisa Orii, Peter Szolovits", "title": "Hooks in the Headline: Learning to Generate Headlines with Controlled\n  Styles", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": "12 pages", "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current summarization systems only produce plain, factual headlines, but do\nnot meet the practical needs of creating memorable titles to increase exposure.\nWe propose a new task, Stylistic Headline Generation (SHG), to enrich the\nheadlines with three style options (humor, romance and clickbait), in order to\nattract more readers. With no style-specific article-headline pair (only a\nstandard headline summarization dataset and mono-style corpora), our method\nTitleStylist generates style-specific headlines by combining the summarization\nand reconstruction tasks into a multitasking framework. We also introduced a\nnovel parameter sharing scheme to further disentangle the style from the text.\nThrough both automatic and human evaluation, we demonstrate that TitleStylist\ncan generate relevant, fluent headlines with three target styles: humor,\nromance, and clickbait. The attraction score of our model generated headlines\nsurpasses that of the state-of-the-art summarization model by 9.68%, and even\noutperforms human-written references.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 17:24:47 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 18:48:19 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 02:21:37 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Zhou", "Joey Tianyi", ""], ["Orii", "Lisa", ""], ["Szolovits", "Peter", ""]]}, {"id": "2004.01981", "submitter": "Ze Yang", "authors": "Ze Yang, Wei Wu, Huang Hu, Can Xu, Wei Wang, Zhoujun Li", "title": "Open Domain Dialogue Generation with Latent Images", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider grounding open domain dialogues with images. Existing work\nassumes that both an image and a textual context are available, but\nimage-grounded dialogues by nature are more difficult to obtain than textual\ndialogues. Thus, we propose learning a response generation model with both\nimage-grounded dialogues and textual dialogues by assuming that the visual\nscene information at the time of a conversation can be represented by an image,\nand trying to recover the latent images of the textual dialogues through\ntext-to-image generation techniques. The likelihood of the two types of\ndialogues is then formulated by a response generator and an image reconstructor\nthat are learned within a conditional variational auto-encoding framework.\nEmpirical studies are conducted in both image-grounded conversation and\ntext-based conversation. In the first scenario, image-grounded dialogues,\nespecially under a low-resource setting, can be effectively augmented by\ntextual dialogues with latent images; while in the second scenario, latent\nimages can enrich the content of responses and at the same time keep them\nrelevant to contexts.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 17:32:46 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 07:43:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Yang", "Ze", ""], ["Wu", "Wei", ""], ["Hu", "Huang", ""], ["Xu", "Can", ""], ["Wang", "Wei", ""], ["Li", "Zhoujun", ""]]}, {"id": "2004.02001", "submitter": "Ming Tu", "authors": "Ming Tu, Jing Huang, Xiaodong He, Bowen Zhou", "title": "Graph Sequential Network for Reasoning over Sequences", "comments": "Part of this paper was presented at NeurIPS 2019 Workshop on Graph\n  Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Graph Neural Network (GNN) has been applied successfully to various\nNLP tasks that require reasoning, such as multi-hop machine reading\ncomprehension. In this paper, we consider a novel case where reasoning is\nneeded over graphs built from sequences, i.e. graph nodes with sequence data.\nExisting GNN models fulfill this goal by first summarizing the node sequences\ninto fixed-dimensional vectors, then applying GNN on these vectors. To avoid\ninformation loss inherent in the early summarization and make sequential\nlabeling tasks on GNN output feasible, we propose a new type of GNN called\nGraph Sequential Network (GSN), which features a new message passing algorithm\nbased on co-attention between a node and each of its neighbors. We validate the\nproposed GSN on two NLP tasks: interpretable multi-hop reading comprehension on\nHotpotQA and graph based fact verification on FEVER. Both tasks require\nreasoning over multiple documents or sentences. Our experimental results show\nthat the proposed GSN attains better performance than the standard GNN based\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 19:18:54 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Tu", "Ming", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "2004.02002", "submitter": "Tiancheng Zhao", "authors": "Tianchang Zhao and Kyusong Lee", "title": "Talk to Papers: Bringing Neural Question Answering to Academic Search", "comments": "demo paper accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Talk to Papers, which exploits the recent open-domain question\nanswering (QA) techniques to improve the current experience of academic search.\nIt's designed to enable researchers to use natural language queries to find\nprecise answers and extract insights from a massive amount of academic papers.\nWe present a large improvement over classic search engine baseline on several\nstandard QA datasets and provide the community a collaborative data collection\ntool to curate the first natural language processing research QA dataset via a\ncommunity effort.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 19:19:55 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 14:38:11 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 20:26:28 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Zhao", "Tianchang", ""], ["Lee", "Kyusong", ""]]}, {"id": "2004.02028", "submitter": "Bhavya Ghai", "authors": "Bhavya Ghai, Q. Vera Liao, Yunfeng Zhang, Klaus Mueller", "title": "Measuring Social Biases of Crowd Workers using Counterfactual Queries", "comments": "Accepted at the Workshop on Fair and Responsible AI at ACM CHI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social biases based on gender, race, etc. have been shown to pollute machine\nlearning (ML) pipeline predominantly via biased training datasets.\nCrowdsourcing, a popular cost-effective measure to gather labeled training\ndatasets, is not immune to the inherent social biases of crowd workers. To\nensure such social biases aren't passed onto the curated datasets, it's\nimportant to know how biased each crowd worker is. In this work, we propose a\nnew method based on counterfactual fairness to quantify the degree of inherent\nsocial bias in each crowd worker. This extra information can be leveraged\ntogether with individual worker responses to curate a less biased dataset.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 21:41:55 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ghai", "Bhavya", ""], ["Liao", "Q. Vera", ""], ["Zhang", "Yunfeng", ""], ["Mueller", "Klaus", ""]]}, {"id": "2004.02032", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi, Md. Mehrab Tanjim, Julian J. McAuley, and Garrison\n  W. Cottrell", "title": "Generating Rationales in Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in Visual QuestionAnswering (VQA), it remains a\nchallenge todetermine how much success can be attributedto sound reasoning and\ncomprehension ability.We seek to investigate this question by propos-ing a new\ntask ofrationale generation. Es-sentially, we task a VQA model with generat-ing\nrationales for the answers it predicts. Weuse data from the Visual Commonsense\nRea-soning (VCR) task, as it contains ground-truthrationales along with visual\nquestions and an-swers. We first investigate commonsense un-derstanding in one\nof the leading VCR mod-els, ViLBERT, by generating rationales frompretrained\nweights using a state-of-the-art lan-guage model, GPT-2. Next, we seek to\njointlytrain ViLBERT with GPT-2 in an end-to-endfashion with the dual task of\npredicting the an-swer in VQA and generating rationales. Weshow that this kind\nof training injects com-monsense understanding in the VQA modelthrough\nquantitative and qualitative evaluationmetrics\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 22:15:35 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ayyubi", "Hammad A.", ""], ["Tanjim", "Md. Mehrab", ""], ["McAuley", "Julian J.", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "2004.02047", "submitter": "Ivan Brugere", "authors": "Ivan Brugere, Tanya y. Berger-Wolf", "title": "Privacy Shadow: Measuring Node Predictability and Privacy Over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of network data enables simple predictive models to leverage\nlocal correlations between nodes to high accuracy on tasks such as attribute\nand link prediction. While this is useful for building better user models, it\nintroduces the privacy concern that a user's data may be re-inferred from the\nnetwork structure, after they leave the application. We propose the privacy\nshadow for measuring how long a user remains predictive from an arbitrary time\nwithin the network. Furthermore, we demonstrate that the length of the privacy\nshadow can be predicted for individual users in three real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 23:31:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Brugere", "Ivan", ""], ["Berger-Wolf", "Tanya y.", ""]]}, {"id": "2004.02082", "submitter": "Arthur Choi", "authors": "Weijia Shi and Andy Shih and Adnan Darwiche and Arthur Choi", "title": "On Tractable Representations of Binary Neural Networks", "comments": "In Proceedings of the 17th International Conference on Principles of\n  Knowledge Representation and Reasoning (KR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the compilation of a binary neural network's decision function\ninto tractable representations such as Ordered Binary Decision Diagrams (OBDDs)\nand Sentential Decision Diagrams (SDDs). Obtaining this function as an OBDD/SDD\nfacilitates the explanation and formal verification of a neural network's\nbehavior. First, we consider the task of verifying the robustness of a neural\nnetwork, and show how we can compute the expected robustness of a neural\nnetwork, given an OBDD/SDD representation of it. Next, we consider a more\nefficient approach for compiling neural networks, based on a pseudo-polynomial\ntime algorithm for compiling a neuron. We then provide a case study in a\nhandwritten digits dataset, highlighting how two neural networks trained from\nthe same dataset can have very high accuracies, yet have very different levels\nof robustness. Finally, in experiments, we show that it is feasible to obtain\ncompact representations of neural networks as SDDs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 03:21:26 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 03:22:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Shi", "Weijia", ""], ["Shih", "Andy", ""], ["Darwiche", "Adnan", ""], ["Choi", "Arthur", ""]]}, {"id": "2004.02256", "submitter": "K.R. Chowdhary", "authors": "K. R. Chowdhary", "title": "Natural language processing for word sense disambiguation and\n  information extraction", "comments": "150 pages, PhD Thesis", "journal-ref": null, "doi": null, "report-no": "cse-mbm-krc-p-thesis-04", "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research work deals with Natural Language Processing (NLP) and\nextraction of essential information in an explicit form. The most common among\nthe information management strategies is Document Retrieval (DR) and\nInformation Filtering. DR systems may work as combine harvesters, which bring\nback useful material from the vast fields of raw material. With large amount of\npotentially useful information in hand, an Information Extraction (IE) system\ncan then transform the raw material by refining and reducing it to a germ of\noriginal text. A Document Retrieval system collects the relevant documents\ncarrying the required information, from the repository of texts. An IE system\nthen transforms them into information that is more readily digested and\nanalyzed. It isolates relevant text fragments, extracts relevant information\nfrom the fragments, and then arranges together the targeted information in a\ncoherent framework. The thesis presents a new approach for Word Sense\nDisambiguation using thesaurus. The illustrative examples supports the\neffectiveness of this approach for speedy and effective disambiguation. A\nDocument Retrieval method, based on Fuzzy Logic has been described and its\napplication is illustrated. A question-answering system describes the operation\nof information extraction from the retrieved text documents. The process of\ninformation extraction for answering a query is considerably simplified by\nusing a Structured Description Language (SDL) which is based on cardinals of\nqueries in the form of who, what, when, where and why. The thesis concludes\nwith the presentation of a novel strategy based on Dempster-Shafer theory of\nevidential reasoning, for document retrieval and information extraction. This\nstrategy permits relaxation of many limitations, which are inherent in Bayesian\nprobabilistic approach.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 17:13:43 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chowdhary", "K. R.", ""]]}, {"id": "2004.02275", "submitter": "Minh Ho\\`ang H\\`a", "authors": "Minh Ho\\`ang H\\`a and Lam Vu and Duy Manh Vu", "title": "The two-echelon routing problem with truck and drones", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study novel variants of the well-known two-echelon vehicle\nrouting problem in which a truck works on the first echelon to transport\nparcels and a fleet of drones to intermediate depots while in the second\nechelon, the drones are used to deliver parcels from intermediate depots to\ncustomers. The objective is to minimize the completion time instead of the\ntransportation cost as in classical 2-echelon vehicle routing problems.\nDepending on the context, a drone can be launched from the truck at an\nintermediate depot once (single trip drone) or several times (multiple trip\ndrone). Mixed Integer Linear Programming (MILP) models are first proposed to\nformulate mathematically the problems and solve to optimality small-size\ninstances. To handle larger instances, a metaheuristic based on the idea of\nGreedy Randomized Adaptive Search Procedure (GRASP) is introduced. Experimental\nresults obtained on instances of different contexts are reported and analyzed.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:33:16 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["H\u00e0", "Minh Ho\u00e0ng", ""], ["Vu", "Lam", ""], ["Vu", "Duy Manh", ""]]}, {"id": "2004.02289", "submitter": "Jonathan Martinez", "authors": "Jonathan Martinez (1), Kobi Gal (1 and 2), Ece Kamar (3), Levi H. S.\n  Lelis (4) ((1) Ben-Gurion University, (2) University of Edinburgh, (3)\n  Microsoft Research, (4) University of Alberta)", "title": "Personalization in Human-AI Teams: Improving the Compatibility-Accuracy\n  Tradeoff", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems that model and interact with users can update their models over\ntime to reflect new information and changes in the environment. Although these\nupdates may improve the overall performance of the AI system, they may actually\nhurt the performance with respect to individual users. Prior work has studied\nthe trade-off between improving the system's accuracy following an update and\nthe compatibility of the updated system with prior user experience. The more\nthe model is forced to be compatible with a prior version, the higher loss in\naccuracy it will incur. In this paper, we show that by personalizing the loss\nfunction to specific users, in some cases it is possible to improve the\ncompatibility-accuracy trade-off with respect to these users (increase the\ncompatibility of the model while sacrificing less accuracy). We present\nexperimental results indicating that this approach provides moderate\nimprovements on average (around 20%) but large improvements for certain users\n(up to 300%).\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:35:18 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 13:13:22 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Martinez", "Jonathan", "", "1 and 2"], ["Gal", "Kobi", "", "1 and 2"], ["Kamar", "Ece", ""], ["Lelis", "Levi H. S.", ""]]}, {"id": "2004.02304", "submitter": "Gordana Dodig Crnkovic", "authors": "Gordana Dodig-Crnkovic", "title": "Morphological Computation and Learning to Learn In Natural Intelligent\n  Systems And AI", "comments": "5 pages, no figures, AISB 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, artificial intelligence in the form of machine learning is making\nimpressive progress, especially the field of deep learning (DL) [1]. Deep\nlearning algorithms have been inspired from the beginning by nature,\nspecifically by the human brain, in spite of our incomplete knowledge about its\nbrain function. Learning from nature is a two-way process as discussed in\n[2][3][4], computing is learning from neuroscience, while neuroscience is\nquickly adopting information processing models. The question is, what can the\ninspiration from computational nature at this stage of the development\ncontribute to deep learning and how much models and experiments in machine\nlearning can motivate, justify and lead research in neuroscience and cognitive\nscience and to practical applications of artificial intelligence.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 20:11:42 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dodig-Crnkovic", "Gordana", ""]]}, {"id": "2004.02326", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier and Vladimir Makarenkov", "title": "XtracTree for Regulator Validation of Bagging Methods Used in Retail\n  Banking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap aggregation, known as bagging, is one of the most popular ensemble\nmethods used in machine learning (ML). An ensemble method is a supervised ML\nmethod that combines multiple hypotheses to form a single hypothesis used for\nprediction. A bagging algorithm combines multiple classifiers modelled on\ndifferent sub-samples of the same data set to build one large classifier. Large\nretail banks are nowadays using the power of ML algorithms, including decision\ntrees and random forests, to optimize the retail banking activities. However,\nAI bank researchers face a strong challenge from their own model validation\ndepartment as well as from national financial regulators. Each proposed ML\nmodel has to be validated and clear rules for every algorithm-based decision\nhave to be established. In this context, we propose XtracTree, an algorithm\nthat is capable of effectively converting an ML bagging classifier, such as a\ndecision tree or a random forest, into simple \"if-then\" rules satisfying the\nrequirements of model validation. Our algorithm is also capable of highlighting\nthe decision path for each individual sample or a group of samples, addressing\nany concern from the regulators regarding ML \"black-box\". We use a public loan\ndata set from Kaggle to illustrate the usefulness of our approach. Our\nexperiments indicate that, using XtracTree, we are able to ensure a better\nunderstanding for our model, leading to an easier model validation by national\nfinancial regulators and the internal model validation department.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:57:06 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:32:03 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Charlier", "Jeremy", ""], ["Makarenkov", "Vladimir", ""]]}, {"id": "2004.02349", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig, Pawe{\\l} Krzysztof Nowak, Thomas M\\\"uller, Francesco\n  Piccinno, Julian Martin Eisenschlos", "title": "TAPAS: Weakly Supervised Table Parsing via Pre-training", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering natural language questions over tables is usually seen as a\nsemantic parsing task. To alleviate the collection cost of full logical forms,\none popular approach focuses on weak supervision consisting of denotations\ninstead of logical forms. However, training semantic parsers from weak\nsupervision poses difficulties, and in addition, the generated logical forms\nare only used as an intermediate step prior to retrieving the denotation. In\nthis paper, we present TAPAS, an approach to question answering over tables\nwithout generating logical forms. TAPAS trains from weak supervision, and\npredicts the denotation by selecting table cells and optionally applying a\ncorresponding aggregation operator to such selection. TAPAS extends BERT's\narchitecture to encode tables as input, initializes from an effective joint\npre-training of text segments and tables crawled from Wikipedia, and is trained\nend-to-end. We experiment with three different semantic parsing datasets, and\nfind that TAPAS outperforms or rivals semantic parsing models by improving\nstate-of-the-art accuracy on SQA from 55.1 to 67.2 and performing on par with\nthe state-of-the-art on WIKISQL and WIKITQ, but with a simpler model\narchitecture. We additionally find that transfer learning, which is trivial in\nour setting, from WIKISQL to WIKITQ, yields 48.7 accuracy, 4.2 points above the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:18:37 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 15:09:48 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Herzig", "Jonathan", ""], ["Nowak", "Pawe\u0142 Krzysztof", ""], ["M\u00fcller", "Thomas", ""], ["Piccinno", "Francesco", ""], ["Eisenschlos", "Julian Martin", ""]]}, {"id": "2004.02353", "submitter": "Jie Chen", "authors": "Jie Chen, Joel Vaughan, Vijayan N. Nair, Agus Sudjianto", "title": "Adaptive Explainable Neural Networks (AxNNs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning techniques have been successfully applied in several\nfields, the black-box nature of the models presents challenges for interpreting\nand explaining the results. We develop a new framework called Adaptive\nExplainable Neural Networks (AxNN) for achieving the dual goals of good\npredictive performance and model interpretability. For predictive performance,\nwe build a structured neural network made up of ensembles of generalized\nadditive model networks and additive index models (through explainable neural\nnetworks) using a two-stage process. This can be done using either a boosting\nor a stacking ensemble. For interpretability, we show how to decompose the\nresults of AxNN into main effects and higher-order interaction effects. The\ncomputations are inherited from Google's open source tool AdaNet and can be\nefficiently accelerated by training with distributed computing. The results are\nillustrated on simulated and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:40:57 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 06:18:04 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Jie", ""], ["Vaughan", "Joel", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2004.02438", "submitter": "Xuming Hu", "authors": "Xuming Hu, Chenwei Zhang, Yusong Xu, Lijie Wen, Philip S. Yu", "title": "SelfORE: Self-supervised Relational Feature Learning for Open Relation\n  Extraction", "comments": "In EMNLP 2020 as a long paper. Code and data are available at\n  https://github.com/THU-BPM/SelfORE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open relation extraction is the task of extracting open-domain relation facts\nfrom natural language sentences. Existing works either utilize heuristics or\ndistant-supervised annotations to train a supervised classifier over\npre-defined relations, or adopt unsupervised methods with additional\nassumptions that have less discriminative power. In this work, we proposed a\nself-supervised framework named SelfORE, which exploits weak, self-supervised\nsignals by leveraging large pretrained language model for adaptive clustering\non contextualized relational features, and bootstraps the self-supervised\nsignals by improving contextualized features in relation classification.\nExperimental results on three datasets show the effectiveness and robustness of\nSelfORE on open-domain Relation Extraction when comparing with competitive\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:23:17 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 12:32:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Hu", "Xuming", ""], ["Zhang", "Chenwei", ""], ["Xu", "Yusong", ""], ["Wen", "Lijie", ""], ["Yu", "Philip S.", ""]]}, {"id": "2004.02462", "submitter": "Yuval Jacoby", "authors": "Yuval Jacoby, Clark Barrett, Guy Katz", "title": "Verifying Recurrent Neural Networks using Invariant Inference", "comments": "This is the extended version of a paper with the same title that\n  appeared at ATVA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are revolutionizing the way complex systems are\ndeveloped. However, these automatically-generated networks are opaque to\nhumans, making it difficult to reason about them and guarantee their\ncorrectness. Here, we propose a novel approach for verifying properties of a\nwidespread variant of neural networks, called recurrent neural networks.\nRecurrent neural networks play a key role in, e.g., natural language\nprocessing, and their verification is crucial for guaranteeing the reliability\nof many critical systems. Our approach is based on the inference of invariants,\nwhich allow us to reduce the complex problem of verifying recurrent networks\ninto simpler, non-recurrent problems. Experiments with a proof-of-concept\nimplementation of our approach demonstrate that it performs orders-of-magnitude\nbetter than the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 08:08:24 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 08:38:35 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jacoby", "Yuval", ""], ["Barrett", "Clark", ""], ["Katz", "Guy", ""]]}, {"id": "2004.02490", "submitter": "Bruno Yun", "authors": "Bruno Yun and Madalina Croitoru", "title": "Trust-based Multiagent Consensus or Weightings Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for reaching a consensus amongst several agents\ncommunicating via a trust network on conflicting information about their\nenvironment. We formalise our approach and provide an empirical and theoretical\nanalysis of its properties.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 08:50:13 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yun", "Bruno", ""], ["Croitoru", "Madalina", ""]]}, {"id": "2004.02502", "submitter": "Kengo Nakamura", "authors": "Kengo Nakamura, Shuhei Denzumi, Masaaki Nishino", "title": "Variable Shift SDD: A More Succinct Sentential Decision Diagram", "comments": "21 pages; Accepted for SEA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sentential Decision Diagram (SDD) is a tractable representation of\nBoolean functions that subsumes the famous Ordered Binary Decision Diagram\n(OBDD) as a strict subset. SDDs are attracting much attention because they are\nmore succinct than OBDDs, as well as having canonical forms and supporting many\nuseful queries and transformations such as model counting and Apply operation.\nIn this paper, we propose a more succinct variant of SDD named Variable Shift\nSDD (VS-SDD). The key idea is to create a unique representation for Boolean\nfunctions that are equivalent under a specific variable substitution. We show\nthat VS-SDDs are never larger than SDDs and there are cases in which the size\nof a VS-SDD is exponentially smaller than that of an SDD. Moreover, despite\nsuch succinctness, we show that numerous basic operations that are supported in\npolytime with SDD are also supported in polytime with VS-SDD. Experiments\nconfirm that VS-SDDs are significantly more succinct than SDDs when applied to\nclassical planning instances, where inherent symmetry exists.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 09:18:19 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nakamura", "Kengo", ""], ["Denzumi", "Shuhei", ""], ["Nishino", "Masaaki", ""]]}, {"id": "2004.02557", "submitter": "Nuo Xu", "authors": "Nuo Xu, Pinghui Wang, Long Chen, Li Pan, Xiaoyan Wang, Junzhou Zhao", "title": "Distinguish Confusing Law Articles for Legal Judgment Prediction", "comments": "This work has been accepted by the 58th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal Judgment Prediction (LJP) is the task of automatically predicting a law\ncase's judgment results given a text describing its facts, which has excellent\nprospects in judicial assistance systems and convenient services for the\npublic. In practice, confusing charges are frequent, because law cases\napplicable to similar law articles are easily misjudged. For addressing this\nissue, the existing method relies heavily on domain experts, which hinders its\napplication in different law systems. In this paper, we present an end-to-end\nmodel, LADAN, to solve the task of LJP. To distinguish confusing charges, we\npropose a novel graph neural network to automatically learn subtle differences\nbetween confusing law articles and design a novel attention mechanism that\nfully exploits the learned differences to extract compelling discriminative\nfeatures from fact descriptions attentively. Experiments conducted on\nreal-world datasets demonstrate the superiority of our LADAN.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:09:44 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 09:02:11 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 13:20:23 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Xu", "Nuo", ""], ["Wang", "Pinghui", ""], ["Chen", "Long", ""], ["Pan", "Li", ""], ["Wang", "Xiaoyan", ""], ["Zhao", "Junzhou", ""]]}, {"id": "2004.02575", "submitter": "Andreasa Morris-Martin", "authors": "Andreasa Morris-Martin and Marina De Vos and Julian Padget", "title": "A Norm Emergence Framework for Normative MAS -- Position Paper", "comments": "16 pages, 2 figures, pre-print for International Workshop on\n  Coordination, Organizations, Institutions, Norms and Ethics for Governance of\n  Multi-Agent Systems (COINE), co-located with AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Norm emergence is typically studied in the context of multiagent systems\n(MAS) where norms are implicit, and participating agents use simplistic\ndecision-making mechanisms. These implicit norms are usually unconsciously\nshared and adopted through agent interaction. A norm is deemed to have emerged\nwhen a threshold or predetermined percentage of agents follow the \"norm\".\nConversely, in normative MAS, norms are typically explicit and agents\ndeliberately share norms through communication or are informed about norms by\nan authority, following which an agent decides whether to adopt the norm or\nnot. The decision to adopt a norm by the agent can happen immediately after\nrecognition or when an applicable situation arises. In this paper, we make the\ncase that, similarly, a norm has emerged in a normative MAS when a percentage\nof agents adopt the norm. Furthermore, we posit that agents themselves can and\nshould be involved in norm synthesis, and hence influence the norms governing\nthe MAS, in line with Ostrom's eight principles. Consequently, we put forward a\nframework for the emergence of norms within a normative MAS, that allows\nparticipating agents to propose/request changes to the normative system, while\nspecial-purpose synthesizer agents formulate new norms or revisions in response\nto these requests. Synthesizers must collectively agree that the new norm or\nnorm revision should proceed, and then finally be approved by an \"Oracle\". The\nnormative system is then modified to incorporate the norm.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:42:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Morris-Martin", "Andreasa", ""], ["De Vos", "Marina", ""], ["Padget", "Julian", ""]]}, {"id": "2004.02594", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Yonghao Song, Cheng Zhang, Xiaofang Zhao,\n  Dawei Yin", "title": "Data Manipulation: Towards Effective Instance Learning for Neural\n  Dialogue Generation via Learning to Augment and Reweight", "comments": "To appear at ACL 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art neural dialogue models learn from human\nconversations following the data-driven paradigm. As such, a reliable training\ncorpus is the crux of building a robust and well-behaved dialogue model.\nHowever, due to the open-ended nature of human conversations, the quality of\nuser-generated training data varies greatly, and effective training samples are\ntypically insufficient while noisy samples frequently appear. This impedes the\nlearning of those data-driven neural dialogue models. Therefore, effective\ndialogue learning requires not only more reliable learning samples, but also\nfewer noisy samples. In this paper, we propose a data manipulation framework to\nproactively reshape the data distribution towards reliable samples by\naugmenting and highlighting effective learning samples as well as reducing the\neffect of inefficient samples simultaneously. In particular, the data\nmanipulation model selectively augments the training samples and assigns an\nimportance weight to each instance to reform the training data. Note that, the\nproposed data manipulation framework is fully data-driven and learnable. It not\nonly manipulates training samples to optimize the dialogue generation model,\nbut also learns to increase its manipulation skills through gradient descent\nwith validation samples. Extensive experiments show that our framework can\nimprove the dialogue generation performance with respect to various automatic\nevaluation metrics and human judgments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:14:09 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 01:30:15 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 05:48:22 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 09:51:39 GMT"}, {"version": "v5", "created": "Thu, 11 Jun 2020 14:01:55 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Song", "Yonghao", ""], ["Zhang", "Cheng", ""], ["Zhao", "Xiaofang", ""], ["Yin", "Dawei", ""]]}, {"id": "2004.02596", "submitter": "Bhushan Kotnis", "authors": "Bhushan Kotnis, Carolin Lawrence, Mathias Niepert", "title": "Answering Complex Queries in Knowledge Graphs with Bidirectional\n  Sequence Encoders", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning for knowledge graphs (KGs) has focused on the problem\nof answering simple link prediction queries. In this work we address the more\nambitious challenge of predicting the answers of conjunctive queries with\nmultiple missing entities. We propose Bi-Directional Query Embedding (BIQE), a\nmethod that embeds conjunctive queries with models based on bi-directional\nattention mechanisms. Contrary to prior work, bidirectional self-attention can\ncapture interactions among all the elements of a query graph. We introduce a\nnew dataset for predicting the answer of conjunctive query and conduct\nexperiments that show BIQE significantly outperforming state of the art\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:17:57 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:07:25 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 22:30:36 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 11:23:52 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Kotnis", "Bhushan", ""], ["Lawrence", "Carolin", ""], ["Niepert", "Mathias", ""]]}, {"id": "2004.02600", "submitter": "Ioannis Apostolopoulos", "authors": "Ioannis Apostolopoulos, Peter Groumpos", "title": "Non-invasive modelling methodology for the diagnosis of Coronary Artery\n  Disease using Fuzzy Cognitive Maps", "comments": "13 pages, Manuscript Submitted for Peer-Review, Pre-Print", "journal-ref": "Journal Computer Methods in Biomechanics and Biomedical\n  Engineering. 2020. p. 1-9", "doi": "10.1080/10255842.2020.1768534", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cardiovascular Diseases (CVD) and strokes produce immense health and economic\nburdens globally. Coronary Artery Disease (CAD) is the most common type of\ncardiovascular disease. Coronary Angiography, which is an invasive treatment,\nis also the standard procedure for diagnosing CAD. In this work, we illustrate\na Medical Decision Support System for the prediction of Coronary Artery Disease\n(CAD) utilizing Fuzzy Cognitive Maps (FCMs). FCMs are a promising modeling\nmethodology, based on human knowledge, capable of dealing with ambiguity and\nuncertainty, and learning how to adapt to the unknown or changing environment.\nThe newly proposed MDSS is developed using the basic notions of Fuzzy Logic and\nFuzzy Cognitive Maps, with some adjustments to improve the results. The\nproposed model, tested on a labelled CAD dataset of 303 patients, obtains an\naccuracy of 78.2% outmatching several state-of-the-art classification\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:10:31 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Apostolopoulos", "Ioannis", ""], ["Groumpos", "Peter", ""]]}, {"id": "2004.02603", "submitter": "Florian Fontan", "authors": "Florian Fontan, Luc Libralesso", "title": "An anytime tree search algorithm for two-dimensional two- and\n  three-staged guillotine packing problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [libralesso_anytime_2020] proposed an anytime tree search algorithm for the\n2018 ROADEF/EURO challenge glass cutting problem\n(https://www.roadef.org/challenge/2018/en/index.php). The resulting program was\nranked first among 64 participants. In this article, we generalize it and show\nthat it is not only effective for the specific problem it was originally\ndesigned for, but is also very competitive and even returns state-of-the-art\nsolutions on a large variety of Cutting and Packing problems from the\nliterature. We adapted the algorithm for two-dimensional Bin Packing, Multiple\nKnapsack, and Strip Packing Problems, with two- or three-staged exact or\nnon-exact guillotine cuts, the orientation of the first cut being imposed or\nnot, and with or without item rotation. The combination of efficiency, ability\nto provide good solutions fast, simplicity and versatility makes it\nparticularly suited for industrial applications, which require quickly\ndeveloping algorithms implementing several business-specific constraints. The\nalgorithm is implemented in a new software package called PackingSolver.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 13:41:07 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 15:49:14 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Fontan", "Florian", ""], ["Libralesso", "Luc", ""]]}, {"id": "2004.02610", "submitter": "Chuanzheng Wang", "authors": "Chuanzheng Wang, Yinan Li, Stephen L. Smith, Jun Liu", "title": "Continuous Motion Planning with Temporal Logic Specifications using Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model-free reinforcement learning method to\nsynthesize control policies for motion planning problems with continuous states\nand actions. The robot is modelled as a labeled discrete-time Markov decision\nprocess (MDP) with continuous state and action spaces. Linear temporal logics\n(LTL) are used to specify high-level tasks. We then train deep neural networks\nto approximate the value function and policy using an actor-critic\nreinforcement learning method. The LTL specification is converted into an\nannotated limit-deterministic B\\\"uchi automaton (LDBA) for continuously shaping\nthe reward so that dense rewards are available during training. A na\\\"ive way\nof solving a motion planning problem with LTL specifications using\nreinforcement learning is to sample a trajectory and then assign a high reward\nfor training if the trajectory satisfies the entire LTL formula. However, the\nsampling complexity needed to find such a trajectory is too high when we have a\ncomplex LTL formula for continuous state and action spaces. As a result, it is\nvery unlikely that we get enough reward for training if all sample trajectories\nstart from the initial state in the automata. In this paper, we propose a\nmethod that samples not only an initial state from the state space, but also an\narbitrary state in the automata at the beginning of each training episode. We\ntest our algorithm in simulation using a car-like robot and find out that our\nmethod can learn policies for different working configurations and LTL\nspecifications successfully.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:58:03 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:18:54 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Chuanzheng", ""], ["Li", "Yinan", ""], ["Smith", "Stephen L.", ""], ["Liu", "Jun", ""]]}, {"id": "2004.02614", "submitter": "Sam Vente", "authors": "Sam Vente (1), Angelika Kimmig (1), Alun Preece (1), Federico Cerutti\n  (2) ((1) Cardiff University, (2) University of Brescia)", "title": "The current state of automated negotiation theory: a literature review", "comments": "pre-print. New version fixes mistake in title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automated negotiation can be an efficient method for resolving conflict and\nredistributing resources in a coalition setting. Automated negotiation has\nalready seen increased usage in fields such as e-commerce and power\ndistribution in smart girds, and recent advancements in opponent modelling have\nproven to deliver better outcomes. However, significant barriers to more\nwidespread adoption remain, such as lack of predictable outcome over time and\nuser trust. Additionally, there have been many recent advancements in the field\nof reasoning about uncertainty, which could help alleviate both those problems.\nAs there is no recent survey on these two fields, and specifically not on their\npossible intersection we aim to provide such a survey here.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 20:27:20 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 10:17:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Vente", "Sam", "", "Cardiff University"], ["Kimmig", "Angelika", "", "Cardiff University"], ["Preece", "Alun", "", "Cardiff University"], ["Cerutti", "Federico", "", "University of Brescia"]]}, {"id": "2004.02671", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "On Evaluating the Quality of Rule-Based Classification Systems", "comments": "ICIC Express Letters Volume 11, Number 10, October 2017", "journal-ref": "ICIC Express Letters ICIC International c 2013 ISSN 1881-803X ICIC\n  Express Letters Volume 11, Number 10, October 2017 c 2013 ISSN 1881-803X\n  Volume 11, Number 10, October 2017", "doi": "10.24507/icicel.11.10.1515", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two indicators are classically used to evaluate the quality of rule-based\nclassification systems: predictive accuracy, i.e. the system's ability to\nsuccessfully reproduce learning data and coverage, i.e. the proportion of\npossible cases for which the logical rules constituting the system apply. In\nthis work, we claim that these two indicators may be insufficient, and\nadditional measures of quality may need to be developed. We theoretically show\nthat classification systems presenting \"good\" predictive accuracy and coverage\ncan, nonetheless, be trivially improved and illustrate this proposition with\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:41:49 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2004.02673", "submitter": "Michal Nazarczuk", "authors": "Michal Nazarczuk and Krystian Mikolajczyk", "title": "SHOP-VRB: A Visual Reasoning Benchmark for Object Perception", "comments": "International Conference on Robotics and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an approach and a benchmark for visual reasoning in\nrobotics applications, in particular small object grasping and manipulation.\nThe approach and benchmark are focused on inferring object properties from\nvisual and text data. It concerns small household objects with their\nproperties, functionality, natural language descriptions as well as\nquestion-answer pairs for visual reasoning queries along with their\ncorresponding scene semantic representations. We also present a method for\ngenerating synthetic data which allows to extend the benchmark to other objects\nor scenes and propose an evaluation protocol that is more challenging than in\nthe existing datasets. We propose a reasoning system based on symbolic program\nexecution. A disentangled representation of the visual and textual inputs is\nobtained and used to execute symbolic programs that represent a 'reasoning\nprocess' of the algorithm. We perform a set of experiments on the proposed\nbenchmark and compare to results for the state of the art methods. These\nresults expose the shortcomings of the existing benchmarks that may lead to\nmisleading conclusions on the actual performance of the visual reasoning\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:46:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nazarczuk", "Michal", ""], ["Mikolajczyk", "Krystian", ""]]}, {"id": "2004.02720", "submitter": "Peter Turney", "authors": "Peter D. Turney", "title": "Conditions for Open-Ended Evolution in Immigration Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Immigration Game (invented by Don Woods in 1971) extends the solitaire\nGame of Life (invented by John Conway in 1970) to enable two-player\ncompetition. The Immigration Game can be used in a model of evolution by\nnatural selection, where fitness is measured with competitions. The rules for\nthe Game of Life belong to the family of semitotalistic rules, a family with\n262,144 members. Woods' method for converting the Game of Life into a\ntwo-player game generalizes to 8,192 members of the family of semitotalistic\nrules. In this paper, we call the original Immigration Game the Life\nImmigration Game and we call the 8,192 generalizations Immigration Games\n(including the Life Immigration Game). The question we examine here is, what\nare the conditions for one of the 8,192 Immigration Games to be suitable for\nmodeling open-ended evolution? Our focus here is specifically on conditions for\nthe rules, as opposed to conditions for other aspects of the model of\nevolution. In previous work, it was conjectured that Turing-completeness of the\nrules for the Game of Life may have been necessary for the success of evolution\nusing the Life Immigration Game. Here we present evidence that\nTuring-completeness is a sufficient condition on the rules of Immigration\nGames, but not a necessary condition. The evidence suggests that a necessary\nand sufficient condition on the rules of Immigration Games, for open-ended\nevolution, is that the rules should allow growth.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:00:13 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Turney", "Peter D.", ""]]}, {"id": "2004.02746", "submitter": "Dongdong Wu", "authors": "Dongdong Wu and Zijing Liu and Yongchuan Tang", "title": "A new approach for generation of generalized basic probability\n  assignment in the evidence theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of information fusion needs to deal with a large number of\nuncertain information with multi-source, heterogeneity, inaccuracy,\nunreliability, and incompleteness. In practical engineering applications,\nDempster-Shafer evidence theory is widely used in multi-source information\nfusion owing to its effectiveness in data fusion. Information sources have an\nimportant impact on multi-source information fusion in an environment of\ncomplex, unstable, uncertain, and incomplete characteristics. To address\nmulti-source information fusion problem, this paper considers the situation of\nuncertain information modeling from the closed world to the open world\nassumption and studies the generation of basic probability assignment (BPA)\nwith incomplete information. In this paper, a new method is proposed to\ngenerate generalized basic probability assignment (GBPA) based on the\ntriangular fuzzy number model under the open world assumption. The proposed\nmethod can not only be used in different complex environments simply and\nflexibly, but also have less information loss in information processing.\nFinally, a series of comprehensive experiments basing on the UCI data sets are\nused to verify the rationality and superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:40:35 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wu", "Dongdong", ""], ["Liu", "Zijing", ""], ["Tang", "Yongchuan", ""]]}, {"id": "2004.02762", "submitter": "Elif Surer", "authors": "Ayberk Ayd{\\i}n and Elif Surer", "title": "Using Generative Adversarial Nets on Atari Games for Feature Extraction\n  in Deep Reinforcement Learning", "comments": "in Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has been successfully applied in several\nresearch domains such as robot navigation and automated video game playing.\nHowever, these methods require excessive computation and interaction with the\nenvironment, so enhancements on sample efficiency are required. The main reason\nfor this requirement is that sparse and delayed rewards do not provide an\neffective supervision for representation learning of deep neural networks. In\nthis study, Proximal Policy Optimization (PPO) algorithm is augmented with\nGenerative Adversarial Networks (GANs) to increase the sample efficiency by\nenforcing the network to learn efficient representations without depending on\nsparse and delayed rewards as supervision. The results show that an increased\nperformance can be obtained by jointly training a DRL agent with a GAN\ndiscriminator.\n  ----\n  Derin Pekistirmeli Ogrenme, robot navigasyonu ve otomatiklestirilmis video\noyunu oynama gibi arastirma alanlarinda basariyla uygulanmaktadir. Ancak,\nkullanilan yontemler ortam ile fazla miktarda etkilesim ve hesaplama\ngerektirmekte ve bu nedenle de ornek verimliligi yonunden iyilestirmelere\nihtiyac duyulmaktadir. Bu gereksinimin en onemli nedeni, gecikmeli ve seyrek\nodul sinyallerinin derin yapay sinir aglarinin etkili betimlemeler\nogrenebilmesi icin yeterli bir denetim saglayamamasidir. Bu calismada,\nProksimal Politika Optimizasyonu algoritmasi Uretici Cekismeli Aglar (UCA) ile\ndesteklenerek derin yapay sinir aglarinin seyrek ve gecikmeli odul sinyallerine\nbagimli olmaksizin etkili betimlemeler ogrenmesi tesvik edilmektedir. Elde\nedilen sonuclar onerilen algoritmanin ornek verimliliginde artis elde ettigini\ngostermektedir.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:46:45 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ayd\u0131n", "Ayberk", ""], ["Surer", "Elif", ""]]}, {"id": "2004.02780", "submitter": "Rishi Hazra", "authors": "Shubham Gupta, Rishi Hazra, Ambedkar Dukkipati", "title": "Networked Multi-Agent Reinforcement Learning with Emergent Communication", "comments": "An abridged version of this paper has been accepted as a short paper\n  at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) methods find optimal policies for\nagents that operate in the presence of other learning agents. Central to\nachieving this is how the agents coordinate. One way to coordinate is by\nlearning to communicate with each other. Can the agents develop a language\nwhile learning to perform a common task? In this paper, we formulate and study\na MARL problem where cooperative agents are connected to each other via a fixed\nunderlying network. These agents can communicate along the edges of this\nnetwork by exchanging discrete symbols. However, the semantics of these symbols\nare not predefined and, during training, the agents are required to develop a\nlanguage that helps them in accomplishing their goals. We propose a method for\ntraining these agents using emergent communication. We demonstrate the\napplicability of the proposed framework by applying it to the problem of\nmanaging traffic controllers, where we achieve state-of-the-art performance as\ncompared to a number of strong baselines. More importantly, we perform a\ndetailed analysis of the emergent communication to show, for instance, that the\ndeveloped language is grounded and demonstrate its relationship with the\nunderlying network topology. To the best of our knowledge, this is the only\nwork that performs an in depth analysis of emergent communication in a\nnetworked MARL setting while being applicable to a broad class of problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:13:23 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 04:14:14 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Gupta", "Shubham", ""], ["Hazra", "Rishi", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2004.02809", "submitter": "Edgar Rojas-Mu\\~noz", "authors": "Edgar Rojas-Mu\\~noz, Kyle Couperus and Juan Wachs", "title": "DAISI: Database for AI Surgical Instruction", "comments": "10 pages, 4 figures, to access database, see\n  https://engineering.purdue.edu/starproj/_daisi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Telementoring surgeons as they perform surgery can be essential in the\ntreatment of patients when in situ expertise is not available. Nonetheless,\nexpert mentors are often unavailable to provide trainees with real-time medical\nguidance. When mentors are unavailable, a fallback autonomous mechanism should\nprovide medical practitioners with the required guidance. However,\nAI/autonomous mentoring in medicine has been limited by the availability of\ngeneralizable prediction models, and surgical procedures datasets to train\nthose models with. This work presents the initial steps towards the development\nof an intelligent artificial system for autonomous medical mentoring.\nSpecifically, we present the first Database for AI Surgical Instruction\n(DAISI). DAISI leverages on images and instructions to provide step-by-step\ndemonstrations of how to perform procedures from various medical disciplines.\nThe dataset was acquired from real surgical procedures and data from academic\ntextbooks. We used DAISI to train an encoder-decoder neural network capable of\npredicting medical instructions given a current view of the surgery.\nAfterwards, the instructions predicted by the network were evaluated using\ncumulative BLEU scores and input from expert physicians. According to the BLEU\nscores, the predicted and ground truth instructions were as high as 67%\nsimilar. Additionally, expert physicians subjectively assessed the algorithm\nusing Likert scale, and considered that the predicted descriptions were related\nto the images. This work provides a baseline for AI algorithms to assist in\nautonomous medical mentoring.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 22:07:43 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Rojas-Mu\u00f1oz", "Edgar", ""], ["Couperus", "Kyle", ""], ["Wachs", "Juan", ""]]}, {"id": "2004.02845", "submitter": "Marieke Van Erp", "authors": "Albert Mero\\~no-Pe\\~nuela, Victor de Boer, Marieke van Erp, Richard\n  Zijdeman, Rick Mourits, Willem Melder, Auke Rijpma, Ruben Schalk", "title": "Ontologies in CLARIAH: Towards Interoperability in History, Language and\n  Media", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important goals of digital humanities is to provide\nresearchers with data and tools for new research questions, either by\nincreasing the scale of scholarly studies, linking existing databases, or\nimproving the accessibility of data. Here, the FAIR principles provide a useful\nframework as these state that data needs to be: Findable, as they are often\nscattered among various sources; Accessible, since some might be offline or\nbehind paywalls; Interoperable, thus using standard knowledge representation\nformats and shared vocabularies; and Reusable, through adequate licensing and\npermissions. Integrating data from diverse humanities domains is not trivial,\nresearch questions such as \"was economic wealth equally distributed in the 18th\ncentury?\", or \"what are narratives constructed around disruptive media\nevents?\") and preparation phases (e.g. data collection, knowledge organisation,\ncleaning) of scholars need to be taken into account. In this chapter, we\ndescribe the ontologies and tools developed and integrated in the Dutch\nnational project CLARIAH to address these issues across datasets from three\nfundamental domains or \"pillars\" of the humanities (linguistics, social and\neconomic history, and media studies) that have paradigmatic data\nrepresentations (textual corpora, structured data, and multimedia). We\nsummarise the lessons learnt from using such ontologies and tools in these\ndomains from a generalisation and reusability perspective.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:38:47 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 15:34:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Mero\u00f1o-Pe\u00f1uela", "Albert", ""], ["de Boer", "Victor", ""], ["van Erp", "Marieke", ""], ["Zijdeman", "Richard", ""], ["Mourits", "Rick", ""], ["Melder", "Willem", ""], ["Rijpma", "Auke", ""], ["Schalk", "Ruben", ""]]}, {"id": "2004.02919", "submitter": "John Burden", "authors": "John Burden and Daniel Kudenko", "title": "Uniform State Abstraction For Reinforcement Learning", "comments": "8 Pages, 2 figures, Accepted for publication in the European\n  Conference of Artificial Intelligence (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential Based Reward Shaping combined with a potential function based on\nappropriately defined abstract knowledge has been shown to significantly\nimprove learning speed in Reinforcement Learning. MultiGrid Reinforcement\nLearning (MRL) has further shown that such abstract knowledge in the form of a\npotential function can be learned almost solely from agent interaction with the\nenvironment. However, we show that MRL faces the problem of not extending well\nto work with Deep Learning. In this paper we extend and improve MRL to take\nadvantage of modern Deep Learning algorithms such as Deep Q-Networks (DQN). We\nshow that DQN augmented with our approach perform significantly better on\ncontinuous control tasks than its Vanilla counterpart and DQN augmented with\nMRL.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:13:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Burden", "John", ""], ["Kudenko", "Daniel", ""]]}, {"id": "2004.02958", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Dominique Mercier, Andreas Dengel, Sheraz Ahmed", "title": "TSInsight: A local-global attribution framework for interpretability in\n  time-series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise in the employment of deep learning methods in safety-critical\nscenarios, interpretability is more essential than ever before. Although many\ndifferent directions regarding interpretability have been explored for visual\nmodalities, time-series data has been neglected with only a handful of methods\ntested due to their poor intelligibility. We approach the problem of\ninterpretability in a novel way by proposing TSInsight where we attach an\nauto-encoder to the classifier with a sparsity-inducing norm on its output and\nfine-tune it based on the gradients from the classifier and a reconstruction\npenalty. TSInsight learns to preserve features that are important for\nprediction by the classifier and suppresses those that are irrelevant i.e.\nserves as a feature attribution method to boost interpretability. In contrast\nto most other attribution frameworks, TSInsight is capable of generating both\ninstance-based and model-based explanations. We evaluated TSInsight along with\n9 other commonly used attribution methods on 8 different time-series datasets\nto validate its efficacy. Evaluation results show that TSInsight naturally\nachieves output space contraction, therefore, is an effective tool for the\ninterpretability of deep time-series models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:34:25 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2004.02973", "submitter": "Omer Ben-Porat", "authors": "Omer Ben-Porat, Sharon Hirsch, Lital Kuchy, Guy Elad, Roi Reichart,\n  Moshe Tennenholtz", "title": "Predicting Strategic Behavior from Free Text", "comments": "Accepted to Journal of Artificial Intelligence Research (JAIR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connection between messaging and action is fundamental both to web\napplications, such as web search and sentiment analysis, and to economics.\nHowever, while prominent online applications exploit messaging in natural\n(human) language in order to predict non-strategic action selection, the\neconomics literature focuses on the connection between structured stylized\nmessaging to strategic decisions in games and multi-agent encounters. This\npaper aims to connect these two strands of research, which we consider highly\ntimely and important due to the vast online textual communication on the web.\nParticularly, we introduce the following question: can free text expressed in\nnatural language serve for the prediction of action selection in an economic\ncontext, modeled as a game?\n  In order to initiate the research on this question, we introduce the study of\nan individual's action prediction in a one-shot game based on free text he/she\nprovides, while being unaware of the game to be played. We approach the problem\nby attributing commonsensical personality attributes via crowd-sourcing to free\ntexts written by individuals, and employing transductive learning to predict\nactions taken by these individuals in one-shot games based on these attributes.\nOur approach allows us to train a single classifier that can make predictions\nwith respect to actions taken in multiple games. In experiments with three\nwell-studied games, our algorithm compares favorably with strong alternative\napproaches. In ablation analysis, we demonstrate the importance of our modeling\nchoices---the representation of the text with the commonsensical personality\nattributes and our classifier---to the predictive power of our model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:05:30 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:17:52 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ben-Porat", "Omer", ""], ["Hirsch", "Sharon", ""], ["Kuchy", "Lital", ""], ["Elad", "Guy", ""], ["Reichart", "Roi", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "2004.02988", "submitter": "Gustavo A Valencia-Zapata", "authors": "Gustavo A. Valencia-Zapata, Carolina Gonzalez-Canas, Michael G.\n  Zentner, Okan Ersoy, and Gerhard Klimeck", "title": "Probabilistic Diagnostic Tests for Degradation Problems in Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Several studies point out different causes of performance degradation in\nsupervised machine learning. Problems such as class imbalance, overlapping,\nsmall-disjuncts, noisy labels, and sparseness limit accuracy in classification\nalgorithms. Even though a number of approaches either in the form of a\nmethodology or an algorithm try to minimize performance degradation, they have\nbeen isolated efforts with limited scope. Most of these approaches focus on\nremediation of one among many problems, with experimental results coming from\nfew datasets and classification algorithms, insufficient measures of prediction\npower, and lack of statistical validation for testing the real benefit of the\nproposed approach. This paper consists of two main parts: In the first part, a\nnovel probabilistic diagnostic model based on identifying signs and symptoms of\neach problem is presented. Thereby, early and correct diagnosis of these\nproblems is to be achieved in order to select not only the most convenient\nremediation treatment but also unbiased performance metrics. Secondly, the\nbehavior and performance of several supervised algorithms are studied when\ntraining sets have such problems. Therefore, prediction of success for\ntreatments can be estimated across classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:32:35 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 19:12:24 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Valencia-Zapata", "Gustavo A.", ""], ["Gonzalez-Canas", "Carolina", ""], ["Zentner", "Michael G.", ""], ["Ersoy", "Okan", ""], ["Klimeck", "Gerhard", ""]]}, {"id": "2004.03053", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, and Masayoshi Tomizuka", "title": "Scenario-Transferable Semantic Graph Reasoning for Interaction-Aware\n  Probabilistic Prediction", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the possible behaviors of traffic participants is an\nessential capability for autonomous vehicles. Since autonomous vehicles need to\nnavigate in dynamically changing environments, they are expected to make\naccurate predictions regardless of where they are and what driving\ncircumstances they encountered. A number of methodologies have been proposed to\nsolve prediction problems under different traffic situations. However, these\nworks either focus on one particular driving scenario (e.g. highway,\nintersection, or roundabout) or do not take sufficient environment information\n(e.g. road topology, traffic rules, and surrounding agents) into account. In\nfact, the limitation to certain scenario is mainly due to the lackness of\ngeneric representations of the environment. The insufficiency of environment\ninformation further limits the flexibility and transferability of the\npredictor. In this paper, we propose a scenario-transferable and\ninteraction-aware probabilistic prediction algorithm based on semantic graph\nreasoning. We first introduce generic representations for both static and\ndynamic elements in driving environments. Then these representations are\nutilized to describe semantic goals for selected agents and incorporate them\ninto spatial-temporal structures. Finally, we reason internal relations among\nthese structured semantic representations using learning-based method and\nobtain prediction results. The proposed algorithm is thoroughly examined under\nseveral complicated real-world driving scenarios to demonstrate its flexibility\nand transferability, where the predictor can be directly used under unforeseen\ndriving circumstances with different static and dynamic information.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:34:36 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 02:56:58 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2004.03070", "submitter": "Duyu Tang", "authors": "Daya Guo, Akari Asai, Duyu Tang, Nan Duan, Ming Gong, Linjun Shou,\n  Daxin Jiang, Jian Yin and Ming Zhou", "title": "Inferential Text Generation with Multiple Knowledge Sources and\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating inferential texts of events for a variety\nof commonsense like \\textit{if-else} relations. Existing approaches typically\nuse limited evidence from training examples and learn for each relation\nindividually. In this work, we use multiple knowledge sources as fuels for the\nmodel. Existing commonsense knowledge bases like ConceptNet are dominated by\ntaxonomic knowledge (e.g., \\textit{isA} and \\textit{relatedTo} relations),\nhaving a limited number of inferential knowledge. We use not only structured\ncommonsense knowledge bases, but also natural language snippets from\nsearch-engine results. These sources are incorporated into a generative base\nmodel via key-value memory network. In addition, we introduce a meta-learning\nbased multi-task learning algorithm. For each targeted commonsense relation, we\nregard the learning of examples from other relations as the meta-training\nprocess, and the evaluation on examples from the targeted relation as the\nmeta-test process. We conduct experiments on Event2Mind and ATOMIC datasets.\nResults show that both the integration of multiple knowledge sources and the\nuse of the meta-learning algorithm improve the performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:49:18 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 05:02:26 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Guo", "Daya", ""], ["Asai", "Akari", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Gong", "Ming", ""], ["Shou", "Linjun", ""], ["Jiang", "Daxin", ""], ["Yin", "Jian", ""], ["Zhou", "Ming", ""]]}, {"id": "2004.03101", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee and Chitta Baral", "title": "Knowledge Fusion and Semantic Knowledge Ranking for Open Domain Question\n  Answering", "comments": "9 pages. 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Domain Question Answering requires systems to retrieve external\nknowledge and perform multi-hop reasoning by composing knowledge spread over\nmultiple sentences. In the recently introduced open domain question answering\nchallenge datasets, QASC and OpenBookQA, we need to perform retrieval of facts\nand compose facts to correctly answer questions. In our work, we learn a\nsemantic knowledge ranking model to re-rank knowledge retrieved through Lucene\nbased information retrieval systems. We further propose a \"knowledge fusion\nmodel\" which leverages knowledge in BERT-based language models with externally\nretrieved knowledge and improves the knowledge understanding of the BERT-based\nlanguage models. On both OpenBookQA and QASC datasets, the knowledge fusion\nmodel with semantically re-ranked knowledge outperforms previous attempts.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:16:47 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 06:46:36 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""]]}, {"id": "2004.03168", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas and Katja Hofmann and Pierre-Yves Oudeyer", "title": "Trying AGAIN instead of Trying Longer: Prior Learning for Automatic\n  Curriculum Learning", "comments": "Accepted to the ICLR 2020 workshop Beyond tabula rasa in RL (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in the Deep RL (DRL) community is to train agents able to\ngeneralize over unseen situations, which is often approached by training them\non a diversity of tasks (or environments). A powerful method to foster\ndiversity is to procedurally generate tasks by sampling their parameters from a\nmulti-dimensional distribution, enabling in particular to propose a different\ntask for each training episode. In practice, to get the high diversity of\ntraining tasks necessary for generalization, one has to use complex procedural\ngeneration systems. With such generators, it is hard to get prior knowledge on\nthe subset of tasks that are actually learnable at all (many generated tasks\nmay be unlearnable), what is their relative difficulty and what is the most\nefficient task distribution ordering for training. A typical solution in such\ncases is to rely on some form of Automated Curriculum Learning (ACL) to adapt\nthe sampling distribution. One limit of current approaches is their need to\nexplore the task space to detect progress niches over time, which leads to a\nloss of time. Additionally, we hypothesize that the induced noise in the\ntraining data may impair the performances of brittle DRL learners. We address\nthis problem by proposing a two stage ACL approach where 1) a teacher algorithm\nfirst learns to train a DRL agent with a high-exploration curriculum, and then\n2) distills learned priors from the first run to generate an \"expert\ncurriculum\" to re-train the same agent from scratch. Besides demonstrating 50%\nimprovements on average over the current state of the art, the objective of\nthis work is to give a first example of a new research direction oriented\ntowards refining ACL techniques over multiple learners, which we call Classroom\nTeaching.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:30:27 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2004.03188", "submitter": "Saeed Rahimi Gorji", "authors": "Saeed Rahimi Gorji, Ole-Christoffer Granmo, Sondre Glimsdal, Jonathan\n  Edwards, Morten Goodwin", "title": "Increasing the Inference and Learning Speed of Tsetlin Machines with\n  Clause Indexing", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is a machine learning algorithm founded on the\nclassical Tsetlin Automaton (TA) and game theory. It further leverages frequent\npattern mining and resource allocation principles to extract common patterns in\nthe data, rather than relying on minimizing output error, which is prone to\noverfitting. Unlike the intertwined nature of pattern representation in neural\nnetworks, a TM decomposes problems into self-contained patterns, represented as\nconjunctive clauses. The clause outputs, in turn, are combined into a\nclassification decision through summation and thresholding, akin to a logistic\nregression function, however, with binary weights and a unit step output\nfunction. In this paper, we exploit this hierarchical structure by introducing\na novel algorithm that avoids evaluating the clauses exhaustively. Instead we\nuse a simple look-up table that indexes the clauses on the features that\nfalsify them. In this manner, we can quickly evaluate a large number of clauses\nthrough falsification, simply by iterating through the features and using the\nlook-up table to eliminate those clauses that are falsified. The look-up table\nis further structured so that it facilitates constant time updating, thus\nsupporting use also during learning. We report up to 15 times faster\nclassification and three times faster learning on MNIST and Fashion-MNIST image\nclassification, and IMDb sentiment analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 08:16:07 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Gorji", "Saeed Rahimi", ""], ["Granmo", "Ole-Christoffer", ""], ["Glimsdal", "Sondre", ""], ["Edwards", "Jonathan", ""], ["Goodwin", "Morten", ""]]}, {"id": "2004.03237", "submitter": "Richard Meyes", "authors": "Richard Meyes, Moritz Schneider, Tobias Meisen", "title": "How Do You Act? An Empirical Study to Understand Behavior of Deep\n  Reinforcement Learning Agents", "comments": "16 pages, currently under review for publication for the ECMLPKDD\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for more transparency of decision-making processes of deep\nreinforcement learning agents is greater than ever, due to their increased use\nin safety critical and ethically challenging domains such as autonomous\ndriving. In this empirical study, we address this lack of transparency\nfollowing an idea that is inspired by research in the field of neuroscience. We\ncharacterize the learned representations of an agent's policy network through\nits activation space and perform partial network ablations to compare the\nrepresentations of the healthy and the intentionally damaged networks. We show\nthat the healthy agent's behavior is characterized by a distinct correlation\npattern between the network's layer activation and the performed actions during\nan episode and that network ablations, which cause a strong change of this\npattern, lead to the agent failing its trained control task. Furthermore, the\nlearned representation of the healthy agent is characterized by a distinct\npattern in its activation space reflecting its different behavioral stages\nduring an episode, which again, when distorted by network ablations, leads to\nthe agent failing its trained control task. Concludingly, we argue in favor of\na new perspective on artificial neural networks as objects of empirical\ninvestigations, just as biological neural systems in neuroscientific studies,\npaving the way towards a new standard of scientific falsifiability with respect\nto research on transparency and interpretability of artificial neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:08:55 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Meyes", "Richard", ""], ["Schneider", "Moritz", ""], ["Meisen", "Tobias", ""]]}, {"id": "2004.03238", "submitter": "Kazutoshi Shinoda", "authors": "Kazutoshi Shinoda, Saku Sugawara, Akiko Aizawa", "title": "Improving the Robustness of QA Models to Challenge Sets with Variational\n  Question-Answer Pair Generation", "comments": "ACL-IJCNLP 2021 SRW", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:15:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 01:21:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Shinoda", "Kazutoshi", ""], ["Sugawara", "Saku", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2004.03267", "submitter": "Ziming Li", "authors": "Ziming Li, Sungjin Lee, Baolin Peng, Jinchao Li, Julia Kiseleva,\n  Maarten de Rijke, Shahin Shayandeh, Jianfeng Gao", "title": "Guided Dialog Policy Learning without Adversarial Learning in the Loop", "comments": "10 pages", "journal-ref": "Findings of EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) methods have emerged as a popular choice for\ntraining an efficient and effective dialogue policy. However, these methods\nsuffer from sparse and unstable reward signals returned by a user simulator\nonly when a dialogue finishes. Besides, the reward signal is manually designed\nby human experts, which requires domain knowledge. Recently, a number of\nadversarial learning methods have been proposed to learn the reward function\ntogether with the dialogue policy. However, to alternatively update the\ndialogue policy and the reward model on the fly, we are limited to\npolicy-gradient-based algorithms, such as REINFORCE and PPO. Moreover, the\nalternating training of a dialogue agent and the reward model can easily get\nstuck in local optima or result in mode collapse. To overcome the listed\nissues, we propose to decompose the adversarial training into two steps. First,\nwe train the discriminator with an auxiliary dialogue generator and then\nincorporate a derived reward model into a common RL method to guide the\ndialogue policy learning. This approach is applicable to both on-policy and\noff-policy RL methods. Based on our extensive experimentation, we can conclude\nthe proposed method: (1) achieves a remarkable task success rate using both\non-policy and off-policy RL methods; and (2) has the potential to transfer\nknowledge from existing domains to a new domain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:03:17 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:26:31 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Li", "Ziming", ""], ["Lee", "Sungjin", ""], ["Peng", "Baolin", ""], ["Li", "Jinchao", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""], ["Shayandeh", "Shahin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.03329", "submitter": "Pengtao Xie", "authors": "Xuehai He, Shu Chen, Zeqian Ju, Xiangyu Dong, Hongchao Fang, Sicheng\n  Wang, Yue Yang, Jiaqi Zeng, Ruisi Zhang, Ruoyu Zhang, Meng Zhou, Penghui Zhu,\n  Pengtao Xie", "title": "MedDialog: Two Large-scale Medical Dialogue Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical dialogue systems are promising in assisting in telemedicine to\nincrease access to healthcare services, improve the quality of patient care,\nand reduce medical costs. To facilitate the research and development of medical\ndialogue systems, we build two large-scale medical dialogue datasets:\nMedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing\n0.3 million conversations between patients and doctors and 0.5 million\nutterances. MedDialog-CN is an Chinese dataset containing 1.1 million\nconversations and 4 million utterances. To our best knowledge,\nMedDialog-(EN,CN) are the largest medical dialogue datasets to date. The\ndataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:07:09 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 22:15:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["He", "Xuehai", ""], ["Chen", "Shu", ""], ["Ju", "Zeqian", ""], ["Dong", "Xiangyu", ""], ["Fang", "Hongchao", ""], ["Wang", "Sicheng", ""], ["Yang", "Yue", ""], ["Zeng", "Jiaqi", ""], ["Zhang", "Ruisi", ""], ["Zhang", "Ruoyu", ""], ["Zhou", "Meng", ""], ["Zhu", "Penghui", ""], ["Xie", "Pengtao", ""]]}, {"id": "2004.03340", "submitter": "Germ\\'an Kruszewski", "authors": "Germ\\'an Kruszewski, Ionut-Teodor Sorodoc, Tomas Mikolov", "title": "Evaluating Online Continual Learning with CALM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Continual Learning (OCL) studies learning over a continuous data\nstream without observing any single example more than once, a setting that is\ncloser to the experience of humans and systems that must learn \"on-the-wild\".\nYet, commonly available benchmarks are far from these real-world conditions,\nbecause they explicitly signal different tasks, lack latent similarity\nstructure or assume temporal independence between different examples. Here, we\npropose a new benchmark for OCL based on language modelling in which input\nalternates between different languages and domains without any explicit\ndelimitation. Additionally, we propose new metrics to study catastrophic\nforgetting in this setting and evaluate multiple baseline models based on\ncompositions of experts. Finally, we introduce a simple gating technique that\nlearns the latent similarities between different inputs, improving the\nperformance of a Products of Experts model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:17:05 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 12:20:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kruszewski", "Germ\u00e1n", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Mikolov", "Tomas", ""]]}, {"id": "2004.03343", "submitter": "Loick Bonniot", "authors": "Lo\\\"ick Bonniot (WIDE), Christoph Neumann, Fran\\c{c}ois Ta\\\"iani\n  (WIDE)", "title": "DiagNet: towards a generic, Internet-scale root cause analysis solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing problems in Internet-scale services remains particularly difficult\nand costly for both content providers and ISPs. Because the Internet is\ndecentralized, the cause of such problems might lie anywhere between an\nend-user's device and the service datacenters. Further, the set of possible\nproblems and causes is not known in advance, making it impossible in practice\nto train a classifier with all combinations of problems, causes and locations.\nIn this paper, we explore how different machine learning techniques can be used\nfor Internet-scale root cause analysis using measurements taken from end-user\ndevices. We show how to build generic models that (i) are agnostic to the\nunderlying network topology, (ii) do not require to define the full set of\npossible causes during training, and (iii) can be quickly adapted to diagnose\nnew services. Our solution, DiagNet, adapts concepts from image processing\nresearch to handle network and system metrics. We evaluate DiagNet with a\nmulti-cloud deployment of online services with injected faults and emulated\nclients with automated browsers. We demonstrate promising root cause analysis\ncapabilities, with a recall of 73.9% including causes only being introduced at\ninference time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:21:32 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Bonniot", "Lo\u00efck", "", "WIDE"], ["Neumann", "Christoph", "", "WIDE"], ["Ta\u00efani", "Fran\u00e7ois", "", "WIDE"]]}, {"id": "2004.03372", "submitter": "Ioannis Apostolopoulos", "authors": "Ioannis D. Apostolopoulos, Peter P. Groumpos, Dimitris I.\n  Apostolopoulos", "title": "State Space Advanced Fuzzy Cognitive Map approach for automatic and non\n  Invasive diagnosis of Coronary Artery Disease", "comments": "14 pages", "journal-ref": "Biomed. Phys. Eng. Express, 2021", "doi": "10.1088/2057-1976/abfd83", "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: In this study, the recently emerged advances in Fuzzy Cognitive Maps\n(FCM) are investigated and employed, for achieving the automatic and\nnon-invasive diagnosis of Coronary Artery Disease (CAD). Methods: A\nComputer-Aided Diagnostic model for the acceptable and non-invasive prediction\nof CAD using the State Space Advanced FCM (AFCM) approach is proposed. Also, a\nrule-based mechanism is incorporated, to further increase the knowledge of the\nsystem and the interpretability of the decision mechanism. The proposed method\nis tested utilizing a CAD dataset from the Laboratory of Nuclear Medicine of\nthe University of Patras. More specifically, two architectures of AFCMs are\ndesigned, and different parameter testing is performed. Furthermore, the\nproposed AFCMs, which are based on the new equations proposed recently, are\ncompared with the traditional FCM approach. Results: The experiments highlight\nthe effectiveness of the AFCM approach and the new equations over the\ntraditional approach, which obtained an accuracy of 78.21%, achieving an\nincrease of seven percent (+7%) on the classification task, and obtaining\n85.47% accuracy. Conclusions: It is demonstrated that the AFCM approach in\ndeveloping Fuzzy Cognitive Maps outperforms the conventional approach, while it\nconstitutes a reliable method for the diagnosis of Coronary Artery Disease.\nConclusions and future research related to recent pandemic of coronavirus are\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 18:30:41 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 13:18:04 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Apostolopoulos", "Ioannis D.", ""], ["Groumpos", "Peter P.", ""], ["Apostolopoulos", "Dimitris I.", ""]]}, {"id": "2004.03386", "submitter": "Su Zhu", "authors": "Su Zhu, Jieyu Li, Lu Chen, and Kai Yu", "title": "Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue\n  State Tracking", "comments": "16 pages, 4 figures, 11 tables. Accepted to EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking (DST) aims at estimating the current dialogue state\ngiven all the preceding conversation. For multi-domain DST, the data sparsity\nproblem is a major obstacle due to increased numbers of state candidates and\ndialogue lengths. To encode the dialogue context efficiently, we utilize the\nprevious dialogue state (predicted) and the current dialogue utterance as the\ninput for DST. To consider relations among different domain-slots, the schema\ngraph involving prior knowledge is exploited. In this paper, a novel context\nand schema fusion network is proposed to encode the dialogue context and schema\ngraph by using internal and external attention mechanisms. Experiment results\nshow that our approach can obtain new state-of-the-art performance of the\nopen-vocabulary DST on both MultiWOZ 2.0 and MultiWOZ 2.1 benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:46:39 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 13:08:17 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 10:31:51 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 11:19:57 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Zhu", "Su", ""], ["Li", "Jieyu", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2004.03397", "submitter": "Iztok Fister", "authors": "Iztok Fister Jr., Karin Fister, Iztok Fister", "title": "Discovering associations in COVID-19 related research papers", "comments": "arXiv admin note: text overlap with arXiv:2003.00348", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A COVID-19 pandemic has already proven itself to be a global challenge. It\nproves how vulnerable humanity can be. It has also mobilized researchers from\ndifferent sciences and different countries in the search for a way to fight\nthis potentially fatal disease. In line with this, our study analyses the\nabstracts of papers related to COVID-19 and coronavirus-related-research using\nassociation rule text mining in order to find the most interestingness words,\non the one hand, and relationships between them on the other. Then, a method,\ncalled information cartography, was applied for extracting structured knowledge\nfrom a huge amount of association rules. On the basis of these methods, the\npurpose of our study was to show how researchers have responded in similar\nepidemic/pandemic situations throughout history.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 10:52:25 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Fister", "Iztok", "Jr."], ["Fister", "Karin", ""], ["Fister", "Iztok", ""]]}, {"id": "2004.03484", "submitter": "Soham Parikh", "authors": "Soham Parikh, Quaizar Vohra, Mitul Tiwari", "title": "Automated Utterance Generation", "comments": "AAAI/IAAI-20, Emerging Application Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational AI assistants are becoming popular and question-answering is\nan important part of any conversational assistant. Using relevant utterances as\nfeatures in question-answering has shown to improve both the precision and\nrecall for retrieving the right answer by a conversational assistant. Hence,\nutterance generation has become an important problem with the goal of\ngenerating relevant utterances (sentences or phrases) from a knowledge base\narticle that consists of a title and a description. However, generating good\nutterances usually requires a lot of manual effort, creating the need for an\nautomated utterance generation. In this paper, we propose an utterance\ngeneration system which 1) uses extractive summarization to extract important\nsentences from the description, 2) uses multiple paraphrasing techniques to\ngenerate a diverse set of paraphrases of the title and summary sentences, and\n3) selects good candidate paraphrases with the help of a novel candidate\nselection algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:35:54 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 01:27:09 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Parikh", "Soham", ""], ["Vohra", "Quaizar", ""], ["Tiwari", "Mitul", ""]]}, {"id": "2004.03561", "submitter": "Changmao Li", "authors": "Changmao Li, Jinho D. Choi", "title": "Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for\n  Span-based Question Answering", "comments": "Accepted by the Annual Conference of the Association for\n  Computational Linguistics, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to transformers that learns hierarchical\nrepresentations in multiparty dialogue. First, three language modeling tasks\nare used to pre-train the transformers, token- and utterance-level language\nmodeling and utterance order prediction, that learn both token and utterance\nembeddings for better understanding in dialogue contexts. Then, multi-task\nlearning between the utterance prediction and the token span prediction is\napplied to fine-tune for span-based question answering (QA). Our approach is\nevaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over\nthe two state-of-the-art transformer models, BERT and RoBERTa, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:36:33 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 04:35:45 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Li", "Changmao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2004.03573", "submitter": "Maxwell Crouse", "authors": "Maxwell Crouse, Constantine Nakos, Ibrahim Abdelaziz, Kenneth Forbus", "title": "Neural Analogical Matching", "comments": "AAAI version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogy is core to human cognition. It allows us to solve problems based on\nprior experience, it governs the way we conceptualize new information, and it\neven influences our visual perception. The importance of analogy to humans has\nmade it an active area of research in the broader field of artificial\nintelligence, resulting in data-efficient models that learn and reason in\nhuman-like ways. While cognitive perspectives of analogy and deep learning have\ngenerally been studied independently of one another, the integration of the two\nlines of research is a promising step towards more robust and efficient\nlearning techniques. As part of a growing body of research on such an\nintegration, we introduce the Analogical Matching Network: a neural\narchitecture that learns to produce analogies between structured, symbolic\nrepresentations that are largely consistent with the principles of\nStructure-Mapping Theory.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:50:52 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 04:49:40 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 15:01:42 GMT"}, {"version": "v4", "created": "Thu, 3 Dec 2020 22:31:43 GMT"}, {"version": "v5", "created": "Tue, 15 Dec 2020 16:59:33 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Crouse", "Maxwell", ""], ["Nakos", "Constantine", ""], ["Abdelaziz", "Ibrahim", ""], ["Forbus", "Kenneth", ""]]}, {"id": "2004.03592", "submitter": "Ahana Pradhan", "authors": "Ahana Pradhan and Rushikesh K. Joshi", "title": "A Structural Approach to Dynamic Migration in Petri Net Models of\n  Structured Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of dynamic evolution of workflow processes, the change region\nidentifies the part of the old process from which migration to the new process\nis guaranteed to be inconsistent. However, this approach may lead to\noverestimated regions, incorrectly identifying migratable instances as\nnon-migratable. This overestimation causes delays due to postponement of\nimmediate migration. The paper analyzes this overestimation problem on a class\nof Petri nets models. Structural properties leading to conditions for minimal\nchange regions and overestimations are developed resulting into classification\nof change regions into two types of change regions called Structural Change\nRegions and Perfect Structural Change Regions. Necessary and sufficient\nconditions for perfect regions are identified. The paper also discusses ways\nfor computing the same in terms of structural properties of the old and the new\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:05:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Pradhan", "Ahana", ""], ["Joshi", "Rushikesh K.", ""]]}, {"id": "2004.03636", "submitter": "Jun Chen", "authors": "Jun Chen, Robert Hoehndorf, Mohamed Elhoseiny and Xiangliang Zhang", "title": "Efficient long-distance relation extraction with DG-SpanBERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In natural language processing, relation extraction seeks to rationally\nunderstand unstructured text. Here, we propose a novel SpanBERT-based graph\nconvolutional network (DG-SpanBERT) that extracts semantic features from a raw\nsentence using the pre-trained language model SpanBERT and a graph\nconvolutional network to pool latent features. Our DG-SpanBERT model inherits\nthe advantage of SpanBERT on learning rich lexical features from large-scale\ncorpus. It also has the ability to capture long-range relations between\nentities due to the usage of GCN on dependency tree. The experimental results\nshow that our model outperforms other existing dependency-based and\nsequence-based models and achieves a state-of-the-art performance on the TACRED\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:21:47 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Chen", "Jun", ""], ["Hoehndorf", "Robert", ""], ["Elhoseiny", "Mohamed", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2004.03644", "submitter": "Babak Salimi", "authors": "Babak Salimi, Harsh Parikh, Moe Kayali, Sudeepa Roy, Lise Getoor, and\n  Dan Suciu", "title": "Causal Relational Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is at the heart of empirical research in natural and social\nsciences and is critical for scientific discovery and informed decision making.\nThe gold standard in causal inference is performing randomized controlled\ntrials; unfortunately these are not always feasible due to ethical, legal, or\ncost constraints. As an alternative, methodologies for causal inference from\nobservational data have been developed in statistical studies and social\nsciences. However, existing methods critically rely on restrictive assumptions\nsuch as the study population consisting of homogeneous elements that can be\nrepresented in a single flat table, where each row is referred to as a unit. In\ncontrast, in many real-world settings, the study domain naturally consists of\nheterogeneous elements with complex relational structure, where the data is\nnaturally represented in multiple related tables. In this paper, we present a\nformal framework for causal inference from such relational data. We propose a\ndeclarative language called CaRL for capturing causal background knowledge and\nassumptions and specifying causal queries using simple Datalog-like rules.CaRL\nprovides a foundation for inferring causality and reasoning about the effect of\ncomplex interventions in relational domains. We present an extensive\nexperimental evaluation on real relational data to illustrate the applicability\nof CaRL in social sciences and healthcare.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:33:05 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Salimi", "Babak", ""], ["Parikh", "Harsh", ""], ["Kayali", "Moe", ""], ["Roy", "Sudeepa", ""], ["Getoor", "Lise", ""], ["Suciu", "Dan", ""]]}, {"id": "2004.03744", "submitter": "Virginie Do", "authors": "Virginie Do, Oana-Maria Camburu, Zeynep Akata and Thomas Lukasiewicz", "title": "e-SNLI-VE-2.0: Corrected Visual-Textual Entailment with Natural Language\n  Explanations", "comments": null, "journal-ref": "IEEE CVPR Workshop on Fair, Data Efficient and Trusted Computer\n  Vision, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed SNLI-VE corpus for recognising visual-textual\nentailment is a large, real-world dataset for fine-grained multimodal\nreasoning. However, the automatic way in which SNLI-VE has been assembled (via\ncombining parts of two related datasets) gives rise to a large number of errors\nin the labels of this corpus. In this paper, we first present a data collection\neffort to correct the class with the highest error rate in SNLI-VE. Secondly,\nwe re-evaluate an existing model on the corrected corpus, which we call\nSNLI-VE-2.0, and provide a quantitative comparison with its performance on the\nnon-corrected corpus. Thirdly, we introduce e-SNLI-VE-2.0, which appends\nhuman-written natural language explanations to SNLI-VE-2.0. Finally, we train\nmodels that learn from these explanations at training time, and output such\nexplanations at testing time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 23:12:51 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 07:26:19 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Do", "Virginie", ""], ["Camburu", "Oana-Maria", ""], ["Akata", "Zeynep", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2004.03755", "submitter": "Goonmeet Bajaj", "authors": "Goonmeet Bajaj, Bortik Bandyopadhyay, Daniel Schmidt, Pranav\n  Maneriker, Christopher Myers, Srinivasan Parthasarathy", "title": "Understanding Knowledge Gaps in Visual Question Answering: Implications\n  for Gap Identification and Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) systems are tasked with answering natural\nlanguage questions corresponding to a presented image. Traditional VQA datasets\ntypically contain questions related to the spatial information of objects,\nobject attributes, or general scene questions. Recently, researchers have\nrecognized the need to improve the balance of such datasets to reduce the\nsystem's dependency on memorized linguistic features and statistical biases,\nwhile aiming for enhanced visual understanding. However, it is unclear whether\nany latent patterns exist to quantify and explain these failures. As an initial\nstep towards better quantifying our understanding of the performance of VQA\nmodels, we use a taxonomy of Knowledge Gaps (KGs) to tag questions with one or\nmore types of KGs. Each Knowledge Gap (KG) describes the reasoning abilities\nneeded to arrive at a resolution. After identifying KGs for each question, we\nexamine the skew in the distribution of questions for each KG. We then\nintroduce a targeted question generation model to reduce this skew, which\nallows us to generate new types of questions for an image. These new questions\ncan be added to existing VQA datasets to increase the diversity of questions\nand reduce the skew.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 00:27:43 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 21:53:59 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Bajaj", "Goonmeet", ""], ["Bandyopadhyay", "Bortik", ""], ["Schmidt", "Daniel", ""], ["Maneriker", "Pranav", ""], ["Myers", "Christopher", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "2004.03761", "submitter": "Shakti Kumar", "authors": "Shakti Kumar, Jerrod Parker, Panteha Naderian", "title": "Adaptive Transformers in RL", "comments": "10 pages with 9 figures and 4 tables. Main text is 6 pages, appendix\n  is 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Transformers have opened new interesting areas of\nresearch in partially observable reinforcement learning tasks. Results from\nlate 2019 showed that Transformers are able to outperform LSTMs on both memory\nintense and reactive tasks. In this work we first partially replicate the\nresults shown in Stabilizing Transformers in RL on both reactive and memory\nbased environments. We then show performance improvement coupled with reduced\ncomputation when adding adaptive attention span to this Stable Transformer on a\nchallenging DMLab30 environment. The code for all our experiments and models is\navailable at https://github.com/jerrodparker20/adaptive-transformers-in-rl.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 01:03:10 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kumar", "Shakti", ""], ["Parker", "Jerrod", ""], ["Naderian", "Panteha", ""]]}, {"id": "2004.03762", "submitter": "Noah Weber", "authors": "Noah Weber, Leena Shekhar, Heeyoung Kwon, Niranjan Balasubramanian,\n  Nathanael Chambers", "title": "Generating Narrative Text in a Switching Dynamical System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early work on narrative modeling used explicit plans and goals to generate\nstories, but the language generation itself was restricted and inflexible.\nModern methods use language models for more robust generation, but often lack\nan explicit representation of the scaffolding and dynamics that guide a\ncoherent narrative. This paper introduces a new model that integrates explicit\nnarrative structure with neural language models, formalizing narrative modeling\nas a Switching Linear Dynamical System (SLDS). A SLDS is a dynamical system in\nwhich the latent dynamics of the system (i.e. how the state vector transforms\nover time) is controlled by top-level discrete switching variables. The\nswitching variables represent narrative structure (e.g., sentiment or discourse\nstates), while the latent state vector encodes information on the current state\nof the narrative. This probabilistic formulation allows us to control\ngeneration, and can be learned in a semi-supervised fashion using both labeled\nand unlabeled data. Additionally, we derive a Gibbs sampler for our model that\ncan fill in arbitrary parts of the narrative, guided by the switching\nvariables. Our filled-in (English language) narratives outperform several\nbaselines on both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 01:05:19 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Weber", "Noah", ""], ["Shekhar", "Leena", ""], ["Kwon", "Heeyoung", ""], ["Balasubramanian", "Niranjan", ""], ["Chambers", "Nathanael", ""]]}, {"id": "2004.03788", "submitter": "Yue Zhou", "authors": "Yue Zhou, Yan Zhang, JingTao Yao", "title": "Satirical News Detection with Semantic Feature Extraction and\n  Game-theoretic Rough Sets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satirical news detection is an important yet challenging task to prevent\nspread of misinformation. Many feature based and end-to-end neural nets based\nsatirical news detection systems have been proposed and delivered promising\nresults. Existing approaches explore comprehensive word features from satirical\nnews articles, but lack semantic metrics using word vectors for tweet form\nsatirical news. Moreover, the vagueness of satire and news parody determines\nthat a news tweet can hardly be classified with a binary decision, that is,\nsatirical or legitimate. To address these issues, we collect satirical and\nlegitimate news tweets, and propose a semantic feature based approach. Features\nare extracted by exploring inconsistencies in phrases, entities, and between\nmain and relative clauses. We apply game-theoretic rough set model to detect\nsatirical news, in which probabilistic thresholds are derived by game\nequilibrium and repetition learning mechanism. Experimental results on the\ncollected dataset show the robustness and improvement of the proposed approach\ncompared with Pawlak rough set model and SVM.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 03:22:21 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Zhou", "Yue", ""], ["Zhang", "Yan", ""], ["Yao", "JingTao", ""]]}, {"id": "2004.03846", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Fei Huang, Kewei Tu", "title": "Structure-Level Knowledge Distillation For Multilingual Sequence\n  Labeling", "comments": "Accepted to ACL 2020, camera-ready. 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual sequence labeling is a task of predicting label sequences using\na single unified model for multiple languages. Compared with relying on\nmultiple monolingual models, using a multilingual model has the benefit of a\nsmaller model size, easier in online serving, and generalizability to\nlow-resource languages. However, current multilingual models still underperform\nindividual monolingual models significantly due to model capacity limitations.\nIn this paper, we propose to reduce the gap between monolingual models and the\nunified multilingual model by distilling the structural knowledge of several\nmonolingual models (teachers) to the unified multilingual model (student). We\npropose two novel KD methods based on structure-level information: (1)\napproximately minimizes the distance between the student's and the teachers'\nstructure level probability distributions, (2) aggregates the structure-level\nknowledge to local distributions and minimizes the distance between two local\nprobability distributions. Our experiments on 4 multilingual tasks with 25\ndatasets show that our approaches outperform several strong baselines and have\nstronger zero-shot generalizability than both the baseline model and teacher\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:14:01 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 15:10:38 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 09:28:07 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2004.03868", "submitter": "Dieuwke Hupkes", "authors": "Diana Rodr\\'iguez Luna, Edoardo Maria Ponti, Dieuwke Hupkes, Elia\n  Bruni", "title": "Internal and external pressures on language emergence: least effort,\n  object constancy and frequency", "comments": "Accepted for EMNLP-findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, artificial agents were shown to achieve almost perfect\naccuracy in referential games where they have to communicate to identify\nimages. Nevertheless, the resulting communication protocols rarely display\nsalient features of natural languages, such as compositionality. In this paper,\nwe propose some realistic sources of pressure on communication that avert this\noutcome. More specifically, we formalise the principle of least effort through\nan auxiliary objective. Moreover, we explore several game variants, inspired by\nthe principle of object constancy, in which we alter the frequency, position,\nand luminosity of the objects in the images. We perform an extensive analysis\non their effect through compositionality metrics, diagnostic classifiers, and\nzero-shot evaluation. Our findings reveal that the proposed sources of pressure\nresult in emerging languages with less redundancy, more focus on high-level\nconceptual information, and better abilities of generalisation. Overall, our\ncontributions reduce the gap between emergent and natural languages.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 08:12:41 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 17:48:06 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 09:29:44 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Luna", "Diana Rodr\u00edguez", ""], ["Ponti", "Edoardo Maria", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "2004.04000", "submitter": "Pablo Barros", "authors": "Pablo Barros, Ana Tanevska, Alessandra Sciutti", "title": "Learning from Learners: Adapting Reinforcement Learning Agents to be\n  Competitive in a Card Game", "comments": "Submitted to ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning how to adapt to complex and dynamic environments is one of the most\nimportant factors that contribute to our intelligence. Endowing artificial\nagents with this ability is not a simple task, particularly in competitive\nscenarios. In this paper, we present a broad study on how popular reinforcement\nlearning algorithms can be adapted and implemented to learn and to play a\nreal-world implementation of a competitive multiplayer card game. We propose\nspecific training and validation routines for the learning agents, in order to\nevaluate how the agents learn to be competitive and explain how they adapt to\neach others' playing style. Finally, we pinpoint how the behavior of each agent\nderives from their learning style and create a baseline for future research on\nthis scenario.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:11:05 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Barros", "Pablo", ""], ["Tanevska", "Ana", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2004.04100", "submitter": "Hao Zhou", "authors": "Hao Zhou, Chujie Zheng, Kaili Huang, Minlie Huang, Xiaoyan Zhu", "title": "KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn\n  Knowledge-driven Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research of knowledge-driven conversational systems is largely limited\ndue to the lack of dialog data which consist of multi-turn conversations on\nmultiple topics and with knowledge annotations. In this paper, we propose a\nChinese multi-domain knowledge-driven conversation dataset, KdConv, which\ngrounds the topics in multi-turn conversations to knowledge graphs. Our corpus\ncontains 4.5K conversations from three domains (film, music, and travel), and\n86K utterances with an average turn number of 19.0. These conversations contain\nin-depth discussions on related topics and natural transition between multiple\ntopics. To facilitate the following research on this corpus, we provide several\nbenchmark models. Comparative results show that the models can be enhanced by\nintroducing background knowledge, yet there is still a large space for\nleveraging knowledge to model multi-turn conversations for further research.\nResults also show that there are obvious performance differences between\ndifferent domains, indicating that it is worth to further explore transfer\nlearning and domain adaptation. The corpus and benchmark models are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:25:39 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Zhou", "Hao", ""], ["Zheng", "Chujie", ""], ["Huang", "Kaili", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "2004.04131", "submitter": "Francesco Lazzarotto PhD", "authors": "Francesco Lazzarotto, Marco Feroci, and Maria Teresa Pazienza", "title": "A computational theoretical approach for mining data on transient events\n  from databases of high energy astrophysics experiments", "comments": "9 pages, 6 figures (in colors). Conference poster at Third Rome\n  Workshop on Gamma-Ray Bursts in the Afterglow Era, Held 27-30 September 2002\n  at CNR Headquarters, Rome, Italy", "journal-ref": "ASP Conference Series, Vol. 312, pages 528-531, 2004", "doi": "10.13140/RG.2.2.35665.48487", "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data on transient events, like GRBs, are often contained in large databases\nof unstructured data from space experiments, merged with potentially large\namount of background or simply undesired information. We present a\ncomputational formal model to apply techniques of modern computer science -such\nas Data Mining (DM) and Knowledge Discovering in Databases (KDD)- to a generic,\nlarge database derived from a high energy astrophysics experiment. This method\nis aimed to search, identify and extract expected information, and maybe to\ndiscover unexpected information .\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:34:45 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Lazzarotto", "Francesco", ""], ["Feroci", "Marco", ""], ["Pazienza", "Maria Teresa", ""]]}, {"id": "2004.04188", "submitter": "Rafael Melo", "authors": "Leopoldo E. C\\'ardenas-Barr\\'on and Rafael A. Melo", "title": "A fast and effective MIP-based heuristic for a selective and periodic\n  inventory routing problem in reverse logistics", "comments": null, "journal-ref": null, "doi": "10.1016/j.omega.2021.102394", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an NP-hard selective and periodic inventory routing problem\n(SPIRP) in a waste vegetable oil collection environment. This SPIRP arises in\nthe context of reverse logistics where a biodiesel company has daily\nrequirements of oil to be used as raw material in its production process. These\nrequirements can be fulfilled by using the available inventory, collecting\nwaste vegetable oil or purchasing virgin oil. The problem consists in\ndetermining a period (cyclic) planning for the collection and purchasing of oil\nsuch that the total collection, inventory and purchasing costs are minimized,\nwhile meeting the company's oil requirements and all the operational\nconstraints. We propose a MIP-based heuristic which solves a relaxed model\nwithout routing, constructs routes taking into account the relaxation's\nsolution and then improves these routes by solving the capacitated vehicle\nrouting problem associated to each period. Following this approach, an a\nposteriori performance guarantee is ensured, as the approach provides both a\nlower bound and a feasible solution. The performed computational experiments\nshow that the MIP-based heuristic is very fast and effective as it is able to\nencounter near optimal solutions with low gaps within seconds, improving\nseveral of the best known results using just a fraction of the time spent by a\nstate-of-the-art heuristic. A remarkable fact is that the proposed MIP-based\nheuristic improves over the best known results for all the large instances\navailable in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:14:25 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 14:55:18 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["C\u00e1rdenas-Barr\u00f3n", "Leopoldo E.", ""], ["Melo", "Rafael A.", ""]]}, {"id": "2004.04198", "submitter": "Kenneth McMIllan", "authors": "Kenneth L. McMillan", "title": "Bayesian Interpolants as Explanations for Neural Inferences", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of Craig interpolant, used as a form of explanation in automated\nreasoning, is adapted from logical inference to statistical inference and used\nto explain inferences made by neural networks. The method produces explanations\nthat are at the same time concise, understandable and precise.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:45:06 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["McMillan", "Kenneth L.", ""]]}, {"id": "2004.04305", "submitter": "Shahin Shayandeh", "authors": "Swadheen Shukla, Lars Liden, Shahin Shayandeh, Eslam Kamal, Jinchao\n  Li, Matt Mazzola, Thomas Park, Baolin Peng, Jianfeng Gao", "title": "Conversation Learner -- A Machine Teaching Tool for Building Dialog\n  Managers for Task-Oriented Dialog Systems", "comments": "Accepted to ACL 2020 Demonstration Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, industry solutions for building a task-oriented dialog system\nhave relied on helping dialog authors define rule-based dialog managers,\nrepresented as dialog flows. While dialog flows are intuitively interpretable\nand good for simple scenarios, they fall short of performance in terms of the\nflexibility needed to handle complex dialogs. On the other hand, purely\nmachine-learned models can handle complex dialogs, but they are considered to\nbe black boxes and require large amounts of training data. In this\ndemonstration, we showcase Conversation Learner, a machine teaching tool for\nbuilding dialog managers. It combines the best of both approaches by enabling\ndialog authors to create a dialog flow using familiar tools, converting the\ndialog flow into a parametric model (e.g., neural networks), and allowing\ndialog authors to improve the dialog manager (i.e., the parametric model) over\ntime by leveraging user-system dialog logs as training data through a machine\nteaching interface.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 00:10:54 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 20:14:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shukla", "Swadheen", ""], ["Liden", "Lars", ""], ["Shayandeh", "Shahin", ""], ["Kamal", "Eslam", ""], ["Li", "Jinchao", ""], ["Mazzola", "Matt", ""], ["Park", "Thomas", ""], ["Peng", "Baolin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.04366", "submitter": "Xu Chen", "authors": "Haowei Chen, Liekang Zeng, Shuai Yu, and Xu Chen", "title": "Knowledge Distillation for Mobile Edge Computation Offloading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computation offloading allows mobile end devices to put execution of\ncompute-intensive task on the edge servers. End devices can decide whether\noffload the tasks to edge servers, cloud servers or execute locally according\nto current network condition and devices' profile in an online manner. In this\narticle, we propose an edge computation offloading framework based on Deep\nImitation Learning (DIL) and Knowledge Distillation (KD), which assists end\ndevices to quickly make fine-grained decisions to optimize the delay of\ncomputation tasks online. We formalize computation offloading problem into a\nmulti-label classification problem. Training samples for our DIL model are\ngenerated in an offline manner. After model is trained, we leverage knowledge\ndistillation to obtain a lightweight DIL model, by which we further reduce the\nmodel's inference delay. Numerical experiment shows that the offloading\ndecisions made by our model outperforms those made by other related policies in\nlatency metric. Also, our model has the shortest inference delay among all\npolicies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 04:58:46 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Chen", "Haowei", ""], ["Zeng", "Liekang", ""], ["Yu", "Shuai", ""], ["Chen", "Xu", ""]]}, {"id": "2004.04374", "submitter": "Oliver Bendel", "authors": "Oliver Bendel", "title": "Co-Robots as Care Robots", "comments": "Accepted paper of the AAAI 2020 Spring Symposium \"Applied AI in\n  Healthcare: Safety, Community, and the Environment\" (Stanford University).\n  Because of the COVID-19 outbreak, the physical meeting has been postponed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation and collaboration robots, co-robots or cobots for short, are an\nintegral part of factories. For example, they work closely with the fitters in\nthe automotive sector, and everyone does what they do best. However, the novel\nrobots are not only relevant in production and logistics, but also in the\nservice sector, especially where proximity between them and the users is\ndesired or unavoidable. For decades, individual solutions of a very different\nkind have been developed in care. Now experts are increasingly relying on\nco-robots and teaching them the special tasks that are involved in care or\ntherapy. This article presents the advantages, but also the disadvantages of\nco-robots in care and support, and provides information with regard to\nhuman-robot interaction and communication. The article is based on a model that\nhas already been tested in various nursing and retirement homes, namely Lio\nfrom F&P Robotics, and uses results from accompanying studies. The authors can\nshow that co-robots are ideal for care and support in many ways. Of course, it\nis also important to consider a few points in order to guarantee functionality\nand acceptance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 05:58:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Bendel", "Oliver", ""]]}, {"id": "2004.04376", "submitter": "Hongzhi Wang", "authors": "Hongzhi Wang, Bozhou Chen, Yueyang Xu, Kaixin Zhang and Shengwen Zheng", "title": "ConsciousControlFlow(CCF): A Demonstration for conscious Artificial\n  Intelligence", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this demo, we present ConsciousControlFlow(CCF), a prototype system to\ndemonstrate conscious Artificial Intelligence (AI). The system is based on the\ncomputational model for consciousness and the hierarchy of needs. CCF supports\ntypical scenarios to show the behaviors and the mental activities of conscious\nAI. We demonstrate that CCF provides a useful tool for effective machine\nconsciousness demonstration and human behavior study assistance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 06:28:26 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 02:43:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wang", "Hongzhi", ""], ["Chen", "Bozhou", ""], ["Xu", "Yueyang", ""], ["Zhang", "Kaixin", ""], ["Zheng", "Shengwen", ""]]}, {"id": "2004.04412", "submitter": "Christian Meilicke", "authors": "Christian Meilicke, Melisachew Wudage Chekol, Manuel Fink, Heiner\n  Stuckenschmidt", "title": "Reinforced Anytime Bottom Up Rule Learning for Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of todays work on knowledge graph completion is concerned with\nsub-symbolic approaches that focus on the concept of embedding a given graph in\na low dimensional vector space. Against this trend, we propose an approach\ncalled AnyBURL that is rooted in the symbolic space. Its core algorithm is\nbased on sampling paths, which are generalized into Horn rules. Previously\npublished results show that the prediction quality of AnyBURL is on the same\nlevel as current state of the art with the additional benefit of offering an\nexplanation for the predicted fact. In this paper, we are concerned with two\nextensions of AnyBURL. Firstly, we change AnyBURLs interpretation of rules from\n$\\Theta$-subsumption into $\\Theta$-subsumption under Object Identity. Secondly,\nwe introduce reinforcement learning to better guide the sampling process. We\nfound out that reinforcement learning helps finding more valuable rules earlier\nin the search process. We measure the impact of both extensions and compare the\nresulting approach with current state of the art approaches. Our results show\nthat AnyBURL outperforms most sub-symbolic methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 08:15:39 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Meilicke", "Christian", ""], ["Chekol", "Melisachew Wudage", ""], ["Fink", "Manuel", ""], ["Stuckenschmidt", "Heiner", ""]]}, {"id": "2004.04423", "submitter": "Heiko Paulheim", "authors": "Ahmad Al Taweel and Heiko Paulheim", "title": "Towards Exploiting Implicit Human Feedback for Improving RDF2vec\n  Embeddings", "comments": "Workshop paper accepted at Deep Learning for Knowledge Graphs\n  Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RDF2vec is a technique for creating vector space embeddings from an RDF\nknowledge graph, i.e., representing each entity in the graph as a vector. It\nfirst creates sequences of nodes by performing random walks on the graph. In a\nsecond step, those sequences are processed by the word2vec algorithm for\ncreating the actual embeddings. In this paper, we explore the use of external\nedge weights for guiding the random walks. As edge weights, transition\nprobabilities between pages in Wikipedia are used as a proxy for the human\nfeedback for the importance of an edge. We show that in some scenarios, RDF2vec\nutilizing those transition probabilities can outperform both RDF2vec based on\nrandom walks as well as the usage of graph internal edge weights.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 08:39:19 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Taweel", "Ahmad Al", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2004.04450", "submitter": "Danial Kamran", "authors": "Danial Kamran, Carlos Fernandez Lopez, Martin Lauer, Christoph Stiller", "title": "Risk-Aware High-level Decisions for Automated Driving at Occluded\n  Intersections with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is nowadays a popular framework for solving different\ndecision making problems in automated driving. However, there are still some\nremaining crucial challenges that need to be addressed for providing more\nreliable policies. In this paper, we propose a generic risk-aware DQN approach\nin order to learn high level actions for driving through unsignalized occluded\nintersections. The proposed state representation provides lane based\ninformation which allows to be used for multi-lane scenarios. Moreover, we\npropose a risk based reward function which punishes risky situations instead of\nonly collision failures. Such rewarding approach helps to incorporate risk\nprediction into our deep Q network and learn more reliable policies which are\nsafer in challenging situations. The efficiency of the proposed approach is\ncompared with a DQN learned with conventional collision based rewarding scheme\nand also with a rule-based intersection navigation policy. Evaluation results\nshow that the proposed approach outperforms both of these methods. It provides\nsafer actions than collision-aware DQN approach and is less overcautious than\nthe rule-based policy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:44:41 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kamran", "Danial", ""], ["Lopez", "Carlos Fernandez", ""], ["Lauer", "Martin", ""], ["Stiller", "Christoph", ""]]}, {"id": "2004.04464", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi and Yoshinobu Kawahara", "title": "On Anomaly Interpretation via Shapley Values", "comments": "23 pages, 5 figures and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly localization is an essential problem as anomaly detection is. Because\na rigorous localization requires a causal model of a target system, practically\nwe often resort to a relaxed problem of anomaly interpretation, for which we\nare to obtain meaningful attribution of anomaly scores to input features. In\nthis paper, we investigate the use of the Shapley value for anomaly\ninterpretation. We focus on the semi-supervised anomaly detection and newly\npropose a characteristic function, on which the Shapley value is computed,\nspecifically for anomaly scores. The idea of the proposed method is\napproximating the absence of some features by minimizing an anomaly score with\nregard to them. We examine the performance of the proposed method as well as\nother general approaches to computing the Shapley value in interpreting anomaly\nscores. We show the results of experiments on multiple datasets and anomaly\ndetection methods, which indicate the usefulness of the Shapley-based anomaly\ninterpretation toward anomaly localization.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:27:00 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2004.04479", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Desmond J. Higham, and Alexander N. Gorban", "title": "On Adversarial Examples and Stealth Attacks in Artificial Intelligence\n  Systems", "comments": null, "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020", "doi": "10.1109/IJCNN48605.2020.9207472", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present a formal theoretical framework for assessing and\nanalyzing two classes of malevolent action towards generic Artificial\nIntelligence (AI) systems. Our results apply to general multi-class classifiers\nthat map from an input space into a decision space, including artificial neural\nnetworks used in deep learning applications. Two classes of attacks are\nconsidered. The first class involves adversarial examples and concerns the\nintroduction of small perturbations of the input data that cause\nmisclassification. The second class, introduced here for the first time and\nnamed stealth attacks, involves small perturbations to the AI system itself.\nHere the perturbed system produces whatever output is desired by the attacker\non a specific small data set, perhaps even a single input, but performs as\nnormal on a validation set (which is unknown to the attacker). We show that in\nboth cases, i.e., in the case of an attack based on adversarial examples and in\nthe case of a stealth attack, the dimensionality of the AI's decision-making\nspace is a major contributor to the AI's susceptibility. For attacks based on\nadversarial examples, a second crucial parameter is the absence of local\nconcentrations in the data probability distribution, a property known as\nSmeared Absolute Continuity. According to our findings, robustness to\nadversarial examples requires either (a) the data distributions in the AI's\nfeature space to have concentrated probability density functions or (b) the\ndimensionality of the AI's decision variables to be sufficiently small. We also\nshow how to construct stealth attacks on high-dimensional AI systems that are\nhard to spot unless the validation set is made exponentially large.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:56:53 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Higham", "Desmond J.", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2004.04571", "submitter": "Anthony Constantinou", "authors": "Anthony Constantinou", "title": "Learning Bayesian Networks that enable full propagation of evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on recent developments in Bayesian network (BN) structure\nlearning under the controversial assumption that the input variables are\ndependent. This assumption can be viewed as a learning constraint geared\ntowards cases where the input variables are known or assumed to be dependent.\nIt addresses the problem of learning multiple disjoint subgraphs that do not\nenable full propagation of evidence. This problem is highly prevalent in cases\nwhere the sample size of the input data is low with respect to the\ndimensionality of the model, which is often the case when working with real\ndata. The paper presents a novel hybrid structure learning algorithm, called\nSaiyanH, that addresses this issue. The results show that this constraint helps\nthe algorithm to estimate the number of true edges with higher accuracy\ncompared to the state-of-the-art. Out of the 13 algorithms investigated, the\nresults rank SaiyanH 4th in reconstructing the true DAG, with accuracy scores\nlower by 8.1% (F1), 10.2% (BSF), and 19.5% (SHD) compared to the top ranked\nalgorithm, and higher by 75.5% (F1), 118% (BSF), and 4.3% (SHD) compared to the\nbottom ranked algorithm. Overall, the results suggest that the proposed\nalgorithm discovers satisfactorily accurate connected DAGs in cases where other\nalgorithms produce multiple disjoint subgraphs that often underfit the true\ngraph.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:44:11 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 14:16:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Constantinou", "Anthony", ""]]}, {"id": "2004.04574", "submitter": "Aras Dargazany", "authors": "Aras Dargazany", "title": "Model-based actor-critic: GAN (model generator) + DRL (actor-critic) =>\n  AGI", "comments": "arXiv admin note: text overlap with arXiv:1610.01945,\n  arXiv:1903.04411, arXiv:1910.01007 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our effort is toward unifying GAN and DRL algorithms into a unifying AI model\n(AGI or general-purpose AI or artificial general intelligence which has\ngeneral-purpose applications to: (A) offline learning (of stored data) like GAN\nin (un/semi-/fully-)SL setting such as big data analytics (mining) and\nvisualization; (B) online learning (of real or simulated devices) like DRL in\nRL setting (with/out environment reward) such as (real or simulated) robotics\nand control; Our core proposal is adding an (generative/predictive) environment\nmodel to the actor-critic (model-free) architecture which results in a\nmodel-based actor-critic architecture with temporal-differencing (TD) error and\nan episodic memory. The proposed AI model is similar to (model-free) DDPG and\ntherefore it's called model-based DDPG. To evaluate it, we compare it with\n(model-free) DDPG by applying them both to a variety (wide range) of\nindependent simulated robotic and control task environments in OpenAI Gym and\nUnity Agents. Our initial limited experiments show that DRL and GAN in\nmodel-based actor-critic results in an incremental goal-driven intellignce\nrequired to solve each task with similar performance to (model-free) DDPG. Our\nfuture focus is to investigate the proposed AI model potential to: (A) unify\nDRL field inside AI by producing competitive performance compared to the best\nof model-based (PlaNet) and model-free (D4PG) approaches; (B) bridge the gap\nbetween AI and robotics communities by solving the important problem of reward\nengineering with learning the reward function by demonstration.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 02:05:54 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 19:36:09 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 00:54:41 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 17:14:19 GMT"}, {"version": "v5", "created": "Mon, 28 Dec 2020 20:19:56 GMT"}, {"version": "v6", "created": "Fri, 22 Jan 2021 16:56:39 GMT"}, {"version": "v7", "created": "Mon, 1 Mar 2021 21:35:45 GMT"}, {"version": "v8", "created": "Fri, 16 Apr 2021 23:03:35 GMT"}, {"version": "v9", "created": "Tue, 20 Apr 2021 22:09:26 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Dargazany", "Aras", ""]]}, {"id": "2004.04640", "submitter": "Maohong Chen", "authors": "Maohong Chen, Yong Xiao, Qiang Li and Kwang-cheng Chen", "title": "Minimizing Age-of-Information for Fog Computing-supported Vehicular\n  Networks with Deep Q-learning", "comments": "6 pages,9 figures. Accepted at IEEE International Conference on\n  Communications (ICC), Dublin, Ireland, June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected vehicular network is one of the key enablers for next generation\ncloud/fog-supported autonomous driving vehicles. Most connected vehicular\napplications require frequent status updates and Age of Information (AoI) is a\nmore relevant metric to evaluate the performance of wireless links between\nvehicles and cloud/fog servers. This paper introduces a novel proactive and\ndata-driven approach to optimize the driving route with a main objective of\nguaranteeing the confidence of AoI. In particular, we report a study on three\nmonth measurements of a multi-vehicle campus shuttle system connected to\ncloud/fog servers via a commercial LTE network. We establish empirical models\nfor AoI in connected vehicles and investigate the impact of major factors on\nthe performance of AoI. We also propose a Deep Q-Learning Netwrok (DQN)-based\nalgorithm to decide the optimal driving route for each connected vehicle with\nmaximized confidence level. Numerical results show that the proposed approach\ncan lead to a significant improvement on the AoI confidence for various types\nof services supported.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:19:25 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Chen", "Maohong", ""], ["Xiao", "Yong", ""], ["Li", "Qiang", ""], ["Chen", "Kwang-cheng", ""]]}, {"id": "2004.04647", "submitter": "Jamal Toutouh", "authors": "Una-May O'Reilly and Jamal Toutouh and Marcos Pertierra and Daniel\n  Prado Sanchez and Dennis Garcia and Anthony Erb Luogo and Jonathan Kelly and\n  Erik Hemberg", "title": "Adversarial Genetic Programming for Cyber Security: A Rising Application\n  Domain Where GP Matters", "comments": null, "journal-ref": null, "doi": "10.1007/s10710-020-09389-y", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber security adversaries and engagements are ubiquitous and ceaseless. We\ndelineate Adversarial Genetic Programming for Cyber Security, a research topic\nthat, by means of genetic programming (GP), replicates and studies the behavior\nof cyber adversaries and the dynamics of their engagements. Adversarial Genetic\nProgramming for Cyber Security encompasses extant and immediate research\nefforts in a vital problem domain, arguably occupying a position at the\nfrontier where GP matters. Additionally, it prompts research questions around\nevolving complex behavior by expressing different abstractions with GP and\nopportunities to reconnect to the Machine Learning, Artificial Life,\nAgent-Based Modeling and Cyber Security communities. We present a framework\ncalled RIVALS which supports the study of network security arms races. Its goal\nis to elucidate the dynamics of cyber networks under attack by computationally\nmodeling and simulating them.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:13:14 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["O'Reilly", "Una-May", ""], ["Toutouh", "Jamal", ""], ["Pertierra", "Marcos", ""], ["Sanchez", "Daniel Prado", ""], ["Garcia", "Dennis", ""], ["Luogo", "Anthony Erb", ""], ["Kelly", "Jonathan", ""], ["Hemberg", "Erik", ""]]}, {"id": "2004.04686", "submitter": "Niklas K\\\"uhl", "authors": "Niklas K\\\"uhl, Marc Goutier, Robin Hirt, Gerhard Satzger", "title": "Machine Learning in Artificial Intelligence: Towards a Common\n  Understanding", "comments": "Hawaii International Conference on System Sciences (HICSS-52) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The application of \"machine learning\" and \"artificial intelligence\" has\nbecome popular within the last decade. Both terms are frequently used in\nscience and media, sometimes interchangeably, sometimes with different\nmeanings. In this work, we aim to clarify the relationship between these terms\nand, in particular, to specify the contribution of machine learning to\nartificial intelligence. We review relevant literature and present a conceptual\nframework which clarifies the role of machine learning to build (artificial)\nintelligent agents. Hence, we seek to provide more terminological clarity and a\nstarting point for (interdisciplinary) discussions and future research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:09:57 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["K\u00fchl", "Niklas", ""], ["Goutier", "Marc", ""], ["Hirt", "Robin", ""], ["Satzger", "Gerhard", ""]]}, {"id": "2004.04687", "submitter": "Majid Farzaneh", "authors": "Majid Farzaneh and Rahil Mahdian Toroghi", "title": "GGA-MG: Generative Genetic Algorithm for Music Generation", "comments": "14 pages, Submitted to Journal of Evolutionary Intelligence", "journal-ref": null, "doi": "10.13140/RG.2.2.16677.24805", "report-no": null, "categories": "cs.SD cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music Generation (MG) is an interesting research topic that links the art of\nmusic and Artificial Intelligence (AI). The goal is to train an artificial\ncomposer to generate infinite, fresh, and pleasurable musical pieces. Music has\ndifferent parts such as melody, harmony, and rhythm. In this paper, we propose\na Generative Genetic Algorithm (GGA) to produce a melody automatically. The\nmain GGA uses a Long Short-Term Memory (LSTM) recurrent neural network as the\nobjective function, which should be trained by a spectrum of bad-to-good\nmelodies. These melodies have to be provided by another GGA with a different\nobjective function. Good melodies have been provided by CAMPINs collection. We\nhave considered the rhythm in this work, too. The experimental results clearly\nshow that the proposed GGA method is able to generate eligible melodies with\nnatural transitions and without rhythm error.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 22:45:42 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Farzaneh", "Majid", ""], ["Toroghi", "Rahil Mahdian", ""]]}, {"id": "2004.04722", "submitter": "Paul Van Eecke", "authors": "Paul Van Eecke (1 and 2), Katrien Beuls (1) ((1) Artificial\n  Intelligence Laboratory, Vrije Universiteit Brussel, Brussels, Belgium, (2)\n  ITEC, imec research group at KU Leuven, Kortrijk, Belgium)", "title": "Re-conceptualising the Language Game Paradigm in the Framework of\n  Multi-Agent Reinforcement Learning", "comments": "This paper was accepted for presentation at the 2020 AAAI Spring\n  Symposium `Challenges and Opportunities for Multi-Agent Reinforcement\n  Learning' after a double-blind reviewing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate the challenge of re-conceptualising the language\ngame experimental paradigm in the framework of multi-agent reinforcement\nlearning (MARL). If successful, future language game experiments will benefit\nfrom the rapid and promising methodological advances in the MARL community,\nwhile future MARL experiments on learning emergent communication will benefit\nfrom the insights and results gained from language game experiments. We\nstrongly believe that this cross-pollination has the potential to lead to major\nbreakthroughs in the modelling of how human-like languages can emerge and\nevolve in multi-agent systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:55:15 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Van Eecke", "Paul", "", "1 and 2"], ["Beuls", "Katrien", ""]]}, {"id": "2004.04733", "submitter": "Denny Vrande\\v{c}i\\'c", "authors": "Denny Vrande\\v{c}i\\'c", "title": "Architecture for a multilingual Wikipedia", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia's vision is a world in which everyone can share in the sum of all\nknowledge. In its first two decades, this vision has been very unevenly\nachieved. One of the largest hindrances is the sheer number of languages\nWikipedia needs to cover in order to achieve that goal. We argue that we need a\nnew approach to tackle this problem more effectively, a multilingual Wikipedia\nwhere content can be shared between language editions. This paper proposes an\narchitecture for a system that fulfills this goal. It separates the goal in two\nparts: creating and maintaining content in an abstract notation within a\nproject called Abstract Wikipedia, and creating an infrastructure called\nWikilambda that can translate this notation to natural language. Both parts are\nfully owned and maintained by the community, as is the integration of the\nresults in the existing Wikipedia editions. This architecture will make more\nencyclopedic content available to more people in their own language, and at the\nsame time allow more people to contribute knowledge and reach more people with\ntheir contributions, no matter what their respective language backgrounds.\nAdditionally, Wikilambda will unlock a new type of knowledge asset people can\nshare in through the Wikimedia projects, functions, which will vastly expand\nwhat people can do with knowledge from Wikimedia, and provide a new venue to\ncollaborate and to engage the creativity of contributors from all around the\nworld. These two projects will considerably expand the capabilities of the\nWikimedia platform to enable every single human being to freely share in the\nsum of all knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 22:25:10 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Vrande\u010di\u0107", "Denny", ""]]}, {"id": "2004.04768", "submitter": "Zhibo Yang", "authors": "Jianyuan Deng, Zhibo Yang, Yao Li, Dimitris Samaras, Fusheng Wang", "title": "Towards Better Opioid Antagonists Using Deep Reinforcement Learning", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Naloxone, an opioid antagonist, has been widely used to save lives from\nopioid overdose, a leading cause for death in the opioid epidemic. However,\nnaloxone has short brain retention ability, which limits its therapeutic\nefficacy. Developing better opioid antagonists is critical in combating the\nopioid epidemic.Instead of exhaustively searching in a huge chemical space for\nbetter opioid antagonists, we adopt reinforcement learning which allows\nefficient gradient-based search towards molecules with desired physicochemical\nand/or biological properties. Specifically, we implement a deep reinforcement\nlearning framework to discover potential lead compounds as better opioid\nantagonists with enhanced brain retention ability. A customized multi-objective\nreward function is designed to bias the generation towards molecules with both\nsufficient opioid antagonistic effect and enhanced brain retention ability.\nThorough evaluation demonstrates that with this framework, we are able to\nidentify valid, novel and feasible molecules with multiple desired properties,\nwhich has high potential in drug discovery.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:28:50 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Deng", "Jianyuan", ""], ["Yang", "Zhibo", ""], ["Li", "Yao", ""], ["Samaras", "Dimitris", ""], ["Wang", "Fusheng", ""]]}, {"id": "2004.04778", "submitter": "Lucas N. Alegre", "authors": "Lucas N. Alegre, Ana L. C. Bazzan, Bruno C. da Silva", "title": "Quantifying the Impact of Non-Stationarity in Reinforcement\n  Learning-Based Traffic Signal Control", "comments": "13 pages", "journal-ref": "PeerJ Computer Science 2021", "doi": "10.7717/peerj-cs.575", "report-no": "7:e575", "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), dealing with non-stationarity is a\nchallenging issue. However, some domains such as traffic optimization are\ninherently non-stationary. Causes for and effects of this are manifold. In\nparticular, when dealing with traffic signal controls, addressing\nnon-stationarity is key since traffic conditions change over time and as a\nfunction of traffic control decisions taken in other parts of a network. In\nthis paper we analyze the effects that different sources of non-stationarity\nhave in a network of traffic signals, in which each signal is modeled as a\nlearning agent. More precisely, we study both the effects of changing the\n\\textit{context} in which an agent learns (e.g., a change in flow rates\nexperienced by it), as well as the effects of reducing agent observability of\nthe true environment state. Partial observability may cause distinct states (in\nwhich distinct actions are optimal) to be seen as the same by the traffic\nsignal agents. This, in turn, may lead to sub-optimal performance. We show that\nthe lack of suitable sensors to provide a representative observation of the\nreal state seems to affect the performance more drastically than the changes to\nthe underlying traffic patterns.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 19:20:43 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Alegre", "Lucas N.", ""], ["Bazzan", "Ana L. C.", ""], ["da Silva", "Bruno C.", ""]]}, {"id": "2004.04787", "submitter": "Ha Q. Ngo", "authors": "Ha Q. Ngo, Christoph Henke, Frank Hees", "title": "An End-to-End Learning Approach for Trajectory Prediction in Pedestrian\n  Zones", "comments": "Submitted 23 March 2020", "journal-ref": "2020 ACM/IEEE International Conference on Human-Robot Interaction.\n  Workshop on The Forgotten in HRI: Incidental Encounters with Robots in Public\n  Spaces", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to explore the problem of trajectory prediction in\nheterogeneous pedestrian zones, where social dynamics representation is a big\nchallenge. Proposed is an end-to-end learning framework for prediction accuracy\nimprovement based on an attention mechanism to learn social interaction from\nmulti-factor inputs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 19:56:45 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 22:43:17 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ngo", "Ha Q.", ""], ["Henke", "Christoph", ""], ["Hees", "Frank", ""]]}, {"id": "2004.04849", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Tushar Khot, Ashish Sabharwal", "title": "More Bang for Your Buck: Natural Perturbation for Robust Question\n  Answering", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent models have achieved human-level scores on many NLP datasets, we\nobserve that they are considerably sensitive to small changes in input. As an\nalternative to the standard approach of addressing this issue by constructing\ntraining sets of completely new examples, we propose doing so via minimal\nperturbation of examples. Specifically, our approach involves first collecting\na set of seed examples and then applying human-driven natural perturbations (as\nopposed to rule-based machine perturbations), which often change the gold label\nas well. Local perturbations have the advantage of being relatively easier (and\nhence cheaper) to create than writing out completely new examples. To evaluate\nthe impact of this phenomenon, we consider a recent question-answering dataset\n(BoolQ) and study the benefit of our approach as a function of the perturbation\ncost ratio, the relative cost of perturbing an existing question vs. creating a\nnew one from scratch. We find that when natural perturbations are moderately\ncheaper to create, it is more effective to train models using them: such models\nexhibit higher robustness and better generalization, while retaining\nperformance on the original BoolQ dataset.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:12:39 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:10:00 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "2004.04851", "submitter": "Ankan Bansal", "authors": "Ankan Bansal, Sai Saketh Rambhatla, Abhinav Shrivastava, Rama\n  Chellappa", "title": "Spatial Priming for Detecting Human-Object Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relative spatial layout of a human and an object is an important cue for\ndetermining how they interact. However, until now, spatial layout has been used\njust as side-information for detecting human-object interactions (HOIs). In\nthis paper, we present a method for exploiting this spatial layout information\nfor detecting HOIs in images. The proposed method consists of a layout module\nwhich primes a visual module to predict the type of interaction between a human\nand an object. The visual and layout modules share information through lateral\nconnections at several stages. The model uses predictions from the layout\nmodule as a prior to the visual module and the prediction from the visual\nmodule is given as the final output. It also incorporates semantic information\nabout the object using word2vec vectors. The proposed model reaches an mAP of\n24.79% for HICO-Det dataset which is about 2.8% absolute points higher than the\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:20:30 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bansal", "Ankan", ""], ["Rambhatla", "Sai Saketh", ""], ["Shrivastava", "Abhinav", ""], ["Chellappa", "Rama", ""]]}, {"id": "2004.04917", "submitter": "Mahdi Abavisani", "authors": "Mahdi Abavisani and Liwei Wu and Shengli Hu and Joel Tetreault and\n  Alejandro Jaimes", "title": "Multimodal Categorization of Crisis Events in Social Media", "comments": "Conference on Computer Vision and Pattern Recognition (CVPR 2020)", "journal-ref": "Conference on Computer Vision and Pattern Recognition (CVPR 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent developments in image classification and natural language processing,\ncoupled with the rapid growth in social media usage, have enabled fundamental\nadvances in detecting breaking events around the world in real-time. Emergency\nresponse is one such area that stands to gain from these advances. By\nprocessing billions of texts and images a minute, events can be automatically\ndetected to enable emergency response workers to better assess rapidly evolving\nsituations and deploy resources accordingly. To date, most event detection\ntechniques in this area have focused on image-only or text-only approaches,\nlimiting detection performance and impacting the quality of information\ndelivered to crisis response teams. In this paper, we present a new multimodal\nfusion method that leverages both images and texts as input. In particular, we\nintroduce a cross-attention module that can filter uninformative and misleading\ncomponents from weak modalities on a sample by sample basis. In addition, we\nemploy a multimodal graph-based approach to stochastically transition between\nembeddings of different multimodal pairs during training to better regularize\nthe learning process as well as dealing with limited training data by\nconstructing new matched pairs from different samples. We show that our method\noutperforms the unimodal approaches and strong multimodal baselines by a large\nmargin on three crisis-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 06:31:30 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Abavisani", "Mahdi", ""], ["Wu", "Liwei", ""], ["Hu", "Shengli", ""], ["Tetreault", "Joel", ""], ["Jaimes", "Alejandro", ""]]}, {"id": "2004.04938", "submitter": "Yufei Tian", "authors": "Yufei Tian, Tuhin Chakrabarty, Fred Morstatter and Nanyun Peng", "title": "Identifying Distributional Perspective Differences from Colingual Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perspective differences exist among different cultures or languages. A lack\nof mutual understanding among different groups about their perspectives on\nspecific values or events may lead to uninformed decisions or biased opinions.\nAutomatically understanding the group perspectives can provide essential\nbackground for many downstream applications of natural language processing\ntechniques. In this paper, we study colingual groups and use language corpora\nas a proxy to identify their distributional perspectives. We present a novel\ncomputational approach to learn shared understandings, and benchmark our method\nby building culturally-aware models for the English, Chinese, and Japanese\nlanguages. On a held out set of diverse topics including marriage, corruption,\ndemocracy, our model achieves high correlation with human judgements regarding\nintra-group values and inter-group differences.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 08:13:07 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 19:11:33 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Tian", "Yufei", ""], ["Chakrabarty", "Tuhin", ""], ["Morstatter", "Fred", ""], ["Peng", "Nanyun", ""]]}, {"id": "2004.05002", "submitter": "Reza Bonyadi", "authors": "Mohammad Reza Bonyadi, Rui Wang, Maryam Ziaei", "title": "Self Punishment and Reward Backfill for Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents learn by encouraging behaviours which maximize\ntheir total reward, usually provided by the environment. In many environments,\nhowever, the reward is provided after a series of actions rather than each\nsingle action, causing the agent to experience ambiguity in terms of whether\nthose actions are effective, an issue called the credit assignment problem. In\nthis paper, we propose two strategies, inspired by behavioural psychology, to\nestimate a more informative reward value for actions with no reward. The first\nstrategy, called self-punishment, discourages the agent to avoid making\nmistakes, i.e., actions which lead to a terminal state. The second strategy,\ncalled the rewards backfill, backpropagates the rewards between two rewarded\nactions. We prove that, under certain assumptions, these two strategies\nmaintain the order of the policies in the space of all possible policies in\nterms of their total reward, and, by extension, maintain the optimal policy. We\nincorporated these two strategies into three popular deep reinforcement\nlearning approaches and evaluated the results on thirty Atari games. After\nparameter tuning, our results indicate that the proposed strategies improve the\ntested methods in over 65 percent of tested games by up to over 25 times\nperformance improvement.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 11:53:11 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bonyadi", "Mohammad Reza", ""], ["Wang", "Rui", ""], ["Ziaei", "Maryam", ""]]}, {"id": "2004.05077", "submitter": "Agostinho J\\'unior", "authors": "Janderson Ferreira (1), Agostinho A. F. J\\'unior (1), Yves M. Galv\\~ao\n  (1), Bruno J. T. Fernandes (1) and Pablo Barros (1 and 2) ((1) Universidade\n  de Pernambuco - Escola Polit\\'ecnica de Pernambuco, (2) Cognitive\n  Architecture for Collaborative Technologies Unit - Istituto Italiano di\n  Tecnologia)", "title": "CNN Encoder to Reduce the Dimensionality of Data Image for Motion\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications need path planning algorithms to solve tasks in\ndifferent areas, such as social applications, autonomous cars, and tracking\nactivities. And most importantly motion planning. Although the use of path\nplanning is sufficient in most motion planning scenarios, they represent\npotential bottlenecks in large environments with dynamic changes. To tackle\nthis problem, the number of possible routes could be reduced to make it easier\nfor path planning algorithms to find the shortest path with less efforts. An\ntraditional algorithm for path planning is the A*, it uses an heuristic to work\nfaster than other solutions. In this work, we propose a CNN encoder capable of\neliminating useless routes for motion planning problems, then we combine the\nproposed neural network output with A*. To measure the efficiency of our\nsolution, we propose a database with different scenarios of motion planning\nproblems. The evaluated metric is the number of the iterations to find the\nshortest path. The A* was compared with the CNN Encoder (proposal) with A*. In\nall evaluated scenarios, our solution reduced the number of iterations by more\nthan 60\\%.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 15:44:52 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Ferreira", "Janderson", "", "1 and 2"], ["J\u00fanior", "Agostinho A. F.", "", "1 and 2"], ["Galv\u00e3o", "Yves M.", "", "1 and 2"], ["Fernandes", "Bruno J. T.", "", "1 and 2"], ["Barros", "Pablo", "", "1 and 2"]]}, {"id": "2004.05146", "submitter": "Aron Laszka", "authors": "Amutheezan Sivagnanam, Afiya Ayman, Michael Wilbur, Philip Pugliese,\n  Abhishek Dubey, Aron Laszka", "title": "Minimizing Energy Use of Mixed-Fleet Public Transit for Fixed-Route\n  Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affordable public transit services are crucial for communities since they\nenable residents to access employment, education, and other services.\nUnfortunately, transit services that provide wide coverage tend to suffer from\nrelatively low utilization, which results in high fuel usage per passenger per\nmile, leading to high operating costs and environmental impact. Electric\nvehicles (EVs) can reduce energy costs and environmental impact, but most\npublic transit agencies have to employ them in combination with conventional,\ninternal-combustion engine vehicles due to the high upfront costs of EVs. To\nmake the best use of such a mixed fleet of vehicles, transit agencies need to\noptimize route assignments and charging schedules, which presents a challenging\nproblem for large transit networks. We introduce a novel problem formulation to\nminimize fuel and electricity use by assigning vehicles to transit trips and\nscheduling them for charging, while serving an existing fixed-route transit\nschedule. We present an integer program for optimal assignment and scheduling,\nand we propose polynomial-time heuristic and meta-heuristic algorithms for\nlarger networks. We evaluate our algorithms on the public transit service of\nChattanooga, TN using operational data collected from transit vehicles. Our\nresults show that the proposed algorithms are scalable and can reduce energy\nuse and, hence, environmental impact and operational costs. For Chattanooga,\nthe proposed algorithms can save $145,635 in energy costs and 576.7 metric tons\nof CO2 emission annually.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:45:14 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 20:50:38 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 05:19:44 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 03:48:57 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sivagnanam", "Amutheezan", ""], ["Ayman", "Afiya", ""], ["Wilbur", "Michael", ""], ["Pugliese", "Philip", ""], ["Dubey", "Abhishek", ""], ["Laszka", "Aron", ""]]}, {"id": "2004.05155", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta,\n  Ruslan Salakhutdinov", "title": "Learning to Explore using Active Neural SLAM", "comments": "Published in ICLR-2020. See the project webpage at\n  https://devendrachaplot.github.io/projects/Neural-SLAM for supplementary\n  videos. The code is available at\n  https://github.com/devendrachaplot/Neural-SLAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a modular and hierarchical approach to learn policies for\nexploring 3D environments, called `Active Neural SLAM'. Our approach leverages\nthe strengths of both classical and learning-based methods, by using analytical\npath planners with learned SLAM module, and global and local policies. The use\nof learning provides flexibility with respect to input modalities (in the SLAM\nmodule), leverages structural regularities of the world (in global policies),\nand provides robustness to errors in state estimation (in local policies). Such\nuse of learning within each module retains its benefits, while at the same\ntime, hierarchical decomposition and modular training allow us to sidestep the\nhigh sample complexities associated with training end-to-end policies. Our\nexperiments in visually and physically realistic simulated 3D environments\ndemonstrate the effectiveness of our approach over past learning and\ngeometry-based approaches. The proposed model can also be easily transferred to\nthe PointGoal task and was the winning entry of the CVPR 2019 Habitat PointGoal\nNavigation Challenge.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:57:29 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Gandhi", "Dhiraj", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2004.05205", "submitter": "Christoforos Mavrogiannis", "authors": "Christoforos Mavrogiannis, Jonathan A. DeCastro, Siddhartha S.\n  Srinivasa", "title": "Implicit Multiagent Coordination at Unsignalized Intersections via\n  Multimodal Inference Enabled by Topological Braids", "comments": "16 pages, 13 figures, new experiments, new explanatory figures for\n  intuition and new title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on navigation among rational, non-communicating agents at\nunsignalized street intersections. Following collision-free motion under such\nsettings demands nuanced implicit coordination among agents. Often, the\nstructure of these domains constrains multiagent trajectories to belong to a\nfinite set of modes. Our key insight is that empowering agents with a model of\nthese modes can enable effective coordination, realized implicitly via intent\nsignals encoded in agents' actions. In this paper, we represent modes of joint\nbehavior in a compact and interpretable fashion using the formalism of\ntopological braids. We design a decentralized planning algorithm that generates\nactions aimed at reducing the uncertainty over the mode of the emerging\nmultiagent behavior. This mechanism enables agents that individually run our\nalgorithm to collectively reject unsafe intersection crossings. We validate our\napproach in a simulated case study featuring challenging multiagent scenarios\nat a four-way unsignalized intersection. Our model is shown to reduce frequency\nof collisions by >65% over a set of baselines explicitly reasoning over\ntrajectories, while maintaining comparable time efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 19:01:29 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 00:39:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mavrogiannis", "Christoforos", ""], ["DeCastro", "Jonathan A.", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2004.05219", "submitter": "Georgiana Dinu", "authors": "Georgiana Dinu, Prashant Mathur, Marcello Federico, Stanislas Lauly,\n  Yaser Al-Onaizan", "title": "Joint translation and unit conversion for end-to-end localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of natural language tasks require processing of textual data which\ncontains a mix of natural language and formal languages such as mathematical\nexpressions. In this paper, we take unit conversions as an example and propose\na data augmentation technique which leads to models learning both translation\nand conversion tasks as well as how to adequately switch between them for\nend-to-end localization.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 20:18:43 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dinu", "Georgiana", ""], ["Mathur", "Prashant", ""], ["Federico", "Marcello", ""], ["Lauly", "Stanislas", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "2004.05267", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "What Kind of Programming Language Best Suits Integrative AGI?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What kind of programming language would be most appropriate to serve the\nneeds of integrative, multi-paradigm, multi-software-system approaches to AGI?\nThis question is broached via exploring the more particular question of how to\ncreate a more scalable and usable version of the \"Atomese\" programming language\nthat forms a key component of the OpenCog AGI design (an \"Atomese 2.0\") . It is\ntentatively proposed that the core of Atomese 2.0 should be a very flexible\nframework of rewriting rules for rewriting a metagraph (where the rules\nthemselves are represented within the same metagraph, and some of the\nintermediate data created and used during the rule-interpretation process may\nbe represented in the same metagraph). This framework should support concurrent\nrewriting of the metagraph according to rules that are labeled with various\nsorts of uncertainty-quantifications, and that are labeled with various sorts\nof types associated with various type systems. A gradual typing approach should\nbe used to enable mixture of rules and other metagraph nodes/links associated\nwith various type systems, and untyped metagraph nodes/links not associated\nwith any type system. This must be done in a way that allows reasonable\nefficiency and scalability, including in concurrent and distributed processing\ncontexts, in the case where a large percentage of of processing time is\noccupied with evaluating static pattern-matching queries on specific subgraphs\nof a large metagraph (including a rich variety of queries such as matches\nagainst nodes representing variables, and matches against whole subgraphs,\netc.).\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:20:48 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2004.05268", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Combinatorial Decision Dags: A Natural Computational Model for General\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel computational model (CoDD) utilizing combinatory logic to create\nhigher-order decision trees is presented. A theoretical analysis of general\nintelligence in terms of the formal theory of pattern recognition and pattern\nformation is outlined, and shown to take especially natural form in the case\nwhere patterns are expressed in CoDD language. Relationships between logical\nentropy and algorithmic information, and Shannon entropy and runtime\ncomplexity, are shown to be elucidated by this approach. Extension to the\nquantum computing case is also briefly discussed.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:23:35 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2004.05269", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Grounding Occam's Razor in a Formal Theory of Simplicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A formal theory of simplicity is introduced, in the context of a\n\"combinational\" computation model that views computation as comprising the\niterated transformational and compositional activity of a population of agents\nupon each other. Conventional measures of simplicity in terms of algorithmic\ninformation etc. are shown to be special cases of a broader understanding of\nthe core \"symmetry\" properties constituting what is defined here as a\nCompositional Simplicity Measure (CoSM).\n  This theory of CoSMs is extended to a theory of CoSMOS (Combinational\nSimplicity Measure Operating Sets) which involve multiple simplicity measures\nutilized together. Given a vector of simplicity measures, an entity is\nassociated not with an individual simplicity value but with a \"simplicity\nbundles\" of Pareto-optimal simplicity-value vectors.\n  CoSMs and CoSMOS are then used as a foundation for a theory of pattern and\nmultipattern, and a theory of hierarchy and heterarchy in systems of patterns.\nA formalization of the cognitive-systems notion of a \"coherent dual network\"\ninterweaving hierarchy and heterarchy in a consistent way is presented.\n  The high level end result of this investigation is to re-envision Occam's\nRazor as something like: When in doubt, prefer hypotheses whose simplicity\nbundles are Pareto optimal, partly because doing so both permits and benefits\nfrom the construction of coherent dual networks comprising coordinated and\nconsistent multipattern hierarchies and heterarchies.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:26:56 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 01:34:38 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2004.05352", "submitter": "Hyunjae Kim", "authors": "Hyunjae Kim, Yookyung Koh, Jinheon Baek, Jaewoo Kang", "title": "Exploring The Spatial Reasoning Ability of Neural Models in Human IQ\n  Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural models have performed impressively well on various tasks such\nas image recognition and question answering, their reasoning ability has been\nmeasured in only few studies. In this work, we focus on spatial reasoning and\nexplore the spatial understanding of neural models. First, we describe the\nfollowing two spatial reasoning IQ tests: rotation and shape composition. Using\nwell-defined rules, we constructed datasets that consist of various complexity\nlevels. We designed a variety of experiments in terms of generalization, and\nevaluated six different baseline models on the newly generated datasets. We\nprovide an analysis of the results and factors that affect the generalization\nabilities of models. Also, we analyze how neural models solve spatial reasoning\ntests with visual aids. Our findings would provide valuable insights into\nunderstanding a machine and the difference between a machine and human.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 09:41:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Kim", "Hyunjae", ""], ["Koh", "Yookyung", ""], ["Baek", "Jinheon", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2004.05380", "submitter": "Fabio Caraffini PhD", "authors": "Johana Florez-Lozano, Fabio Caraffini, Carlos Parra and Mario Gongora", "title": "Training Data Set Assessment for Decision-Making in a Multiagent\n  Landmine Detection Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems such as landmine detection require multiple sources of\ninformation to reduce the uncertainty of decision-making. A novel approach to\nsolve these problems includes distributed systems, as presented in this work\nbased on hardware and software multi-agent systems. To achieve a high rate of\nlandmine detection, we evaluate the performance of a trained system over the\ndistribution of samples between training and validation sets. Additionally, a\ngeneral explanation of the data set is provided, presenting the samples\ngathered by a cooperative multi-agent system developed for detecting improvised\nexplosive devices. The results show that input samples affect the performance\nof the output decisions, and a decision-making system can be less sensitive to\nsensor noise with intelligent systems obtained from a diverse and suitably\norganised training set.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:05:30 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Florez-Lozano", "Johana", ""], ["Caraffini", "Fabio", ""], ["Parra", "Carlos", ""], ["Gongora", "Mario", ""]]}, {"id": "2004.05388", "submitter": "Qian Liu", "authors": "Qian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou, Zixuan Chen, Bin\n  Zhou, Dongmei Zhang", "title": "You Impress Me: Dialogue Generation via Mutual Persona Perception", "comments": "Accepted by ACL 2020, code is avaiable at\n  https://github.com/SivilTaram/Persona-Dialogue-Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the continuing efforts to improve the engagingness and consistency of\nchit-chat dialogue systems, the majority of current work simply focus on\nmimicking human-like responses, leaving understudied the aspects of modeling\nunderstanding between interlocutors. The research in cognitive science,\ninstead, suggests that understanding is an essential signal for a high-quality\nchit-chat conversation. Motivated by this, we propose P^2 Bot, a\ntransmitter-receiver based framework with the aim of explicitly modeling\nunderstanding. Specifically, P^2 Bot incorporates mutual persona perception to\nenhance the quality of personalized dialogue generation. Experiments on a large\npublic dataset, Persona-Chat, demonstrate the effectiveness of our approach,\nwith a considerable boost over the state-of-the-art baselines across both\nautomatic metrics and human evaluations.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:51:07 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Yihong", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Chen", "Zixuan", ""], ["Zhou", "Bin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2004.05417", "submitter": "Warren Powell", "authors": "Kristopher Reyes and Warren B Powell", "title": "Optimal Learning for Sequential Decisions in Laboratory Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of discovery in the physical, biological and medical sciences can\nbe painstakingly slow. Most experiments fail, and the time from initiation of\nresearch until a new advance reaches commercial production can span 20 years.\nThis tutorial is aimed to provide experimental scientists with a foundation in\nthe science of making decisions. Using numerical examples drawn from the\nexperiences of the authors, the article describes the fundamental elements of\nany experimental learning problem. It emphasizes the important role of belief\nmodels, which include not only the best estimate of relationships provided by\nprior research, previous experiments and scientific expertise, but also the\nuncertainty in these relationships. We introduce the concept of a learning\npolicy, and review the major categories of policies. We then introduce a\npolicy, known as the knowledge gradient, that maximizes the value of\ninformation from each experiment. We bring out the importance of reducing\nuncertainty, and illustrate this process for different belief models.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 14:53:29 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 00:54:16 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Reyes", "Kristopher", ""], ["Powell", "Warren B", ""]]}, {"id": "2004.05473", "submitter": "Pablo Lanillos", "authors": "Pablo Lanillos and Jordi Pages and Gordon Cheng", "title": "Robot self/other distinction: active inference meets neural networks\n  learning in a mirror", "comments": "Accepted at European Conference on Artificial Intelligence (ECAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self/other distinction and self-recognition are important skills for\ninteracting with the world, as it allows humans to differentiate own actions\nfrom others and be self-aware. However, only a selected group of animals,\nmainly high order mammals such as humans, has passed the mirror test, a\nbehavioural experiment proposed to assess self-recognition abilities. In this\npaper, we describe self-recognition as a process that is built on top of body\nperception unconscious mechanisms. We present an algorithm that enables a robot\nto perform non-appearance self-recognition on a mirror and distinguish its\nsimple actions from other entities, by answering the following question: am I\ngenerating these sensations? The algorithm combines active inference, a\ntheoretical model of perception and action in the brain, with neural network\nlearning. The robot learns the relation between its actions and its body with\nthe effect produced in the visual field and its body sensors. The prediction\nerror generated between the models and the real observations during the\ninteraction is used to infer the body configuration through free energy\nminimization and to accumulate evidence for recognizing its body. Experimental\nresults on a humanoid robot show the reliability of the algorithm for different\ninitial conditions, such as mirror recognition in any perspective, robot-robot\ndistinction and human-robot differentiation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 19:51:47 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lanillos", "Pablo", ""], ["Pages", "Jordi", ""], ["Cheng", "Gordon", ""]]}, {"id": "2004.05499", "submitter": "Julian Yarkony", "authors": "Naveed Haghani, Claudio Contardo, Julian Yarkony", "title": "Relaxed Dual Optimal Inequalities for Relaxed Columns: with Application\n  to Vehicle Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of accelerating column generation for set cover\nproblems in which we relax the state space of the columns to do efficient\npricing. We achieve this by adapting the recently introduced smooth and\nflexible dual optimal inequalities (DOI) for use with relaxed columns. Smooth\nDOI exploit the observation that similar items are nearly fungible, and hence\nshould be associated with similarly valued dual variables. Flexible DOI exploit\nthe observation that the change in cost of a column induced by removing an item\ncan be bounded. We adapt these DOI to the problem of capacitated vehicle\nrouting in the context of ng-route relaxations. We demonstrate significant\nspeed ups on a benchmark data set, while provably not weakening the relaxation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 22:28:32 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Haghani", "Naveed", ""], ["Contardo", "Claudio", ""], ["Yarkony", "Julian", ""]]}, {"id": "2004.05512", "submitter": "Lisa Torrey", "authors": "Lisa Torrey", "title": "Reinforcement Learning via Reasoning from Demonstration", "comments": "Adaptive and Learning Agents Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demonstration is an appealing way for humans to provide assistance to\nreinforcement-learning agents. Most approaches in this area view demonstrations\nprimarily as sources of behavioral bias. But in sparse-reward tasks, humans\nseem to treat demonstrations more as sources of causal knowledge. This paper\nproposes a framework for agents that benefit from demonstration in this\nhuman-inspired way. In this framework, agents develop causal models through\nobservation, and reason from this knowledge to decompose tasks for effective\nreinforcement learning. Experimental results show that a basic implementation\nof Reasoning from Demonstration (RfD) is effective in a range of sparse-reward\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 00:41:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Torrey", "Lisa", ""]]}, {"id": "2004.05565", "submitter": "Alvin Wan", "authors": "Alvin Wan, Xiaoliang Dai, Peizhao Zhang, Zijian He, Yuandong Tian,\n  Saining Xie, Bichen Wu, Matthew Yu, Tao Xu, Kan Chen, Peter Vajda, Joseph E.\n  Gonzalez", "title": "FBNetV2: Differentiable Neural Architecture Search for Spatial and\n  Channel Dimensions", "comments": "8 pages, 10 figures, accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Neural Architecture Search (DNAS) has demonstrated great\nsuccess in designing state-of-the-art, efficient neural networks. However,\nDARTS-based DNAS's search space is small when compared to other search\nmethods', since all candidate network layers must be explicitly instantiated in\nmemory. To address this bottleneck, we propose a memory and computationally\nefficient DNAS variant: DMaskingNAS. This algorithm expands the search space by\nup to $10^{14}\\times$ over conventional DNAS, supporting searches over spatial\nand channel dimensions that are otherwise prohibitively expensive: input\nresolution and number of filters. We propose a masking mechanism for feature\nmap reuse, so that memory and computational costs stay nearly constant as the\nsearch space expands. Furthermore, we employ effective shape propagation to\nmaximize per-FLOP or per-parameter accuracy. The searched FBNetV2s yield\nstate-of-the-art performance when compared with all previous architectures.\nWith up to 421$\\times$ less search cost, DMaskingNAS finds models with 0.9%\nhigher accuracy, 15% fewer FLOPs than MobileNetV3-Small; and with similar\naccuracy but 20% fewer FLOPs than Efficient-B0. Furthermore, our FBNetV2\noutperforms MobileNetV3 by 2.6% in accuracy, with equivalent model size.\nFBNetV2 models are open-sourced at\nhttps://github.com/facebookresearch/mobile-vision.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 08:52:15 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wan", "Alvin", ""], ["Dai", "Xiaoliang", ""], ["Zhang", "Peizhao", ""], ["He", "Zijian", ""], ["Tian", "Yuandong", ""], ["Xie", "Saining", ""], ["Wu", "Bichen", ""], ["Yu", "Matthew", ""], ["Xu", "Tao", ""], ["Chen", "Kan", ""], ["Vajda", "Peter", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2004.05569", "submitter": "Veronica Latcinnik", "authors": "Veronica Latcinnik, Jonathan Berant", "title": "Explaining Question Answering Models through Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models (LMs) have been shown to perform\nsurprisingly well when fine-tuned on tasks that require commonsense and world\nknowledge. However, in end-to-end architectures, it is difficult to explain\nwhat is the knowledge in the LM that allows it to make a correct prediction. In\nthis work, we propose a model for multi-choice question answering, where a\nLM-based generator generates a textual hypothesis that is later used by a\nclassifier to answer the question. The hypothesis provides a window into the\ninformation used by the fine-tuned LM that can be inspected by humans. A key\nchallenge in this setup is how to constrain the model to generate hypotheses\nthat are meaningful to humans. We tackle this by (a) joint training with a\nsimple similarity classifier that encourages meaningful hypotheses, and (b) by\nadding loss functions that encourage natural text without repetitions. We show\non several tasks that our model reaches performance that is comparable to\nend-to-end architectures, while producing hypotheses that elucidate the\nknowledge used by the LM for answering the question.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 09:06:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Latcinnik", "Veronica", ""], ["Berant", "Jonathan", ""]]}, {"id": "2004.05654", "submitter": "Abhishek Dubey", "authors": "Charles Hartsell and Nagabhushan Mahadevan and Harmon Nine and Ted\n  Bapty and Abhishek Dubey and Gabor Karsai", "title": "Workflow Automation for Cyber Physical System Development Processes", "comments": "Accepted for Publication at DESTION 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of Cyber Physical Systems (CPSs) requires close interaction\nbetween developers with expertise in many domains to achieve ever-increasing\ndemands for improved performance, reduced cost, and more system autonomy. Each\nengineering discipline commonly relies on domain-specific modeling languages,\nand analysis and execution of these models is often automated with appropriate\ntooling. However, integration between these heterogeneous models and tools is\noften lacking, and most of the burden for inter-operation of these tools is\nplaced on system developers. To address this problem, we introduce a workflow\nmodeling language for the automation of complex CPS development processes and\nimplement a platform for execution of these models in the Assurance-based\nLearning-enabled CPS (ALC) Toolchain. Several illustrative examples are\nprovided which show how these workflow models are able to automate many\ntime-consuming integration tasks previously performed manually by system\ndevelopers.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 17:32:05 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Hartsell", "Charles", ""], ["Mahadevan", "Nagabhushan", ""], ["Nine", "Harmon", ""], ["Bapty", "Ted", ""], ["Dubey", "Abhishek", ""], ["Karsai", "Gabor", ""]]}, {"id": "2004.05704", "submitter": "Robik Shrestha", "authors": "Robik Shrestha, Kushal Kafle, Christopher Kanan", "title": "A negative case analysis of visual grounding methods for VQA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Visual Question Answering (VQA) methods tend to exploit dataset\nbiases and spurious statistical correlations, instead of producing right\nanswers for the right reasons. To address this issue, recent bias mitigation\nmethods for VQA propose to incorporate visual cues (e.g., human attention maps)\nto better ground the VQA models, showcasing impressive gains. However, we show\nthat the performance improvements are not a result of improved visual\ngrounding, but a regularization effect which prevents over-fitting to\nlinguistic priors. For instance, we find that it is not actually necessary to\nprovide proper, human-based cues; random, insensible cues also result in\nsimilar improvements. Based on this observation, we propose a simpler\nregularization scheme that does not require any external annotations and yet\nachieves near state-of-the-art performance on VQA-CPv2.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 21:45:23 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 17:38:04 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Shrestha", "Robik", ""], ["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "2004.05722", "submitter": "Weiyuan Wu", "authors": "Weiyuan Wu, Lampros Flokas, Eugene Wu, Jiannan Wang", "title": "Complaint-driven Training Data Debugging for Query 2.0", "comments": "Proceedings of the 2020 ACM SIGMOD International Conference on\n  Management of Data", "journal-ref": null, "doi": "10.1145/3318464.3389696", "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the need for machine learning (ML) increases rapidly across all industry\nsectors, there is a significant interest among commercial database providers to\nsupport \"Query 2.0\", which integrates model inference into SQL queries.\nDebugging Query 2.0 is very challenging since an unexpected query result may be\ncaused by the bugs in training data (e.g., wrong labels, corrupted features).\nIn response, we propose Rain, a complaint-driven training data debugging\nsystem. Rain allows users to specify complaints over the query's intermediate\nor final output, and aims to return a minimum set of training examples so that\nif they were removed, the complaints would be resolved. To the best of our\nknowledge, we are the first to study this problem. A naive solution requires\nretraining an exponential number of ML models. We propose two novel heuristic\napproaches based on influence functions which both require linear retraining\nsteps. We provide an in-depth analytical and empirical analysis of the two\napproaches and conduct extensive experiments to evaluate their effectiveness\nusing four real-world datasets. Results show that Rain achieves the highest\nrecall@k among all the baselines while still returns results interactively.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:56:06 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wu", "Weiyuan", ""], ["Flokas", "Lampros", ""], ["Wu", "Eugene", ""], ["Wang", "Jiannan", ""]]}, {"id": "2004.05764", "submitter": "Kaijie Xu", "authors": "Kaijie Xu, Witold Pedrycz, Zhiwu Li", "title": "Augmentation of the Reconstruction Performance of Fuzzy C-Means with an\n  Optimized Fuzzification Factor Vector", "comments": null, "journal-ref": null, "doi": null, "report-no": "TFS-2019-1068", "categories": "cs.AI cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information granules have been considered to be the fundamental constructs of\nGranular Computing (GrC). As a useful unsupervised learning technique, Fuzzy\nC-Means (FCM) is one of the most frequently used methods to construct\ninformation granules. The FCM-based granulation-degranulation mechanism plays a\npivotal role in GrC. In this paper, to enhance the quality of the degranulation\n(reconstruction) process, we augment the FCM-based degranulation mechanism by\nintroducing a vector of fuzzification factors (fuzzification factor vector) and\nsetting up an adjustment mechanism to modify the prototypes and the partition\nmatrix. The design is regarded as an optimization problem, which is guided by a\nreconstruction criterion. In the proposed scheme, the initial partition matrix\nand prototypes are generated by the FCM. Then a fuzzification factor vector is\nintroduced to form an appropriate fuzzification factor for each cluster to\nbuild up an adjustment scheme of modifying the prototypes and the partition\nmatrix. With the supervised learning mode of the granulation-degranulation\nprocess, we construct a composite objective function of the fuzzification\nfactor vector, the prototypes and the partition matrix. Subsequently, the\nparticle swarm optimization (PSO) is employed to optimize the fuzzification\nfactor vector to refine the prototypes and develop the optimal partition\nmatrix. Finally, the reconstruction performance of the FCM algorithm is\nenhanced. We offer a thorough analysis of the developed scheme. In particular,\nwe show that the classical FCM algorithm forms a special case of the proposed\nscheme. Experiments completed for both synthetic and publicly available\ndatasets show that the proposed approach outperforms the generic data\nreconstruction approach.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 04:17:30 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Xu", "Kaijie", ""], ["Pedrycz", "Witold", ""], ["Li", "Zhiwu", ""]]}, {"id": "2004.05773", "submitter": "Isabelle Augenstein", "authors": "Pepa Atanasova and Jakob Grue Simonsen and Christina Lioma and\n  Isabelle Augenstein", "title": "Generating Fact Checking Explanations", "comments": "In Proceedings of the 2020 Annual Conference of the Association for\n  Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing work on automated fact checking is concerned with predicting\nthe veracity of claims based on metadata, social network spread, language used\nin claims, and, more recently, evidence supporting or denying claims. A crucial\npiece of the puzzle that is still missing is to understand how to automate the\nmost elaborate part of the process -- generating justifications for verdicts on\nclaims. This paper provides the first study of how these explanations can be\ngenerated automatically based on available claim context, and how this task can\nbe modelled jointly with veracity prediction. Our results indicate that\noptimising both objectives at the same time, rather than training them\nseparately, improves the performance of a fact checking system. The results of\na manual evaluation further suggest that the informativeness, coverage and\noverall quality of the generated explanations are also improved in the\nmulti-task model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 05:23:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Atanasova", "Pepa", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2004.05802", "submitter": "Hans van Ditmarsch", "authors": "Hans van Ditmarsch", "title": "To Be Announced", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this survey we review dynamic epistemic logics with modalities for\nquantification over information change. Of such logics we present complete\naxiomatizations, focussing on axioms involving the interaction between\nknowledge and such quantifiers, we report on their relative expressivity, on\ndecidability and on the complexity of model checking and satisfiability, and on\napplications. We focus on open problems and new directions for research.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:34:02 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 18:11:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["van Ditmarsch", "Hans", ""]]}, {"id": "2004.05812", "submitter": "Shuangyong Song", "authors": "Shuangyong Song, Chao Wang, Qianqian Xie, Xinxing Zu, Huan Chen,\n  Haiqing Chen", "title": "MLR: A Two-stage Conversational Query Rewriting Model with Multi-task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational context understanding aims to recognize the real intention of\nuser from the conversation history, which is critical for building the dialogue\nsystem. However, the multi-turn conversation understanding in open domain is\nstill quite challenging, which requires the system extracting the important\ninformation and resolving the dependencies in contexts among a variety of open\ntopics. In this paper, we propose the conversational query rewriting model -\nMLR, which is a Multi-task model on sequence Labeling and query Rewriting. MLR\nreformulates the multi-turn conversational queries into a single turn query,\nwhich conveys the true intention of users concisely and alleviates the\ndifficulty of the multi-turn dialogue modeling. In the model, we formulate the\nquery rewriting as a sequence generation problem and introduce word category\ninformation via the auxiliary word category label predicting task. To train our\nmodel, we construct a new Chinese query rewriting dataset and conduct\nexperiments on it. The experimental results show that our model outperforms\ncompared models, and prove the effectiveness of the word category information\nin improving the rewriting performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:04:49 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Song", "Shuangyong", ""], ["Wang", "Chao", ""], ["Xie", "Qianqian", ""], ["Zu", "Xinxing", ""], ["Chen", "Huan", ""], ["Chen", "Haiqing", ""]]}, {"id": "2004.05827", "submitter": "Shuyang Gao", "authors": "Shuyang Gao, Sanchit Agarwal, Tagyoung Chung, Di Jin, Dilek\n  Hakkani-Tur", "title": "From Machine Reading Comprehension to Dialogue State Tracking: Bridging\n  the Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking (DST) is at the heart of task-oriented dialogue\nsystems. However, the scarcity of labeled data is an obstacle to building\naccurate and robust state tracking systems that work across a variety of\ndomains. Existing approaches generally require some dialogue data with state\ninformation and their ability to generalize to unknown domains is limited. In\nthis paper, we propose using machine reading comprehension (RC) in state\ntracking from two perspectives: model architectures and datasets. We divide the\nslot types in dialogue state into categorical or extractive to borrow the\nadvantages from both multiple-choice and span-based reading comprehension\nmodels. Our method achieves near the current state-of-the-art in joint goal\naccuracy on MultiWOZ 2.1 given full training data. More importantly, by\nleveraging machine reading comprehension datasets, our method outperforms the\nexisting approaches by many a large margin in few-shot scenarios when the\navailability of in-domain data is limited. Lastly, even without any state\ntracking data, i.e., zero-shot scenario, our proposed approach achieves greater\nthan 90% average slot accuracy in 12 out of 30 slots in MultiWOZ 2.1.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:00:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gao", "Shuyang", ""], ["Agarwal", "Sanchit", ""], ["Chung", "Tagyoung", ""], ["Jin", "Di", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2004.05886", "submitter": "Sao Mai Nguyen", "authors": "Sao Mai Nguyen, Nathalie Collot-Lavenne (CHU - BREST), Christophe Lohr\n  (INFO), S\\'ebastien Guillon (IMT Atlantique), Patricio Tula (IMT Atlantique),\n  Alvaro Paez (IMT Atlantique), Mouad Bouaida (IMT Atlantique), Arthus Anin\n  (IMT Atlantique), Saad El Qacemi (IMT Atlantique)", "title": "An implementation of an imitation game with ASD children to learn\n  nursery rhymes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have suggested that being imitated by an adult is an\neffective intervention with children with autism and developmental delay. The\npurpose of this study is to investigate if an imitation game with a robot can\narise interest from children and constitute an effective tool to be used in\nclinical activities. In this paper, we describe the design of our nursery rhyme\nimitation game, its implementation based on RGB image pose recognition and the\npreliminary tests we performed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 06:50:35 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Nguyen", "Sao Mai", "", "CHU - BREST"], ["Collot-Lavenne", "Nathalie", "", "CHU - BREST"], ["Lohr", "Christophe", "", "INFO"], ["Guillon", "S\u00e9bastien", "", "IMT Atlantique"], ["Tula", "Patricio", "", "IMT Atlantique"], ["Paez", "Alvaro", "", "IMT Atlantique"], ["Bouaida", "Mouad", "", "IMT Atlantique"], ["Anin", "Arthus", "", "IMT Atlantique"], ["Qacemi", "Saad El", "", "IMT Atlantique"]]}, {"id": "2004.05915", "submitter": "Navid Khoshavi", "authors": "Navid Khoshavi, Connor Broyles, and Yu Bi", "title": "A Survey on Impact of Transient Faults on BNN Inference Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over past years, the philosophy for designing the artificial intelligence\nalgorithms has significantly shifted towards automatically extracting the\ncomposable systems from massive data volumes. This paradigm shift has been\nexpedited by the big data booming which enables us to easily access and analyze\nthe highly large data sets. The most well-known class of big data analysis\ntechniques is called deep learning. These models require significant\ncomputation power and extremely high memory accesses which necessitate the\ndesign of novel approaches to reduce the memory access and improve power\nefficiency while taking into account the development of domain-specific\nhardware accelerators to support the current and future data sizes and model\nstructures.The current trends for designing application-specific integrated\ncircuits barely consider the essential requirement for maintaining the complex\nneural network computation to be resilient in the presence of soft errors. The\nsoft errors might strike either memory storage or combinational logic in the\nhardware accelerator that can affect the architectural behavior such that the\nprecision of the results fall behind the minimum allowable correctness. In this\nstudy, we demonstrate that the impact of soft errors on a customized deep\nlearning algorithm called Binarized Neural Network might cause drastic image\nmisclassification. Our experimental results show that the accuracy of image\nclassifier can drastically drop by 76.70% and 19.25% in lfcW1A1 and cnvW1A1\nnetworks,respectively across CIFAR-10 and MNIST datasets during the fault\ninjection for the worst-case scenarios\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:15:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Khoshavi", "Navid", ""], ["Broyles", "Connor", ""], ["Bi", "Yu", ""]]}, {"id": "2004.05920", "submitter": "Tatiana Urazaeva", "authors": "Tatiana Urazaeva", "title": "Game-theoretic applications of a relational risk model", "comments": "14 pages, 5 figures, 18 bibliographic links", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The report suggests the concept of risk, outlining two mathematical\nstructures necessary for risk genesis: the set of outcomes and, in a general\ncase, partial order of preference on it. It is shown that this minimum partial\norder should constitute the structure of a semilattice. In some cases, there\nshould be a system of semilattices nested in a certain way. On this basis, the\nclassification of risk theory tasks is given in the context of specialization\nof mathematical knowledge. In other words, we are talking about the development\nof a new rela-tional risk theory. The problem of political decision making in\ngame-theoretic formulation in terms of having partial order of preference on\nthe set of outcomes for each par-ticipant of the game forming a certain system\nof nested semilattices is consid-ered as an example of a relational risk\nconcept implementation. Solutions to the problem obtained through the use of\nvarious optimality principles are investi-gated.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 18:54:58 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Urazaeva", "Tatiana", ""]]}, {"id": "2004.05930", "submitter": "Francesco Conti", "authors": "Francesco Conti", "title": "Technical Report: NEMO DNN Quantization for Deployment Model", "comments": "12 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report aims at defining a formal framework for Deep Neural\nNetwork (DNN) layer-wise quantization, focusing in particular on the problems\nrelated to the final deployment. It also acts as a documentation for the NEMO\n(NEural Minimization for pytOrch) framework. It describes the four DNN\nrepresentations used in NEMO (FullPrecision, FakeQuantized, QuantizedDeployable\nand IntegerDeployable), focusing in particular on a formal definition of the\nlatter two. An important feature of this model, and in particular the\nIntegerDeployable representation, is that it enables DNN inference using purely\nintegers - without resorting to real-valued numbers in any part of the\ncomputation and without relying on an explicit fixed-point numerical\nrepresentation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:23:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Conti", "Francesco", ""]]}, {"id": "2004.05937", "submitter": "Lin Wang", "authors": "Lin Wang and Kuk-Jin Yoon", "title": "Knowledge Distillation and Student-Teacher Learning for Visual\n  Intelligence: A Review and New Outlooks", "comments": "Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence(TPAMI),2021. Some references are updated in this version", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3055564", "report-no": "https://ieeexplore.ieee.org/document/9340578", "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural models in recent years have been successful in almost every\nfield, including extremely complex problem statements. However, these models\nare huge in size, with millions (and even billions) of parameters, thus\ndemanding more heavy computation power and failing to be deployed on edge\ndevices. Besides, the performance boost is highly dependent on redundant\nlabeled data. To achieve faster speeds and to handle the problems caused by the\nlack of data, knowledge distillation (KD) has been proposed to transfer\ninformation learned from one model to another. KD is often characterized by the\nso-called `Student-Teacher' (S-T) learning framework and has been broadly\napplied in model compression and knowledge transfer. This paper is about KD and\nS-T learning, which are being actively studied in recent years. First, we aim\nto provide explanations of what KD is and how/why it works. Then, we provide a\ncomprehensive survey on the recent progress of KD methods together with S-T\nframeworks typically for vision tasks. In general, we consider some fundamental\nquestions that have been driving this research area and thoroughly generalize\nthe research progress and technical details. Additionally, we systematically\nanalyze the research status of KD in vision applications. Finally, we discuss\nthe potentials and open challenges of existing methods and prospect the future\ndirections of KD and S-T learning.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:45:38 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 06:53:08 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 01:27:02 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 13:33:33 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 08:16:08 GMT"}, {"version": "v6", "created": "Mon, 25 Jan 2021 12:37:46 GMT"}, {"version": "v7", "created": "Thu, 17 Jun 2021 07:17:50 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Lin", ""], ["Yoon", "Kuk-Jin", ""]]}, {"id": "2004.05940", "submitter": "Ioannis Boukas", "authors": "Ioannis Boukas, Damien Ernst, Thibaut Th\\'eate, Adrien Bolland,\n  Alexandre Huynen, Martin Buchwald, Christelle Wynants, Bertrand Corn\\'elusse", "title": "A Deep Reinforcement Learning Framework for Continuous Intraday Market\n  Bidding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large integration of variable energy resources is expected to shift a\nlarge part of the energy exchanges closer to real-time, where more accurate\nforecasts are available. In this context, the short-term electricity markets\nand in particular the intraday market are considered a suitable trading floor\nfor these exchanges to occur. A key component for the successful renewable\nenergy sources integration is the usage of energy storage. In this paper, we\npropose a novel modelling framework for the strategic participation of energy\nstorage in the European continuous intraday market where exchanges occur\nthrough a centralized order book. The goal of the storage device operator is\nthe maximization of the profits received over the entire trading horizon, while\ntaking into account the operational constraints of the unit. The sequential\ndecision-making problem of trading in the intraday market is modelled as a\nMarkov Decision Process. An asynchronous distributed version of the fitted Q\niteration algorithm is chosen for solving this problem due to its sample\nefficiency. The large and variable number of the existing orders in the order\nbook motivates the use of high-level actions and an alternative state\nrepresentation. Historical data are used for the generation of a large number\nof artificial trajectories in order to address exploration issues during the\nlearning process. The resulting policy is back-tested and compared against a\nbenchmark strategy that is the current industrial standard. Results indicate\nthat the agent converges to a policy that achieves in average higher total\nrevenues than the benchmark strategy.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:50:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Boukas", "Ioannis", ""], ["Ernst", "Damien", ""], ["Th\u00e9ate", "Thibaut", ""], ["Bolland", "Adrien", ""], ["Huynen", "Alexandre", ""], ["Buchwald", "Martin", ""], ["Wynants", "Christelle", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "2004.05966", "submitter": "Sibo Zhang", "authors": "Sibo Zhang, Yuexin Ma, Ruigang Yang", "title": "CVPR 2019 WAD Challenge on Trajectory Prediction and 3D Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the CVPR 2019 challenge on Autonomous Driving. Baidu's\nRobotics and Autonomous Driving Lab (RAL) providing 150 minutes labeled\nTrajectory and 3D Perception dataset including about 80k lidar point cloud and\n1000km trajectories for urban traffic. The challenge has two tasks in (1)\nTrajectory Prediction and (2) 3D Lidar Object Detection. There are more than\n200 teams submitted results on Leaderboard and more than 1000 participants\nattended the workshop.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 06:36:33 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 22:24:03 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Sibo", ""], ["Ma", "Yuexin", ""], ["Yang", "Ruigang", ""]]}, {"id": "2004.06040", "submitter": "Eric Jones", "authors": "Eric B. Jones, Peter Graf, Eliot Kapit and Wesley Jones", "title": "K-spin Hamiltonian for quantum-resolvable Markov decision processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Markov decision process is the mathematical formalization underlying the\nmodern field of reinforcement learning when transition and reward functions are\nunknown. We derive a pseudo-Boolean cost function that is equivalent to a\nK-spin Hamiltonian representation of the discrete, finite, discounted Markov\ndecision process with infinite horizon. This K-spin Hamiltonian furnishes a\nstarting point from which to solve for an optimal policy using heuristic\nquantum algorithms such as adiabatic quantum annealing and the quantum\napproximate optimization algorithm on near-term quantum hardware. In proving\nthat the variational minimization of our Hamiltonian is equivalent to the\nBellman optimality condition we establish an interesting analogy with classical\nfield theory. Along with proof-of-concept calculations to corroborate our\nformulation by simulated and quantum annealing against classical Q-Learning, we\nanalyze the scaling of physical resources required to solve our Hamiltonian on\nquantum hardware.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:15:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Jones", "Eric B.", ""], ["Graf", "Peter", ""], ["Kapit", "Eliot", ""], ["Jones", "Wesley", ""]]}, {"id": "2004.06063", "submitter": "Markus Freitag", "authors": "Markus Freitag, David Grangier, Isaac Caswell", "title": "BLEU might be Guilty but References are not Innocent", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of automatic metrics for machine translation has been\nincreasingly called into question, especially for high-quality systems. This\npaper demonstrates that, while choice of metric is important, the nature of the\nreferences is also critical. We study different methods to collect references\nand compare their value in automated evaluation by reporting correlation with\nhuman evaluation for a variety of systems and metrics. Motivated by the finding\nthat typical references exhibit poor diversity, concentrating around\ntranslationese language, we develop a paraphrasing task for linguists to\nperform on existing reference translations, which counteracts this bias. Our\nmethod yields higher correlation with human judgment not only for the\nsubmissions of WMT 2019 English to German, but also for Back-translation and\nAPE augmented MT output, which have been shown to have low correlation with\nautomatic metrics using standard references. We demonstrate that our\nmethodology improves correlation with all modern evaluation metrics we look at,\nincluding embedding-based methods. To complete this picture, we reveal that\nmulti-reference BLEU does not improve the correlation for high quality output,\nand present an alternative multi-reference formulation that is more effective.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:49:09 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 13:02:12 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Freitag", "Markus", ""], ["Grangier", "David", ""], ["Caswell", "Isaac", ""]]}, {"id": "2004.06076", "submitter": "Adyasha Maharana", "authors": "Adyasha Maharana, Mohit Bansal", "title": "Adversarial Augmentation Policy Search for Domain and Cross-Lingual\n  Generalization in Reading Comprehension", "comments": "Findings of EMNLP, 2020 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension models often overfit to nuances of training datasets\nand fail at adversarial evaluation. Training with adversarially augmented\ndataset improves robustness against those adversarial attacks but hurts\ngeneralization of the models. In this work, we present several effective\nadversaries and automated data augmentation policy search methods with the goal\nof making reading comprehension models more robust to adversarial evaluation,\nbut also improving generalization to the source domain as well as new domains\nand languages. We first propose three new methods for generating QA\nadversaries, that introduce multiple points of confusion within the context,\nshow dependence on insertion location of the distractor, and reveal the\ncompounding effect of mixing adversarial strategies with syntactic and semantic\nparaphrasing methods. Next, we find that augmenting the training datasets with\nuniformly sampled adversaries improves robustness to the adversarial attacks\nbut leads to decline in performance on the original unaugmented dataset. We\naddress this issue via RL and more efficient Bayesian policy search methods for\nautomatically learning the best augmentation policy combinations of the\ntransformation probability for each adversary in a large search space. Using\nthese learned policies, we show that adversarial training can lead to\nsignificant improvements in in-domain, out-of-domain, and cross-lingual\n(German, Russian, Turkish) generalization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:20:08 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 15:30:48 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 01:38:28 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 16:43:56 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Maharana", "Adyasha", ""], ["Bansal", "Mohit", ""]]}, {"id": "2004.06089", "submitter": "Ted Xiao", "authors": "Ted Xiao, Eric Jang, Dmitry Kalashnikov, Sergey Levine, Julian Ibarz,\n  Karol Hausman, Alexander Herzog", "title": "Thinking While Moving: Deep Reinforcement Learning with Concurrent\n  Control", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study reinforcement learning in settings where sampling an action from the\npolicy must be done concurrently with the time evolution of the controlled\nsystem, such as when a robot must decide on the next action while still\nperforming the previous action. Much like a person or an animal, the robot must\nthink and move at the same time, deciding on its next action before the\nprevious one has completed. In order to develop an algorithmic framework for\nsuch concurrent control problems, we start with a continuous-time formulation\nof the Bellman equations, and then discretize them in a way that is aware of\nsystem delays. We instantiate this new class of approximate dynamic programming\nmethods via a simple architectural extension to existing value-based deep\nreinforcement learning algorithms. We evaluate our methods on simulated\nbenchmark tasks and a large-scale robotic grasping task where the robot must\n\"think while moving\".\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:49:29 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:31:07 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 23:22:39 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 21:19:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xiao", "Ted", ""], ["Jang", "Eric", ""], ["Kalashnikov", "Dmitry", ""], ["Levine", "Sergey", ""], ["Ibarz", "Julian", ""], ["Hausman", "Karol", ""], ["Herzog", "Alexander", ""]]}, {"id": "2004.06213", "submitter": "Nibraas Khan", "authors": "Nibraas Khan and Joshua Phillips", "title": "Combined Model for Partially-Observable and Non-Observable Task\n  Switching: Solving Hierarchical Reinforcement Learning Problems Statically\n  and Dynamically with Transfer Learning", "comments": "substantial text overlap with arXiv:1911.10425 which is the same as\n  this paper. It was meant to be a revision of that paper, but I mistakenly\n  submitted it as a new paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integral function of fully autonomous robots and humans is the ability to\nfocus attention on a few relevant percepts to reach a certain goal while\ndisregarding irrelevant percepts. Humans and animals rely on the interactions\nbetween the Pre-Frontal Cortex (PFC) and the Basal Ganglia (BG) to achieve this\nfocus called Working Memory (WM). The Working Memory Toolkit (WMtk) was\ndeveloped based on a computational neuroscience model of this phenomenon with\nTemporal Difference (TD) Learning for autonomous systems. Recent adaptations of\nthe toolkit either utilize Abstract Task Representations (ATRs) to solve\nNon-Observable (NO) tasks or storage of past input features to solve\nPartially-Observable (PO) tasks, but not both. We propose a new model,\nPONOWMtk, which combines both approaches, ATRs and input storage, with a static\nor dynamic number of ATRs. The results of our experiments show that PONOWMtk\nperforms effectively for tasks that exhibit PO, NO, or both properties.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 21:44:54 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 18:45:51 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Khan", "Nibraas", ""], ["Phillips", "Joshua", ""]]}, {"id": "2004.06223", "submitter": "Guilherme Ramos", "authors": "Joao Saude and Guilherme Ramos and Ludovico Boratto and Carlos Caleiro", "title": "A Robust Reputation-based Group Ranking System and its Resistance to\n  Bribery", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of online reviews and opinions and its growing influence on\npeople's behavior and decisions, boosted the interest to extract meaningful\ninformation from this data deluge. Hence, crowdsourced ratings of products and\nservices gained a critical role in business and governments. Current\nstate-of-the-art solutions rank the items with an average of the ratings\nexpressed for an item, with a consequent lack of personalization for the users,\nand the exposure to attacks and spamming/spurious users. Using these ratings to\ngroup users with similar preferences might be useful to present users with\nitems that reflect their preferences and overcome those vulnerabilities. In\nthis paper, we propose a new reputation-based ranking system, utilizing\nmultipartite rating subnetworks, which clusters users by their similarities\nusing three measures, two of them based on Kolmogorov complexity. We also study\nits resistance to bribery and how to design optimal bribing strategies. Our\nsystem is novel in that it reflects the diversity of preferences by (possibly)\nassigning distinct rankings to the same item, for different groups of users. We\nprove the convergence and efficiency of the system. By testing it on synthetic\nand real data, we see that it copes better with spamming/spurious users, being\nmore robust to attacks than state-of-the-art approaches. Also, by clustering\nusers, the effect of bribery in the proposed multipartite ranking system is\ndimmed, comparing to the bipartite case.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 22:28:29 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 14:00:45 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Saude", "Joao", ""], ["Ramos", "Guilherme", ""], ["Boratto", "Ludovico", ""], ["Caleiro", "Carlos", ""]]}, {"id": "2004.06353", "submitter": "Lu Yin", "authors": "Lu Yin, Vlado Menkovski, Mykola Pechenizkiy", "title": "Knowledge Elicitation using Deep Metric Learning and Psychometric\n  Testing", "comments": "16 pages, 11 figures", "journal-ref": "Machine Learning and Knowledge Discovery in Databases: European\n  Conference, ECML PKDD 2020", "doi": "10.1007/978-3-030-67661-2_10", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge present in a domain is well expressed as relationships between\ncorresponding concepts. For example, in zoology, animal species form complex\nhierarchies; in genomics, the different (parts of) molecules are organized in\ngroups and subgroups based on their functions; plants, molecules, and\nastronomical objects all form complex taxonomies. Nevertheless, when applying\nsupervised machine learning (ML) in such domains, we commonly reduce the\ncomplex and rich knowledge to a fixed set of labels, and induce a model shows\ngood generalization performance with respect to these labels. The main reason\nfor such a reductionist approach is the difficulty in eliciting the domain\nknowledge from the experts. Developing a label structure with sufficient\nfidelity and providing comprehensive multi-label annotation can be exceedingly\nlabor-intensive in many real-world applications. In this paper, we provide a\nmethod for efficient hierarchical knowledge elicitation (HKE) from experts\nworking with high-dimensional data such as images or videos. Our method is\nbased on psychometric testing and active deep metric learning. The developed\nmodels embed the high-dimensional data in a metric space where distances are\nsemantically meaningful, and the data can be organized in a hierarchical\nstructure. We provide empirical evidence with a series of experiments on a\nsynthetically generated dataset of simple shapes, and Cifar 10 and\nFashion-MNIST benchmarks that our method is indeed successful in uncovering\nhierarchical structures.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 08:33:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yin", "Lu", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2004.06518", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Mojtaba Heidarysafa, Tolu Odukoya, Philip Potter,\n  Laura E. Barnes, Donald E. Brown", "title": "Gender Detection on Social Networks using Ensemble Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-63128-4_26", "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the ever-increasing volume of posts on social media sites such as\nFacebook and Twitter requires improved information processing methods for\nprofiling authorship. Document classification is central to this task, but the\nperformance of traditional supervised classifiers has degraded as the volume of\nsocial media has increased. This paper addresses this problem in the context of\ngender detection through ensemble classification that employs multi-model deep\nlearning architectures to generate specialized understanding from different\nfeature spaces.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:08:49 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 17:25:00 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 21:54:34 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kowsari", "Kamran", ""], ["Heidarysafa", "Mojtaba", ""], ["Odukoya", "Tolu", ""], ["Potter", "Philip", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "2004.06519", "submitter": "Federico Bianchi", "authors": "Federico Bianchi and Valerio Di Carlo and Paolo Nicoli and Matteo\n  Palmonari", "title": "Compass-aligned Distributional Embeddings for Studying Semantic\n  Differences across Corpora", "comments": "arXiv admin note: text overlap with arXiv:1906.02376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2vec is one of the most used algorithms to generate word embeddings\nbecause of a good mix of efficiency, quality of the generated representations\nand cognitive grounding. However, word meaning is not static and depends on the\ncontext in which words are used. Differences in word meaning that depends on\ntime, location, topic, and other factors, can be studied by analyzing\nembeddings generated from different corpora in collections that are\nrepresentative of these factors. For example, language evolution can be studied\nusing a collection of news articles published in different time periods. In\nthis paper, we present a general framework to support cross-corpora language\nstudies with word embeddings, where embeddings generated from different corpora\ncan be compared to find correspondences and differences in meaning across the\ncorpora. CADE is the core component of our framework and solves the key problem\nof aligning the embeddings generated from different corpora. In particular, we\nfocus on providing solid evidence about the effectiveness, generality, and\nrobustness of CADE. To this end, we conduct quantitative and qualitative\nexperiments in different domains, from temporal word embeddings to language\nlocalization and topical analysis. The results of our experiments suggest that\nCADE achieves state-of-the-art or superior performance on tasks where several\ncompeting approaches are available, yet providing a general method that can be\nused in a variety of domains. Finally, our experiments shed light on the\nconditions under which the alignment is reliable, which substantially depends\non the degree of cross-corpora vocabulary overlap.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:46:47 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Bianchi", "Federico", ""], ["Di Carlo", "Valerio", ""], ["Nicoli", "Paolo", ""], ["Palmonari", "Matteo", ""]]}, {"id": "2004.06559", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Aritz D. Martinez, Akemi Galvez, Andres Iglesias, Javier\n  Del Ser", "title": "dMFEA-II: An Adaptive Multifactorial Evolutionary Algorithm for\n  Permutation-based Discrete Optimization Problems", "comments": "7 pages, 0 figures, Camera-ready version of the paper accepted for\n  presentation in The Genetic and Evolutionary Computation Conference 2020\n  (GECCO 2020)", "journal-ref": null, "doi": "10.1145/3377929.3398084", "report-no": null, "categories": "cs.AI cs.DM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging research paradigm coined as multitasking optimization aims to\nsolve multiple optimization tasks concurrently by means of a single search\nprocess. For this purpose, the exploitation of complementarities among the\ntasks to be solved is crucial, which is often achieved via the transfer of\ngenetic material, thereby forging the Transfer Optimization field. In this\ncontext, Evolutionary Multitasking addresses this paradigm by resorting to\nconcepts from Evolutionary Computation. Within this specific branch, approaches\nsuch as the Multifactorial Evolutionary Algorithm (MFEA) has lately gained a\nnotable momentum when tackling multiple optimization tasks. This work\ncontributes to this trend by proposing the first adaptation of the recently\nintroduced Multifactorial Evolutionary Algorithm II (MFEA-II) to\npermutation-based discrete optimization environments. For modeling this\nadaptation, some concepts cannot be directly applied to discrete search spaces,\nsuch as parent-centric interactions. In this paper we entirely reformulate such\nconcepts, making them suited to deal with permutation-based search spaces\nwithout loosing the inherent benefits of MFEA-II. The performance of the\nproposed solver has been assessed over 5 different multitasking setups,\ncomposed by 8 datasets of the well-known Traveling Salesman (TSP) and\nCapacitated Vehicle Routing Problems (CVRP). The obtained results and their\ncomparison to those by the discrete version of the MFEA confirm the good\nperformance of the developed dMFEA-II, and concur with the insights drawn in\nprevious studies for continuous optimization.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:42:47 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 14:28:56 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 15:35:08 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Galvez", "Akemi", ""], ["Iglesias", "Andres", ""], ["Del Ser", "Javier", ""]]}, {"id": "2004.06564", "submitter": "Yali Wang", "authors": "Yali Wang, Bas van Stein, Michael T.M. Emmerich, Thomas B\\\"ack", "title": "A Tailored NSGA-III Instantiation for Flexible Job Shop Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A customized multi-objective evolutionary algorithm (MOEA) is proposed for\nthe multi-objective flexible job shop scheduling problem (FJSP). It uses smart\ninitialization approaches to enrich the first generated population, and\nproposes various crossover operators to create a better diversity of offspring.\nEspecially, the MIP-EGO configurator, which can tune algorithm parameters, is\nadopted to automatically tune operator probabilities. Furthermore, different\nlocal search strategies are employed to explore the neighborhood for better\nsolutions. In general, the algorithm enhancement strategy can be integrated\nwith any standard EMO algorithm. In this paper, it has been combined with\nNSGA-III to solve benchmark multi-objective FJSPs, whereas an off-the-shelf\nimplementation of NSGA-III is not capable of solving the FJSP. The experimental\nresults show excellent performance with less computing budget.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:49:36 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Wang", "Yali", ""], ["van Stein", "Bas", ""], ["Emmerich", "Michael T. M.", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2004.06581", "submitter": "Elena Guti\\'errez Viedma", "authors": "Elena Guti\\'errez, Takamasa Okudono, Masaki Waga, Ichiro Hasuo", "title": "Genetic Algorithm for the Weight Maximization Problem on Weighted\n  Automata", "comments": "Accepted at GECCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weight maximization problem (WMP) is the problem of finding the word of\nhighest weight on a weighted finite state automaton (WFA). It is an essential\nquestion that emerges in many optimization problems in automata theory.\nUnfortunately, the general problem can be shown to be undecidable, whereas its\nbounded decisional version is NP-complete. Designing efficient algorithms that\nproduce approximate solutions to the WMP in reasonable time is an appealing\nresearch direction that can lead to several new applications including formal\nverification of systems abstracted as WFAs. In particular, in combination with\na recent procedure that translates a recurrent neural network into a weighted\nautomaton, an algorithm for the WMP can be used to analyze and verify the\nnetwork by exploiting the simpler and more compact automata model. In this\nwork, we propose, implement and evaluate a metaheuristic based on genetic\nalgorithms to approximate solutions to the WMP. We experimentally evaluate its\nperformance on examples from the literature and show its potential on different\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 09:30:11 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Guti\u00e9rrez", "Elena", ""], ["Okudono", "Takamasa", ""], ["Waga", "Masaki", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "2004.06627", "submitter": "Thibaut Theate", "authors": "Thibaut Th\\'eate, Damien Ernst", "title": "An Application of Deep Reinforcement Learning to Algorithmic Trading", "comments": "Preprint submitted to Elsevier journal \"Expert Systems with\n  Applications\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This scientific research paper presents an innovative approach based on deep\nreinforcement learning (DRL) to solve the algorithmic trading problem of\ndetermining the optimal trading position at any point in time during a trading\nactivity in stock markets. It proposes a novel DRL trading strategy so as to\nmaximise the resulting Sharpe ratio performance indicator on a broad range of\nstock markets. Denominated the Trading Deep Q-Network algorithm (TDQN), this\nnew trading strategy is inspired from the popular DQN algorithm and\nsignificantly adapted to the specific algorithmic trading problem at hand. The\ntraining of the resulting reinforcement learning (RL) agent is entirely based\non the generation of artificial trajectories from a limited set of stock market\nhistorical data. In order to objectively assess the performance of trading\nstrategies, the research paper also proposes a novel, more rigorous performance\nassessment methodology. Following this new performance assessment approach,\npromising results are reported for the TDQN strategy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:57:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:01:06 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 12:09:03 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Th\u00e9ate", "Thibaut", ""], ["Ernst", "Damien", ""]]}, {"id": "2004.06675", "submitter": "Firoj Alam", "authors": "Muhammad Imran, Firoj Alam, Umair Qazi, Steve Peterson and Ferda Ofli", "title": "Rapid Damage Assessment Using Social Media Images by Combining Human and\n  Machine Intelligence", "comments": "Accepted at ISCRAM 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid damage assessment is one of the core tasks that response organizations\nperform at the onset of a disaster to understand the scale of damage to\ninfrastructures such as roads, bridges, and buildings. This work analyzes the\nusefulness of social media imagery content to perform rapid damage assessment\nduring a real-world disaster. An automatic image processing system, which was\nactivated in collaboration with a volunteer response organization, processed\n~280K images to understand the extent of damage caused by the disaster. The\nsystem achieved an accuracy of 76% computed based on the feedback received from\nthe domain experts who analyzed ~29K system-processed images during the\ndisaster. An extensive error analysis reveals several insights and challenges\nfaced by the system, which are vital for the research community to advance this\nline of research.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:26:36 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Imran", "Muhammad", ""], ["Alam", "Firoj", ""], ["Qazi", "Umair", ""], ["Peterson", "Steve", ""], ["Ofli", "Ferda", ""]]}, {"id": "2004.06684", "submitter": "Wei Du", "authors": "Wei Du, Fahad Islam and Maxim Likhachev", "title": "Multi-Resolution A*", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristic search-based planning techniques are commonly used for motion\nplanning on discretized spaces. The performance of these algorithms is heavily\naffected by the resolution at which the search space is discretized. Typically\na fixed resolution is chosen for a given domain. While a finer resolution\nallows for better maneuverability, it significantly increases the size of the\nstate space, and hence demands more search efforts. On the contrary, a coarser\nresolution gives a fast exploratory behavior but compromises on maneuverability\nand the completeness of the search. To effectively leverage the advantages of\nboth high and low resolution discretizations, we propose Multi-Resolution A*\n(MRA*) algorithm, that runs multiple weighted-A*(WA*) searches having different\nresolution levels simultaneously and combines the strengths of all of them. In\naddition to these searches, MRA* uses one anchor search to control expansions\nfrom these searches. We show that MRA* is bounded suboptimal with respect to\nthe anchor resolution search space and resolution complete. We performed\nexperiments on several motion planning domains including 2D, 3D grid planning\nand 7 DOF manipulation planning and compared our approach with several\nsearch-based and sampling-based baselines.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:38:11 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Du", "Wei", ""], ["Islam", "Fahad", ""], ["Likhachev", "Maxim", ""]]}, {"id": "2004.06774", "submitter": "Firoj Alam", "authors": "Firoj Alam, Hassan Sajjad, Muhammad Imran and Ferda Ofli", "title": "CrisisBench: Benchmarking Crisis-related Social Media Datasets for\n  Humanitarian Information Processing", "comments": "Accepted in ICWSM-2021, Twitter datasets, Textual content, Natural\n  disasters, Crisis Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time-critical analysis of social media streams is important for humanitarian\norganizations for planing rapid response during disasters. The \\textit{crisis\ninformatics} research community has developed several techniques and systems\nfor processing and classifying big crisis-related data posted on social media.\nHowever, due to the dispersed nature of the datasets used in the literature\n(e.g., for training models), it is not possible to compare the results and\nmeasure the progress made towards building better models for crisis informatics\ntasks. In this work, we attempt to bridge this gap by combining various\nexisting crisis-related datasets. We consolidate eight human-annotated datasets\nand provide 166.1k and 141.5k tweets for \\textit{informativeness} and\n\\textit{humanitarian} classification tasks, respectively. We believe that the\nconsolidated dataset will help train more sophisticated models. Moreover, we\nprovide benchmarks for both binary and multiclass classification tasks using\nseveral deep learning architecrures including, CNN, fastText, and transformers.\nWe make the dataset and scripts available at:\nhttps://crisisnlp.qcri.org/crisis_datasets_benchmarks.html\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 19:51:04 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 09:48:46 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 08:58:43 GMT"}, {"version": "v4", "created": "Sat, 17 Apr 2021 16:10:22 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Alam", "Firoj", ""], ["Sajjad", "Hassan", ""], ["Imran", "Muhammad", ""], ["Ofli", "Ferda", ""]]}, {"id": "2004.06856", "submitter": "Pratap Tokekar", "authors": "Aravind Preshant Premkumar, Kevin Yu, and Pratap Tokekar", "title": "Combining Geometric and Information-Theoretic Approaches for Multi-Robot\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to explore an orthogonal polygon using a team of $p$\nrobots. This algorithm combines ideas from information-theoretic exploration\nalgorithms and computational geometry based exploration algorithms. We show\nthat the exploration time of our algorithm is competitive (as a function of\n$p$) with respect to the offline optimal exploration algorithm. The algorithm\nis based on a single-robot polygon exploration algorithm, a tree exploration\nalgorithm for higher level planning and a submodular orienteering algorithm for\nlower level planning. We discuss how this strategy can be adapted to real-world\nsettings to deal with noisy sensors. In addition to theoretical analysis, we\ninvestigate the performance of our algorithm through simulations for multiple\nrobots and experiments with a single robot.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 02:02:12 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Premkumar", "Aravind Preshant", ""], ["Yu", "Kevin", ""], ["Tokekar", "Pratap", ""]]}, {"id": "2004.06883", "submitter": "Jon McCormack", "authors": "Nina Rajcic and Jon McCormack", "title": "Mirror Ritual: Human-Machine Co-Construction of Emotion", "comments": "Paper presented at ACM TEI Conference 2020 Arts Track, Sydney\n  Australia", "journal-ref": "TEI '20: Proceedings of the Fourteenth International Conference on\n  Tangible, Embedded, and Embodied Interaction, February 2020, Pages 697-702", "doi": "10.1145/3374920.3375293", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirror Ritual is an interactive installation that challenges the existing\nparadigms in our understanding of human emotion and machine perception. In\ncontrast to prescriptive interfaces, the work's real-time affective interface\nengages the audience in the iterative conceptualisation of their emotional\nstate through the use of affectively-charged machine generated poetry. The\naudience are encouraged to make sense of the mirror's poetry by framing it with\nrespect to their recent life experiences, effectively `putting into words'\ntheir felt emotion. This process of affect labelling and contextualisation\nworks to not only regulate emotion, but helps to construct the rich personal\nnarratives that constitute human identity.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 05:09:38 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Rajcic", "Nina", ""], ["McCormack", "Jon", ""]]}, {"id": "2004.06894", "submitter": "Haizi Yu", "authors": "Haizi Yu, Heinrich Taube, James A. Evans, Lav R. Varshney", "title": "Human Evaluation of Interpretability: The Case of AI-Generated Music\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning models has gained more and more\nattention among researchers in the artificial intelligence (AI) and\nhuman-computer interaction (HCI) communities. Most existing work focuses on\ndecision making, whereas we consider knowledge discovery. In particular, we\nfocus on evaluating AI-discovered knowledge/rules in the arts and humanities.\nFrom a specific scenario, we present an experimental procedure to collect and\nassess human-generated verbal interpretations of AI-generated music\ntheory/rules rendered as sophisticated symbolic/numeric objects. Our goal is to\nreveal both the possibilities and the challenges in such a process of decoding\nexpressive messages from AI sources. We treat this as a first step towards 1)\nbetter design of AI representations that are human interpretable and 2) a\ngeneral methodology to evaluate interpretability of AI-discovered knowledge\nrepresentations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 06:03:34 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Yu", "Haizi", ""], ["Taube", "Heinrich", ""], ["Evans", "James A.", ""], ["Varshney", "Lav R.", ""]]}, {"id": "2004.06961", "submitter": "Geoffrey Pruvost", "authors": "Geoffrey Pruvost (BONUS), Bilel Derbel (BONUS), Arnaud Liefooghe\n  (BONUS), Ke Li, Qingfu Zhang (CUHK)", "title": "On the Combined Impact of Population Size and Sub-problem Selection in\n  MOEA/D", "comments": "European Conference on Evolutionary Computation in Combinatorial\n  Optimization, Apr 2020, Seville, Spain", "journal-ref": null, "doi": "10.1007/978-3-030-43680-3_9", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper intends to understand and to improve the working principle of\ndecomposition-based multi-objective evolutionary algorithms. We review the\ndesign of the well-established Moea/d framework to support the smooth\nintegration of different strategies for sub-problem selection, while\nemphasizing the role of the population size and of the number of offspring\ncreated at each generation. By conducting a comprehensive empirical analysis on\na wide range of multi-and many-objective combinatorial NK landscapes, we\nprovide new insights into the combined effect of those parameters on the\nanytime performance of the underlying search process. In particular, we show\nthat even a simple random strategy selecting sub-problems at random outperforms\nexisting sophisticated strategies. We also study the sensitivity of such\nstrategies with respect to the ruggedness and the objective space dimension of\nthe target problem.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:13:32 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Pruvost", "Geoffrey", "", "BONUS"], ["Derbel", "Bilel", "", "BONUS"], ["Liefooghe", "Arnaud", "", "BONUS"], ["Li", "Ke", "", "CUHK"], ["Zhang", "Qingfu", "", "CUHK"]]}, {"id": "2004.06971", "submitter": "Guillaume Vaudaux-Ruth", "authors": "Guillaume Vaudaux-Ruth, Adrien Chan-Hon-Tong, Catherine Achard (ISIR,\n  PIROS, SU)", "title": "ActionSpotter: Deep Reinforcement Learning Framework for Temporal Action\n  Spotting in Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing video content is an important task in many applications. This\ntask can be defined as the computation of the ordered list of actions present\nin a video. Such a list could be extracted using action detection algorithms.\nHowever, it is not necessary to determine the temporal boundaries of actions to\nknow their existence. Moreover, localizing precise boundaries usually requires\ndense video analysis to be effective. In this work, we propose to directly\ncompute this ordered list by sparsely browsing the video and selecting one\nframe per action instance, task known as action spotting in literature. To do\nthis, we propose ActionSpotter, a spotting algorithm that takes advantage of\nDeep Reinforcement Learning to efficiently spot actions while adapting its\nvideo browsing speed, without additional supervision. Experiments performed on\ndatasets THUMOS14 and ActivityNet show that our framework outperforms state of\nthe art detection methods. In particular, the spotting mean Average Precision\non THUMOS14 is significantly improved from 59.7% to 65.6% while skipping 23% of\nvideo.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:36:37 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 16:43:56 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Vaudaux-Ruth", "Guillaume", "", "ISIR,\n  PIROS, SU"], ["Chan-Hon-Tong", "Adrien", "", "ISIR,\n  PIROS, SU"], ["Achard", "Catherine", "", "ISIR,\n  PIROS, SU"]]}, {"id": "2004.07017", "submitter": "Jonatas Chagas", "authors": "Jonatas B. C. Chagas and Markus Wagner", "title": "Ants can orienteer a thief in their robbery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Thief Orienteering Problem (ThOP) is a multi-component problem that\ncombines features of two classic combinatorial optimization problems:\nOrienteering Problem and Knapsack Problem. The ThOP is challenging due to the\ngiven time constraint and the interaction between its components. We propose an\nAnt Colony Optimization algorithm together with a new packing heuristic to deal\nindividually and interactively with problem components. Our approach\noutperforms existing work on more than 90% of the benchmarking instances, with\nan average improvement of over 300%.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 11:30:37 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 14:14:58 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 11:43:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chagas", "Jonatas B. C.", ""], ["Wagner", "Markus", ""]]}, {"id": "2004.07027", "submitter": "Francesco Fuggitti", "authors": "Francesco Fuggitti", "title": "FOND Planning for LTLf and PLTLf Goals", "comments": "Extract of MSc Thesis, 35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this report, we will define a new approach to the problem of non\ndeterministic planning for extended temporal goals. In particular, we will give\na solution to this problem reducing it to a fully observable non deterministic\n(FOND) planning problem and taking advantage of the LTLfToDFA tool. First of\nall, we will introduce the main idea and motivations supporting our approach.\nThen, we will give some preliminaries explaining the Planning Domain Definition\nLanguage (PDDL) language and the FOND planning problem formally. After that, we\nwill illustrate our FOND4LTLfPLTLf (also available online) approach with the\nencoding of temporal goals into a PDDL domain and problem. Finally, we will\npresent some of the results obtained through the application of the proposed\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 12:04:02 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Fuggitti", "Francesco", ""]]}, {"id": "2004.07141", "submitter": "Weijie Zheng", "authors": "Benjamin Doerr and Weijie Zheng", "title": "From Understanding Genetic Drift to a Smart-Restart Parameter-less\n  Compact Genetic Algorithm", "comments": "4 figures. Extended version of a paper appearing at GECCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key difficulties in using estimation-of-distribution algorithms is\nchoosing the population size(s) appropriately: Too small values lead to genetic\ndrift, which can cause enormous difficulties. In the regime with no genetic\ndrift, however, often the runtime is roughly proportional to the population\nsize, which renders large population sizes inefficient.\n  Based on a recent quantitative analysis which population sizes lead to\ngenetic drift, we propose a parameter-less version of the compact genetic\nalgorithm that automatically finds a suitable population size without spending\ntoo much time in situations unfavorable due to genetic drift.\n  We prove a mathematical runtime guarantee for this algorithm and conduct an\nextensive experimental analysis on four classic benchmark problems both without\nand with additive centered Gaussian posterior noise. The former shows that\nunder a natural assumption, our algorithm has a performance very similar to the\none obtainable from the best problem-specific population size. The latter\nconfirms that missing the right population size in the original cGA can be\ndetrimental and that previous theory-based suggestions for the population size\ncan be far away from the right values; it also shows that our algorithm as well\nas a previously proposed parameter-less variant of the cGA based on parallel\nruns avoid such pitfalls. Comparing the two parameter-less approaches, ours\nprofits from its ability to abort runs which are likely to be stuck in a\ngenetic drift situation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:12:01 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 10:27:56 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 07:16:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Doerr", "Benjamin", ""], ["Zheng", "Weijie", ""]]}, {"id": "2004.07200", "submitter": "Jingkang Wang", "authors": "Tianshi Cao, Jingkang Wang, Yining Zhang, Sivabalan Manivasagam", "title": "BabyAI++: Towards Grounded-Language Learning beyond Memorization", "comments": "Accepted to the ICLR 2020 workshop: Beyond tabula rasa in RL\n  (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite success in many real-world tasks (e.g., robotics), reinforcement\nlearning (RL) agents still learn from tabula rasa when facing new and dynamic\nscenarios. By contrast, humans can offload this burden through textual\ndescriptions. Although recent works have shown the benefits of instructive\ntexts in goal-conditioned RL, few have studied whether descriptive texts help\nagents to generalize across dynamic environments. To promote research in this\ndirection, we introduce a new platform, BabyAI++, to generate various dynamic\nenvironments along with corresponding descriptive texts. Moreover, we benchmark\nseveral baselines inherited from the instruction following setting and develop\na novel approach towards visually-grounded language learning on our platform.\nExtensive experiments show strong evidence that using descriptive texts\nimproves the generalization of RL agents across environments with varied\ndynamics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:58:19 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Cao", "Tianshi", ""], ["Wang", "Jingkang", ""], ["Zhang", "Yining", ""], ["Manivasagam", "Sivabalan", ""]]}, {"id": "2004.07333", "submitter": "Colin Bellinger", "authors": "Colin Bellinger, Rory Coles, Mark Crowley, and Isaac Tamblyn", "title": "Reinforcement Learning in a Physics-Inspired Semi-Markov Environment", "comments": "To appear in the Canadian Conference on Artificial Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been demonstrated to have great potential in\nmany applications of scientific discovery and design. Recent work includes, for\nexample, the design of new structures and compositions of molecules for\ntherapeutic drugs. Much of the existing work related to the application of RL\nto scientific domains, however, assumes that the available state representation\nobeys the Markov property. For reasons associated with time, cost, sensor\naccuracy, and gaps in scientific knowledge, many scientific design and\ndiscovery problems do not satisfy the Markov property. Thus, something other\nthan a Markov decision process (MDP) should be used to plan / find the optimal\npolicy. In this paper, we present a physics-inspired semi-Markov RL\nenvironment, namely the phase change environment. In addition, we evaluate the\nperformance of value-based RL algorithms for both MDPs and partially observable\nMDPs (POMDPs) on the proposed environment. Our results demonstrate deep\nrecurrent Q-networks (DRQN) significantly outperform deep Q-networks (DQN), and\nthat DRQNs benefit from training with hindsight experience replay. Implications\nfor the use of semi-Markovian RL and POMDPs for scientific laboratories are\nalso discussed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 20:43:29 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bellinger", "Colin", ""], ["Coles", "Rory", ""], ["Crowley", "Mark", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "2004.07347", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, William\n  Wang", "title": "HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and\n  Textual Data", "comments": "Accepted to Proceedings of EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing question answering datasets focus on dealing with homogeneous\ninformation, based either only on text or KB/Table information alone. However,\nas human knowledge is distributed over heterogeneous forms, using homogeneous\ninformation alone might lead to severe coverage problems. To fill in the gap,\nwe present HybridQA https://github.com/wenhuchen/HybridQA, a new large-scale\nquestion-answering dataset that requires reasoning on heterogeneous\ninformation. Each question is aligned with a Wikipedia table and multiple\nfree-form corpora linked with the entities in the table. The questions are\ndesigned to aggregate both tabular information and text information, i.e., lack\nof either form would render the question unanswerable. We test with three\ndifferent models: 1) a table-only model. 2) text-only model. 3) a hybrid model\nthat combines heterogeneous information to find the answer. The experimental\nresults show that the EM scores obtained by two baselines are below 20\\%, while\nthe hybrid model can achieve an EM over 40\\%. This gap suggests the necessity\nto aggregate heterogeneous information in HybridQA. However, the hybrid model's\nscore is still far behind human performance. Hence, HybridQA can serve as a\nchallenging benchmark to study question answering with heterogeneous\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:18:15 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 06:52:11 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 23:29:14 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Chen", "Wenhu", ""], ["Zha", "Hanwen", ""], ["Chen", "Zhiyu", ""], ["Xiong", "Wenhan", ""], ["Wang", "Hong", ""], ["Wang", "William", ""]]}, {"id": "2004.07383", "submitter": "Brian Lucena", "authors": "Brian Lucena", "title": "Exploiting Categorical Structure Using Tree-Based Methods", "comments": "To appear in AISTATS 2020 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods of using categorical variables as predictors either endow\nthem with an ordinal structure or assume they have no structure at all.\nHowever, categorical variables often possess structure that is more complicated\nthan a linear ordering can capture. We develop a mathematical framework for\nrepresenting the structure of categorical variables and show how to generalize\ndecision trees to make use of this structure. This approach is applicable to\nmethods such as Gradient Boosted Trees which use a decision tree as the\nunderlying learner. We show results on weather data to demonstrate the\nimprovement yielded by this approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:58:27 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lucena", "Brian", ""]]}, {"id": "2004.07447", "submitter": "Daniel Halpern", "authors": "Vasilis Gkatzelis, Daniel Halpern, and Nisarg Shah", "title": "Resolving the Optimal Metric Distortion Conjecture", "comments": "An extended abstract of this paper appears in the Proceedings of FOCS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following metric distortion problem: there are two finite sets\nof points, $V$ and $C$, that lie in the same metric space, and our goal is to\nchoose a point in $C$ whose total distance from the points in $V$ is as small\nas possible. However, rather than having access to the underlying distance\nmetric, we only know, for each point in $V$, a ranking of its distances to the\npoints in $C$. We propose algorithms that choose a point in $C$ using only\nthese rankings as input and we provide bounds on their \\emph{distortion}\n(worst-case approximation ratio). A prominent motivation for this problem comes\nfrom voting theory, where $V$ represents a set of voters, $C$ represents a set\nof candidates, and the rankings correspond to ordinal preferences of the\nvoters. A major conjecture in this framework is that the optimal deterministic\nalgorithm has distortion $3$. We resolve this conjecture by providing a\npolynomial-time algorithm that achieves distortion $3$, matching a known lower\nbound. We do so by proving a novel lemma about matching voters to candidates,\nwhich we refer to as the \\emph{ranking-matching lemma}. This lemma induces a\nfamily of novel algorithms, which may be of independent interest, and we show\nthat a special algorithm in this family achieves distortion $3$. We also\nprovide more refined, parameterized, bounds using the notion of\n$\\alpha$-decisiveness, which quantifies the extent to which a voter may prefer\nher top choice relative to all others. Finally, we introduce a new randomized\nalgorithm with improved distortion compared to known results, and also provide\nimproved lower bounds on the distortion of all deterministic and randomized\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 04:13:06 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 16:52:59 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Gkatzelis", "Vasilis", ""], ["Halpern", "Daniel", ""], ["Shah", "Nisarg", ""]]}, {"id": "2004.07462", "submitter": "Silin Gao", "authors": "Silin Gao, Yichi Zhang, Zhijian Ou and Zhou Yu", "title": "Paraphrase Augmented Task-Oriented Dialog Generation", "comments": "Accepted to ACL 2020, 10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generative models have achieved promising performance on dialog\ngeneration tasks if given a huge data set. However, the lack of high-quality\ndialog data and the expensive data annotation process greatly limit their\napplication in real-world settings. We propose a paraphrase augmented response\ngeneration (PARG) framework that jointly trains a paraphrase model and a\nresponse generation model to improve the dialog generation performance. We also\ndesign a method to automatically construct paraphrase training data set based\non dialog state and dialog act labels. PARG is applicable to various dialog\ngeneration models, such as TSCP (Lei et al., 2018) and DAMD (Zhang et al.,\n2019). Experimental results show that the proposed framework improves these\nstate-of-the-art dialog models further on CamRest676 and MultiWOZ. PARG also\nsignificantly outperforms other data augmentation methods in dialog generation\ntasks, especially under low resource settings.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 05:12:36 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 12:26:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Gao", "Silin", ""], ["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""], ["Yu", "Zhou", ""]]}, {"id": "2004.07473", "submitter": "Patrick Ebel", "authors": "Patrick Ebel, Ibrahim Emre G\\\"ol, Christoph Lingenfelder and Andreas\n  Vogelsang", "title": "Destination Prediction Based on Partial Trajectory Data", "comments": "2020 IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-thirds of the people who buy a new car prefer to use a substitute instead\nof the built-in navigation system. However, for many applications, knowledge\nabout a user's intended destination and route is crucial. For example,\nsuggestions for available parking spots close to the destination can be made or\nride-sharing opportunities along the route are facilitated. Our approach\npredicts probable destinations and routes of a vehicle, based on the most\nrecent partial trajectory and additional contextual data. The approach follows\na three-step procedure: First, a $k$-d tree-based space discretization is\nperformed, mapping GPS locations to discrete regions. Secondly, a recurrent\nneural network is trained to predict the destination based on partial sequences\nof trajectories. The neural network produces destination scores, signifying the\nprobability of each region being the destination. Finally, the routes to the\nmost probable destinations are calculated. To evaluate the method, we compare\nmultiple neural architectures and present the experimental results of the\ndestination prediction. The experiments are based on two public datasets of\nnon-personalized, timestamped GPS locations of taxi trips. The best performing\nmodels were able to predict the destination of a vehicle with a mean error of\n1.3 km and 1.43 km respectively.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 06:26:10 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ebel", "Patrick", ""], ["G\u00f6l", "Ibrahim Emre", ""], ["Lingenfelder", "Christoph", ""], ["Vogelsang", "Andreas", ""]]}, {"id": "2004.07478", "submitter": "Deepak Singh", "authors": "Deepak Singh, Dilip Singh Sisodia, Pradeep Singh", "title": "Multi-Objective Evolutionary approach for the Performance Improvement of\n  Learners using Ensembling Feature selection and Discretization Technique on\n  Medical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical data is filled with continuous real values; these values in the\nfeature set tend to create problems like underfitting, the curse of\ndimensionality and increase in misclassification rate because of higher\nvariance. In response, pre-processing techniques on dataset minimizes the side\neffects and have shown success in maintaining the adequate accuracy. Feature\nselection and discretization are the two necessary preprocessing steps that\nwere effectively employed to handle the data redundancies in the biomedical\ndata. However, in the previous works, the absence of unified effort by\nintegrating feature selection and discretization together in solving the data\nredundancy problem leads to the disjoint and fragmented field. This paper\nproposes a novel multi-objective based dimensionality reduction framework,\nwhich incorporates both discretization and feature reduction as an ensemble\nmodel for performing feature selection and discretization. Selection of optimal\nfeatures and the categorization of discretized and non-discretized features\nfrom the feature subset is governed by the multi-objective genetic algorithm\n(NSGA-II). The two objective, minimizing the error rate during the feature\nselection and maximizing the information gain while discretization is\nconsidered as fitness criteria.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 06:32:15 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Singh", "Deepak", ""], ["Sisodia", "Dilip Singh", ""], ["Singh", "Pradeep", ""]]}, {"id": "2004.07499", "submitter": "Bill Yuchen Lin", "authors": "Dong-Ho Lee, Rahul Khanna, Bill Yuchen Lin, Jamin Chen, Seyeon Lee,\n  Qinyuan Ye, Elizabeth Boschee, Leonardo Neves, Xiang Ren", "title": "LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from\n  Explanation", "comments": "Accepted to the ACL 2020 (demo). The first two authors contributed\n  equally. Project page: http://inklab.usc.edu/leanlife/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successfully training a deep neural network demands a huge corpus of labeled\ndata. However, each label only provides limited information to learn from and\ncollecting the requisite number of labels involves massive human effort. In\nthis work, we introduce LEAN-LIFE, a web-based, Label-Efficient AnnotatioN\nframework for sequence labeling and classification tasks, with an easy-to-use\nUI that not only allows an annotator to provide the needed labels for a task,\nbut also enables LearnIng From Explanations for each labeling decision. Such\nexplanations enable us to generate useful additional labeled data from\nunlabeled instances, bolstering the pool of available training data. On three\npopular NLP tasks (named entity recognition, relation extraction, sentiment\nanalysis), we find that using this enhanced supervision allows our models to\nsurpass competitive baseline F1 scores by more than 5-10 percentage points,\nwhile using 2X times fewer labeled instances. Our framework is the first to\nutilize this enhanced supervision technique and does so for three important\ntasks -- thus providing improved annotation recommendations to users and an\nability to build datasets of (data, label, explanation) triples instead of the\nregular (data, label) pair.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:38:07 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lee", "Dong-Ho", ""], ["Khanna", "Rahul", ""], ["Lin", "Bill Yuchen", ""], ["Chen", "Jamin", ""], ["Lee", "Seyeon", ""], ["Ye", "Qinyuan", ""], ["Boschee", "Elizabeth", ""], ["Neves", "Leonardo", ""], ["Ren", "Xiang", ""]]}, {"id": "2004.07506", "submitter": "Christoph Benzm\\\"uller", "authors": "Alexander Steen and Christoph Benzm\\\"uller", "title": "On Reductions of Hintikka Sets for Higher-Order Logic", "comments": "10 pages; improved version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steen's (2018) Hintikka set properties for Church's type theory based on\nprimitive equality are reduced to the Hintikka set properties of Brown (2007).\nUsing this reduction, a model existence theorem for Steen's properties is\nderived.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:53:12 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 01:49:51 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 13:57:07 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Steen", "Alexander", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2004.07511", "submitter": "Tom Vermeire", "authors": "Tom Vermeire, David Martens", "title": "Explainable Image Classification with Evidence Counterfactual", "comments": "23 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of state-of-the-art modeling techniques for image\nclassification impedes the ability to explain model predictions in an\ninterpretable way. Existing explanation methods generally create importance\nrankings in terms of pixels or pixel groups. However, the resulting\nexplanations lack an optimal size, do not consider feature dependence and are\nonly related to one class. Counterfactual explanation methods are considered\npromising to explain complex model decisions, since they are associated with a\nhigh degree of human interpretability. In this paper, SEDC is introduced as a\nmodel-agnostic instance-level explanation method for image classification to\nobtain visual counterfactual explanations. For a given image, SEDC searches a\nsmall set of segments that, in case of removal, alters the classification. As\nimage classification tasks are typically multiclass problems, SEDC-T is\nproposed as an alternative method that allows specifying a target\ncounterfactual class. We compare SEDC(-T) with popular feature importance\nmethods such as LRP, LIME and SHAP, and we describe how the mentioned\nimportance ranking issues are addressed. Moreover, concrete examples and\nexperiments illustrate the potential of our approach (1) to obtain trust and\ninsight, and (2) to obtain input for model improvement by explaining\nmisclassifications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:02:48 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Vermeire", "Tom", ""], ["Martens", "David", ""]]}, {"id": "2004.07530", "submitter": "Christos Kaplanis", "authors": "Christos Kaplanis, Claudia Clopath, and Murray Shanahan", "title": "Continual Reinforcement Learning with Multi-Timescale Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a multi-timescale replay (MTR) buffer for improving\ncontinual learning in RL agents faced with environments that are changing\ncontinuously over time at timescales that are unknown to the agent. The basic\nMTR buffer comprises a cascade of sub-buffers that accumulate experiences at\ndifferent timescales, enabling the agent to improve the trade-off between\nadaptation to new data and retention of old knowledge. We also combine the MTR\nframework with invariant risk minimization, with the idea of encouraging the\nagent to learn a policy that is robust across the various environments it\nencounters over time. The MTR methods are evaluated in three different\ncontinual learning settings on two continuous control tasks and, in many cases,\nshow improvement over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:47:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kaplanis", "Christos", ""], ["Clopath", "Claudia", ""], ["Shanahan", "Murray", ""]]}, {"id": "2004.07633", "submitter": "Jan Deriu", "authors": "Jan Deriu, Katsiaryna Mlynchyk, Philippe Schl\\\"apfer, Alvaro Rodrigo,\n  Dirk von Gr\\\"unigen, Nicolas Kaiser, Kurt Stockinger, Eneko Agirre, and Mark\n  Cieliebak", "title": "A Methodology for Creating Question Answering Corpora Using Inverse Data\n  Annotation", "comments": null, "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics. 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel methodology to efficiently construct a\ncorpus for question answering over structured data. For this, we introduce an\nintermediate representation that is based on the logical query plan in a\ndatabase called Operation Trees (OT). This representation allows us to invert\nthe annotation process without losing flexibility in the types of queries that\nwe generate. Furthermore, it allows for fine-grained alignment of query tokens\nto OT operations. In our method, we randomly generate OTs from a context-free\ngrammar. Afterwards, annotators have to write the appropriate natural language\nquestion that is represented by the OT. Finally, the annotators assign the\ntokens to the OT operations. We apply the method to create a new corpus OTTA\n(Operation Trees and Token Assignment), a large semantic parsing corpus for\nevaluating natural language interfaces to databases. We compare OTTA to Spider\nand LC-QuaD 2.0 and show that our methodology more than triples the annotation\nspeed while maintaining the complexity of the queries. Finally, we train a\nstate-of-the-art semantic parsing model on our data and show that our corpus is\na challenging dataset and that the token alignment can be leveraged to increase\nthe performance significantly.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 12:50:01 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 08:13:32 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Deriu", "Jan", ""], ["Mlynchyk", "Katsiaryna", ""], ["Schl\u00e4pfer", "Philippe", ""], ["Rodrigo", "Alvaro", ""], ["von Gr\u00fcnigen", "Dirk", ""], ["Kaiser", "Nicolas", ""], ["Stockinger", "Kurt", ""], ["Agirre", "Eneko", ""], ["Cieliebak", "Mark", ""]]}, {"id": "2004.07690", "submitter": "Phuong Ngo", "authors": "Phuong D. Ngo, Fred Godtliebsen", "title": "Data-Driven Robust Control Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a robust control design method using\nreinforcement-learning for controlling partially-unknown dynamical systems\nunder uncertain conditions. The method extends the optimal\nreinforcement-learning algorithm with a new learning technique that is based on\nthe robust control theory. By learning from the data, the algorithm proposed\nactions that guarantees the stability of the closed loop system within the\nuncertainties estimated from the data. Control policies are calculated by\nsolving a set of linear matrix inequalities. The controller was evaluated using\nsimulations on a blood glucose model for patients with type-1 diabetes.\nSimulation results show that the proposed methodology is capable of safely\nregulates the blood glucose within a healthy level under the influence of\nmeasurement and process noises. The controller has also significantly reduced\nthe post-meal fluctuation of the blood glucose. A comparison between the\nproposed algorithm and the existing optimal reinforcement learning algorithm\nshows the improved robustness of the closed loop system using our method.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:57:15 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ngo", "Phuong D.", ""], ["Godtliebsen", "Fred", ""]]}, {"id": "2004.07707", "submitter": "Declan Oller", "authors": "Declan Oller, Tobias Glasmachers, Giuseppe Cuccu", "title": "Analyzing Reinforcement Learning Benchmarks with Random Weight Guessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for analyzing and visualizing the complexity of\nstandard reinforcement learning (RL) benchmarks based on score distributions. A\nlarge number of policy networks are generated by randomly guessing their\nparameters, and then evaluated on the benchmark task; the study of their\naggregated results provide insights into the benchmark complexity. Our method\nguarantees objectivity of evaluation by sidestepping learning altogether: the\npolicy network parameters are generated using Random Weight Guessing (RWG),\nmaking our method agnostic to (i) the classic RL setup, (ii) any learning\nalgorithm, and (iii) hyperparameter tuning. We show that this approach isolates\nthe environment complexity, highlights specific types of challenges, and\nprovides a proper foundation for the statistical analysis of the task's\ndifficulty. We test our approach on a variety of classic control benchmarks\nfrom the OpenAI Gym, where we show that small untrained networks can provide a\nrobust baseline for a variety of tasks. The networks generated often show good\nperformance even without gradual learning, incidentally highlighting the\ntriviality of a few popular benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:32:52 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Oller", "Declan", ""], ["Glasmachers", "Tobias", ""], ["Cuccu", "Giuseppe", ""]]}, {"id": "2004.07780", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, J\\\"orn-Henrik Jacobsen, Claudio Michaelis, Richard\n  Zemel, Wieland Brendel, Matthias Bethge, Felix A. Wichmann", "title": "Shortcut Learning in Deep Neural Networks", "comments": "perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)", "journal-ref": null, "doi": "10.1038/s42256-020-00257-z", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distil how many\nof deep learning's problem can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:18:49 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:03:44 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 09:10:46 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 13:53:12 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Geirhos", "Robert", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Michaelis", "Claudio", ""], ["Zemel", "Richard", ""], ["Brendel", "Wieland", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "2004.07790", "submitter": "Joe Stacey", "authors": "Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Sebastian Riedel,\n  Tim Rockt\\\"aschel", "title": "Avoiding the Hypothesis-Only Bias in Natural Language Inference via\n  Ensemble Adversarial Training", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) datasets contain annotation artefacts\nresulting in spurious correlations between the natural language utterances and\ntheir respective entailment classes. These artefacts are exploited by neural\nnetworks even when only considering the hypothesis and ignoring the premise,\nleading to unwanted biases. Belinkov et al. (2019b) proposed tackling this\nproblem via adversarial training, but this can lead to learned sentence\nrepresentations that still suffer from the same biases. We show that the bias\ncan be reduced in the sentence representations by using an ensemble of\nadversaries, encouraging the model to jointly decrease the accuracy of these\ndifferent adversaries while fitting the data. This approach produces more\nrobust NLI models, outperforming previous de-biasing efforts when generalised\nto 12 other datasets (Belinkov et al., 2019a; Mahabadi et al., 2020). In\naddition, we find that the optimal number of adversarial classifiers depends on\nthe dimensionality of the sentence representations, with larger sentence\nrepresentations being more difficult to de-bias while benefiting from using a\ngreater number of adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:37:15 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 17:19:14 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:47:32 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2020 17:12:15 GMT"}, {"version": "v5", "created": "Thu, 27 May 2021 17:14:46 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Stacey", "Joe", ""], ["Minervini", "Pasquale", ""], ["Dubossarsky", "Haim", ""], ["Riedel", "Sebastian", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2004.07804", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Igor Mordatch, Vikash Kumar", "title": "A Game Theoretic Framework for Model Based Reinforcement Learning", "comments": "ICML 2020. This version contains expanded discussion, hyperparameter\n  configurations, and ablation studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) has recently gained immense\ninterest due to its potential for sample efficiency and ability to incorporate\noff-policy data. However, designing stable and efficient MBRL algorithms using\nrich function approximators have remained challenging. To help expose the\npractical challenges in MBRL and simplify algorithm design from the lens of\nabstraction, we develop a new framework that casts MBRL as a game between: (1)\na policy player, which attempts to maximize rewards under the learned model;\n(2) a model player, which attempts to fit the real-world data collected by the\npolicy player. For algorithm development, we construct a Stackelberg game\nbetween the two players, and show that it can be solved with approximate\nbi-level optimization. This gives rise to two natural families of algorithms\nfor MBRL based on which player is chosen as the leader in the Stackelberg game.\nTogether, they encapsulate, unify, and generalize many previous MBRL\nalgorithms. Furthermore, our framework is consistent with and provides a clear\nbasis for heuristics known to be important in practice from prior works.\nFinally, through experiments we validate that our proposed algorithms are\nhighly sample efficient, match the asymptotic performance of model-free policy\ngradient, and scale gracefully to high-dimensional tasks like dexterous hand\nmanipulation. Additional details and code can be obtained from the project page\nat https://sites.google.com/view/mbrl-game\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:51:45 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 05:52:14 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Mordatch", "Igor", ""], ["Kumar", "Vikash", ""]]}, {"id": "2004.07822", "submitter": "Mehrdad Zakershahrak", "authors": "Mehrdad Zakershahrak, Shashank Rao Marpally, Akshay Sharma, Ze Gong\n  and Yu Zhang", "title": "Order Matters: Generating Progressive Explanations for Planning Tasks in\n  Human-Robot Teaming", "comments": "arXiv admin note: text overlap with arXiv:1902.00604", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on generating explanations in a planning and decision-making\ncontext has focused on providing the rationale behind an AI agent's decision\nmaking. While these methods provide the right explanations from the explainer's\nperspective, they fail to heed the cognitive requirement of understanding an\nexplanation from the explainee's (the human's) perspective. In this work, we\nset out to address this issue by first considering the influence of information\norder in an explanation, or the progressiveness of explanations. Intuitively,\nprogression builds later concepts on previous ones and is known to contribute\nto better learning. In this work, we aim to investigate similar effects during\nexplanation generation when an explanation is broken into multiple parts that\nare communicated sequentially. The challenge here lies in modeling the humans'\npreferences for information order in receiving such explanations to assist\nunderstanding. Given this sequential process, a formulation based on goal-based\nMDP for generating progressive explanations is presented. The reward function\nof this MDP is learned via inverse reinforcement learning based on explanations\nthat are retrieved via human subject studies. We first evaluated our approach\non a scavenger-hunt domain to demonstrate its effectively in capturing the\nhumans' preferences. Upon analyzing the results, it revealed something more\nfundamental: the preferences arise strongly from both domain dependent and\nindependence features. The correlation with domain independent features pushed\nus to verify this result further in an escape room domain. Results confirmed\nour hypothesis that the process of understanding an explanation was a dynamic\nprocess. The human preference that reflected this aspect corresponded exactly\nto the progression for knowledge assimilation hidden deeper in our cognitive\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 00:17:02 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 01:15:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zakershahrak", "Mehrdad", ""], ["Marpally", "Shashank Rao", ""], ["Sharma", "Akshay", ""], ["Gong", "Ze", ""], ["Zhang", "Yu", ""]]}, {"id": "2004.07879", "submitter": "Ashok Goel", "authors": "Snejana Sheghava and Ashok Goel", "title": "Symmetry as an Organizing Principle for Geometric Intelligence", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration of geometrical patterns stimulates imagination and encourages\nabstract reasoning which is a distinctive feature of human intelligence. In\ncognitive science, Gestalt principles such as symmetry have often explained\nsignificant aspects of human perception. We present a computational technique\nfor building artificial intelligence (AI) agents that use symmetry as the\norganizing principle for addressing Dehaene's test of geometric intelligence\n\\cite{dehaene2006core}. The performance of our model is on par with extant AI\nmodels of problem solving on the Dehaene's test and seems correlated with some\nelements of human behavior on the same test.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 18:58:15 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Sheghava", "Snejana", ""], ["Goel", "Ashok", ""]]}, {"id": "2004.07928", "submitter": "Dmitry Kazhdan", "authors": "Dmitry Kazhdan, Zohreh Shams, Pietro Li\\`o", "title": "MARLeME: A Multi-Agent Reinforcement Learning Model Extraction Library", "comments": "Presented at the KR2ML workshop at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) encompasses a powerful class of\nmethodologies that have been applied in a wide range of fields. An effective\nway to further empower these methodologies is to develop libraries and tools\nthat could expand their interpretability and explainability. In this work, we\nintroduce MARLeME: a MARL model extraction library, designed to improve\nexplainability of MARL systems by approximating them with symbolic models.\nSymbolic models offer a high degree of interpretability, well-defined\nproperties, and verifiable behaviour. Consequently, they can be used to inspect\nand better understand the underlying MARL system and corresponding MARL agents,\nas well as to replace all/some of the agents that are particularly safety and\nsecurity critical.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:27:38 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Kazhdan", "Dmitry", ""], ["Shams", "Zohreh", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2004.07950", "submitter": "Alexander Pashevich", "authors": "Alexander Pashevich, Igor Kalevatykh, Ivan Laptev, Cordelia Schmid", "title": "Learning visual policies for building 3D shape categories", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation and assembly tasks require non-trivial planning of actions\ndepending on the environment and the final goal. Previous work in this domain\noften assembles particular instances of objects from known sets of primitives.\nIn contrast, we aim to handle varying sets of primitives and to construct\ndifferent objects of a shape category. Given a single object instance of a\ncategory, e.g. an arch, and a binary shape classifier, we learn a visual policy\nto assemble other instances of the same category. In particular, we propose a\ndisassembly procedure and learn a state policy that discovers new object\ninstances and their assembly plans in state space. We then render simulated\nstates in the observation space and learn a heatmap representation to predict\nalternative actions from a given input image. To validate our approach, we\nfirst demonstrate its efficiency for building object categories in state space.\nWe then show the success of our visual policies for building arches from\ndifferent primitives. Moreover, we demonstrate (i) the reactive ability of our\nmethod to re-assemble objects using additional primitives and (ii) the robust\nperformance of our policy for unseen primitives resembling building blocks used\nduring training. Our visual assembly policies are trained with no real images\nand reach up to 95% success rate when evaluated on a real robot.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:29:10 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:24:32 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Pashevich", "Alexander", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2004.08051", "submitter": "Keuntaek Lee", "authors": "Keuntaek Lee, Bogdan Vlahov, Jason Gibson, James M. Rehg, Evangelos A.\n  Theodorou", "title": "Approximate Inverse Reinforcement Learning from Vision-based Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we present a method for obtaining an implicit objective\nfunction for vision-based navigation. The proposed methodology relies on\nImitation Learning, Model Predictive Control (MPC), and an interpretation\ntechnique used in Deep Neural Networks. We use Imitation Learning as a means to\ndo Inverse Reinforcement Learning in order to create an approximate cost\nfunction generator for a visual navigation challenge. The resulting cost\nfunction, the costmap, is used in conjunction with MPC for real-time control\nand outperforms other state-of-the-art costmap generators in novel\nenvironments. The proposed process allows for simple training and robustness to\nout-of-sample data. We apply our method to the task of vision-based autonomous\ndriving in multiple real and simulated environments and show its\ngeneralizability.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:36:50 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 03:37:41 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 19:52:37 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Lee", "Keuntaek", ""], ["Vlahov", "Bogdan", ""], ["Gibson", "Jason", ""], ["Rehg", "James M.", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2004.08128", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Christopher L Buckley", "title": "Whence the Expected Free Energy?", "comments": "24 pages, 0 figures. Reuploaded to correct typos in the original.\n  Update 05-07-20 -- minor corrections. Update 28-09-20 -- Final version\n  accepted by Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expected Free Energy (EFE) is a central quantity in the theory of active\ninference. It is the quantity that all active inference agents are mandated to\nminimize through action, and its decomposition into extrinsic and intrinsic\nvalue terms is key to the balance of exploration and exploitation that active\ninference agents evince. Despite its importance, the mathematical origins of\nthis quantity and its relation to the Variational Free Energy (VFE) remain\nunclear. In this paper, we investigate the origins of the EFE in detail and\nshow that it is not simply \"the free energy in the future\". We present a\nfunctional that we argue is the natural extension of the VFE, but which\nactively discourages exploratory behaviour, thus demonstrating that exploration\ndoes not directly follow from free energy minimization into the future. We then\ndevelop a novel objective, the Free-Energy of the Expected Future (FEEF), which\npossesses both the epistemic component of the EFE as well as an intuitive\nmathematical grounding as the divergence between predicted and desired futures.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 09:06:56 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 10:19:53 GMT"}, {"version": "v3", "created": "Sun, 10 May 2020 15:38:57 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2020 18:41:09 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 21:04:16 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2004.08144", "submitter": "Marc Van Zee", "authors": "Marc van Zee, Dragan Doder, Leendert van der Torre, Mehdi Dastani,\n  Thomas Icard, Eric Pacuit", "title": "Intention as Commitment toward Time", "comments": "83 pages, 4 figures, Artificial Intelligence journal pre-print", "journal-ref": "Artificial Intelligence, Volume 283, June 2020, 103270", "doi": "10.1016/j.artint.2020.103270", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the interplay among intention, time, and belief in\ndynamic environments. The first contribution is a logic for reasoning about\nintention, time and belief, in which assumptions of intentions are represented\nby preconditions of intended actions. Intentions and beliefs are coherent as\nlong as these assumptions are not violated, i.e. as long as intended actions\ncan be performed such that their preconditions hold as well. The second\ncontribution is the formalization of what-if scenarios: what happens with\nintentions and beliefs if a new (possibly conflicting) intention is adopted, or\na new fact is learned? An agent is committed to its intended actions as long as\nits belief-intention database is coherent. We conceptualize intention as\ncommitment toward time and we develop AGM-based postulates for the iterated\nrevision of belief-intention databases, and we prove a Katsuno-Mendelzon-style\nrepresentation theorem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 09:47:39 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["van Zee", "Marc", ""], ["Doder", "Dragan", ""], ["van der Torre", "Leendert", ""], ["Dastani", "Mehdi", ""], ["Icard", "Thomas", ""], ["Pacuit", "Eric", ""]]}, {"id": "2004.08212", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski and Josef Urban", "title": "Stateful Premise Selection by Recurrent Neural Networks", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a new learning-based method for selecting facts\n(premises) when proving new goals over large formal libraries. Unlike previous\nmethods that choose sets of facts independently of each other by their rank,\nthe new method uses the notion of \\emph{state} that is updated each time a\nchoice of a fact is made. Our stateful architecture is based on recurrent\nneural networks which have been recently very successful in stateful tasks such\nas language translation. The new method is combined with data augmentation\ntechniques, evaluated in several ways on a standard large-theory benchmark, and\ncompared to state-of-the-art premise approach based on gradient boosted trees.\nIt is shown to perform significantly better and to solve many new problems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:59:37 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "2004.08279", "submitter": "Soheila Ghambari", "authors": "Mahmoud Golabi, Soheila Ghambari, Julien Lepagnot, Laetitia Jourdan,\n  Mathieu Brevilliers, Lhassane Idoumghar", "title": "Bypassing or flying above the obstacles? A novel multi-objective UAV\n  path planning problem", "comments": "8 pages, 5 figures, Accepted for presentation at the IEEE CEC 2020\n  and for publication in the conference proceedings published by IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a novel multi-objective integer programming model for a\ncollision-free discrete drone path planning problem. Considering the\npossibility of bypassing obstacles or flying above them, this study aims to\nminimize the path length, energy consumption, and maximum path risk\nsimultaneously. The static environment is represented as 3D grid cells. Due to\nthe NP-hardness nature of the problem, several state-of-theart evolutionary\nmulti-objective optimization (EMO) algorithms with customized crossover and\nmutation operators are applied to find a set of non-dominated solutions. The\nresults show the effectiveness of applied algorithms in solving several\ngenerated test cases.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 13:42:05 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Golabi", "Mahmoud", ""], ["Ghambari", "Soheila", ""], ["Lepagnot", "Julien", ""], ["Jourdan", "Laetitia", ""], ["Brevilliers", "Mathieu", ""], ["Idoumghar", "Lhassane", ""]]}, {"id": "2004.08353", "submitter": "Toby Jia-Jun Li", "authors": "Toby Jia-Jun Li, Jingya Chen, Brandon Canfield, Brad A. Myers", "title": "Privacy-Preserving Script Sharing in GUI-based\n  Programming-by-Demonstration Systems", "comments": "In the Proceedings of the ACM on Human-Computer Interaction (PACM)\n  Vol.4 No. CSCW1. (CSCW 2020)", "journal-ref": "Proc. ACM Hum.-Comput. Interact. 4, CSCW1, Article 60 (May 2020),\n  23 pages", "doi": "10.1145/3392869", "report-no": null, "categories": "cs.HC cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important concern in end user development (EUD) is accidentally embedding\npersonal information in program artifacts when sharing them. This issue is\nparticularly important in GUI-based programming-by-demonstration (PBD) systems\ndue to the lack of direct developer control of script contents. Prior studies\nreported that these privacy concerns were the main barrier to script sharing in\nEUD. We present a new approach that can identify and obfuscate the potential\npersonal information in GUI-based PBD scripts based on the uniqueness of\ninformation entries with respect to the corresponding app GUI context. Compared\nwith the prior approaches, ours supports broader types of personal information\nbeyond explicitly pre-specified ones, requires minimal user effort, addresses\nthe threat of re-identification attacks, and can work with third-party apps\nfrom any task domain. Our approach also recovers obfuscated fields locally on\nthe script consumer's side to preserve the shared scripts' transparency,\nreadability, robustness, and generalizability. Our evaluation shows that our\napproach (1) accurately identifies the potential personal information in\nscripts across different apps in diverse task domains; (2) allows end-user\ndevelopers to feel comfortable sharing their own scripts; and (3) enables\nscript consumers to understand the operation of shared scripts despite the\nobfuscated fields.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:20:10 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Li", "Toby Jia-Jun", ""], ["Chen", "Jingya", ""], ["Canfield", "Brandon", ""], ["Myers", "Brad A.", ""]]}, {"id": "2004.08355", "submitter": "Georg Rehm", "authors": "Georg Rehm, Dimitrios Galanis, Penny Labropoulou, Stelios Piperidis,\n  Martin Wel{\\ss}, Ricardo Usbeck, Joachim K\\\"ohler, Miltos Deligiannis,\n  Katerina Gkirtzou, Johannes Fischer, Christian Chiarcos, Nils Feldhus,\n  Juli\\'an Moreno-Schneider, Florian Kintzel, Elena Montiel, V\\'ictor\n  Rodr\\'iguez Doncel, John P. McCrae, David Laqua, Irina Patricia Theile,\n  Christian Dittmar, Kalina Bontcheva, Ian Roberts, Andrejs Vasiljevs, Andis\n  Lagzdi\\c{n}\\v{s}", "title": "Towards an Interoperable Ecosystem of AI and LT Platforms: A Roadmap for\n  the Implementation of Different Levels of Interoperability", "comments": "Proceedings of the 1st International Workshop on Language Technology\n  Platforms (IWLTP 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With regard to the wider area of AI/LT platform interoperability, we\nconcentrate on two core aspects: (1) cross-platform search and discovery of\nresources and services; (2) composition of cross-platform service workflows. We\ndevise five different levels (of increasing complexity) of platform\ninteroperability that we suggest to implement in a wider federation of AI/LT\nplatforms. We illustrate the approach using the five emerging AI/LT platforms\nAI4EU, ELG, Lynx, QURATOR and SPEAKER.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:22:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Rehm", "Georg", ""], ["Galanis", "Dimitrios", ""], ["Labropoulou", "Penny", ""], ["Piperidis", "Stelios", ""], ["Wel\u00df", "Martin", ""], ["Usbeck", "Ricardo", ""], ["K\u00f6hler", "Joachim", ""], ["Deligiannis", "Miltos", ""], ["Gkirtzou", "Katerina", ""], ["Fischer", "Johannes", ""], ["Chiarcos", "Christian", ""], ["Feldhus", "Nils", ""], ["Moreno-Schneider", "Juli\u00e1n", ""], ["Kintzel", "Florian", ""], ["Montiel", "Elena", ""], ["Doncel", "V\u00edctor Rodr\u00edguez", ""], ["McCrae", "John P.", ""], ["Laqua", "David", ""], ["Theile", "Irina Patricia", ""], ["Dittmar", "Christian", ""], ["Bontcheva", "Kalina", ""], ["Roberts", "Ian", ""], ["Vasiljevs", "Andrejs", ""], ["Lagzdi\u0146\u0161", "Andis", ""]]}, {"id": "2004.08356", "submitter": "Aditi Mavalankar", "authors": "Aditi Mavalankar", "title": "Goal-conditioned Batch Reinforcement Learning for Rotation Invariant\n  Locomotion", "comments": "Accepted to the BeTR-RL workshop at ICLR 2020. Link to code:\n  https://github.com/aditimavalankar/gc-batch-rl-locomotion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to learn goal-conditioned policies for locomotion\nin a batch RL setting. The batch data is collected by a policy that is not\ngoal-conditioned. For the locomotion task, this translates to data collection\nusing a policy learnt by the agent for walking straight in one direction, and\nusing that data to learn a goal-conditioned policy that enables the agent to\nwalk in any direction. The data collection policy used should be invariant to\nthe direction the agent is facing i.e. regardless of its initial orientation,\nthe agent should take the same actions to walk forward. We exploit this\nproperty to learn a goal-conditioned policy using two key ideas: (1) augmenting\ndata by generating trajectories with the same actions in different directions,\nand (2) learning an encoder that enforces invariance between these rotated\ntrajectories with a Siamese framework. We show that our approach outperforms\nexisting RL algorithms on 3-D locomotion agents like Ant, Humanoid and\nMinitaur.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:25:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Mavalankar", "Aditi", ""]]}, {"id": "2004.08366", "submitter": "Yun Zeng", "authors": "Yun Zeng, Siqi Zuo, Dongcai Shen", "title": "DynamicEmbedding: Extending TensorFlow for Colossal-Scale Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the limitations of deep learning models with sparse features today\nstems from the predefined nature of their input, which requires a dictionary be\ndefined prior to the training. With this paper we propose both a theory and a\nworking system design which remove this limitation, and show that the resulting\nmodels are able to perform better and efficiently run at a much larger scale.\nSpecifically, we achieve this by decoupling a model's content from its form to\ntackle architecture evolution and memory growth separately. To efficiently\nhandle model growth, we propose a new neuron model, called DynamicCell, drawing\ninspiration from from the free energy principle [15] to introduce the concept\nof reaction to discharge non-digestive energy, which also subsumes gradient\ndescent based approaches as its special cases. We implement DynamicCell by\nintroducing a new server into TensorFlow to take over most of the work\ninvolving model growth. Consequently, it enables any existing deep learning\nmodels to efficiently handle arbitrary number of distinct sparse features\n(e.g., search queries), and grow incessantly without redefining the model. Most\nnotably, one of our models, which has been reliably running in production for\nover a year, is capable of suggesting high quality keywords for advertisers of\nGoogle Smart Campaigns and achieved significant accuracy gains based on a\nchallenging metric -- evidence that data-driven, self-evolving systems can\npotentially exceed the performance of traditional rule-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:43:51 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Zeng", "Yun", ""], ["Zuo", "Siqi", ""], ["Shen", "Dongcai", ""]]}, {"id": "2004.08440", "submitter": "Haoze Wu", "authors": "Haoze Wu, Alex Ozdemir, Aleksandar Zelji\\'c, Ahmed Irfan, Kyle Julian,\n  Divya Gopinath, Sadjad Fouladi, Guy Katz, Corina Pasareanu and Clark Barrett", "title": "Parallelization Techniques for Verifying Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes with parallel optimization techniques for\nsolving Boolean satisfiability, we investigate a set of strategies and\nheuristics that aim to leverage parallel computing to improve the scalability\nof neural network verification. We introduce an algorithm based on partitioning\nthe verification problem in an iterative manner and explore two partitioning\nstrategies, that work by partitioning the input space or by case splitting on\nthe phases of the neuron activations, respectively. We also introduce a highly\nparallelizable pre-processing algorithm that uses the neuron activation phases\nto simplify the neural network verification problems. An extensive experimental\nevaluation shows the benefit of these techniques on both existing benchmarks\nand new benchmarks from the aviation domain. A preliminary experiment with\nultra-scaling our algorithm using a large distributed cloud-based platform also\nshows promising results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:21:47 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 20:43:08 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 16:15:13 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Wu", "Haoze", ""], ["Ozdemir", "Alex", ""], ["Zelji\u0107", "Aleksandar", ""], ["Irfan", "Ahmed", ""], ["Julian", "Kyle", ""], ["Gopinath", "Divya", ""], ["Fouladi", "Sadjad", ""], ["Katz", "Guy", ""], ["Pasareanu", "Corina", ""], ["Barrett", "Clark", ""]]}, {"id": "2004.08519", "submitter": "Noriyoshi Sukegawa", "authors": "Naoki Nishimura, Noriyoshi Sukegawa, Yuichi Takano, Jiro Iwanaga", "title": "Predicting Online Item-choice Behavior: A Shape-restricted Regression\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the relationship between user pageview (PV) histories and\ntheir item-choice behavior on an e-commerce website. We focus on PV sequences,\nwhich represent time series of the number of PVs for each user--item pair. We\npropose a shape-restricted optimization model that accurately estimates\nitem-choice probabilities for all possible PV sequences. This model imposes\nmonotonicity constraints on item-choice probabilities by exploiting partial\norders for PV sequences, according to the recency and frequency of a user's\nprevious PVs. To improve the computational efficiency of our optimization\nmodel, we devise efficient algorithms for eliminating all redundant constraints\naccording to the transitivity of the partial orders. Experimental results using\nreal-world clickstream data demonstrate that our method achieves higher\nprediction performance than that of a state-of-the-art optimization model and\ncommon machine learning methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 04:12:40 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 13:18:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nishimura", "Naoki", ""], ["Sukegawa", "Noriyoshi", ""], ["Takano", "Yuichi", ""], ["Iwanaga", "Jiro", ""]]}, {"id": "2004.08555", "submitter": "Xueyan Yin", "authors": "Xueyan Yin, Genze Wu, Jinze Wei, Yanming Shen, Heng Qi, and Baocai Yin", "title": "Deep Learning on Traffic Prediction: Methods, Analysis and Future\n  Directions", "comments": "to be published in IEEE Transactions on Intelligent Transportation\n  Systems", "journal-ref": null, "doi": "10.1109/TITS.2021.3054840", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic prediction plays an essential role in intelligent transportation\nsystem. Accurate traffic prediction can assist route planing, guide vehicle\ndispatching, and mitigate traffic congestion. This problem is challenging due\nto the complicated and dynamic spatio-temporal dependencies between different\nregions in the road network. Recently, a significant amount of research efforts\nhave been devoted to this area, especially deep learning method, greatly\nadvancing traffic prediction abilities. The purpose of this paper is to provide\na comprehensive survey on deep learning-based approaches in traffic prediction\nfrom multiple perspectives. Specifically, we first summarize the existing\ntraffic prediction methods, and give a taxonomy. Second, we list the\nstate-of-the-art approaches in different traffic prediction applications.\nThird, we comprehensively collect and organize widely used public datasets in\nthe existing literature to facilitate other researchers. Furthermore, we give\nan evaluation and analysis by conducting extensive experiments to compare the\nperformance of different methods on a real-world public dataset. Finally, we\ndiscuss open challenges in this field.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 08:28:10 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:37:40 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 04:04:20 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 01:40:26 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Yin", "Xueyan", ""], ["Wu", "Genze", ""], ["Wei", "Jinze", ""], ["Shen", "Yanming", ""], ["Qi", "Heng", ""], ["Yin", "Baocai", ""]]}, {"id": "2004.08599", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Three Modern Roles for Logic in AI", "comments": "To be published in PODS 2020", "journal-ref": null, "doi": "10.1145/3375395.3389131", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three modern roles for logic in artificial intelligence, which\nare based on the theory of tractable Boolean circuits: (1) logic as a basis for\ncomputation, (2) logic for learning from a combination of data and knowledge,\nand (3) logic for reasoning about the behavior of machine learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:51:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "2004.08600", "submitter": "Chris Reinke", "authors": "Chris Reinke", "title": "Time Adaptive Reinforcement Learning", "comments": "ICLR 2020 Workshop: Beyond Tabula Rasa in Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) allows to solve complex tasks such as Go often\nwith a stronger performance than humans. However, the learned behaviors are\nusually fixed to specific tasks and unable to adapt to different contexts. Here\nwe consider the case of adapting RL agents to different time restrictions, such\nas finishing a task with a given time limit that might change from one task\nexecution to the next. We define such problems as Time Adaptive Markov Decision\nProcesses and introduce two model-free, value-based algorithms: the Independent\nGamma-Ensemble and the n-Step Ensemble. In difference to classical approaches,\nthey allow a zero-shot adaptation between different time restrictions. The\nproposed approaches represent general mechanisms to handle time adaptive tasks\nmaking them compatible with many existing RL methods, algorithms, and\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:52:07 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Reinke", "Chris", ""]]}, {"id": "2004.08607", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "Accumulator Bet Selection Through Stochastic Diffusion Search", "comments": null, "journal-ref": "Information and Control, Volume 15, Number 2, pp 641 652 (2019)", "doi": "10.24507/ijicic.15.02.641", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accumulator is a bet that presents a rather unique payout structure, in\nthat it combines multiple bets into a wager that can generate a total payout\ngiven by the multiplication of the individual odds of its parts. These\npotentially important returns come however at an increased risk of a loss.\nIndeed, the presence of a single incorrect bet in this selection would make the\nwhole accumulator lose. The complexity of selecting a set of matches to place\nan accumulator bet on, as well as the number of opportunities to identify\nwinning combinations have both dramatically increased with the easier access to\nonline and offline bookmakers that bettors have nowadays. We address this\nrelatively under-studied combinatorial aspect of sports betting, and propose a\nbinary optimization model for the problem of selecting the most promising\ncombinations of matches, in terms of their total potential payout and\nprobability of a win, to form an accumulator bet. The results of an ongoing\ncomputational experiment, in which our model is applied to real data pertaining\nto the four main football leagues in the world over a complete season, are\npresented and compared to those of single bet selection methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 12:42:23 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2004.08646", "submitter": "Yuchen Xiao", "authors": "Yuchen Xiao, Joshua Hoffman, and Christopher Amato", "title": "Macro-Action-Based Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": "3rd Conference on Robot Learning (CoRL 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world multi-robot systems, performing high-quality, collaborative\nbehaviors requires robots to asynchronously reason about high-level action\nselection at varying time durations. Macro-Action Decentralized Partially\nObservable Markov Decision Processes (MacDec-POMDPs) provide a general\nframework for asynchronous decision making under uncertainty in fully\ncooperative multi-agent tasks. However, multi-agent deep reinforcement learning\nmethods have only been developed for (synchronous) primitive-action problems.\nThis paper proposes two Deep Q-Network (DQN) based methods for learning\ndecentralized and centralized macro-action-value functions with novel\nmacro-action trajectory replay buffers introduced for each case. Evaluations on\nbenchmark problems and a larger domain demonstrate the advantage of learning\nwith macro-actions over primitive-actions and the scalability of our\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 15:46:38 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Xiao", "Yuchen", ""], ["Hoffman", "Joshua", ""], ["Amato", "Christopher", ""]]}, {"id": "2004.08648", "submitter": "Saeed Moazami", "authors": "Saeed Moazami, Peggy Doerschuk", "title": "Modeling Survival in model-based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent model-free reinforcement learning algorithms have been shown\nto be capable of mastering complicated decision-making tasks, the sample\ncomplexity of these methods has remained a hurdle to utilizing them in many\nreal-world applications. In this regard, model-based reinforcement learning\nproposes some remedies. Yet, inherently, model-based methods are more\ncomputationally expensive and susceptible to sub-optimality. One reason is that\nmodel-generated data are always less accurate than real data, and this often\nleads to inaccurate transition and reward function models. With the aim to\nmitigate this problem, this work presents the notion of survival by discussing\ncases in which the agent's goal is to survive and its analogy to maximizing the\nexpected rewards. To that end, a substitute model for the reward function\napproximator is introduced that learns to avoid terminal states rather than to\nmaximize accumulated rewards from safe states. Focusing on terminal states, as\na small fraction of state-space, reduces the training effort drastically. Next,\na model-based reinforcement learning method is proposed (Survive) to train an\nagent to avoid dangerous states through a safety map model built upon temporal\ncredit assignment in the vicinity of terminal states. Finally, the performance\nof the presented algorithm is investigated, along with a comparison between the\nproposed and current methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 15:49:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Moazami", "Saeed", ""], ["Doerschuk", "Peggy", ""]]}, {"id": "2004.08672", "submitter": "Shiqi Zhang", "authors": "Shiqi Zhang, Peter Stone", "title": "iCORPP: Interleaved Commonsense Reasoning and Probabilistic Planning on\n  Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot sequential decision-making in the real world is a challenge because it\nrequires the robots to simultaneously reason about the current world state and\ndynamics, while planning actions to accomplish complex tasks. On the one hand,\ndeclarative languages and reasoning algorithms well support representing and\nreasoning with commonsense knowledge. But these algorithms are not good at\nplanning actions toward maximizing cumulative reward over a long, unspecified\nhorizon. On the other hand, probabilistic planning frameworks, such as Markov\ndecision processes (MDPs) and partially observable MDPs (POMDPs), well support\nplanning to achieve long-term goals under uncertainty. But they are\nill-equipped to represent or reason about knowledge that is not directly\nrelated to actions.\n  In this article, we present a novel algorithm, called iCORPP, to\nsimultaneously estimate the current world state, reason about world dynamics,\nand construct task-oriented controllers. In this process, robot decision-making\nproblems are decomposed into two interdependent (smaller) subproblems that\nfocus on reasoning to \"understand the world\" and planning to \"achieve the goal\"\nrespectively. Contextual knowledge is represented in the reasoning component,\nwhich makes the planning component epistemic and enables active information\ngathering. The developed algorithm has been implemented and evaluated both in\nsimulation and on real robots using everyday service tasks, such as indoor\nnavigation, dialog management, and object delivery. Results show significant\nimprovements in scalability, efficiency, and adaptiveness, compared to\ncompetitive baselines including handcrafted action policies.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 17:46:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Shiqi", ""], ["Stone", "Peter", ""]]}, {"id": "2004.08694", "submitter": "Kaustubh Dhole", "authors": "Kaustubh D. Dhole and Christopher D. Manning", "title": "Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation", "comments": "Some of the results in the paper were incorrect", "journal-ref": "Association for Computational Linguistics, 2020.acl-main.69", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Generation (QG) is fundamentally a simple syntactic transformation;\nhowever, many aspects of semantics influence what questions are good to form.\nWe implement this observation by developing Syn-QG, a set of transparent\nsyntactic rules leveraging universal dependencies, shallow semantic parsing,\nlexical resources, and custom rules which transform declarative sentences into\nquestion-answer pairs. We utilize PropBank argument descriptions and VerbNet\nstate predicates to incorporate shallow semantic content, which helps generate\nquestions of a descriptive nature and produce inferential and semantically\nricher questions than existing systems. In order to improve syntactic fluency\nand eliminate grammatically incorrect questions, we employ back-translation\nover the output of these syntactic rules. A set of crowd-sourced evaluations\nshows that our system can generate a larger number of highly grammatical and\nrelevant questions than previous QG systems and that back-translation\ndrastically improves grammaticality at a slight cost of generating irrelevant\nquestions.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 19:57:39 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 18:37:33 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 11:36:17 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 15:51:55 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Dhole", "Kaustubh D.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2004.08762", "submitter": "Cheng Feng", "authors": "Cheng Feng, Xiao Liang, Daniel Schneegass, PengWei Tian", "title": "RelSen: An Optimization-based Framework for Simultaneously Sensor\n  Reliability Monitoring and Data Cleaning", "comments": "accepted in CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.IR cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in the Internet of Things (IoT) technology have led to a\nsurge on the popularity of sensing applications. As a result, people\nincreasingly rely on information obtained from sensors to make decisions in\ntheir daily life. Unfortunately, in most sensing applications, sensors are\nknown to be error-prone and their measurements can become misleading at any\nunexpected time. Therefore, in order to enhance the reliability of sensing\napplications, apart from the physical phenomena/processes of interest, we\nbelieve it is also highly important to monitor the reliability of sensors and\nclean the sensor data before analysis on them being conducted. Existing studies\noften regard sensor reliability monitoring and sensor data cleaning as separate\nproblems. In this work, we propose RelSen, a novel optimization-based framework\nto address the two problems simultaneously via utilizing the mutual dependence\nbetween them. Furthermore, RelSen is not application-specific as its\nimplementation assumes a minimal prior knowledge of the process dynamics under\nmonitoring. This significantly improves its generality and applicability in\npractice. In our experiments, we apply RelSen on an outdoor air pollution\nmonitoring system and a condition monitoring system for a cement rotary kiln.\nExperimental results show that our framework can timely identify unreliable\nsensors and remove sensor measurement errors caused by three types of most\ncommonly observed sensor faults.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 03:52:25 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 09:59:10 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 13:23:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Feng", "Cheng", ""], ["Liang", "Xiao", ""], ["Schneegass", "Daniel", ""], ["Tian", "PengWei", ""]]}, {"id": "2004.08763", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Kevin Xie, Florian Shkurti", "title": "Model-Predictive Control via Cross-Entropy and Gradient-Based\n  Optimization", "comments": "L4DC 2020; Accepted for presentation in the 2nd Annual Conference on\n  Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in high-dimensional model-predictive control and model-based\nreinforcement learning with learned dynamics and reward models have resorted to\npopulation-based optimization methods, such as the Cross-Entropy Method (CEM),\nfor planning a sequence of actions. To decide on an action to take, CEM\nconducts a search for the action sequence with the highest return according to\nthe dynamics model and reward. Action sequences are typically randomly sampled\nfrom an unconditional Gaussian distribution and evaluated on the environment.\nThis distribution is iteratively updated towards action sequences with higher\nreturns. However, this planning method can be very inefficient, especially for\nhigh-dimensional action spaces. An alternative line of approaches optimize\naction sequences directly via gradient descent, but are prone to local optima.\nWe propose a method to solve this planning problem by interleaving CEM and\ngradient descent steps in optimizing the action sequence. Our experiments show\nfaster convergence of the proposed hybrid approach, even for high-dimensional\naction spaces, avoidance of local minima, and better or equal performance to\nCEM. Code accompanying the paper is available here\nhttps://github.com/homangab/gradcem.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 03:54:50 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Xie", "Kevin", ""], ["Shkurti", "Florian", ""]]}, {"id": "2004.08830", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Improving Robot Dual-System Motor Learning with Intrinsically Motivated\n  Meta-Control and Latent-Space Experience Imagination", "comments": null, "journal-ref": "Robotics and Autonomous Systems 133 (2020) 103630", "doi": "10.1016/j.robot.2020.103630", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining model-based and model-free learning systems has been shown to\nimprove the sample efficiency of learning to perform complex robotic tasks.\nHowever, dual-system approaches fail to consider the reliability of the learned\nmodel when it is applied to make multiple-step predictions, resulting in a\ncompounding of prediction errors and performance degradation. In this paper, we\npresent a novel dual-system motor learning approach where a meta-controller\narbitrates online between model-based and model-free decisions based on an\nestimate of the local reliability of the learned model. The reliability\nestimate is used in computing an intrinsic feedback signal, encouraging actions\nthat lead to data that improves the model. Our approach also integrates\narbitration with imagination where a learned latent-space model generates\nimagined experiences, based on its local reliability, to be used as additional\ntraining data. We evaluate our approach against baseline and state-of-the-art\nmethods on learning vision-based robotic grasping in simulation and real world.\nThe results show that our approach outperforms the compared methods and learns\nnear-optimal grasping policies in dense- and sparse-reward environments.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 12:14:46 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:03:29 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 09:12:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "2004.08858", "submitter": "Zarathustra Amadeus Goertzel", "authors": "Zarathustra Amadeus Goertzel", "title": "Make E Smart Again", "comments": "8 pages, 2 figures, IJCAR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work in progress, we demonstrate a new use-case for the ENIGMA\nsystem. The ENIGMA system using the XGBoost implementation of gradient boosted\ndecision trees has demonstrated high capability to learn to guide the E theorem\nprover's inferences in real-time. Here, we strip E to the bare bones: we\nreplace the KBO term ordering with an identity relation as the minimal possible\nordering, disable literal selection, and replace evolved strategies with a\nsimple combination of the clause weight and FIFO (first in first out) clause\nevaluation functions. We experimentally demonstrate that ENIGMA can learn to\nguide E as well as the smart, evolved strategies even without these standard\nautomated theorem prover functionalities. To this end, we experiment with\nXGBoost's meta-parameters over a dozen loops.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:14:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Goertzel", "Zarathustra Amadeus", ""]]}, {"id": "2004.08866", "submitter": "Marko Jankovic", "authors": "Marko Jankovic (1), Mehmed Y\\\"uksel (1), Mohammad Mohammadzadeh Babr\n  (1), Francesca Letizia (2), Vitali Braun (2) ((1) Robotics Innovation Center\n  (RIC)--DFKI GmbH and University of Bremen, (2) IMS Space Consultancy for the\n  European Space Operation Center (ESOC)--ESA)", "title": "Space Debris Ontology for ADR Capture Methods Selection", "comments": "32 pages, 7 figures and 6 tables", "journal-ref": "Acta Astronautica, Volume: 173, Year: 2020, Pages: 56-68, ISSN:\n  0094-5765", "doi": "10.1016/j.actaastro.2020.03.047", "report-no": null, "categories": "cs.AI astro-ph.IM physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies have concluded that active debris removal (ADR) of the existing\nin-orbit mass is necessary. However, the quest for an optimal solution does not\nhave a unique answer and the available data often lacks coherence. To improve\nthis situation, modern knowledge representation techniques, that have been\nshaping the World Wide Web, medicine and pharmacy, should be employed. Prior\nefforts in the domain of space debris have only focused onto space situational\nawareness, neglecting ADR. To bridge this gap we present a domain-ontology of\nintact derelict objects, i.e. payloads and rocket bodies, for ADR capture\nmethods selection. The ontology is defined on a minimal set of physical,\ndynamical and statistical parameters of a target object. The practicality and\nvalidity of the ontology are demonstrated by applying it onto a database of 30\nrepresentative objects, built by combining structured and unstructured data\nfrom publicly available sources. The analysis of results proves the ontology\ncapable of inferring the most suited ADR capture methods for considered\nobjects. Furthermore, it confirms its ability to handle the input data from\ndifferent sources transparently, minimizing user input. The developed ontology\nprovides an initial step towards a more comprehensive knowledge representation\nframework meant to improve data management and knowledge discovery in the\ndomain of space debris. Furthermore, it provides a tool that should make the\ninitial planning of future ADR missions simpler yet more systematic.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:45:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jankovic", "Marko", ""], ["Y\u00fcksel", "Mehmed", ""], ["Babr", "Mohammad Mohammadzadeh", ""], ["Letizia", "Francesca", ""], ["Braun", "Vitali", ""]]}, {"id": "2004.08892", "submitter": "Brian Jabarian", "authors": "Brian Jabarian", "title": "The Moral Burden of Ambiguity Aversion", "comments": "The original document was prepared for the PEA Soup Discussion held\n  on May, 15 2019\n  :http://peasoup.us/2019/05/ppa-discussion-thomas-rowe-and-alex-voorhoeves-egalitarianism-under-severe-uncertainty-with-critical-precis-by-brian-jabarian/", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their article, \"Egalitarianism under Severe Uncertainty\", Philosophy and\nPublic Affairs, 46:3, 2018, Thomas Rowe and Alex Voorhoeve develop an original\nmoral decision theory for cases under uncertainty, called \"pluralist\negalitarianism under uncertainty\". In this paper, I firstly sketch their views\nand arguments. I then elaborate on their moral decision theory by discussing\nhow it applies to choice scenarios in health ethics. Finally, I suggest a new\ntwo-stage Ellsberg thought experiment challenging the core of the principle of\ntheir theory. In such an experiment pluralist egalitarianism seems to suggest\nthe wrong, morally and rationally speaking, course of action -- no matter\nwhether I consider my thought experiment in a simultaneous or a sequential\nsetting.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:08:12 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 15:57:29 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Jabarian", "Brian", ""]]}, {"id": "2004.09044", "submitter": "Chi Zhang", "authors": "Yixin Zhu, Tao Gao, Lifeng Fan, Siyuan Huang, Mark Edmonds, Hangxin\n  Liu, Feng Gao, Chi Zhang, Siyuan Qi, Ying Nian Wu, Joshua B. Tenenbaum,\n  Song-Chun Zhu", "title": "Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike\n  Common Sense", "comments": "For high quality figures, please refer to\n  http://wellyzhang.github.io/attach/dark.pdf", "journal-ref": "Engineering, Feb, 2020", "doi": "10.1016/j.eng.2020.01.011", "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in deep learning is essentially based on a \"big data for\nsmall tasks\" paradigm, under which massive amounts of data are used to train a\nclassifier for a single narrow task. In this paper, we call for a shift that\nflips this paradigm upside down. Specifically, we propose a \"small data for big\ntasks\" paradigm, wherein a single artificial intelligence (AI) system is\nchallenged to develop \"common sense\", enabling it to solve a wide range of\ntasks with little training data. We illustrate the potential power of this new\nparadigm by reviewing models of common sense that synthesize recent\nbreakthroughs in both machine and human vision. We identify functionality,\nphysics, intent, causality, and utility (FPICU) as the five core domains of\ncognitive AI with humanlike common sense. When taken as a unified concept,\nFPICU is concerned with the questions of \"why\" and \"how\", beyond the dominant\n\"what\" and \"where\" framework for understanding vision. They are invisible in\nterms of pixels but nevertheless drive the creation, maintenance, and\ndevelopment of visual scenes. We therefore coin them the \"dark matter\" of\nvision. Just as our universe cannot be understood by merely studying observable\nmatter, we argue that vision cannot be understood without studying FPICU. We\ndemonstrate the power of this perspective to develop cognitive AI systems with\nhumanlike common sense by showing how to observe and apply FPICU with little\ntraining data to solve a wide range of challenging tasks, including tool use,\nplanning, utility inference, and social learning. In summary, we argue that the\nnext generation of AI must embrace \"dark\" humanlike common sense for solving\nnovel tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 04:07:28 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhu", "Yixin", ""], ["Gao", "Tao", ""], ["Fan", "Lifeng", ""], ["Huang", "Siyuan", ""], ["Edmonds", "Mark", ""], ["Liu", "Hangxin", ""], ["Gao", "Feng", ""], ["Zhang", "Chi", ""], ["Qi", "Siyuan", ""], ["Wu", "Ying Nian", ""], ["Tenenbaum", "Joshua B.", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2004.09124", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Diane Bouchacourt, Emmanuel\n  Dupoux, Marco Baroni", "title": "Compositionality and Generalization in Emergent Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language allows us to refer to novel composite concepts by combining\nexpressions denoting their parts according to systematic rules, a property\nknown as \\emph{compositionality}. In this paper, we study whether the language\nemerging in deep multi-agent simulations possesses a similar ability to refer\nto novel primitive combinations, and whether it accomplishes this feat by\nstrategies akin to human-language compositionality. Equipped with new ways to\nmeasure compositionality in emergent languages inspired by disentanglement in\nrepresentation learning, we establish three main results. First, given\nsufficiently large input spaces, the emergent language will naturally develop\nthe ability to refer to novel composite concepts. Second, there is no\ncorrelation between the degree of compositionality of an emergent language and\nits ability to generalize. Third, while compositionality is not necessary for\ngeneralization, it provides an advantage in terms of language transmission: The\nmore compositional a language is, the more easily it will be picked up by new\nlearners, even when the latter differ in architecture from the original agents.\nWe conclude that compositionality does not arise from simple generalization\npressure, but if an emergent language does chance upon it, it will be more\nlikely to survive and thrive.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:30:14 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Bouchacourt", "Diane", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "2004.09134", "submitter": "Florenc Demrozi Dr.", "authors": "Florenc Demrozi, Graziano Pravadelli, Patrick J Tighe, Azra Bihorac\n  and Parisa Rashidi", "title": "Joint Distribution and Transitions of Pain and Activity in Critically\n  Ill Patients", "comments": "Accepted for Publication in EMBC 2020", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9176453", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain and physical function are both essential indices of recovery in\ncritically ill patients in the Intensive Care Units (ICU). Simultaneous\nmonitoring of pain intensity and patient activity can be important for\ndetermining which analgesic interventions can optimize mobility and function,\nwhile minimizing opioid harm. Nonetheless, so far, our knowledge of the\nrelation between pain and activity has been limited to manual and sporadic\nactivity assessments. In recent years, wearable devices equipped with 3-axis\naccelerometers have been used in many domains to provide a continuous and\nautomated measure of mobility and physical activity. In this study, we\ncollected activity intensity data from 57 ICU patients, using the Actigraph\nGT3X device. We also collected relevant clinical information, including nurse\nassessments of pain intensity, recorded every 1-4 hours. Our results show the\njoint distribution and state transition of joint activity and pain states in\ncritically ill patients.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:56:13 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Demrozi", "Florenc", ""], ["Pravadelli", "Graziano", ""], ["Tighe", "Patrick J", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.09141", "submitter": "Jimmy Wu", "authors": "Jimmy Wu, Xingyuan Sun, Andy Zeng, Shuran Song, Johnny Lee, Szymon\n  Rusinkiewicz, Thomas Funkhouser", "title": "Spatial Action Maps for Mobile Manipulation", "comments": "To appear at Robotics: Science and Systems (RSS), 2020. Project page:\n  https://spatial-action-maps.cs.princeton.edu", "journal-ref": null, "doi": "10.15607/RSS.2020.XVI.035", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical end-to-end formulations for learning robotic navigation involve\npredicting a small set of steering command actions (e.g., step forward, turn\nleft, turn right, etc.) from images of the current state (e.g., a bird's-eye\nview of a SLAM reconstruction). Instead, we show that it can be advantageous to\nlearn with dense action representations defined in the same domain as the\nstate. In this work, we present \"spatial action maps,\" in which the set of\npossible actions is represented by a pixel map (aligned with the input image of\nthe current state), where each pixel represents a local navigational endpoint\nat the corresponding scene location. Using ConvNets to infer spatial action\nmaps from state images, action predictions are thereby spatially anchored on\nlocal visual features in the scene, enabling significantly faster learning of\ncomplex behaviors for mobile manipulation tasks with reinforcement learning. In\nour experiments, we task a robot with pushing objects to a goal location, and\nfind that policies learned with spatial action maps achieve much better\nperformance than traditional alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:06:10 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 10:56:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wu", "Jimmy", ""], ["Sun", "Xingyuan", ""], ["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Lee", "Johnny", ""], ["Rusinkiewicz", "Szymon", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "2004.09218", "submitter": "Jens Nevens", "authors": "Jens Nevens and Paul Van Eecke and Katrien Beuls", "title": "A Practical Guide to Studying Emergent Communication through Grounded\n  Language Games", "comments": "This paper was officially published at the 'Language Learning for\n  Artificial Agents (L2A2) Symposium' of the 2019 Artificial Intelligence and\n  Simulation of Behaviour (AISB) Convention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how an effective and efficient communication system can\nemerge in a population of agents that need to solve a particular task attracts\nmore and more attention from researchers in many fields, including artificial\nintelligence, linguistics and statistical physics. A common methodology for\nstudying this question consists of carrying out multi-agent experiments in\nwhich a population of agents takes part in a series of scripted and\ntask-oriented communicative interactions, called 'language games'. While each\nindividual language game is typically played by two agents in the population, a\nlarge series of games allows the population to converge on a shared\ncommunication system. Setting up an experiment in which a rich system for\ncommunicating about the real world emerges is a major enterprise, as it\nrequires a variety of software components for running multi-agent experiments,\nfor interacting with sensors and actuators, for conceptualising and\ninterpreting semantic structures, and for mapping between these semantic\nstructures and linguistic utterances. The aim of this paper is twofold. On the\none hand, it introduces a high-level robot interface that extends the Babel\nsoftware system, presenting for the first time a toolkit that provides flexible\nmodules for dealing with each subtask involved in running advanced grounded\nlanguage game experiments. On the other hand, it provides a practical guide to\nusing the toolkit for implementing such experiments, taking a grounded colour\nnaming game experiment as a didactic example.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:48:24 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Nevens", "Jens", ""], ["Van Eecke", "Paul", ""], ["Beuls", "Katrien", ""]]}, {"id": "2004.09287", "submitter": "Hamed Rahimi", "authors": "Hamed Rahimi and Dhayananth Dharmalingam", "title": "Road Quality Analysis Based on Cognitive Internet of Vehicles (CIoV)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposal aims to use cognitive methods to analyze the quality\nof roads based on the new proposed technology called Cognitive Internet of\nVehicles (CIoV). By using Big Data corresponding to the collected data of\nautonomous vehicles, we can apply cognitive analytics to a huge amount of\ntransportation data. This process can help us to create valuable information\nsuch as road quality from an immense volume of meaningless data. In this\nproposal, we are going to focus on the quality of roads for various business\nand commercial purposes. The proposed system can be used as an additional\nservice of autonomous car companies or as a mobile application for ordinary\nusages. As a result, this system can reduce the usage of resources such as\nenergy consumption of autonomous vehicles. Moreover, this technology benefits\nthe next-generation of self-driving applications to improve their QoS.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 09:59:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rahimi", "Hamed", ""], ["Dharmalingam", "Dhayananth", ""]]}, {"id": "2004.09312", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Tobias Uhlig, Gabi Dreo Rodosek, Oliver Rose", "title": "A Novel Multi-Agent System for Complex Scheduling Problems", "comments": null, "journal-ref": "Winter Simulation Conference 2014", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex scheduling problems require a large amount computation power and\ninnovative solution methods. The objective of this paper is the conception and\nimplementation of a multi-agent system that is applicable in various problem\ndomains. Independent specialized agents handle small tasks, to reach a\nsuperordinate target. Effective coordination is therefore required to achieve\nproductive cooperation. Role models and distributed artificial intelligence are\nemployed to tackle the resulting challenges. We simulate a NP-hard scheduling\nproblem to demonstrate the validity of our approach. In addition to the general\nagent based framework we propose new simulation-based optimization heuristics\nto given scheduling problems. Two of the described optimization algorithms are\nimplemented using agents. This paper highlights the advantages of the\nagent-based approach, like the reduction in layout complexity, improved control\nof complicated systems, and extendability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:04:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hillmann", "Peter", ""], ["Uhlig", "Tobias", ""], ["Rodosek", "Gabi Dreo", ""], ["Rose", "Oliver", ""]]}, {"id": "2004.09392", "submitter": "WaiChing Sun", "authors": "Kun Wang, WaiChing Sun, Qiang Du", "title": "A non-cooperative meta-modeling game for automated third-party\n  calibrating, validating, and falsifying constitutive laws with parallelized\n  adversarial attacks", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113514", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evaluation of constitutive models, especially for high-risk and\nhigh-regret engineering applications, requires efficient and rigorous\nthird-party calibration, validation and falsification. While there are numerous\nefforts to develop paradigms and standard procedures to validate models,\ndifficulties may arise due to the sequential, manual and often biased nature of\nthe commonly adopted calibration and validation processes, thus slowing down\ndata collections, hampering the progress towards discovering new physics,\nincreasing expenses and possibly leading to misinterpretations of the\ncredibility and application ranges of proposed models. This work attempts to\nintroduce concepts from game theory and machine learning techniques to overcome\nmany of these existing difficulties. We introduce an automated meta-modeling\ngame where two competing AI agents systematically generate experimental data to\ncalibrate a given constitutive model and to explore its weakness, in order to\nimprove experiment design and model robustness through competition. The two\nagents automatically search for the Nash equilibrium of the meta-modeling game\nin an adversarial reinforcement learning framework without human intervention.\nBy capturing all possible design options of the laboratory experiments into a\nsingle decision tree, we recast the design of experiments as a game of\ncombinatorial moves that can be resolved through deep reinforcement learning by\nthe two competing players. Our adversarial framework emulates idealized\nscientific collaborations and competitions among researchers to achieve a\nbetter understanding of the application range of the learned material laws and\nprevent misinterpretations caused by conventional AI-based third-party\nvalidation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:43:28 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Kun", ""], ["Sun", "WaiChing", ""], ["Du", "Qiang", ""]]}, {"id": "2004.09406", "submitter": "Christina Funke", "authors": "Christina M. Funke, Judy Borowski, Karolina Stosio, Wieland Brendel,\n  Thomas S. A. Wallis, Matthias Bethge", "title": "Five Points to Check when Comparing Visual Perception in Humans and\n  Machines", "comments": "V3: minor changes like in published JOV version\n  (https://doi.org/10.1167/jov.21.3.16) V2: New title; added general section\n  (checklist); manuscript restructured such that each case study is one\n  chapter; adversarial examples in first study replaced by different analysis", "journal-ref": "Journal of Vision 21, no. 3 (2021): 16-16", "doi": "10.1167/jov.21.3.16", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of machines to human-level performance in complex recognition\ntasks, a growing amount of work is directed towards comparing information\nprocessing in humans and machines. These studies are an exciting chance to\nlearn about one system by studying the other. Here, we propose ideas on how to\ndesign, conduct and interpret experiments such that they adequately support the\ninvestigation of mechanisms when comparing human and machine perception. We\ndemonstrate and apply these ideas through three case studies. The first case\nstudy shows how human bias can affect how we interpret results, and that\nseveral analytic tools can help to overcome this human reference point. In the\nsecond case study, we highlight the difference between necessary and sufficient\nmechanisms in visual reasoning tasks. Thereby, we show that contrary to\nprevious suggestions, feedback mechanisms might not be necessary for the tasks\nin question. The third case study highlights the importance of aligning\nexperimental conditions. We find that a previously-observed difference in\nobject recognition does not hold when adapting the experiment to make\nconditions more equitable between humans and machines. In presenting a\nchecklist for comparative studies of visual reasoning in humans and machines,\nwe hope to highlight how to overcome potential pitfalls in design or inference.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:05:36 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 08:37:22 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 16:03:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Funke", "Christina M.", ""], ["Borowski", "Judy", ""], ["Stosio", "Karolina", ""], ["Brendel", "Wieland", ""], ["Wallis", "Thomas S. A.", ""], ["Bethge", "Matthias", ""]]}, {"id": "2004.09456", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Anna Bethke, Siva Reddy", "title": "StereoSet: Measuring stereotypical bias in pretrained language models", "comments": "9 pages, 6 tables, and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A stereotype is an over-generalized belief about a particular group of\npeople, e.g., Asians are good at math or Asians are bad drivers. Such beliefs\n(biases) are known to hurt target groups. Since pretrained language models are\ntrained on large real world data, they are known to capture stereotypical\nbiases. In order to assess the adverse effects of these models, it is important\nto quantify the bias captured in them. Existing literature on quantifying bias\nevaluates pretrained language models on a small set of artificially constructed\nbias-assessing sentences. We present StereoSet, a large-scale natural dataset\nin English to measure stereotypical biases in four domains: gender, profession,\nrace, and religion. We evaluate popular models like BERT, GPT-2, RoBERTa, and\nXLNet on our dataset and show that these models exhibit strong stereotypical\nbiases. We also present a leaderboard with a hidden test set to track the bias\nof future language models at https://stereoset.mit.edu\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:14:33 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Nadeem", "Moin", ""], ["Bethke", "Anna", ""], ["Reddy", "Siva", ""]]}, {"id": "2004.09473", "submitter": "Haiguang Liao", "authors": "Haiguang Liao, Qingyi Dong, Xuliang Dong, Wentai Zhang, Wangyang\n  Zhang, Weiyi Qi, Elias Fallon, Levent Burak Kara", "title": "Attention Routing: track-assignment detailed routing using\n  attention-based reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the physical design of integrated circuits, global and detailed routing\nare critical stages involving the determination of the interconnected paths of\neach net on a circuit while satisfying the design constraints. Existing actual\nrouters as well as routability predictors either have to resort to expensive\napproaches that lead to high computational times, or use heuristics that do not\ngeneralize well. Even though new, learning-based routing methods have been\nproposed to address this need, requirements on labelled data and difficulties\nin addressing complex design rule constraints have limited their adoption in\nadvanced technology node physical design problems. In this work, we propose a\nnew router: attention router, which is the first attempt to solve the\ntrack-assignment detailed routing problem using reinforcement learning. Complex\ndesign rule constraints are encoded into the routing algorithm and an\nattention-model-based REINFORCE algorithm is applied to solve the most critical\nstep in routing: sequencing device pairs to be routed. The attention router and\nits baseline genetic router are applied to solve different commercial advanced\ntechnologies analog circuits problem sets. The attention router demonstrates\ngeneralization ability to unseen problems and is also able to achieve more than\n100 times acceleration over the genetic router without significantly\ncompromising the routing solution quality. We also discover a similarity\nbetween the attention router and the baseline genetic router in terms of\npositive correlations in cost and routing patterns, which demonstrate the\nattention router's ability to be utilized not only as a detailed router but\nalso as a predictor for routability and congestion.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:50:13 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:44:33 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Liao", "Haiguang", ""], ["Dong", "Qingyi", ""], ["Dong", "Xuliang", ""], ["Zhang", "Wentai", ""], ["Zhang", "Wangyang", ""], ["Qi", "Weiyi", ""], ["Fallon", "Elias", ""], ["Kara", "Levent Burak", ""]]}, {"id": "2004.09507", "submitter": "Antonio Lieto", "authors": "Laura Giordano, Valentina Gliozzi, Antonio Lieto, Nicola Olivetti,\n  Gian Luca Pozzato", "title": "Reasoning about Typicality and Probabilities in Preferential Description\n  Logics", "comments": "17 pages. arXiv admin note: text overlap with arXiv:1811.02366", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe preferential Description Logics of typicality, a\nnonmonotonic extension of standard Description Logics by means of a typicality\noperator T allowing to extend a knowledge base with inclusions of the form T(C)\nv D, whose intuitive meaning is that normally/typically Cs are also Ds. This\nextension is based on a minimal model semantics corresponding to a notion of\nrational closure, built upon preferential models. We recall the basic concepts\nunderlying preferential Description Logics. We also present two extensions of\nthe preferential semantics: on the one hand, we consider probabilistic\nextensions, based on a distributed semantics that is suitable for tackling the\nproblem of commonsense concept combination, on the other hand, we consider\nother strengthening of the rational closure semantics and construction to avoid\nthe so-called blocking of property inheritance problem.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:50:31 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 16:15:31 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""], ["Lieto", "Antonio", ""], ["Olivetti", "Nicola", ""], ["Pozzato", "Gian Luca", ""]]}, {"id": "2004.09524", "submitter": "Asad Khan", "authors": "Asad Khan, E. A. Huerta, Arnav Das", "title": "Physics-inspired deep learning to characterize the signal manifold of\n  quasi-circular, spinning, non-precessing binary black hole mergers", "comments": "25 pages, 12 figures, 1 appendix, 1 Interactive visualization at\n  https://khanx169.github.io/smr_bbm_v2/interactive_results.html", "journal-ref": "Physics Letters B 808 (2020) 0370-2693", "doi": "10.1016/j.physletb.2020.135628", "report-no": null, "categories": "gr-qc astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spin distribution of binary black hole mergers contains key information\nconcerning the formation channels of these objects, and the astrophysical\nenvironments where they form, evolve and coalesce. To quantify the suitability\nof deep learning to characterize the signal manifold of quasi-circular,\nspinning, non-precessing binary black hole mergers, we introduce a modified\nversion of WaveNet trained with a novel optimization scheme that incorporates\ngeneral relativistic constraints of the spin properties of astrophysical black\nholes. The neural network model is trained, validated and tested with 1.5\nmillion $\\ell=|m|=2$ waveforms generated within the regime of validity of\nNRHybSur3dq8, i.e., mass-ratios $q\\leq8$ and individual black hole spins $ |\ns^z_{\\{1,\\,2\\}} | \\leq 0.8$. Using this neural network model, we quantify how\naccurately we can infer the astrophysical parameters of black hole mergers in\nthe absence of noise. We do this by computing the overlap between waveforms in\nthe testing data set and the corresponding signals whose mass-ratio and\nindividual spins are predicted by our neural network. We find that the\nconvergence of high performance computing and physics-inspired optimization\nalgorithms enable an accurate reconstruction of the mass-ratio and individual\nspins of binary black hole mergers across the parameter space under\nconsideration. This is a significant step towards an informed utilization of\nphysics-inspired deep learning models to reconstruct the spin distribution of\nbinary black hole mergers in realistic detection scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:00:02 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 22:07:41 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Khan", "Asad", ""], ["Huerta", "E. A.", ""], ["Das", "Arnav", ""]]}, {"id": "2004.09551", "submitter": "Nabeel Gillani", "authors": "Eric Chu, Nabeel Gillani, Sneha Priscilla Makini", "title": "Games for Fairness and Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Machine Learning (ML) systems becomes more ubiquitous, ensuring the fair\nand equitable application of their underlying algorithms is of paramount\nimportance. We argue that one way to achieve this is to proactively cultivate\npublic pressure for ML developers to design and develop fairer algorithms --\nand that one way to cultivate public pressure while simultaneously serving the\ninterests and objectives of algorithm developers is through gameplay. We\npropose a new class of games -- ``games for fairness and interpretability'' --\nas one example of an incentive-aligned approach for producing fairer and more\nequitable algorithms. Games for fairness and interpretability are\ncarefully-designed games with mass appeal. They are inherently engaging,\nprovide insights into how machine learning models work, and ultimately produce\ndata that helps researchers and developers improve their algorithms. We\nhighlight several possible examples of games, their implications for fairness\nand interpretability, how their proliferation could creative positive public\npressure by narrowing the gap between algorithm developers and the general\npublic, and why the machine learning community could benefit from them.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:09:32 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chu", "Eric", ""], ["Gillani", "Nabeel", ""], ["Makini", "Sneha Priscilla", ""]]}, {"id": "2004.09685", "submitter": "Jon McCormack", "authors": "Nina Rajcic and Jon McCormack", "title": "Mirror Ritual: An Affective Interface for Emotional Self-Reflection", "comments": "Paper presented at ACM CHI2020: Proceedings of the 2020 CHI\n  Conference on Human Factors in Computing Systems, ACM, New York, April 2020", "journal-ref": null, "doi": "10.1145/3313831.3376625", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new form of real-time affective interface that\nengages the user in a process of conceptualisation of their emotional state.\nInspired by Barrett's Theory of Constructed Emotion, `Mirror Ritual' aims to\nexpand upon the user's accessible emotion concepts, and to ultimately provoke\nemotional reflection and regulation. The interface uses classified emotions --\nobtained through facial expression recognition -- as a basis for dynamically\ngenerating poetry. The perceived emotion is used to seed a poetry generation\nsystem based on OpenAI's GPT-2 model, fine-tuned on a specially curated corpus.\nWe evaluate the device's ability to foster a personalised, meaningful\nexperience for individual users over a sustained period. A qualitative analysis\nrevealed that participants were able to affectively engage with the mirror,\nwith each participant developing a unique interpretation of its poetry in the\ncontext of their own emotional landscape.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 00:19:59 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Rajcic", "Nina", ""], ["McCormack", "Jon", ""]]}, {"id": "2004.09703", "submitter": "Will Zou", "authors": "Will Y. Zou, Smitha Shyam, Michael Mui, Mingshi Wang, Jan Pedersen,\n  Zoubin Ghahramani", "title": "Learning Continuous Treatment Policy and Bipartite Embeddings for\n  Matching with Heterogeneous Causal Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Causal inference methods are widely applied in the fields of medicine,\npolicy, and economics. Central to these applications is the estimation of\ntreatment effects to make decisions. Current methods make binary yes-or-no\ndecisions based on the treatment effect of a single outcome dimension. These\nmethods are unable to capture continuous space treatment policies with a\nmeasure of intensity. They also lack the capacity to consider the complexity of\ntreatment such as matching candidate treatments with the subject. We propose to\nformulate the effectiveness of treatment as a parametrizable model, expanding\nto a multitude of treatment intensities and complexities through the continuous\npolicy treatment function, and the likelihood of matching. Our proposal to\ndecompose treatment effect functions into effectiveness factors presents a\nframework to model a rich space of actions using causal inference. We utilize\ndeep learning to optimize the desired holistic metric space instead of\npredicting single-dimensional treatment counterfactual. This approach employs a\npopulation-wide effectiveness measure and significantly improves the overall\neffectiveness of the model. The performance of our algorithms is. demonstrated\nwith experiments. When using generic continuous space treatments and matching\narchitecture, we observe a 41% improvement upon prior art with\ncost-effectiveness and 68% improvement upon a similar method in the average\ntreatment effect. The algorithms capture subtle variations in treatment space,\nstructures the efficient optimizations techniques, and opens up the arena for\nmany applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:36:20 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zou", "Will Y.", ""], ["Shyam", "Smitha", ""], ["Mui", "Michael", ""], ["Wang", "Mingshi", ""], ["Pedersen", "Jan", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2004.09705", "submitter": "Wei Shiung Liew Mr", "authors": "Fatai Sado, Chu Kiong Loo, Wei Shiung Liew, Matthias Kerzel, Stefan\n  Wermter", "title": "Explainable Goal-Driven Agents and Robots -- A Comprehensive Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent applications of autonomous agents and robots, such as self-driving\ncars, scenario-based trainers, exploration robots, and service robots have\nbrought attention to crucial trust-related challenges associated with the\ncurrent generation of artificial intelligence (AI) systems. AI systems based on\nthe connectionist deep learning neural network approach lack capabilities of\nexplaining their decisions and actions to others, despite their great\nsuccesses. Without symbolic interpretation capabilities, they are black boxes,\nwhich renders their decisions or actions opaque, making it difficult to trust\nthem in safety-critical applications. The recent stance on the explainability\nof AI systems has witnessed several approaches on eXplainable Artificial\nIntelligence (XAI); however, most of the studies have focused on data-driven\nXAI systems applied in computational sciences. Studies addressing the\nincreasingly pervasive goal-driven agents and robots are still missing. This\npaper reviews approaches on explainable goal-driven intelligent agents and\nrobots, focusing on techniques for explaining and communicating agents\nperceptual functions (example, senses, and vision) and cognitive reasoning\n(example, beliefs, desires, intention, plans, and goals) with humans in the\nloop. The review highlights key strategies that emphasize transparency,\nunderstandability, and continual learning for explainability. Finally, the\npaper presents requirements for explainability and suggests a roadmap for the\npossible realization of effective goal-driven explainable agents and robots.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:41:20 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 09:29:31 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 03:28:25 GMT"}, {"version": "v4", "created": "Sat, 10 Apr 2021 06:55:15 GMT"}, {"version": "v5", "created": "Thu, 22 Jul 2021 13:08:01 GMT"}, {"version": "v6", "created": "Wed, 28 Jul 2021 07:35:10 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sado", "Fatai", ""], ["Loo", "Chu Kiong", ""], ["Liew", "Wei Shiung", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "2004.09846", "submitter": "Richa Verma", "authors": "Somjit Nath, Richa Verma, Abhik Ray, Harshad Khadilkar", "title": "SIBRE: Self Improvement Based REwards for Adaptive Feedback in\n  Reinforcement Learning", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a generic reward shaping approach for improving the rate of\nconvergence in reinforcement learning (RL), called Self Improvement Based\nREwards, or SIBRE. The approach is designed for use in conjunction with any\nexisting RL algorithm, and consists of rewarding improvement over the agent's\nown past performance. We prove that SIBRE converges in expectation under the\nsame conditions as the original RL algorithm. The reshaped rewards help\ndiscriminate between policies when the original rewards are weakly\ndiscriminated or sparse. Experiments on several well-known benchmark\nenvironments with different RL algorithms show that SIBRE converges to the\noptimal policy faster and more stably. We also perform sensitivity analysis\nwith respect to hyper-parameters, in comparison with baseline RL algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:22:16 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 04:27:49 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 10:08:03 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Nath", "Somjit", ""], ["Verma", "Richa", ""], ["Ray", "Abhik", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2004.09853", "submitter": "Siyu Ren", "authors": "Siyu Ren, Kenny Q. Zhu", "title": "Knowledge-Driven Distractor Generation for Cloze-style Multiple Choice\n  Questions", "comments": "To appear at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel configurable framework to automatically\ngenerate distractive choices for open-domain cloze-style multiple-choice\nquestions, which incorporates a general-purpose knowledge base to effectively\ncreate a small distractor candidate set, and a feature-rich learning-to-rank\nmodel to select distractors that are both plausible and reliable. Experimental\nresults on datasets across four domains show that our framework yields\ndistractors that are more plausible and reliable than previous methods. This\ndataset can also be used as a benchmark for distractor generation in the\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:29:50 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 13:24:20 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 01:53:44 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ren", "Siyu", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2004.09855", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Sebastijan Duman\\v{c}i\\'c", "title": "Learning large logic programs by going beyond entailment", "comments": "IJCAI2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in inductive logic programming (ILP) is learning large\nprograms. We argue that a key limitation of existing systems is that they use\nentailment to guide the hypothesis search. This approach is limited because\nentailment is a binary decision: a hypothesis either entails an example or does\nnot, and there is no intermediate position. To address this limitation, we go\nbeyond entailment and use \\emph{example-dependent} loss functions to guide the\nsearch, where a hypothesis can partially cover an example. We implement our\nidea in Brute, a new ILP system which uses best-first search, guided by an\nexample-dependent loss function, to incrementally build programs. Our\nexperiments on three diverse program synthesis domains (robot planning, string\ntransformations, and ASCII art), show that Brute can substantially outperform\nexisting ILP systems, both in terms of predictive accuracies and learning\ntimes, and can learn programs 20 times larger than state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:31:06 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 09:11:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""]]}, {"id": "2004.09931", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic and Tias Guns and Andrew Cropper", "title": "Knowledge Refactoring for Inductive Program Synthesis", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans constantly restructure knowledge to use it more efficiently. Our goal\nis to give a machine learning system similar abilities so that it can learn\nmore efficiently. We introduce the \\textit{knowledge refactoring} problem,\nwhere the goal is to restructure a learner's knowledge base to reduce its size\nand to minimise redundancy in it. We focus on inductive logic programming,\nwhere the knowledge base is a logic program. We introduce Knorf, a system which\nsolves the refactoring problem using constraint optimisation. We evaluate our\napproach on two program induction domains: real-world string transformations\nand building Lego structures. Our experiments show that learning from\nrefactored knowledge can improve predictive accuracies fourfold and reduce\nlearning times by half.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:04:38 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:19:22 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 08:23:31 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Guns", "Tias", ""], ["Cropper", "Andrew", ""]]}, {"id": "2004.09957", "submitter": "Jason Rhuggenaath", "authors": "Jason Rhuggenaath, Alp Akcay, Yingqian Zhang and Uzay Kaymak", "title": "Algorithms for slate bandits with non-separable reward functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a slate bandit problem where the function that\ndetermines the slate-level reward is non-separable: the optimal value of the\nfunction cannot be determined by learning the optimal action for each slot. We\nare mainly concerned with cases where the number of slates is large relative to\nthe time horizon, so that trying each slate as a separate arm in a traditional\nmulti-armed bandit, would not be feasible. Our main contribution is the design\nof algorithms that still have sub-linear regret with respect to the time\nhorizon, despite the large number of slates. Experimental results on simulated\ndata and real-world data show that our proposed method outperforms popular\nbenchmark bandit algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:45:02 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Rhuggenaath", "Jason", ""], ["Akcay", "Alp", ""], ["Zhang", "Yingqian", ""], ["Kaymak", "Uzay", ""]]}, {"id": "2004.09969", "submitter": "Javier Del Ser Dr.", "authors": "Antonio LaTorre, Daniel Molina, Eneko Osaba, Javier Del Ser, Francisco\n  Herrera", "title": "Fairness in Bio-inspired Optimization Research: A Prescription of\n  Methodological Guidelines for Comparing Meta-heuristics", "comments": "43 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired optimization (including Evolutionary Computation and Swarm\nIntelligence) is a growing research topic with many competitive bio-inspired\nalgorithms being proposed every year. In such an active area, preparing a\nsuccessful proposal of a new bio-inspired algorithm is not an easy task. Given\nthe maturity of this research field, proposing a new optimization technique\nwith innovative elements is no longer enough. Apart from the novelty, results\nreported by the authors should be proven to achieve a significant advance over\nprevious outcomes from the state of the art. Unfortunately, not all new\nproposals deal with this requirement properly. Some of them fail to select an\nappropriate benchmark or reference algorithms to compare with. In other cases,\nthe validation process carried out is not defined in a principled way (or is\neven not done at all). Consequently, the significance of the results presented\nin such studies cannot be guaranteed. In this work we review several\nrecommendations in the literature and propose methodological guidelines to\nprepare a successful proposal, taking all these issues into account. We expect\nthese guidelines to be useful not only for authors, but also for reviewers and\neditors along their assessment of new contributions to the field.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 04:46:45 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["LaTorre", "Antonio", ""], ["Molina", "Daniel", ""], ["Osaba", "Eneko", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2004.09986", "submitter": "Daniel Leite", "authors": "Daniel Leite, Leticia Decker, Marcio Santana, Paulo Souza", "title": "EGFC: Evolving Gaussian Fuzzy Classifier from Never-Ending\n  Semi-Supervised Data Streams -- With Application to Power Quality Disturbance\n  Detection and Classification", "comments": "10 pages, 6 figures, 1 table, IEEE International Conference on Fuzzy\n  Systems (FUZZ-IEEE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-quality disturbances lead to several drawbacks such as limitation of\nthe production capacity, increased line and equipment currents, and consequent\nohmic losses; higher operating temperatures, premature faults, reduction of\nlife expectancy of machines, malfunction of equipment, and unplanned outages.\nReal-time detection and classification of disturbances are deemed essential to\nindustry standards. We propose an Evolving Gaussian Fuzzy Classification (EGFC)\nframework for semi-supervised disturbance detection and classification combined\nwith a hybrid Hodrick-Prescott and Discrete-Fourier-Transform\nattribute-extraction method applied over a landmark window of voltage\nwaveforms. Disturbances such as spikes, notching, harmonics, and oscillatory\ntransient are considered. Different from other monitoring systems, which\nrequire offline training of models based on a limited amount of data and\noccurrences, the proposed online data-stream-based EGFC method is able to learn\ndisturbance patterns autonomously from never-ending data streams by adapting\nthe parameters and structure of a fuzzy rule base on the fly. Moreover, the\nfuzzy model obtained is linguistically interpretable, which improves model\nacceptability. We show encouraging classification results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:08:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Leite", "Daniel", ""], ["Decker", "Leticia", ""], ["Santana", "Marcio", ""], ["Souza", "Paulo", ""]]}, {"id": "2004.09990", "submitter": "Alexander Martin Mussgnug", "authors": "Alexander M. Mussgnug", "title": "A Philosophy of Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that while this discourse on data ethics is of critical importance,\nit is missing one fundamental point: If more and more efforts in business,\ngovernment, science, and our daily lives are data-driven, we should pay more\nattention to what exactly we are driven by. Therefore, we need more debate on\nwhat fundamental properties constitute data. In the first section of the paper,\nwe work from the fundamental properties necessary for statistical computation\nto a definition of statistical data. We define a statistical datum as the\ncoming together of substantive and numerical properties and differentiate\nbetween qualitative and quantitative data. Subsequently, we qualify our\ndefinition by arguing that for data to be practically useful, it needs to be\ncommensurable in a manner that reveals meaningful differences that allow for\nthe generation of relevant insights through statistical methodologies. In the\nsecond section, we focus on what our conception of data can contribute to the\ndiscourse on data ethics and beyond. First, we hold that the need for useful\ndata to be commensurable rules out an understanding of properties as\nfundamentally unique or equal. Second, we argue that practical concerns lead us\nto increasingly standardize how we operationalize a substantive property; in\nother words, how we formalize the relationship between the substantive and\nnumerical properties of data. Thereby, we also standardize the interpretation\nof a property. With our increasing reliance on data and data technologies,\nthese two characteristics of data affect our collective conception of reality.\nStatistical data's exclusion of the fundamentally unique and equal influences\nour perspective on the world, and the standardization of substantive properties\ncan be viewed as profound ontological practice, entrenching ever more pervasive\ninterpretations of phenomena in our everyday lives.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 14:47:24 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 12:36:57 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Mussgnug", "Alexander M.", ""]]}, {"id": "2004.09999", "submitter": "R\\'emy Tuy\\'eras", "authors": "R\\'emy Tuy\\'eras", "title": "A category theoretical argument for causal inference", "comments": "48 pages, 1 figure; v2: typos corrected and clarifications linking\n  the results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI math.AG math.CT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to design a causal inference method accounting for\ncomplex interactions between causal factors. The proposed method relies on a\ncategory theoretical reformulation of the definitions of dependent variables,\nindependent variables and latent variables in terms of products and arrows in\nthe category of unlabeled partitions. Throughout the paper, we demonstrate how\nthe proposed method accounts for possible hidden variables, such as\nenvironmental variables or noise, and how it can be interpreted statistically\nin terms of $p$-values. This interpretation, from category theory to\nstatistics, is implemented through a collection of propositions highlighting\nthe functorial properties of ANOVA. We use these properties in combination with\nour category theoretical framework to provide solutions to causal inference\nproblems with both sound algebraic and statistical properties. As an\napplication, we show how the proposed method can be used to design a\ncombinatorial genome-wide association algorithm for the field of genetics.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 05:48:46 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 21:43:32 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tuy\u00e9ras", "R\u00e9my", ""]]}, {"id": "2004.10014", "submitter": "Weizi Li", "authors": "Weizi Li and Jan M. Allbeck", "title": "Imperatives for Virtual Humans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Seemingly since the inception of virtual humans, there has been an effort to\nmake their behaviors more natural and human-like. In additions to improving\nmovement's visual quality, there has been considerable research focused on\ncreating more intelligent virtual characters. This paper presents a framework\ninspired by natural language constructs that aims to author more reasonable\nvirtual human behaviors using structured English input. We focus mainly on\nobject types and properties, quantifiers, determiners, and spatial relations.\nThe framework provides a natural, flexible authoring system for simulating\nhuman behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 12:47:15 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Weizi", ""], ["Allbeck", "Jan M.", ""]]}, {"id": "2004.10030", "submitter": "Marie-Laure Mugnier", "authors": "Stathis Delivorias, Michel Lecl\\`ere, Marie-Laure Mugnier, Federico\n  Ulliana", "title": "Characterizing Boundedness in Chase Variants", "comments": "Under consideration for publication in Theory and Practice of Logic\n  Programming", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 51-79", "doi": "10.1017/S1471068420000083", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules are a positive fragment of first-order logic that\ngeneralizes function-free Horn rules by allowing existentially quantified\nvariables in rule heads. This family of languages has recently attracted\nsignificant interest in the context of ontology-mediated query answering.\nForward chaining, also known as the chase, is a fundamental tool for computing\nuniversal models of knowledge bases, which consist of existential rules and\nfacts. Several chase variants have been defined, which differ on the way they\nhandle redundancies. A set of existential rules is bounded if it ensures the\nexistence of a bound on the depth of the chase, independently from any set of\nfacts. Deciding if a set of rules is bounded is an undecidable problem for all\nchase variants. Nevertheless, when computing universal models, knowing that a\nset of rules is bounded for some chase variant does not help much in practice\nif the bound remains unknown or even very large. Hence, we investigate the\ndecidability of the k-boundedness problem, which asks whether the depth of the\nchase for a given set of rules is bounded by an integer k. We identify a\ngeneral property which, when satisfied by a chase variant, leads to the\ndecidability of k-boundedness. We then show that the main chase variants\nsatisfy this property, namely the oblivious, semi-oblivious (aka Skolem), and\nrestricted chase, as well as their breadth-first versions. This paper is under\nconsideration for publication in Theory and Practice of Logic Programming.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:07:10 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Delivorias", "Stathis", ""], ["Lecl\u00e8re", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Ulliana", "Federico", ""]]}, {"id": "2004.10037", "submitter": "Jing Zhang", "authors": "Yanhui Peng and Jing Zhang", "title": "LineaRE: Simple but Powerful Knowledge Graph Embedding for Link\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of link prediction for knowledge graphs is to predict missing\nrelationships between entities. Knowledge graph embedding, which aims to\nrepresent entities and relations of a knowledge graph as low dimensional\nvectors in a continuous vector space, has achieved promising predictive\nperformance. If an embedding model can cover different types of connectivity\npatterns and mapping properties of relations as many as possible, it will\npotentially bring more benefits for link prediction tasks. In this paper, we\npropose a novel embedding model, namely LineaRE, which is capable of modeling\nfour connectivity patterns (i.e., symmetry, antisymmetry, inversion, and\ncomposition) and four mapping properties (i.e., one-to-one, one-to-many,\nmany-to-one, and many-to-many) of relations. Specifically, we regard knowledge\ngraph embedding as a simple linear regression task, where a relation is modeled\nas a linear function of two low-dimensional vector-presented entities with two\nweight vectors and a bias vector. Since the vectors are defined in a real\nnumber space and the scoring function of the model is linear, our model is\nsimple and scalable to large knowledge graphs. Experimental results on multiple\nwidely used real-world datasets show that the proposed LineaRE model\nsignificantly outperforms existing state-of-the-art models for link prediction\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:19:43 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 05:55:39 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Peng", "Yanhui", ""], ["Zhang", "Jing", ""]]}, {"id": "2004.10048", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "Devolutionary genetic algorithms with application to the minimum\n  labeling Steiner tree problem", "comments": null, "journal-ref": "Evolving Systems volume 9(2018), pages 157-168", "doi": "10.1007/s12530-017-9182-z", "report-no": null, "categories": "math.OC cs.AI cs.NE math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper characterizes and discusses devolutionary genetic algorithms and\nevaluates their performances in solving the minimum labeling Steiner tree\n(MLST) problem. We define devolutionary algorithms as the process of reaching a\nfeasible solution by devolving a population of super-optimal unfeasible\nsolutions over time. We claim that distinguishing them from the widely used\nevolutionary algorithms is relevant. The most important distinction lies in the\nfact that in the former type of processes, the value function decreases over\nsuccessive generation of solutions, thus providing a natural stopping condition\nfor the computation process. We show how classical evolutionary concepts, such\nas crossing, mutation and fitness can be adapted to aim at reaching an optimal\nor close-to-optimal solution among the first generations of feasible solutions.\nWe additionally introduce a novel integer linear programming formulation of the\nMLST problem and a valid constraint used for speeding up the devolutionary\nprocess. Finally, we conduct an experiment comparing the performances of\ndevolutionary algorithms to those of state of the art approaches used for\nsolving randomly generated instances of the MLST problem. Results of this\nexperiment support the use of devolutionary algorithms for the MLST problem and\ntheir development for other NP-hard combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 13:27:28 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2004.10099", "submitter": "Kaiyu Zheng", "authors": "Kaiyu Zheng, Stefanie Tellex", "title": "pomdp_py: A Framework to Build and Solve POMDP Problems", "comments": "5 pages, 3 figures. Submitted to ICAPS 2020 Planning and Robotics\n  (PlanRob) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present pomdp_py, a general purpose Partially Observable\nMarkov Decision Process (POMDP) library written in Python and Cython. Existing\nPOMDP libraries often hinder accessibility and efficient prototyping due to the\nunderlying programming language or interfaces, and require extra complexity in\nsoftware toolchain to integrate with robotics systems. pomdp_py features simple\nand comprehensive interfaces capable of describing large discrete or continuous\n(PO)MDP problems. Here, we summarize the design principles and describe in\ndetail the programming model and interfaces in pomdp_py. We also describe\nintuitive integration of this library with ROS (Robot Operating System), which\nenabled our torso-actuated robot to perform object search in 3D. Finally, we\nnote directions to improve and extend this library for POMDP planning and\nbeyond.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:21:00 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zheng", "Kaiyu", ""], ["Tellex", "Stefanie", ""]]}, {"id": "2004.10119", "submitter": "Luigi Bellomarini", "authors": "Luigi Bellomarini, Marco Benedetti, Andrea Gentili, Rosario Laurendi,\n  Davide Magnanimi, Antonio Muci, Emanuel Sallinger", "title": "COVID-19 and Company Knowledge Graphs: Assessing Golden Powers and\n  Economic Impact of Selective Lockdown via AI Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the COVID-19 outbreak, governments have applied progressive restrictions\nto production activities, permitting only those that are considered strategic\nor that provide essential services. This is particularly apparent in countries\nthat have been stricken hard by the virus, with Italy being a major example.\nYet we know that companies are not just isolated entities: They organize\nthemselves into intricate shareholding structures --- forming company networks\n--- distributing decision power and dividends in sophisticated schemes for\nvarious purposes.\n  One tool from the Artificial Intelligence (AI) toolbox that is particularly\neffective to perform reasoning tasks on domains characterized by many entities\nhighly interconnected with one another is Knowledge Graphs (KG). In this work,\nwe present a visionary opinion and report on ongoing work about the application\nof Automated Reasoning and Knowledge Graph technology to address the impact of\nthe COVID-19 outbreak on the network of Italian companies and support the\napplication of legal instruments for the protection of strategic companies from\ntakeovers.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:55:47 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Bellomarini", "Luigi", ""], ["Benedetti", "Marco", ""], ["Gentili", "Andrea", ""], ["Laurendi", "Rosario", ""], ["Magnanimi", "Davide", ""], ["Muci", "Antonio", ""], ["Sallinger", "Emanuel", ""]]}, {"id": "2004.10151", "submitter": "Ari Holtzman", "authors": "Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua\n  Bengio, Joyce Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May,\n  Aleksandr Nisnevich, Nicolas Pinto, Joseph Turian", "title": "Experience Grounds Language", "comments": "Empirical Methods in Natural Language Processing (EMNLP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language understanding research is held back by a failure to relate language\nto the physical world it describes and to the social interactions it\nfacilitates. Despite the incredible effectiveness of language processing models\nto tackle tasks after being trained on text alone, successful linguistic\ncommunication relies on a shared experience of the world. It is this shared\nexperience that makes utterances meaningful.\n  Natural language processing is a diverse field, and progress throughout its\ndevelopment has come from new representational theories, modeling techniques,\ndata collection paradigms, and tasks. We posit that the present success of\nrepresentation learning approaches trained on large, text-only corpora requires\nthe parallel tradition of research on the broader physical and social context\nof language to address the deeper questions of communication.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:56:27 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:03:56 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 00:40:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bisk", "Yonatan", ""], ["Holtzman", "Ari", ""], ["Thomason", "Jesse", ""], ["Andreas", "Jacob", ""], ["Bengio", "Yoshua", ""], ["Chai", "Joyce", ""], ["Lapata", "Mirella", ""], ["Lazaridou", "Angeliki", ""], ["May", "Jonathan", ""], ["Nisnevich", "Aleksandr", ""], ["Pinto", "Nicolas", ""], ["Turian", "Joseph", ""]]}, {"id": "2004.10263", "submitter": "Grant Passmore", "authors": "Grant Olney Passmore, Simon Cruanes, Denis Ignatovich, Dave Aitken,\n  Matt Bray, Elijah Kagan, Kostya Kanishev, Ewen Maclean, and Nicola Mometto", "title": "The Imandra Automated Reasoning System (system description)", "comments": "To appear in Proceedings of The International Joint Conference on\n  Automated Reasoning (IJCAR) 2020, Lecture Notes in Artificial Intelligence,\n  Springer-Verlag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Imandra, a modern computational logic theorem prover designed to\nbridge the gap between decision procedures such as SMT, semi-automatic\ninductive provers of the Boyer-Moore family like ACL2, and interactive proof\nassistants for typed higher-order logics. Imandra's logic is computational,\nbased on a pure subset of OCaml in which all functions are terminating, with\nrestrictions on types and higher-order functions that allow conjectures to be\ntranslated into multi-sorted first-order logic with theories, including\narithmetic and datatypes. Imandra has novel features supporting large-scale\nindustrial applications, including a seamless integration of bounded and\nunbounded verification, first-class computable counterexamples, efficiently\nexecutable models and a cloud-native architecture supporting live multiuser\ncollaboration.\n  The core reasoning mechanisms of Imandra are (i) a semi-complete procedure\nfor finding models of formulas in the logic mentioned above, centered around\nthe lazy expansion of recursive functions, and (ii) an inductive waterfall and\nsimplifier which \"lifts\" many Boyer-Moore ideas to our typed higher-order\nsetting.\n  These mechanisms are tightly integrated and subject to many forms of user\ncontrol. Imandra's user interfaces include an interactive toplevel, Jupyter\nnotebooks and asynchronous document-based verification (in the spirit of\nIsabelle's Prover IDE) with VS Code.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:57:34 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Passmore", "Grant Olney", ""], ["Cruanes", "Simon", ""], ["Ignatovich", "Denis", ""], ["Aitken", "Dave", ""], ["Bray", "Matt", ""], ["Kagan", "Elijah", ""], ["Kanishev", "Kostya", ""], ["Maclean", "Ewen", ""], ["Mometto", "Nicola", ""]]}, {"id": "2004.10293", "submitter": "Xu Shen", "authors": "Xu Shen, Ivo Batkovic, Vijay Govindarajan, Paolo Falcone, Trevor\n  Darrell, and Francesco Borrelli", "title": "ParkPredict: Motion and Intent Prediction of Vehicles in Parking Lots", "comments": "* Indicates equal contribution. Accepted at IEEE Intelligent Vehicles\n  Symposium (IV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of predicting driver behavior in parking lots, an\nenvironment which is less structured than typical road networks and features\ncomplex, interactive maneuvers in a compact space. Using the CARLA simulator,\nwe develop a parking lot environment and collect a dataset of human parking\nmaneuvers. We then study the impact of model complexity and feature information\nby comparing a multi-modal Long Short-Term Memory (LSTM) prediction model and a\nConvolution Neural Network LSTM (CNN-LSTM) to a physics-based Extended Kalman\nFilter (EKF) baseline. Our results show that 1) intent can be estimated well\n(roughly 85% top-1 accuracy and nearly 100% top-3 accuracy with the LSTM and\nCNN-LSTM model); 2) knowledge of the human driver's intended parking spot has a\nmajor impact on predicting parking trajectory; and 3) the semantic\nrepresentation of the environment improves long term predictions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:46:32 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Shen", "Xu", ""], ["Batkovic", "Ivo", ""], ["Govindarajan", "Vijay", ""], ["Falcone", "Paolo", ""], ["Darrell", "Trevor", ""], ["Borrelli", "Francesco", ""]]}, {"id": "2004.10301", "submitter": "Jayesh Gupta", "authors": "Jayesh K. Gupta, Kunal Menda, Zachary Manchester and Mykel J.\n  Kochenderfer", "title": "Structured Mechanical Models for Robot Learning and Control", "comments": "First two authors contributed equally. Accepted at L4DC2020. Source\n  code and videos at https://sites.google.com/stanford.edu/smm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-based methods are the dominant paradigm for controlling robotic\nsystems, though their efficacy depends heavily on the accuracy of the model\nused. Deep neural networks have been used to learn models of robot dynamics\nfrom data, but they suffer from data-inefficiency and the difficulty to\nincorporate prior knowledge. We introduce Structured Mechanical Models, a\nflexible model class for mechanical systems that are data-efficient, easily\namenable to prior knowledge, and easily usable with model-based control\ntechniques. The goal of this work is to demonstrate the benefits of using\nStructured Mechanical Models in lieu of black-box neural networks when modeling\nrobot dynamics. We demonstrate that they generalize better from limited data\nand yield more reliable model-based controllers on a variety of simulated\nrobotic domains.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 21:12:03 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Gupta", "Jayesh K.", ""], ["Menda", "Kunal", ""], ["Manchester", "Zachary", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.10386", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Cheng Li, Antonio Robles-Kelly and Mohan Kankanhalli", "title": "Hierarchically Fair Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the federated learning is adopted among competitive agents with siloed\ndatasets, agents are self-interested and participate only if they are fairly\nrewarded. To encourage the application of federated learning, this paper\nemploys a management strategy, i.e., more contributions should lead to more\nrewards. We propose a novel hierarchically fair federated learning (HFFL)\nframework. Under this framework, agents are rewarded in proportion to their\npre-negotiated contribution levels. HFFL+ extends this to incorporate\nheterogeneous models. Theoretical analysis and empirical evaluation on several\ndatasets confirm the efficacy of our frameworks in upholding fairness and thus\nfacilitating federated learning in the competitive settings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:41:06 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 11:42:33 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Li", "Cheng", ""], ["Robles-Kelly", "Antonio", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2004.10404", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen and William Yang Wang", "title": "Logical Natural Language Generation from Open-Domain Tables", "comments": "Accepted to ACL 2020 as Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural natural language generation (NLG) models have recently shown\nremarkable progress in fluency and coherence. However, existing studies on\nneural NLG are primarily focused on surface-level realizations with limited\nemphasis on logical inference, an important aspect of human thinking and\nlanguage. In this paper, we suggest a new NLG task where a model is tasked with\ngenerating natural language statements that can be \\emph{logically entailed} by\nthe facts in an open-domain semi-structured table. To facilitate the study of\nthe proposed logical NLG problem, we use the existing TabFact dataset\n\\cite{chen2019tabfact} featured with a wide range of logical/symbolic\ninferences as our testbed, and propose new automatic metrics to evaluate the\nfidelity of generation models w.r.t.\\ logical inference. The new task poses\nchallenges to the existing monotonic generation frameworks due to the mismatch\nbetween sequence order and logical order. In our experiments, we\ncomprehensively survey different generation architectures (LSTM, Transformer,\nPre-Trained LM) trained with different algorithms (RL, Adversarial Training,\nCoarse-to-Fine) on the dataset and made following observations: 1) Pre-Trained\nLM can significantly boost both the fluency and logical fidelity metrics, 2) RL\nand Adversarial Training are trading fluency for fidelity, 3) Coarse-to-Fine\ngeneration can help partially alleviate the fidelity issue while maintaining\nhigh language fluency. The code and data are available at\n\\url{https://github.com/wenhuchen/LogicNLG}.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 06:03:10 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 00:26:21 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Chen", "Wenhu", ""], ["Chen", "Jianshu", ""], ["Su", "Yu", ""], ["Chen", "Zhiyu", ""], ["Wang", "William Yang", ""]]}, {"id": "2004.10430", "submitter": "Jie Chen", "authors": "Jie Chen, Wenjun Xu", "title": "Policy Gradient from Demonstration and Curiosity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With reinforcement learning, an agent could learn complex behaviors from\nhigh-level abstractions of the task. However, exploration and reward shaping\nremained challenging for existing methods, especially in scenarios where the\nextrinsic feedback was sparse. Expert demonstrations have been investigated to\nsolve these difficulties, but a tremendous number of high-quality\ndemonstrations were usually required. In this work, an integrated policy\ngradient algorithm was proposed to boost exploration and facilitate intrinsic\nreward learning from only limited number of demonstrations. We achieved this by\nreformulating the original reward function with two additional terms, where the\nfirst term measured the Jensen-Shannon divergence between current policy and\nthe expert, and the second term estimated the agent's uncertainty about the\nenvironment. The presented algorithm was evaluated on a range of simulated\ntasks with sparse extrinsic reward signals where only one single demonstrated\ntrajectory was provided to each task, superior exploration efficiency and high\naverage return were demonstrated in all tasks. Furthermore, it was found that\nthe agent could imitate the expert's behavior and meanwhile sustain high\nreturn.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 07:57:39 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 10:57:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Jie", ""], ["Xu", "Wenjun", ""]]}, {"id": "2004.10439", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Krister Wolff, Leo Laine", "title": "Tactical Decision-Making in Autonomous Driving by Reinforcement Learning\n  with Uncertainty Estimation", "comments": null, "journal-ref": "IEEE Intelligent Vehicles Symposium (IV), 2020, pp. 1292-1298", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) can be used to create a tactical decision-making\nagent for autonomous driving. However, previous approaches only output\ndecisions and do not provide information about the agent's confidence in the\nrecommended actions. This paper investigates how a Bayesian RL technique, based\non an ensemble of neural networks with additional randomized prior functions\n(RPF), can be used to estimate the uncertainty of decisions in autonomous\ndriving. A method for classifying whether or not an action should be considered\nsafe is also introduced. The performance of the ensemble RPF method is\nevaluated by training an agent on a highway driving scenario. It is shown that\nthe trained agent can estimate the uncertainty of its decisions and indicate an\nunacceptable level when the agent faces a situation that is far from the\ntraining distribution. Furthermore, within the training distribution, the\nensemble RPF agent outperforms a standard Deep Q-Network agent. In this study,\nthe estimated uncertainty is used to choose safe actions in unknown situations.\nHowever, the uncertainty information could also be used to identify situations\nthat should be added to the training process.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:22:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""]]}, {"id": "2004.10489", "submitter": "Fabio Caraffini PhD", "authors": "Anna V. Kononova, Fabio Caraffini and Thomas B\\\"ack", "title": "Differential evolution outside the box", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how often the popular configurations of Differential\nEvolution generate solutions outside the feasible domain. Following previous\npublications in the field, we argue that what the algorithm does with such\nsolutions and how often this has to happen is important for the overall\nperformance of the algorithm and interpretation of results. Significantly more\nsolutions than what is usually assumed by practitioners have to undergo some\nsort of 'correction' to conform with the definition of the problem's search\ndomain. A wide range of popular Differential Evolution configurations is\nconsidered in this study. Conclusions are made regarding the effect the\nDifferential Evolution components and parameter settings have on the\ndistribution of percentages of infeasible solutions generated in a series of\nindependent runs. Results shown in this study suggest strong dependencies\nbetween percentages of generated infeasible solutions and every aspect\nmentioned above. Further investigation of the distribution of percentages of\ngenerated infeasible solutions is required.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 10:58:05 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kononova", "Anna V.", ""], ["Caraffini", "Fabio", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2004.10518", "submitter": "Fatemeh Ziaeetabar", "authors": "Fatemeh Ziaeetabar, Jennifer Pomp, Stefan Pfeiffer, Nadiya El-Sourani,\n  Ricarda I. Schubotz, Minija Tamosiunaite and Florentin W\\\"org\\\"otter", "title": "Human and Machine Action Prediction Independent of Object Information", "comments": "This paper includes 31 pages, 11 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting other people's action is key to successful social interactions,\nenabling us to adjust our own behavior to the consequence of the others' future\nactions. Studies on action recognition have focused on the importance of\nindividual visual features of objects involved in an action and its context.\nHumans, however, recognize actions on unknown objects or even when objects are\nimagined (pantomime). Other cues must thus compensate the lack of recognizable\nvisual object features. Here, we focus on the role of inter-object relations\nthat change during an action. We designed a virtual reality setup and tested\nrecognition speed for 10 different manipulation actions on 50 subjects. All\nobjects were abstracted by emulated cubes so the actions could not be inferred\nusing object information. Instead, subjects had to rely only on the information\nthat comes from the changes in the spatial relations that occur between those\ncubes. In spite of these constraints, our results show the subjects were able\nto predict actions in, on average, less than 64% of the action's duration. We\nemployed a computational model -an enriched Semantic Event Chain (eSEC)-\nincorporating the information of spatial relations, specifically (a) objects'\ntouching/untouching, (b) static spatial relations between objects and (c)\ndynamic spatial relations between objects. Trained on the same actions as those\nobserved by subjects, the model successfully predicted actions even better than\nhumans. Information theoretical analysis shows that eSECs optimally use\nindividual cues, whereas humans presumably mostly rely on a mixed-cue strategy,\nwhich takes longer until recognition. Providing a better cognitive basis of\naction recognition may, on one hand improve our understanding of related human\npathologies and, on the other hand, also help to build robots for conflict-free\nhuman-robot cooperation. Our results open new avenues here.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:13:25 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Ziaeetabar", "Fatemeh", ""], ["Pomp", "Jennifer", ""], ["Pfeiffer", "Stefan", ""], ["El-Sourani", "Nadiya", ""], ["Schubotz", "Ricarda I.", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.10521", "submitter": "Ezequiel Smucler", "authors": "Ezequiel Smucler, Facundo Sapienza and Andrea Rotnitzky", "title": "Efficient adjustment sets in causal graphical models with hidden\n  variables", "comments": "Fixed an error in Example 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the selection of covariate adjustment sets for estimating the value\nof point exposure dynamic policies, also known as dynamic treatment regimes,\nassuming a non-parametric causal graphical model with hidden variables, in\nwhich at least one adjustment set is fully observable. We show that recently\ndeveloped criteria, for graphs without hidden variables, to compare the\nasymptotic variance of non-parametric estimators of static policy values that\ncontrol for certain adjustment sets, are also valid under dynamic policies and\ngraphs with hidden variables. We show that there exist adjustment sets that are\noptimal minimal (minimum), in the sense of yielding estimators with the\nsmallest variance among those that control for adjustment sets that are minimal\n(of minimum cardinality). Moreover, we show that if either no variables are\nhidden or if all the observable variables are ancestors of either treatment,\noutcome, or the variables that are used to decide treatment, a globally optimal\nadjustment set exists. We provide polynomial time algorithms to compute the\nglobally optimal (when it exists), optimal minimal, and optimal minimum\nadjustment sets. Our results are based on the construction of an undirected\ngraph in which vertex cuts between the treatment and outcome variables\ncorrespond to adjustment sets. In this undirected graph, a partial order\nbetween minimal vertex cuts can be defined that makes the set of minimal cuts a\nlattice. This partial order corresponds directly to the ordering of the\nasymptotic variances of the corresponding non-parametrically adjusted\nestimators.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:22:01 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 14:50:19 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 15:32:54 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Smucler", "Ezequiel", ""], ["Sapienza", "Facundo", ""], ["Rotnitzky", "Andrea", ""]]}, {"id": "2004.10638", "submitter": "Michal Najman", "authors": "Olga Petrova, Karel Durkota, Galina Alperovich, Karel Horak, Michal\n  Najman, Branislav Bosansky, Viliam Lisy", "title": "Discovering Imperfectly Observable Adversarial Actions using Anomaly\n  Detection", "comments": "9 pages, 3 figures, 3 tables. Extended Abstract of this paper is\n  accepted to AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a method for discovering unusual and suspicious\nbehavior. In many real-world scenarios, the examined events can be directly\nlinked to the actions of an adversary, such as attacks on computer networks or\nfrauds in financial operations. While the defender wants to discover such\nmalicious behavior, the attacker seeks to accomplish their goal (e.g.,\nexfiltrating data) while avoiding the detection. To this end, anomaly detectors\nhave been used in a game-theoretic framework that captures these goals of a\ntwo-player competition. We extend the existing models to more realistic\nsettings by (1) allowing both players to have continuous action spaces and by\nassuming that (2) the defender cannot perfectly observe the action of the\nattacker. We propose two algorithms for solving such games -- a direct\nextension of existing algorithms based on discretizing the feature space and\nlinear programming and the second algorithm based on constrained learning.\nExperiments show that both algorithms are applicable for cases with low feature\nspace dimensions but the learning-based method produces less exploitable\nstrategies and it is scalable to higher dimensions. Moreover, we use real-world\ndata to compare our approaches with existing classifiers in a data-exfiltration\nscenario via the DNS channel. The results show that our models are\nsignificantly less exploitable by an informed attacker.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:31:53 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Petrova", "Olga", ""], ["Durkota", "Karel", ""], ["Alperovich", "Galina", ""], ["Horak", "Karel", ""], ["Najman", "Michal", ""], ["Bosansky", "Branislav", ""], ["Lisy", "Viliam", ""]]}, {"id": "2004.10645", "submitter": "Sewon Min", "authors": "Sewon Min, Julian Michael, Hannaneh Hajishirzi, Luke Zettlemoyer", "title": "AmbigQA: Answering Ambiguous Open-domain Questions", "comments": "Published as a conference paper at EMNLP 2020 (long)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambiguity is inherent to open-domain question answering; especially when\nexploring new topics, it can be difficult to ask questions that have a single,\nunambiguous answer. In this paper, we introduce AmbigQA, a new open-domain\nquestion answering task which involves finding every plausible answer, and then\nrewriting the question for each one to resolve the ambiguity. To study this\ntask, we construct AmbigNQ, a dataset covering 14,042 questions from NQ-open,\nan existing open-domain QA benchmark. We find that over half of the questions\nin NQ-open are ambiguous, with diverse sources of ambiguity such as event and\nentity references. We also present strong baseline models for AmbigQA which we\nshow benefit from weakly supervised learning that incorporates NQ-open,\nstrongly suggesting our new task and data will support significant future\nresearch effort. Our data and baselines are available at\nhttps://nlp.cs.washington.edu/ambigqa.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:42:13 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 03:28:21 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Min", "Sewon", ""], ["Michael", "Julian", ""], ["Hajishirzi", "Hannaneh", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2004.10667", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Simple Dataset for Proof Method Recommendation in Isabelle/HOL (Dataset\n  Description)", "comments": "This is the preprint of our short paper accepted at the 13th\n  Conference on Intelligent Computer Mathematics (CICM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a growing number of researchers have applied machine learning to\nassist users of interactive theorem provers. However, the expressive nature of\nunderlying logics and esoteric structures of proof documents impede machine\nlearning practitioners, who often do not have much expertise in formal logic,\nlet alone Isabelle/HOL, from achieving a large scale success in this field. In\nthis data description, we present a simple dataset that contains data on over\n400k proof method applications along with over 100 extracted features for each\nin a format that can be processed easily without any knowledge about formal\nlogic. Our simple data format allows machine learning practitioners to try\nmachine learning tools to predict proof methods in Isabelle/HOL without\nrequiring domain expertise in logic.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:00:11 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 06:38:37 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:46:04 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2004.10698", "submitter": "Keting Lu", "authors": "Keting Lu, Shiqi Zhang, Xiaoping Chen", "title": "AutoEG: Automated Experience Grafting for Off-Policy Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms frequently require prohibitive\ninteraction experience to ensure the quality of learned policies. The\nlimitation is partly because the agent cannot learn much from the many\nlow-quality trials in early learning phase, which results in low learning rate.\nFocusing on addressing this limitation, this paper makes a twofold\ncontribution. First, we develop an algorithm, called Experience Grafting (EG),\nto enable RL agents to reorganize segments of the few high-quality trajectories\nfrom the experience pool to generate many synthetic trajectories while\nretaining the quality. Second, building on EG, we further develop an AutoEG\nagent that automatically learns to adjust the grafting-based learning strategy.\nResults collected from a set of six robotic control environments show that, in\ncomparison to a standard deep RL algorithm (DDPG), AutoEG increases the speed\nof learning process by at least 30%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:07:08 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 14:32:51 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Lu", "Keting", ""], ["Zhang", "Shiqi", ""], ["Chen", "Xiaoping", ""]]}, {"id": "2004.10746", "submitter": "Azalia Mirhoseini", "authors": "Azalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe Jiang, Ebrahim\n  Songhori, Shen Wang, Young-Joon Lee, Eric Johnson, Omkar Pathak, Sungmin Bae,\n  Azade Nazi, Jiwoo Pak, Andy Tong, Kavya Srinivasa, William Hang, Emre Tuncer,\n  Anand Babu, Quoc V. Le, James Laudon, Richard Ho, Roger Carpenter, Jeff Dean", "title": "Chip Placement with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a learning-based approach to chip placement, one of\nthe most complex and time-consuming stages of the chip design process. Unlike\nprior methods, our approach has the ability to learn from past experience and\nimprove over time. In particular, as we train over a greater number of chip\nblocks, our method becomes better at rapidly generating optimized placements\nfor previously unseen chip blocks. To achieve these results, we pose placement\nas a Reinforcement Learning (RL) problem and train an agent to place the nodes\nof a chip netlist onto a chip canvas. To enable our RL policy to generalize to\nunseen blocks, we ground representation learning in the supervised task of\npredicting placement quality. By designing a neural architecture that can\naccurately predict reward across a wide variety of netlists and their\nplacements, we are able to generate rich feature embeddings of the input\nnetlists. We then use this architecture as the encoder of our policy and value\nnetworks to enable transfer learning. Our objective is to minimize PPA (power,\nperformance, and area), and we show that, in under 6 hours, our method can\ngenerate placements that are superhuman or comparable on modern accelerator\nnetlists, whereas existing baselines require human experts in the loop and take\nseveral weeks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:56:07 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mirhoseini", "Azalia", ""], ["Goldie", "Anna", ""], ["Yazgan", "Mustafa", ""], ["Jiang", "Joe", ""], ["Songhori", "Ebrahim", ""], ["Wang", "Shen", ""], ["Lee", "Young-Joon", ""], ["Johnson", "Eric", ""], ["Pathak", "Omkar", ""], ["Bae", "Sungmin", ""], ["Nazi", "Azade", ""], ["Pak", "Jiwoo", ""], ["Tong", "Andy", ""], ["Srinivasa", "Kavya", ""], ["Hang", "William", ""], ["Tuncer", "Emre", ""], ["Babu", "Anand", ""], ["Le", "Quoc V.", ""], ["Laudon", "James", ""], ["Ho", "Richard", ""], ["Carpenter", "Roger", ""], ["Dean", "Jeff", ""]]}, {"id": "2004.10808", "submitter": "Ben Kybartas", "authors": "Ben Kybartas, Clark Verbrugge, Jonathan Lessard", "title": "Tension Space Analysis for Emergent Narrative", "comments": "14 pages, 7 figures, IEEE Transactions on Games 2020", "journal-ref": null, "doi": "10.1109/TG.2020.2989072", "report-no": null, "categories": "cs.AI cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent narratives provide a unique and compelling approach to interactive\nstorytelling through simulation, and have applications in games, narrative\ngeneration, and virtual agents. However the inherent complexity of simulation\nmakes understanding the expressive potential of emergent narratives difficult,\nparticularly at the design phase of development. In this paper, we present a\nnovel approach to emergent narrative using the narratological theory of\npossible worlds and demonstrate how the design of works in such a system can be\nunderstood through a formal means of analysis inspired by expressive range\nanalysis. Lastly, we propose a novel way through which content may be authored\nfor the emergent narrative system using a sketch-based interface.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:26:09 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Kybartas", "Ben", ""], ["Verbrugge", "Clark", ""], ["Lessard", "Jonathan", ""]]}, {"id": "2004.10876", "submitter": "Aidan Curtis", "authors": "Aidan Curtis, Minjian Xin, Dilip Arumugam, Kevin Feigelis, Daniel\n  Yamins", "title": "Flexible and Efficient Long-Range Planning Through Curious Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying algorithms that flexibly and efficiently discover\ntemporally-extended multi-phase plans is an essential step for the advancement\nof robotics and model-based reinforcement learning. The core problem of\nlong-range planning is finding an efficient way to search through the tree of\npossible action sequences. Existing non-learned planning solutions from the\nTask and Motion Planning (TAMP) literature rely on the existence of logical\ndescriptions for the effects and preconditions for actions. This constraint\nallows TAMP methods to efficiently reduce the tree search problem but limits\ntheir ability to generalize to unseen and complex physical environments. In\ncontrast, deep reinforcement learning (DRL) methods use flexible\nneural-network-based function approximators to discover policies that\ngeneralize naturally to unseen circumstances. However, DRL methods struggle to\nhandle the very sparse reward landscapes inherent to long-range multi-step\nplanning situations. Here, we propose the Curious Sample Planner (CSP), which\nfuses elements of TAMP and DRL by combining a curiosity-guided sampling\nstrategy with imitation learning to accelerate planning. We show that CSP can\nefficiently discover interesting and complex temporally-extended plans for\nsolving a wide range of physically realistic 3D tasks. In contrast, standard\nplanning and learning methods often fail to solve these tasks at all or do so\nonly with a huge and highly variable number of training samples. We explore the\nuse of a variety of curiosity metrics with CSP and analyze the types of\nsolutions that CSP discovers. Finally, we show that CSP supports task transfer\nso that the exploration policies learned during experience with one task can\nhelp improve efficiency on related tasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 21:47:29 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 06:32:15 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Curtis", "Aidan", ""], ["Xin", "Minjian", ""], ["Arumugam", "Dilip", ""], ["Feigelis", "Kevin", ""], ["Yamins", "Daniel", ""]]}, {"id": "2004.10888", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Shimon Whiteson", "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:23:44 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:57:35 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 16:42:41 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 01:02:59 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2004.10908", "submitter": "Tsung-Wei Huang", "authors": "Tsung-Wei Huang, Dian-Lun Lin, Yibo Lin, Chun-Xun Lin", "title": "Taskflow: A General-purpose Parallel and Heterogeneous Task Programming\n  System", "comments": "19 pages, 23 pages", "journal-ref": "2019 IEEE International Parallel and Distributed Processing\n  Symposium (IPDPS)", "doi": "10.1109/IPDPS.2019.00105", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Taskflow project addresses the long-standing question: How can we make it\neasier for developers to write parallel and heterogeneous programs with high\nperformance and simultaneous high productivity? Taskflow develops a simple and\npowerful task programming model to enable efficient implementations of\nheterogeneous decomposition strategies. Our programming model empowers users\nwith both static and dynamic task graph constructions to incorporate a broad\nrange of computational patterns including hybrid CPU-GPU computing, dynamic\ncontrol flow, and irregularity. We develop an efficient heterogeneous\nwork-stealing strategy that adapts worker threads to available task parallelism\nat any time during the graph execution. We have demonstrated promising\nperformance of Taskflow on both micro-benchmark and real-world applications. As\nan example, we solved a large machine learning workload by up to 1.5x faster,\n1.6x less memory, and 1.7x fewer lines of code than two industrial-strength\nsystems, oneTBB and StarPU, on a machine of 40 CPUs and 4 GPUs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 00:21:05 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:50:03 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 03:49:24 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Huang", "Tsung-Wei", ""], ["Lin", "Dian-Lun", ""], ["Lin", "Yibo", ""], ["Lin", "Chun-Xun", ""]]}, {"id": "2004.10927", "submitter": "Shunsuke Aoki", "authors": "Shunsuke Aoki, Takamasa Higuchi, Onur Altintas", "title": "Cooperative Perception with Deep Reinforcement Learning for Connected\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor-based perception on vehicles are becoming prevalent and important to\nenhance the road safety. Autonomous driving systems use cameras, LiDAR, and\nradar to detect surrounding objects, while human-driven vehicles use them to\nassist the driver. However, the environmental perception by individual vehicles\nhas the limitations on coverage and/or detection accuracy. For example, a\nvehicle cannot detect objects occluded by other moving/static obstacles. In\nthis paper, we present a cooperative perception scheme with deep reinforcement\nlearning to enhance the detection accuracy for the surrounding objects. By\nusing the deep reinforcement learning to select the data to transmit, our\nscheme mitigates the network load in vehicular communication networks and\nenhances the communication reliability. To design, test, and verify the\ncooperative perception scheme, we develop a Cooperative & Intelligent Vehicle\nSimulation (CIVS) Platform, which integrates three software components: traffic\nsimulator, vehicle simulator, and object classifier. We evaluate that our\nscheme decreases packet loss and thereby increases the detection accuracy by up\nto 12%, compared to the baseline protocol.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 01:44:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Aoki", "Shunsuke", ""], ["Higuchi", "Takamasa", ""], ["Altintas", "Onur", ""]]}, {"id": "2004.10958", "submitter": "Yiwen Sun", "authors": "Yiwen Sun, Yulu Wang, Kun Fu, Zheng Wang, Changshui Zhang, Jieping Ye", "title": "Constructing Geographic and Long-term Temporal Graph for Traffic\n  Forecasting", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting influences various intelligent transportation system\n(ITS) services and is of great significance for user experience as well as\nurban traffic control. It is challenging due to the fact that the road network\ncontains complex and time-varying spatial-temporal dependencies. Recently, deep\nlearning based methods have achieved promising results by adopting graph\nconvolutional network (GCN) to extract the spatial correlations and recurrent\nneural network (RNN) to capture the temporal dependencies. However, the\nexisting methods often construct the graph only based on road network\nconnectivity, which limits the interaction between roads. In this work, we\npropose Geographic and Long term Temporal Graph Convolutional Recurrent Neural\nNetwork (GLT-GCRNN), a novel framework for traffic forecasting that learns the\nrich interactions between roads sharing similar geographic or longterm temporal\npatterns. Extensive experiments on a real-world traffic state dataset validate\nthe effectiveness of our method by showing that GLT-GCRNN outperforms the\nstate-of-the-art methods in terms of different metrics.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 03:50:46 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Sun", "Yiwen", ""], ["Wang", "Yulu", ""], ["Fu", "Kun", ""], ["Wang", "Zheng", ""], ["Zhang", "Changshui", ""], ["Ye", "Jieping", ""]]}, {"id": "2004.10966", "submitter": "Tasmia Tasrin", "authors": "Tasmia Tasrin, Md Sultan Al Nahian and Brent Harrison", "title": "Visual Question Answering Using Semantic Information from Image\n  Descriptions", "comments": "6 pages, 5 figures, The 34th International FLAIRS Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a deep neural architecture that uses an attention\nmechanism which utilizes region based image features, the natural language\nquestion asked, and semantic knowledge extracted from the regions of an image\nto produce open-ended answers for questions asked in a visual question\nanswering (VQA) task. The combination of both region based features and region\nbased textual information about the image bolsters a model to more accurately\nrespond to questions and potentially do so with less required training data. We\nevaluate our proposed architecture on a VQA task against a strong baseline and\nshow that our method achieves excellent results on this task.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 04:35:04 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 18:09:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tasrin", "Tasmia", ""], ["Nahian", "Md Sultan Al", ""], ["Harrison", "Brent", ""]]}, {"id": "2004.10978", "submitter": "Bao Trung Nguyen", "authors": "Trung B. Nguyen, Will N. Browne, Mengjie Zhang", "title": "Constructing Complexity-efficient Features in XCS with Tree-based Rule\n  Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major goal of machine learning is to create techniques that abstract away\nirrelevant information. The generalisation property of standard Learning\nClassifier System (LCS) removes such information at the feature level but not\nat the feature interaction level. Code Fragments (CFs), a form of tree-based\nprograms, introduced feature manipulation to discover important interactions,\nbut they often contain irrelevant information, which causes structural\ninefficiency. XOF is a recently introduced LCS that uses CFs to encode building\nblocks of knowledge about feature interaction. This paper aims to optimise the\nstructural efficiency of CFs in XOF. We propose two measures to improve\nconstructing CFs to achieve this goal. Firstly, a new CF-fitness update\nestimates the applicability of CFs that also considers the structural\ncomplexity. The second measure we can use is a niche-based method of generating\nCFs. These approaches were tested on Even-parity and Hierarchical problems,\nwhich require highly complex combinations of input features to capture the data\npatterns. The results show that the proposed methods significantly increase the\nstructural efficiency of CFs, which is estimated by the rule \"generality rate\".\nThis results in faster learning performance in the Hierarchical Majority-on\nproblem. Furthermore, a user-set depth limit for CF generation is not needed as\nthe learning agent will not adopt higher-level CFs once optimal CFs are\nconstructed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:41:41 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Nguyen", "Trung B.", ""], ["Browne", "Will N.", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2004.10984", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger and Oliver Schulte", "title": "A Complete Characterization of Projectivity for Statistical Relational\n  Models", "comments": "Extended version (with proof appendix) of paper that is too appear in\n  Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A generative probabilistic model for relational data consists of a family of\nprobability distributions for relational structures over domains of different\nsizes. In most existing statistical relational learning (SRL) frameworks, these\nmodels are not projective in the sense that the marginal of the distribution\nfor size-$n$ structures on induced sub-structures of size $k<n$ is equal to the\ngiven distribution for size-$k$ structures. Projectivity is very beneficial in\nthat it directly enables lifted inference and statistically consistent learning\nfrom sub-sampled relational structures. In earlier work some simple fragments\nof SRL languages have been identified that represent projective models.\nHowever, no complete characterization of, and representation framework for\nprojective models has been given. In this paper we fill this gap: exploiting\nrepresentation theorems for infinite exchangeable arrays we introduce a class\nof directed graphical latent variable models that precisely correspond to the\nclass of projective relational models. As a by-product we also obtain a\ncharacterization for when a given distribution over size-$k$ structures is the\nstatistical frequency distribution of size-$k$ sub-structures in much larger\nsize-$n$ structures. These results shed new light onto the old open problem of\nhow to apply Halpern et al.'s \"random worlds approach\" for probabilistic\ninference to general relational signatures.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:58:27 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 11:44:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jaeger", "Manfred", ""], ["Schulte", "Oliver", ""]]}, {"id": "2004.11051", "submitter": "Yannis Kalantidis", "authors": "Yannis Kalantidis, Laura Sevilla-Lara, Ernest Mwebaze, Dina Machuve,\n  Hamed Alemohammad, David Guerena", "title": "Proceedings of the ICLR Workshop on Computer Vision for Agriculture\n  (CV4A) 2020", "comments": "14 papers accepted, 4 as oral, 10 as spotlights", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the proceedings of the Computer Vision for Agriculture (CV4A)\nWorkshop that was held in conjunction with the International Conference on\nLearning Representations (ICLR) 2020.\n  The Computer Vision for Agriculture (CV4A) 2020 workshop was scheduled to be\nheld in Addis Ababa, Ethiopia, on April 26th, 2020. It was held virtually that\nsame day due to the COVID-19 pandemic. The workshop was held in conjunction\nwith the International Conference on Learning Representations (ICLR) 2020.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:11:52 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 12:33:59 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 16:50:58 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kalantidis", "Yannis", ""], ["Sevilla-Lara", "Laura", ""], ["Mwebaze", "Ernest", ""], ["Machuve", "Dina", ""], ["Alemohammad", "Hamed", ""], ["Guerena", "David", ""]]}, {"id": "2004.11113", "submitter": "Cl\\'ement Gautrais", "authors": "Cl\\'ement Gautrais, Yann Dauxais, Stefano Teso, Samuel Kolb, Gust\n  Verbruggen, Luc De Raedt", "title": "Human-Machine Collaboration for Democratizing Data Science", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Everybody wants to analyse their data, but only few posses the data science\nexpertise to to this. Motivated by this observation we introduce a novel\nframework and system \\textsc{VisualSynth} for human-machine collaboration in\ndata science.\n  It wants to democratize data science by allowing users to interact with\nstandard spreadsheet software in order to perform and automate various data\nanalysis tasks ranging from data wrangling, data selection, clustering,\nconstraint learning, predictive modeling and auto-completion.\n\\textsc{VisualSynth} relies on the user providing colored sketches, i.e.,\ncoloring parts of the spreadsheet, to partially specify data science tasks,\nwhich are then determined and executed using artificial intelligence\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 12:50:52 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Gautrais", "Cl\u00e9ment", ""], ["Dauxais", "Yann", ""], ["Teso", "Stefano", ""], ["Kolb", "Samuel", ""], ["Verbruggen", "Gust", ""], ["De Raedt", "Luc", ""]]}, {"id": "2004.11145", "submitter": "Xiangfeng Wang", "authors": "Wenhao Li and Bo Jin and Xiangfeng Wang and Junchi Yan and Hongyuan\n  Zha", "title": "F2A2: Flexible Fully-decentralized Approximate Actor-critic for\n  Cooperative Multi-agent Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1810.02912,\n  arXiv:1803.11485 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional centralized multi-agent reinforcement learning (MARL) algorithms\nare sometimes unpractical in complicated applications, due to non-interactivity\nbetween agents, curse of dimensionality and computation complexity. Hence,\nseveral decentralized MARL algorithms are motivated. However, existing\ndecentralized methods only handle the fully cooperative setting where massive\ninformation needs to be transmitted in training. The block coordinate gradient\ndescent scheme they used for successive independent actor and critic steps can\nsimplify the calculation, but it causes serious bias. In this paper, we propose\na flexible fully decentralized actor-critic MARL framework, which can combine\nmost of actor-critic methods, and handle large-scale general cooperative\nmulti-agent setting. A primal-dual hybrid gradient descent type algorithm\nframework is designed to learn individual agents separately for\ndecentralization. From the perspective of each agent, policy improvement and\nvalue evaluation are jointly optimized, which can stabilize multi-agent policy\nlearning. Furthermore, our framework can achieve scalability and stability for\nlarge-scale environment and reduce information transmission, by the parameter\nsharing mechanism and a novel modeling-other-agents methods based on\ntheory-of-mind and online supervised learning. Sufficient experiments in\ncooperative Multi-agent Particle Environment and StarCraft II show that our\ndecentralized MARL instantiation algorithms perform competitively against\nconventional centralized and decentralized methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 14:56:29 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Li", "Wenhao", ""], ["Jin", "Bo", ""], ["Wang", "Xiangfeng", ""], ["Yan", "Junchi", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2004.11204", "submitter": "Keshab Parhi", "authors": "Lulu Ge and Keshab K. Parhi", "title": "Classification using Hyperdimensional Computing: A Review", "comments": "IEEE Circuits and Systems Magazine (2020)", "journal-ref": "IEEE Circuits and Systems Magazine, 20(2), pp. 30-47, June 2020", "doi": "10.1109/MCAS.2020.2988388", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperdimensional (HD) computing is built upon its unique data type referred\nto as hypervectors. The dimension of these hypervectors is typically in the\nrange of tens of thousands. Proposed to solve cognitive tasks, HD computing\naims at calculating similarity among its data. Data transformation is realized\nby three operations, including addition, multiplication and permutation. Its\nultra-wide data representation introduces redundancy against noise. Since\ninformation is evenly distributed over every bit of the hypervectors, HD\ncomputing is inherently robust. Additionally, due to the nature of those three\noperations, HD computing leads to fast learning ability, high energy efficiency\nand acceptable accuracy in learning and classification tasks. This paper\nintroduces the background of HD computing, and reviews the data representation,\ndata transformation, and similarity measurement. The orthogonality in high\ndimensions presents opportunities for flexible computing. To balance the\ntradeoff between accuracy and efficiency, strategies include but are not\nlimited to encoding, retraining, binarization and hardware acceleration.\nEvaluations indicate that HD computing shows great potential in addressing\nproblems using data in the form of letters, signals and images. HD computing\nespecially shows significant promise to replace machine learning algorithms as\na light-weight classifier in the field of internet of things (IoTs).\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 23:51:44 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Ge", "Lulu", ""], ["Parhi", "Keshab K.", ""]]}, {"id": "2004.11302", "submitter": "Daniel Krutz", "authors": "Jeffrey Palmerino, Qi Yu, Travis Desell and Daniel E. Krutz", "title": "Improving the Decision-Making Process of Self-Adaptive Systems by\n  Accounting for Tactic Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When self-adaptive systems encounter changes within their surrounding\nenvironments, they enact tactics to perform necessary adaptations. For example,\na self-adaptive cloud-based system may have a tactic that initiates additional\ncomputing resources when response time thresholds are surpassed, or there may\nbe a tactic to activate a specific security measure when an intrusion is\ndetected. In real-world environments, these tactics frequently experience\ntactic volatility which is variable behavior during the execution of the\ntactic.\n  Unfortunately, current self-adaptive approaches do not account for tactic\nvolatility in their decision-making processes, and merely assume that tactics\ndo not experience volatility. This limitation creates uncertainty in the\ndecision-making process and may adversely impact the system's ability to\neffectively and efficiently adapt. Additionally, many processes do not properly\naccount for volatility that may effect the system's Service Level Agreement\n(SLA). This can limit the system's ability to act proactively, especially when\nutilizing tactics that contain latency.\n  To address the challenge of sufficiently accounting for tactic volatility, we\npropose a Tactic Volatility Aware (TVA) solution. Using Multiple Regression\nAnalysis (MRA), TVA enables self-adaptive systems to accurately estimate the\ncost and time required to execute tactics. TVA also utilizes Autoregressive\nIntegrated Moving Average (ARIMA) for time series forecasting, allowing the\nsystem to proactively maintain specifications.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:34:28 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Palmerino", "Jeffrey", ""], ["Yu", "Qi", ""], ["Desell", "Travis", ""], ["Krutz", "Daniel E.", ""]]}, {"id": "2004.11339", "submitter": "Jimmy Lin", "authors": "Raphael Tang, Rodrigo Nogueira, Edwin Zhang, Nikhil Gupta, Phuong Cam,\n  Kyunghyun Cho, Jimmy Lin", "title": "Rapidly Bootstrapping a Question Answering Dataset for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CovidQA, the beginnings of a question answering dataset\nspecifically designed for COVID-19, built by hand from knowledge gathered from\nKaggle's COVID-19 Open Research Dataset Challenge. To our knowledge, this is\nthe first publicly available resource of its type, and intended as a stopgap\nmeasure for guiding research until more substantial evaluation resources become\navailable. While this dataset, comprising 124 question-article pairs as of the\npresent version 0.1 release, does not have sufficient examples for supervised\nmachine learning, we believe that it can be helpful for evaluating the\nzero-shot or transfer capabilities of existing models on topics specifically\nrelated to COVID-19. This paper describes our methodology for constructing the\ndataset and presents the effectiveness of a number of baselines, including\nterm-based techniques and various transformer-based models. The dataset is\navailable at http://covidqa.ai/\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:35:11 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Tang", "Raphael", ""], ["Nogueira", "Rodrigo", ""], ["Zhang", "Edwin", ""], ["Gupta", "Nikhil", ""], ["Cam", "Phuong", ""], ["Cho", "Kyunghyun", ""], ["Lin", "Jimmy", ""]]}, {"id": "2004.11345", "submitter": "Gregory Kahn", "authors": "Suneel Belkhale, Rachel Li, Gregory Kahn, Rowan McAllister, Roberto\n  Calandra, Sergey Levine", "title": "Model-Based Meta-Reinforcement Learning for Flight with Suspended\n  Payloads", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters 2021", "doi": "10.1109/LRA.2021.3057046", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transporting suspended payloads is challenging for autonomous aerial vehicles\nbecause the payload can cause significant and unpredictable changes to the\nrobot's dynamics. These changes can lead to suboptimal flight performance or\neven catastrophic failure. Although adaptive control and learning-based methods\ncan in principle adapt to changes in these hybrid robot-payload systems, rapid\nmid-flight adaptation to payloads that have a priori unknown physical\nproperties remains an open problem. We propose a meta-learning approach that\n\"learns how to learn\" models of altered dynamics within seconds of\npost-connection flight data. Our experiments demonstrate that our online\nadaptation approach outperforms non-adaptive methods on a series of challenging\nsuspended payload transportation tasks. Videos and other supplemental material\nare available on our website: https://sites.google.com/view/meta-rl-for-flight\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:43:56 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 06:32:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Belkhale", "Suneel", ""], ["Li", "Rachel", ""], ["Kahn", "Gregory", ""], ["McAllister", "Rowan", ""], ["Calandra", "Roberto", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.11410", "submitter": "Giambattista Parascandolo", "authors": "Giambattista Parascandolo, Lars Buesing, Josh Merel, Leonard\n  Hasenclever, John Aslanides, Jessica B. Hamrick, Nicolas Heess, Alexander\n  Neitz, Theophane Weber", "title": "Divide-and-Conquer Monte Carlo Tree Search For Goal-Directed Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard planners for sequential decision making (including Monte Carlo\nplanning, tree search, dynamic programming, etc.) are constrained by an\nimplicit sequential planning assumption: The order in which a plan is\nconstructed is the same in which it is executed. We consider alternatives to\nthis assumption for the class of goal-directed Reinforcement Learning (RL)\nproblems. Instead of an environment transition model, we assume an imperfect,\ngoal-directed policy. This low-level policy can be improved by a plan,\nconsisting of an appropriate sequence of sub-goals that guide it from the start\nto the goal state. We propose a planning algorithm, Divide-and-Conquer Monte\nCarlo Tree Search (DC-MCTS), for approximating the optimal plan by means of\nproposing intermediate sub-goals which hierarchically partition the initial\ntasks into simpler ones that are then solved independently and recursively. The\nalgorithm critically makes use of a learned sub-goal proposal for finding\nappropriate partitions trees of new tasks based on prior experience. Different\nstrategies for learning sub-goal proposals give rise to different planning\nstrategies that strictly generalize sequential planning. We show that this\nalgorithmic flexibility over planning order leads to improved results in\nnavigation tasks in grid-worlds as well as in challenging continuous control\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:08:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Buesing", "Lars", ""], ["Merel", "Josh", ""], ["Hasenclever", "Leonard", ""], ["Aslanides", "John", ""], ["Hamrick", "Jessica B.", ""], ["Heess", "Nicolas", ""], ["Neitz", "Alexander", ""], ["Weber", "Theophane", ""]]}, {"id": "2004.11434", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Meeyoung Cha", "title": "Responsible AI and Its Stakeholders", "comments": "4 pages, accepted to the Fair & Responsible AI Workshop at ACM CHI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responsible Artificial Intelligence (AI) proposes a framework that holds all\nstakeholders involved in the development of AI to be responsible for their\nsystems. It, however, fails to accommodate the possibility of holding AI\nresponsible per se, which could close some legal and moral gaps concerning the\ndeployment of autonomous and self-learning systems. We discuss three notions of\nresponsibility (i.e., blameworthiness, accountability, and liability) for all\nstakeholders, including AI, and suggest the roles of jurisdiction and the\ngeneral public in this matter.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:27:19 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Lima", "Gabriel", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2004.11469", "submitter": "Martin Aleksandrov D", "authors": "Martin Aleksandrov", "title": "Jealousy-freeness and other common properties in Fair Division of Mixed\n  Manna", "comments": "12 pages, 1 table, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fair division setting where indivisible items are allocated to\nagents. Each agent in the setting has strictly negative, zero or strictly\npositive utility for each item. We, thus, make a distinction between items that\nare good for some agents and bad for other agents (i.e. mixed), good for\neveryone (i.e. goods) or bad for everyone (i.e. bads). For this model, we study\naxiomatic concepts of allocations such as jealousy-freeness up to one item,\nenvy-freeness up to one item and Pareto-optimality. We obtain many new\npossibility and impossibility results in regard to combinations of these\nproperties. We also investigate new computational tasks related to such\ncombinations. Thus, we advance the state-of-the-art in fair division of mixed\nmanna.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 21:39:12 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 22:52:03 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 19:18:02 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Aleksandrov", "Martin", ""]]}, {"id": "2004.11638", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "Belief functions induced by random fuzzy sets: A general framework for\n  representing uncertain and fuzzy evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit Zadeh's notion of \"evidence of the second kind\" and show that it\nprovides the foundation for a general theory of epistemic random fuzzy sets,\nwhich generalizes both the Dempster-Shafer theory of belief functions and\npossibility theory. In this perspective, Dempster-Shafer theory deals with\nbelief functions generated by random sets, while possibility theory deals with\nbelief functions induced by fuzzy sets. The more general theory allows us to\nrepresent and combine evidence that is both uncertain and fuzzy. We demonstrate\nthe application of this formalism to statistical inference, and show that it\nmakes it possible to reconcile the possibilistic interpretation of likelihood\nwith Bayesian inference.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 10:14:54 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:48:02 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "2004.11667", "submitter": "Guillaume Matheron", "authors": "Guillaume Matheron, Nicolas Perrin, Olivier Sigaud", "title": "PBCS : Efficient Exploration and Exploitation Using a Synergy between\n  Reinforcement Learning and Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration-exploitation trade-off is at the heart of reinforcement\nlearning (RL). However, most continuous control benchmarks used in recent RL\nresearch only require local exploration. This led to the development of\nalgorithms that have basic exploration capabilities, and behave poorly in\nbenchmarks that require more versatile exploration. For instance, as\ndemonstrated in our empirical study, state-of-the-art RL algorithms such as\nDDPG and TD3 are unable to steer a point mass in even small 2D mazes. In this\npaper, we propose a new algorithm called \"Plan, Backplay, Chain Skills\" (PBCS)\nthat combines motion planning and reinforcement learning to solve hard\nexploration environments. In a first phase, a motion planning algorithm is used\nto find a single good trajectory, then an RL algorithm is trained using a\ncurriculum derived from the trajectory, by combining a variant of the Backplay\nalgorithm and skill chaining. We show that this method outperforms\nstate-of-the-art RL algorithms in 2D maze environments of various sizes, and is\nable to improve on the trajectory obtained by the motion planning phase.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 11:37:09 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Matheron", "Guillaume", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2004.11763", "submitter": "Sebastian Gottwald", "authors": "Sebastian Gottwald, Daniel A. Braun", "title": "The Two Kinds of Free Energy and the Bayesian Revolution", "comments": null, "journal-ref": "PLOS Computational Biology 16(12), 2020", "doi": "10.1371/journal.pcbi.1008420", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of free energy has its origins in 19th century thermodynamics,\nbut has recently found its way into the behavioral and neural sciences, where\nit has been promoted for its wide applicability and has even been suggested as\na fundamental principle of understanding intelligent behavior and brain\nfunction. We argue that there are essentially two different notions of free\nenergy in current models of intelligent agency, that can both be considered as\napplications of Bayesian inference to the problem of action selection: one that\nappears when trading off accuracy and uncertainty based on a general maximum\nentropy principle, and one that formulates action selection in terms of\nminimizing an error measure that quantifies deviations of beliefs and policies\nfrom given reference models. The first approach provides a normative rule for\naction selection in the face of model uncertainty or when information\nprocessing capabilities are limited. The second approach directly aims to\nformulate the action selection problem as an inference problem in the context\nof Bayesian brain theories, also known as Active Inference in the literature.\nWe elucidate the main ideas and discuss critical technical and conceptual\nissues revolving around these two notions of free energy that both claim to\napply at all levels of decision-making, from the high-level deliberation of\nreasoning down to the low-level information processing of perception.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:09:28 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 11:56:08 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 07:17:59 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 00:03:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "2004.11812", "submitter": "Pascal Klink", "authors": "Pascal Klink, Carlo D'Eramo, Jan Peters, Joni Pajarinen", "title": "Self-Paced Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum reinforcement learning (CRL) improves the learning speed and\nstability of an agent by exposing it to a tailored series of tasks throughout\nlearning. Despite empirical successes, an open question in CRL is how to\nautomatically generate a curriculum for a given reinforcement learning (RL)\nagent, avoiding manual design. In this paper, we propose an answer by\ninterpreting the curriculum generation as an inference problem, where\ndistributions over tasks are progressively learned to approach the target task.\nThis approach leads to an automatic curriculum generation, whose pace is\ncontrolled by the agent, with solid theoretical motivation and easily\nintegrated with deep RL algorithms. In the conducted experiments, the curricula\ngenerated with the proposed algorithm significantly improve learning\nperformance across several environments and deep RL algorithms, matching or\noutperforming state-of-the-art existing CRL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:48:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 11:51:39 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 13:41:19 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 19:51:56 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 09:42:00 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Klink", "Pascal", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2004.11858", "submitter": "Amir Hosein Afshar Sedigh", "authors": "Amir Hosein Afshar Sedigh, Martin K. Purvis, Bastin Tony Roy\n  Savarimuthu, Christopher K Frantz, and Maryam A. Purvis", "title": "Impact of different belief facets on agents' decision -- a refined\n  cognitive architecture to model the interaction between organisations'\n  institutional characteristics and agents' behaviour", "comments": "Submitted to COINE 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a conceptual refinement of agent cognitive architecture\ninspired from the beliefs-desires-intentions (BDI) and the theory of planned\nbehaviour (TPB) models, with an emphasis on different belief facets. This\nenables us to investigate the impact of personality and the way that an agent\nweights its internal beliefs and social sanctions on an agent's actions. The\nstudy also uses the concept of cognitive dissonance associated with the\nfairness of institutions to investigate the agents' behaviour. To showcase our\nmodel, we simulate two historical long-distance trading societies, namely\nArmenian merchants of New-Julfa and the English East India Company. The results\ndemonstrate the importance of internal beliefs of agents as a pivotal aspect\nfor following institutional rules.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:06:32 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 07:04:24 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Sedigh", "Amir Hosein Afshar", ""], ["Purvis", "Martin K.", ""], ["Savarimuthu", "Bastin Tony Roy", ""], ["Frantz", "Christopher K", ""], ["Purvis", "Maryam A.", ""]]}, {"id": "2004.11861", "submitter": "Simon Gottschalk", "authors": "Tarc\\'isio Souza Costa, Simon Gottschalk, Elena Demidova", "title": "Event-QA: A Dataset for Event-Centric Question Answering over Knowledge\n  Graphs", "comments": "(c) 2020 Copyright held by the authors. This is the author's version\n  of the work. It is posted here for your personal use. Not for redistribution.\n  The definitive version was published in the Proceedings of the 29th ACM\n  International Conference on Information and Knowledge Management,\n  https://doi.org/10.1145/3340531.3412760", "journal-ref": null, "doi": "10.1145/3340531.3412760", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Question Answering (QA) is a crucial technology to facilitate\nintuitive user access to semantic information stored in knowledge graphs.\nWhereas most of the existing QA systems and datasets focus on entity-centric\nquestions, very little is known about these systems' performance in the context\nof events. As new event-centric knowledge graphs emerge, datasets for such\nquestions gain importance. In this paper, we present the Event-QA dataset for\nanswering event-centric questions over knowledge graphs. Event-QA contains 1000\nsemantic queries and the corresponding English, German and Portuguese\nverbalizations for EventKG - an event-centric knowledge graph with more than\n970 thousand events.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:11:37 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 14:07:47 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Costa", "Tarc\u00edsio Souza", ""], ["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""]]}, {"id": "2004.11870", "submitter": "Domenico Fabio Savo", "authors": "Gianluca Cima (1), Domenico Lembo (1), Riccardo Rosati (1), Domenico\n  Fabio Savo (2) ((1) Sapienza Universit\\`a di Roma, (2) Universit\\`a degli\n  Studi di Bergamo)", "title": "CQE in Description Logics Through Instance Indistinguishability\n  (extended version)", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study privacy-preserving query answering in Description Logics (DLs).\nSpecifically, we consider the approach of controlled query evaluation (CQE)\nbased on the notion of instance indistinguishability. We derive data complexity\nresults for query answering over DL-Lite$_{\\mathcal{R}}$ ontologies, through a\ncomparison with an alternative, existing confidentiality-preserving approach to\nCQE. Finally, we identify a semantically well-founded notion of approximated\nquery answering for CQE, and prove that, for DL-Lite$_{\\mathcal{R}}$\nontologies, this form of CQE is tractable with respect to data complexity and\nis first-order rewritable, i.e., it is always reducible to the evaluation of a\nfirst-order query over the data instance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:28:24 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Cima", "Gianluca", ""], ["Lembo", "Domenico", ""], ["Rosati", "Riccardo", ""], ["Savo", "Domenico Fabio", ""]]}, {"id": "2004.11947", "submitter": "Jiri Kubalik", "authors": "J. Kubal\\'ik, E. Derner, R. Babu\\v{s}ka", "title": "Symbolic Regression Driven by Training Data and Prior Knowledge", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3377930.3390152", "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symbolic regression, the search for analytic models is typically driven\npurely by the prediction error observed on the training data samples. However,\nwhen the data samples do not sufficiently cover the input space, the prediction\nerror does not provide sufficient guidance toward desired models. Standard\nsymbolic regression techniques then yield models that are partially incorrect,\nfor instance, in terms of their steady-state characteristics or local behavior.\nIf these properties were considered already during the search process, more\naccurate and relevant models could be produced. We propose a multi-objective\nsymbolic regression approach that is driven by both the training data and the\nprior knowledge of the properties the desired model should manifest. The\nproperties given in the form of formal constraints are internally represented\nby a set of discrete data samples on which candidate models are exactly\nchecked. The proposed approach was experimentally evaluated on three test\nproblems with results clearly demonstrating its capability to evolve realistic\nmodels that fit the training data well while complying with the prior knowledge\nof the desired model characteristics at the same time. It outperforms standard\nsymbolic regression by several orders of magnitude in terms of the mean squared\ndeviation from a reference model.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:15:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kubal\u00edk", "J.", ""], ["Derner", "E.", ""], ["Babu\u0161ka", "R.", ""]]}, {"id": "2004.11958", "submitter": "Awais Khan", "authors": "Ranjita Thapa (1), Noah Snavely (2), Serge Belongie (2), Awais Khan\n  (1) ((1) Plant Pathology and Plant-Microbe Biology Section, Cornell\n  University, Geneva, NY, (2) Cornell Tech)", "title": "The Plant Pathology 2020 challenge dataset to classify foliar disease of\n  apples", "comments": "11 pages, 5 figures, Kaggle competition website:\n  https://www.kaggle.com/c/plant-pathology-2020-fgvc7, CVPR fine-grained visual\n  categorization website: https://sites.google.com/view/fgvc7/competitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apple orchards in the U.S. are under constant threat from a large number of\npathogens and insects. Appropriate and timely deployment of disease management\ndepends on early disease detection. Incorrect and delayed diagnosis can result\nin either excessive or inadequate use of chemicals, with increased production\ncosts, environmental, and health impacts. We have manually captured 3,651\nhigh-quality, real-life symptom images of multiple apple foliar diseases, with\nvariable illumination, angles, surfaces, and noise. A subset, expert-annotated\nto create a pilot dataset for apple scab, cedar apple rust, and healthy leaves,\nwas made available to the Kaggle community for 'Plant Pathology Challenge';\npart of the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2020\n(Computer Vision and Pattern Recognition). We also trained an off-the-shelf\nconvolutional neural network (CNN) on this data for disease classification and\nachieved 97% accuracy on a held-out test set. This dataset will contribute\ntowards development and deployment of machine learning-based automated plant\ndisease classification algorithms to ultimately realize fast and accurate\ndisease detection. We will continue to add images to the pilot dataset for a\nlarger, more comprehensive expert-annotated dataset for future Kaggle\ncompetitions and to explore more advanced methods for disease classification\nand quantification.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:36:37 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Thapa", "Ranjita", ""], ["Snavely", "Noah", ""], ["Belongie", "Serge", ""], ["Khan", "Awais", ""]]}, {"id": "2004.12059", "submitter": "Di Zhuang", "authors": "Di Zhuang, Nam Nguyen, Keyu Chen, J. Morris Chang", "title": "SAIA: Split Artificial Intelligence Architecture for Mobile Healthcare\n  System", "comments": "17 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the advancement of deep learning (DL), the Internet of Things and cloud\ncomputing techniques for biomedical and healthcare problems, mobile healthcare\nsystems have received unprecedented attention. Since DL techniques usually\nrequire enormous amount of computation, most of them cannot be directly\ndeployed on the resource-constrained mobile and IoT devices. Hence, most of the\nmobile healthcare systems leverage the cloud computing infrastructure, where\nthe data collected by the mobile and IoT devices would be transmitted to the\ncloud computing platforms for analysis. However, in the contested environments,\nrelying on the cloud might not be practical at all times. For instance, the\nsatellite communication might be denied or disrupted. We propose SAIA, a Split\nArtificial Intelligence Architecture for mobile healthcare systems. Unlike\ntraditional approaches for artificial intelligence (AI) which solely exploits\nthe computational power of the cloud server, SAIA could not only relies on the\ncloud computing infrastructure while the wireless communication is available,\nbut also utilizes the lightweight AI solutions that work locally on the client\nside, hence, it can work even when the communication is impeded. In SAIA, we\npropose a meta-information based decision unit, that could tune whether a\nsample captured by the client should be operated by the embedded AI (i.e.,\nkeeping on the client) or the networked AI (i.e., sending to the server), under\ndifferent conditions. In our experimental evaluation, extensive experiments\nhave been conducted on two popular healthcare datasets. Our results show that\nSAIA consistently outperforms its baselines in terms of both effectiveness and\nefficiency.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 05:06:51 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 05:00:59 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhuang", "Di", ""], ["Nguyen", "Nam", ""], ["Chen", "Keyu", ""], ["Chang", "J. Morris", ""]]}, {"id": "2004.12062", "submitter": "Xiaoxi Guo", "authors": "Xiaoxi Guo, Sujoy Sikdar, Haibin Wang, Lirong Xia, Yongzhi Cao, Hanpin\n  Wang", "title": "Probabilistic Serial Mechanism for Multi-Type Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-type resource allocation (MTRA) problems, there are p $\\ge$ 2 types\nof items, and n agents, who each demand one unit of items of each type, and\nhave strict linear preferences over bundles consisting of one item of each\ntype. For MTRAs with indivisible items, our first result is an impossibility\ntheorem that is in direct contrast to the single type (p = 1) setting: No\nmechanism, the output of which is always decomposable into a probability\ndistribution over discrete assignments (where no item is split between agents),\ncan satisfy both sd-efficiency and sd-envy-freeness. To circumvent this\nimpossibility result, we consider the natural assumption of lexicographic\npreference, and provide an extension of the probabilistic serial (PS), called\nlexicographic probabilistic serial (LexiPS).We prove that LexiPS satisfies\nsd-efficiency and sd-envy-freeness, retaining the desirable properties of PS.\nMoreover, LexiPS satisfies sd-weak-strategyproofness when agents are not\nallowed to misreport their importance orders. For MTRAs with divisible items,\nwe show that the existing multi-type probabilistic serial (MPS) mechanism\nsatisfies the stronger efficiency notion of lexi-efficiency, and is\nsd-envy-free under strict linear preferences, and sd-weak-strategyproof under\nlexicographic preferences. We also prove that MPS can be characterized both by\nleximin-ptimality and by item-wise ordinal fairness, and the family of eating\nalgorithms which MPS belongs to can be characterized by no-generalized-cycle\ncondition.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 05:38:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Guo", "Xiaoxi", ""], ["Sikdar", "Sujoy", ""], ["Wang", "Haibin", ""], ["Xia", "Lirong", ""], ["Cao", "Yongzhi", ""], ["Wang", "Hanpin", ""]]}, {"id": "2004.12092", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir, Sam Campbell, Deborah Scott, Dan\n  Lubman", "title": "Towards Accurate Predictions and Causal 'What-if' Analyses for Planning\n  and Policy-making: A Case Study in Emergency Medical Services Demand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency Medical Services (EMS) demand load has become a considerable burden\nfor many government authorities, and EMS demand is often an early indicator for\nstress in communities, a warning sign of emerging problems. In this paper, we\nintroduce Deep Planning and Policy Making Net (DeepPPMNet), a Long Short-Term\nMemory network based, global forecasting and inference framework to forecast\nthe EMS demand, analyse causal relationships, and perform `what-if' analyses\nfor policy-making across multiple local government areas. Unless traditional\nunivariate forecasting techniques, the proposed method follows the global\nforecasting methodology, where a model is trained across all the available EMS\ndemand time series to exploit the potential cross-series information available.\nDeepPPMNet also uses seasonal decomposition techniques, incorporated in two\ndifferent training paradigms into the framework, to suit various\ncharacteristics of the EMS related time series data. We then explore causal\nrelationships using the notion of Granger Causality, where the global\nforecasting framework enables us to perform `what-if' analyses that could be\nused for the national policy-making process. We empirically evaluate our\nmethod, using a set of EMS datasets related to alcohol, drug use and self-harm\nin Australia. The proposed framework is able to outperform many\nstate-of-the-art techniques and achieve competitive results in terms of\nforecasting accuracy. We finally illustrate its use for policy-making in an\nexample regarding alcohol outlet licenses.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 09:03:10 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Campbell", "Sam", ""], ["Scott", "Deborah", ""], ["Lubman", "Dan", ""]]}, {"id": "2004.12117", "submitter": "Reza Refaei", "authors": "Reza Refaei Afshar and Yingqian Zhang and Murat Firat and Uzay Kaymak", "title": "A State Aggregation Approach for Solving Knapsack Problem with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Deep Reinforcement Learning (DRL) approach for solving\nknapsack problem. The proposed method consists of a state aggregation step\nbased on tabular reinforcement learning to extract features and construct\nstates. The state aggregation policy is applied to each problem instance of the\nknapsack problem, which is used with Advantage Actor Critic (A2C) algorithm to\ntrain a policy through which the items are sequentially selected at each time\nstep. The method is a constructive solution approach and the process of\nselecting items is repeated until the final solution is obtained. The\nexperiments show that our approach provides close to optimal solutions for all\ntested instances, outperforms the greedy algorithm, and is able to handle\nlarger instances and more flexible than an existing DRL approach. In addition,\nthe results demonstrate that the proposed model with the state aggregation\nstrategy not only gives better solutions but also learns in less timesteps,\nthan the one without state aggregation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 11:52:24 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Afshar", "Reza Refaei", ""], ["Zhang", "Yingqian", ""], ["Firat", "Murat", ""], ["Kaymak", "Uzay", ""]]}, {"id": "2004.12152", "submitter": "Briti Gangopadhyay", "authors": "Briti Gangopadhyay, Somnath Hazra and Pallab Dasgupta", "title": "Semi-Lexical Languages -- A Formal Basis for Unifying Machine Learning\n  and Symbolic Reasoning in Computer Vision", "comments": "The paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human vision is able to compensate imperfections in sensory inputs from the\nreal world by reasoning based on prior knowledge about the world. Machine\nlearning has had a significant impact on computer vision due to its inherent\nability in handling imprecision, but the absence of a reasoning framework based\non domain knowledge limits its ability to interpret complex scenarios. We\npropose semi-lexical languages as a formal basis for dealing with imperfect\ntokens provided by the real world. The power of machine learning is used to map\nthe imperfect tokens into the alphabet of the language and symbolic reasoning\nis used to determine the membership of input in the language. Semi-lexical\nlanguages also have bindings that prevent the variations in which a\nsemi-lexical token is interpreted in different parts of the input, thereby\nleaning on deduction to enhance the quality of recognition of individual\ntokens. We present case studies that demonstrate the advantage of using such a\nframework over pure machine learning and pure symbolic methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:37:24 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:20:08 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Gangopadhyay", "Briti", ""], ["Hazra", "Somnath", ""], ["Dasgupta", "Pallab", ""]]}, {"id": "2004.12171", "submitter": "Mani A", "authors": "Mani A and Sandor Radeleczki", "title": "Algebraic Approach to Directed Rough Sets", "comments": "37 pages, Forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In relational approach to general rough sets, ideas of directed relations are\nsupplemented with additional conditions for multiple algebraic approaches in\nthis research paper. The relations are also specialized to representations of\ngeneral parthood that are upper-directed, reflexive and antisymmetric for a\nbetter behaved groupoidal semantics over the set of roughly equivalent objects\nby the first author. Another distinct algebraic semantics over the set of\napproximations, and a new knowledge interpretation are also invented in this\nresearch by her. Because of minimal conditions imposed on the relations,\nneighborhood granulations are used in the construction of all approximations\n(granular and pointwise). Necessary and sufficient conditions for the lattice\nof local upper approximations to be completely distributive are proved by the\nsecond author. These results are related to formal concept analysis.\nApplications to student centered learning and decision making are also\noutlined.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 15:39:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["A", "Mani", ""], ["Radeleczki", "Sandor", ""]]}, {"id": "2004.12193", "submitter": "Chi Zhang", "authors": "Wenhe Zhang, Chi Zhang, Yixin Zhu, Song-Chun Zhu", "title": "Machine Number Sense: A Dataset of Visual Arithmetic Problems for\n  Abstract and Relational Reasoning", "comments": "AAAI 2020 Oral. Project page:\n  https://sites.google.com/view/number-sense/home Code:\n  https://github.com/zwh1999anne/Machine-Number-Sense-Dataset Dataset:\n  https://drive.google.com/file/d/17KuL8KOIDAeRL-lD418oiDEm8bE6TEFb/view", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a comprehensive indicator of mathematical thinking and intelligence, the\nnumber sense (Dehaene 2011) bridges the induction of symbolic concepts and the\ncompetence of problem-solving. To endow such a crucial cognitive ability to\nmachine intelligence, we propose a dataset, Machine Number Sense (MNS),\nconsisting of visual arithmetic problems automatically generated using a\ngrammar model--And-Or Graph (AOG). These visual arithmetic problems are in the\nform of geometric figures: each problem has a set of geometric shapes as its\ncontext and embedded number symbols. Solving such problems is not trivial; the\nmachine not only has to recognize the number, but also to interpret the number\nwith its contexts, shapes, and relations (e.g., symmetry) together with proper\noperations. We benchmark the MNS dataset using four predominant neural network\nmodels as baselines in this visual reasoning task. Comprehensive experiments\nshow that current neural-network-based models still struggle to understand\nnumber concepts and relational operations. We show that a simple brute-force\nsearch algorithm could work out some of the problems without context\ninformation. Crucially, taking geometric context into account by an additional\nperception module would provide a sharp performance gain with fewer search\nsteps. Altogether, we call for attention in fusing the classic search-based\nalgorithms with modern neural networks to discover the essential number\nconcepts in future research.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:14:58 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Wenhe", ""], ["Zhang", "Chi", ""], ["Zhu", "Yixin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2004.12212", "submitter": "Lior Sidi", "authors": "Lior Sidi and Hadar Klein", "title": "Neural Network-Based Collaborative Filtering for Question Sequencing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  E-Learning systems (ELS) and Intelligent Tutoring Systems (ITS) play a\nsignificant part in today's education programs. Sequencing questions is the art\nof generating a personalized quiz for a target learner. A personalized test\nwill enrich the learner's experience and will contribute to a more effective\nand efficient learning process. In this paper, we used the Neural Collaborative\nFiltering (NCF) model to generate question sequencing and compare it to a\npair-wise memory-based question sequencing algorithm - EduRank. The NCF model\nshowed significantly better ranking results than the EduRank model with an\nAverage precision correlation score of 0.85 compared to 0.8.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 19:15:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sidi", "Lior", ""], ["Klein", "Hadar", ""]]}, {"id": "2004.12277", "submitter": "Sheng Shi", "authors": "Sheng Shi, Yangzhou Du and Wei Fan", "title": "An Extension of LIME with Improvement of Interpretability and Fidelity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning makes significant achievements in Artificial Intelligence\n(AI), the lack of transparency has limited its broad application in various\nvertical domains. Explainability is not only a gateway between AI and real\nworld, but also a powerful feature to detect flaw of the models and bias of the\ndata. Local Interpretable Model-agnostic Explanation (LIME) is a\nwidely-accepted technique that explains the prediction of any classifier\nfaithfully by learning an interpretable model locally around the predicted\ninstance. As an extension of LIME, this paper proposes an high-interpretability\nand high-fidelity local explanation method, known as Local Explanation using\nfeature Dependency Sampling and Nonlinear Approximation (LEDSNA). Given an\ninstance being explained, LEDSNA enhances interpretability by feature sampling\nwith intrinsic dependency. Besides, LEDSNA improves the local explanation\nfidelity by approximating nonlinear boundary of local decision. We evaluate our\nmethod with classification tasks in both image domain and text domain.\nExperiments show that LEDSNA's explanation of the back-box model achieves much\nbetter performance than original LIME in terms of interpretability and\nfidelity.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 02:54:27 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shi", "Sheng", ""], ["Du", "Yangzhou", ""], ["Fan", "Wei", ""]]}, {"id": "2004.12303", "submitter": "Xinyue Zheng", "authors": "Xinyue Zheng, Peng Wang, Qigang Wang, Zhongchao Shi", "title": "Challenge Closed-book Science Exam: A Meta-learning Based Question\n  Answering System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work in standardized science exams requires support from large text\ncorpus, such as targeted science corpus fromWikipedia or SimpleWikipedia.\nHowever, retrieving knowledge from the large corpus is time-consuming and\nquestions embedded in complex semantic representation may interfere with\nretrieval. Inspired by the dual process theory in cognitive science, we propose\na MetaQA framework, where system 1 is an intuitive meta-classifier and system 2\nis a reasoning module. Specifically, our method based on meta-learning method\nand large language model BERT, which can efficiently solve science problems by\nlearning from related example questions without relying on external knowledge\nbases. We evaluate our method on AI2 Reasoning Challenge (ARC), and the\nexperimental results show that meta-classifier yields considerable\nclassification performance on emerging question types. The information provided\nby meta-classifier significantly improves the accuracy of reasoning module from\n46.6% to 64.2%, which has a competitive advantage over retrieval-based QA\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 07:43:30 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zheng", "Xinyue", ""], ["Wang", "Peng", ""], ["Wang", "Qigang", ""], ["Shi", "Zhongchao", ""]]}, {"id": "2004.12311", "submitter": "Hao Cheng", "authors": "Hao Cheng, Fanxu Meng, Ke Li, Yuting Gao, Guangming Lu, Xing Sun,\n  Rongrong Ji", "title": "Filter Grafting for Deep Neural Networks: Reason, Method, and\n  Cultivation", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.05868", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter is the key component in modern convolutional neural networks (CNNs).\nHowever, since CNNs are usually over-parameterized, a pre-trained network\nalways contain some invalid (unimportant) filters. These filters have\nrelatively small $l_{1}$ norm and contribute little to the output\n(\\textbf{Reason}). While filter pruning removes these invalid filters for\nefficiency consideration, we tend to reactivate them to improve the\nrepresentation capability of CNNs. In this paper, we introduce filter grafting\n(\\textbf{Method}) to achieve this goal. The activation is processed by grafting\nexternal information (weights) into invalid filters. To better perform the\ngrafting, we develop a novel criterion to measure the information of filters\nand an adaptive weighting strategy to balance the grafted information among\nnetworks. After the grafting operation, the network has fewer invalid filters\ncompared with its initial state, enpowering the model with more representation\ncapacity. Meanwhile, since grafting is operated reciprocally on all networks\ninvolved, we find that grafting may lose the information of valid filters when\nimproving invalid filters. To gain a universal improvement on both valid and\ninvalid filters, we compensate grafting with distillation\n(\\textbf{Cultivation}) to overcome the drawback of grafting . Extensive\nexperiments are performed on the classification and recognition tasks to show\nthe superiority of our method. Code is available at\n\\textcolor{black}{\\emph{https://github.com/fxmeng/filter-grafting}}.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:36:26 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 03:51:47 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Cheng", "Hao", ""], ["Meng", "Fanxu", ""], ["Li", "Ke", ""], ["Gao", "Yuting", ""], ["Lu", "Guangming", ""], ["Sun", "Xing", ""], ["Ji", "Rongrong", ""]]}, {"id": "2004.12316", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Chen Zhang, Hao Wang, Yong Liu, Chunyan Miao", "title": "Towards Persona-Based Empathetic Conversational Models", "comments": "Accepted to EMNLP 2020 (A new dataset is proposed:\n  https://github.com/zhongpeixiang/PEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empathetic conversational models have been shown to improve user satisfaction\nand task outcomes in numerous domains. In Psychology, persona has been shown to\nbe highly correlated to personality, which in turn influences empathy. In\naddition, our empirical analysis also suggests that persona plays an important\nrole in empathetic conversations. To this end, we propose a new task towards\npersona-based empathetic conversations and present the first empirical study on\nthe impact of persona on empathetic responding. Specifically, we first present\na novel large-scale multi-domain dataset for persona-based empathetic\nconversations. We then propose CoBERT, an efficient BERT-based response\nselection model that obtains the state-of-the-art performance on our dataset.\nFinally, we conduct extensive experiments to investigate the impact of persona\non empathetic responding. Notably, our results show that persona improves\nempathetic responding more when CoBERT is trained on empathetic conversations\nthan non-empathetic ones, establishing an empirical link between persona and\nempathy in human conversations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:51:01 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 01:55:05 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 03:40:56 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 06:48:24 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2020 08:23:51 GMT"}, {"version": "v6", "created": "Mon, 5 Oct 2020 09:21:06 GMT"}, {"version": "v7", "created": "Thu, 19 Nov 2020 11:00:23 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhong", "Peixiang", ""], ["Zhang", "Chen", ""], ["Wang", "Hao", ""], ["Liu", "Yong", ""], ["Miao", "Chunyan", ""]]}, {"id": "2004.12317", "submitter": "\\`Eric Pairet", "authors": "\\`Eric Pairet, Juan David Hern\\'andez, Marc Carreras, Yvan Petillot,\n  Morteza Lahijanian", "title": "Online Mapping and Motion Planning under Uncertainty for Safe Navigation\n  in Unknown Environments", "comments": "The International Journal of Robotics Research (under review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe autonomous navigation is an essential and challenging problem for robots\noperating in highly unstructured or completely unknown environments. Under\nthese conditions, not only robotic systems must deal with limited localisation\ninformation, but also their manoeuvrability is constrained by their dynamics\nand often suffer from uncertainty. In order to cope with these constraints,\nthis manuscript proposes an uncertainty-based framework for mapping and\nplanning feasible motions online with probabilistic safety-guarantees. The\nproposed approach deals with the motion, probabilistic safety, and online\ncomputation constraints by: (i) incrementally mapping the surroundings to build\nan uncertainty-aware representation of the environment, and (ii) iteratively\n(re)planning trajectories to goal that are kinodynamically feasible and\nprobabilistically safe through a multi-layered sampling-based planner in the\nbelief space. In-depth empirical analyses illustrate some important properties\nof this approach, namely, (a) the multi-layered planning strategy enables rapid\nexploration of the high-dimensional belief space while preserving asymptotic\noptimality and completeness guarantees, and (b) the proposed routine for\nprobabilistic collision checking results in tighter probability bounds in\ncomparison to other uncertainty-aware planners in the literature. Furthermore,\nreal-world in-water experimental evaluation on a non-holonomic torpedo-shaped\nautonomous underwater vehicle and simulated trials in the Stairwell scenario of\nthe DARPA Subterranean Challenge 2019 on a quadrotor unmanned aerial vehicle\ndemonstrate the efficacy of the method as well as its suitability for systems\nwith limited on-board computational power.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:53:37 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 15:23:18 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Pairet", "\u00c8ric", ""], ["Hern\u00e1ndez", "Juan David", ""], ["Carreras", "Marc", ""], ["Petillot", "Yvan", ""], ["Lahijanian", "Morteza", ""]]}, {"id": "2004.12330", "submitter": "Adrian Groza", "authors": "Adrian Groza", "title": "Detecting fake news for the new coronavirus by reasoning on the Covid-19\n  ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the Covid-19 pandemic, many were quick to spread deceptive\ninformation. I investigate here how reasoning in Description Logics (DLs) can\ndetect inconsistencies between trusted medical sources and not trusted ones.\nThe not-trusted information comes in natural language (e.g. \"Covid-19 affects\nonly the elderly\"). To automatically convert into DLs, I used the FRED\nconverter. Reasoning in Description Logics is then performed with the Racer\ntool.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 09:34:32 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Groza", "Adrian", ""]]}, {"id": "2004.12357", "submitter": "Hui Wang", "authors": "Hui Wang, Mike Preuss, Aske Plaat", "title": "Warm-Start AlphaZero Self-Play Search Enhancements", "comments": null, "journal-ref": "PPSN 2020", "doi": "10.1007/978-3-030-58115-2_37", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, AlphaZero has achieved landmark results in deep reinforcement\nlearning, by providing a single self-play architecture that learned three\ndifferent games at super human level. AlphaZero is a large and complicated\nsystem with many parameters, and success requires much compute power and\nfine-tuning. Reproducing results in other games is a challenge, and many\nresearchers are looking for ways to improve results while reducing\ncomputational demands. AlphaZero's design is purely based on self-play and\nmakes no use of labeled expert data ordomain specific enhancements; it is\ndesigned to learn from scratch. We propose a novel approach to deal with this\ncold-start problem by employing simple search enhancements at the beginning\nphase of self-play training, namely Rollout, Rapid Action Value Estimate (RAVE)\nand dynamically weighted combinations of these with the neural network, and\nRolling Horizon Evolutionary Algorithms (RHEA). Our experiments indicate that\nmost of these enhancements improve the performance of their baseline player in\nthree different (small) board games, with especially RAVE based variants\nplaying strongly.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 11:48:53 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Wang", "Hui", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "2004.12363", "submitter": "Xiaojun Quan", "authors": "Kai Wang and Junfeng Tian and Rui Wang and Xiaojun Quan and Jianxing\n  Yu", "title": "Multi-Domain Dialogue Acts and Response Co-Generation", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating fluent and informative responses is of critical importance for\ntask-oriented dialogue systems. Existing pipeline approaches generally predict\nmultiple dialogue acts first and use them to assist response generation. There\nare at least two shortcomings with such approaches. First, the inherent\nstructures of multi-domain dialogue acts are neglected. Second, the semantic\nassociations between acts and responses are not taken into account for response\ngeneration. To address these issues, we propose a neural co-generation model\nthat generates dialogue acts and responses concurrently. Unlike those pipeline\napproaches, our act generation module preserves the semantic structures of\nmulti-domain dialogue acts and our response generation module dynamically\nattends to different acts as needed. We train the two modules jointly using an\nuncertainty loss to adjust their task weights adaptively. Extensive experiments\nare conducted on the large-scale MultiWOZ dataset and the results show that our\nmodel achieves very favorable improvement over several state-of-the-art models\nin both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 12:21:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Kai", ""], ["Tian", "Junfeng", ""], ["Wang", "Rui", ""], ["Quan", "Xiaojun", ""], ["Yu", "Jianxing", ""]]}, {"id": "2004.12399", "submitter": "Jerry Zikun Chen", "authors": "Jerry Zikun Chen", "title": "Reinforcement Learning Generalization with Surprise Minimization", "comments": "Inductive biases, invariances and generalization in RL Workshop, ICML\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization remains a challenging problem for deep reinforcement learning\nalgorithms, which are often trained and tested on the same set of deterministic\ngame environments. When test environments are unseen and perturbed but the\nnature of the task remains the same, generalization gaps can arise. In this\nwork, we propose and evaluate a surprise minimizing agent on a generalization\nbenchmark to show an additional reward learned from a simple density model can\nshow robustness in procedurally generated game environments that provide\nconstant source of entropy and stochasticity.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 14:50:59 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 23:25:49 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Chen", "Jerry Zikun", ""]]}, {"id": "2004.12480", "submitter": "Najma Mathema", "authors": "Najma Mathema, Michael A. Goodrich, and Jacob W. Crandall", "title": "Predicting Plans and Actions in Two-Player Repeated Games", "comments": "Accepted in The AAAI 2020 Workshop on Plan, Activity, and Intent\n  Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) agents will need to interact with both other AI\nagents and humans. Creating models of associates help to predict the modeled\nagents' actions, plans, and intentions. This work introduces algorithms that\npredict actions, plans and intentions in repeated play games, with providing an\nexploration of algorithms. We form a generative Bayesian approach to model S#.\nS# is designed as a robust algorithm that learns to cooperate with its\nassociate in 2 by 2 matrix games. The actions, plans and intentions associated\nwith each S# expert are identified from the literature, grouping the S# experts\naccordingly, and thus predicting actions, plans, and intentions based on their\nstate probabilities. Two prediction methods are explored for Prisoners Dilemma:\nthe Maximum A Posteriori (MAP) and an Aggregation approach. MAP (~89% accuracy)\nperformed the best for action prediction. Both methods predicted plans of S#\nwith ~88% accuracy. Paired T-test shows that MAP performs significantly better\nthan Aggregation for predicting S#'s actions without cheap talk. Intention is\nexplored based on the goals of the S# experts; results show that goals are\npredicted precisely when modeling S#. The obtained results show that the\nproposed Bayesian approach is well suited for modeling agents in two-player\nrepeated games.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:03:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Mathema", "Najma", ""], ["Goodrich", "Michael A.", ""], ["Crandall", "Jacob W.", ""]]}, {"id": "2004.12481", "submitter": "Andrew Wood", "authors": "Andrew Wood, Ali Sydney, Peter Chin, Bishal Thapa, Ryan Ross", "title": "GymFG: A Framework with a Gym Interface for FlightGear", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, progress in deployable autonomous flight systems has\nslowly stagnated. This is reflected in today's production air-crafts, where\npilots only enable simple physics-based systems such as autopilot for takeoff,\nlanding, navigation, and terrain/traffic avoidance. Evidently, autonomy has not\ngained the trust of the community where higher problem complexity and cognitive\nworkload are required. To address trust, we must revisit the process for\ndeveloping autonomous capabilities: modeling and simulation. Given the\nprohibitive costs for live tests, we need to prototype and evaluate autonomous\naerial agents in a high fidelity flight simulator with autonomous learning\ncapabilities applicable to flight systems: such a open-source development\nplatform is not available. As a result, we have developed GymFG: GymFG couples\nand extends a high fidelity, open-source flight simulator and a robust agent\nlearning framework to facilitate learning of more complex tasks. Furthermore,\nwe have demonstrated the use of GymFG to train an autonomous aerial agent using\nImitation Learning. With GymFG, we can now deploy innovative ideas to address\ncomplex problems and build the trust necessary to move prototypes to the\nreal-world.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:06:20 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wood", "Andrew", ""], ["Sydney", "Ali", ""], ["Chin", "Peter", ""], ["Thapa", "Bishal", ""], ["Ross", "Ryan", ""]]}, {"id": "2004.12485", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna Gottipati, Boris Sattarov, Sufeng Niu, Yashaswi Pathak,\n  Haoran Wei, Shengchao Liu, Karam M. J. Thomas, Simon Blackburn, Connor W.\n  Coley, Jian Tang, Sarath Chandar, Yoshua Bengio", "title": "Learning To Navigate The Synthetically Accessible Chemical Space Using\n  Reinforcement Learning", "comments": "added the statistics of top-100 compounds used logP metric with\n  scaled components added values of the initial reactants to the box plots some\n  values in tables are recalculated due to the inconsistent environments on\n  different machines. corresponding benchmarks were rerun with the requirements\n  on github. no significant changes in the results. corrected figures in the\n  Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, there has been significant progress in the field of\nmachine learning for de novo drug design, particularly in deep generative\nmodels. However, current generative approaches exhibit a significant challenge\nas they do not ensure that the proposed molecular structures can be feasibly\nsynthesized nor do they provide the synthesis routes of the proposed small\nmolecules, thereby seriously limiting their practical applicability. In this\nwork, we propose a novel forward synthesis framework powered by reinforcement\nlearning (RL) for de novo drug design, Policy Gradient for Forward Synthesis\n(PGFS), that addresses this challenge by embedding the concept of synthetic\naccessibility directly into the de novo drug design system. In this setup, the\nagent learns to navigate through the immense synthetically accessible chemical\nspace by subjecting commercially available small molecule building blocks to\nvalid chemical reactions at every time step of the iterative virtual multi-step\nsynthesis process. The proposed environment for drug discovery provides a\nhighly challenging test-bed for RL algorithms owing to the large state space\nand high-dimensional continuous action space with hierarchical actions. PGFS\nachieves state-of-the-art performance in generating structures with high QED\nand penalized clogP. Moreover, we validate PGFS in an in-silico\nproof-of-concept associated with three HIV targets. Finally, we describe how\nthe end-to-end training conceptualized in this study represents an important\nparadigm in radically expanding the synthesizable chemical space and automating\nthe drug discovery process.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:40:03 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 03:28:15 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Gottipati", "Sai Krishna", ""], ["Sattarov", "Boris", ""], ["Niu", "Sufeng", ""], ["Pathak", "Yashaswi", ""], ["Wei", "Haoran", ""], ["Liu", "Shengchao", ""], ["Thomas", "Karam M. J.", ""], ["Blackburn", "Simon", ""], ["Coley", "Connor W.", ""], ["Tang", "Jian", ""], ["Chandar", "Sarath", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2004.12527", "submitter": "Jerry Zikun Chen", "authors": "Jerrod Parker and Jerry Zikun Chen", "title": "Neural Machine Translation with Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent algorithms in machine translation have included a value network to\nassist the policy network when deciding which word to output at each step of\nthe translation. The addition of a value network helps the algorithm perform\nbetter on evaluation metrics like the BLEU score. After training the policy and\nvalue networks in a supervised setting, the policy and value networks can be\njointly improved through common actor-critic methods. The main idea of our\nproject is to instead leverage Monte-Carlo Tree Search (MCTS) to search for\ngood output words with guidance from a combined policy and value network\narchitecture in a similar fashion as AlphaZero. This network serves both as a\nlocal and a global look-ahead reference that uses the result of the search to\nimprove itself. Experiments using the IWLST14 German to English translation\ndataset show that our method outperforms the actor-critic methods used in\nrecent machine translation papers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:03:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Parker", "Jerrod", ""], ["Chen", "Jerry Zikun", ""]]}, {"id": "2004.12554", "submitter": "Frederico Gadelha Guimaraes", "authors": "Petr\\^onio C\\^andido de Lima e Silva, Carlos Alberto Severiano Junior,\n  Marcos Antonio Alves, Rodrigo Silva, Miri Weiss Cohen, Frederico Gadelha\n  Guimar\\~aes", "title": "Forecasting in Non-stationary Environments with Fuzzy Time Series", "comments": "21 pages, 7 figures, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a Non-Stationary Fuzzy Time Series (NSFTS) method\nwith time varying parameters adapted from the distribution of the data. In this\napproach, we employ Non-Stationary Fuzzy Sets, in which perturbation functions\nare used to adapt the membership function parameters in the knowledge base in\nresponse to statistical changes in the time series. The proposed method is\ncapable of dynamically adapting its fuzzy sets to reflect the changes in the\nstochastic process based on the residual errors, without the need to retraining\nthe model. This method can handle non-stationary and heteroskedastic data as\nwell as scenarios with concept-drift. The proposed approach allows the model to\nbe trained only once and remain useful long after while keeping reasonable\naccuracy. The flexibility of the method by means of computational experiments\nwas tested with eight synthetic non-stationary time series data with several\nkinds of concept drifts, four real market indices (Dow Jones, NASDAQ, SP500 and\nTAIEX), three real FOREX pairs (EUR-USD, EUR-GBP, GBP-USD), and two real\ncryptocoins exchange rates (Bitcoin-USD and Ethereum-USD). As competitor models\nthe Time Variant fuzzy time series and the Incremental Ensemble were used,\nthese are two of the major approaches for handling non-stationary data sets.\nNon-parametric tests are employed to check the significance of the results. The\nproposed method shows resilience to concept drift, by adapting parameters of\nthe model, while preserving the symbolic structure of the knowledge base.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:35:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Silva", "Petr\u00f4nio C\u00e2ndido de Lima e", ""], ["Junior", "Carlos Alberto Severiano", ""], ["Alves", "Marcos Antonio", ""], ["Silva", "Rodrigo", ""], ["Cohen", "Miri Weiss", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2004.12684", "submitter": "Mohammad Hatami", "authors": "Mohammad Hatami, Mojtaba Jahandideh, Markus Leinonen and Marian\n  Codreanu", "title": "Age-Aware Status Update Control for Energy Harvesting IoT Sensors via\n  Reinforcement Learning", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an IoT sensing network with multiple users, multiple energy\nharvesting sensors, and a wireless edge node acting as a gateway between the\nusers and sensors. The users request for updates about the value of physical\nprocesses, each of which is measured by one sensor. The edge node has a cache\nstorage that stores the most recently received measurements from each sensor.\nUpon receiving a request, the edge node can either command the corresponding\nsensor to send a status update, or use the data in the cache. We aim to find\nthe best action of the edge node to minimize the average long-term cost which\ntrade-offs between the age of information and energy consumption. We propose a\npractical reinforcement learning approach that finds an optimal policy without\nknowing the exact battery levels of the sensors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:01:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hatami", "Mohammad", ""], ["Jahandideh", "Mojtaba", ""], ["Leinonen", "Markus", ""], ["Codreanu", "Marian", ""]]}, {"id": "2004.12734", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto", "title": "An Epistemic Approach to the Formal Specification of Statistical Machine\n  Learning", "comments": "Accepted in Software and Systems Modeling https://rdcu.be/b7ssR This\n  paper is the journal version of the SEFM'19 conference paper arxiv:1907.10327", "journal-ref": null, "doi": "10.1007/s10270-020-00825-2", "report-no": null, "categories": "cs.LO cs.AI cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an epistemic approach to formalizing statistical properties of\nmachine learning. Specifically, we introduce a formal model for supervised\nlearning based on a Kripke model where each possible world corresponds to a\npossible dataset and modal operators are interpreted as transformation and\ntesting on datasets. Then we formalize various notions of the classification\nperformance, robustness, and fairness of statistical classifiers by using our\nextension of statistical epistemic logic (StatEL). In this formalization, we\nshow relationships among properties of classifiers, and relevance between\nclassification performance and robustness. As far as we know, this is the first\nwork that uses epistemic models and logical formulas to express statistical\nproperties of machine learning, and would be a starting point to develop\ntheories of formal specification of machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:16:45 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:52:54 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 17:51:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kawamoto", "Yusuke", ""]]}, {"id": "2004.12750", "submitter": "Mohamed El Yafrani", "authors": "Mohamed El Yafrani, Marcella Scoczynski Ribeiro Martins, Inkyung Sung,\n  Markus Wagner, Carola Doerr, and Peter Nielsen", "title": "MATE: A Model-based Algorithm Tuning Engine", "comments": "16 pages. Submitted to Evo* 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a Model-based Algorithm Turning Engine, namely\nMATE, where the parameters of an algorithm are represented as expressions of\nthe features of a target optimisation problem. In contrast to most static\n(feature-independent) algorithm tuning engines such as irace and SPOT, our\napproach aims to derive the best parameter configuration of a given algorithm\nfor a specific problem, exploiting the relationships between the algorithm\nparameters and the features of the problem. We formulate the problem of finding\nthe relationships between the parameters and the problem features as a symbolic\nregression problem and we use genetic programming to extract these expressions.\nFor the evaluation, we apply our approach to configuration of the (1+1) EA and\nRLS algorithms for the OneMax, LeadingOnes, BinValue and Jump optimisation\nproblems, where the theoretically optimal algorithm parameters to the problems\nare available as functions of the features of the problems. Our study shows\nthat the found relationships typically comply with known theoretical results,\nthus demonstrating a new opportunity to consider model-based parameter tuning\nas an effective alternative to the static algorithm tuning engines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:50:48 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:38:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Yafrani", "Mohamed El", ""], ["Martins", "Marcella Scoczynski Ribeiro", ""], ["Sung", "Inkyung", ""], ["Wagner", "Markus", ""], ["Doerr", "Carola", ""], ["Nielsen", "Peter", ""]]}, {"id": "2004.12770", "submitter": "Crist\\'obal Eyzaguirre", "authors": "Cristobal Eyzaguirre, Alvaro Soto", "title": "Differentiable Adaptive Computation Time for Visual Reasoning", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel attention-based algorithm for achieving adaptive\ncomputation called DACT, which, unlike existing ones, is end-to-end\ndifferentiable. Our method can be used in conjunction with many networks; in\nparticular, we study its application to the widely known MAC architecture,\nobtaining a significant reduction in the number of recurrent steps needed to\nachieve similar accuracies, therefore improving its performance to computation\nratio. Furthermore, we show that by increasing the maximum number of steps\nused, we surpass the accuracy of even our best non-adaptive MAC in the CLEVR\ndataset, demonstrating that our approach is able to control the number of steps\nwithout significant loss of performance. Additional advantages provided by our\napproach include considerably improving interpretability by discarding useless\nsteps and providing more insights into the underlying reasoning process.\nFinally, we present adaptive computation as an equivalent to an ensemble of\nmodels, similar to a mixture of expert formulation. Both the code and the\nconfiguration files for our experiments are made available to support further\nresearch in this area.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 13:20:23 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:16:57 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 16:57:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Eyzaguirre", "Cristobal", ""], ["Soto", "Alvaro", ""]]}, {"id": "2004.12781", "submitter": "Rupert Small", "authors": "Volodymyr Rospotniuk and Rupert Small", "title": "Optimal Any-Angle Pathfinding on a Sphere", "comments": "29 pages, 19 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathfinding in Euclidean space is a common problem faced in robotics and\ncomputer games. For long-distance navigation on the surface of the earth or in\nouter space however, approximating the geometry as Euclidean can be\ninsufficient for real-world applications such as the navigation of spacecraft,\naeroplanes, drones and ships. This article describes an any-angle pathfinding\nalgorithm for calculating the shortest path between point pairs over the\nsurface of a sphere. Introducing several novel adaptations, it is shown that\nAnya as described by (Harabor & Grastien, 2013) for Euclidean space can be\nextended to Spherical geometry. There, where the shortest-distance line between\ncoordinates is defined instead by a great-circle path, the optimal solution is\ntypically a curved line in Euclidean space. In addition the turning points for\noptimal paths in Spherical geometry are not necessarily corner points as they\nare in Euclidean space, as will be shown, making further substantial\nadaptations to Anya necessary. Spherical Anya returns the optimal path on the\nsphere, given these different properties of world maps defined in Spherical\ngeometry. It preserves all primary benefits of Anya in Euclidean geometry,\nnamely the Spherical Anya algorithm always returns an optimal path on a sphere\nand does so entirely on-line, without any preprocessing or large memory\noverheads. Performance benchmarks are provided for several game maps including\nStarcraft and Warcraft III as well as for sea navigation on Earth using the\nNOAA bathymetric dataset. Always returning the shorter path compared with the\nEuclidean approximation yielded by Anya, Spherical Anya is shown to be faster\nthan Anya for the majority of sea routes and slower for Game Maps and Random\nMaps.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:33:05 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 09:50:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Rospotniuk", "Volodymyr", ""], ["Small", "Rupert", ""]]}, {"id": "2004.12846", "submitter": "Eseoghene Ben-Iwhiwhu", "authors": "Eseoghene Ben-Iwhiwhu, Pawel Ladosz, Jeffery Dick, Wen-Hua Chen,\n  Praveen Pilly, Andrea Soltoggio", "title": "Evolving Inborn Knowledge For Fast Adaptation in Dynamic POMDP Problems", "comments": "9 pages. Accepted as a full paper in the Genetic and Evolutionary\n  Computation Conference (GECCO 2020)", "journal-ref": null, "doi": "10.1145/3377930.3390214", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid online adaptation to changing tasks is an important problem in machine\nlearning and, recently, a focus of meta-reinforcement learning. However,\nreinforcement learning (RL) algorithms struggle in POMDP environments because\nthe state of the system, essential in a RL framework, is not always visible.\nAdditionally, hand-designed meta-RL architectures may not include suitable\ncomputational structures for specific learning problems. The evolution of\nonline learning mechanisms, on the contrary, has the ability to incorporate\nlearning strategies into an agent that can (i) evolve memory when required and\n(ii) optimize adaptation speed to specific online learning problems. In this\npaper, we exploit the highly adaptive nature of neuromodulated neural networks\nto evolve a controller that uses the latent space of an autoencoder in a POMDP.\nThe analysis of the evolved networks reveals the ability of the proposed\nalgorithm to acquire inborn knowledge in a variety of aspects such as the\ndetection of cues that reveal implicit rewards, and the ability to evolve\nlocation neurons that help with navigation. The integration of inborn knowledge\nand online plasticity enabled fast adaptation and better performance in\ncomparison to some non-evolutionary meta-reinforcement learning algorithms. The\nalgorithm proved also to succeed in the 3D gaming environment Malmo Minecraft.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 14:55:08 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:04:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ben-Iwhiwhu", "Eseoghene", ""], ["Ladosz", "Pawel", ""], ["Dick", "Jeffery", ""], ["Chen", "Wen-Hua", ""], ["Pilly", "Praveen", ""], ["Soltoggio", "Andrea", ""]]}, {"id": "2004.12850", "submitter": "Masataro Asai", "authors": "Masataro Asai and Christian Muise", "title": "Learning Neural-Symbolic Descriptive Planning Models via Cube-Space\n  Priors: The Voyage Home (to STRIPS)", "comments": "Accepted in IJCAI 2020 main track (accept ratio 12.6%). The prequel\n  of this paper, \"The Search for STRIPS\", can be found here: arXiv:1912.05492 .\n  (update, 2020/08/11) We expanded the related work section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We achieved a new milestone in the difficult task of enabling agents to learn\nabout their environment autonomously. Our neuro-symbolic architecture is\ntrained end-to-end to produce a succinct and effective discrete state\ntransition model from images alone. Our target representation (the Planning\nDomain Definition Language) is already in a form that off-the-shelf solvers can\nconsume, and opens the door to the rich array of modern heuristic search\ncapabilities. We demonstrate how the sophisticated innate prior we place on the\nlearning process significantly reduces the complexity of the learned\nrepresentation, and reveals a connection to the graph-theoretic notion of\n\"cube-like graphs\", thus opening the door to a deeper understanding of the\nideal properties for learned symbolic representations. We show that the\npowerful domain-independent heuristics allow our system to solve visual\n15-Puzzle instances which are beyond the reach of blind search, without\nresorting to the Reinforcement Learning approach that requires a huge amount of\ntraining on the domain-dependent reward information.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:01:54 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:08:38 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 20:05:30 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Asai", "Masataro", ""], ["Muise", "Christian", ""]]}, {"id": "2004.12873", "submitter": "Saurabh Arora", "authors": "Saurabh Arora, Bikramjit Banerjee, Prashant Doshi", "title": "Maximum Entropy Multi-Task Inverse RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task IRL allows for the possibility that the expert could be switching\nbetween multiple ways of solving the same problem, or interleaving\ndemonstrations of multiple tasks. The learner aims to learn the multiple reward\nfunctions that guide these ways of solving the problem. We present a new method\nfor multi-task IRL that generalizes the well-known maximum entropy approach to\nIRL by combining it with the Dirichlet process based clustering of the observed\ninput. This yields a single nonlinear optimization problem, called MaxEnt\nMulti-task IRL, which can be solved using the Lagrangian relaxation and\ngradient descent methods. We evaluate MaxEnt Multi-task IRL in simulation on\nthe robotic task of sorting onions on a processing line where the expert\nutilizes multiple ways of detecting and removing blemished onions. The method\nis able to learn the underlying reward functions to a high level of accuracy\nand it improves on the previous approaches to multi-task IRL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:30:58 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Arora", "Saurabh", ""], ["Banerjee", "Bikramjit", ""], ["Doshi", "Prashant", ""]]}, {"id": "2004.12908", "submitter": "Jayanta Dey", "authors": "Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak\n  D. Mehta, Ali Geisa, Gido M. van de Ven, Emily Chang, Chenyu Gao, Weiwei\n  Yang, Bryan Tower, Jonathan Larson, Christopher M. White, and Carey E. Priebe", "title": "Omnidirectional Transfer for Quasilinear Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biological learning, data are used to improve performance not only on the\ncurrent task, but also on previously encountered and as yet unencountered\ntasks. In contrast, classical machine learning starts from a blank slate, or\ntabula rasa, using data only for the single task at hand. While typical\ntransfer learning algorithms can improve performance on future tasks, their\nperformance on prior tasks degrades upon learning new tasks (called\ncatastrophic forgetting). Many recent approaches for continual or lifelong\nlearning have attempted to maintain performance given new tasks. But striving\nto avoid forgetting sets the goal unnecessarily low: the goal of lifelong\nlearning, whether biological or artificial, should be to improve performance on\nall tasks (including past and future) with any new data. We propose\nomnidirectional transfer learning algorithms, which includes two special cases\nof interest: decision forests and deep networks. Our key insight is the\ndevelopment of the omni-voter layer, which ensembles representations learned\nindependently on all tasks to jointly decide how to proceed on any given new\ndata point, thereby improving performance on both past and future tasks. Our\nalgorithms demonstrate omnidirectional transfer in a variety of simulated and\nreal data scenarios, including tabular data, image data, spoken data, and\nadversarial tasks. Moreover, they do so with quasilinear space and time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:16:30 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:42:48 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 19:10:05 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 19:22:48 GMT"}, {"version": "v5", "created": "Thu, 20 Aug 2020 14:34:24 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 15:46:10 GMT"}, {"version": "v7", "created": "Mon, 14 Jun 2021 15:35:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vogelstein", "Joshua T.", ""], ["Dey", "Jayanta", ""], ["Helm", "Hayden S.", ""], ["LeVine", "Will", ""], ["Mehta", "Ronak D.", ""], ["Geisa", "Ali", ""], ["van de Ven", "Gido M.", ""], ["Chang", "Emily", ""], ["Gao", "Chenyu", ""], ["Yang", "Weiwei", ""], ["Tower", "Bryan", ""], ["Larson", "Jonathan", ""], ["White", "Christopher M.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2004.12916", "submitter": "Sariah Mghames Dr", "authors": "Sariah Mghames, Marc Hanheide and Amir Ghalamzan E", "title": "Interactive Movement Primitives: Planning to Push Occluding Pieces for\n  Fruit Picking", "comments": "This work is accepted for publication in IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Robotic technology is increasingly considered the major mean for fruit\npicking. However, picking fruits in a dense cluster imposes a challenging\nresearch question in terms of motion/path planning as conventional planning\napproaches may not find collision-free movements for the robot to\nreach-and-pick a ripe fruit within a dense cluster. In such cases, the robot\nneeds to safely push unripe fruits to reach a ripe one. Nonetheless, existing\napproaches to planning pushing movements in cluttered environments either are\ncomputationally expensive or only deal with 2-D cases and are not suitable for\nfruit picking, where it needs to compute 3-D pushing movements in a short time.\nIn this work, we present a path planning algorithm for pushing occluding fruits\nto reach-and-pick a ripe one. Our proposed approach, called Interactive\nProbabilistic Movement Primitives (I-ProMP), is not computationally expensive\n(its computation time is in the order of 100 milliseconds) and is readily used\nfor 3-D problems. We demonstrate the efficiency of our approach with pushing\nunripe strawberries in a simulated polytunnel. Our experimental results confirm\nI-ProMP successfully pushes table top grown strawberries and reaches a ripe\none.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:30:18 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 11:31:53 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Mghames", "Sariah", ""], ["Hanheide", "Marc", ""], ["E", "Amir Ghalamzan", ""]]}, {"id": "2004.12919", "submitter": "Jeff Clune", "authors": "Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O. Stanley and\n  Jeff Clune", "title": "First return, then explore", "comments": "45 pages, 13 figures, 4 tables; reorganized sections and modified SI\n  text extensively; added reference to the published version, changed title to\n  published title", "journal-ref": "Nature 590, 580-586 (2021)", "doi": "10.1038/s41586-020-03157-9", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of reinforcement learning is to solve complex sequential decision\nproblems by specifying a high-level reward function only. However, RL\nalgorithms struggle when, as is often the case, simple and intuitive rewards\nprovide sparse and deceptive feedback. Avoiding these pitfalls requires\nthoroughly exploring the environment, but despite substantial investments by\nthe community, creating algorithms that can do so remains one of the central\nchallenges of the field. We hypothesize that the main impediment to effective\nexploration originates from algorithms forgetting how to reach previously\nvisited states (\"detachment\") and from failing to first return to a state\nbefore exploring from it (\"derailment\"). We introduce Go-Explore, a family of\nalgorithms that addresses these two challenges directly through the simple\nprinciples of explicitly remembering promising states and first returning to\nsuch states before exploring. Go-Explore solves all heretofore unsolved Atari\ngames (those for which algorithms could not previously outperform humans when\nevaluated following current community standards) and surpasses the state of the\nart on all hard-exploration games, with orders of magnitude improvements on the\ngrand challenges Montezuma's Revenge and Pitfall. We also demonstrate the\npractical potential of Go-Explore on a challenging and extremely sparse-reward\nrobotics task. Additionally, we show that adding a goal-conditioned policy can\nfurther improve Go-Explore's exploration efficiency and enable it to handle\nstochasticity throughout training. The striking contrast between the\nsubstantial performance gains from Go-Explore and the simplicity of its\nmechanisms suggests that remembering promising states, returning to them, and\nexploring from them is a powerful and general approach to exploration, an\ninsight that may prove critical to the creation of truly intelligent learning\nagents.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:31:26 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 18:40:39 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 21:09:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ecoffet", "Adrien", ""], ["Huizinga", "Joost", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "2004.12926", "submitter": "Greg Hager", "authors": "Polina Golland, Jack Gallant, Greg Hager, Hanspeter Pfister, Christos\n  Papadimitriou, Stefan Schaal, and Joshua T. Vogelstein", "title": "A New Age of Computing and the Brain", "comments": "A Computing Community Consortium (CCC) workshop report, 24 pages", "journal-ref": null, "doi": null, "report-no": "ccc2014report_5", "categories": "cs.CY cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The history of computer science and brain sciences are intertwined. In his\nunfinished manuscript \"The Computer and the Brain,\" von Neumann debates whether\nor not the brain can be thought of as a computing machine and identifies some\nof the similarities and differences between natural and artificial computation.\nTuring, in his 1950 article in Mind, argues that computing devices could\nultimately emulate intelligence, leading to his proposed Turing test. Herbert\nSimon predicted in 1957 that most psychological theories would take the form of\na computer program. In 1976, David Marr proposed that the function of the\nvisual system could be abstracted and studied at computational and algorithmic\nlevels that did not depend on the underlying physical substrate.\n  In December 2014, a two-day workshop supported by the Computing Community\nConsortium (CCC) and the National Science Foundation's Computer and Information\nScience and Engineering Directorate (NSF CISE) was convened in Washington, DC,\nwith the goal of bringing together computer scientists and brain researchers to\nexplore these new opportunities and connections, and develop a new, modern\ndialogue between the two research communities. Specifically, our objectives\nwere: 1. To articulate a conceptual framework for research at the interface of\nbrain sciences and computing and to identify key problems in this interface,\npresented in a way that will attract both CISE and brain researchers into this\nspace. 2. To inform and excite researchers within the CISE research community\nabout brain research opportunities and to identify and explain strategic roles\nthey can play in advancing this initiative. 3. To develop new connections,\nconversations and collaborations between brain sciences and CISE researchers\nthat will lead to highly relevant and competitive proposals, high-impact\nresearch, and influential publications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:38:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Golland", "Polina", ""], ["Gallant", "Jack", ""], ["Hager", "Greg", ""], ["Pfister", "Hanspeter", ""], ["Papadimitriou", "Christos", ""], ["Schaal", "Stefan", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "2004.12960", "submitter": "Roykrong Sukkerd", "authors": "Roykrong Sukkerd, Reid Simmons, and David Garlan", "title": "Tradeoff-Focused Contrastive Explanation for MDP Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-users' trust in automated agents is important as automated\ndecision-making and planning is increasingly used in many aspects of people's\nlives. In real-world applications of planning, multiple optimization objectives\nare often involved. Thus, planning agents' decisions can involve complex\ntradeoffs among competing objectives. It can be difficult for the end-users to\nunderstand why an agent decides on a particular planning solution on the basis\nof its objective values. As a result, the users may not know whether the agent\nis making the right decisions, and may lack trust in it. In this work, we\ncontribute an approach, based on contrastive explanation, that enables a\nmulti-objective MDP planning agent to explain its decisions in a way that\ncommunicates its tradeoff rationale in terms of the domain-level concepts. We\nconduct a human subjects experiment to evaluate the effectiveness of our\nexplanation approach in a mobile robot navigation domain. The results show that\nour approach significantly improves the users' understanding, and confidence in\ntheir understanding, of the tradeoff rationale of the planning agent.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:17:58 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 16:07:02 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sukkerd", "Roykrong", ""], ["Simmons", "Reid", ""], ["Garlan", "David", ""]]}, {"id": "2004.13102", "submitter": "Gagan Bansal", "authors": "Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, Daniel S. Weld", "title": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork", "comments": "v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI practitioners typically strive to develop the most accurate systems,\nmaking an implicit assumption that the AI system will function autonomously.\nHowever, in practice, AI systems often are used to provide advice to people in\ndomains ranging from criminal justice and finance to healthcare. In such\nAI-advised decision making, humans and machines form a team, where the human is\nresponsible for making final decisions. But is the most accurate AI the best\nteammate? We argue \"No\" -- predictable performance may be worth a slight\nsacrifice in AI accuracy. Instead, we argue that AI systems should be trained\nin a human-centered manner, directly optimized for team performance. We study\nthis proposal for a specific type of human-AI teaming, where the human overseer\nchooses to either accept the AI recommendation or solve the task themselves. To\noptimize the team performance for this setting we maximize the team's expected\nutility, expressed in terms of the quality of the final decision, cost of\nverifying, and individual accuracies of people and machines. Our experiments\nwith linear and non-linear models on real-world, high-stakes datasets show that\nthe most accuracy AI may not lead to highest team performance and show the\nbenefit of modeling teamwork during training through improvements in expected\nteam utility across datasets, considering parameters such as human skill and\nthe cost of mistakes. We discuss the shortcoming of current optimization\napproaches beyond well-studied loss functions such as log-loss, and encourage\nfuture work on AI optimization problems motivated by human-AI collaboration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 19:06:28 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 02:07:57 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 20:22:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bansal", "Gagan", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Horvitz", "Eric", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2004.13161", "submitter": "G\\\"ozde G\\\"ul \\c{S}ahin", "authors": "G\\\"ozde G\\\"ul \\c{S}ahin, Yova Kementchedjhieva, Phillip Rust, Iryna\n  Gurevych", "title": "PuzzLing Machines: A Challenge on Learning From Small Data", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural models have repeatedly proved excellent at memorizing surface\npatterns from large datasets for various ML and NLP benchmarks. They struggle\nto achieve human-like thinking, however, because they lack the skill of\niterative reasoning upon knowledge. To expose this problem in a new light, we\nintroduce a challenge on learning from small data, PuzzLing Machines, which\nconsists of Rosetta Stone puzzles from Linguistic Olympiads for high school\nstudents. These puzzles are carefully designed to contain only the minimal\namount of parallel text necessary to deduce the form of unseen expressions.\nSolving them does not require external information (e.g., knowledge bases,\nvisual signals) or linguistic expertise, but meta-linguistic awareness and\ndeductive skills. Our challenge contains around 100 puzzles covering a wide\nrange of linguistic phenomena from 81 languages. We show that both simple\nstatistical algorithms and state-of-the-art deep neural models perform\ninadequately on this challenge, as expected. We hope that this benchmark,\navailable at https://ukplab.github.io/PuzzLing-Machines/, inspires further\nefforts towards a new paradigm in NLP---one that is grounded in human-like\nreasoning and understanding.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:34:26 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["Kementchedjhieva", "Yova", ""], ["Rust", "Phillip", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2004.13230", "submitter": "Marjan Albooyeh", "authors": "Marjan Albooyeh, Rishab Goel, Seyed Mehran Kazemi", "title": "Out-of-Sample Representation Learning for Multi-Relational Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important problems can be formulated as reasoning in knowledge graphs.\nRepresentation learning has proved extremely effective for transductive\nreasoning, in which one needs to make new predictions for already observed\nentities. This is true for both attributed graphs(where each entity has an\ninitial feature vector) and non-attributed graphs (where the only initial\ninformation derives from known relations with other entities). For\nout-of-sample reasoning, where one needs to make predictions for entities that\nwere unseen at training time, much prior work considers attributed graph.\nHowever, this problem is surprisingly under-explored for non-attributed graphs.\nIn this paper, we study the out-of-sample representation learning problem for\nnon-attributed knowledge graphs, create benchmark datasets for this task,\ndevelop several models and baselines, and provide empirical analyses and\ncomparisons of the proposed models and baselines.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 00:53:01 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:22:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Albooyeh", "Marjan", ""], ["Goel", "Rishab", ""], ["Kazemi", "Seyed Mehran", ""]]}, {"id": "2004.13242", "submitter": "Cameron Allen", "authors": "Cameron Allen, Michael Katz, Tim Klinger, George Konidaris, Matthew\n  Riemer, Gerald Tesauro", "title": "Efficient Black-Box Planning Using Macro-Actions with Focused Effects", "comments": "To appear at IJCAI 2021; code available at\n  https://github.com/camall3n/focused-macros", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of deterministic planning increases exponentially with\nsearch-tree depth. Black-box planning presents an even greater challenge, since\nplanners must operate without an explicit model of the domain. Heuristics can\nmake search more efficient, but goal-aware heuristics for black-box planning\nusually rely on goal counting, which is often quite uninformative. In this\nwork, we show how to overcome this limitation by discovering macro-actions that\nmake the goal-count heuristic more accurate. Our approach searches for\nmacro-actions with focused effects (i.e. macros that modify only a small number\nof state variables), which align well with the assumptions made by the\ngoal-count heuristic. Focused macros dramatically improve black-box planning\nefficiency across a wide range of planning domains, sometimes beating even\nstate-of-the-art planners with access to a full domain model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:13:12 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:17:18 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 19:38:24 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Allen", "Cameron", ""], ["Katz", "Michael", ""], ["Klinger", "Tim", ""], ["Konidaris", "George", ""], ["Riemer", "Matthew", ""], ["Tesauro", "Gerald", ""]]}, {"id": "2004.13248", "submitter": "Tuhin Chakrabarty Mr", "authors": "Tuhin Chakrabarty, and Debanjan Ghosh, and Smaranda Muresan, and\n  Nanyun Peng", "title": "$R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with\n  Commonsense Knowledge", "comments": "Accepted at the 2020 Annual Conference of the Association for\n  Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised approach for sarcasm generation based on a\nnon-sarcastic input sentence. Our method employs a retrieve-and-edit framework\nto instantiate two major characteristics of sarcasm: reversal of valence and\nsemantic incongruity with the context which could include shared commonsense or\nworld knowledge between the speaker and the listener. While prior works on\nsarcasm generation predominantly focus on context incongruity, we show that\ncombining valence reversal and semantic incongruity based on the commonsense\nknowledge generates sarcasm of higher quality. Human evaluation shows that our\nsystem generates sarcasm better than human annotators 34% of the time, and\nbetter than a reinforced hybrid baseline 90% of the time.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:30:09 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 20:34:04 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 11:14:11 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 06:42:06 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Ghosh", "Debanjan", ""], ["Muresan", "Smaranda", ""], ["Peng", "Nanyun", ""]]}, {"id": "2004.13291", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Xianbo Gao, Youjin Chung, Julian Togelius, Andy Nealen\n  and Stefan Menzel", "title": "Evaluating the Rainbow DQN Agent in Hanabi with Unseen Partners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hanabi is a cooperative game that challenges exist-ing AI techniques due to\nits focus on modeling the mental states ofother players to interpret and\npredict their behavior. While thereare agents that can achieve near-perfect\nscores in the game byagreeing on some shared strategy, comparatively little\nprogresshas been made in ad-hoc cooperation settings, where partnersand\nstrategies are not known in advance. In this paper, we showthat agents trained\nthrough self-play using the popular RainbowDQN architecture fail to cooperate\nwell with simple rule-basedagents that were not seen during training and,\nconversely, whenthese agents are trained to play with any individual\nrule-basedagent, or even a mix of these agents, they fail to achieve\ngoodself-play scores.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:24:44 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Gao", "Xianbo", ""], ["Chung", "Youjin", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""], ["Menzel", "Stefan", ""]]}, {"id": "2004.13384", "submitter": "Bogdan Boc\\c{s}e", "authors": "Bogdan Bocse and Ioan Radu Jinga", "title": "The Immersion of Directed Multi-graphs in Embedding Fields.\n  Generalisations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The purpose of this paper is to outline a generalised model for representing\nhybrids of relational-categorical, symbolic, perceptual-sensory and\nperceptual-latent data, so as to embody, in the same architectural data layer,\nrepresentations for the input, output and latent tensors. This variety of\nrepresentation is currently used by various machine-learning models in computer\nvision, NLP/NLU, reinforcement learning which allows for direct application of\ncross-domain queries and functions. This is achieved by endowing a directed\nTensor-Typed Multi-Graph with at least some edge attributes which represent the\nembeddings from various latent spaces, so as to define, construct and compute\nnew similarity and distance relationships between and across tensorial forms,\nincluding visual, linguistic, auditory latent representations, thus stitching\nthe logical-categorical view of the observed universe to the\nBayesian/statistical view.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 09:28:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bocse", "Bogdan", ""], ["Jinga", "Ioan Radu", ""]]}, {"id": "2004.13439", "submitter": "Thilo Stadelmann", "authors": "Dano Roost, Ralph Meier, Stephan Huschauer, Erik Nygren, Adrian Egli,\n  Andreas Weiler, Thilo Stadelmann", "title": "Improving Sample Efficiency and Multi-Agent Communication in RL-based\n  Train Rescheduling", "comments": "Accepted for publication at the 7th Swiss Conference on Data Science\n  (SDS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present preliminary results from our sixth placed entry to the Flatland\ninternational competition for train rescheduling, including two improvements\nfor optimized reinforcement learning (RL) training efficiency, and two\nhypotheses with respect to the prospect of deep RL for complex real-world\ncontrol tasks: first, that current state of the art policy gradient methods\nseem inappropriate in the domain of high-consequence environments; second, that\nlearning explicit communication actions (an emerging machine-to-machine\nlanguage, so to speak) might offer a remedy. These hypotheses need to be\nconfirmed by future work. If confirmed, they hold promises with respect to\noptimizing highly efficient logistics ecosystems like the Swiss Federal\nRailways railway network.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:46:58 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Roost", "Dano", ""], ["Meier", "Ralph", ""], ["Huschauer", "Stephan", ""], ["Nygren", "Erik", ""], ["Egli", "Adrian", ""], ["Weiler", "Andreas", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "2004.13455", "submitter": "Lianwei Wu", "authors": "Lianwei Wu, Yuan Rao, Yongqiang Zhao, Hao Liang, Ambreen Nazir", "title": "DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim\n  Verification", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many methods discover effective evidence from reliable sources by\nappropriate neural networks for explainable claim verification, which has been\nwidely recognized. However, in these methods, the discovery process of evidence\nis nontransparent and unexplained. Simultaneously, the discovered evidence only\nroughly aims at the interpretability of the whole sequence of claims but\ninsufficient to focus on the false parts of claims. In this paper, we propose a\nDecision Tree-based Co-Attention model (DTCA) to discover evidence for\nexplainable claim verification. Specifically, we first construct Decision\nTree-based Evidence model (DTE) to select comments with high credibility as\nevidence in a transparent and interpretable way. Then we design Co-attention\nSelf-attention networks (CaSa) to make the selected evidence interact with\nclaims, which is for 1) training DTE to determine the optimal decision\nthresholds and obtain more powerful evidence; and 2) utilizing the evidence to\nfind the false parts in the claim. Experiments on two public datasets,\nRumourEval and PHEME, demonstrate that DTCA not only provides explanations for\nthe results of claim verification but also achieves the state-of-the-art\nperformance, boosting the F1-score by 3.11%, 2.41%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 12:19:46 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Wu", "Lianwei", ""], ["Rao", "Yuan", ""], ["Zhao", "Yongqiang", ""], ["Liang", "Hao", ""], ["Nazir", "Ambreen", ""]]}, {"id": "2004.13477", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "Pushing the Envelope: From Discrete to Continuous Movements in\n  Multi-Agent Path Finding via Lazy Encodings", "comments": "arXiv admin note: text overlap with arXiv:1903.09820", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent path finding in continuous space and time with geometric agents\nMAPF$^\\mathcal{R}$ is addressed in this paper. The task is to navigate agents\nthat move smoothly between predefined positions to their individual goals so\nthat they do not collide. We introduce a novel solving approach for obtaining\nmakespan optimal solutions called SMT-CBS$^\\mathcal{R}$ based on {\\em\nsatisfiability modulo theories} (SMT). The new algorithm combines collision\nresolution known from conflict-based search (CBS) with previous generation of\nincomplete SAT encodings on top of a novel scheme for selecting decision\nvariables in a potentially uncountable search space. We experimentally compare\nSMT-CBS$^\\mathcal{R}$ and previous CCBS algorithm for MAPF$^\\mathcal{R}$.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 13:21:32 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "2004.13482", "submitter": "Roger Granada", "authors": "Roger Granada and Ramon Fraga Pereira and Juarez Monteiro and Leonardo\n  Amado and Rodrigo C. Barros and Duncan Ruiz and Felipe Meneguzzi", "title": "HAPRec: Hybrid Activity and Plan Recognizer", "comments": "Demo paper of the AAAI 2020 Workshop on Plan, Activity, and Intent\n  Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-based assistants have recently attracted much interest due to its\napplicability to ambient assisted living. Such assistants have to detect and\nrecognize the high-level activities and goals performed by the assisted human\nbeings. In this work, we demonstrate activity recognition in an indoor\nenvironment in order to identify the goal towards which the subject of the\nvideo is pursuing. Our hybrid approach combines an action recognition module\nand a goal recognition algorithm to identify the ultimate goal of the subject\nin the video.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:20:14 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Granada", "Roger", ""], ["Pereira", "Ramon Fraga", ""], ["Monteiro", "Juarez", ""], ["Amado", "Leonardo", ""], ["Barros", "Rodrigo C.", ""], ["Ruiz", "Duncan", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "2004.13515", "submitter": "Philippe Burlina", "authors": "Philippe Burlina, Neil Joshi, William Paul, Katia D. Pacheco, Neil M.\n  Bressler", "title": "Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics", "comments": "Accepted for publication at journal of Translational Vision Science\n  and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study evaluated generative methods to potentially mitigate AI bias when\ndiagnosing diabetic retinopathy (DR) resulting from training data imbalance, or\ndomain generalization which occurs when deep learning systems (DLS) face\nconcepts at test/inference time they were not initially trained on. The public\ndomain Kaggle-EyePACS dataset (88,692 fundi and 44,346 individuals, originally\ndiverse for ethnicity) was modified by adding clinician-annotated labels and\nconstructing an artificial scenario of data imbalance and domain generalization\nby disallowing training (but not testing) exemplars for images of retinas with\nDR warranting referral (DR-referable) and from darker-skin individuals, who\npresumably have greater concentration of melanin within uveal melanocytes, on\naverage, contributing to retinal image pigmentation. A traditional/baseline\ndiagnostic DLS was compared against new DLSs that would use training data\naugmented via generative models for debiasing. Accuracy (95% confidence\nintervals [CI]) of the baseline diagnostics DLS for fundus images of\nlighter-skin individuals was 73.0% (66.9%, 79.2%) vs. darker-skin of 60.5%\n(53.5%, 67.3%), demonstrating bias/disparity (delta=12.5%) (Welch t-test\nt=2.670, P=.008) in AI performance across protected subpopulations. Using novel\ngenerative methods for addressing missing subpopulation training data\n(DR-referable darker-skin) achieved instead accuracy, for lighter-skin, of\n72.0% (65.8%, 78.2%), and for darker-skin, of 71.5% (65.2%,77.8%),\ndemonstrating closer parity (delta=0.5%) in accuracy across subpopulations\n(Welch t-test t=0.111, P=.912). Findings illustrate how data imbalance and\ndomain generalization can lead to disparity of accuracy across subpopulations,\nand show that novel generative methods of synthetic fundus images may play a\nrole for debiasing AI.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:46:54 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 21:08:04 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 13:29:33 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 15:11:18 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Burlina", "Philippe", ""], ["Joshi", "Neil", ""], ["Paul", "William", ""], ["Pacheco", "Katia D.", ""], ["Bressler", "Neil M.", ""]]}, {"id": "2004.13527", "submitter": "Daniel Leite", "authors": "Leticia Decker, Daniel Leite, Luca Giommi, Daniele Bonacorsi", "title": "Real-Time Anomaly Detection in Data Centers for Log-based Predictive\n  Maintenance using an Evolving Fuzzy-Rule-Based Approach", "comments": "9 pages, 6 figures, 1 table, IEEE World Congress on Computational\n  Intelligence (WCCI 2020). arXiv admin note: substantial text overlap with\n  arXiv:2004.09986", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of anomalous behaviors in data centers is crucial to predictive\nmaintenance and data safety. With data centers, we mean any computer network\nthat allows users to transmit and exchange data and information. In particular,\nwe focus on the Tier-1 data center of the Italian Institute for Nuclear Physics\n(INFN), which supports the high-energy physics experiments at the Large Hadron\nCollider (LHC) in Geneva. The center provides resources and services needed for\ndata processing, storage, analysis, and distribution. Log records in the data\ncenter is a stochastic and non-stationary phenomenon in nature. We propose a\nreal-time approach to monitor and classify log records based on sliding time\nwindows, and a time-varying evolving fuzzy-rule-based classification model. The\nmost frequent log pattern according to a control chart is taken as the normal\nsystem status. We extract attributes from time windows to gradually develop and\nupdate an evolving Gaussian Fuzzy Classifier (eGFC) on the fly. The real-time\nanomaly monitoring system has to provide encouraging results in terms of\naccuracy, compactness, and real-time operation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 21:19:44 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Decker", "Leticia", ""], ["Leite", "Daniel", ""], ["Giommi", "Luca", ""], ["Bonacorsi", "Daniele", ""]]}, {"id": "2004.13529", "submitter": "Juarez Monteiro", "authors": "Juarez Monteiro, Nathan Gavenski, Roger Granada, Felipe Meneguzzi and\n  Rodrigo Barros", "title": "Augmented Behavioral Cloning from Observation", "comments": "This paper has been accepted in the International Joint Conference on\n  Neural Networks 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation from observation is a computational technique that teaches an agent\non how to mimic the behavior of an expert by observing only the sequence of\nstates from the expert demonstrations. Recent approaches learn the inverse\ndynamics of the environment and an imitation policy by interleaving epochs of\nboth models while changing the demonstration data. However, such approaches\noften get stuck into sub-optimal solutions that are distant from the expert,\nlimiting their imitation effectiveness. We address this problem with a novel\napproach that overcomes the problem of reaching bad local minima by exploring:\n(I) a self-attention mechanism that better captures global features of the\nstates; and (ii) a sampling strategy that regulates the observations that are\nused for learning. We show empirically that our approach outperforms the\nstate-of-the-art approaches in four different environments by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:56:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Monteiro", "Juarez", ""], ["Gavenski", "Nathan", ""], ["Granada", "Roger", ""], ["Meneguzzi", "Felipe", ""], ["Barros", "Rodrigo", ""]]}, {"id": "2004.13553", "submitter": "Dekai Wu", "authors": "De Kai, Guy-Philippe Goldstein, Alexey Morgunov, Vishal Nangalia, Anna\n  Rotkirch", "title": "Universal Masking is Urgent in the COVID-19 Pandemic: SEIR and Agent\n  Based Models, Empirical Validation, Policy Recommendations", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two models for the COVID-19 pandemic predicting the impact of\nuniversal face mask wearing upon the spread of the SARS-CoV-2 virus--one\nemploying a stochastic dynamic network based compartmental SEIR\n(susceptible-exposed-infectious-recovered) approach, and the other employing\nindividual ABM (agent-based modelling) Monte Carlo simulation--indicating (1)\nsignificant impact under (near) universal masking when at least 80% of a\npopulation is wearing masks, versus minimal impact when only 50% or less of the\npopulation is wearing masks, and (2) significant impact when universal masking\nis adopted early, by Day 50 of a regional outbreak, versus minimal impact when\nuniversal masking is adopted late. These effects hold even at the lower\nfiltering rates of homemade masks. To validate these theoretical models, we\ncompare their predictions against a new empirical data set we have collected\nthat includes whether regions have universal masking cultures or policies,\ntheir daily case growth rates, and their percentage reduction from peak daily\ncase growth rates. Results show a near perfect correlation between early\nuniversal masking and successful suppression of daily case growth rates and/or\nreduction from peak daily case growth rates, as predicted by our theoretical\nsimulations.\n  Our theoretical and empirical results argue for urgent implementation of\nuniversal masking. As governments plan how to exit societal lockdowns, it is\nemerging as a key NPI; a \"mouth-and-nose lockdown\" is far more sustainable than\na \"full body lockdown\", on economic, social, and mental health axes. An\ninteractive visualization of the ABM simulation is at http://dek.ai/masks4all.\nWe recommend immediate mask wearing recommendations, official guidelines for\ncorrect use, and awareness campaigns to shift masking mindsets away from pure\nself-protection, towards aspirational goals of responsibly protecting one's\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:42:11 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Kai", "De", ""], ["Goldstein", "Guy-Philippe", ""], ["Morgunov", "Alexey", ""], ["Nangalia", "Vishal", ""], ["Rotkirch", "Anna", ""]]}, {"id": "2004.13577", "submitter": "Zhongyi Han", "authors": "Zhongyi Han, Benzheng Wei, Yilong Yin, Shuo Li", "title": "Unifying Neural Learning and Symbolic Reasoning for Spinal Medical\n  Report Generation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated medical report generation in spine radiology, i.e., given spinal\nmedical images and directly create radiologist-level diagnosis reports to\nsupport clinical decision making, is a novel yet fundamental study in the\ndomain of artificial intelligence in healthcare. However, it is incredibly\nchallenging because it is an extremely complicated task that involves visual\nperception and high-level reasoning processes. In this paper, we propose the\nneural-symbolic learning (NSL) framework that performs human-like learning by\nunifying deep neural learning and symbolic logical reasoning for the spinal\nmedical report generation. Generally speaking, the NSL framework firstly\nemploys deep neural learning to imitate human visual perception for detecting\nabnormalities of target spinal structures. Concretely, we design an adversarial\ngraph network that interpolates a symbolic graph reasoning module into a\ngenerative adversarial network through embedding prior domain knowledge,\nachieving semantic segmentation of spinal structures with high complexity and\nvariability. NSL secondly conducts human-like symbolic logical reasoning that\nrealizes unsupervised causal effect analysis of detected entities of\nabnormalities through meta-interpretive learning. NSL finally fills these\ndiscoveries of target diseases into a unified template, successfully achieving\na comprehensive medical report generation. When it employed in a real-world\nclinical dataset, a series of empirical studies demonstrate its capacity on\nspinal medical report generation as well as show that our algorithm remarkably\nexceeds existing methods in the detection of spinal structures. These indicate\nits potential as a clinical tool that contributes to computer-aided diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:06:24 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Han", "Zhongyi", ""], ["Wei", "Benzheng", ""], ["Yin", "Yilong", ""], ["Li", "Shuo", ""]]}, {"id": "2004.13579", "submitter": "Zequn Sun", "authors": "Zequn Sun, Jiacheng Huang, Wei Hu, Muchao Chen, Lingbing Guo, Yuzhong\n  Qu", "title": "TransEdge: Translating Relation-contextualized Embeddings for Knowledge\n  Graphs", "comments": "Published in proceedings of the 18th International Semantic Web\n  Conference (ISWC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph (KG) embeddings has received increasing attention in\nrecent years. Most embedding models in literature interpret relations as linear\nor bilinear mapping functions to operate on entity embeddings. However, we find\nthat such relation-level modeling cannot capture the diverse relational\nstructures of KGs well. In this paper, we propose a novel edge-centric\nembedding model TransEdge, which contextualizes relation representations in\nterms of specific head-tail entity pairs. We refer to such contextualized\nrepresentations of a relation as edge embeddings and interpret them as\ntranslations between entity embeddings. TransEdge achieves promising\nperformance on different prediction tasks. Our experiments on benchmark\ndatasets indicate that it obtains the state-of-the-art results on\nembedding-based entity alignment. We also show that TransEdge is complementary\nwith conventional entity alignment methods. Moreover, it shows very competitive\nperformance on link prediction.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:00:45 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Sun", "Zequn", ""], ["Huang", "Jiacheng", ""], ["Hu", "Wei", ""], ["Chen", "Muchao", ""], ["Guo", "Lingbing", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2004.13631", "submitter": "Jie Zhou", "authors": "Jie Zhou, Shengding Hu, Xin Lv, Cheng Yang, Zhiyuan Liu, Wei Xu, Jie\n  Jiang, Juanzi Li, Maosong Sun", "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization\n  and Completion", "comments": "Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:21:57 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 03:23:10 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhou", "Jie", ""], ["Hu", "Shengding", ""], ["Lv", "Xin", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Xu", "Wei", ""], ["Jiang", "Jie", ""], ["Li", "Juanzi", ""], ["Sun", "Maosong", ""]]}, {"id": "2004.13637", "submitter": "Jason  Weston", "authors": "Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson,\n  Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau,\n  and Jason Weston", "title": "Recipes for building an open-domain chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building open-domain chatbots is a challenging area for machine learning\nresearch. While prior work has shown that scaling neural models in the number\nof parameters and the size of the data they are trained on gives improved\nresults, we show that other ingredients are important for a high-performing\nchatbot. Good conversation requires a number of skills that an expert\nconversationalist blends in a seamless way: providing engaging talking points\nand listening to their partners, and displaying knowledge, empathy and\npersonality appropriately, while maintaining a consistent persona. We show that\nlarge scale models can learn these skills when given appropriate training data\nand choice of generation strategy. We build variants of these recipes with 90M,\n2.7B and 9.4B parameter models, and make our models and code publicly\navailable. Human evaluations show our best models are superior to existing\napproaches in multi-turn dialogue in terms of engagingness and humanness\nmeasurements. We then discuss the limitations of this work by analyzing failure\ncases of our models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:33:25 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 15:36:52 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Roller", "Stephen", ""], ["Dinan", "Emily", ""], ["Goyal", "Naman", ""], ["Ju", "Da", ""], ["Williamson", "Mary", ""], ["Liu", "Yinhan", ""], ["Xu", "Jing", ""], ["Ott", "Myle", ""], ["Shuster", "Kurt", ""], ["Smith", "Eric M.", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""]]}, {"id": "2004.13654", "submitter": "Stuart Armstrong", "authors": "Stuart Armstrong and Jan Leike and Laurent Orseau and Shane Legg", "title": "Pitfalls of learning a reward function online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some agent designs like inverse reinforcement learning an agent needs to\nlearn its own reward function. Learning the reward function and optimising for\nit are typically two different processes, usually performed at different\nstages. We consider a continual (``one life'') learning approach where the\nagent both learns the reward function and optimises for it at the same time. We\nshow that this comes with a number of pitfalls, such as deliberately\nmanipulating the learning process in one direction, refusing to learn,\n``learning'' facts already known to the agent, and making decisions that are\nstrictly dominated (for all relevant reward functions). We formally introduce\ntwo desirable properties: the first is `unriggability', which prevents the\nagent from steering the learning process in the direction of a reward function\nthat is easier to optimise. The second is `uninfluenceability', whereby the\nreward-function learning process operates by learning facts about the\nenvironment. We show that an uninfluenceable process is automatically\nunriggable, and if the set of possible environments is sufficiently rich, the\nconverse is true too.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:58:58 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Armstrong", "Stuart", ""], ["Leike", "Jan", ""], ["Orseau", "Laurent", ""], ["Legg", "Shane", ""]]}, {"id": "2004.13657", "submitter": "Katya Kudashkina", "authors": "Katya Kudashkina, Valliappa Chockalingam, Graham W. Taylor, Michael\n  Bowling", "title": "Sample-Efficient Model-based Actor-Critic for an Interactive Dialogue\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-computer interactive systems that rely on machine learning are becoming\nparamount to the lives of millions of people who use digital assistants on a\ndaily basis. Yet, further advances are limited by the availability of data and\nthe cost of acquiring new samples. One way to address this problem is by\nimproving the sample efficiency of current approaches. As a solution path, we\npresent a model-based reinforcement learning algorithm for an interactive\ndialogue task. We build on commonly used actor-critic methods, adding an\nenvironment model and planner that augments a learning agent to learn the model\nof the environment dynamics. Our results show that, on a simulation that mimics\nthe interactive task, our algorithm requires 70 times fewer samples, compared\nto the baseline of commonly used model-free algorithm, and demonstrates 2~times\nbetter performance asymptotically. Moreover, we introduce a novel contribution\nof computing a soft planner policy and further updating a model-free policy\nyielding a less computationally expensive model-free agent as good as the\nmodel-based one. This model-based architecture serves as a foundation that can\nbe extended to other human-computer interactive tasks allowing further advances\nin this direction.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:00:59 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Kudashkina", "Katya", ""], ["Chockalingam", "Valliappa", ""], ["Taylor", "Graham W.", ""], ["Bowling", "Michael", ""]]}, {"id": "2004.13702", "submitter": "Russa Biswas", "authors": "Russa Biswas, Radina Sofronova, Mehwish Alam, Harald Sack", "title": "Entity Type Prediction in Knowledge Graphs using Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Open Knowledge Graphs (such as DBpedia, Wikidata, YAGO) have been recognized\nas the backbone of diverse applications in the field of data mining and\ninformation retrieval. Hence, the completeness and correctness of the Knowledge\nGraphs (KGs) are vital. Most of these KGs are mostly created either via an\nautomated information extraction from Wikipedia snapshots or information\naccumulation provided by the users or using heuristics. However, it has been\nobserved that the type information of these KGs is often noisy, incomplete, and\nincorrect. To deal with this problem a multi-label classification approach is\nproposed in this work for entity typing using KG embeddings. We compare our\napproach with the current state-of-the-art type prediction method and report on\nexperiments with the KGs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:57:08 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:16:54 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Biswas", "Russa", ""], ["Sofronova", "Radina", ""], ["Alam", "Mehwish", ""], ["Sack", "Harald", ""]]}, {"id": "2004.13710", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Xianbo Gao, Julian Togelius, Andy Nealen and Stefan\n  Menzel", "title": "Generating and Adapting to Diverse Ad-Hoc Cooperation Agents in Hanabi", "comments": "arXiv admin note: text overlap with arXiv:1907.03840", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hanabi is a cooperative game that brings the problem of modeling other\nplayers to the forefront. In this game, coordinated groups of players can\nleverage pre-established conventions to great effect, but playing in an ad-hoc\nsetting requires agents to adapt to its partner's strategies with no previous\ncoordination. Evaluating an agent in this setting requires a diverse population\nof potential partners, but so far, the behavioral diversity of agents has not\nbeen considered in a systematic way. This paper proposes Quality Diversity\nalgorithms as a promising class of algorithms to generate diverse populations\nfor this purpose, and generates a population of diverse Hanabi agents using\nMAP-Elites. We also postulate that agents can benefit from a diverse population\nduring training and implement a simple \"meta-strategy\" for adapting to an\nagent's perceived behavioral niche. We show this meta-strategy can work better\nthan generalist strategies even outside the population it was trained with if\nits partner's behavioral niche can be correctly inferred, but in practice a\npartner's behavior depends and interferes with the meta-agent's own behavior,\nsuggesting an avenue for future research in characterizing another agent's\nbehavior during gameplay.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 05:03:19 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 01:49:53 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Gao", "Xianbo", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""], ["Menzel", "Stefan", ""]]}, {"id": "2004.13786", "submitter": "Shanchan Wu", "authors": "Shanchan Wu and Kai Fan", "title": "A Practical Framework for Relation Extraction with Noisy Labels Based on\n  Doubly Transitional Loss", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Either human annotation or rule based automatic labeling is an effective\nmethod to augment data for relation extraction. However, the inevitable wrong\nlabeling problem for example by distant supervision may deteriorate the\nperformance of many existing methods. To address this issue, we introduce a\npractical end-to-end deep learning framework, including a standard feature\nextractor and a novel noisy classifier with our proposed doubly transitional\nmechanism. One transition is basically parameterized by a non-linear\ntransformation between hidden layers that implicitly represents the conversion\nbetween the true and noisy labels, and it can be readily optimized together\nwith other model parameters. Another is an explicit probability transition\nmatrix that captures the direct conversion between labels but needs to be\nderived from an EM algorithm. We conduct experiments on the NYT dataset and\nSemEval 2018 Task 7. The empirical results show comparable or better\nperformance over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 19:38:20 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wu", "Shanchan", ""], ["Fan", "Kai", ""]]}, {"id": "2004.13789", "submitter": "Rapha\\\"el Berthon", "authors": "Rapha\\\"el Berthon, Shibashis Guha, Jean-Fran\\c{c}ois Raskin", "title": "Mixing Probabilistic and non-Probabilistic Objectives in Markov Decision\n  Processes", "comments": "Paper accepted to LICS 2020 - Full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider algorithms to decide the existence of strategies\nin MDPs for Boolean combinations of objectives. These objectives are\nomega-regular properties that need to be enforced either surely, almost surely,\nexistentially, or with non-zero probability. In this setting, relevant\nstrategies are randomized infinite memory strategies: both infinite memory and\nrandomization may be needed to play optimally. We provide algorithms to solve\nthe general case of Boolean combinations and we also investigate relevant\nsubcases. We further report on complexity bounds for these problems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 19:48:15 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Guha", "Shibashis", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "2004.13818", "submitter": "Long Xuan Ma", "authors": "Longxuan Ma and Wei-Nan Zhang and Mingda Li and Ting Liu", "title": "A Survey of Document Grounded Dialogue Systems (DGDS)", "comments": "30 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue system (DS) attracts great attention from industry and academia\nbecause of its wide application prospects. Researchers usually divide the DS\naccording to the function. However, many conversations require the DS to switch\nbetween different functions. For example, movie discussion can change from\nchit-chat to QA, the conversational recommendation can transform from chit-chat\nto recommendation, etc. Therefore, classification according to functions may\nnot be enough to help us appreciate the current development trend. We classify\nthe DS based on background knowledge. Specifically, study the latest DS based\non the unstructured document(s). We define Document Grounded Dialogue System\n(DGDS) as the DS that the dialogues are centering on the given document(s). The\nDGDS can be used in scenarios such as talking over merchandise against product\nManual, commenting on news reports, etc. We believe that extracting\nunstructured document(s) information is the future trend of the DS because a\ngreat amount of human knowledge lies in these document(s). The research of the\nDGDS not only possesses a broad application prospect but also facilitates AI to\nbetter understand human knowledge and natural language. We analyze the\nclassification, architecture, datasets, models, and future development trends\nof the DGDS, hoping to help researchers in this field.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:22:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ma", "Longxuan", ""], ["Zhang", "Wei-Nan", ""], ["Li", "Mingda", ""], ["Liu", "Ting", ""]]}, {"id": "2004.13821", "submitter": "GuanMing Xiong", "authors": "Guanming Xiong", "title": "Fine-tuning Multi-hop Question Answering with Hierarchical Graph Network", "comments": "the experience result is not as good as I except", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a two stage model for multi-hop question answering.\nThe first stage is a hierarchical graph network, which is used to reason over\nmulti-hop question and is capable to capture different levels of granularity\nusing the nature structure(i.e., paragraphs, questions, sentences and entities)\nof documents. The reasoning process is convert to node classify task(i.e.,\nparagraph nodes and sentences nodes). The second stage is a language model\nfine-tuning task. In a word, stage one use graph neural network to select and\nconcatenate support sentences as one paragraph, and stage two find the answer\nspan in language model fine-tuning paradigm.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:34:16 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 03:33:21 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Guanming", ""]]}, {"id": "2004.13823", "submitter": "Xiangpeng Wan", "authors": "Xiangpeng Wan, Hakim Ghazzai, and Yehia Massoud", "title": "Leveraging Personal Navigation Assistant Systems Using Automated Social\n  Media Traffic Reporting", "comments": "This paper is accepted for publication in IEEE Technology Engineering\n  Management Society International Conference (TEMSCON'20), Metro Detroit,\n  Michigan (USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern urbanization is demanding smarter technologies to improve a variety of\napplications in intelligent transportation systems to relieve the increasing\namount of vehicular traffic congestion and incidents. Existing incident\ndetection techniques are limited to the use of sensors in the transportation\nnetwork and hang on human-inputs. Despite of its data abundance, social media\nis not well-exploited in such context. In this paper, we develop an automated\ntraffic alert system based on Natural Language Processing (NLP) that filters\nthis flood of information and extract important traffic-related bullets. To\nthis end, we employ the fine-tuning Bidirectional Encoder Representations from\nTransformers (BERT) language embedding model to filter the related traffic\ninformation from social media. Then, we apply a question-answering model to\nextract necessary information characterizing the report event such as its exact\nlocation, occurrence time, and nature of the events. We demonstrate the adopted\nNLP approaches outperform other existing approach and, after effectively\ntraining them, we focus on real-world situation and show how the developed\napproach can, in real-time, extract traffic-related information and\nautomatically convert them into alerts for navigation assistance applications\nsuch as navigation apps.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:26:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wan", "Xiangpeng", ""], ["Ghazzai", "Hakim", ""], ["Massoud", "Yehia", ""]]}, {"id": "2004.13829", "submitter": "Makoto Nakatsuji Ph. D.", "authors": "Makoto Nakatsuji, Sohei Okui", "title": "Answer Generation through Unified Memories over Multiple Passages", "comments": "IJCAI-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension methods that generate answers by referring to\nmultiple passages for a question have gained much attention in AI and NLP\ncommunities. The current methods, however, do not investigate the relationships\namong multiple passages in the answer generation process, even though topics\ncorrelated among the passages may be answer candidates. Our method, called\nneural answer Generation through Unified Memories over Multiple Passages\n(GUM-MP), solves this problem as follows. First, it determines which tokens in\nthe passages are matched to the question. In particular, it investigates\nmatches between tokens in positive passages, which are assigned to the\nquestion, and those in negative passages, which are not related to the\nquestion. Next, it determines which tokens in the passage are matched to other\npassages assigned to the same question and at the same time it investigates the\ntopics in which they are matched. Finally, it encodes the token sequences with\nthe above two matching results into unified memories in the passage encoders\nand learns the answer sequence by using an encoder-decoder with a\nmultiple-pointer-generator mechanism. As a result, GUM-MP can generate answers\nby pointing to important tokens present across passages. Evaluations indicate\nthat GUM-MP generates much more accurate results than the current models do.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:46:40 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Nakatsuji", "Makoto", ""], ["Okui", "Sohei", ""]]}, {"id": "2004.13831", "submitter": "Vid Kocijan", "authors": "Vid Kocijan, Thomas Lukasiewicz, Ernest Davis, Gary Marcus, Leora\n  Morgenstern", "title": "A Review of Winograd Schema Challenge Datasets and Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Winograd Schema Challenge is both a commonsense reasoning and natural\nlanguage understanding challenge, introduced as an alternative to the Turing\ntest. A Winograd schema is a pair of sentences differing in one or two words\nwith a highly ambiguous pronoun, resolved differently in the two sentences,\nthat appears to require commonsense knowledge to be resolved correctly. The\nexamples were designed to be easily solvable by humans but difficult for\nmachines, in principle requiring a deep understanding of the content of the\ntext and the situation it describes. This paper reviews existing Winograd\nSchema Challenge benchmark datasets and approaches that have been published\nsince its introduction.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 08:40:11 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kocijan", "Vid", ""], ["Lukasiewicz", "Thomas", ""], ["Davis", "Ernest", ""], ["Marcus", "Gary", ""], ["Morgenstern", "Leora", ""]]}, {"id": "2004.13832", "submitter": "Luca Mariot", "authors": "Luca Manzoni, Domagoj Jakobovic, Luca Mariot, Stjepan Picek, Mauro\n  Castelli", "title": "Towards an evolutionary-based approach for natural language processing", "comments": "18 pages, 7 figures, 2 tables. Accepted for publication at the\n  Genetic and Evolutionary Computation Conference (GECCO 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks related to Natural Language Processing (NLP) have recently been the\nfocus of a large research endeavor by the machine learning community. The\nincreased interest in this area is mainly due to the success of deep learning\nmethods. Genetic Programming (GP), however, was not under the spotlight with\nrespect to NLP tasks. Here, we propose a first proof-of-concept that combines\nGP with the well established NLP tool word2vec for the next word prediction\ntask. The main idea is that, once words have been moved into a vector space,\ntraditional GP operators can successfully work on vectors, thus producing\nmeaningful words as the output. To assess the suitability of this approach, we\nperform an experimental evaluation on a set of existing newspaper headlines.\nIndividuals resulting from this (pre-)training phase can be employed as the\ninitial population in other NLP tasks, like sentence generation, which will be\nthe focus of future investigations, possibly employing adversarial\nco-evolutionary approaches.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:44:12 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Manzoni", "Luca", ""], ["Jakobovic", "Domagoj", ""], ["Mariot", "Luca", ""], ["Picek", "Stjepan", ""], ["Castelli", "Mauro", ""]]}, {"id": "2004.13835", "submitter": "Jing Gu", "authors": "Jing Gu, Qingyang Wu, Chongruo Wu, Weiyan Shi, Zhou Yu", "title": "A Tailored Pre-Training Model for Task-Oriented Dialog Generation", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of large pre-trained language models such as BERT and\nGPT-2 has suggested the effectiveness of incorporating language priors in\ndownstream dialog generation tasks. However, the performance of pre-trained\nmodels on the dialog task is not as optimal as expected. In this paper, we\npropose a Pre-trained Role Alternating Language model (PRAL), designed\nspecifically for task-oriented conversational systems. We adopted (Wu et al.,\n2019) that models two speakers separately. We also design several techniques,\nsuch as start position randomization, knowledge distillation, and history\ndiscount to improve pre-training performance. We introduce a task-oriented\ndialog pretraining dataset by cleaning 13 existing data sets. We test PRAL on\nthree different downstream tasks. The results show that PRAL performs better or\non par with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 09:25:45 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gu", "Jing", ""], ["Wu", "Qingyang", ""], ["Wu", "Chongruo", ""], ["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "2004.13836", "submitter": "Heerok Banerjee", "authors": "Heerok Banerjee, V. Ganapathy and V. M. Shenbagaraman", "title": "Uncertainty Modelling in Risk-averse Supply Chain Systems Using\n  Multi-objective Pareto Optimization", "comments": "15 pages, 6 Figures, 2 Tables, research article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the arduous tasks in supply chain modelling is to build robust models\nagainst irregular variations. During the proliferation of time-series analyses\nand machine learning models, several modifications were proposed such as\nacceleration of the classical levenberg-marquardt algorithm, weight decaying\nand normalization, which introduced an algorithmic optimization approach to\nthis problem. In this paper, we have introduced a novel methodology namely,\nPareto Optimization to handle uncertainties and bound the entropy of such\nuncertainties by explicitly modelling them under some apriori assumptions. We\nhave implemented Pareto Optimization using a genetic approach and compared the\nresults with classical genetic algorithms and Mixed-Integer Linear Programming\n(MILP) models. Our results yields empirical evidence suggesting that Pareto\nOptimization can elude such non-deterministic errors and is a formal approach\ntowards producing robust and reactive supply chain models.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:04:25 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Banerjee", "Heerok", ""], ["Ganapathy", "V.", ""], ["Shenbagaraman", "V. M.", ""]]}, {"id": "2004.13912", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Nicholas Frosst, Xuezhou Zhang, Rich Caruana and\n  Geoffrey E. Hinton", "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful black-box predictors that have\nachieved impressive performance on a wide variety of tasks. However, their\naccuracy comes at the cost of intelligibility: it is usually unclear how they\nmake their decisions. This hinders their applicability to high stakes\ndecision-making domains such as healthcare. We propose Neural Additive Models\n(NAMs) which combine some of the expressivity of DNNs with the inherent\nintelligibility of generalized additive models. NAMs learn a linear combination\nof neural networks that each attend to a single input feature. These networks\nare trained jointly and can learn arbitrarily complex relationships between\ntheir input feature and the output. Our experiments on regression and\nclassification datasets show that NAMs are more accurate than widely used\nintelligible models such as logistic regression and shallow decision trees.\nThey perform similarly to existing state-of-the-art generalized additive models\nin accuracy, but can be more easily applied to real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:28:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Frosst", "Nicholas", ""], ["Zhang", "Xuezhou", ""], ["Caruana", "Rich", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "2004.13936", "submitter": "Marcella Martins", "authors": "Marcella Scoczynski Ribeiro Martins, Mohamed El Yafrani, Myriam R. B.\n  S. Delgado, and Ricardo Luders", "title": "Multi-layer local optima networks for the analysis of advanced local\n  search-based algorithms", "comments": "Accepted in GECCO2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Local Optima Network (LON) is a graph model that compresses the fitness\nlandscape of a particular combinatorial optimization problem based on a\nspecific neighborhood operator and a local search algorithm. Determining which\nand how landscape features affect the effectiveness of search algorithms is\nrelevant for both predicting their performance and improving the design\nprocess. This paper proposes the concept of multi-layer LONs as well as a\nmethodology to explore these models aiming at extracting metrics for fitness\nlandscape analysis. Constructing such models, extracting and analyzing their\nmetrics are the preliminary steps into the direction of extending the study on\nsingle neighborhood operator heuristics to more sophisticated ones that use\nmultiple operators. Therefore, in the present paper we investigate a twolayer\nLON obtained from instances of a combinatorial problem using bitflip and swap\noperators. First, we enumerate instances of NK-landscape model and use the hill\nclimbing heuristic to build the corresponding LONs. Then, using LON metrics, we\nanalyze how efficiently the search might be when combining both strategies. The\nexperiments show promising results and demonstrate the ability of multi-layer\nLONs to provide useful information that could be used for in metaheuristics\nbased on multiple operators such as Variable Neighborhood Search.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 03:20:01 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Martins", "Marcella Scoczynski Ribeiro", ""], ["Yafrani", "Mohamed El", ""], ["Delgado", "Myriam R. B. S.", ""], ["Luders", "Ricardo", ""]]}, {"id": "2004.13954", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Haoyi Xiong, Dongrui Wu", "title": "Rethink the Connections among Generalization, Memorization and the\n  Spectral Bias of DNNs", "comments": "IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized deep neural networks (DNNs) with sufficient capacity to\nmemorize random noise can achieve excellent generalization performance,\nchallenging the bias-variance trade-off in classical learning theory. Recent\nstudies claimed that DNNs first learn simple patterns and then memorize noise;\nsome other works showed a phenomenon that DNNs have a spectral bias to learn\ntarget functions from low to high frequencies during training. However, we show\nthat the monotonicity of the learning bias does not always hold: under the\nexperimental setup of deep double descent, the high-frequency components of\nDNNs diminish in the late stage of training, leading to the second descent of\nthe test error. Besides, we find that the spectrum of DNNs can be applied to\nindicating the second descent of the test error, even though it is calculated\nfrom the training set only.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 04:24:25 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 11:18:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Xiao", ""], ["Xiong", "Haoyi", ""], ["Wu", "Dongrui", ""]]}, {"id": "2004.14014", "submitter": "Olivier Teytaud", "authors": "Jialin Liu, Antoine Moreau, Mike Preuss, Baptiste Roziere, Jeremy\n  Rapin, Fabien Teytaud, Olivier Teytaud", "title": "Versatile Black-Box Optimization", "comments": "Accepted at GECCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing automatically the right algorithm using problem descriptors is a\nclassical component of combinatorial optimization. It is also a good tool for\nmaking evolutionary algorithms fast, robust and versatile. We present Shiwa, an\nalgorithm good at both discrete and continuous, noisy and noise-free,\nsequential and parallel, black-box optimization. Our algorithm is\nexperimentally compared to competitors on YABBOB, a BBOB comparable testbed,\nand on some variants of it, and then validated on several real world testbeds.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:20:36 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Liu", "Jialin", ""], ["Moreau", "Antoine", ""], ["Preuss", "Mike", ""], ["Roziere", "Baptiste", ""], ["Rapin", "Jeremy", ""], ["Teytaud", "Fabien", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2004.14025", "submitter": "Sungjin Park", "authors": "Sungjin Park, Taesun Whang, Yeochan Yoon, Heuiseok Lim", "title": "Multi-View Attention Network for Visual Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual dialog is a challenging vision-language task in which a series of\nquestions visually grounded by a given image are answered. To resolve the\nvisual dialog task, a high-level understanding of various multimodal inputs\n(e.g., question, dialog history, and image) is required. Specifically, it is\nnecessary for an agent to 1) determine the semantic intent of question and 2)\nalign question-relevant textual and visual contents among heterogeneous\nmodality inputs. In this paper, we propose Multi-View Attention Network (MVAN),\nwhich leverages multiple views about heterogeneous inputs based on attention\nmechanisms. MVAN effectively captures the question-relevant information from\nthe dialog history with two complementary modules (i.e., Topic Aggregation and\nContext Matching), and builds multimodal representations through sequential\nalignment processes (i.e., Modality Alignment). Experimental results on VisDial\nv1.0 dataset show the effectiveness of our proposed model, which outperforms\nthe previous state-of-the-art methods with respect to all evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:46:38 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:28:57 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 00:51:40 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Park", "Sungjin", ""], ["Whang", "Taesun", ""], ["Yoon", "Yeochan", ""], ["Lim", "Heuiseok", ""]]}, {"id": "2004.14034", "submitter": "Jens Schreiber", "authors": "Jens Schreiber, Bernhard Sick", "title": "Emerging Relation Network and Task Embedding for Multi-Task Regression\n  Problems", "comments": "8 pages;2 tables;5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (mtl) provides state-of-the-art results in many\napplications of computer vision and natural language processing. In contrast to\nsingle-task learning (stl), mtl allows for leveraging knowledge between related\ntasks improving prediction results on the main task (in contrast to an\nauxiliary task) or all tasks. However, there is a limited number of comparative\nstudies on applying mtl architectures for regression and time series problems\ntaking recent advances of mtl into account. An interesting, non-linear problem\nis the forecast of the expected power generation for renewable power plants.\nTherefore, this article provides a comparative study of the following recent\nand important mtl architectures: Hard parameter sharing, cross-stitch network,\nsluice network (sn). They are compared to a multi-layer perceptron model of\nsimilar size in an stl setting. Additionally, we provide a simple, yet\neffective approach to model task specific information through an embedding\nlayer in an multi-layer perceptron, referred to as task embedding. Further, we\nintroduce a new mtl architecture named emerging relation network (ern), which\ncan be considered as an extension of the sluice network. For a solar power\ndataset, the task embedding achieves the best mean improvement with 14.9%. The\nmean improvement of the ern and the sn on the solar dataset is of similar\nmagnitude with 14.7% and 14.8%. On a wind power dataset, only the ern achieves\na significant improvement of up to 7.7%. Results suggest that the ern is\nbeneficial when tasks are only loosely related and the prediction problem is\nmore non-linear. Contrary, the proposed task embedding is advantageous when\ntasks are strongly correlated. Further, the task embedding provides an\neffective approach with reduced computational effort compared to other mtl\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:02:24 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Schreiber", "Jens", ""], ["Sick", "Bernhard", ""]]}, {"id": "2004.14035", "submitter": "Sebastian Feld", "authors": "Thomas Gabor (1), Leo S\\\"unkel (1), Fabian Ritz (1), Thomy Phan (1),\n  Lenz Belzner (2), Christoph Roch (1), Sebastian Feld (1), Claudia\n  Linnhoff-Popien (1) ((1) LMU Munich, (2) MaibornWolff)", "title": "The Holy Grail of Quantum Artificial Intelligence: Major Challenges in\n  Accelerating the Machine Learning Pipeline", "comments": "6 pages, 4 figures, accepted at the 1st International Workshop on\n  Quantum Software Engineering (Q-SE 2020) at ICSE 2020 and to be published in\n  the corresponding proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the synergetic connection between quantum computing and artificial\nintelligence. After surveying current approaches to quantum artificial\nintelligence and relating them to a formal model for machine learning\nprocesses, we deduce four major challenges for the future of quantum artificial\nintelligence: (i) Replace iterative training with faster quantum algorithms,\n(ii) distill the experience of larger amounts of data into the training\nprocess, (iii) allow quantum and classical components to be easily combined and\nexchanged, and (iv) build tools to thoroughly analyze whether observed benefits\nreally stem from quantum properties of the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:07:05 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gabor", "Thomas", "", "LMU Munich"], ["S\u00fcnkel", "Leo", "", "LMU Munich"], ["Ritz", "Fabian", "", "LMU Munich"], ["Phan", "Thomy", "", "LMU Munich"], ["Belzner", "Lenz", "", "MaibornWolff"], ["Roch", "Christoph", "", "LMU Munich"], ["Feld", "Sebastian", "", "LMU Munich"], ["Linnhoff-Popien", "Claudia", "", "LMU Munich"]]}, {"id": "2004.14067", "submitter": "Anjana Wijekoon", "authors": "Nirmalie Wiratunga, Kay Cooper, Anjana Wijekoon, Chamath Palihawadana,\n  Vanessa Mendham, Ehud Reiter, Kyle Martin", "title": "FitChat: Conversational Artificial Intelligence Interventions for\n  Encouraging Physical Activity in Older Adults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delivery of digital behaviour change interventions which encourage physical\nactivity has been tried in many forms. Most often interventions are delivered\nas text notifications, but these do not promote interaction. Advances in\nconversational AI have improved natural language understanding and generation,\nallowing AI chatbots to provide an engaging experience with the user. For this\nreason, chatbots have recently been seen in healthcare delivering digital\ninterventions through free text or choice selection. In this work, we explore\nthe use of voice-based AI chatbots as a novel mode of intervention delivery,\nspecifically targeting older adults to encourage physical activity. We\nco-created \"FitChat\", an AI chatbot, with older adults and we evaluate the\nfirst prototype using Think Aloud Sessions. Our thematic evaluation suggests\nthat older adults prefer voice-based chat over text notifications or free text\nentry and that voice is a powerful mode for encouraging motivation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:39:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wiratunga", "Nirmalie", ""], ["Cooper", "Kay", ""], ["Wijekoon", "Anjana", ""], ["Palihawadana", "Chamath", ""], ["Mendham", "Vanessa", ""], ["Reiter", "Ehud", ""], ["Martin", "Kyle", ""]]}, {"id": "2004.14069", "submitter": "Ming Gong", "authors": "Fei Yuan, Linjun Shou, Xuanyu Bai, Ming Gong, Yaobo Liang, Nan Duan,\n  Yan Fu, Daxin Jiang", "title": "Enhancing Answer Boundary Detection for Multilingual Machine Reading\n  Comprehension", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual pre-trained models could leverage the training data from a rich\nsource language (such as English) to improve performance on low resource\nlanguages. However, the transfer quality for multilingual Machine Reading\nComprehension (MRC) is significantly worse than sentence classification tasks\nmainly due to the requirement of MRC to detect the word level answer boundary.\nIn this paper, we propose two auxiliary tasks in the fine-tuning stage to\ncreate additional phrase boundary supervision: (1) A mixed MRC task, which\ntranslates the question or passage to other languages and builds cross-lingual\nquestion-passage pairs; (2) A language-agnostic knowledge masking task by\nleveraging knowledge phrases mined from web. Besides, extensive experiments on\ntwo cross-lingual MRC datasets show the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:44:00 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 13:17:28 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Yuan", "Fei", ""], ["Shou", "Linjun", ""], ["Bai", "Xuanyu", ""], ["Gong", "Ming", ""], ["Liang", "Yaobo", ""], ["Duan", "Nan", ""], ["Fu", "Yan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2004.14120", "submitter": "Ant\\'onio G\\'ois", "authors": "Ant\\'onio G\\'ois, Kyunghyun Cho, Andr\\'e Martins", "title": "Learning Non-Monotonic Automatic Post-Editing of Translations from Human\n  Orderings", "comments": "Accepted at EAMT 2020; dataset available here:\n  https://github.com/antoniogois/keystrokes_ape", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in neural machine translation has explored flexible\ngeneration orders, as an alternative to left-to-right generation. However,\ntraining non-monotonic models brings a new complication: how to search for a\ngood ordering when there is a combinatorial explosion of orderings arriving at\nthe same final result? Also, how do these automatic orderings compare with the\nactual behaviour of human translators? Current models rely on manually built\nbiases or are left to explore all possibilities on their own. In this paper, we\nanalyze the orderings produced by human post-editors and use them to train an\nautomatic post-editing system. We compare the resulting system with those\ntrained with left-to-right and random post-editing orderings. We observe that\nhumans tend to follow a nearly left-to-right order, but with interesting\ndeviations, such as preferring to start by correcting punctuation or verbs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:19:50 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["G\u00f3is", "Ant\u00f3nio", ""], ["Cho", "Kyunghyun", ""], ["Martins", "Andr\u00e9", ""]]}, {"id": "2004.14162", "submitter": "Pengjie Ren", "authors": "Pengjie Ren, Zhumin Chen, Zhaochun Ren, Evangelos Kanoulas, Christof\n  Monz, and Maarten de Rijke", "title": "Conversations with Search Engines: SERP-based Conversational Response\n  Generation", "comments": "published in TOIS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of answering complex information needs\nby conversing conversations with search engines, in the sense that users can\nexpress their queries in natural language, and directly receivethe information\nthey need from a short system response in a conversational manner. Recently,\nthere have been some attempts towards a similar goal, e.g., studies on\nConversational Agents (CAs) and Conversational Search (CS). However, they\neither do not address complex information needs, or they are limited to the\ndevelopment of conceptual frameworks and/or laboratory-based user studies.\n  We pursue two goals in this paper: (1) the creation of a suitable dataset,\nthe Search as a Conversation (SaaC) dataset, for the development of pipelines\nfor conversations with search engines, and (2) the development of\nastate-of-the-art pipeline for conversations with search engines, the\nConversations with Search Engines (CaSE), using this dataset. SaaC is built\nbased on a multi-turn conversational search dataset, where we further employ\nworkers from a crowdsourcing platform to summarize each relevant passage into a\nshort, conversational response. CaSE enhances the state-of-the-art by\nintroducing a supporting token identification module and aprior-aware pointer\ngenerator, which enables us to generate more accurate responses.\n  We carry out experiments to show that CaSE is able to outperform strong\nbaselines. We also conduct extensive analyses on the SaaC dataset to show where\nthere is room for further improvement beyond CaSE. Finally, we release the SaaC\ndataset and the code for CaSE and all models used for comparison to facilitate\nfuture research on this topic.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:07:53 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 06:40:31 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Ren", "Zhaochun", ""], ["Kanoulas", "Evangelos", ""], ["Monz", "Christof", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2004.14171", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Ling Cai, Rui Zhu, Blake Regalia, Bo\n  Yan, Meilin Shi, Ni Lao", "title": "SE-KGE: A Location-Aware Knowledge Graph Embedding Model for Geographic\n  Question Answering and Spatial Semantic Lifting", "comments": "Accepted to Transactions in GIS", "journal-ref": "Transactions in GIS, 2020", "doi": "10.1111/TGIS.12629", "report-no": null, "categories": "cs.DB cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph (KG) embeddings is an emerging technique for a\nvariety of downstream tasks such as summarization, link prediction, information\nretrieval, and question answering. However, most existing KG embedding models\nneglect space and, therefore, do not perform well when applied to (geo)spatial\ndata and tasks. For those models that consider space, most of them primarily\nrely on some notions of distance. These models suffer from higher computational\ncomplexity during training while still losing information beyond the relative\ndistance between entities. In this work, we propose a location-aware KG\nembedding model called SE-KGE. It directly encodes spatial information such as\npoint coordinates or bounding boxes of geographic entities into the KG\nembedding space. The resulting model is capable of handling different types of\nspatial reasoning. We also construct a geographic knowledge graph as well as a\nset of geographic query-answer pairs called DBGeo to evaluate the performance\nof SE-KGE in comparison to multiple baselines. Evaluation results show that\nSE-KGE outperforms these baselines on the DBGeo dataset for geographic logic\nquery answering task. This demonstrates the effectiveness of our\nspatially-explicit model and the importance of considering the scale of\ndifferent geographic entities. Finally, we introduce a novel downstream task\ncalled spatial semantic lifting which links an arbitrary location in the study\narea to entities in the KG via some relations. Evaluation on DBGeo shows that\nour model outperforms the baseline by a substantial margin.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:46:31 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Cai", "Ling", ""], ["Zhu", "Rui", ""], ["Regalia", "Blake", ""], ["Yan", "Bo", ""], ["Shi", "Meilin", ""], ["Lao", "Ni", ""]]}, {"id": "2004.14173", "submitter": "Sarath Pathari", "authors": "Sarath P, Soorya M, Shaik Abdul Rahman A, S Suresh Kumar, K Devaki", "title": "Assessing Car Damage using Mask R-CNN", "comments": null, "journal-ref": null, "doi": "10.35940/ijeat.C5302.029320", "report-no": "C5302029320", "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Picture based vehicle protection handling is a significant region with\nenormous degree for mechanization. In this paper we consider the issue of\nvehicle harm characterization, where a portion of the classifications can be\nfine-granular. We investigate profound learning based procedures for this\nreason. At first, we attempt legitimately preparing a CNN. In any case, because\nof little arrangement of marked information, it doesn't function admirably. At\nthat point, we investigate the impact of space explicit pre-preparing followed\nby tweaking. At last, we explore different avenues regarding move learning and\noutfit learning. Trial results show that move learning works superior to space\nexplicit tweaking. We accomplish precision of 89.5% with blend of move and\ngathering learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:19:25 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 04:13:34 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 03:29:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["P", "Sarath", ""], ["M", "Soorya", ""], ["A", "Shaik Abdul Rahman", ""], ["Kumar", "S Suresh", ""], ["Devaki", "K", ""]]}, {"id": "2004.14174", "submitter": "John Morris", "authors": "John X. Morris, Eli Lifland, Jack Lanchantin, Yangfeng Ji, Yanjun Qi", "title": "Reevaluating Adversarial Examples in Natural Language", "comments": "15 pages; 9 Tables; 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art attacks on NLP models lack a shared definition of a what\nconstitutes a successful attack. We distill ideas from past work into a unified\nframework: a successful natural language adversarial example is a perturbation\nthat fools the model and follows some linguistic constraints. We then analyze\nthe outputs of two state-of-the-art synonym substitution attacks. We find that\ntheir perturbations often do not preserve semantics, and 38% introduce\ngrammatical errors. Human surveys reveal that to successfully preserve\nsemantics, we need to significantly increase the minimum cosine similarities\nbetween the embeddings of swapped words and between the sentence encodings of\noriginal and perturbed sentences.With constraints adjusted to better preserve\nsemantics and grammaticality, the attack success rate drops by over 70\npercentage points.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 03:09:48 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 04:16:23 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Lanchantin", "Jack", ""], ["Ji", "Yangfeng", ""], ["Qi", "Yanjun", ""]]}, {"id": "2004.14201", "submitter": "Ruize Wang", "authors": "Ruize Wang, Duyu Tang, Nan Duan, Wanjun Zhong, Zhongyu Wei, Xuanjing\n  Huang, Daxin Jiang, Ming Zhou", "title": "Leveraging Declarative Knowledge in Text and First-Order Logic for\n  Fine-Grained Propaganda Detection", "comments": "Accepted as a long paper to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the detection of propagandistic text fragments in news articles.\nInstead of merely learning from input-output datapoints in training data, we\nintroduce an approach to inject declarative knowledge of fine-grained\npropaganda techniques. Specifically, we leverage the declarative knowledge\nexpressed in both first-order logic and natural language. The former refers to\nthe logical consistency between coarse- and fine-grained predictions, which is\nused to regularize the training process with propositional Boolean expressions.\nThe latter refers to the literal definition of each propaganda technique, which\nis utilized to get class representations for regularizing the model parameters.\nWe conduct experiments on Propaganda Techniques Corpus, a large manually\nannotated dataset for fine-grained propaganda detection. Experiments show that\nour method achieves superior performance, demonstrating that leveraging\ndeclarative knowledge can help the model to make more accurate predictions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:46:15 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 13:08:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Ruize", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Zhong", "Wanjun", ""], ["Wei", "Zhongyu", ""], ["Huang", "Xuanjing", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "2004.14254", "submitter": "Kangenbei Liao", "authors": "Kangenbei Liao, Qianlong Liu, Zhongyu Wei, Baolin Peng, Qin Chen,\n  Weijian Sun, Xuanjing Huang", "title": "Task-oriented Dialogue System for Automatic Disease Diagnosis via\n  Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on automatic disease diagnosis with reinforcement\nlearning (RL) methods in task-oriented dialogues setting. Different from\nconventional RL tasks, the action space for disease diagnosis (i.e., symptoms)\nis inevitably large, especially when the number of diseases increases. However,\nexisting approaches to this problem employ a flat RL policy, which typically\nworks well in simple tasks but has significant challenges in complex scenarios\nlike disease diagnosis. Towards this end, we propose to integrate a\nhierarchical policy of two levels into the dialogue policy learning. The high\nlevel policy consists of a model named master that is responsible for\ntriggering a model in low level, the low level policy consists of several\nsymptom checkers and a disease classifier. Experimental results on both\nself-constructed real-world and synthetic datasets demonstrate that our\nhierarchical framework achieves higher accuracy in disease diagnosis compared\nwith existing systems. Besides, the datasets\n(http://www.sdspeople.fudan.edu.cn/zywei/data/Fudan-Medical-Dialogue2.0) and\ncodes (https://github.com/nnbay/MeicalChatbot-HRL) are all available now.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:02:41 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Liao", "Kangenbei", ""], ["Liu", "Qianlong", ""], ["Wei", "Zhongyu", ""], ["Peng", "Baolin", ""], ["Chen", "Qin", ""], ["Sun", "Weijian", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2004.14265", "submitter": "Epaminondas Kapetanios", "authors": "Epaminondas Kapetanios, Vijayan Sugumaran, and Anastassia Angelopoulou", "title": "Exploring the Suitability of Semantic Spaces as Word Association Models\n  for the Extraction of Semantic Relationships", "comments": "10 pages, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Given the recent advances and progress in Natural Language Processing (NLP),\nextraction of semantic relationships has been at the top of the research agenda\nin the last few years. This work has been mainly motivated by the fact that\nbuilding knowledge graphs (KG) and bases (KB), as a key ingredient of\nintelligent applications, is a never-ending challenge, since new knowledge\nneeds to be harvested while old knowledge needs to be revised. Currently,\napproaches towards relation extraction from text are dominated by neural models\npracticing some sort of distant (weak) supervision in machine learning from\nlarge corpora, with or without consulting external knowledge sources. In this\npaper, we empirically study and explore the potential of a novel idea of using\nclassical semantic spaces and models, e.g., Word Embedding, generated for\nextracting word association, in conjunction with relation extraction\napproaches. The goal is to use these word association models to reinforce\ncurrent relation extraction approaches. We believe that this is a first attempt\nof this kind and the results of the study should shed some light on the extent\nto which these word association models can be used as well as the most\npromising types of relationships to be considered for extraction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:25:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kapetanios", "Epaminondas", ""], ["Sugumaran", "Vijayan", ""], ["Angelopoulou", "Anastassia", ""]]}, {"id": "2004.14283", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva, Nikita Bhutani, Behzad Golshan, Wang-Chiew Tan, and\n  Isabelle Augenstein", "title": "SubjQA: A Dataset for Subjectivity and Review Comprehension", "comments": "EMNLP 2020 Long Paper - Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Subjectivity is the expression of internal opinions or beliefs which cannot\nbe objectively observed or verified, and has been shown to be important for\nsentiment analysis and word-sense disambiguation. Furthermore, subjectivity is\nan important aspect of user-generated data. In spite of this, subjectivity has\nnot been investigated in contexts where such data is widespread, such as in\nquestion answering (QA). We therefore investigate the relationship between\nsubjectivity and QA, while developing a new dataset. We compare and contrast\nwith analyses from previous work, and verify that findings regarding\nsubjectivity still hold when using recently developed NLP architectures. We\nfind that subjectivity is also an important feature in the case of QA, albeit\nwith more intricate interactions between subjectivity and QA performance. For\ninstance, a subjective question may or may not be associated with a subjective\nanswer. We release an English QA dataset (SubjQA) based on customer reviews,\ncontaining subjectivity annotations for questions and answer spans across 6\ndistinct domains.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:59:30 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 13:36:44 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 06:04:27 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Bjerva", "Johannes", ""], ["Bhutani", "Nikita", ""], ["Golshan", "Behzad", ""], ["Tan", "Wang-Chiew", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2004.14303", "submitter": "Hatem Haddad", "authors": "Chayma Fourati, Abir Messaoudi and Hatem Haddad", "title": "TUNIZI: a Tunisian Arabizi sentiment analysis Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  On social media, Arabic people tend to express themselves in their own local\ndialects. More particularly, Tunisians use the informal way called \"Tunisian\nArabizi\". Analytical studies seek to explore and recognize online opinions\naiming to exploit them for planning and prediction purposes such as measuring\nthe customer satisfaction and establishing sales and marketing strategies.\nHowever, analytical studies based on Deep Learning are data hungry. On the\nother hand, African languages and dialects are considered low resource\nlanguages. For instance, to the best of our knowledge, no annotated Tunisian\nArabizi dataset exists. In this paper, we introduce TUNIZI a sentiment analysis\nTunisian Arabizi Dataset, collected from social networks, preprocessed for\nanalytical studies and annotated manually by Tunisian native speakers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:24:02 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Fourati", "Chayma", ""], ["Messaoudi", "Abir", ""], ["Haddad", "Hatem", ""]]}, {"id": "2004.14309", "submitter": "Pierluca D'Oro", "authors": "Pierluca D'Oro, Wojciech Ja\\'skowski", "title": "How to Learn a Useful Critic? Model-based Action-Gradient-Estimator\n  Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic-policy actor-critic algorithms for continuous control improve\nthe actor by plugging its actions into the critic and ascending the\naction-value gradient, which is obtained by chaining the actor's Jacobian\nmatrix with the gradient of the critic with respect to input actions. However,\ninstead of gradients, the critic is, typically, only trained to accurately\npredict expected returns, which, on their own, are useless for policy\noptimization. In this paper, we propose MAGE, a model-based actor-critic\nalgorithm, grounded in the theory of policy gradients, which explicitly learns\nthe action-value gradient. MAGE backpropagates through the learned dynamics to\ncompute gradient targets in temporal difference learning, leading to a critic\ntailored for policy improvement. On a set of MuJoCo continuous-control tasks,\nwe demonstrate the efficiency of the algorithm in comparison to model-free and\nmodel-based state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:30:53 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:24:34 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["D'Oro", "Pierluca", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "2004.14362", "submitter": "Eugenio Alcala", "authors": "Eugenio Alcal\\'a, Olivier Sename, Vicen\\c{c} Puig, and Joseba Quevedo", "title": "TS-MPC for Autonomous Vehicle using a Learning Approach", "comments": "6 pages, 7 figures, IFAC 2020 World Congress", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the Model Predictive Control (MPC) and Moving Horizon\nEstimator (MHE) strategies using a data-driven approach to learn a\nTakagi-Sugeno (TS) representation of the vehicle dynamics are proposed to solve\nautonomous driving control problems in real-time. To address the TS modeling,\nwe use the Adaptive Neuro-Fuzzy Inference System (ANFIS) approach to obtain a\nset of polytopic-based linear representations as well as a set of membership\nfunctions relating in a non-linear way the different linear subsystems. The\nproposed control approach is provided by racing-based references of an external\nplanner and estimations from the MHE offering a high driving performance in\nracing mode. The control-estimation scheme is tested in a simulated racing\nenvironment to show the potential of the presented approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:42:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Alcal\u00e1", "Eugenio", ""], ["Sename", "Olivier", ""], ["Puig", "Vicen\u00e7", ""], ["Quevedo", "Joseba", ""]]}, {"id": "2004.14378", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte, Norbert Manthey, Julian Stecklina, Andr\\'e\n  Schidler", "title": "Towards Faster Reasoners By Using Transparent Huge Pages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various state-of-the-art automated reasoning (AR) tools are widely used as\nbackend tools in research of knowledge representation and reasoning as well as\nin industrial applications. In testing and verification, those tools often run\ncontinuously or nightly. In this work, we present an approach to reduce the\nruntime of AR tools by 10% on average and up to 20% for long running tasks. Our\nimprovement addresses the high memory usage that comes with the data structures\nused in AR tools, which are based on conflict driven no-good learning. We\nestablish a general way to enable faster memory access by using the memory\ncache line of modern hardware more effectively. Therefore, we extend the\nstandard C library (glibc) by dynamically allowing to use a memory management\nfeature called huge pages. Huge pages allow to reduce the overhead that is\nrequired to translate memory addresses between the virtual memory of the\noperating system and the physical memory of the hardware. In that way, we can\nreduce runtime, costs, and energy consumption of AR tools and applications with\nsimilar memory access patterns simply by linking the tool against this new\nglibc library when compiling it. In every day industrial applications this\neasily allows to be more eco-friendly in computation. To back up the claimed\nspeed-up, we present experimental results for tools that are commonly used in\nthe AR community, including the domains ASP, BMC, MaxSAT, SAT, and SMT.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:57:19 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Manthey", "Norbert", ""], ["Stecklina", "Julian", ""], ["Schidler", "Andr\u00e9", ""]]}, {"id": "2004.14507", "submitter": "Qingfu Zhu", "authors": "Qingfu Zhu, Weinan Zhang, Ting Liu, William Yang Wang", "title": "Counterfactual Off-Policy Training for Neural Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialogue generation suffers from the data insufficiency problem\ndue to the vast size of potential responses. In this paper, we propose to\nexplore potential responses by counterfactual reasoning. Given an observed\nresponse, the counterfactual reasoning model automatically infers the outcome\nof an alternative policy that could have been taken. The resulting\ncounterfactual response synthesized in hindsight is of higher quality than the\nresponse synthesized from scratch. Training on the counterfactual responses\nunder the adversarial learning framework helps to explore the high-reward area\nof the potential response space. An empirical study on the DailyDialog dataset\nshows that our approach significantly outperforms the HRED model as well as the\nconventional adversarial learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 22:46:28 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 07:47:45 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhu", "Qingfu", ""], ["Zhang", "Weinan", ""], ["Liu", "Ting", ""], ["Wang", "William Yang", ""]]}, {"id": "2004.14545", "submitter": "Ning Xie", "authors": "Ning Xie, Gabrielle Ras, Marcel van Gerven, Derek Doran", "title": "Explainable Deep Learning: A Field Guide for the Uninitiated", "comments": "Survey paper on Explainable Deep Learning, 54 pages including\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) is an indispensable machine learning tool for\nachieving human-level performance on many learning tasks. Yet, due to its\nblack-box nature, it is inherently difficult to understand which aspects of the\ninput data drive the decisions of the network. There are various real-world\nscenarios in which humans need to make actionable decisions based on the output\nDNNs. Such decision support systems can be found in critical domains, such as\nlegislation, law enforcement, etc. It is important that the humans making\nhigh-level decisions can be sure that the DNN decisions are driven by\ncombinations of data features that are appropriate in the context of the\ndeployment of the decision support system and that the decisions made are\nlegally or ethically defensible. Due to the incredible pace at which DNN\ntechnology is being developed, the development of new methods and studies on\nexplaining the decision-making process of DNNs has blossomed into an active\nresearch field. A practitioner beginning to study explainable deep learning may\nbe intimidated by the plethora of orthogonal directions the field is taking.\nThis complexity is further exacerbated by the general confusion that exists in\ndefining what it means to be able to explain the actions of a deep learning\nsystem and to evaluate a system's \"ability to explain\". To alleviate this\nproblem, this article offers a \"field guide\" to deep learning explainability\nfor those uninitiated in the field. The field guide: i) Discusses the traits of\na deep learning system that researchers enhance in explainability research, ii)\nplaces explainability in the context of other related deep learning research\nareas, and iii) introduces three simple dimensions defining the space of\nfoundational methods that contribute to explainable deep learning. The guide is\ndesigned as an easy-to-digest starting point for those just embarking in the\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:09:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Xie", "Ning", ""], ["Ras", "Gabrielle", ""], ["van Gerven", "Marcel", ""], ["Doran", "Derek", ""]]}, {"id": "2004.14547", "submitter": "Xiaoteng Ma", "authors": "Xiaoteng Ma, Li Xia, Zhengyuan Zhou, Jun Yang, Qianchuan Zhao", "title": "DSAC: Distributional Soft Actor Critic for Risk-Sensitive Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new reinforcement learning (RL) algorithm called\nDistributional Soft Actor Critic (DSAC), which exploits the distributional\ninformation of accumulated rewards to achieve better performance. Seamlessly\nintegrating SAC (which uses entropy to encourage exploration) with a principled\ndistributional view of the underlying objective, DSAC takes into consideration\nthe randomness in both action and rewards, and beats the state-of-the-art\nbaselines in several continuous control benchmarks. Moreover, with the\ndistributional information of rewards, we propose a unified framework for\nrisk-sensitive learning, one that goes beyond maximizing only expected\naccumulated rewards. Under this framework we discuss three specific\nrisk-related metrics: percentile, mean-variance and distorted expectation. Our\nextensive experiments demonstrate that with distribution modeling in RL, the\nagent performs better for both risk-averse and risk-seeking control tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:23:15 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 02:08:35 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ma", "Xiaoteng", ""], ["Xia", "Li", ""], ["Zhou", "Zhengyuan", ""], ["Yang", "Jun", ""], ["Zhao", "Qianchuan", ""]]}, {"id": "2004.14646", "submitter": "Mohammad Gheshlaghi Azar", "authors": "Daniel Guo, Bernardo Avila Pires, Bilal Piot, Jean-bastien Grill,\n  Florent Altch\\'e, R\\'emi Munos, Mohammad Gheshlaghi Azar", "title": "Bootstrap Latent-Predictive Representations for Multitask Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a good representation is an essential component for deep\nreinforcement learning (RL). Representation learning is especially important in\nmultitask and partially observable settings where building a representation of\nthe unknown environment is crucial to solve the tasks. Here we introduce\nPrediction of Bootstrap Latents (PBL), a simple and flexible self-supervised\nrepresentation learning algorithm for multitask deep RL. PBL builds on\nmultistep predictive representations of future observations, and focuses on\ncapturing structured information about environment dynamics. Specifically, PBL\ntrains its representation by predicting latent embeddings of future\nobservations. These latent embeddings are themselves trained to be predictive\nof the aforementioned representations. These predictions form a bootstrapping\neffect, allowing the agent to learn more about the key aspects of the\nenvironment dynamics. In addition, by defining prediction tasks completely in\nlatent space, PBL provides the flexibility of using multimodal observations\ninvolving pixel images, language instructions, rewards and more. We show in our\nexperiments that PBL delivers across-the-board improved performance over state\nof the art deep RL agents in the DMLab-30 and Atari-57 multitask setting.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:09:41 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Guo", "Daniel", ""], ["Pires", "Bernardo Avila", ""], ["Piot", "Bilal", ""], ["Grill", "Jean-bastien", ""], ["Altch\u00e9", "Florent", ""], ["Munos", "R\u00e9mi", ""], ["Azar", "Mohammad Gheshlaghi", ""]]}, {"id": "2004.14648", "submitter": "Jifan Chen", "authors": "Jifan Chen and Greg Durrett", "title": "Robust Question Answering Through Sub-part Alignment", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current textual question answering models achieve strong performance on\nin-domain test sets, but often do so by fitting surface-level patterns in the\ndata, so they fail to generalize to out-of-distribution settings. To make a\nmore robust and understandable QA system, we model question answering as an\nalignment problem. We decompose both the question and context into smaller\nunits based on off-the-shelf semantic representations (here, semantic roles),\nand align the question to a subgraph of the context in order to find the\nanswer. We formulate our model as a structured SVM, with alignment scores\ncomputed via BERT, and we can train end-to-end despite using beam search for\napproximate inference. Our explicit use of alignments allows us to explore a\nset of constraints with which we can prohibit certain types of bad model\nbehavior arising in cross-domain settings. Furthermore, by investigating\ndifferences in scores across different potential answers, we can seek to\nunderstand what particular aspects of the input lead the model to choose the\nanswer without relying on post-hoc explanation techniques. We train our model\non SQuAD v1.1 and test it on several adversarial and out-of-domain datasets.\nThe results show that our model is more robust cross-domain than the standard\nBERT QA model, and constraints derived from alignment scores allow us to\neffectively trade off coverage and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:10:57 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 23:58:37 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 20:43:55 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Chen", "Jifan", ""], ["Durrett", "Greg", ""]]}, {"id": "2004.14677", "submitter": "Tuhin Chakrabarty Mr", "authors": "Tuhin Chakrabarty, Christopher Hidey, Smaranda Muresan, Kathy Mckeown,\n  Alyssa Hwang", "title": "AMPERSAND: Argument Mining for PERSuAsive oNline Discussions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Argumentation is a type of discourse where speakers try to persuade their\naudience about the reasonableness of a claim by presenting supportive\narguments. Most work in argument mining has focused on modeling arguments in\nmonologues. We propose a computational model for argument mining in online\npersuasive discussion forums that brings together the micro-level (argument as\nproduct) and macro-level (argument as process) models of argumentation.\nFundamentally, this approach relies on identifying relations between components\nof arguments in a discussion thread. Our approach for relation prediction uses\ncontextual information in terms of fine-tuning a pre-trained language model and\nleveraging discourse relations based on Rhetorical Structure Theory. We\nadditionally propose a candidate selection method to automatically predict what\nparts of one's argument will be targeted by other participants in the\ndiscussion. Our models obtain significant improvements compared to recent\nstate-of-the-art approaches using pointer networks and a pre-trained language\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 10:33:40 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Hidey", "Christopher", ""], ["Muresan", "Smaranda", ""], ["Mckeown", "Kathy", ""], ["Hwang", "Alyssa", ""]]}, {"id": "2004.14684", "submitter": "Thomas Chaffre", "authors": "Thomas Chaffre, Julien Moras, Adrien Chan-Hon-Tong, Julien Marzat", "title": "Sim-to-Real Transfer with Incremental Environment Complexity for\n  Reinforcement Learning of Depth-Based Robot Navigation", "comments": null, "journal-ref": "ICINCO 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring learning-based models to the real world remains one of the\nhardest problems in model-free control theory. Due to the cost of data\ncollection on a real robot and the limited sample efficiency of Deep\nReinforcement Learning algorithms, models are usually trained in a simulator\nwhich theoretically provides an infinite amount of data. Despite offering\nunbounded trial and error runs, the reality gap between simulation and the\nphysical world brings little guarantee about the policy behavior in real\noperation. Depending on the problem, expensive real fine-tuning and/or a\ncomplex domain randomization strategy may be required to produce a relevant\npolicy. In this paper, a Soft-Actor Critic (SAC) training strategy using\nincremental environment complexity is proposed to drastically reduce the need\nfor additional training in the real world. The application addressed is\ndepth-based mapless navigation, where a mobile robot should reach a given\nwaypoint in a cluttered environment with no prior mapping information.\nExperimental results in simulated and real environments are presented to assess\nquantitatively the efficiency of the proposed approach, which demonstrated a\nsuccess rate twice higher than a naive strategy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 10:47:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Chaffre", "Thomas", ""], ["Moras", "Julien", ""], ["Chan-Hon-Tong", "Adrien", ""], ["Marzat", "Julien", ""]]}, {"id": "2004.14690", "submitter": "Fei Tang", "authors": "Fei Tang, Wanling Gao, Jianfeng Zhan, Chuanxin Lan, Xu Wen, Lei Wang,\n  Chunjie Luo, Jiahui Dai, Zheng Cao, Xingwang Xiong, Zihan Jiang, Tianshu Hao,\n  Fanda Fan, Fan Zhang, Yunyou Huang, Jianan Chen, Mengjia Du, Rui Ren, Chen\n  Zheng, Daoyi Zheng, Haoning Tang, Kunlin Zhan, Biao Wang, Defei Kong, Minghe\n  Yu, Chongkang Tan, Huan Li, Xinhui Tian, Yatao Li, Junchao Shao, Zhenyu Wang,\n  Xiaoyu Wang, and Hainan Ye", "title": "AIBench Training: Balanced Industry-Standard AI Training Benchmarking", "comments": "ISPASS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier-stage evaluations of a new AI architecture/system need affordable\nbenchmarks. Only using a few AI component benchmarks like MLPerfalone in the\nother stages may lead to misleading conclusions. Moreover, the learning\ndynamics are not well understood, and the benchmarks' shelf-life is short. This\npaper proposes a balanced benchmarking methodology. We use real-world\nbenchmarks to cover the factors space that impacts the learning dynamics to the\nmost considerable extent. After performing an exhaustive survey on Internet\nservice AI domains, we identify and implement nineteen representative AI tasks\nwith state-of-the-art models. For repeatable performance ranking (RPR subset)\nand workload characterization (WC subset), we keep two subsets to a minimum for\naffordability. We contribute by far the most comprehensive AI training\nbenchmark suite. The evaluations show: (1) AIBench Training (v1.1) outperforms\nMLPerfTraining (v0.7) in terms of diversity and representativeness of model\ncomplexity, computational cost, convergent rate, computation, and memory access\npatterns, and hotspot functions; (2) Against the AIBench full benchmarks, its\nRPR subset shortens the benchmarking cost by 64%, while maintaining the primary\nworkload characteristics; (3) The performance ranking shows the single-purpose\nAI accelerator like TPU with the optimized TensorFlowframework performs better\nthan that of GPUs while losing the latter's general support for various AI\nmodels. The specification, source code, and performance numbers are available\nfrom the AIBench homepage\nhttps://www.benchcouncil.org/aibench-training/index.html.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:08:49 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 01:44:14 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 16:41:13 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 06:24:57 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Tang", "Fei", ""], ["Gao", "Wanling", ""], ["Zhan", "Jianfeng", ""], ["Lan", "Chuanxin", ""], ["Wen", "Xu", ""], ["Wang", "Lei", ""], ["Luo", "Chunjie", ""], ["Dai", "Jiahui", ""], ["Cao", "Zheng", ""], ["Xiong", "Xingwang", ""], ["Jiang", "Zihan", ""], ["Hao", "Tianshu", ""], ["Fan", "Fanda", ""], ["Zhang", "Fan", ""], ["Huang", "Yunyou", ""], ["Chen", "Jianan", ""], ["Du", "Mengjia", ""], ["Ren", "Rui", ""], ["Zheng", "Chen", ""], ["Zheng", "Daoyi", ""], ["Tang", "Haoning", ""], ["Zhan", "Kunlin", ""], ["Wang", "Biao", ""], ["Kong", "Defei", ""], ["Yu", "Minghe", ""], ["Tan", "Chongkang", ""], ["Li", "Huan", ""], ["Tian", "Xinhui", ""], ["Li", "Yatao", ""], ["Shao", "Junchao", ""], ["Wang", "Zhenyu", ""], ["Wang", "Xiaoyu", ""], ["Ye", "Hainan", ""]]}, {"id": "2004.14841", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM (UMR\\_8001)), G\\'erard Biau (LSTA),\n  S\\'ebastien da Veiga, Erwan Scornet (CMAP)", "title": "Interpretable Random Forests via Rule Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SIRUS (Stable and Interpretable RUle Set) for regression, a\nstable rule learning algorithm which takes the form of a short and simple list\nof rules. State-of-the-art learning algorithms are often referred to as \"black\nboxes\" because of the high number of operations involved in their prediction\nprocess. Despite their powerful predictivity, this lack of interpretability may\nbe highly restrictive for applications with critical decisions at stake. On the\nother hand, algorithms with a simple structure-typically decision trees, rule\nalgorithms, or sparse linear models-are well known for their instability. This\nundesirable feature makes the conclusions of the data analysis unreliable and\nturns out to be a strong operational limitation. This motivates the design of\nSIRUS, which combines a simple structure with a remarkable stable behavior when\ndata is perturbed. The algorithm is based on random forests, the predictive\naccuracy of which is preserved. We demonstrate the efficiency of the method\nboth empirically (through experiments) and theoretically (with the proof of its\nasymptotic stability). Our R/C++ software implementation sirus is available\nfrom CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:13:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:56:50 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 07:45:02 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 09:09:31 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["Biau", "G\u00e9rard", "", "LSTA"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "2004.14843", "submitter": "Federico Bianchi", "authors": "Federico Bianchi and Gaetano Rossiello and Luca Costabello and Matteo\n  Palmonari and Pasquale Minervini", "title": "Knowledge Graph Embeddings and Explainable AI", "comments": "Federico Bianchi, Gaetano Rossiello, Luca Costabello, Matteo\n  Plamonari, Pasquale Minervini, Knowledge Graph Embeddings and Explainable AI.\n  In: Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge Graphs for\n  eXplainable AI -- Foundations, Applications and Challenges. Studies on the\n  Semantic Web, IOS Press, Amsterdam, 2020", "journal-ref": null, "doi": "10.3233/SSW200011", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embeddings are now a widely adopted approach to knowledge\nrepresentation in which entities and relationships are embedded in vector\nspaces. In this chapter, we introduce the reader to the concept of knowledge\ngraph embeddings by explaining what they are, how they can be generated and how\nthey can be evaluated. We summarize the state-of-the-art in this field by\ndescribing the approaches that have been introduced to represent knowledge in\nthe vector space. In relation to knowledge representation, we consider the\nproblem of explainability, and discuss models and methods for explaining\npredictions obtained via knowledge graph embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:55:09 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Bianchi", "Federico", ""], ["Rossiello", "Gaetano", ""], ["Costabello", "Luca", ""], ["Palmonari", "Matteo", ""], ["Minervini", "Pasquale", ""]]}, {"id": "2004.14850", "submitter": "Ella Peltonen", "authors": "Ella Peltonen, Mehdi Bennis, Michele Capobianco, Merouane Debbah,\n  Aaron Ding, Felipe Gil-Casti\\~neira, Marko Jurmu, Teemu Karvonen, Markus\n  Kelanti, Adrian Kliks, Teemu Lepp\\\"anen, Lauri Lov\\'en, Tommi Mikkonen,\n  Ashwin Rao, Sumudu Samarakoon, Kari Sepp\\\"anen, Pawe{\\l} Sroka, Sasu Tarkoma,\n  Tingting Yang", "title": "6G White Paper on Edge Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this white paper we provide a vision for 6G Edge Intelligence. Moving\ntowards 5G and beyond the future 6G networks, intelligent solutions utilizing\ndata-driven machine learning and artificial intelligence become crucial for\nseveral real-world applications including but not limited to, more efficient\nmanufacturing, novel personal smart device environments and experiences, urban\ncomputing and autonomous traffic settings. We present edge computing along with\nother 6G enablers as a key component to establish the future 2030 intelligent\nInternet technologies as shown in this series of 6G White Papers.\n  In this white paper, we focus in the domains of edge computing infrastructure\nand platforms, data and edge network management, software development for edge,\nand real-time and distributed training of ML/AI algorithms, along with\nsecurity, privacy, pricing, and end-user aspects. We discuss the key enablers\nand challenges and identify the key research questions for the development of\nthe Intelligent Edge services. As a main outcome of this white paper, we\nenvision a transition from Internet of Things to Intelligent Internet of\nIntelligent Things and provide a roadmap for development of 6G Intelligent\nEdge.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:02:08 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Peltonen", "Ella", ""], ["Bennis", "Mehdi", ""], ["Capobianco", "Michele", ""], ["Debbah", "Merouane", ""], ["Ding", "Aaron", ""], ["Gil-Casti\u00f1eira", "Felipe", ""], ["Jurmu", "Marko", ""], ["Karvonen", "Teemu", ""], ["Kelanti", "Markus", ""], ["Kliks", "Adrian", ""], ["Lepp\u00e4nen", "Teemu", ""], ["Lov\u00e9n", "Lauri", ""], ["Mikkonen", "Tommi", ""], ["Rao", "Ashwin", ""], ["Samarakoon", "Sumudu", ""], ["Sepp\u00e4nen", "Kari", ""], ["Sroka", "Pawe\u0142", ""], ["Tarkoma", "Sasu", ""], ["Yang", "Tingting", ""]]}, {"id": "2004.14870", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Lav R. Varshney, Min-Yen Kan", "title": "Mind Your Inflections! Improving NLP for Non-Standard Englishes with\n  Base-Inflection Encoding", "comments": "Published in the Proceedings of the 2020 Conference on Empirical\n  Methods in Natural Language Processing", "journal-ref": "2020.emnlp-main.455", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inflectional variation is a common feature of World Englishes such as\nColloquial Singapore English and African American Vernacular English. Although\ncomprehension by human readers is usually unimpaired by non-standard\ninflections, current NLP systems are not yet robust. We propose Base-Inflection\nEncoding (BITE), a method to tokenize English text by reducing inflected words\nto their base forms before reinjecting the grammatical information as special\nsymbols. Fine-tuning pretrained NLP models for downstream tasks using our\nencoding defends against inflectional adversaries while maintaining performance\non clean data. Models using BITE generalize better to dialects with\nnon-standard inflections without explicit training and translation models\nconverge faster when trained with BITE. Finally, we show that our encoding\nimproves the vocabulary efficiency of popular data-driven subword tokenizers.\nSince there has been no prior work on quantitatively evaluating vocabulary\nefficiency, we propose metrics to do so.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:15:40 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 18:54:40 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 05:20:28 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 06:16:31 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Varshney", "Lav R.", ""], ["Kan", "Min-Yen", ""]]}, {"id": "2004.14892", "submitter": "Pranab K. Muhuri Dr.", "authors": "Prashant K Gupta and Pranab K. Muhuri", "title": "An empirical study of computing with words approaches for multi-person\n  and single-person systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing with words (CWW) has emerged as a powerful tool for processing the\nlinguistic information, especially the one generated by human beings. Various\nCWW approaches have emerged since the inception of CWW, such as perceptual\ncomputing, extension principle based CWW approach, symbolic method based CWW\napproach, and 2-tuple based CWW approach. Furthermore, perceptual computing can\nuse interval approach (IA), enhanced interval approach (EIA), or Hao-Mendel\napproach (HMA), for data processing. There have been numerous works in which\nHMA was shown to be better at word modelling than EIA, and EIA better than IA.\nBut, a deeper study of these works reveals that HMA captures lesser fuzziness\nthan the EIA or IA. Thus, we feel that EIA is more suited for word modelling in\nmulti-person systems and HMA for single-person systems (as EIA is an\nimprovement over IA). Furthermore, another set of works, compared the\nperformances perceptual computing to the other above said CWW approaches. In\nall these works, perceptual computing was shown to be better than other CWW\napproaches. However, none of the works tried to investigate the reason behind\nthis observed better performance of perceptual computing. Also, no comparison\nhas been performed for scenarios where the inputs are differentially weighted.\nThus, the aim of this work is to empirically establish that EIA is suitable for\nmulti-person systems and HMA for single-person systems. Another dimension of\nthis work is also to empirically prove that perceptual computing gives better\nperformance than other CWW approaches based on extension principle, symbolic\nmethod and 2-tuple especially in scenarios where inputs are differentially\nweighted.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:45:38 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Gupta", "Prashant K", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2004.14933", "submitter": "Pranab K. Muhuri Dr.", "authors": "Prashant K Gupta and Pranab K. Muhuri", "title": "Perceptual reasoning based solution methodology for linguistic\n  optimization problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in real-life scenarios may often be modeled as an\noptimization problem. It requires the consideration of various attributes like\nhuman preferences and thinking, which constrain achieving the optimal value of\nthe problem objectives. The value of the objectives may be maximized or\nminimized, depending on the situation. Numerous times, the values of these\nproblem parameters are in linguistic form, as human beings naturally understand\nand express themselves using words. These problems are therefore termed as\nlinguistic optimization problems (LOPs), and are of two types, namely single\nobjective linguistic optimization problems (SOLOPs) and multi-objective\nlinguistic optimization problems (MOLOPs). In these LOPs, the value of the\nobjective function(s) may not be known at all points of the decision space, and\ntherefore, the objective function(s) as well as problem constraints are linked\nby the if-then rules. Tsukamoto inference method has been used to solve these\nLOPs; however, it suffers from drawbacks. As, the use of linguistic information\ninevitably calls for the utilization of computing with words (CWW), and\ntherefore, 2-tuple linguistic model based solution methodologies were proposed\nfor LOPs. However, we found that 2-tuple linguistic model based solution\nmethodologies represent the semantics of the linguistic information using a\ncombination of type-1 fuzzy sets and ordinal term sets. As, the semantics of\nlinguistic information are best modeled using the interval type-2 fuzzy sets,\nhence we propose solution methodologies for LOPs based on CWW approach of\nperceptual computing, in this paper. The perceptual computing based solution\nmethodologies use a novel design of CWW engine, called the perceptual reasoning\n(PR). PR in the current form is suitable for solving SOLOPs and, hence, we have\nalso extended it to the MOLOPs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:35:01 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Gupta", "Prashant K", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2004.14939", "submitter": "Stanislav Zhydkov", "authors": "Nicholas Mattei, Paolo Turrini, Stanislav Zhydkov", "title": "PeerNomination: Relaxing Exactness for Increased Accuracy in Peer\n  Selection", "comments": "7 pages, 5 figures, submitted to IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In peer selection agents must choose a subset of themselves for an award or a\nprize. As agents are self-interested, we want to design algorithms that are\nimpartial, so that an individual agent cannot affect their own chance of being\nselected. This problem has broad application in resource allocation and\nmechanism design and has received substantial attention in the artificial\nintelligence literature. Here, we present a novel algorithm for impartial peer\nselection, PeerNomination, and provide a theoretical analysis of its accuracy.\nOur algorithm possesses various desirable features. In particular, it does not\nrequire an explicit partitioning of the agents, as previous algorithms in the\nliterature. We show empirically that it achieves higher accuracy than the\nexiting algorithms over several metrics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:39:47 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Mattei", "Nicholas", ""], ["Turrini", "Paolo", ""], ["Zhydkov", "Stanislav", ""]]}, {"id": "2004.14955", "submitter": "Pranab K. Muhuri Dr.", "authors": "Prashant K Gupta and Pranab K. Muhuri", "title": "Parallel processor scheduling: formulation as multi-objective linguistic\n  optimization and solution using Perceptual Reasoning based methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of Industry 4.0, the focus is on the minimization of human element\nand maximizing the automation in almost all the industrial and manufacturing\nestablishments. These establishments contain numerous processing systems, which\ncan execute a number of tasks, in parallel with minimum number of human beings.\nThis parallel execution of tasks is done in accordance to a scheduling policy.\nHowever, the minimization of human element beyond a certain point is difficult.\nIn fact, the expertise and experience of a group of humans, called the experts,\nbecomes imminent to design a fruitful scheduling policy. The aim of the\nscheduling policy is to achieve the optimal value of an objective, like\nproduction time, cost, etc. In real-life situations, there are more often than\nnot, multiple objectives in any parallel processing scenario. Furthermore, the\nexperts generally provide their opinions, about various scheduling criteria\n(pertaining to the scheduling policies) in linguistic terms or words. Word\nsemantics are best modeled using fuzzy sets (FSs). Thus, all these factors have\nmotivated us to model the parallel processing scenario as a multi-objective\nlinguistic optimization problem (MOLOP) and use the novel perceptual reasoning\n(PR) based methodology for solving it. We have also compared the results of the\nPR based solution methodology with those obtained from the 2-tuple based\nsolution methodology. PR based solution methodology offers three main\nadvantages viz., it generates unique recommendations, here the linguistic\nrecommendations match a codebook word, and also the word model comes before the\nword. 2-tuple based solution methodology fails to give all these advantages.\nThus, we feel that our work is novel and will provide directions for the future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:04:49 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Gupta", "Prashant K", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2004.14969", "submitter": "Baoxu Shi", "authors": "Baoxu Shi, Shan Li, Jaewon Yang, Mustafa Emre Kazdagli, Qi He", "title": "Learning to Ask Screening Questions for Job Postings", "comments": "10 pages, to appear in SIGIR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At LinkedIn, we want to create economic opportunity for everyone in the\nglobal workforce. A critical aspect of this goal is matching jobs with\nqualified applicants. To improve hiring efficiency and reduce the need to\nmanually screening each applicant, we develop a new product where recruiters\ncan ask screening questions online so that they can filter qualified candidates\neasily. To add screening questions to all $20$M active jobs at LinkedIn, we\npropose a new task that aims to automatically generate screening questions for\na given job posting. To solve the task of generating screening questions, we\ndevelop a two-stage deep learning model called Job2Questions, where we apply a\ndeep learning model to detect intent from the text description, and then rank\nthe detected intents by their importance based on other contextual features.\nSince this is a new product with no historical data, we employ deep transfer\nlearning to train complex models with limited training data. We launched the\nscreening question product and our AI models to LinkedIn users and observed\nsignificant impact in the job marketplace. During our online A/B test, we\nobserved $+53.10\\%$ screening question suggestion acceptance rate, $+22.17\\%$\njob coverage, $+190\\%$ recruiter-applicant interaction, and $+11$ Net Promoter\nScore. In sum, the deployed Job2Questions model helps recruiters to find\nqualified applicants and job seekers to find jobs they are qualified for.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:18:17 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Shi", "Baoxu", ""], ["Li", "Shan", ""], ["Yang", "Jaewon", ""], ["Kazdagli", "Mustafa Emre", ""], ["He", "Qi", ""]]}, {"id": "2004.14973", "submitter": "Arjun Majumdar", "authors": "Arjun Majumdar, Ayush Shrivastava, Stefan Lee, Peter Anderson, Devi\n  Parikh, Dhruv Batra", "title": "Improving Vision-and-Language Navigation with Image-Text Pairs from the\n  Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a navigation instruction such as 'Walk down the stairs and stop at\nthe brown sofa' requires embodied AI agents to ground scene elements referenced\nvia language (e.g. 'stairs') to visual content in the environment (pixels\ncorresponding to 'stairs').\n  We ask the following question -- can we leverage abundant 'disembodied'\nweb-scraped vision-and-language corpora (e.g. Conceptual Captions) to learn\nvisual groundings (what do 'stairs' look like?) that improve performance on a\nrelatively data-starved embodied perception task (Vision-and-Language\nNavigation)? Specifically, we develop VLN-BERT, a visiolinguistic\ntransformer-based model for scoring the compatibility between an instruction\n('...stop at the brown sofa') and a sequence of panoramic RGB images captured\nby the agent. We demonstrate that pretraining VLN-BERT on image-text pairs from\nthe web before fine-tuning on embodied path-instruction data significantly\nimproves performance on VLN -- outperforming the prior state-of-the-art in the\nfully-observed setting by 4 absolute percentage points on success rate.\nAblations of our pretraining curriculum show each stage to be impactful -- with\ntheir combination resulting in further positive synergistic effects.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:22:40 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 17:16:50 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Majumdar", "Arjun", ""], ["Shrivastava", "Ayush", ""], ["Lee", "Stefan", ""], ["Anderson", "Peter", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "2004.14975", "submitter": "Alex Tamkin", "authors": "Alex Tamkin, Trisha Singh, Davide Giovanardi, Noah Goodman", "title": "Investigating Transferability in Pretrained Language Models", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does language model pretraining help transfer learning? We consider a\nsimple ablation technique for determining the impact of each pretrained layer\non transfer task performance. This method, partial reinitialization, involves\nreplacing different layers of a pretrained model with random weights, then\nfinetuning the entire model on the transfer task and observing the change in\nperformance. This technique reveals that in BERT, layers with high probing\nperformance on downstream GLUE tasks are neither necessary nor sufficient for\nhigh accuracy on those tasks. Furthermore, the benefit of using pretrained\nparameters for a layer varies dramatically with finetuning dataset size:\nparameters that provide tremendous performance improvement when data is\nplentiful may provide negligible benefits in data-scarce settings. These\nresults reveal the complexity of the transfer learning process, highlighting\nthe limitations of methods that operate on frozen models or single data\nsamples.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:23:19 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 00:56:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tamkin", "Alex", ""], ["Singh", "Trisha", ""], ["Giovanardi", "Davide", ""], ["Goodman", "Noah", ""]]}, {"id": "2004.15004", "submitter": "Zijie Wang", "authors": "Zijie J. Wang, Robert Turko, Omar Shaikh, Haekyu Park, Nilaksh Das,\n  Fred Hohman, Minsuk Kahng, Duen Horng Chau", "title": "CNN Explainer: Learning Convolutional Neural Networks with Interactive\n  Visualization", "comments": "11 pages, 14 figures, to be presented at IEEE VIS 2020. For a demo\n  video, see https://youtu.be/HnWIHWFbuUQ . For a live demo, visit\n  https://poloclub.github.io/cnn-explainer/", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030418", "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning's great success motivates many practitioners and students to\nlearn about this exciting technology. However, it is often challenging for\nbeginners to take their first step due to the complexity of understanding and\napplying deep learning. We present CNN Explainer, an interactive visualization\ntool designed for non-experts to learn and examine convolutional neural\nnetworks (CNNs), a foundational deep learning model architecture. Our tool\naddresses key challenges that novices face while learning about CNNs, which we\nidentify from interviews with instructors and a survey with past students. CNN\nExplainer tightly integrates a model overview that summarizes a CNN's\nstructure, and on-demand, dynamic visual explanation views that help users\nunderstand the underlying components of CNNs. Through smooth transitions across\nlevels of abstraction, our tool enables users to inspect the interplay between\nlow-level mathematical operations and high-level model structures. A\nqualitative user study shows that CNN Explainer helps users more easily\nunderstand the inner workings of CNNs, and is engaging and enjoyable to use. We\nalso derive design lessons from our study. Developed using modern web\ntechnologies, CNN Explainer runs locally in users' web browsers without the\nneed for installation or specialized hardware, broadening the public's\neducation access to modern deep learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:49:44 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 01:37:29 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 18:42:23 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Wang", "Zijie J.", ""], ["Turko", "Robert", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Das", "Nilaksh", ""], ["Hohman", "Fred", ""], ["Kahng", "Minsuk", ""], ["Chau", "Duen Horng", ""]]}]