[{"id": "1212.0059", "submitter": "Minakshi Sharma", "authors": "Minakshi Sharma", "title": "Artificial Neural Network Fuzzy Inference System (ANFIS) For Brain Tumor\n  Detection", "comments": "5 pages", "journal-ref": "IJFLS 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection and segmentation of Brain tumor is very important because it\nprovides anatomical information of normal and abnormal tissues which helps in\ntreatment planning and patient follow-up. There are number of techniques for\nimage segmentation. Proposed research work uses ANFIS (Artificial Neural\nNetwork Fuzzy Inference System) for image classification and then compares the\nresults with FCM (Fuzzy C means) and K-NN (K-nearest neighbor). ANFIS includes\nbenefits of both ANN and the fuzzy logic systems. A comprehensive feature set\nand fuzzy rules are selected to classify an abnormal image to the corresponding\ntumor type. Experimental results illustrate promising results in terms of\nclassification accuracy. A comparative analysis is performed with the FCM and\nK-NN to show the superior nature of ANFIS systems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 03:58:09 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Sharma", "Minakshi", ""]]}, {"id": "1212.0079", "submitter": "Guido Governatori", "authors": "Guido Governatori, Francesco Olivieri, Antonino Rotolo and Simone\n  Scannapieco", "title": "Computing Strong and Weak Permissions in Defeasible Logic", "comments": null, "journal-ref": "Journal of Philosophical Logic (2013) 42:799-829", "doi": "10.1007/s10992-013-9295-1", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an extension of Defeasible Logic to represent and\ncompute three concepts of defeasible permission. In particular, we discuss\ndifferent types of explicit permissive norms that work as exceptions to\nopposite obligations. Moreover, we show how strong permissions can be\nrepresented both with, and without introducing a new consequence relation for\ninferring conclusions from explicit permissive norms. Finally, we illustrate\nhow a preference operator applicable to contrary-to-duty obligations can be\ncombined with a new operator representing ordered sequences of strong\npermissions which derogate from prohibitions. The logical system is studied\nfrom a computational standpoint and is shown to have liner computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 07:36:46 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Governatori", "Guido", ""], ["Olivieri", "Francesco", ""], ["Rotolo", "Antonino", ""], ["Scannapieco", "Simone", ""]]}, {"id": "1212.0229", "submitter": "J. G. Wolff", "authors": "James Gerard Wolff", "title": "Simplification and integration in computing and cognition: the SP theory\n  and the multiple alignment concept", "comments": "32 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this article is to describe potential benefits and\napplications of the SP theory, a unique attempt to simplify and integrate ideas\nacross artificial intelligence, mainstream computing and human cognition, with\ninformation compression as a unifying theme. The theory, including a concept of\nmultiple alignment, combines conceptual simplicity with descriptive and\nexplanatory power in several areas including representation of knowledge,\nnatural language processing, pattern recognition, several kinds of reasoning,\nthe storage and retrieval of information, planning and problem solving,\nunsupervised learning, information compression, and human perception and\ncognition. In the SP machine -- an expression of the SP theory which is\ncurrently realised in the form of computer models -- there is potential for an\noverall simplification of computing systems, including software. As a theory\nwith a broad base of support, the SP theory promises useful insights in many\nareas and the integration of structures and functions, both within a given area\nand amongst different areas. There are potential benefits in natural language\nprocessing (with potential for the understanding and translation of natural\nlanguages), the need for a versatile intelligence in autonomous robots,\ncomputer vision, intelligent databases, maintaining multiple versions of\ndocuments or web pages, software engineering, criminal investigations, the\nmanagement of big data and gaining benefits from it, the semantic web, medical\ndiagnosis, the detection of computer viruses, the economical transmission of\ndata, and data fusion. Further development of these ideas would be facilitated\nby the creation of a high-parallel, web-based, open-source version of the SP\nmachine, with a good user interface. This would provide a means for researchers\nto explore what can be done with the system and to refine it.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 18:06:57 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Wolff", "James Gerard", ""]]}, {"id": "1212.0582", "submitter": "Eric Mjolsness", "authors": "Eric Mjolsness", "title": "Compositional Stochastic Modeling and Probabilistic Programming", "comments": "Extended Abstract for the Neural Information Processing Systems\n  (NIPS) Workshop on Probabilistic Programming, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is related to a compositional approach to\nstochastic modeling by switching from discrete to continuous time dynamics. In\ncontinuous time, an operator-algebra semantics is available in which processes\nproceeding in parallel (and possibly interacting) have summed time-evolution\noperators. From this foundation, algorithms for simulation, inference and model\nreduction may be systematically derived. The useful consequences are\npotentially far-reaching in computational science, machine learning and beyond.\nHybrid compositional stochastic modeling/probabilistic programming approaches\nmay also be possible.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 23:05:30 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Mjolsness", "Eric", ""]]}, {"id": "1212.0692", "submitter": "Roberto Amadini", "authors": "Roberto Amadini, Maurizio Gabbrielli, Jacopo Mauro", "title": "An Empirical Evaluation of Portfolios Approaches for solving CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in areas such as SAT solving and Integer Linear Programming\nhas shown that the performances of a single arbitrarily efficient solver can be\nsignificantly outperformed by a portfolio of possibly slower on-average\nsolvers. We report an empirical evaluation and comparison of portfolio\napproaches applied to Constraint Satisfaction Problems (CSPs). We compared\nmodels developed on top of off-the-shelf machine learning algorithms with\nrespect to approaches used in the SAT field and adapted for CSPs, considering\ndifferent portfolio sizes and using as evaluation metrics the number of solved\nproblems and the time taken to solve them. Results indicate that the best SAT\napproaches have top performances also in the CSP field and are slightly more\ncompetitive than simple models built on top of classification algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 12:00:54 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2014 02:25:04 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Amadini", "Roberto", ""], ["Gabbrielli", "Maurizio", ""], ["Mauro", "Jacopo", ""]]}, {"id": "1212.0750", "submitter": "Michael  Gr. Voskoglou Prof. Dr.", "authors": "Michael Gr. Voskoglou, Sheryl Buckley", "title": "Problem Solving and Computational Thinking in a Learning Environment", "comments": "19 pages, 2 figures", "journal-ref": "Egyptian Computer Science Journal, Vol. 36 (4), 28-46, 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational thinking is a new problem soling method named for its extensive\nuse of computer science techniques. It synthesizes critical thinking and\nexisting knowledge and applies them in solving complex technological problems.\nThe term was coined by J. Wing, but the relationship between computational and\ncritical thinking, the two modes of thiking in solving problems, has not been\nyet learly established. This paper aims at shedding some light into this\nrelationship. We also present two classroom experiments performed recently at\nthe Graduate Technological Educational Institute of Patras in Greece. The\nresults of these experiments give a strong indication that the use of computers\nas a tool for problem solving enchances the students' abilities in solving real\nworld problems involving mathematical modelling. This is also crossed by\nearlier findings of other researchers for the problem solving process in\ngeneral (not only for mathematical problems).\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 17:34:36 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Voskoglou", "Michael Gr.", ""], ["Buckley", "Sheryl", ""]]}, {"id": "1212.0768", "submitter": "Philippe Morignot", "authors": "Philippe Morignot (INRIA Rocquencourt), Fawzi Nashashibi (INRIA\n  Rocquencourt)", "title": "An ontology-based approach to relax traffic regulation for autonomous\n  vehicle assistance", "comments": null, "journal-ref": "12th IASTED International Conference on Artificial Intelligence\n  and Applications (AIA'13), Austria (2013)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic regulation must be respected by all vehicles, either human- or\ncomputer- driven. However, extreme traffic situations might exhibit practical\ncases in which a vehicle should safely and reasonably relax traffic regulation,\ne.g., in order not to be indefinitely blocked and to keep circulating. In this\npaper, we propose a high-level representation of an automated vehicle, other\nvehicles and their environment, which can assist drivers in taking such\n\"illegal\" but practical relaxation decisions. This high-level representation\n(an ontology) includes topological knowledge and inference rules, in order to\ncompute the next high-level motion an automated vehicle should take, as\nassistance to a driver. Results on practical cases are presented.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 15:34:10 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Morignot", "Philippe", "", "INRIA Rocquencourt"], ["Nashashibi", "Fawzi", "", "INRIA\n  Rocquencourt"]]}, {"id": "1212.0873", "submitter": "Peter Richtarik", "authors": "Peter Richt\\'arik and Martin Tak\\'a\\v{c}", "title": "Parallel Coordinate Descent Methods for Big Data Optimization", "comments": "43 pages, 8 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that randomized (block) coordinate descent methods can\nbe accelerated by parallelization when applied to the problem of minimizing the\nsum of a partially separable smooth convex function and a simple separable\nconvex function. The theoretical speedup, as compared to the serial method, and\nreferring to the number of iterations needed to approximately solve the problem\nwith high probability, is a simple expression depending on the number of\nparallel processors and a natural and easily computable measure of separability\nof the smooth component of the objective function. In the worst case, when no\ndegree of separability is present, there may be no speedup; in the best case,\nwhen the problem is separable, the speedup is equal to the number of\nprocessors. Our analysis also works in the mode when the number of blocks being\nupdated at each iteration is random, which allows for modeling situations with\nbusy or unreliable processors. We show that our algorithm is able to solve a\nLASSO problem involving a matrix with 20 billion nonzeros in 2 hours on a large\nmemory node with 24 cores.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 21:10:37 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2013 21:14:58 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1212.0967", "submitter": "Sameer Singh", "authors": "Sameer Singh and Thore Graepel", "title": "Compiling Relational Database Schemata into Probabilistic Graphical\n  Models", "comments": "NIPS 2012 Workshop on Probabilistic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Instead of requiring a domain expert to specify the probabilistic\ndependencies of the data, in this work we present an approach that uses the\nrelational DB schema to automatically construct a Bayesian graphical model for\na database. This resulting model contains customized distributions for columns,\nlatent variables that cluster the data, and factors that reflect and represent\nthe foreign key links. Experiments demonstrate the accuracy of the model and\nthe scalability of inference on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 08:52:33 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Singh", "Sameer", ""], ["Graepel", "Thore", ""]]}, {"id": "1212.1100", "submitter": "Jim Smith Dr", "authors": "J. E. Smith, P. Caleb-Solly, M. A. Tahir, D. Sannen, H. van-Brussel", "title": "Making Early Predictions of the Accuracy of Machine Learning\n  Applications", "comments": "35 pagers, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of machine learning systems is a widely studied research topic.\nEstablished techniques such as cross-validation predict the accuracy on unseen\ndata of the classifier produced by applying a given learning method to a given\ntraining data set. However, they do not predict whether incurring the cost of\nobtaining more data and undergoing further training will lead to higher\naccuracy. In this paper we investigate techniques for making such early\npredictions. We note that when a machine learning algorithm is presented with a\ntraining set the classifier produced, and hence its error, will depend on the\ncharacteristics of the algorithm, on training set's size, and also on its\nspecific composition. In particular we hypothesise that if a number of\nclassifiers are produced, and their observed error is decomposed into bias and\nvariance terms, then although these components may behave differently, their\nbehaviour may be predictable.\n  We test our hypothesis by building models that, given a measurement taken\nfrom the classifier created from a limited number of samples, predict the\nvalues that would be measured from the classifier produced when the full data\nset is presented. We create separate models for bias, variance and total error.\nOur models are built from the results of applying ten different machine\nlearning algorithms to a range of data sets, and tested with \"unseen\"\nalgorithms and datasets. We analyse the results for various numbers of initial\ntraining samples, and total dataset sizes. Results show that our predictions\nare very highly correlated with the values observed after undertaking the extra\ntraining. Finally we consider the more complex case where an ensemble of\nheterogeneous classifiers is trained, and show how we can accurately estimate\nan upper bound on the accuracy achievable after further training.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 17:07:39 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Smith", "J. E.", ""], ["Caleb-Solly", "P.", ""], ["Tahir", "M. A.", ""], ["Sannen", "D.", ""], ["van-Brussel", "H.", ""]]}, {"id": "1212.1108", "submitter": "Luis Ortiz", "authors": "Joshua Belanich and Luis E. Ortiz", "title": "On the Convergence Properties of Optimal AdaBoost", "comments": "66 pp, 7 figs, 1 table; Change - presentation; dominated and\n  effective weak-classifiers; experiments with dec. stumps in real-world data:\n  reduction in #effective and unique stumps, may explain \"resistance to\n  overfitting;\" log-growth #unique stumps with #rounds -> \"AdaBoost-cycles\n  Conjecture\" likely false in general; and new generalization bounds; submitted\n  to MLJ 4/10/15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AdaBoost is one of the most popular machine-learning algorithms. It is simple\nto implement and often found very effective by practitioners, while still being\nmathematically elegant and theoretically sound. AdaBoost's behavior in\npractice, and in particular the test-error behavior, has puzzled many eminent\nresearchers for over a decade: It seems to defy our general intuition in\nmachine learning regarding the fundamental trade-off between model complexity\nand generalization performance. In this paper, we establish the convergence of\n\"Optimal AdaBoost,\" a term coined by Rudin, Daubechies, and Schapire in 2004.\nWe prove the convergence, with the number of rounds, of the classifier itself,\nits generalization error, and its resulting margins for fixed data sets, under\ncertain reasonable conditions. More generally, we prove that the time/per-round\naverage of almost any function of the example weights converges. Our approach\nis to frame AdaBoost as a dynamical system, to provide sufficient conditions\nfor the existence of an invariant measure, and to employ tools from ergodic\ntheory. Unlike previous work, we do not assume AdaBoost cycles; actually, we\npresent empirical evidence against it on real-world datasets. Our main\ntheoretical results hold under a weaker condition. We show sufficient empirical\nevidence that Optimal AdaBoost always met the condition on every real-world\ndataset we tried. Our results formally ground future convergence-rate analyses,\nand may even provide opportunities for slight algorithmic modifications to\noptimize the generalization ability of AdaBoost classifiers, thus reducing a\npractitioner's burden of deciding how long to run the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 17:29:59 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2015 16:18:43 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Belanich", "Joshua", ""], ["Ortiz", "Luis E.", ""]]}, {"id": "1212.1143", "submitter": "Jake Bouvrie", "authors": "Jake Bouvrie and Mauro Maggioni", "title": "Multiscale Markov Decision Problems: Compression, Solution, and Transfer\n  Learning", "comments": "86 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in sequential decision making and stochastic control often have\nnatural multiscale structure: sub-tasks are assembled together to accomplish\ncomplex goals. Systematically inferring and leveraging hierarchical structure,\nparticularly beyond a single level of abstraction, has remained a longstanding\nchallenge. We describe a fast multiscale procedure for repeatedly compressing,\nor homogenizing, Markov decision processes (MDPs), wherein a hierarchy of\nsub-problems at different scales is automatically determined. Coarsened MDPs\nare themselves independent, deterministic MDPs, and may be solved using\nexisting algorithms. The multiscale representation delivered by this procedure\ndecouples sub-tasks from each other and can lead to substantial improvements in\nconvergence rates both locally within sub-problems and globally across\nsub-problems, yielding significant computational savings. A second fundamental\naspect of this work is that these multiscale decompositions yield new transfer\nopportunities across different problems, where solutions of sub-tasks at\ndifferent levels of the hierarchy may be amenable to transfer to new problems.\nLocalized transfer of policies and potential operators at arbitrary scales is\nemphasized. Finally, we demonstrate compression and transfer in a collection of\nillustrative domains, including examples involving discrete and continuous\nstatespaces.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 20:09:11 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Bouvrie", "Jake", ""], ["Maggioni", "Mauro", ""]]}, {"id": "1212.1313", "submitter": "Debajyoti Banerji", "authors": "Debajyoti Banerji, Ranjit Ray, Jhankar Basu and Indrajit Basak", "title": "Autonomous Navigation by Robust Scan Matching Technique", "comments": "7 pages, 9 figures", "journal-ref": "INTERNATIONAL JOURNAL OF INNOVATIVE TECHNOLOGY AND CREATIVE\n  ENGINEERING (ISSN:2045-8711), VOL.2 NO.10 OCTOBER 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For effective autonomous navigation,estimation of the pose of the robot is\nessential at every sampling time. For computing an accurate\nestimation,odometric error needs to be reduced with the help of data from\nexternal sensor. In this work, a technique has been developed for accurate pose\nestimation of mobile robot by using Laser Range data. The technique is robust\nto noisy data, which may contain considerable amount of outliers. A grey image\nis formed from laser range data and the key points from this image are\nextracted by Harris corner detector. The matching of the key points from\nconsecutive data sets have been done while outliers have been rejected by\nRANSAC method. Robot state is measured by the correspondence between the two\nsets of keypoints. Finally, optimal robot state is estimated by Extended Kalman\nFilter. The technique has been applied to an operational robot in the\nlaboratory environment to show the robustness of the technique in presence of\nnoisy sensor data. The performance of this new technique has been compared with\nthat of conventional ICP method. Through this method, effective and accurate\nnavigation has been achieved even in presence of substantial noise in the\nsensor data at the cost of a small amount of additional computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 12:53:26 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Banerji", "Debajyoti", ""], ["Ray", "Ranjit", ""], ["Basu", "Jhankar", ""], ["Basak", "Indrajit", ""]]}, {"id": "1212.1570", "submitter": "Mohammad Hadi Valipour", "authors": "Khashayar Niki Maleki, Mohammad Hadi Valipour, Sadegh Mokari,\n  Roohollah Yeylaghi Ashrafi, Mohammad Reza Jamali and Caro Lucas", "title": "A simple method for decision making in robocup soccer simulation 3d\n  environment", "comments": "8 pages, 10 figures; Revista Avances en Sistemas e Informatica, Vol.\n  5, No. 3, December 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper new hierarchical hybrid fuzzy-crisp methods for decision making\nand action selection of an agent in soccer simulation 3D environment are\npresented. First, the skills of an agent are introduced, implemented and\nclassified in two layers, the basicskills and the highlevel skills. In the\nsecond layer, a twophase mechanism for decision making is introduced. In phase\none, some useful methods are implemented which check the agent's situation for\nperforming required skills. In the next phase, the team str ategy, team for\nmation, agent's role and the agent's positioning system are introduced. A fuzzy\nlogical approach is employed to recognize the team strategy and further more to\ntell the player the best position to move. At last, we comprised our\nimplemented algor ithm in the Robocup Soccer Simulation 3D environment and\nresults showed th eefficiency of the introduced methodology.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 10:08:06 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Maleki", "Khashayar Niki", ""], ["Valipour", "Mohammad Hadi", ""], ["Mokari", "Sadegh", ""], ["Ashrafi", "Roohollah Yeylaghi", ""], ["Jamali", "Mohammad Reza", ""], ["Lucas", "Caro", ""]]}, {"id": "1212.1625", "submitter": "Daniel Faria", "authors": "Daniel Faria, Catia Pesquita, Emanuel Santos, Francisco M. Couto,\n  Cosmin Stroe, Isabel F. Cruz", "title": "Testing the AgreementMaker System in the Anatomy Task of OAEI 2012", "comments": "4 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AgreementMaker system was the leading system in the anatomy task of the\nOntology Alignment Evaluation Initiative (OAEI) competition in 2011. While\nAgreementMaker did not compete in OAEI 2012, here we report on its performance\nin the 2012 anatomy task, using the same configurations of AgreementMaker\nsubmitted to OAEI 2011. Additionally, we also test AgreementMaker using an\nupdated version of the UBERON ontology as a mediating ontology, and otherwise\nidentical configurations. AgreementMaker achieved an F-measure of 91.8% with\nthe 2011 configurations, and an F-measure of 92.2% with the updated UBERON\nontology. Thus, AgreementMaker would have been the second best system had it\ncompeted in the anatomy task of OAEI 2012, and only 0.1% below the F-measure of\nthe best system.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 14:59:36 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Faria", "Daniel", ""], ["Pesquita", "Catia", ""], ["Santos", "Emanuel", ""], ["Couto", "Francisco M.", ""], ["Stroe", "Cosmin", ""], ["Cruz", "Isabel F.", ""]]}, {"id": "1212.1735", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Towards Design of System Hierarchy (research survey)", "comments": "36 pages, 41 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses design/building frameworks for some kinds of tree-like\nand hierarchical structures of systems. The following approaches are examined:\n(1) expert-based procedures, (2) hierarchical clustering; (3) spanning problems\n(e.g., minimum spanning tree, minimum Steiner tree, maximum leaf spanning tree\nproblem; (4) design of organizational 'optimal' hierarchies; (5) design of\nmulti-layer (e.g., three-layer) k-connected network; (6) modification of\nhierarchies or networks: (i) modification of tree via condensing of neighbor\nnodes, (ii) hotlink assignment, (iii) transformation of tree into Steiner tree,\n(iv) restructuring as modification of an initial structural solution into a\nsolution that is the most close to a goal solution while taking into account a\ncost of the modification. Combinatorial optimization problems are considered as\nbasic ones (e.g., classification, knapsack problem, multiple choice problem,\nassignment problem). Some numerical examples illustrate the suggested problems\nand solving frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 22:53:03 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1212.1798", "submitter": "Nizar Rokbani", "authors": "Nizar Rokbani and Adel M Alimi", "title": "IK-PSO, PSO Inverse Kinematics Solver with Application to Biped Gait\n  Generation", "comments": "7 pages, 7 figures, \"Published with International Journal of Computer\n  Applications (IJCA)\"", "journal-ref": "International Journal of Computer applications (IJCA) 58 (22),\n  33-39 (2012)", "doi": "10.5120/9432-3844", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new approach allowing the generation of a simplified\nBiped gait. This approach combines a classical dynamic modeling with an inverse\nkinematics' solver based on particle swarm optimization, PSO. First, an\ninverted pendulum, IP, is used to obtain a simplified dynamic model of the\nrobot and to compute the target position of a key point in biped locomotion,\nthe Centre Of Mass, COM. The proposed algorithm, called IK-PSO, Inverse\nKinematics PSO, returns and inverse kinematics solution corresponding to that\nCOM respecting the joints constraints. In This paper the inertia weight PSO\nvariant is used to generate a possible solution according to the stability\nbased fitness function and a set of joints motions constraints. The method is\napplied with success to a leg motion generation. Since based on a\npre-calculated COM, that satisfied the biped stability, the proposal allowed\nalso to plan a walk with application on a small size biped robot.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 14:45:54 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Rokbani", "Nizar", ""], ["Alimi", "Adel M", ""]]}, {"id": "1212.1881", "submitter": "Georg Gottlob", "authors": "Georg Gottlob", "title": "Deciding Monotone Duality and Identifying Frequent Itemsets in Quadratic\n  Logspace", "comments": "Preprint of a paper which appeared in: Proceedings of the 32nd ACM\n  SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS 2013,\n  New York, NY,USA, June 22-27,2013, pp.25-36", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monotone duality problem is defined as follows: Given two monotone\nformulas f and g in iredundant DNF, decide whether f and g are dual. This\nproblem is the same as duality testing for hypergraphs, that is, checking\nwhether a hypergraph H consists of precisely all minimal transversals of a\nsimple hypergraph G. By exploiting a recent problem-decomposition method by\nBoros and Makino (ICALP 2009), we show that duality testing for hypergraphs,\nand thus for monotone DNFs, is feasible in DSPACE[log^2 n], i.e., in quadratic\nlogspace. As the monotone duality problem is equivalent to a number of problems\nin the areas of databases, data mining, and knowledge discovery, the results\npresented here yield new complexity results for those problems, too. For\nexample, it follows from our results that whenever for a Boolean-valued\nrelation (whose attributes represent items), a number of maximal frequent\nitemsets and a number of minimal infrequent itemsets are known, then it can be\ndecided in quadratic logspace whether there exist additional frequent or\ninfrequent itemsets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2012 11:36:09 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 18:16:02 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2013 16:55:31 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Gottlob", "Georg", ""]]}, {"id": "1212.1942", "submitter": "Sumedha", "authors": "Sumedha, Supriya Krishnamurthy and Sharmistha Sahoo", "title": "Balanced K-SAT and Biased random K-SAT on trees", "comments": "22 pages, 7 figures", "journal-ref": "Phys. Rev. E 87, 042130 (2013)", "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study and solve some variations of the random K-satisfiability problem -\nbalanced K-SAT and biased random K-SAT - on a regular tree, using techniques we\nhave developed earlier(arXiv:1110.2065). In both these problems, as well as\nvariations of these that we have looked at, we find that the SAT-UNSAT\ntransition obtained on the Bethe lattice matches the exact threshold for the\nsame model on a random graph for K=2 and is very close to the numerical value\nobtained for K=3. For higher K it deviates from the numerical estimates of the\nsolvability threshold on random graphs, but is very close to the dynamical\n1-RSB threshold as obtained from the first non-trivial fixed point of the\nsurvey propagation algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 00:20:45 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Sumedha", "", ""], ["Krishnamurthy", "Supriya", ""], ["Sahoo", "Sharmistha", ""]]}, {"id": "1212.2005", "submitter": "Roberto Posenato", "authors": "Luke Hunsberger and Roberto Posenato and Carlo Combi", "title": "The Dynamic Controllability of Conditional STNs with Uncertainty", "comments": null, "journal-ref": "PlanEX Workshop, ICAPS-2012, pages 21-29, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attempts to automate business processes and medical-treatment\nprocesses have uncovered the need for a formal framework that can accommodate\nnot only temporal constraints, but also observations and actions with\nuncontrollable durations. To meet this need, this paper defines a Conditional\nSimple Temporal Network with Uncertainty (CSTNU) that combines the simple\ntemporal constraints from a Simple Temporal Network (STN) with the conditional\nnodes from a Conditional Simple Temporal Problem (CSTP) and the contingent\nlinks from a Simple Temporal Network with Uncertainty (STNU). A notion of\ndynamic controllability for a CSTNU is defined that generalizes the dynamic\nconsistency of a CTP and the dynamic controllability of an STNU. The paper also\npresents some sound constraint-propagation rules for dynamic controllability\nthat are expected to form the backbone of a dynamic-controllability-checking\nalgorithm for CSTNUs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 09:37:31 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Hunsberger", "Luke", ""], ["Posenato", "Roberto", ""], ["Combi", "Carlo", ""]]}, {"id": "1212.2056", "submitter": "Giacoma Monreale", "authors": "Giacoma Valentina Monreale, Ugo Montanari and Nicklas Hoch", "title": "Soft Constraint Logic Programming for Electric Vehicle Travel\n  Optimization", "comments": "17 pages; 26th Workshop on Logic Programming - 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft Constraint Logic Programming is a natural and flexible declarative\nprogramming formalism, which allows to model and solve real-life problems\ninvolving constraints of different types.\n  In this paper, after providing a slightly more general and elegant\npresentation of the framework, we show how we can apply it to the e-mobility\nproblem of coordinating electric vehicles in order to overcome both energetic\nand temporal constraints and so to reduce their running cost. In particular, we\nfocus on the journey optimization sub-problem, considering sequences of trips\nfrom a user's appointment to another one. Solutions provide the best\nalternatives in terms of time and energy consumption, including route sequences\nand possible charging events.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 13:30:23 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Monreale", "Giacoma Valentina", ""], ["Montanari", "Ugo", ""], ["Hoch", "Nicklas", ""]]}, {"id": "1212.2129", "submitter": "Bin Li", "authors": "Bin Li and Steven C. H. Hoi", "title": "Online Portfolio Selection: A Survey", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.CE q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online portfolio selection is a fundamental problem in computational finance,\nwhich has been extensively studied across several research communities,\nincluding finance, statistics, artificial intelligence, machine learning, and\ndata mining, etc. This article aims to provide a comprehensive survey and a\nstructural understanding of published online portfolio selection techniques.\nFrom an online machine learning perspective, we first formulate online\nportfolio selection as a sequential decision problem, and then survey a variety\nof state-of-the-art approaches, which are grouped into several major\ncategories, including benchmarks, \"Follow-the-Winner\" approaches,\n\"Follow-the-Loser\" approaches, \"Pattern-Matching\" based approaches, and\n\"Meta-Learning Algorithms\". In addition to the problem formulation and related\nalgorithms, we also discuss the relationship of these algorithms with the\nCapital Growth theory in order to better understand the similarities and\ndifferences of their underlying trading ideas. This article aims to provide a\ntimely and comprehensive survey for both machine learning and data mining\nresearchers in academia and quantitative portfolio managers in the financial\nindustry to help them understand the state-of-the-art and facilitate their\nresearch and practical applications. We also discuss some open issues and\nevaluate some emerging new trends for future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 16:49:54 GMT"}, {"version": "v2", "created": "Sun, 19 May 2013 12:08:21 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Li", "Bin", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1212.2262", "submitter": "Jin Wang", "authors": "Jin Wang, Ping Liu, Mary F.H.She, Saeid Nahavandi and and Abbas\n  Kouzani", "title": "Bag-of-Words Representation for Biomedical Time Series Classification", "comments": "10 pages, 7 figures. Submitted to IEEE Transaction on Biomedical\n  Engineering", "journal-ref": null, "doi": "10.1016/j.bspc.2013.06.004", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Automatic analysis of biomedical time series such as electroencephalogram\n(EEG) and electrocardiographic (ECG) signals has attracted great interest in\nthe community of biomedical engineering due to its important applications in\nmedicine. In this work, a simple yet effective bag-of-words representation that\nis able to capture both local and global structure similarity information is\nproposed for biomedical time series representation. In particular, similar to\nthe bag-of-words model used in text document domain, the proposed method treats\na time series as a text document and extracts local segments from the time\nseries as words. The biomedical time series is then represented as a histogram\nof codewords, each entry of which is the count of a codeword appeared in the\ntime series. Although the temporal order of the local segments is ignored, the\nbag-of-words representation is able to capture high-level structural\ninformation because both local and global structural information are well\nutilized. The performance of the bag-of-words model is validated on three\ndatasets extracted from real EEG and ECG signals. The experimental results\ndemonstrate that the proposed method is not only insensitive to parameters of\nthe bag-of-words model such as local segment length and codebook size, but also\nrobust to noise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 00:49:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Wang", "Jin", ""], ["Liu", "Ping", ""], ["She", "Mary F. H.", ""], ["Nahavandi", "Saeid", ""], ["Kouzani", "and Abbas", ""]]}, {"id": "1212.2314", "submitter": "Francesco Scarcello", "authors": "Gianluigi Greco and Francesco Scarcello", "title": "Tree Projections and Structural Decomposition Methods: Minimality and\n  Game-Theoretic Characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree projections provide a mathematical framework that encompasses all the\nvarious (purely) structural decomposition methods that have been proposed in\nthe literature to single out classes of nearly-acyclic (hyper)graphs, such as\nthe tree decomposition method, which is the most powerful decomposition method\non graphs, and the (generalized) hypertree decomposition method, which is its\nnatural counterpart on arbitrary hypergraphs. The paper analyzes this\nframework, by focusing in particular on \"minimal\" tree projections, that is, on\ntree projections without useless redundancies. First, it is shown that minimal\ntree projections enjoy a number of properties that are usually required for\nnormal form decompositions in various structural decomposition methods. In\nparticular, they enjoy the same kind of connection properties as (minimal) tree\ndecompositions of graphs, with the result being tight in the light of the\nnegative answer that is provided to the open question about whether they enjoy\na slightly stronger notion of connection property, defined to speed-up the\ncomputation of hypertree decompositions. Second, it is shown that tree\nprojections admit a natural game-theoretic characterization in terms of the\nCaptain and Robber game. In this game, as for the Robber and Cops game\ncharacterizing tree decompositions, the existence of winning strategies implies\nthe existence of monotone ones. As a special case, the Captain and Robber game\ncan be used to characterize the generalized hypertree decomposition method,\nwhere such a game-theoretic characterization was missing and asked for. Besides\ntheir theoretical interest, these results have immediate algorithmic\napplications both for the general setting and for structural decomposition\nmethods that can be recast in terms of tree projections.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 07:02:31 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Greco", "Gianluigi", ""], ["Scarcello", "Francesco", ""]]}, {"id": "1212.2444", "submitter": "Richard Booth", "authors": "Richard Booth, Eva Richter", "title": "On revising fuzzy belief bases", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-81-88", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look at the problem of revising fuzzy belief bases, i.e., belief base\nrevision in which both formulas in the base as well as revision-input formulas\ncan come attached with varying truth-degrees. Working within a very general\nframework for fuzzy logic which is able to capture a variety of types of\ninference under uncertainty, such as truth-functional fuzzy logics and certain\ntypes of probabilistic inference, we show how the idea of rational change from\n'crisp' base revision, as embodied by the idea of partial meet revision, can be\nfaithfully extended to revising fuzzy belief bases. We present and axiomatise\nan operation of partial meet fuzzy revision and illustrate how the operation\nworks in several important special instances of the framework.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:03 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Booth", "Richard", ""], ["Richter", "Eva", ""]]}, {"id": "1212.2445", "submitter": "Janneke H. Bolt", "authors": "Janneke H. Bolt, Silja Renooij, Linda C. van der Gaag", "title": "Upgrading Ambiguous Signs in QPNs", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-73-80", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WA qualitative probabilistic network models the probabilistic relationships\nbetween its variables by means of signs. Non-monotonic influences have\nassociated an ambiguous sign. These ambiguous signs typically lead to\nuninformative results upon inference. A non-monotonic influence can, however,\nbe associated with a, more informative, sign that indicates its effect in the\ncurrent state of the network. To capture this effect, we introduce the concept\nof situational sign. Furthermore, if the network converts to a state in which\nall variables that provoke the non-monotonicity have been observed, a\nnon-monotonic influence reduces to a monotonic influence. We study the\npersistence and propagation of situational signs upon inference and give a\nmethod to establish the sign of a reduced influence.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:58 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Bolt", "Janneke H.", ""], ["Renooij", "Silja", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1212.2446", "submitter": "Andrea Bobbio", "authors": "Andrea Bobbio, Stefania Montani, Luigi Portinale", "title": "Parametric Dependability Analysis through Probabilistic Horn Abduction", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-65-72", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependability modeling and evaluation is aimed at investigating that a system\nperforms its function correctly in time. A usual way to achieve a high\nreliability, is to design redundant systems that contain several replicas of\nthe same subsystem or component. State space methods for dependability analysis\nmay suffer of the state space explosion problem in such a kind of situation.\nCombinatorial models, on the other hand, require the simplified assumption of\nstatistical independence; however, in case of redundant systems, this does not\nguarantee a reduced number of modeled elements. In order to provide a more\ncompact system representation, parametric system modeling has been investigated\nin the literature, in such a way that a set of replicas of a given subsystem is\nparameterized so that only one representative instance is explicitly included.\nWhile modeling aspects can be suitably addressed by these approaches,\nanalytical tools working on parametric characterizations are often more\ndifficult to be defined and the standard approach is to 'unfold' the parametric\nmodel, in order to exploit standard analysis algorithms working at the unfolded\n'ground' level. Moreover, parameterized combinatorial methods still require the\nstatistical independence assumption. In the present paper we consider the\nformalism of Parametric Fault Tree (PFT) and we show how it can be related to\nProbabilistic Horn Abduction (PHA). Since PHA is a framework where both\nmodeling and analysis can be performed in a restricted first-order language, we\naim at showing that converting a PFT into a PHA knowledge base will allow an\napproach to dependability analysis directly exploiting parametric\nrepresentation. We will show that classical qualitative and quantitative\ndependability measures can be characterized within PHA. Furthermore, additional\nmodeling aspects (such as noisy gates and local dependencies) as well as\nadditional reliability measures (such as posterior probability analysis) can be\nnaturally addressed by this conversion. A simple example of a multi-processor\nsystem with several replicated units is used to illustrate the approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:55 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Bobbio", "Andrea", ""], ["Montani", "Stefania", ""], ["Portinale", "Luigi", ""]]}, {"id": "1212.2448", "submitter": "Jeff A. Bilmes", "authors": "Jeff A. Bilmes, Chris Bartels", "title": "On Triangulating Dynamic Graphical Models", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-47-56", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces new methodology to triangulate dynamic Bayesian\nnetworks (DBNs) and dynamic graphical models (DGMs). While most methods to\ntriangulate such networks use some form of constrained elimination scheme based\non properties of the underlying directed graph, we find it useful to view\ntriangulation and elimination using properties only of the resulting undirected\ngraph, obtained after the moralization step. We first briefly introduce the\nGraphical model toolkit (GMTK) and its notion of dynamic graphical models, one\nthat slightly extends the standard notion of a DBN. We next introduce the\n'boundary algorithm', a method to find the best boundary between partitions in\na dynamic model. We find that using this algorithm, the notions of forward- and\nbackward-interface become moot - namely, the size and fill-in of the best\nforward- and backward- interface are identical. Moreover, we observe that\nfinding a good partition boundary allows for constrained elimination orders\n(and therefore graph triangulations) that are not possible using standard\nslice-by-slice constrained eliminations. More interestingly, with certain\nboundaries it is possible to obtain constrained elimination schemes that lie\noutside the space of possible triangulations using only unconstrained\nelimination. Lastly, we report triangulation results on invented graphs,\nstandard DBNs from the literature, novel DBNs used in speech recognition\nresearch systems, and also random graphs. Using a number of different\ntriangulation quality measures (max clique size, state-space, etc.), we find\nthat with our boundary algorithm the triangulation quality can dramatically\nimprove.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:47 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Bilmes", "Jeff A.", ""], ["Bartels", "Chris", ""]]}, {"id": "1212.2449", "submitter": "Bozhena Bidyuk", "authors": "Bozhena Bidyuk, Rina Dechter", "title": "An Empirical Study of w-Cutset Sampling for Bayesian Networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-37-46", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies empirically the time-space trade-off between sampling and\ninference in a sl cutset sampling algorithm. The algorithm samples over a\nsubset of nodes in a Bayesian network and applies exact inference over the\nrest. Consequently, while the size of the sampling space decreases, requiring\nless samples for convergence, the time for generating each single sample\nincreases. The w-cutset sampling selects a sampling set such that the\ninduced-width of the network when the sampling set is observed is bounded by w,\nthus requiring inference whose complexity is exponential in w. In this paper,\nwe investigate performance of w-cutset sampling over a range of w values and\nmeasure the accuracy of w-cutset sampling as a function of w. Our experiments\ndemonstrate that the cutset sampling idea is quite powerful showing that an\noptimal balance between inference and sampling benefits substantially from\nrestricting the cutset size, even at the cost of more complex inference.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:43 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Bidyuk", "Bozhena", ""], ["Dechter", "Rina", ""]]}, {"id": "1212.2450", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Sylvain Lagrue, Odile Papini", "title": "A possibilistic handling of partially ordered information", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-29-36", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a standard possibilistic logic, prioritized information are encoded by\nmeans of weighted knowledge base. This paper proposes an extension of\npossibilistic logic for dealing with partially ordered information. We Show\nthat all basic notions of standard possibilitic logic (sumbsumption, syntactic\nand semantic inference, etc.) have natural couterparts when dealing with\npartially ordered information. We also propose an algorithm which computes\npossibilistic conclusions of a partial knowledge base of a partially ordered\nknowlege base.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:38 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Benferhat", "Salem", ""], ["Lagrue", "Sylvain", ""], ["Papini", "Odile", ""]]}, {"id": "1212.2452", "submitter": "Fahiem Bacchus", "authors": "Fahiem Bacchus, Shannon Dalmao, Toniann Pitassi", "title": "Value Elimination: Bayesian Inference via Backtracking Search", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-20-28", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backtracking search is a powerful algorithmic paradigm that can be used to\nsolve many problems. It is in a certain sense the dual of variable elimination;\nbut on many problems, e.g., SAT, it is vastly superior to variable elimination\nin practice. Motivated by this we investigate the application of backtracking\nsearch to the problem of Bayesian inference (Bayes). We show that natural\ngeneralizations of known techniques allow backtracking search to achieve\nperformance guarantees similar to standard algorithms for Bayes, and that there\nexist problems on which backtracking can in fact do much better. We also\ndemonstrate that these ideas can be applied to implement a Bayesian inference\nengine whose performance is competitive with standard algorithms. Since\nbacktracking search can very naturally take advantage of context specific\nstructure, the potential exists for performance superior to standard algorithms\non many problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:31 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Bacchus", "Fahiem", ""], ["Dalmao", "Shannon", ""], ["Pitassi", "Toniann", ""]]}, {"id": "1212.2455", "submitter": "David Allen", "authors": "David Allen, Adnan Darwiche", "title": "New Advances in Inference by Recursive Conditioning", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-2-10", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive Conditioning (RC) was introduced recently as the first any-space\nalgorithm for inference in Bayesian networks which can trade time for space by\nvarying the size of its cache at the increment needed to store a floating point\nnumber. Under full caching, RC has an asymptotic time and space complexity\nwhich is comparable to mainstream algorithms based on variable elimination and\nclustering (exponential in the network treewidth and linear in its size). We\nshow two main results about RC in this paper. First, we show that its actual\nspace requirements under full caching are much more modest than those needed by\nmainstream methods and study the implications of this finding. Second, we show\nthat RC can effectively deal with determinism in Bayesian networks by employing\nstandard logical techniques, such as unit resolution, allowing a significant\nreduction in its time requirements in certain cases. We illustrate our results\nusing a number of benchmark networks, including the very challenging ones that\narise in genetic linkage analysis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:22 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Allen", "David", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1212.2456", "submitter": "Julia M Flores", "authors": "Julia M. Flores, Jose A. Gamez, Kristian G. Olesen", "title": "Incremental Compilation of Bayesian networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-233-240", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most methods of exact probability propagation in Bayesian networks do not\ncarry out the inference directly over the network, but over a secondary\nstructure known as a junction tree or a join tree (JT). The process of\nobtaining a JT is usually termed {sl compilation}. As compilation is usually\nviewed as a whole process; each time the network is modified, a new compilation\nprocess has to be carried out. The possibility of reusing an already existing\nJT, in order to obtain the new one regarding only the modifications in the\nnetwork has received only little attention in the literature. In this paper we\npresent a method for incremental compilation of a Bayesian network, following\nthe classical scheme in which triangulation plays the key role. In order to\nperform incremental compilation we propose to recompile only those parts of the\nJT which can have been affected by the networks modifications. To do so, we\nexploit the technique OF maximal prime subgraph decomposition in determining\nthe minimal subgraph(s) that have to be recompiled, and thereby the minimal\nsubtree(s) of the JT that should be replaced by new subtree(s).We focus on\nstructural modifications : addition and deletion of links and variables.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:20 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Flores", "Julia M.", ""], ["Gamez", "Jose A.", ""], ["Olesen", "Kristian G.", ""]]}, {"id": "1212.2457", "submitter": "Alberto Finzi", "authors": "Alberto Finzi, Thomas Lukasiewicz", "title": "Structure-Based Causes and Explanations in the Independent Choice Logic", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-225-232", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is directed towards combining Pearl's structural-model approach to\ncausal reasoning with high-level formalisms for reasoning about actions. More\nprecisely, we present a combination of Pearl's structural-model approach with\nPoole's independent choice logic. We show how probabilistic theories in the\nindependent choice logic can be mapped to probabilistic causal models. This\nmapping provides the independent choice logic with appealing concepts of\ncausality and explanation from the structural-model approach. We illustrate\nthis along Halpern and Pearl's sophisticated notions of actual cause,\nexplanation, and partial explanation. This mapping also adds first-order\nmodeling capabilities and explicit actions to the structural-model approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:16 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Finzi", "Alberto", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1212.2458", "submitter": "Jose Carlos Ferreira da Rocha", "authors": "Jose Carlos Ferreira da Rocha, Fabio Gagliardi Cozman, Cassio Polpo de\n  Campos", "title": "Inference in Polytrees with Sets of Probabilities", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-217-224", "categories": "cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferences in directed acyclic graphs associated with probability sets and\nprobability intervals are NP-hard, even for polytrees. In this paper we focus\non such inferences, and propose: 1) a substantial improvement on Tessems A / R\nalgorithm FOR polytrees WITH probability intervals; 2) a new algorithm FOR\ndirection - based local search(IN sets OF probability) that improves ON\nexisting methods; 3) a collection OF branch - AND - bound algorithms that\ncombine the previous techniques.The first two techniques lead TO approximate\nsolutions, WHILE branch - AND - bound procedures can produce either exact OR\napproximate solutions.We report ON dramatic improvements ON existing techniques\nFOR inference WITH probability sets AND intervals, IN SOME cases reducing the\ncomputational effort BY many orders OF magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:11 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["da Rocha", "Jose Carlos Ferreira", ""], ["Cozman", "Fabio Gagliardi", ""], ["de Campos", "Cassio Polpo", ""]]}, {"id": "1212.2459", "submitter": "Zhengzhu Feng", "authors": "Zhengzhu Feng, Eric A. Hansen, Shlomo Zilberstein", "title": "Symbolic Generalization for On-line Planning", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-209-216", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic representations have been used successfully in off-line planning\nalgorithms for Markov decision processes. We show that they can also improve\nthe performance of on-line planners. In addition to reducing computation time,\nsymbolic generalization can reduce the amount of costly real-world interactions\nrequired for convergence. We introduce Symbolic Real-Time Dynamic Programming\n(or sRTDP), an extension of RTDP. After each step of on-line interaction with\nan environment, sRTDP uses symbolic model-checking techniques to generalizes\nits experience by updating a group of states rather than a single state. We\nexamine two heuristic approaches to dynamic grouping of states and show that\nthey accelerate the planning process significantly in terms of both CPU time\nand the number of steps of interaction with the environment.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:06 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Feng", "Zhengzhu", ""], ["Hansen", "Eric A.", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1212.2461", "submitter": "Thomas Eiter", "authors": "Thomas Eiter, Thomas Lukasiewicz", "title": "Probabilistic Reasoning about Actions in Nonmonotonic Causal Theories", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-192-199", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the language {m P}{cal C}+ for probabilistic reasoning about\nactions, which is a generalization of the action language {cal C}+ that allows\nto deal with probabilistic as well as nondeterministic effects of actions. We\ndefine a formal semantics of {m P}{cal C}+ in terms of probabilistic\ntransitions between sets of states. Using a concept of a history and its belief\nstate, we then show how several important problems in reasoning about actions\ncan be concisely formulated in our formalism.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:57 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Eiter", "Thomas", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1212.2463", "submitter": "Rina Dechter", "authors": "Rina Dechter, Robert Mateescu", "title": "A Simple Insight into Iterative Belief Propagation's Success", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-175-183", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Non - ergodic belief networks the posterior belief OF many queries given\nevidence may become zero.The paper shows that WHEN belief propagation IS\napplied iteratively OVER arbitrary networks(the so called, iterative OR loopy\nbelief propagation(IBP)) it IS identical TO an arc - consistency algorithm\nrelative TO zero - belief queries(namely assessing zero posterior\nprobabilities). This implies that zero - belief conclusions derived BY belief\npropagation converge AND are sound.More importantly it suggests that the\ninference power OF IBP IS AS strong AND AS weak, AS that OF arc -\nconsistency.This allows the synthesis OF belief networks FOR which belief\npropagation IS useless ON one hand, AND focuses the investigation OF classes OF\nbelief network FOR which belief propagation may be zero - complete.Finally, ALL\nthe above conclusions apply also TO Generalized belief propagation algorithms\nthat extend loopy belief propagation AND allow a crisper understanding OF their\npower.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:48 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Dechter", "Rina", ""], ["Mateescu", "Robert", ""]]}, {"id": "1212.2464", "submitter": "Denver Dash", "authors": "Denver Dash, Marek J. Druzdzel", "title": "A Robust Independence Test for Constraint-Based Learning of Causal\n  Structure", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-167-174", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based (CB) learning is a formalism for learning a causal network\nwith a database D by performing a series of conditional-independence tests to\ninfer structural information. This paper considers a new test of independence\nthat combines ideas from Bayesian learning, Bayesian network inference, and\nclassical hypothesis testing to produce a more reliable and robust test. The\nnew test can be calculated in the same asymptotic time and space required for\nthe standard tests such as the chi-squared test, but it allows the\nspecification of a prior distribution over parameters and can be used when the\ndatabase is incomplete. We prove that the test is correct, and we demonstrate\nempirically that, when used with a CB causal discovery algorithm with\nnoninformative priors, it recovers structural features more reliably and it\nproduces networks with smaller KL-Divergence, especially as the number of nodes\nincreases or the number of records decreases. Another benefit is the dramatic\nreduction in the probability that a CB algorithm will stall during the search,\nproviding a remedy for an annoying problem plaguing CB learning when the\ndatabase is small.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:44 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Dash", "Denver", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1212.2465", "submitter": "Christopher Crick", "authors": "Christopher Crick, Avi Pfeffer", "title": "Loopy Belief Propagation as a Basis for Communication in Sensor Networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-159-166", "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor networks are an exciting new kind of computer system. Consisting of a\nlarge number of tiny, cheap computational devices physically distributed in an\nenvironment, they gather and process data about the environment in real time.\nOne of the central questions in sensor networks is what to do with the data,\ni.e., how to reason with it and how to communicate it. This paper argues that\nthe lessons of the UAI community, in particular that one should produce and\ncommunicate beliefs rather than raw sensor values, are highly relevant to\nsensor networks. We contend that loopy belief propagation is particularly well\nsuited to communicating beliefs in sensor networks, due to its compact\nimplementation and distributed nature. We investigate the ability of loopy\nbelief propagation to function under the stressful conditions likely to prevail\nin sensor networks. Our experiments show that it performs well and degrades\ngracefully. It converges to appropriate beliefs even in highly asynchronous\nsettings where some nodes communicate far less frequently than others; it\ncontinues to function if some nodes fail to participate in the propagation\nprocess; and it can track changes in the environment that occur while beliefs\nare propagating. As a result, we believe that sensor networks present an\nimportant application opportunity for UAI.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:40 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Crick", "Christopher", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1212.2468", "submitter": "David Maxwell Chickering", "authors": "David Maxwell Chickering, Christopher Meek, David Heckerman", "title": "Large-Sample Learning of Bayesian Networks is NP-Hard", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-124-133", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide new complexity results for algorithms that learn\ndiscrete-variable Bayesian networks from data. Our results apply whenever the\nlearning algorithm uses a scoring criterion that favors the simplest model able\nto represent the generative distribution exactly. Our results therefore hold\nwhenever the learning algorithm uses a consistent scoring criterion and is\napplied to a sufficiently large dataset. We show that identifying high-scoring\nstructures is hard, even when we are given an independence oracle, an inference\noracle, and/or an information oracle. Our negative results also apply to the\nlearning of discrete-variable Bayesian networks in which each node has at most\nk parents, for all k > 3.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:28 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""], ["Heckerman", "David", ""]]}, {"id": "1212.2469", "submitter": "Sanjay Chaudhari", "authors": "Sanjay Chaudhari, Thomas S. Richardson", "title": "Using the structure of d-connecting paths as a qualitative measure of\n  the strength of dependence", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-116-123", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pearls concept OF a d - connecting path IS one OF the foundations OF the\nmodern theory OF graphical models : the absence OF a d - connecting path IN a\nDAG indicates that conditional independence will hold IN ANY distribution\nfactorising according TO that graph. IN this paper we show that IN singly -\nconnected Gaussian DAGs it IS possible TO USE the form OF a d - connection TO\nobtain qualitative information about the strength OF conditional\ndependence.More precisely, the squared partial correlations BETWEEN two given\nvariables, conditioned ON different subsets may be partially ordered BY\nexamining the relationship BETWEEN the d - connecting path AND the SET OF\nvariables conditioned upon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:23 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Chaudhari", "Sanjay", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1212.2470", "submitter": "Hei Chan", "authors": "Hei Chan, Adnan Darwiche", "title": "Reasoning about Bayesian Network Classifiers", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-107-115", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian network classifiers are used in many fields, and one common class of\nclassifiers are naive Bayes classifiers. In this paper, we introduce an\napproach for reasoning about Bayesian network classifiers in which we\nexplicitly convert them into Ordered Decision Diagrams (ODDs), which are then\nused to reason about the properties of these classifiers. Specifically, we\npresent an algorithm for converting any naive Bayes classifier into an ODD, and\nwe show theoretically and experimentally that this algorithm can give us an ODD\nthat is tractable in size even given an intractable number of instances. Since\nODDs are tractable representations of classifiers, our algorithm allows us to\nefficiently test the equivalence of two naive Bayes classifiers and\ncharacterize discrepancies between them. We also show a number of additional\nresults including a count of distinct classifiers that can be induced by\nchanging some CPT in a naive Bayes classifier, and the range of allowable\nchanges to a CPT which keeps the current classifier unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:17 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Chan", "Hei", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1212.2471", "submitter": "Fletcher Lu", "authors": "Fletcher Lu, Dale Schuurmans", "title": "Monte Carlo Matrix Inversion Policy Evaluation", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-386-393", "categories": "cs.LG cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1950, Forsythe and Leibler (1950) introduced a statistical technique for\nfinding the inverse of a matrix by characterizing the elements of the matrix\ninverse as expected values of a sequence of random walks. Barto and Duff (1994)\nsubsequently showed relations between this technique and standard dynamic\nprogramming and temporal differencing methods. The advantage of the Monte Carlo\nmatrix inversion (MCMI) approach is that it scales better with respect to\nstate-space size than alternative techniques. In this paper, we introduce an\nalgorithm for performing reinforcement learning policy evaluation using MCMI.\nWe demonstrate that MCMI improves on runtime over a maximum likelihood\nmodel-based policy evaluation approach and on both runtime and accuracy over\nthe temporal differencing (TD) policy evaluation approach. We further improve\non MCMI policy evaluation by adding an importance sampling technique to our\nalgorithm to reduce the variance of our estimator. Lastly, we illustrate\ntechniques for scaling up MCMI to large state spaces in order to perform policy\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:41 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Lu", "Fletcher", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1212.2473", "submitter": "Liping Liu", "authors": "Liping Liu, Catherine Shenoy, Prakash P. Shenoy", "title": "A Linear Belief Function Approach to Portfolio Evaluation", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-370-377", "categories": "cs.AI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By elaborating on the notion of linear belief functions (Dempster 1990; Liu\n1996), we propose an elementary approach to knowledge representation for expert\nsystems using linear belief functions. We show how to use basic matrices to\nrepresent market information and financial knowledge, including complete\nignorance, statistical observations, subjective speculations, distributional\nassumptions, linear relations, and empirical asset pricing models. We then\nappeal to Dempster's rule of combination to integrate the knowledge for\nassessing an overall belief of portfolio performance, and updating the belief\nby incorporating additional information. We use an example of three gold stocks\nto illustrate the approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:32 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Liu", "Liping", ""], ["Shenoy", "Catherine", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1212.2476", "submitter": "David Ephraim Larkin", "authors": "David Ephraim Larkin", "title": "Approximate Decomposition: A Method for Bounding and Estimating\n  Probabilistic and Deterministic Queries", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-346-353", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a method for approximating the solution to\ninference and optimization tasks in uncertain and deterministic reasoning. Such\ntasks are in general intractable for exact algorithms because of the large\nnumber of dependency relationships in their structure. Our method effectively\nmaps such a dense problem to a sparser one which is in some sense \"closest\".\nExact methods can be run on the sparser problem to derive bounds on the\noriginal answer, which can be quite sharp. We present empirical results\ndemonstrating that our method works well on the tasks of belief inference and\nfinding the probability of the most probable explanation in belief networks,\nand finding the cost of the solution that violates the smallest number of\nconstraints in constraint satisfaction problems. On one large CPCS network, for\nexample, we were able to calculate upper and lower bounds on the conditional\nprobability of a variable, given evidence, that were almost identical in the\naverage case.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:19 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Larkin", "David Ephraim", ""]]}, {"id": "1212.2479", "submitter": "Mark Hopkins", "authors": "Mark Hopkins", "title": "LAYERWIDTH: Analysis of a New Metric for Directed Acyclic Graphs", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-321-328", "categories": "cs.DS cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a new property of directed acyclic graphs (DAGs), called\nlayerwidth, arising from a class of DAGs proposed by Eiter and Lukasiewicz.\nThis class of DAGs permits certain problems of structural model-based causality\nand explanation to be tractably solved. In this paper, we first address an open\nquestion raised by Eiter and Lukasiewicz - the computational complexity of\ndeciding whether a given graph has a bounded layerwidth. After proving that\nthis problem is NP-complete, we proceed by proving numerous important\nproperties of layerwidth that are helpful in efficiently computing the optimal\nlayerwidth. Finally, we compare this new DAG property to two other important\nDAG properties: treewidth and bandwidth.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:04 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Hopkins", "Mark", ""]]}, {"id": "1212.2480", "submitter": "Tom Heskes", "authors": "Tom Heskes, Kees Albers, Hilbert Kappen", "title": "Approximate Inference and Constrained Optimization", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-313-320", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loopy and generalized belief propagation are popular algorithms for\napproximate inference in Markov random fields and Bayesian networks. Fixed\npoints of these algorithms correspond to extrema of the Bethe and Kikuchi free\nenergy. However, belief propagation does not always converge, which explains\nthe need for approaches that explicitly minimize the Kikuchi/Bethe free energy,\nsuch as CCCP and UPS. Here we describe a class of algorithms that solves this\ntypically nonconvex constrained minimization of the Kikuchi free energy through\na sequence of convex constrained minimizations of upper bounds on the Kikuchi\nfree energy. Intuitively one would expect tighter bounds to lead to faster\nalgorithms, which is indeed convincingly demonstrated in our simulations.\nSeveral ideas are applied to obtain tight convex bounds that yield dramatic\nspeed-ups over CCCP.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:00 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Heskes", "Tom", ""], ["Albers", "Kees", ""], ["Kappen", "Hilbert", ""]]}, {"id": "1212.2481", "submitter": "Milos Hauskrecht", "authors": "Milos Hauskrecht, Tomas Singliar", "title": "Monte-Carlo optimizations for resource allocation problems in stochastic\n  network systems", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-305-312", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world distributed systems and networks are often unreliable and subject\nto random failures of its components. Such a stochastic behavior affects\nadversely the complexity of optimization tasks performed routinely upon such\nsystems, in particular, various resource allocation tasks. In this work we\ninvestigate and develop Monte Carlo solutions for a class of two-stage\noptimization problems in stochastic networks in which the expected value of\nresource allocations before and after stochastic failures needs to be\noptimized. The limitation of these problems is that their exact solutions are\nexponential in the number of unreliable network components: thus, exact methods\ndo not scale-up well to large networks often seen in practice. We first prove\nthat Monte Carlo optimization methods can overcome the exponential bottleneck\nof exact methods. Next we support our theoretical findings on resource\nallocation experiments and show a very good scale-up potential of the new\nmethods to large stochastic networks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:55 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Hauskrecht", "Milos", ""], ["Singliar", "Tomas", ""]]}, {"id": "1212.2482", "submitter": "Charles Gretton", "authors": "Charles Gretton, David Price, Sylvie Thiebaux", "title": "Implementation and Comparison of Solution Methods for Decision Processes\n  with Non-Markovian Rewards", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-289-296", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines a number of solution methods for decision processes with\nnon-Markovian rewards (NMRDPs). They all exploit a temporal logic specification\nof the reward function to automatically translate the NMRDP into an equivalent\nMarkov decision process (MDP) amenable to well-known MDP solution methods. They\ndiffer however in the representation of the target MDP and the class of MDP\nsolution methods to which they are suited. As a result, they adopt different\ntemporal logics and different translations. Unfortunately, no implementation of\nthese methods nor experimental let alone comparative results have ever been\nreported. This paper is the first step towards filling this gap. We describe an\nintegrated system for solving NMRDPs which implements these methods and several\nvariants under a common interface; we use it to compare the various approaches\nand identify the problem features favoring one over the other.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:51 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Gretton", "Charles", ""], ["Price", "David", ""], ["Thiebaux", "Sylvie", ""]]}, {"id": "1212.2484", "submitter": "Phan H. Giang", "authors": "Phan H. Giang, Prakash P. Shenoy", "title": "Decision Making with Partially Consonant Belief Functions", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-272-280", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies decision making for Walley's partially consonant belief\nfunctions (pcb). In a pcb, the set of foci are partitioned. Within each\npartition, the foci are nested. The pcb class includes probability functions\nand possibility functions as extreme cases. Unlike earlier proposals for a\ndecision theory with belief functions, we employ an axiomatic approach. We\nadopt an axiom system similar in spirit to von Neumann - Morgenstern's linear\nutility theory for a preference relation on pcb lotteries. We prove a\nrepresentation theorem for this relation. Utility for a pcb lottery is a\ncombination of linear utility for probabilistic lottery and binary utility for\npossibilistic lottery.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:42 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Giang", "Phan H.", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1212.2485", "submitter": "Yong Gao", "authors": "Yong Gao", "title": "Phase Transition of Tractability in Constraint Satisfaction and Bayesian\n  Network Inference", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-265-271", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been great interest in identifying tractable subclasses of NP\ncomplete problems and designing efficient algorithms for these tractable\nclasses. Constraint satisfaction and Bayesian network inference are two\nexamples of such problems that are of great importance in AI and algorithms. In\nthis paper we study, under the frameworks of random constraint satisfaction\nproblems and random Bayesian networks, a typical tractable subclass\ncharacterized by the treewidth of the problems. We show that the property of\nhaving a bounded treewidth for CSPs and Bayesian network inference problem has\na phase transition that occurs while the underlying structures of problems are\nstill sparse. This implies that algorithms making use of treewidth based\nstructural knowledge only work efficiently in a limited range of random\ninstance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:37 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Gao", "Yong", ""]]}, {"id": "1212.2486", "submitter": "Brendan J. Frey", "authors": "Brendan J. Frey", "title": "Extending Factor Graphs so as to Unify Directed and Undirected Graphical\n  Models", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-257-264", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two most popular types of graphical model are directed models (Bayesian\nnetworks) and undirected models (Markov random fields, or MRFs). Directed and\nundirected models offer complementary properties in model construction,\nexpressing conditional independencies, expressing arbitrary factorizations of\njoint distributions, and formulating message-passing inference algorithms. We\nshow that the strengths of these two representations can be combined in a\nsingle type of graphical model called a 'factor graph'. Every Bayesian network\nor MRF can be easily converted to a factor graph that expresses the same\nconditional independencies, expresses the same factorization of the joint\ndistribution, and can be used for probabilistic inference through application\nof a single, simple message-passing algorithm. In contrast to chain graphs,\nwhere message-passing is implemented on a hypergraph, message-passing can be\ndirectly implemented on the factor graph. We describe a modified 'Bayes-ball'\nalgorithm for establishing conditional independence in factor graphs, and we\nshow that factor graphs form a strict superset of Bayesian networks and MRFs.\nIn particular, we give an example of a commonly-used 'mixture of experts' model\nfragment, whose independencies cannot be represented in a Bayesian network or\nan MRF, but can be represented in a factor graph. We finish by giving examples\nof real-world problems that are not well suited to representation in Bayesian\nnetworks and MRFs, but are well-suited to representation in factor graphs.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:33 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Frey", "Brendan J.", ""]]}, {"id": "1212.2493", "submitter": "Matthew Rosencrantz", "authors": "Matthew Rosencrantz, Geoffrey Gordon, Sebastian Thrun", "title": "Decentralized Sensor Fusion With Distributed Particle Filters", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-493-500", "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a scalable Bayesian technique for decentralized state\nestimation from multiple platforms in dynamic environments. As has long been\nrecognized, centralized architectures impose severe scaling limitations for\ndistributed systems due to the enormous communication overheads. We propose a\nstrictly decentralized approach in which only nearby platforms exchange\ninformation. They do so through an interactive communication protocol aimed at\nmaximizing information flow. Our approach is evaluated in the context of a\ndistributed surveillance scenario that arises in a robotic system for playing\nthe game of laser tag. Our results, both from simulation and using physical\nrobots, illustrate an unprecedented scaling capability to large teams of\nvehicles.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:47 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Rosencrantz", "Matthew", ""], ["Gordon", "Geoffrey", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1212.2495", "submitter": "Joelle Pineau", "authors": "Joelle Pineau, Geoffrey Gordon, Sebastian Thrun", "title": "Policy-contingent abstraction for robust robot control", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-477-484", "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a scalable control algorithm that enables a deployed\nmobile robot system to make high-level decisions under full consideration of\nits probabilistic belief. Our approach is based on insights from the rich\nliterature of hierarchical controllers and hierarchical MDPs. The resulting\ncontroller has been successfully deployed in a nursing facility near\nPittsburgh, PA. To the best of our knowledge, this work is a unique instance of\napplying POMDPs to high-level robotic control problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:37 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Pineau", "Joelle", ""], ["Gordon", "Geoffrey", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1212.2496", "submitter": "Patrice Perny", "authors": "Patrice Perny, Olivier Spanjaard", "title": "An Axiomatic Approach to Robustness in Search Problems with Multiple\n  Scenarios", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-469-476", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the search of robust solutions in state space graphs\nwhen costs depend on scenarios. We first present axiomatic requirements for\npreference compatibility with the intuitive idea of robustness.This leads us to\npropose the Lorenz dominance rule as a basis for robustness analysis. Then,\nafter presenting complexity results about the determination of robust\nsolutions, we propose a new sophistication of A* specially designed to\ndetermine the set of robust paths in a state space graph. The behavior of the\nalgorithm is illustrated on a small example. Finally, an axiomatic\njustification of the refinement of robustness by an OWA criterion is provided.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:32 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Perny", "Patrice", ""], ["Spanjaard", "Olivier", ""]]}, {"id": "1212.2497", "submitter": "James D. Park", "authors": "James D. Park, Adnan Darwiche", "title": "Solving MAP Exactly using Systematic Search", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-459-468", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAP is the problem of finding a most probable instantiation of a set of\nvariables in a Bayesian network given some evidence. Unlike computing posterior\nprobabilities, or MPE (a special case of MAP), the time and space complexity of\nstructural solutions for MAP are not only exponential in the network treewidth,\nbut in a larger parameter known as the \"constrained\" treewidth. In practice,\nthis means that computing MAP can be orders of magnitude more expensive than\ncomputing posterior probabilities or MPE. This paper introduces a new, simple\nupper bound on the probability of a MAP solution, which admits a tradeoff\nbetween the bound quality and the time needed to compute it. The bound is shown\nto be generally much tighter than those of other methods of comparable\ncomplexity. We use this proposed upper bound to develop a branch-and-bound\nsearch algorithm for solving MAP exactly. Experimental results demonstrate that\nthe search algorithm is able to solve many problems that are far beyond the\nreach of any structure-based method for MAP. For example, we show that the\nproposed algorithm can compute MAP exactly and efficiently for some networks\nwhose constrained treewidth is more than 40.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:27 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Park", "James D.", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1212.2499", "submitter": "Daniel N Nikovski", "authors": "Daniel N. Nikovski, Matthew Brand", "title": "Marginalizing Out Future Passengers in Group Elevator Control", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-443-450", "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group elevator scheduling is an NP-hard sequential decision-making problem\nwith unbounded state spaces and substantial uncertainty. Decision-theoretic\nreasoning plays a surprisingly limited role in fielded systems. A new\nopportunity for probabilistic methods has opened with the recent discovery of a\ntractable solution for the expected waiting times of all passengers in the\nbuilding, marginalized over all possible passenger itineraries. Though\ncommercially competitive, this solution does not contemplate future passengers.\nYet in up-peak traffic, the effects of future passengers arriving at the lobby\nand entering elevator cars can dominate all waiting times. We develop a\nprobabilistic model of how these arrivals affect the behavior of elevator cars\nat the lobby, and demonstrate how this model can be used to very significantly\nreduce the average waiting time of all passengers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:17 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Nikovski", "Daniel N.", ""], ["Brand", "Matthew", ""]]}, {"id": "1212.2500", "submitter": "Jens D. Nielsen", "authors": "Jens D. Nielsen, Tomas Kocka, Jose M. Pena", "title": "On Local Optima in Learning Bayesian Networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-435-442", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and evaluates the k-greedy equivalence search algorithm\n(KES) for learning Bayesian networks (BNs) from complete data. The main\ncharacteristic of KES is that it allows a trade-off between greediness and\nrandomness, thus exploring different good local optima. When greediness is set\nat maximum, KES corresponds to the greedy equivalence search algorithm (GES).\nWhen greediness is kept at minimum, we prove that under mild assumptions KES\nasymptotically returns any inclusion optimal BN with nonzero probability.\nExperimental results for both synthetic and real data are reported showing that\nKES often finds a better local optima than GES. Moreover, we use KES to\nexperimentally confirm that the number of different local optima is often huge.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:12 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Nielsen", "Jens D.", ""], ["Kocka", "Tomas", ""], ["Pena", "Jose M.", ""]]}, {"id": "1212.2501", "submitter": "Francisco Mugica", "authors": "Francisco Mugica, Angela Nebot, Pilar Gomez", "title": "Dealing with uncertainty in fuzzy inductive reasoning methodology", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-427-434", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this research is to develop a reasoning under uncertainty strategy\nin the context of the Fuzzy Inductive Reasoning (FIR) methodology. FIR emerged\nfrom the General Systems Problem Solving developed by G. Klir. It is a data\ndriven methodology based on systems behavior rather than on structural\nknowledge. It is a very useful tool for both the modeling and the prediction of\nthose systems for which no previous structural knowledge is available. FIR\nreasoning is based on pattern rules synthesized from the available data. The\nsize of the pattern rule base can be very large making the prediction process\nquite difficult. In order to reduce the size of the pattern rule base, it is\npossible to automatically extract classical Sugeno fuzzy rules starting from\nthe set of pattern rules. The Sugeno rule base preserves pattern rules\nknowledge as much as possible. In this process some information is lost but\nrobustness is considerably increased. In the forecasting process either the\npattern rule base or the Sugeno fuzzy rule base can be used. The first option\nis desirable when the computational resources make it possible to deal with the\noverall pattern rule base or when the extracted fuzzy rules are not accurate\nenough due to uncertainty associated to the original data. In the second\noption, the prediction process is done by means of the classical Sugeno\ninference system. If the amount of uncertainty associated to the data is small,\nthe predictions obtained using the Sugeno fuzzy rule base will be very\naccurate. In this paper a mixed pattern/fuzzy rules strategy is proposed to\ndeal with uncertainty in such a way that the best of both perspectives is used.\nAreas in the data space with a higher level of uncertainty are identified by\nmeans of the so-called error models. The prediction process in these areas\nmakes use of a mixed pattern/fuzzy rules scheme, whereas areas identified with\na lower level of uncertainty only use the Sugeno fuzzy rule base. The proposed\nstrategy is applied to a real biomedical system, i.e., the central nervous\nsystem control of the cardiovascular system.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:07 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Mugica", "Francisco", ""], ["Nebot", "Angela", ""], ["Gomez", "Pilar", ""]]}, {"id": "1212.2502", "submitter": "Nicolas Meuleau", "authors": "Nicolas Meuleau, David Smith", "title": "Optimal Limited Contingency Planning", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-417-426", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given problem, the optimal Markov policy can be considerred as a\nconditional or contingent plan containing a (potentially large) number of\nbranches. Unfortunately, there are applications where it is desirable to\nstrictly limit the number of decision points and branches in a plan. For\nexample, it may be that plans must later undergo more detailed simulation to\nverify correctness and safety, or that they must be simple enough to be\nunderstood and analyzed by humans. As a result, it may be necessary to limit\nconsideration to plans with only a small number of branches. This raises the\nquestion of how one goes about finding optimal plans containing only a limited\nnumber of branches. In this paper, we present an any-time algorithm for optimal\nk-contingency planning (OKP). It is the first optimal algorithm for limited\ncontingency planning that is not an explicit enumeration of possible contingent\nplans. By modelling the problem as a Partially Observable Markov Decision\nProcess, it implements the Bellman optimality principle and prunes the solution\nspace. We present experimental results of applying this algorithm to some\nsimple test cases.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:02 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Meuleau", "Nicolas", ""], ["Smith", "David", ""]]}, {"id": "1212.2503", "submitter": "Christopher Meek", "authors": "Christopher Meek, David Maxwell Chickering", "title": "Practically Perfect", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-411-416", "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The property of perfectness plays an important role in the theory of Bayesian\nnetworks. First, the existence of perfect distributions for arbitrary sets of\nvariables and directed acyclic graphs implies that various methods for reading\nindependence from the structure of the graph (e.g., Pearl, 1988; Lauritzen,\nDawid, Larsen & Leimer, 1990) are complete. Second, the asymptotic reliability\nof various search methods is guaranteed under the assumption that the\ngenerating distribution is perfect (e.g., Spirtes, Glymour & Scheines, 2000;\nChickering & Meek, 2002). We provide a lower-bound on the probability of\nsampling a non-perfect distribution when using a fixed number of bits to\nrepresent the parameters of the Bayesian network. This bound approaches zero\nexponentially fast as one increases the number of bits used to represent the\nparameters. This result implies that perfect distributions with fixed-length\nrepresentations exist. We also provide a lower-bound on the number of bits\nneeded to guarantee that a distribution sampled from a uniform Dirichlet\ndistribution is perfect with probability greater than 1/2. This result is\nuseful for constructing randomized reductions for hardness proofs.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:57 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Meek", "Christopher", ""], ["Chickering", "David Maxwell", ""]]}, {"id": "1212.2505", "submitter": "Radu Marinescu", "authors": "Radu Marinescu, Kalev Kask, Rina Dechter", "title": "Systematic vs. Non-systematic Algorithms for Solving the MPE Task", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-394-402", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper continues the study of partitioning based inference of heuristics\nfor search in the context of solving the Most Probable Explanation task in\nBayesian Networks. We compare two systematic Branch and Bound search\nalgorithms, BBBT (for which the heuristic information is constructed during\nsearch and allows dynamic variable/value ordering) and its predecessor BBMB\n(for which the heuristic information is pre-compiled), against a number of\npopular local search algorithms for the MPE problem. We show empirically that,\nwhen viewed as approximation schemes, BBBT/BBMB are superior to all of these\nbest known SLS algorithms, especially when the domain sizes increase beyond 2.\nThis is in contrast with the performance of SLS vs. systematic search on\nCSP/SAT problems, where SLS often significantly outperforms systematic\nalgorithms. As far as we know, BBBT/BBMB are currently the best performing\nalgorithms for solving the MPE task.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:47 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Marinescu", "Radu", ""], ["Kask", "Kalev", ""], ["Dechter", "Rina", ""]]}, {"id": "1212.2506", "submitter": "Jiji Zhang", "authors": "Jiji Zhang, Peter L. Spirtes", "title": "Strong Faithfulness and Uniform Consistency in Causal Inference", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-632-639", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in causal inference is whether it is possible to\nreliably infer manipulation effects from observational data. There are a\nvariety of senses of asymptotic reliability in the statistical literature,\namong which the most commonly discussed frequentist notions are pointwise\nconsistency and uniform consistency. Uniform consistency is in general\npreferred to pointwise consistency because the former allows us to control the\nworst case error bounds with a finite sample size. In the sense of pointwise\nconsistency, several reliable causal inference algorithms have been established\nunder the Markov and Faithfulness assumptions [Pearl 2000, Spirtes et al.\n2001]. In the sense of uniform consistency, however, reliable causal inference\nis impossible under the two assumptions when time order is unknown and/or\nlatent confounders are present [Robins et al. 2000]. In this paper we present\ntwo natural generalizations of the Faithfulness assumption in the context of\nstructural equation models, under which we show that the typical algorithms in\nthe literature (in some cases with modifications) are uniformly consistent even\nwhen the time order is unknown. We also discuss the situation where latent\nconfounders may be present and the sense in which the Faithfulness assumption\nis a limiting case of the stronger assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:09:00 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Zhang", "Jiji", ""], ["Spirtes", "Peter L.", ""]]}, {"id": "1212.2507", "submitter": "Changhe Yuan", "authors": "Changhe Yuan, Marek J. Druzdzel", "title": "An Importance Sampling Algorithm Based on Evidence Pre-propagation", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-624-631", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision achieved by stochastic sampling algorithms for Bayesian networks\ntypically deteriorates in face of extremely unlikely evidence. To address this\nproblem, we propose the Evidence Pre-propagation Importance Sampling algorithm\n(EPIS-BN), an importance sampling algorithm that computes an approximate\nimportance function by the heuristic methods: loopy belief Propagation and\ne-cutoff. We tested the performance of e-cutoff on three large real Bayesian\nnetworks: ANDES, CPCS, and PATHFINDER. We observed that on each of these\nnetworks the EPIS-BN algorithm gives us a considerable improvement over the\ncurrent state of the art algorithm, the AIS-BN algorithm. In addition, it\navoids the costly learning stage of the AIS-BN algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:55 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Yuan", "Changhe", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1212.2509", "submitter": "Joel Young", "authors": "Joel Young, Thomas L. Dean", "title": "Exploiting Locality in Searching the Web", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-608-615", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Published experiments on spidering the Web suggest that, given training data\nin the form of a (relatively small) subgraph of the Web containing a subset of\na selected class of target pages, it is possible to conduct a directed search\nand find additional target pages significantly faster (with fewer page\nretrievals) than by performing a blind or uninformed random or systematic\nsearch, e.g., breadth-first search. If true, this claim motivates a number of\npractical applications. Unfortunately, these experiments were carried out in\nspecialized domains or under conditions that are difficult to replicate. We\npresent and apply an experimental framework designed to reexamine and resolve\nthe basic claims of the earlier work, so that the supporting experiments can be\nreplicated and built upon. We provide high-performance tools for building\nexperimental spiders, make use of the ground truth and static nature of the\nWT10g TREC Web corpus, and rely on simple well understand machine learning\ntechniques to conduct our experiments. In this paper, we describe the basic\nframework, motivate the experimental design, and report on our findings\nsupporting and qualifying the conclusions of the earlier research.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:47 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Young", "Joel", ""], ["Dean", "Thomas L.", ""]]}, {"id": "1212.2515", "submitter": "Benjamin Stewart", "authors": "Benjamin Stewart, Jonathan Ko, Dieter Fox, Kurt Konolige", "title": "The Revisiting Problem in Mobile Robot Map Building: A Hierarchical\n  Bayesian Approach", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-551-558", "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an application of hierarchical Bayesian estimation to robot map\nbuilding. The revisiting problem occurs when a robot has to decide whether it\nis seeing a previously-built portion of a map, or is exploring new territory.\nThis is a difficult decision problem, requiring the probability of being\noutside of the current known map. To estimate this probability, we model the\nstructure of a \"typical\" environment as a hidden Markov model that generates\nsequences of views observed by a robot navigating through the environment. A\nDirichlet prior over structural models is learned from previously explored\nenvironments. Whenever a robot explores a new environment, the posterior over\nthe model is estimated by Dirichlet hyperparameters. Our approach is\nimplemented and tested in the context of multi-robot map merging, a\nparticularly difficult instance of the revisiting problem. Experiments with\nrobot data show that the technique yields strong improvements over alternative\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:19 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Stewart", "Benjamin", ""], ["Ko", "Jonathan", ""], ["Fox", "Dieter", ""], ["Konolige", "Kurt", ""]]}, {"id": "1212.2518", "submitter": "Rita Sharma", "authors": "Rita Sharma, David L Poole", "title": "Efficient Inference in Large Discrete Domains", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-535-542", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine the problem of inference in Bayesian Networks with\ndiscrete random variables that have very large or even unbounded domains. For\nexample, in a domain where we are trying to identify a person, we may have\nvariables that have as domains, the set of all names, the set of all postal\ncodes, or the set of all credit card numbers. We cannot just have big tables of\nthe conditional probabilities, but need compact representations. We provide an\ninference algorithm, based on variable elimination, for belief networks\ncontaining both large domain and normal discrete random variables. We use\nintensional (i.e., in terms of procedures) and extensional (in terms of listing\nthe elements) representations of conditional probabilities and of the\nintermediate factors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:10 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Sharma", "Rita", ""], ["Poole", "David L", ""]]}, {"id": "1212.2519", "submitter": "Vitor Santos Costa", "authors": "Vitor Santos Costa, David Page, Maleeha Qazi, James Cussens", "title": "CLP(BN): Constraint Logic Programming for Probabilistic Knowledge", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-517-524", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CLP(BN), a novel approach that aims at expressing Bayesian\nnetworks through the constraint logic programming framework. Arguably, an\nimportant limitation of traditional Bayesian networks is that they are\npropositional, and thus cannot represent relations between multiple similar\nobjects in multiple contexts. Several researchers have thus proposed\nfirst-order languages to describe such networks. Namely, one very successful\nexample of this approach are the Probabilistic Relational Models (PRMs), that\ncombine Bayesian networks with relational database technology. The key\ndifficulty that we had to address when designing CLP(cal{BN}) is that logic\nbased representations use ground terms to denote objects. With probabilitic\ndata, we need to be able to uniquely represent an object whose value we are not\nsure about. We use {sl Skolem functions} as unique new symbols that uniquely\nrepresent objects with unknown value. The semantics of CLP(cal{BN}) programs\nthen naturally follow from the general framework of constraint logic\nprogramming, as applied to a specific domain where we have probabilistic data.\nThis paper introduces and defines CLP(cal{BN}), and it describes an\nimplementation and initial experiments. The paper also shows how CLP(cal{BN})\nrelates to Probabilistic Relational Models (PRMs), Ngo and Haddawys\nProbabilistic Logic Programs, AND Kersting AND De Raedts Bayesian Logic\nPrograms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:01 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Costa", "Vitor Santos", ""], ["Page", "David", ""], ["Qazi", "Maleeha", ""], ["Cussens", "James", ""]]}, {"id": "1212.2614", "submitter": "Michael  Gr. Voskoglou Prof. Dr.", "authors": "Michael Gr. Voskoglou", "title": "A Study on Fuzzy Systems", "comments": "9 pages, 3 figures, 1 table", "journal-ref": "American Journal of Computational and Applied Mathematics, 2(5),\n  232-240, 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use princiles of fuzzy logic to develop a general model representing\nseveral processes in a system's operation characterized by a degree of\nvagueness and/or uncertainy. Further, we introduce three altenative measures of\na fuzzy system's effectiveness connected to the above model. An applcation is\nalso developed for the Mathematical Modelling process illustrating our results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 20:31:01 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Voskoglou", "Michael Gr.", ""]]}, {"id": "1212.2657", "submitter": "Anna Ryabokon", "authors": "Anna Ryabokon", "title": "Study: Symmetry breaking for ASP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their nature configuration problems are combinatorial (optimization)\nproblems. In order to find a configuration a solver has to instantiate a number\nof components of a some type and each of these components can be used in a\nrelation defined for a type. Therefore, many solutions of a configuration\nproblem have symmetric ones which can be obtained by replacing some component\nof a solution by another one of the same type. These symmetric solutions\ndecrease performance of optimization algorithms because of two reasons: a) they\nsatisfy all requirements and cannot be pruned out from the search space; and b)\nexistence of symmetric optimal solutions does not allow to prove the optimum in\na feasible time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 21:47:26 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Ryabokon", "Anna", ""]]}, {"id": "1212.2671", "submitter": "Ignacio Algredo-Badillo Dr.", "authors": "Ernesto Cort\\'es P\\'erez, Ignacio Algredo-Badillo, V\\'ictor Hugo\n  Garc\\'ia Rodr\\'iguez", "title": "Performance Analysis of ANFIS in short term Wind Speed Prediction", "comments": "9 pages, 11 figures, 1 table; IJCSI International Journal of Computer\n  Science Issues, Vol. 9, Issue 5, No 3, September 2012. ISSN (Online):\n  1694-0814. www.IJCSI.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results are presented on the performance of Adaptive Neuro-Fuzzy Inference\nsystem (ANFIS) for wind velocity forecasts in the Isthmus of Tehuantepec region\nin the state of Oaxaca, Mexico. The data bank was provided by the\nmeteorological station located at the University of Isthmus, Tehuantepec\ncampus, and this data bank covers the period from 2008 to 2011. Three data\nmodels were constructed to carry out 16, 24 and 48 hours forecasts using the\nfollowing variables: wind velocity, temperature, barometric pressure, and date.\nThe performance measure for the three models is the mean standard error (MSE).\nIn this work, performance analysis in short-term prediction is presented,\nbecause it is essential in order to define an adequate wind speed model for\neolian parks, where a right planning provide economic benefits.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 22:48:36 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["P\u00e9rez", "Ernesto Cort\u00e9s", ""], ["Algredo-Badillo", "Ignacio", ""], ["Rodr\u00edguez", "V\u00edctor Hugo Garc\u00eda", ""]]}, {"id": "1212.2791", "submitter": "Llu\\'is Belanche-Mu\\~noz", "authors": "Llu\\'is A. Belanche", "title": "Understanding (dis)similarity measures", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "LSI-12-16-R", "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitively, the concept of similarity is the notion to measure an inexact\nmatching between two entities of the same reference set. The notions of\nsimilarity and its close relative dissimilarity are widely used in many fields\nof Artificial Intelligence. Yet they have many different and often partial\ndefinitions or properties, usually restricted to one field of application and\nthus incompatible with other uses. This paper contributes to the design and\nunderstanding of similarity and dissimilarity measures for Artificial\nIntelligence. A formal dual definition for each concept is proposed, joined\nwith a set of fundamental properties. The behavior of the properties under\nseveral transformations is studied and revealed as an important matter to bear\nin mind. We also develop several practical examples that work out the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 12:27:53 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Belanche", "Llu\u00eds A.", ""]]}, {"id": "1212.2857", "submitter": "Francesco Santini", "authors": "Stefano Bistarelli, Francesco Santini", "title": "ConArg: a Tool to Solve (Weighted) Abstract Argumentation Frameworks\n  with (Soft) Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ConArg is a Constraint Programming-based tool that can be used to model and\nsolve different problems related to Abstract Argumentation Frameworks (AFs). To\nimplement this tool we have used JaCoP, a Java library that provides the user\nwith a Finite Domain Constraint Programming paradigm. ConArg is able to\nrandomly generate networks with small-world properties in order to find\nconflict-free, admissible, complete, stable grounded, preferred, semi-stable,\nstage and ideal extensions on such interaction graphs. We present the main\nfeatures of ConArg and we report the performance in time, showing also a\ncomparison with ASPARTIX [1], a similar tool using Answer Set Programming. The\nuse of techniques for constraint solving can tackle the complexity of the\nproblems presented in [2]. Moreover we suggest semiring-based soft constraints\nas a mean to parametrically represent and solve Weighted Argumentation\nFrameworks: different kinds of preference levels related to attacks, e.g., a\nscore representing a \"fuzziness\", a \"cost\" or a probability, can be represented\nby choosing different instantiation of the semiring algebraic structure. The\nbasic idea is to provide a common computational and quantitative framework.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 16:06:28 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 16:33:47 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Santini", "Francesco", ""]]}, {"id": "1212.2866", "submitter": "Prasun Ghosal PhD", "authors": "Prasun Ghosal, Arijit Chakraborty, Sabyasachee Banerjee, Satabdi\n  Barman", "title": "Speed Optimization In Unplanned Traffic Using Bio-Inspired Computing And\n  Population Knowledge Base", "comments": "19 pages", "journal-ref": "Computer Science & Engineering: An International Journal (CSEIJ),\n  Vol.2, No.3, June 2012, pp. 79 - 97", "doi": "10.5121/cseij.2012.2307", "report-no": null, "categories": "cs.CY cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-Inspired Algorithms on Road Traffic Congestion and safety is a very\npromising research problem. Searching for an efficient optimization method to\nincrease the degree of speed optimization and thereby increasing the traffic\nFlow in an unplanned zone is a widely concerning issue. However, there has been\na limited research effort on the optimization of the lane usage with speed\noptimization. The main objective of this article is to find avenues or\ntechniques in a novel way to solve the problem optimally using the knowledge\nfrom analysis of speeds of vehicles, which, in turn will act as a guide for\ndesign of lanes optimally to provide better optimized traffic. The accident\nfactors adjust the base model estimates for individual geometric design element\ndimensions and for traffic control features. The application of these\nalgorithms in partially modified form in accordance of this novel Speed\nOptimization Technique in an Unplanned Traffic analysis technique is applied to\nthe proposed design and speed optimization plan. The experimental results based\non real life data are quite encouraging.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 16:28:05 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Ghosal", "Prasun", ""], ["Chakraborty", "Arijit", ""], ["Banerjee", "Sabyasachee", ""], ["Barman", "Satabdi", ""]]}, {"id": "1212.2902", "submitter": "Michael Schneider", "authors": "Michael Schneider, Sebastian Rudolph, Geoff Sutcliffe", "title": "Modeling in OWL 2 without Restrictions", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web ontology language OWL 2 DL comes with a variety of language\nfeatures that enable sophisticated and practically useful modeling. However,\nthe use of these features has been severely restricted in order to retain\ndecidability of the language. For example, OWL 2 DL does not allow a property\nto be both transitive and asymmetric, which would be desirable, e.g., for\nrepresenting an ancestor relation. In this paper, we argue that the so-called\nglobal restrictions of OWL 2 DL preclude many useful forms of modeling, by\nproviding a catalog of basic modeling patterns that would be available in OWL 2\nDL if the global restrictions were discarded. We then report on the results of\nevaluating several state-of-the-art OWL 2 DL reasoners on problems that use\ncombinations of features in a way that the global restrictions are violated.\nThe systems turn out to rely heavily on the global restrictions and are thus\nlargely incapable of coping with the modeling patterns. Next we show how\noff-the-shelf first-order logic theorem proving technology can be used to\nperform reasoning in the OWL 2 direct semantics, the semantics that underlies\nOWL 2 DL, but without requiring the global restrictions. Applying a naive\nproof-of-concept implementation of this approach to the test problems was\nsuccessful in all cases. Based on our observations, we make suggestions for\nfuture lines of research on expressive description logic-style OWL reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 17:58:01 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2012 06:41:41 GMT"}, {"version": "v3", "created": "Sun, 28 Apr 2013 22:30:09 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Schneider", "Michael", ""], ["Rudolph", "Sebastian", ""], ["Sutcliffe", "Geoff", ""]]}, {"id": "1212.2958", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza and A. H. EL-Bassiouny", "title": "Spike and Tyke, the Quantized Neuron Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling spike firing assumes that spiking statistics are Poisson, but real\ndata violates this assumption. To capture non-Poissonian features, in order to\nfix the inevitable inherent irregularity, researchers rescale the time axis\nwith tedious computational overhead instead of searching for another\ndistribution. Spikes or action potentials are precisely-timed changes in the\nionic transport through synapses adjusting the synaptic weight, successfully\nmodeled and developed as a memristor. Memristance value is multiples of initial\nresistance. This reminds us with the foundations of quantum mechanics. We try\nto quantize potential and resistance, as done with energy. After reviewing\nPlanck curve for blackbody radiation, we propose the quantization equations. We\nintroduce and prove a theorem that quantizes the resistance. Then we define the\ntyke showing its basic characteristics. Finally we give the basic\ntransformations to model spiking and link an energy quantum to a tyke.\nInvestigation shows how this perfectly models the neuron spiking, with over 97%\nmatch.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 18:15:58 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2013 00:13:32 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1212.2991", "submitter": "Shawn Hershey", "authors": "Shawn Hershey, Jeff Bernstein, Bill Bradley, Andrew Schweitzer, Noah\n  Stein, Theo Weber, Ben Vigoda", "title": "Accelerating Inference: towards a full Language, Compiler and Hardware\n  stack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We introduce Dimple, a fully open-source API for probabilistic modeling.\nDimple allows the user to specify probabilistic models in the form of graphical\nmodels, Bayesian networks, or factor graphs, and performs inference (by\nautomatically deriving an inference engine from a variety of algorithms) on the\nmodel. Dimple also serves as a compiler for GP5, a hardware accelerator for\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 21:40:23 GMT"}], "update_date": "2012-12-14", "authors_parsed": [["Hershey", "Shawn", ""], ["Bernstein", "Jeff", ""], ["Bradley", "Bill", ""], ["Schweitzer", "Andrew", ""], ["Stein", "Noah", ""], ["Weber", "Theo", ""], ["Vigoda", "Ben", ""]]}, {"id": "1212.3013", "submitter": "Gabriele Modena", "authors": "K. Massoudi, G. Modena", "title": "Product/Brand extraction from WikiPedia", "comments": "17 pages. Manuscript first creation date: November 27, 2009. At the\n  time of first creation both authors were affiliated with the University of\n  Amsterdam (The Netherlands)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the task of extracting product and brand pages from\nwikipedia. We present an experimental environment and setup built on top of a\ndataset of wikipedia pages we collected. We introduce a method for recognition\nof product pages modelled as a boolean probabilistic classification task. We\nshow that this approach can lead to promising results and we discuss\nalternative approaches we considered.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 23:25:46 GMT"}], "update_date": "2012-12-14", "authors_parsed": [["Massoudi", "K.", ""], ["Modena", "G.", ""]]}, {"id": "1212.3618", "submitter": "EPTCS", "authors": "Ekaterina Komendantskaya (School of Computing, University of Dundee),\n  J\\'onathan Heras (School of Computing, University of Dundee), Gudmund Grov\n  (School of Mathematical and Computer Sciences, Heriot-Watt University)", "title": "Machine Learning in Proof General: Interfacing Interfaces", "comments": "In Proceedings UITP 2012, arXiv:1307.1528", "journal-ref": "EPTCS 118, 2013, pp. 15-41", "doi": "10.4204/EPTCS.118.2", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ML4PG - a machine learning extension for Proof General. It allows\nusers to gather proof statistics related to shapes of goals, sequences of\napplied tactics, and proof tree structures from the libraries of interactive\nhigher-order proofs written in Coq and SSReflect. The gathered data is\nclustered using the state-of-the-art machine learning algorithms available in\nMATLAB and Weka. ML4PG provides automated interfacing between Proof General and\nMATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints\nin the process of interactive proof development.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 21:06:34 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2013 05:19:38 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Komendantskaya", "Ekaterina", "", "School of Computing, University of Dundee"], ["Heras", "J\u00f3nathan", "", "School of Computing, University of Dundee"], ["Grov", "Gudmund", "", "School of Mathematical and Computer Sciences, Heriot-Watt University"]]}, {"id": "1212.3817", "submitter": "Xing Wang", "authors": "Xing M. Wang", "title": "Probability Bracket Notation: Markov State Chain Projector, Hidden\n  Markov Models and Dynamic Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a brief discussion of Markov Evolution Formula (MEF) expressed in\nProbability Bracket Notation (PBN), its close relation with the joint\nprobability distribution (JPD) of Visible Markov Models (VMM) is demonstrated\nby introducing Markov State Chain Projector (MSCP). The state basis and the\nobserved basis are defined in the Sequential Event Space (SES) of Hidden Markov\nModels (HMM). The JPD of HMM is derived by using basis transformation in SES.\nThe Viterbi algorithm is revisited and applied to the famous Weather HMM\nexample, whose node graph and inference results are displayed by using software\npackage Elvira. In the end, the formulas of VMM, HMM and some factorial HMM\n(FHMM) are expressed in PBN as instances of dynamic Bayesian Networks (DBN).\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 18:58:52 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Wang", "Xing M.", ""]]}, {"id": "1212.3996", "submitter": "Gaetan Marceau", "authors": "Areski Hadjaz, Ga\\'etan Marceau (INRIA Saclay - Ile de France), Pierre\n  Sav\\'eant (TRT), Marc Schoenauer (INRIA Saclay - Ile de France, MSR - INRIA)", "title": "Increasing Air Traffic: What is the Problem?", "comments": "SESAR 2nd Innovation Days (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, huge efforts are made to modernize the air traffic management\nsystems to cope with uncertainty, complexity and sub-optimality. An answer is\nto enhance the information sharing between the stakeholders. This paper\nintroduces a framework that bridges the gap between air traffic management and\nair traffic control on the one hand, and bridges the gap between the ground,\nthe approach and the en-route centers on the other hand. An original system is\npresented, that has three essential components: the trajectory models, the\noptimization process, and the monitoring process. The uncertainty of the\ntrajectory is modeled with a Bayesian Network, where the nodes are associated\nto two types of random variables: the time of overflight on metering points of\nthe airspace, and the traveling time of the routes linking these points. The\nresulting Bayesian Network covers the complete airspace, and Monte- Carlo\nsimulations are done to estimate the probabilities of sector congestion and\ndelays. On top of this trajectory model, an optimization process minimizes\nthese probabilities by tuning the parameters of the Bayesian trajectory model\nrelated to overflight times on metering points. The last component is the\nmonitoring process, that continuously updates the situation of the airspace,\nmodifying the trajectories uncertainties according to actual positions of\naircraft. After each update, a new optimal set of overflight times is computed,\nand can be communicated to the controllers as clearances for the aircraft\npilots. The paper presents a formal specification of this global optimization\nproblem, whose underlying rationale was derived with the help of air traffic\ncontrollers at Thales Air Systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 14:10:45 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Hadjaz", "Areski", "", "INRIA Saclay - Ile de France"], ["Marceau", "Ga\u00e9tan", "", "INRIA Saclay - Ile de France"], ["Sav\u00e9ant", "Pierre", "", "TRT"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France, MSR - INRIA"]]}, {"id": "1212.3998", "submitter": "Gaetan Marceau", "authors": "Areski Hadjaz, Ga\\'etan Marceau (INRIA Saclay - Ile de France), Pierre\n  Sav\\'eant (TRT), Marc Schoenauer (INRIA Saclay - Ile de France, MSR - INRIA)", "title": "Online Learning for Ground Trajectory Prediction", "comments": "SESAR 2nd Innovation Days (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model based on an hybrid system to numerically simulate\nthe climbing phase of an aircraft. This model is then used within a trajectory\nprediction tool. Finally, the Covariance Matrix Adaptation Evolution Strategy\n(CMA-ES) optimization algorithm is used to tune five selected parameters, and\nthus improve the accuracy of the model. Incorporated within a trajectory\nprediction tool, this model can be used to derive the order of magnitude of the\nprediction error over time, and thus the domain of validity of the trajectory\nprediction. A first validation experiment of the proposed model is based on the\nerrors along time for a one-time trajectory prediction at the take off of the\nflight with respect to the default values of the theoretical BADA model. This\nexperiment, assuming complete information, also shows the limit of the model. A\nsecond experiment part presents an on-line trajectory prediction, in which the\nprediction is continuously updated based on the current aircraft position. This\napproach raises several issues, for which improvements of the basic model are\nproposed, and the resulting trajectory prediction tool shows statistically\nsignificantly more accurate results than those of the default model.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 14:17:16 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Hadjaz", "Areski", "", "INRIA Saclay - Ile de France"], ["Marceau", "Ga\u00e9tan", "", "INRIA Saclay - Ile de France"], ["Sav\u00e9ant", "Pierre", "", "TRT"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France, MSR - INRIA"]]}, {"id": "1212.4287", "submitter": "Florian Richoux", "authors": "Charlotte Truchet, Florian Richoux and Philippe Codognet", "title": "Prediction of Parallel Speed-ups for Las Vegas Algorithms", "comments": "10 pages, 14 figures, 5 tables. Latex ACM Sigplan format", "journal-ref": "Proceedings of the IEEE 2013 42nd International Conference on\n  Parallel Processing", "doi": "10.1109/ICPP.2013.25", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for the parallel execution of Las Vegas\nalgorithms, i.e., randomized algorithms whose runtime might vary from one\nexecution to another, even with the same input. This model aims at predicting\nthe parallel performances (i.e., speedups) by analysis the runtime distribution\nof the sequential runs of the algorithm. Then, we study in practice the case of\na particular Las Vegas algorithm for combinatorial optimization, on three\nclassical problems, and compare with an actual parallel implementation up to\n256 cores. We show that the prediction can be quite accurate, matching the\nactual speedups very well up to 100 parallel cores and then with a deviation of\nabout 20% up to 256 cores.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 10:05:51 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Truchet", "Charlotte", ""], ["Richoux", "Florian", ""], ["Codognet", "Philippe", ""]]}, {"id": "1212.4373", "submitter": "Djedid Mohammed Nadir", "authors": "Mohammed Nadir Djedid", "title": "A trust-based security mechanism for nomadic users in pervasive systems", "comments": "7 pages, 1 figure, 2 tables", "journal-ref": "International Journal of Computer Science Issues IJCSI Journal,\n  Volume 9, Issue 5, No 1, September 2012", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of network technologies and the appearance of new varied\napplications in terms of services and resources, has created new security\nproblems for which existing solutions and mechanisms are inadequate, especially\nproblems of identification and authentication. In a highly distributed and\npervasive system, a uniform and centralized security management is not an\noption. It then becomes necessary to give more autonomy to security systems by\nproviding them with mechanisms that allows a dynamic and flexible cooperation\nand collaboration between the actors in the system.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 14:53:32 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Djedid", "Mohammed Nadir", ""]]}, {"id": "1212.4799", "submitter": "Cameron Freer", "authors": "Cameron E. Freer and Daniel M. Roy and Joshua B. Tenenbaum", "title": "Towards common-sense reasoning via conditional simulation: legacies of\n  Turing in Artificial Intelligence", "comments": "51 pages, 6 figures, 1 table. Slight typographical fixes", "journal-ref": "Turing's Legacy: Developments from Turing's Ideas in Logic, ed.\n  Rod Downey, ASL Lecture Notes in Logic 42, Cambridge University Press, 2014", "doi": "10.1017/CBO9781107338579.007", "report-no": null, "categories": "cs.AI math.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of replicating the flexibility of human common-sense reasoning\nhas captured the imagination of computer scientists since the early days of\nAlan Turing's foundational work on computation and the philosophy of artificial\nintelligence. In the intervening years, the idea of cognition as computation\nhas emerged as a fundamental tenet of Artificial Intelligence (AI) and\ncognitive science. But what kind of computation is cognition?\n  We describe a computational formalism centered around a probabilistic Turing\nmachine called QUERY, which captures the operation of probabilistic\nconditioning via conditional simulation. Through several examples and analyses,\nwe demonstrate how the QUERY abstraction can be used to cast common-sense\nreasoning as probabilistic inference in a statistical model of our observations\nand the uncertain structure of the world that generated that experience. This\nformulation is a recent synthesis of several research programs in AI and\ncognitive science, but it also represents a surprising convergence of several\nof Turing's pioneering insights in AI, the foundations of computation, and\nstatistics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 19:20:57 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 15:13:44 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Freer", "Cameron E.", ""], ["Roy", "Daniel M.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1212.5271", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Towards the Evolution of Novel Vertical-Axis Wind Turbines", "comments": "14 pages, 11 figures", "journal-ref": "Proceedings of the 13th Annual UK Workshop on Computational\n  Intelligence, UKCI 2013, pp. 74-81. IEEE Computer Society", "doi": "10.1109/UKCI.2013.6651290", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Renewable and sustainable energy is one of the most important challenges\ncurrently facing mankind. Wind has made an increasing contribution to the\nworld's energy supply mix, but still remains a long way from reaching its full\npotential. In this paper, we investigate the use of artificial evolution to\ndesign vertical-axis wind turbine prototypes that are physically instantiated\nand evaluated under approximated wind tunnel conditions. An artificial neural\nnetwork is used as a surrogate model to assist learning and found to reduce the\nnumber of fabrications required to reach a higher aerodynamic efficiency,\nresulting in an important cost reduction. Unlike in other approaches, such as\ncomputational fluid dynamics simulations, no mathematical formulations are used\nand no model assumptions are made.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 21:08:34 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1212.5276", "submitter": "Marc Schoenauer", "authors": "Mostepha Redouane Khouadjia (INRIA Saclay - Ile de France), Marc\n  Schoenauer (INRIA Saclay - Ile de France, LRI), Vincent Vidal (DCSD), Johann\n  Dr\\'eo (TRT), Pierre Sav\\'eant (TRT)", "title": "Multi-Objective AI Planning: Evaluating DAE-YAHSP on a Tunable Benchmark", "comments": "7th International Conference on Evolutionary Multi-Criterion\n  Optimization (2013) To appearr. arXiv admin note: text overlap with\n  arXiv:0804.3965 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All standard AI planners to-date can only handle a single objective, and the\nonly way for them to take into account multiple objectives is by aggregation of\nthe objectives. Furthermore, and in deep contrast with the single objective\ncase, there exists no benchmark problems on which to test the algorithms for\nmulti-objective planning. Divide and Evolve (DAE) is an evolutionary planner\nthat won the (single-objective) deterministic temporal satisficing track in the\nlast International Planning Competition. Even though it uses intensively the\nclassical (and hence single-objective) planner YAHSP, it is possible to turn\nDAE-YAHSP into a multi-objective evolutionary planner. A tunable benchmark\nsuite for multi-objective planning is first proposed, and the performances of\nseveral variants of multi-objective DAE-YAHSP are compared on different\ninstances of this benchmark, hopefully paving the road to further\nmulti-objective competitions in AI planning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 21:26:17 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Khouadjia", "Mostepha Redouane", "", "INRIA Saclay - Ile de France"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France, LRI"], ["Vidal", "Vincent", "", "DCSD"], ["Dr\u00e9o", "Johann", "", "TRT"], ["Sav\u00e9ant", "Pierre", "", "TRT"]]}, {"id": "1212.5461", "submitter": "Christopher Simons", "authors": "Christopher L. Simons, Jim Smith and Paul White", "title": "Interactive Ant Colony Optimisation (iACO) for Early Lifecycle Software\n  Design", "comments": "31 pages including appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software design is crucial to successful software development, yet is a\ndemanding multi-objective problem for software engineers. In an attempt to\nassist the software designer, interactive (i.e. human in-the-loop)\nmeta-heuristic search techniques such as evolutionary computing have been\napplied and show promising results. Recent investigations have also shown that\nAnt Colony Optimization (ACO) can outperform evolutionary computing as a\npotential search engine for interactive software design. With a limited\ncomputational budget, ACO produces superior candidate design solutions in a\nsmaller number of iterations. Building on these findings, we propose a novel\ninteractive ACO (iACO) approach to assist the designer in early lifecycle\nsoftware design, in which the search is steered jointly by subjective designer\nevaluation as well as machine fitness functions relating the structural\nintegrity and surrogate elegance of software designs. Results show that iACO is\nspeedy, responsive and highly effective in enabling interactive, dynamic\nmulti-objective search in early lifecycle software design. Study participants\nrate the iACO search experience as compelling. Results of machine learning of\nfitness measure weightings indicate that software design elegance does indeed\nplay a significant role in designer evaluation of candidate software design. We\nconclude that the evenness of the number of attributes and methods among\nclasses (NAC) is a significant surrogate elegance measure, which in turn\nsuggests that this evenness of distribution, when combined with structural\nintegrity, is an implicit but crucial component of effective early lifecycle\nsoftware design.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 14:31:42 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2014 10:52:48 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Simons", "Christopher L.", ""], ["Smith", "Jim", ""], ["White", "Paul", ""]]}, {"id": "1212.5776", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza and A.H. EL-Bassiouny", "title": "Improving problem solving by exploiting the concept of symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the concept of symmetry and its role in problem solving. This\npaper first defines precisely the elements that constitute a \"problem\" and its\n\"solution,\" and gives several examples to illustrate these definitions. Given\nprecise definitions of problems, it is relatively straightforward to construct\na search process for finding solutions. Finally this paper attempts to exploit\nthe concept of symmetry in improving problem solving.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2012 09:18:59 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2013 23:26:24 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1212.6207", "submitter": "Kirill Sorudeykin Mr", "authors": "Kirill A. Sorudeykin", "title": "Irrespective Priority-Based Regular Properties of High-Intensity Virtual\n  Environments", "comments": "4 pages, 2 figures; ISBN: 978-1-4673-2984-2", "journal-ref": "20th Telecommunications Forum TELFOR 2012, 2012, pp. 510-513", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have a lot of relation to the encoding and the Theory of Information, when\nconsidering thinking. This is a natural process and, at once, the complex thing\nwe investigate. This always was a challenge - to understand how our mind works,\nand we are trying to find some universal models for this. A lot of ways have\nbeen considered so far, but we are looking for Something, we seek for\napproaches. And the goal is to find a consistent, noncontradictory view, which\nshould at once be enough flexible in any dimensions to allow to represent\nvarious kinds of processes and environments, matters of different nature and\ndiverse objects. Developing of such a model is the destination of this article.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 08:43:22 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Sorudeykin", "Kirill A.", ""]]}, {"id": "1212.6216", "submitter": "Masoud Amoozgar", "authors": "Masoud Amoozgar, Daniel Khashabi, Milad Heydarian, Mohammad Nokhbeh,\n  Saeed Bagheri Shouraki", "title": "Generating Motion Patterns Using Evolutionary Computation in Digital\n  Soccer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dribbling an opponent player in digital soccer environment is an important\npractical problem in motion planning. It has special complexities which can be\ngeneralized to most important problems in other similar Multi Agent Systems. In\nthis paper, we propose a hybrid computational geometry and evolutionary\ncomputation approach for generating motion trajectories to avoid a mobile\nobstacle. In this case an opponent agent is not only an obstacle but also one\nwho tries to harden dribbling procedure. One characteristic of this approach is\nreducing process cost of online stage by transferring it to offline stage which\ncauses increment in agents' performance. This approach breaks the problem into\ntwo offline and online stages. During offline stage the goal is to find desired\ntrajectory using evolutionary computation and saving it as a trajectory plan. A\ntrajectory plan consists of nodes which approximate information of each\ntrajectory plan. In online stage, a linear interpolation along with Delaunay\ntriangulation in xy-plan is applied to trajectory plan to retrieve desired\naction.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 17:14:32 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2013 11:48:03 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Amoozgar", "Masoud", ""], ["Khashabi", "Daniel", ""], ["Heydarian", "Milad", ""], ["Nokhbeh", "Mohammad", ""], ["Shouraki", "Saeed Bagheri", ""]]}, {"id": "1212.6273", "submitter": "John-John Cabibihan", "authors": "John-John Cabibihan, Wing-Chee So, and Soumo Pramanik", "title": "Human-Recognizable Robotic Gestures", "comments": "21 pages, 5 figures", "journal-ref": "Autonomous Mental Development, IEEE Transactions, 2012, 4(4),\n  305-314", "doi": "10.1109/TAMD.2012.2208962", "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  For robots to be accommodated in human spaces and in humans daily activities,\nrobots should be able to understand messages from the human conversation\npartner. In the same light, humans must also understand the messages that are\nbeing communicated by robots, including the non-verbal ones. We conducted a\nweb-based video study wherein participants gave interpretations on the iconic\ngestures and emblems that were produced by an anthropomorphic robot. Out of the\n15 gestures presented, we found 6 robotic gestures that can be accurately\nrecognized by the human observer. These were nodding, clapping, hugging,\nexpressing anger, walking, and flying. We reviewed these gestures for their\nmeaning from literatures in human and animal behavior. We conclude by\ndiscussing the possible implications of these gestures for the design of social\nrobots that are aimed to have engaging interactions with humans.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 22:10:14 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Cabibihan", "John-John", ""], ["So", "Wing-Chee", ""], ["Pramanik", "Soumo", ""]]}, {"id": "1212.6276", "submitter": "Sebasti\\'an Basterrech", "authors": "Sebasti\\'an Basterrech and Gerardo Rubino", "title": "Echo State Queueing Network: a new reservoir computing learning tool", "comments": "Proceedings of the 10th IEEE Consumer Communications and Networking\n  Conference (CCNC), Las Vegas, USA, 2013", "journal-ref": null, "doi": "10.1109/CCNC.2013.6488435", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, a new computational paradigm was introduced in the field\nof Machine Learning, under the name of Reservoir Computing (RC). RC models are\nneural networks which a recurrent part (the reservoir) that does not\nparticipate in the learning process, and the rest of the system where no\nrecurrence (no neural circuit) occurs. This approach has grown rapidly due to\nits success in solving learning tasks and other computational applications.\nSome success was also observed with another recently proposed neural network\ndesigned using Queueing Theory, the Random Neural Network (RandNN). Both\napproaches have good properties and identified drawbacks. In this paper, we\npropose a new RC model called Echo State Queueing Network (ESQN), where we use\nideas coming from RandNNs for the design of the reservoir. ESQNs consist in\nESNs where the reservoir has a new dynamics inspired by recurrent RandNNs. The\npaper positions ESQNs in the global Machine Learning area, and provides\nexamples of their use and performances. We show on largely used benchmarks that\nESQNs are very accurate tools, and we illustrate how they compare with standard\nESNs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 22:31:13 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Basterrech", "Sebasti\u00e1n", ""], ["Rubino", "Gerardo", ""]]}, {"id": "1212.6298", "submitter": "Achmad Benny Mutiara", "authors": "R. Refianti, A. B. Mutiara, H. Gunawan", "title": "Design of Intelligent Agents Based System for Commodity Market\n  Simulation with JADE", "comments": "13 pages, 11 figures; European Journal of Scientific Research (EJSR),\n  Vol. 92 Issue 3, Desember 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A market of potato commodity for industry scale usage is engaging several\ntypes of actors. They are farmers, middlemen, and industries. A multi-agent\nsystem has been built to simulate these actors into agent entities, based on\nmanually given parameters within a simulation scenario file. Each type of\nagents has its own fuzzy logic representing actual actors' knowledge, to be\nused to interpreting values and take appropriated decision of it while on\nsimulation. The system will simulate market activities with programmed\nbehaviors then produce the results as spreadsheet and chart graph files. These\nresults consist of each agent's yearly finance and commodity data. The system\nwill also predict each of next value from these outputs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2012 04:07:01 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Refianti", "R.", ""], ["Mutiara", "A. B.", ""], ["Gunawan", "H.", ""]]}, {"id": "1212.6519", "submitter": "Mani A", "authors": "A. Mani", "title": "Dialectics of Knowledge Representation in a Granular Rough Set Theory", "comments": "Enlarged version of Refereed Conference Paper. 18 pp 1 figure. (An\n  extended version is to appear soon)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of rough and definite objects are relatively more determinate\nthan those of granules and granulation in general rough set theory (RST) [1].\nRepresentation of rough objects can however depend on the dialectical relation\nbetween granulation and definiteness. In this research, we make this exact in\nthe context of RST over proto-transitive approximation spaces. This approach\ncan be directly extended to many other types of RST. These are used for\nformulating an extended concept of knowledge interpretation (KI)(relative the\nsituation for classical RST) and the problem of knowledge representation (KR)\nis solved. These will be of direct interest in granular KR in RST as developed\nby the present author [2] and of rough objects in general. In [3], these have\nalready been used for five different semantics by the present author. This is\nan extended version of [4] with key examples and more results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 14:08:00 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2013 09:03:41 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1212.6521", "submitter": "Jan Koutn\\'ik", "authors": "Jan Koutn\\'ik, Juergen Schmidhuber, Faustino Gomez", "title": "A Frequency-Domain Encoding for Neuroevolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution has yet to scale up to complex reinforcement learning tasks\nthat require large networks. Networks with many inputs (e.g. raw video) imply a\nvery high dimensional search space if encoded directly. Indirect methods use a\nmore compact genotype representation that is transformed into networks of\npotentially arbitrary size. In this paper, we present an indirect method where\nnetworks are encoded by a set of Fourier coefficients which are transformed\ninto network weight matrices via an inverse Fourier-type transform. Because\nthere often exist network solutions whose weight matrices contain regularity\n(i.e. adjacent weights are correlated), the number of coefficients required to\nrepresent these networks in the frequency domain is much smaller than the\nnumber of weights (in the same way that natural images can be compressed by\nignore high-frequency components). This \"compressed\" encoding is compared to\nthe direct approach where search is conducted in the weight space on the\nhigh-dimensional octopus arm task. The results show that representing networks\nin the frequency domain can reduce the search-space dimensionality by as much\nas two orders of magnitude, both accelerating convergence and yielding more\ngeneral solutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 14:23:02 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Koutn\u00edk", "Jan", ""], ["Schmidhuber", "Juergen", ""], ["Gomez", "Faustino", ""]]}, {"id": "1212.6527", "submitter": "Eugene Yuta Bann", "authors": "Eugene Yuta Bann", "title": "Discovering Basic Emotion Sets via Semantic Clustering on a Twitter\n  Corpus", "comments": "University of Bath BSc(Hons) Computer Science Dissertation, 105 Pages", "journal-ref": null, "doi": null, "report-no": "CSBU-2013-01", "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of words are used to describe the spectrum of human emotions, but\nhow many emotions are there really, and how do they interact? Over the past few\ndecades, several theories of emotion have been proposed, each based around the\nexistence of a set of 'basic emotions', and each supported by an extensive\nvariety of research including studies in facial expression, ethology, neurology\nand physiology. Here we present research based on a theory that people transmit\ntheir understanding of emotions through the language they use surrounding\nemotion keywords. Using a labelled corpus of over 21,000 tweets, six of the\nbasic emotion sets proposed in existing literature were analysed using Latent\nSemantic Clustering (LSC), evaluating the distinctiveness of the semantic\nmeaning attached to the emotional label. We hypothesise that the more distinct\nthe language is used to express a certain emotion, then the more distinct the\nperception (including proprioception) of that emotion is, and thus more\n'basic'. This allows us to select the dimensions best representing the entire\nspectrum of emotion. We find that Ekman's set, arguably the most frequently\nused for classifying emotions, is in fact the most semantically distinct\noverall. Next, taking all analysed (that is, previously proposed) emotion terms\ninto account, we determine the optimal semantically irreducible basic emotion\nset using an iterative LSC algorithm. Our newly-derived set (Accepting,\nAshamed, Contempt, Interested, Joyful, Pleased, Sleepy, Stressed) generates a\n6.1% increase in distinctiveness over Ekman's set (Angry, Disgusted, Joyful,\nSad, Scared). We also demonstrate how using LSC data can help visualise\nemotions. We introduce the concept of an Emotion Profile and briefly analyse\ncompound emotions both visually and mathematically.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 15:39:46 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Bann", "Eugene Yuta", ""]]}, {"id": "1212.6550", "submitter": "Andre Martins", "authors": "Andre F. T. Martins, Mario A. T. Figueiredo, Pedro M. Q. Aguiar, Noah\n  A. Smith, Eric P. Xing", "title": "Alternating Directions Dual Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AD3, a new algorithm for approximate maximum a posteriori (MAP)\ninference on factor graphs based on the alternating directions method of\nmultipliers. Like dual decomposition algorithms, AD3 uses worker nodes to\niteratively solve local subproblems and a controller node to combine these\nlocal solutions into a global update. The key characteristic of AD3 is that\neach local subproblem has a quadratic regularizer, leading to a faster\nconsensus than subgradient-based dual decomposition, both theoretically and in\npractice. We provide closed-form solutions for these AD3 subproblems for binary\npairwise factors and factors imposing first-order logic constraints. For\narbitrary factors (large or combinatorial), we introduce an active set method\nwhich requires only an oracle for computing a local MAP configuration, making\nAD3 applicable to a wide range of problems. Experiments on synthetic and\nrealworld problems show that AD3 compares favorably with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 18:38:57 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Martins", "Andre F. T.", ""], ["Figueiredo", "Mario A. T.", ""], ["Aguiar", "Pedro M. Q.", ""], ["Smith", "Noah A.", ""], ["Xing", "Eric P.", ""]]}, {"id": "1212.6659", "submitter": "Raphael Pelossof", "authors": "Raphael Pelossof and Zhiliang Ying", "title": "Focus of Attention for Linear Predictors", "comments": "9 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1105.0382", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to stop the evaluation of a prediction process when the\nresult of the full evaluation is obvious. This trait is highly desirable in\nprediction tasks where a predictor evaluates all its features for every example\nin large datasets. We observe that some examples are easier to classify than\nothers, a phenomenon which is characterized by the event when most of the\nfeatures agree on the class of an example. By stopping the feature evaluation\nwhen encountering an easy- to-classify example, the predictor can achieve\nsubstantial gains in computation. Our method provides a natural attention\nmechanism for linear predictors where the predictor concentrates most of its\ncomputation on hard-to-classify examples and quickly discards easy-to-classify\nones. By modifying a linear prediction algorithm such as an SVM or AdaBoost to\ninclude our attentive method we prove that the average number of features\ncomputed is O(sqrt(n log 1/sqrt(delta))) where n is the original number of\nfeatures, and delta is the error rate incurred due to early stopping. We\ndemonstrate the effectiveness of Attentive Prediction on MNIST, Real-sim,\nGisette, and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2012 20:23:48 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Pelossof", "Raphael", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1212.6837", "submitter": "Hai Nguyen", "authors": "Hai Nguyen and Charles C. Kemp", "title": "Autonomously Learning to Visually Detect Where Manipulation Will Succeed", "comments": "15 pages, 10 figures. Submitted to the Autonomous Robots Journal\n  Special Issue \"Beyond Grasping - Modern Approaches for Dexterous\n  Manipulation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual features can help predict if a manipulation behavior will succeed at a\ngiven location. For example, the success of a behavior that flips light\nswitches depends on the location of the switch. Within this paper, we present\nmethods that enable a mobile manipulator to autonomously learn a function that\ntakes an RGB image and a registered 3D point cloud as input and returns a 3D\nlocation at which a manipulation behavior is likely to succeed. Given a pair of\nmanipulation behaviors that can change the state of the world between two sets\n(e.g., light switch up and light switch down), classifiers that detect when\neach behavior has been successful, and an initial hint as to where one of the\nbehaviors will be successful, the robot autonomously trains a pair of support\nvector machine (SVM) classifiers by trying out the behaviors at locations in\nthe world and observing the results. When an image feature vector associated\nwith a 3D location is provided as input to one of the SVMs, the SVM predicts if\nthe associated manipulation behavior will be successful at the 3D location. To\nevaluate our approach, we performed experiments with a PR2 robot from Willow\nGarage in a simulated home using behaviors that flip a light switch, push a\nrocker-type light switch, and operate a drawer. By using active learning, the\nrobot efficiently learned SVMs that enabled it to consistently succeed at these\ntasks. After training, the robot also continued to learn in order to adapt in\nthe event of failure.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 08:39:14 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Nguyen", "Hai", ""], ["Kemp", "Charles C.", ""]]}, {"id": "1212.6846", "submitter": "Sagar Kale", "authors": "Sagar Kale", "title": "Maximizing a Nonnegative, Monotone, Submodular Function Constrained to\n  Matchings", "comments": "Withdrawn because the main result is implied by a more general result\n  about p-independence-system (which generalize matchings) in the paper by\n  Calinescu, Chekuri, Pal, and Vondrak, Maximizing a Monotone Submodular\n  Function Subject to a Matroid Constraint, SIAM J. Comput., 2011, Vol 40, No\n  6, pp. 1740-1766", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions have many applications. Matchings have many\napplications. The bitext word alignment problem can be modeled as the problem\nof maximizing a nonnegative, monotone, submodular function constrained to\nmatchings in a complete bipartite graph where each vertex corresponds to a word\nin the two input sentences and each edge represents a potential word-to-word\ntranslation. We propose a more general problem of maximizing a nonnegative,\nmonotone, submodular function defined on the edge set of a complete graph\nconstrained to matchings; we call this problem the CSM-Matching problem.\nCSM-Matching also generalizes the maximum-weight matching problem, which has a\npolynomial-time algorithm; however, we show that it is NP-hard to approximate\nCSM-Matching within a factor of e/(e-1) by reducing the max k-cover problem to\nit. Our main result is a simple, greedy, 3-approximation algorithm for\nCSM-Matching. Then we reduce CSM-Matching to maximizing a nonnegative,\nmonotone, submodular function over two matroids, i.e., CSM-2-Matroids.\nCSM-2-Matroids has a (2+epsilon)-approximation algorithm - called LSV2. We show\nthat we can find a (4+epsilon)-approximate solution to CSM-Matching using LSV2.\nWe extend this approach to similar problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 09:32:51 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 21:20:45 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kale", "Sagar", ""]]}]