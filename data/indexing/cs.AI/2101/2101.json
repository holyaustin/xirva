[{"id": "2101.00001", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf", "title": "Etat de l'art sur l'application des bandits multi-bras", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Multi-armed bandit offer the advantage to learn and exploit the already\nlearnt knowledge at the same time. This capability allows this approach to be\napplied in different domains, going from clinical trials where the goal is\ninvestigating the effects of different experimental treatments while minimizing\npatient losses, to adaptive routing where the goal is to minimize the delays in\na network. This article provides a review of the recent results on applying\nbandit to real-life scenario and summarize the state of the art for each of\nthese fields. Different techniques has been proposed to solve this problem\nsetting, like epsilon-greedy, Upper confident bound (UCB) and Thompson Sampling\n(TS). We are showing here how this algorithms were adapted to solve the\ndifferent problems of exploration exploitation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:12:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bouneffouf", "Djallel", ""]]}, {"id": "2101.00058", "submitter": "Mark Law", "authors": "Mark Law", "title": "Conflict-driven Inductive Logic Programming", "comments": "Submitted to the Theory and Practice of Logic Programming (TPLP) --\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Inductive Logic Programming (ILP) is to learn a program that\nexplains a set of examples. Until recently, most research on ILP targeted\nlearning Prolog programs. The ILASP system instead learns Answer Set Programs\n(ASP). Learning such expressive programs widens the applicability of ILP\nconsiderably; for example, enabling preference learning, learning common-sense\nknowledge, including defaults and exceptions, and learning non-deterministic\ntheories.\n  Early versions of ILASP can be considered meta-level ILP approaches, which\nencode a learning task as a logic program and delegate the search to an ASP\nsolver. More recently, ILASP has shifted towards a new method, inspired by\nconflict-driven SAT and ASP solvers. The fundamental idea of the approach,\ncalled Conflict-driven ILP (CDILP), is to iteratively interleave the search for\na hypothesis with the generation of constraints which explain why the current\nhypothesis does not cover a particular example. These coverage constraints\nallow ILASP to rule out not just the current hypothesis, but an entire class of\nhypotheses that do not satisfy the coverage constraint.\n  This paper formalises the CDILP approach and presents the ILASP3 and ILASP4\nsystems for CDILP, which are demonstrated to be more scalable than previous\nILASP systems, particularly in the presence of noise.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 20:24:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Law", "Mark", ""]]}, {"id": "2101.00063", "submitter": "Xiaohan Chen", "authors": "Xiaohan Chen, Yu Cheng, Shuohang Wang, Zhe Gan, Zhangyang Wang,\n  Jingjing Liu", "title": "EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets", "comments": "Accepted at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavily overparameterized language models such as BERT, XLNet and T5 have\nachieved impressive success in many NLP tasks. However, their high model\ncomplexity requires enormous computation resources and extremely long training\ntime for both pre-training and fine-tuning. Many works have studied model\ncompression on large NLP models, but only focusing on reducing inference time\nwhile still requiring an expensive training process. Other works use extremely\nlarge batch sizes to shorten the pre-training time, at the expense of higher\ncomputational resource demands. In this paper, inspired by the Early-Bird\nLottery Tickets recently studied for computer vision tasks, we propose\nEarlyBERT, a general computationally-efficient training algorithm applicable to\nboth pre-training and fine-tuning of large-scale language models. By slimming\nthe self-attention and fully-connected sub-layers inside a transformer, we are\nthe first to identify structured winning tickets in the early stage of BERT\ntraining. We apply those tickets towards efficient BERT training, and conduct\ncomprehensive pre-training and fine-tuning experiments on GLUE and SQuAD\ndownstream tasks. Our results show that EarlyBERT achieves comparable\nperformance to standard BERT, with 35~45% less training time. Code is available\nat https://github.com/VITA-Group/EarlyBERT.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 20:38:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 18:26:28 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chen", "Xiaohan", ""], ["Cheng", "Yu", ""], ["Wang", "Shuohang", ""], ["Gan", "Zhe", ""], ["Wang", "Zhangyang", ""], ["Liu", "Jingjing", ""]]}, {"id": "2101.00073", "submitter": "Nanchun Shi", "authors": "Zhifeng Yu, Nanchun Shi", "title": "A Multi-modal Deep Learning Model for Video Thumbnail Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thumbnail is the face of online videos. The explosive growth of videos both\nin number and variety underpins the importance of a good thumbnail because it\nsaves potential viewers time to choose videos and even entice them to click on\nthem. A good thumbnail should be a frame that best represents the content of a\nvideo while at the same time capturing viewers' attention. However, the\ntechniques and models in the past only focus on frames within a video, and we\nbelieve such narrowed focus leave out much useful information that are part of\na video. In this paper, we expand the definition of content to include title,\ndescription, and audio of a video and utilize information provided by these\nmodalities in our selection model. Specifically, our model will first sample\nframes uniformly in time and return the top 1,000 frames in this subset with\nthe highest aesthetic scores by a Double-column Convolutional Neural Network,\nto avoid the computational burden of processing all frames in downstream task.\nThen, the model incorporates frame features extracted from VGG16, text features\nfrom ELECTRA, and audio features from TRILL. These models were selected because\nof their results on popular datasets as well as their competitive performances.\nAfter feature extraction, the time-series features, frames and audio, will be\nfed into Transformer encoder layers to return a vector representing their\ncorresponding modality. Each of the four features (frames, title, description,\naudios) will pass through a context gating layer before concatenation. Finally,\nour model will generate a vector in the latent space and select the frame that\nis most similar to this vector in the latent space. To the best of our\nknowledge, we are the first to propose a multi-modal deep learning model to\nselect video thumbnail, which beats the result from the previous\nState-of-The-Art models.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 21:10:09 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yu", "Zhifeng", ""], ["Shi", "Nanchun", ""]]}, {"id": "2101.00124", "submitter": "I-Hung Hsu", "authors": "I-Hung Hsu, Xiao Guo, Wael AbdAlmageed, Premkumar Natarajan, Nanyun\n  Peng", "title": "MrGCN: Mirror Graph Convolution Network for Relation Extraction with\n  Long-Term Dependencies", "comments": "13 pages, page 11-13 appendix, 7 figures. The first two authors\n  contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to capture complex linguistic structures and long-term\ndependencies among words in the passage is essential for relation extraction\n(RE) tasks. Graph neural networks (GNNs), one of the means to encode dependency\ngraphs, have been shown to be effective in prior works. However, relatively\nlittle attention has been paid to receptive fields of GNNs, which can be\ncrucial for tasks with extremely long text that requires discourse\nunderstanding. In this work, we leverage the idea of graph pooling and propose\nthe Mirror Graph Convolution Network, a GNN model with a pooling-unpooling\nstructure tailored to RE tasks. The pooling branch reduces the graph size and\nenables the GNN to obtain larger receptive fields within fewer layers; the\nunpooling branch restores the pooled graph to its original resolution for\ntoken-level RE tasks. Experiments on two discourse-level relation extraction\ndatasets demonstrate the effectiveness of our method, showing significant\nimprovements over prior methods especially when modeling long-term dependencies\nis necessary. Moreover, we propose Clause Matching (CM), a novel graph pooling\nmethod that merges nodes based on dependency relations in graph. CM can largely\nreduce the graph size while retaining the main semantics of the input text.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 00:52:53 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 07:33:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hsu", "I-Hung", ""], ["Guo", "Xiao", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""], ["Peng", "Nanyun", ""]]}, {"id": "2101.00133", "submitter": "Sewon Min", "authors": "Sewon Min, Jordan Boyd-Graber, Chris Alberti, Danqi Chen, Eunsol Choi,\n  Michael Collins, Kelvin Guu, Hannaneh Hajishirzi, Kenton Lee, Jennimaria\n  Palomaki, Colin Raffel, Adam Roberts, Tom Kwiatkowski, Patrick Lewis, Yuxiang\n  Wu, Heinrich K\\\"uttler, Linqing Liu, Pasquale Minervini, Pontus Stenetorp,\n  Sebastian Riedel, Sohee Yang, Minjoon Seo, Gautier Izacard, Fabio Petroni,\n  Lucas Hosseini, Nicola De Cao, Edouard Grave, Ikuya Yamada, Sonse Shimaoka,\n  Masatoshi Suzuki, Shumpei Miyawaki, Shun Sato, Ryo Takahashi, Jun Suzuki,\n  Martin Fajcik, Martin Docekal, Karel Ondrej, Pavel Smrz, Hao Cheng, Yelong\n  Shen, Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao, Barlas Oguz,\n  Xilun Chen, Vladimir Karpukhin, Stan Peshterliev, Dmytro Okhonko, Michael\n  Schlichtkrull, Sonal Gupta, Yashar Mehdad, Wen-tau Yih", "title": "NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons\n  Learned", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We review the EfficientQA competition from NeurIPS 2020. The competition\nfocused on open-domain question answering (QA), where systems take natural\nlanguage questions as input and return natural language answers. The aim of the\ncompetition was to build systems that can predict correct answers while also\nsatisfying strict on-disk memory budgets. These memory budgets were designed to\nencourage contestants to explore the trade-off between storing large,\nredundant, retrieval corpora or the parameters of large learned models. In this\nreport, we describe the motivation and organization of the competition, review\nthe best submissions, and analyze system predictions to inform a discussion of\nevaluation for open-domain QA.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 01:24:34 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Min", "Sewon", ""], ["Boyd-Graber", "Jordan", ""], ["Alberti", "Chris", ""], ["Chen", "Danqi", ""], ["Choi", "Eunsol", ""], ["Collins", "Michael", ""], ["Guu", "Kelvin", ""], ["Hajishirzi", "Hannaneh", ""], ["Lee", "Kenton", ""], ["Palomaki", "Jennimaria", ""], ["Raffel", "Colin", ""], ["Roberts", "Adam", ""], ["Kwiatkowski", "Tom", ""], ["Lewis", "Patrick", ""], ["Wu", "Yuxiang", ""], ["K\u00fcttler", "Heinrich", ""], ["Liu", "Linqing", ""], ["Minervini", "Pasquale", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""], ["Yang", "Sohee", ""], ["Seo", "Minjoon", ""], ["Izacard", "Gautier", ""], ["Petroni", "Fabio", ""], ["Hosseini", "Lucas", ""], ["De Cao", "Nicola", ""], ["Grave", "Edouard", ""], ["Yamada", "Ikuya", ""], ["Shimaoka", "Sonse", ""], ["Suzuki", "Masatoshi", ""], ["Miyawaki", "Shumpei", ""], ["Sato", "Shun", ""], ["Takahashi", "Ryo", ""], ["Suzuki", "Jun", ""], ["Fajcik", "Martin", ""], ["Docekal", "Martin", ""], ["Ondrej", "Karel", ""], ["Smrz", "Pavel", ""], ["Cheng", "Hao", ""], ["Shen", "Yelong", ""], ["Liu", "Xiaodong", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Gao", "Jianfeng", ""], ["Oguz", "Barlas", ""], ["Chen", "Xilun", ""], ["Karpukhin", "Vladimir", ""], ["Peshterliev", "Stan", ""], ["Okhonko", "Dmytro", ""], ["Schlichtkrull", "Michael", ""], ["Gupta", "Sonal", ""], ["Mehdad", "Yashar", ""], ["Yih", "Wen-tau", ""]]}, {"id": "2101.00151", "submitter": "Hung Le", "authors": "Hung Le and Chinnadhurai Sankar and Seungwhan Moon and Ahmad Beirami\n  and Alborz Geramifard and Satwik Kottur", "title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded\n  Dialogue", "comments": "20 pages, 14 figures, 8 tables", "journal-ref": "Association for Computational Linguistics (2021)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A video-grounded dialogue system is required to understand both dialogue,\nwhich contains semantic dependencies from turn to turn, and video, which\ncontains visual cues of spatial and temporal scene variations. Building such\ndialogue systems is a challenging problem, involving various reasoning types on\nboth visual and language inputs. Existing benchmarks do not have enough\nannotations to thoroughly analyze dialogue systems and understand their\ncapabilities and limitations in isolation. These benchmarks are also not\nexplicitly designed to minimise biases that models can exploit without actual\nreasoning. To address these limitations, in this paper, we present DVD, a\nDiagnostic Dataset for Video-grounded Dialogues. The dataset is designed to\ncontain minimal biases and has detailed annotations for the different types of\nreasoning over the spatio-temporal space of video. Dialogues are synthesized\nover multiple question turns, each of which is injected with a set of\ncross-turn semantic relationships. We use DVD to analyze existing approaches,\nproviding interesting insights into their abilities and limitations. In total,\nDVD is built from $11k$ CATER synthetic videos and contains $10$ instances of\n$10$-round dialogues for each video, resulting in more than $100k$ dialogues\nand $1M$ question-answer pairs. Our code and dataset are publicly available at\nhttps://github.com/facebookresearch/DVDialogues.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 03:20:22 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:55:57 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Le", "Hung", ""], ["Sankar", "Chinnadhurai", ""], ["Moon", "Seungwhan", ""], ["Beirami", "Ahmad", ""], ["Geramifard", "Alborz", ""], ["Kottur", "Satwik", ""]]}, {"id": "2101.00154", "submitter": "Tianqing Fang", "authors": "Tianqing Fang, Hongming Zhang, Weiqi Wang, Yangqiu Song, Bin He", "title": "DISCOS: Bridging the Gap between Discourse Knowledge and Commonsense\n  Knowledge", "comments": "WWW 2021 paper. 12 pages and 6 Figures", "journal-ref": null, "doi": "10.1145/3442381.3450117", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge is crucial for artificial intelligence systems to\nunderstand natural language. Previous commonsense knowledge acquisition\napproaches typically rely on human annotations (for example, ATOMIC) or text\ngeneration models (for example, COMET.) Human annotation could provide\nhigh-quality commonsense knowledge, yet its high cost often results in\nrelatively small scale and low coverage. On the other hand, generation models\nhave the potential to automatically generate more knowledge. Nonetheless,\nmachine learning models often fit the training data well and thus struggle to\ngenerate high-quality novel knowledge. To address the limitations of previous\napproaches, in this paper, we propose an alternative commonsense knowledge\nacquisition framework DISCOS (from DIScourse to COmmonSense), which\nautomatically populates expensive complex commonsense knowledge to more\naffordable linguistic knowledge resources. Experiments demonstrate that we can\nsuccessfully convert discourse knowledge about eventualities from ASER, a\nlarge-scale discourse knowledge graph, into if-then commonsense knowledge\ndefined in ATOMIC without any additional annotation effort. Further study\nsuggests that DISCOS significantly outperforms previous supervised approaches\nin terms of novelty and diversity with comparable quality. In total, we can\nacquire 3.4M ATOMIC-like inferential commonsense knowledge by populating ATOMIC\non the core part of ASER. Codes and data are available at\nhttps://github.com/HKUST-KnowComp/DISCOS-commonsense.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 03:30:38 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 12:43:37 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Fang", "Tianqing", ""], ["Zhang", "Hongming", ""], ["Wang", "Weiqi", ""], ["Song", "Yangqiu", ""], ["He", "Bin", ""]]}, {"id": "2101.00173", "submitter": "Kai Yi", "authors": "Mohamed Elhoseiny, Kai Yi, Mohamed Elfeki", "title": "CIZSL++: Creativity Inspired Generative Zero-Shot Learning", "comments": "This paper is an extended version of a paper published on the\n  International Conference on Computer Vision (ICCV), held in Seoul, Republic\n  of Korea, October 27-Nov 2nd, 2019 CIZSL-v2 code is available here\n  https://github.com/Vision-CAIR/CIZSLv2. arXiv admin note: substantial text\n  overlap with arXiv:1904.01109", "journal-ref": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Elhoseiny_Creativity_Inspired_Zero-Shot_Learning_ICCV_2019_paper.pdf", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-shot learning (ZSL) aims at understanding unseen categories with no\ntraining examples from class-level descriptions. To improve the discriminative\npower of ZSL, we model the visual learning process of unseen categories with\ninspiration from the psychology of human creativity for producing novel art.\nFirst, we propose CIZSL-v1 as a creativity inspired model for generative ZSL.\nWe relate ZSL to human creativity by observing that ZSL is about recognizing\nthe unseen, and creativity is about creating a likable unseen. We introduce a\nlearning signal inspired by creativity literature that explores the unseen\nspace with hallucinated class-descriptions and encourages careful deviation of\ntheir visual feature generations from seen classes while allowing knowledge\ntransfer from seen to unseen classes. Second, CIZSL-v2 is proposed as an\nimproved version of CIZSL-v1 for generative zero-shot learning. CIZSL-v2\nconsists of an investigation of additional inductive losses for unseen classes\nalong with a semantic guided discriminator. Empirically, we show consistently\nthat CIZSL losses can improve generative ZSL models on the challenging task of\ngeneralized ZSL from a noisy text on CUB and NABirds datasets. We also show the\nadvantage of our approach to Attribute-based ZSL on AwA2, aPY, and SUN\ndatasets. We also show that CIZSL-v2 has improved performance compared to\nCIZSL-v1.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 05:47:57 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 09:08:51 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Elhoseiny", "Mohamed", ""], ["Yi", "Kai", ""], ["Elfeki", "Mohamed", ""]]}, {"id": "2101.00178", "submitter": "Hao Cheng", "authors": "Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng He, Weizhu Chen,\n  Jianfeng Gao", "title": "UnitedQA: A Hybrid Approach for Open Domain Question Answering", "comments": "ACL 2021 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, most of recent work under the retrieval-reader framework for\nopen-domain QA focuses on either extractive or generative reader exclusively.\nIn this paper, we study a hybrid approach for leveraging the strengths of both\nmodels. We apply novel techniques to enhance both extractive and generative\nreaders built upon recent pretrained neural language models, and find that\nproper training methods can provide large improvement over previous\nstate-of-the-art models. We demonstrate that a simple hybrid approach by\ncombining answers from both readers can efficiently take advantages of\nextractive and generative answer inference strategies and outperforms single\nmodels as well as homogeneous ensembles. Our approach outperforms previous\nstate-of-the-art models by 3.3 and 2.7 points in exact match on\nNaturalQuestions and TriviaQA respectively.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 06:36:16 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 18:07:48 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Cheng", "Hao", ""], ["Shen", "Yelong", ""], ["Liu", "Xiaodong", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2101.00200", "submitter": "Chang Keun Paik", "authors": "Chang Keun Paik, Naeun Ko, Youngjoon Yoo", "title": "More than just an auxiliary loss: Anti-spoofing Backbone Training via\n  Adversarial Pseudo-depth Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new method of training pipeline is discussed to achieve\nsignificant performance on the task of anti-spoofing with RGB image. We explore\nand highlight the impact of using pseudo-depth to pre-train a network that will\nbe used as the backbone to the final classifier. While the usage of\npseudo-depth for anti-spoofing task is not a new idea on its own, previous\nendeavours utilize pseudo-depth simply as another medium to extract features\nfor performing prediction, or as part of many auxiliary losses in aiding the\ntraining of the main classifier, normalizing the importance of pseudo-depth as\njust another semantic information. Through this work, we argue that there\nexists a significant advantage in training the final classifier can be gained\nby the pre-trained generator learning to predict the corresponding pseudo-depth\nof a given facial image, from a Generative Adversarial Network framework. Our\nexperimental results indicate that our method results in a much more adaptable\nsystem that can generalize beyond intra-dataset samples, but to inter-dataset\nsamples, which it has never seen before during training. Quantitatively, our\nmethod approaches the baseline performance of the current state of the art\nanti-spoofing models with 15.8x less parameters used. Moreover, experiments\nshowed that the introduced methodology performs well only using basic binary\nlabel without additional semantic information which indicates potential\nbenefits of this work in industrial and application based environment where\ntrade-off between additional labelling and resources are considered.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 09:00:17 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 04:57:42 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Paik", "Chang Keun", ""], ["Ko", "Naeun", ""], ["Yoo", "Youngjoon", ""]]}, {"id": "2101.00203", "submitter": "Anish Madan", "authors": "Anish Madan, Ranjitha Prasad", "title": "B-SMALL: A Bayesian Neural Network approach to Sparse Model-Agnostic\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the learning-to-learn paradigm, also known as\nmeta-learning, where models infer on new tasks using a few training examples.\nRecently, meta-learning based methods have been widely used in few-shot\nclassification, regression, reinforcement learning, and domain adaptation. The\nmodel-agnostic meta-learning (MAML) algorithm is a well-known algorithm that\nobtains model parameter initialization at meta-training phase. In the meta-test\nphase, this initialization is rapidly adapted to new tasks by using gradient\ndescent. However, meta-learning models are prone to overfitting since there are\ninsufficient training tasks resulting in over-parameterized models with poor\ngeneralization performance for unseen tasks. In this paper, we propose a\nBayesian neural network based MAML algorithm, which we refer to as the B-SMALL\nalgorithm. The proposed framework incorporates a sparse variational loss term\nalongside the loss function of MAML, which uses a sparsifying approximated KL\ndivergence as a regularizer. We demonstrate the performance of B-MAML using\nclassification and regression tasks, and highlight that training a sparsifying\nBNN using MAML indeed improves the parameter footprint of the model while\nperforming at par or even outperforming the MAML approach. We also illustrate\napplicability of our approach in distributed sensor networks, where sparsity\nand meta-learning can be beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 09:19:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Madan", "Anish", ""], ["Prasad", "Ranjitha", ""]]}, {"id": "2101.00280", "submitter": "Joar Skalse", "authors": "Joar Skalse", "title": "A General Counterexample to Any Decision Theory and Some Responses", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I present an argument and a general schema which can be used to\nconstruct a problem case for any decision theory, in a way that could be taken\nto show that one cannot formulate a decision theory that is never outperformed\nby any other decision theory. I also present and discuss a number of possible\nresponses to this argument. One of these responses raises the question of what\nit means for two decision problems to be \"equivalent\" in the relevant sense,\nand gives an answer to this question which would invalidate the first argument.\nHowever, this position would have further consequences for how we compare\ndifferent decision theories in decision problems already discussed in the\nliterature (including e.g. Newcomb's problem).\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 17:47:11 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Skalse", "Joar", ""]]}, {"id": "2101.00286", "submitter": "Valentina Anita Carriero", "authors": "Valentina Anita Carriero, Aldo Gangemi, Andrea Giovanni Nuzzolese,\n  Valentina Presutti", "title": "An Ontology Design Pattern for representing Recurrent Situations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an Ontology Design Pattern for representing\nsituations that recur at regular periods and share some invariant factors,\nwhich unify them conceptually: we refer to this set of recurring situations as\nrecurrent situation series. The proposed pattern appears to be foundational,\nsince it can be generalised for modelling the top-level domain-independent\nconcept of recurrence, which is strictly associated with invariance. The\npattern reuses other foundational patterns such as Collection, Description and\nSituation, Classification, Sequence. Indeed, a recurrent situation series is\nformalised as both a collection of situations occurring regularly over time and\nunified according to some properties that are common to all the members, and a\nsituation itself, which provides a relational context to its members that\nsatisfy a reference description. Besides including some exemplifying instances\nof this pattern, we show how it has been implemented and specialised to model\nrecurrent cultural events and ceremonies in ArCo, the Knowledge Graph of\nItalian cultural heritage.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 18:20:13 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Carriero", "Valentina Anita", ""], ["Gangemi", "Aldo", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""]]}, {"id": "2101.00294", "submitter": "Yuning Mao", "authors": "Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao,\n  Jiawei Han, Weizhu Chen", "title": "Reader-Guided Passage Reranking for Open-Domain Question Answering", "comments": "Findings of ACL 2021 Camera-ready. TLDR: Reranking retrieved passages\n  by reader predictions can achieve 10~20 gains in top-1 retrieval accuracy and\n  1~4 gains in Exact Match (EM) without any training", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current open-domain question answering systems often follow a\nRetriever-Reader architecture, where the retriever first retrieves relevant\npassages and the reader then reads the retrieved passages to form an answer. In\nthis paper, we propose a simple and effective passage reranking method, named\nReader-guIDEd Reranker (RIDER), which does not involve training and reranks the\nretrieved passages solely based on the top predictions of the reader before\nreranking. We show that RIDER, despite its simplicity, achieves 10 to 20\nabsolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) gains\nwithout refining the retriever or reader. In addition, RIDER, without any\ntraining, outperforms state-of-the-art transformer-based supervised rerankers.\nRemarkably, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 EM\non the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are\nused as the reader input after passage reranking.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 18:54:19 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 22:17:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mao", "Yuning", ""], ["He", "Pengcheng", ""], ["Liu", "Xiaodong", ""], ["Shen", "Yelong", ""], ["Gao", "Jianfeng", ""], ["Han", "Jiawei", ""], ["Chen", "Weizhu", ""]]}, {"id": "2101.00295", "submitter": "Ali Tourani", "authors": "Ali Tourani, Sajjad Soroori, Asadollah Shahbahrami, and Alireza\n  Akoushideh", "title": "Iranis: A Large-scale Dataset of Farsi License Plate Characters", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing huge amounts of data is a fundamental demand when dealing with Deep\nNeural Networks (DNNs). Employing these algorithms to solve computer vision\nproblems resulted in the advent of various image datasets to feed the most\ncommon visual imagery deep structures, known as Convolutional Neural Networks\n(CNNs). In this regard, some datasets can be found that contain hundreds or\neven thousands of images for license plate detection and optical character\nrecognition purposes. However, no publicly available image dataset provides\nsuch data for the recognition of Farsi characters used in car license plates.\nThe gap has to be filled due to the numerous advantages of developing accurate\ndeep learning-based systems for law enforcement and surveillance purposes. This\npaper introduces a large-scale dataset that includes images of numbers and\ncharacters used in Iranian car license plates. The dataset, named Iranis,\ncontains more than 83,000 images of Farsi numbers and letters collected from\nreal-world license plate images captured by various cameras. The variety of\ninstances in terms of camera shooting angle, illumination, resolution, and\ncontrast make the dataset a proper choice for training DNNs. Dataset images are\nmanually annotated for object detection and image classification. Finally, and\nto build a baseline for Farsi character recognition, the paper provides a\nperformance analysis using a YOLO v.3 object detector.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 18:54:44 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Tourani", "Ali", ""], ["Soroori", "Sajjad", ""], ["Shahbahrami", "Asadollah", ""], ["Akoushideh", "Alireza", ""]]}, {"id": "2101.00300", "submitter": "Dhruv Malik", "authors": "Dhruv Malik, Yuanzhi Li, Pradeep Ravikumar", "title": "When Is Generalizable Reinforcement Learning Tractable?", "comments": "v2 extends results to function approximation setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained by reinforcement learning (RL) often fail to generalize beyond\nthe environment they were trained in, even when presented with new scenarios\nthat seem similar to the training environment. We study the query complexity\nrequired to train RL agents that generalize to multiple environments.\nIntuitively, tractable generalization is only possible when the environments\nare similar or close in some sense. To capture this, we introduce Weak\nProximity, a natural structural condition that requires the environments to\nhave highly similar transition and reward functions and share a policy\nproviding optimal value. Despite such shared structure, we prove that tractable\ngeneralization is impossible in the worst case. This holds even when each\nindividual environment can be efficiently solved to obtain an optimal linear\npolicy, and when the agent possesses a generative model. Our lower bound\napplies to the more complex task of representation learning for the purpose of\nefficient generalization to multiple environments. On the positive side, we\nintroduce Strong Proximity, a strengthened condition which we prove is\nsufficient for efficient generalization.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 19:08:24 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 01:35:52 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Malik", "Dhruv", ""], ["Li", "Yuanzhi", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2101.00316", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Bo Hu, Xiongchang Liu, Jun Lu, Jane You, Lingsheng Kong", "title": "Energy-constrained Self-training for Unsupervised Domain Adaptation", "comments": "Accepted to 25th International Conference on Pattern Recognition\n  (ICPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to transfer the knowledge on a\nlabeled source domain distribution to perform well on an unlabeled target\ndomain. Recently, the deep self-training involves an iterative process of\npredicting on the target domain and then taking the confident predictions as\nhard pseudo-labels for retraining. However, the pseudo-labels are usually\nunreliable, and easily leading to deviated solutions with propagated errors. In\nthis paper, we resort to the energy-based model and constrain the training of\nthe unlabeled target sample with the energy function minimization objective. It\ncan be applied as a simple additional regularization. In this framework, it is\npossible to gain the benefits of the energy-based model, while retaining strong\ndiscriminative performance following a plug-and-play fashion. We deliver\nextensive experiments on the most popular and large scale UDA benchmarks of\nimage classification as well as semantic segmentation to demonstrate its\ngenerality and effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 21:02:18 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Hu", "Bo", ""], ["Liu", "Xiongchang", ""], ["Lu", "Jun", ""], ["You", "Jane", ""], ["Kong", "Lingsheng", ""]]}, {"id": "2101.00317", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Linghao Jin, Xu Han, Jun Lu, Jane You, Lingsheng Kong", "title": "Identity-aware Facial Expression Recognition in Compressed Video", "comments": "Accepted as the Oral paper at ICPR 2020 (<4.4%). arXiv admin note:\n  substantial text overlap with arXiv:2010.10637", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper targets to explore the inter-subject variations eliminated facial\nexpression representation in the compressed video domain. Most of the previous\nmethods process the RGB images of a sequence, while the off-the-shelf and\nvaluable expression-related muscle movement already embedded in the compression\nformat. In the up to two orders of magnitude compressed domain, we can\nexplicitly infer the expression from the residual frames and possible to\nextract identity factors from the I frame with a pre-trained face recognition\nnetwork. By enforcing the marginal independent of them, the expression feature\nis expected to be purer for the expression and be robust to identity shifts. We\ndo not need the identity label or multiple expression samples from the same\nperson for identity elimination. Moreover, when the apex frame is annotated in\nthe dataset, the complementary constraint can be further added to regularize\nthe feature-level game. In testing, only the compressed residual frames are\nrequired to achieve expression prediction. Our solution can achieve comparable\nor better performance than the recent decoded image based methods on the\ntypical FER benchmarks with about 3$\\times$ faster inference with compressed\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 21:03:13 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 23:46:22 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Jin", "Linghao", ""], ["Han", "Xu", ""], ["Lu", "Jun", ""], ["You", "Jane", ""], ["Kong", "Lingsheng", ""]]}, {"id": "2101.00318", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Xiongchang Liu, Bo Hu, Wenxuan Ji, Fangxu Xing, Jun Lu,\n  Jane You, C.-C. Jay Kuo, Georges El Fakhri, Jonghye Woo", "title": "Subtype-aware Unsupervised Domain Adaptation for Medical Diagnosis", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in unsupervised domain adaptation (UDA) show that\ntransferable prototypical learning presents a powerful means for class\nconditional alignment, which encourages the closeness of cross-domain class\ncentroids. However, the cross-domain inner-class compactness and the underlying\nfine-grained subtype structure remained largely underexplored. In this work, we\npropose to adaptively carry out the fine-grained subtype-aware alignment by\nexplicitly enforcing the class-wise separation and subtype-wise compactness\nwith intermediate pseudo labels. Our key insight is that the unlabeled subtypes\nof a class can be divergent to one another with different conditional and label\nshifts, while inheriting the local proximity within a subtype. The cases of\nwith or without the prior information on subtype numbers are investigated to\ndiscover the underlying subtype structure in an online fashion. The proposed\nsubtype-aware dynamic UDA achieves promising results on medical diagnosis\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 21:04:50 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 15:09:03 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Liu", "Xiongchang", ""], ["Hu", "Bo", ""], ["Ji", "Wenxuan", ""], ["Xing", "Fangxu", ""], ["Lu", "Jun", ""], ["You", "Jane", ""], ["Kuo", "C. -C. Jay", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2101.00345", "submitter": "Yasumasa Onoe", "authors": "Yasumasa Onoe, Michael Boratko, Andrew McCallum, Greg Durrett", "title": "Modeling Fine-Grained Entity Types with Box Embeddings", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural entity typing models typically represent fine-grained entity types as\nvectors in a high-dimensional space, but such spaces are not well-suited to\nmodeling these types' complex interdependencies. We study the ability of box\nembeddings, which embed concepts as d-dimensional hyperrectangles, to capture\nhierarchies of types even when these relationships are not defined explicitly\nin the ontology. Our model represents both types and entity mentions as boxes.\nEach mention and its context are fed into a BERT-based model to embed that\nmention in our box space; essentially, this model leverages typological clues\npresent in the surface text to hypothesize a type representation for the\nmention. Box containment can then be used to derive both the posterior\nprobability of a mention exhibiting a given type and the conditional\nprobability relations between types themselves. We compare our approach with a\nvector-based typing model and observe state-of-the-art performance on several\nentity typing benchmarks. In addition to competitive typing performance, our\nbox-based model shows better performance in prediction consistency (predicting\na supertype and a subtype together) and confidence (i.e., calibration),\ndemonstrating that the box-based model captures the latent type hierarchies\nbetter than the vector-based model does.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 00:59:10 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 05:51:55 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Onoe", "Yasumasa", ""], ["Boratko", "Michael", ""], ["McCallum", "Andrew", ""], ["Durrett", "Greg", ""]]}, {"id": "2101.00355", "submitter": "Lei Zhang", "authors": "Yehua Wei, Lei Zhang, Ruiyi Zhang, Shijing Si, Hao Zhang, Lawrence\n  Carin", "title": "Reinforcement Learning for Flexibility Design Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Flexibility design problems are a class of problems that appear in strategic\ndecision-making across industries, where the objective is to design a ($e.g.$,\nmanufacturing) network that affords flexibility and adaptivity. The underlying\ncombinatorial nature and stochastic objectives make flexibility design problems\nchallenging for standard optimization methods. In this paper, we develop a\nreinforcement learning (RL) framework for flexibility design problems.\nSpecifically, we carefully design mechanisms with noisy exploration and\nvariance reduction to ensure empirical success and show the unique advantage of\nRL in terms of fast-adaptation. Empirical results show that the RL-based method\nconsistently finds better solutions compared to classical heuristics.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 02:44:39 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 14:35:06 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wei", "Yehua", ""], ["Zhang", "Lei", ""], ["Zhang", "Ruiyi", ""], ["Si", "Shijing", ""], ["Zhang", "Hao", ""], ["Carin", "Lawrence", ""]]}, {"id": "2101.00360", "submitter": "Pingyi Fan Prof.", "authors": "Pingyi Fan", "title": "New-Type Hoeffding's Inequalities and Application in Tail Bounds", "comments": "8 pages, 1 figure", "journal-ref": "Open Journal of Mathematical Sciences Vol.5 No.1 pp.248 -261, 2021", "doi": "10.30538/oms2021.0161", "report-no": "ISSN: 2523-0212 (Online) 2616-4906 (Print)", "categories": "math.ST cs.AI cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Hoeffding's inequality has a lot of applications in the\nsignal and information processing fields. How to improve Hoeffding's inequality\nand find the refinements of its applications have always attracted much\nattentions. An improvement of Hoeffding inequality was recently given by Hertz\n\\cite{r1}. Eventhough such an improvement is not so big, it still can be used\nto update many known results with original Hoeffding's inequality, especially\nfor Hoeffding-Azuma inequality for martingales. However, the results in\noriginal Hoeffding's inequality and its refinement one by Hertz only considered\nthe first order moment of random variables. In this paper, we present a new\ntype of Hoeffding's inequalities, where the high order moments of random\nvariables are taken into account. It can get some considerable improvements in\nthe tail bounds evaluation compared with the known results. It is expected that\nthe developed new type Hoeffding's inequalities could get more interesting\napplications in some related fields that use Hoeffding's results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 03:19:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fan", "Pingyi", ""]]}, {"id": "2101.00376", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Ziyi Wu, Yichi Yang, Dong-Ho Lee, Xiang Ren", "title": "RiddleSense: Reasoning about Riddle Questions Featuring Linguistic\n  Creativity and Commonsense Knowledge", "comments": "Accepted to ACL 2021 (Findings). Project page:\n  https://inklab.usc.edu/RiddleSense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Question: I have five fingers but I am not alive. What am I? Answer: a glove.\nAnswering such a riddle-style question is a challenging cognitive process, in\nthat it requires complex commonsense reasoning abilities, an understanding of\nfigurative language, and counterfactual reasoning skills, which are all\nimportant abilities for advanced natural language understanding (NLU). However,\nthere are currently no dedicated datasets aiming to test these abilities.\nHerein, we present RiddleSense, a new multiple-choice question answering task,\nwhich comes with the first large dataset (5.7k examples) for answering\nriddle-style commonsense questions. We systematically evaluate a wide range of\nmodels over the challenge, and point out that there is a large gap between the\nbest-supervised model and human performance -- suggesting intriguing future\nresearch in the direction of higher-order commonsense reasoning and linguistic\ncreativity towards building advanced NLU systems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 05:28:15 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 22:50:32 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Wu", "Ziyi", ""], ["Yang", "Yichi", ""], ["Lee", "Dong-Ho", ""], ["Ren", "Xiang", ""]]}, {"id": "2101.00388", "submitter": "Houjin Yu", "authors": "Houjin Yu, Xian-Ling Mao, Zewen Chi, Wei Wei and Heyan Huang", "title": "A Robust and Domain-Adaptive Approach for Low-Resource Named Entity\n  Recognition", "comments": "Best Student Paper of 2020 IEEE International Conference on Knowledge\n  Graph (ICKG)", "journal-ref": "2020 IEEE International Conference on Knowledge Graph (ICKG) (pp.\n  297-304)-", "doi": "10.1109/ICBK50248.2020.00050", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has attracted much attention to build reliable named entity\nrecognition (NER) systems using limited annotated data. Nearly all existing\nworks heavily rely on domain-specific resources, such as external lexicons and\nknowledge bases. However, such domain-specific resources are often not\navailable, meanwhile it's difficult and expensive to construct the resources,\nwhich has become a key obstacle to wider adoption. To tackle the problem, in\nthis work, we propose a novel robust and domain-adaptive approach RDANER for\nlow-resource NER, which only uses cheap and easily obtainable resources.\nExtensive experiments on three benchmark datasets demonstrate that our approach\nachieves the best performance when only using cheap and easily obtainable\nresources, and delivers competitive results against state-of-the-art methods\nwhich use difficultly obtainable domainspecific resources. All our code and\ncorpora can be found on https://github.com/houking-can/RDANER.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 06:47:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yu", "Houjin", ""], ["Mao", "Xian-Ling", ""], ["Chi", "Zewen", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "2101.00407", "submitter": "Liyuan Wang", "authors": "Liyuan Wang, Kuo Yang, Chongxuan Li, Lanqing Hong, Zhenguo Li, Jun Zhu", "title": "ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for\n  Semi-supervised Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning usually assumes the incoming data are fully labeled, which\nmight not be applicable in real applications. In this work, we consider\nsemi-supervised continual learning (SSCL) that incrementally learns from\npartially labeled data. Observing that existing continual learning methods lack\nthe ability to continually exploit the unlabeled data, we propose deep Online\nReplay with Discriminator Consistency (ORDisCo) to interdependently learn a\nclassifier with a conditional generative adversarial network (GAN), which\ncontinually passes the learned data distribution to the classifier. In\nparticular, ORDisCo replays data sampled from the conditional generator to the\nclassifier in an online manner, exploiting unlabeled data in a time- and\nstorage-efficient way. Further, to explicitly overcome the catastrophic\nforgetting of unlabeled data, we selectively stabilize parameters of the\ndiscriminator that are important for discriminating the pairs of old unlabeled\ndata and their pseudo-labels predicted by the classifier. We extensively\nevaluate ORDisCo on various semi-supervised learning benchmark datasets for\nSSCL, and show that ORDisCo achieves significant performance improvement on\nSVHN, CIFAR10 and Tiny-ImageNet, compared to strong baselines.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 09:04:14 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 01:57:03 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wang", "Liyuan", ""], ["Yang", "Kuo", ""], ["Li", "Chongxuan", ""], ["Hong", "Lanqing", ""], ["Li", "Zhenguo", ""], ["Zhu", "Jun", ""]]}, {"id": "2101.00408", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Mostofa Patwary and Mohammad Shoeybi and\n  Neel Kant and Wei Ping and William L Hamilton and Bryan Catanzaro", "title": "End-to-End Training of Neural Retrievers for Open-Domain Question\n  Answering", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on training neural retrievers for open-domain question answering\n(OpenQA) has employed both supervised and unsupervised approaches. However, it\nremains unclear how unsupervised and supervised methods can be used most\neffectively for neural retrievers. In this work, we systematically study\nretriever pre-training. We first propose an approach of unsupervised\npre-training with the Inverse Cloze Task and masked salient spans, followed by\nsupervised finetuning using question-context pairs. This approach leads to\nabsolute gains of 2+ points over the previous best result in the top-20\nretrieval accuracy on Natural Questions and TriviaQA datasets.\n  We also explore two approaches for end-to-end supervised training of the\nreader and retriever components in OpenQA models. In the first approach, the\nreader considers each retrieved document separately while in the second\napproach, the reader considers all the retrieved documents together. Our\nexperiments demonstrate the effectiveness of these approaches as we obtain new\nstate-of-the-art results. On the Natural Questions dataset, we obtain a top-20\nretrieval accuracy of 84, an improvement of 5 points over the recent DPR model.\nIn addition, we achieve good results on answer extraction, outperforming recent\nmodels like REALM and RAG by 3+ points. We further scale up end-to-end training\nto large models and show consistent gains in performance over smaller models.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 09:05:34 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 02:46:38 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Patwary", "Mostofa", ""], ["Shoeybi", "Mohammad", ""], ["Kant", "Neel", ""], ["Ping", "Wei", ""], ["Hamilton", "William L", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2101.00433", "submitter": "Michael Saxon", "authors": "Michael Saxon, Sharon Levy, Xinyi Wang, Alon Albalak, William Yang\n  Wang", "title": "Modeling Discolsive Transparency in NLP Application Descriptions", "comments": "14 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Broader disclosive transparency$-$truth and clarity in communication\nregarding the function of AI systems$-$is widely considered desirable.\nUnfortunately, it is a nebulous concept, difficult to both define and quantify.\nPrevious work has suggested that a trade-off exists between greater disclosive\ntransparency and user confusion, where 'too much information' clouds a reader's\nunderstanding of what a system description means. We address both of these\nissues by connecting disclosive transparency to a \"replication room\" thought\nexperiment, where the person describing the system attempts to convey the\nrequisite information for a third party to reconstruct it. In this setting, the\ndegree to which the necessary information is conveyed represents the\ndescription's transparency, and the level of expertise needed by the third\nparty corresponds to potential user confusion. We introduce two neural language\nmodel-based probabilistic metrics to model these factors, and demonstrate that\nthey correlate with user and expert opinions of system transparency, making\nthem a valid objective proxy. Finally, we apply these metrics to study the\nrelationships between transparency, confusion, and user perceptions in a corpus\nof NLP demo abstracts.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 11:46:17 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 03:42:18 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Saxon", "Michael", ""], ["Levy", "Sharon", ""], ["Wang", "Xinyi", ""], ["Albalak", "Alon", ""], ["Wang", "William Yang", ""]]}, {"id": "2101.00441", "submitter": "Jakub Marecek", "authors": "Sam D. Allen and Edmund K.Burke and Jakub Marecek", "title": "A space-indexed formulation of packing boxes into a larger box", "comments": "arXiv admin note: substantial text overlap with arXiv:1412.2526", "journal-ref": "Operations Research Letters, Volume 40, Issue 1, January 2012,\n  Pages 20-24", "doi": "10.1016/j.orl.2011.10.008", "report-no": null, "categories": "math.OC cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current integer programming solvers fail to decide whether 12 unit cubes can\nbe packed into a 1x1x11 box within an hour using the natural relaxation of\nChen/Padberg. We present an alternative relaxation of the problem of packing\nboxes into a larger box, which makes it possible to solve much larger\ninstances.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 12:10:47 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Allen", "Sam D.", ""], ["Burke", "Edmund K.", ""], ["Marecek", "Jakub", ""]]}, {"id": "2101.00464", "submitter": "Sami Khairy", "authors": "Sami Khairy, Prasanna Balaprakash, Lin X. Cai, H. Vincent Poor", "title": "Data-Driven Random Access Optimization in Multi-Cell IoT Networks with\n  NOMA", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) is a key technology to enable massive\nmachine type communications (mMTC) in 5G networks and beyond. In this paper,\nNOMA is applied to improve the random access efficiency in high-density\nspatially-distributed multi-cell wireless IoT networks, where IoT devices\ncontend for accessing the shared wireless channel using an adaptive\np-persistent slotted Aloha protocol. To enable a capacity-optimal network, a\nnovel formulation of random channel access management is proposed, in which the\ntransmission probability of each IoT device is tuned to maximize the geometric\nmean of users' expected capacity. It is shown that the network optimization\nobjective is high dimensional and mathematically intractable, yet it admits\nfavourable mathematical properties that enable the design of efficient\ndata-driven algorithmic solutions which do not require a priori knowledge of\nthe channel model or network topology. A centralized model-based algorithm and\na scalable distributed model-free algorithm, are proposed to optimally tune the\ntransmission probabilities of IoT devices and attain the maximum capacity. The\nconvergence of the proposed algorithms to the optimal solution is further\nestablished based on convex optimization and game-theoretic analysis. Extensive\nsimulations demonstrate the merits of the novel formulation and the efficacy of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 15:21:08 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 14:44:13 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Khairy", "Sami", ""], ["Balaprakash", "Prasanna", ""], ["Cai", "Lin X.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2101.00485", "submitter": "Pavel Naumov", "authors": "Sanaz Azimipour and Pavel Naumov", "title": "If You're Happy, Then You Know It: The Logic of Happiness... and Sadness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article proposes a formal semantics of happiness and sadness modalities\nin imperfect information setting. It shows that these modalities are not\ndefinable through each other and gives a sound and complete axiomatization of\ntheir properties.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 17:42:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Azimipour", "Sanaz", ""], ["Naumov", "Pavel", ""]]}, {"id": "2101.00494", "submitter": "Lin Yang", "authors": "Minbo Gao, Tianle Xie, Simon S. Du, Lin F. Yang", "title": "A Provably Efficient Algorithm for Linear Markov Decision Process with\n  Low Switching Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications, such as those in medical domains,\nrecommendation systems, etc, can be formulated as large state space\nreinforcement learning problems with only a small budget of the number of\npolicy changes, i.e., low switching cost. This paper focuses on the linear\nMarkov Decision Process (MDP) recently studied in [Yang et al 2019, Jin et al\n2020] where the linear function approximation is used for generalization on the\nlarge state space. We present the first algorithm for linear MDP with a low\nswitching cost. Our algorithm achieves an\n$\\widetilde{O}\\left(\\sqrt{d^3H^4K}\\right)$ regret bound with a near-optimal\n$O\\left(d H\\log K\\right)$ global switching cost where $d$ is the feature\ndimension, $H$ is the planning horizon and $K$ is the number of episodes the\nagent plays. Our regret bound matches the best existing polynomial algorithm by\n[Jin et al 2020] and our switching cost is exponentially smaller than theirs.\nWhen specialized to tabular MDP, our switching cost bound improves those in\n[Bai et al 2019, Zhang et al 20020]. We complement our positive result with an\n$\\Omega\\left(dH/\\log d\\right)$ global switching cost lower bound for any\nno-regret algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 18:41:27 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Gao", "Minbo", ""], ["Xie", "Tianle", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""]]}, {"id": "2101.00509", "submitter": "Benjamin Maschler", "authors": "Benjamin Maschler, Thi Thu Huong Pham, Michael Weyrich", "title": "Regularization-based Continual Learning for Anomaly Detection in\n  Discrete Manufacturing", "comments": "6 pages, 5 figures, 3 tables, submitted to the CIRP Conference on\n  Manufacturing Systems 2021", "journal-ref": null, "doi": "10.13140/RG.2.2.15631.00163", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early and robust detection of anomalies occurring in discrete\nmanufacturing processes allows operators to prevent harm, e.g. defects in\nproduction machinery or products. While current approaches for data-driven\nanomaly detection provide good results on the exact processes they were trained\non, they often lack the ability to flexibly adapt to changes, e.g. in products.\nContinual learning promises such flexibility, allowing for an automatic\nadaption of previously learnt knowledge to new tasks. Therefore, this article\ndiscusses different continual learning approaches from the group of\nregularization strategies, which are implemented, evaluated and compared based\non a real industrial metal forming dataset.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 20:06:00 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Maschler", "Benjamin", ""], ["Pham", "Thi Thu Huong", ""], ["Weyrich", "Michael", ""]]}, {"id": "2101.00521", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz, Ambareen Siraj, Denis Ulybyshev", "title": "Improving DGA-Based Malicious Domain Classifiers for Malware Defense\n  with Adversarial Machine Learning", "comments": "10 pages, 6 figures , 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Generation Algorithms (DGAs) are used by adversaries to establish\nCommand and Control (C\\&C) server communications during cyber attacks.\nBlacklists of known/identified C\\&C domains are often used as one of the\ndefense mechanisms. However, since blacklists are static and generated by\nsignature-based approaches, they can neither keep up nor detect\nnever-seen-before malicious domain names. Due to this shortcoming of blacklist\ndomain checking, machine learning algorithms have been used to address the\nproblem to some extent. However, when training is performed with limited\ndatasets, the algorithms are likely to fail in detecting new DGA variants. To\nmitigate this weakness, we successfully applied a DGA-based malicious domain\nclassifier using the Long Short-Term Memory (LSTM) method with a novel feature\nengineering technique. Our model's performance shows a higher level of accuracy\ncompared to a previously reported model from prior research. Additionally, we\npropose a new method using adversarial machine learning to generate\nnever-before-seen malware-related domain families that can be used to\nillustrate the shortcomings of machine learning algorithms in this regard.\nNext, we augment the training dataset with new samples such that it makes\ntraining of the machine learning models more effective in detecting\nnever-before-seen malicious domain name variants. Finally, to protect\nblacklists of malicious domain names from disclosure and tampering, we devise\nsecure data containers that store blacklists and guarantee their protection\nagainst adversarial access and modifications.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 22:04:22 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yilmaz", "Ibrahim", ""], ["Siraj", "Ambareen", ""], ["Ulybyshev", "Denis", ""]]}, {"id": "2101.00529", "submitter": "Pengchuan Zhang", "authors": "Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang,\n  Lijuan Wang, Yejin Choi, Jianfeng Gao", "title": "VinVL: Revisiting Visual Representations in Vision-Language Models", "comments": null, "journal-ref": "CVPR 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a detailed study of improving visual representations for\nvision language (VL) tasks and develops an improved object detection model to\nprovide object-centric representations of images. Compared to the most widely\nused \\emph{bottom-up and top-down} model \\cite{anderson2018bottom}, the new\nmodel is bigger, better-designed for VL tasks, and pre-trained on much larger\ntraining corpora that combine multiple public annotated object detection\ndatasets. Therefore, it can generate representations of a richer collection of\nvisual objects and concepts. While previous VL research focuses mainly on\nimproving the vision-language fusion model and leaves the object detection\nmodel improvement untouched, we show that visual features matter significantly\nin VL models. In our experiments we feed the visual features generated by the\nnew object detection model into a Transformer-based VL fusion model \\oscar\n\\cite{li2020oscar}, and utilize an improved approach \\short\\ to pre-train the\nVL model and fine-tune it on a wide range of downstream VL tasks. Our results\nshow that the new visual features significantly improve the performance across\nall VL tasks, creating new state-of-the-art results on seven public benchmarks.\nWe will release the new object detection model to public.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 23:35:27 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 01:27:16 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Zhang", "Pengchuan", ""], ["Li", "Xiujun", ""], ["Hu", "Xiaowei", ""], ["Yang", "Jianwei", ""], ["Zhang", "Lei", ""], ["Wang", "Lijuan", ""], ["Choi", "Yejin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2101.00540", "submitter": "Zeming Chen", "authors": "Zeming Chen", "title": "Attentive Tree-structured Network for Monotonicity Reasoning", "comments": "Proceeding of the First Workshop on Natural Logic Meets Machine\n  Learning, Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many state-of-art neural models designed for monotonicity reasoning perform\npoorly on downward inference. To address this shortcoming, we developed an\nattentive tree-structured neural network. It consists of a tree-based\nlong-short-term-memory network (Tree-LSTM) with soft attention. It is designed\nto model the syntactic parse tree information from the sentence pair of a\nreasoning task. A self-attentive aggregator is used for aligning the\nrepresentations of the premise and the hypothesis. We present our model and\nevaluate it using the Monotonicity Entailment Dataset (MED). We show and\nattempt to explain that our model outperforms existing models on MED.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 01:29:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Chen", "Zeming", ""]]}, {"id": "2101.00545", "submitter": "Ashraful Islam", "authors": "Ashraful Islam, Chengjiang Long, Richard Radke", "title": "A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action\n  Localization", "comments": "Extended version/preprint of a AAAI 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weakly supervised temporal action localization is a challenging vision task\ndue to the absence of ground-truth temporal locations of actions in the\ntraining videos. With only video-level supervision during training, most\nexisting methods rely on a Multiple Instance Learning (MIL) framework to\npredict the start and end frame of each action category in a video. However,\nthe existing MIL-based approach has a major limitation of only capturing the\nmost discriminative frames of an action, ignoring the full extent of an\nactivity. Moreover, these methods cannot model background activity effectively,\nwhich plays an important role in localizing foreground activities. In this\npaper, we present a novel framework named HAM-Net with a hybrid attention\nmechanism which includes temporal soft, semi-soft and hard attentions to\naddress these issues. Our temporal soft attention module, guided by an\nauxiliary background class in the classification module, models the background\nactivity by introducing an \"action-ness\" score for each video snippet.\nMoreover, our temporal semi-soft and hard attention modules, calculating two\nattention scores for each video snippet, help to focus on the less\ndiscriminative frames of an action to capture the full action boundary. Our\nproposed approach outperforms recent state-of-the-art methods by at least 2.2%\nmAP at IoU threshold 0.5 on the THUMOS14 dataset, and by at least 1.3% mAP at\nIoU threshold 0.75 on the ActivityNet1.2 dataset. Code can be found at:\nhttps://github.com/asrafulashiq/hamnet.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 03:08:18 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 02:30:59 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 23:15:35 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Islam", "Ashraful", ""], ["Long", "Chengjiang", ""], ["Radke", "Richard", ""]]}, {"id": "2101.00562", "submitter": "Arkabandhu Chowdhury", "authors": "Arkabandhu Chowdhury, Mingchao Jiang, Chris Jermaine", "title": "Few-shot Image Classification: Just Use a Library of Pre-trained Feature\n  Extractors and a Simple Classifier", "comments": "17 pages including appendix and references. 2 figures in the main\n  paper, 1 figure in appendix. Under submission at a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers have suggested that transfer learning can outperform\nsophisticated meta-learning methods for few-shot image classification. We take\nthis hypothesis to its logical conclusion, and suggest the use of an ensemble\nof high-quality, pre-trained feature extractors for few-shot image\nclassification. We show experimentally that a library of pre-trained feature\nextractors combined with a simple feed-forward network learned with an\nL2-regularizer can be an excellent option for solving cross-domain few-shot\nimage classification. Our experimental results suggest that this simpler\nsample-efficient approach far outperforms several well-established\nmeta-learning algorithms on a variety of few-shot tasks.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 05:30:36 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Chowdhury", "Arkabandhu", ""], ["Jiang", "Mingchao", ""], ["Jermaine", "Chris", ""]]}, {"id": "2101.00574", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Santiago Benoit, Louis-Philippe Morency", "title": "StarNet: Gradient-free Training of Deep Generative Models using\n  Determined System of Linear Equations", "comments": "Work in progress at CMU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present an approach for training deep generative models\nsolely based on solving determined systems of linear equations. A network that\nuses this approach, called a StarNet, has the following desirable properties:\n1) training requires no gradient as solution to the system of linear equations\nis not stochastic, 2) is highly scalable when solving the system of linear\nequations w.r.t the latent codes, and similarly for the parameters of the\nmodel, and 3) it gives desirable least-square bounds for the estimation of\nlatent codes and network parameters within each layer.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 08:06:42 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zadeh", "Amir", ""], ["Benoit", "Santiago", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2101.00589", "submitter": "Matthias Nickles", "authors": "Matthias Nickles", "title": "diff-SAT -- A Software for Sampling and Probabilistic Reasoning for SAT\n  and Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes diff-SAT, an Answer Set and SAT solver which combines\nregular solving with the capability to use probabilistic clauses, facts and\nrules, and to sample an optimal world-view (multiset of satisfying Boolean\nvariable assignments or answer sets) subject to user-provided probabilistic\nconstraints. The sampling process minimizes a user-defined differentiable\nobjective function using a gradient descent based optimization method called\nDifferentiable Satisfiability Solving ($\\partial\\mathrm{SAT}$) respectively\nDifferentiable Answer Set Programming ($\\partial\\mathrm{ASP}$). Use cases are\ni.a. probabilistic logic programming (in form of Probabilistic Answer Set\nProgramming), Probabilistic Boolean Satisfiability solving (PSAT), and\ndistribution-aware sampling of model multisets (answer sets or Boolean\ninterpretations).\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 09:04:31 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Nickles", "Matthias", ""]]}, {"id": "2101.00591", "submitter": "Chen Zhao", "authors": "Chen Zhao, Yixiao Ge, Feng Zhu, Rui Zhao, Hongsheng Li, Mathieu\n  Salzmann", "title": "Progressive Correspondence Pruning by Consensus Learning", "comments": "Accepted by ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Correspondence selection aims to correctly select the consistent matches\n(inliers) from an initial set of putative correspondences. The selection is\nchallenging since putative matches are typically extremely unbalanced, largely\ndominated by outliers, and the random distribution of such outliers further\ncomplicates the learning process for learning-based methods. To address this\nissue, we propose to progressively prune the correspondences via a\nlocal-to-global consensus learning procedure. We introduce a ``pruning'' block\nthat lets us identify reliable candidates among the initial matches according\nto consensus scores estimated using local-to-global dynamic graphs. We then\nachieve progressive pruning by stacking multiple pruning blocks sequentially.\nOur method outperforms state-of-the-arts on robust line fitting, camera pose\nestimation and retrieval-based image localization benchmarks by significant\nmargins and shows promising generalization ability to different datasets and\ndetector/descriptor combinations.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 09:10:00 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 15:23:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhao", "Chen", ""], ["Ge", "Yixiao", ""], ["Zhu", "Feng", ""], ["Zhao", "Rui", ""], ["Li", "Hongsheng", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "2101.00604", "submitter": "Jizhe Zhou", "authors": "Jizhe Zhou, Chi-Man Pun, Yu Tong", "title": "Privacy-sensitive Objects Pixelation for Live Video Streaming", "comments": null, "journal-ref": null, "doi": "10.1145/3394171.3413972", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the prevailing of live video streaming, establishing an online\npixelation method for privacy-sensitive objects is an urgency. Caused by the\ninaccurate detection of privacy-sensitive objects, simply migrating the\ntracking-by-detection structure into the online form will incur problems in\ntarget initialization, drifting, and over-pixelation. To cope with the\ninevitable but impacting detection issue, we propose a novel Privacy-sensitive\nObjects Pixelation (PsOP) framework for automatic personal privacy filtering\nduring live video streaming. Leveraging pre-trained detection networks, our\nPsOP is extendable to any potential privacy-sensitive objects pixelation.\nEmploying the embedding networks and the proposed Positioned Incremental\nAffinity Propagation (PIAP) clustering algorithm as the backbone, our PsOP\nunifies the pixelation of discriminating and indiscriminating pixelation\nobjects through trajectories generation. In addition to the pixelation accuracy\nboosting, experiments on the streaming video data we built show that the\nproposed PsOP can significantly reduce the over-pixelation ratio in\nprivacy-sensitive object pixelation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 11:07:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhou", "Jizhe", ""], ["Pun", "Chi-Man", ""], ["Tong", "Yu", ""]]}, {"id": "2101.00646", "submitter": "Tong Xia", "authors": "Tong Xia and Yunhan Qi and Jie Feng and Fengli Xu and Funing Sun and\n  Diansheng Guo and Yong Li", "title": "AttnMove: History Enhanced Trajectory Recovery via Attentional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A considerable amount of mobility data has been accumulated due to the\nproliferation of location-based service. Nevertheless, compared with mobility\ndata from transportation systems like the GPS module in taxis, this kind of\ndata is commonly sparse in terms of individual trajectories in the sense that\nusers do not access mobile services and contribute their data all the time.\nConsequently, the sparsity inevitably weakens the practical value of the data\neven it has a high user penetration rate. To solve this problem, we propose a\nnovel attentional neural network-based model, named AttnMove, to densify\nindividual trajectories by recovering unobserved locations at a fine-grained\nspatial-temporal resolution. To tackle the challenges posed by sparsity, we\ndesign various intra- and inter- trajectory attention mechanisms to better\nmodel the mobility regularity of users and fully exploit the periodical pattern\nfrom long-term history. We evaluate our model on two real-world datasets, and\nextensive results demonstrate the performance gain compared with the\nstate-of-the-art methods. This also shows that, by providing high-quality\nmobility data, our model can benefit a variety of mobility-oriented down-stream\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 15:45:35 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Xia", "Tong", ""], ["Qi", "Yunhan", ""], ["Feng", "Jie", ""], ["Xu", "Fengli", ""], ["Sun", "Funing", ""], ["Guo", "Diansheng", ""], ["Li", "Yong", ""]]}, {"id": "2101.00674", "submitter": "Dennis Ulmer", "authors": "Dennis Ulmer", "title": "Recoding latent sentence representations -- Dynamic gradient-based\n  activation modification in RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Recurrent Neural Networks (RNNs), encoding information in a suboptimal or\nerroneous way can impact the quality of representations based on later elements\nin the sequence and subsequently lead to wrong predictions and a worse model\nperformance. In humans, challenging cases like garden path sentences (an\ninstance of this being the infamous \"The horse raced past the barn fell\") can\nlead their language understanding astray. However, they are still able to\ncorrect their representation accordingly and recover when new information is\nencountered. Inspired by this, I propose an augmentation to standard RNNs in\nform of a gradient-based correction mechanism: This way I hope to enable such\nmodels to dynamically adapt their inner representation of a sentence, adding a\nway to correct deviations as soon as they occur. This could therefore lead to\nmore robust models using more flexible representations, even during inference\ntime.\n  I conduct different experiments in the context of language modeling, where\nthe impact of using such a mechanism is examined in detail. To this end, I look\nat modifications based on different kinds of time-dependent error signals and\nhow they influence the model performance. Furthermore, this work contains a\nstudy of the model's confidence in its predictions during training and for\nchallenging test samples and the effect of the manipulation thereof. Lastly, I\nalso study the difference in behavior of these novel models compared to a\nstandard LSTM baseline and investigate error cases in detail to identify points\nof future research. I show that while the proposed approach comes with\npromising theoretical guarantees and an appealing intuition, it is only able to\nproduce minor improvements over the baseline due to challenges in its practical\napplication and the efficacy of the tested model variants.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 17:54:17 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ulmer", "Dennis", ""]]}, {"id": "2101.00675", "submitter": "Mohamad Alissa", "authors": "Mohamad Alissa, Issa Haddad, Jonathan Meyer, Jade Obeid, Nicolas\n  Wiecek, Sukrit Wongariyakavee", "title": "Sentiment Analysis for Open Domain Conversational Agent", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The applicability of common sentiment analysis models to open domain human\nrobot interaction is investigated within this paper. The models are used on a\ndataset specific to user interaction with the Alana system (a Alexa prize\nsystem) in order to determine which would be more appropriate for the task of\nidentifying sentiment when a user interacts with a non-human driven socialbot.\nWith the identification of a model, various improvements are attempted and\ndetailed prior to integration into the Alana system. The study showed that a\nRandom Forest Model with 25 trees trained on the dataset specific to user\ninteraction with the Alana system combined with the dataset present in NLTK\nVader outperforms other models. The new system (called 'Rob') matches it's\noutput utterance sentiment with the user's utterance sentiment. This method is\nexpected to improve user experience because it builds upon the overall\nsentiment detection which makes it seem that new system sympathises with user\nfeelings. Furthermore, the results obtained from the user feedback confirms our\nexpectation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 18:03:52 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 23:33:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Alissa", "Mohamad", ""], ["Haddad", "Issa", ""], ["Meyer", "Jonathan", ""], ["Obeid", "Jade", ""], ["Wiecek", "Nicolas", ""], ["Wongariyakavee", "Sukrit", ""]]}, {"id": "2101.00687", "submitter": "Joberto Martins Prof. Dr.", "authors": "Carlos E. Arruda, Pedro F. Moraes, Nazim Agoulmine, Joberto S. B.\n  Martins", "title": "Enhanced Pub/Sub Communications for Massive IoT Traffic with SARSA\n  Reinforcement Learning", "comments": "3rd International Conference on Machine Learning for Networking - MLN\n  2020, Paris, 20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sensors are being extensively deployed and are expected to expand at\nsignificant rates in the coming years. They typically generate a large volume\nof data on the internet of things (IoT) application areas like smart cities,\nintelligent traffic systems, smart grid, and e-health. Cloud, edge and fog\ncomputing are potential and competitive strategies for collecting, processing,\nand distributing IoT data. However, cloud, edge, and fog-based solutions need\nto tackle the distribution of a high volume of IoT data efficiently through\nconstrained and limited resource network infrastructures. This paper addresses\nthe issue of conveying a massive volume of IoT data through a network with\nlimited communications resources (bandwidth) using a cognitive communications\nresource allocation based on Reinforcement Learning (RL) with SARSA algorithm.\nThe proposed network infrastructure (PSIoTRL) uses a Publish/ Subscribe\narchitecture to access massive and highly distributed IoT data. It is\ndemonstrated that the PSIoTRL bandwidth allocation for buffer flushing based on\nSARSA enhances the IoT aggregator buffer occupation and network link\nutilization. The PSIoTRL dynamically adapts the IoT aggregator traffic flushing\naccording to the Pub/Sub topic's priority and network constraint requirements.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 18:46:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Arruda", "Carlos E.", ""], ["Moraes", "Pedro F.", ""], ["Agoulmine", "Nazim", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "2101.00692", "submitter": "Guillem Franc\\`es", "authors": "Guillem Franc\\`es, Blai Bonet, Hector Geffner", "title": "Learning General Policies from Small Examples Without Supervision", "comments": "AAAI 2021, version extended with appendix containing full proofs and\n  experimental details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized planning is concerned with the computation of general policies\nthat solve multiple instances of a planning domain all at once. It has been\nrecently shown that these policies can be computed in two steps: first, a\nsuitable abstraction in the form of a qualitative numerical planning problem\n(QNP) is learned from sample plans, then the general policies are obtained from\nthe learned QNP using a planner. In this work, we introduce an alternative\napproach for computing more expressive general policies which does not require\nsample plans or a QNP planner. The new formulation is very simple and can be\ncast in terms that are more standard in machine learning: a large but finite\npool of features is defined from the predicates in the planning examples using\na general grammar, and a small subset of features is sought for separating\n\"good\" from \"bad\" state transitions, and goals from non-goals. The problems of\nfinding such a \"separating surface\" while labeling the transitions as \"good\" or\n\"bad\" are jointly addressed as a single combinatorial optimization problem\nexpressed as a Weighted Max-SAT problem. The advantage of looking for the\nsimplest policy in the given feature space that solves the given examples,\npossibly non-optimally, is that many domains have no general, compact policies\nthat are optimal. The approach yields general policies for a number of\nbenchmark domains.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 19:44:13 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 19:52:39 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Franc\u00e8s", "Guillem", ""], ["Bonet", "Blai", ""], ["Geffner", "Hector", ""]]}, {"id": "2101.00693", "submitter": "Rakesh Dhakhsina Murthy", "authors": "Rakesh Dhakshinamurthy", "title": "Neural Networks for Keyword Spotting on IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore Neural Networks (NNs) for keyword spotting (KWS) on IoT devices\nlike smart speakers and wearables. Since we target to execute our NN on a\nconstrained memory and computation footprint, we propose a CNN design that. (i)\nuses a limited number of multiplies. (ii) uses a limited number of model\nparameters.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 19:57:45 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Dhakshinamurthy", "Rakesh", ""]]}, {"id": "2101.00728", "submitter": "Dom Huh", "authors": "Dom Huh", "title": "Synthetic Embedding-based Data Generation Methods for Student\n  Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the inherent class imbalance issue within student performance datasets,\nsamples belonging to the edges of the target class distribution pose a\nchallenge for predictive machine learning algorithms to learn. In this paper,\nwe introduce a general framework for synthetic embedding-based data generation\n(SEDG), a search-based approach to generate new synthetic samples using\nembeddings to correct the detriment effects of class imbalances optimally. We\ncompare the SEDG framework to past synthetic data generation methods, including\ndeep generative models, and traditional sampling methods. In our results, we\nfind SEDG to outperform the traditional re-sampling methods for deep neural\nnetworks and perform competitively for common machine learning classifiers on\nthe student performance task in several standard performance metrics.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 23:43:36 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Huh", "Dom", ""]]}, {"id": "2101.00729", "submitter": "Ruduan Plug", "authors": "Ruduan Plug", "title": "Meta-Learning Conjugate Priors for Few-Shot Bayesian Optimization", "comments": "6 pages, 8 figures, code available on Github", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Bayesian Optimization is methodology used in statistical modelling that\nutilizes a Gaussian process prior distribution to iteratively update a\nposterior distribution towards the true distribution of the data. Finding\nunbiased informative priors to sample from is challenging and can greatly\ninfluence the outcome on the posterior distribution if only few data are\navailable. In this paper we propose a novel approach to utilize meta-learning\nto automate the estimation of informative conjugate prior distributions given a\ndistribution class. From this process we generate priors that require only few\ndata to estimate the shape parameters of the original distribution of the data.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 23:58:32 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Plug", "Ruduan", ""]]}, {"id": "2101.00737", "submitter": "Xin Tan", "authors": "Xin Tan, Longyin Zhang and Guodong Zhou", "title": "Are Eliminated Spans Useless for Coreference Resolution? Not at all", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various neural-based methods have been proposed so far for joint mention\ndetection and coreference resolution. However, existing works on coreference\nresolution are mainly dependent on filtered mention representation, while other\nspans are largely neglected. In this paper, we aim at increasing the\nutilization rate of data and investigating whether those eliminated spans are\ntotally useless, or to what extent they can improve the performance of\ncoreference resolution. To achieve this, we propose a mention representation\nrefining strategy where spans highly related to mentions are well leveraged\nusing a pointer network for representation enhancing. Notably, we utilize an\nadditional loss term in this work to encourage the diversity between entity\nclusters. Experimental results on the document-level CoNLL-2012 Shared Task\nEnglish dataset show that eliminated spans are indeed much effective and our\napproach can achieve competitive results when compared with previous\nstate-of-the-art in coreference resolution.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 02:02:49 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 02:36:13 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tan", "Xin", ""], ["Zhang", "Longyin", ""], ["Zhou", "Guodong", ""]]}, {"id": "2101.00746", "submitter": "Liwen Zhu", "authors": "Liwen Zhu, Peixi Peng, Zongqing Lu, Xiangqian Wang, Yonghong Tian", "title": "Variationally and Intrinsically motivated reinforcement learning for\n  decentralized traffic signal control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the biggest challenges in multi-agent reinforcement learning is\ncoordination, a typical application scenario of this is traffic signal control.\nRecently, it has attracted a rising number of researchers and has become a hot\nresearch field with great practical significance. In this paper, we propose a\nnovel method called MetaVRS~(Meta Variational RewardShaping) for traffic signal\ncoordination control. By heuristically applying the intrinsic reward to the\nenvironmental reward, MetaVRS can wisely capture the agent-to-agent interplay.\nBesides, latent variables generated by VAE are brought into policy for\nautomatically tradeoff between exploration and exploitation to optimize the\npolicy. In addition, meta learning was used in decoder for faster adaptation\nand better approximation. Empirically, we demonstate that MetaVRS substantially\noutperforms existing methods and shows superior adaptability, which predictably\nhas a far-reaching significance to the multi-agent traffic signal coordination\ncontrol.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 03:06:08 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 07:09:38 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 02:18:51 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 06:56:50 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Zhu", "Liwen", ""], ["Peng", "Peixi", ""], ["Lu", "Zongqing", ""], ["Wang", "Xiangqian", ""], ["Tian", "Yonghong", ""]]}, {"id": "2101.00752", "submitter": "Yuandong Wang", "authors": "Yuandong Wang and Hongzhi Yin and Tong Chen and Chunyang Liu and Ben\n  Wang and Tianyu Wo and Jie Xu", "title": "Passenger Mobility Prediction via Representation Learning for Dynamic\n  Directed and Weighted Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, ride-hailing services have been increasingly prevalent as\nthey provide huge convenience for passengers. As a fundamental problem, the\ntimely prediction of passenger demands in different regions is vital for\neffective traffic flow control and route planning. As both spatial and temporal\npatterns are indispensable passenger demand prediction, relevant research has\nevolved from pure time series to graph-structured data for modeling historical\npassenger demand data, where a snapshot graph is constructed for each time slot\nby connecting region nodes via different relational edges (e.g.,\norigin-destination relationship, geographical distance, etc.). Consequently,\nthe spatiotemporal passenger demand records naturally carry dynamic patterns in\nthe constructed graphs, where the edges also encode important information about\nthe directions and volume (i.e., weights) of passenger demands between two\nconnected regions. However, existing graph-based solutions fail to\nsimultaneously consider those three crucial aspects of dynamic, directed, and\nweighted (DDW) graphs, leading to limited expressiveness when learning graph\nrepresentations for passenger demand prediction. Therefore, we propose a novel\nspatiotemporal graph attention network, namely Gallat (Graph prediction with\nall attention) as a solution. In Gallat, by comprehensively incorporating those\nthree intrinsic properties of DDW graphs, we build three attention layers to\nfully capture the spatiotemporal dependencies among different regions across\nall historical time slots. Moreover, the model employs a subtask to conduct\npretraining so that it can obtain accurate results more quickly. We evaluate\nthe proposed model on real-world datasets, and our experimental results\ndemonstrate that Gallat outperforms the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 03:32:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wang", "Yuandong", ""], ["Yin", "Hongzhi", ""], ["Chen", "Tong", ""], ["Liu", "Chunyang", ""], ["Wang", "Ben", ""], ["Wo", "Tianyu", ""], ["Xu", "Jie", ""]]}, {"id": "2101.00774", "submitter": "Fengbin Zhu", "authors": "Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria,\n  Tat-Seng Chua", "title": "Retrieving and Reading: A Comprehensive Survey on Open-domain Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain Question Answering (OpenQA) is an important task in Natural\nLanguage Processing (NLP), which aims to answer a question in the form of\nnatural language based on large-scale unstructured documents. Recently, there\nhas been a surge in the amount of research literature on OpenQA, particularly\non techniques that integrate with neural Machine Reading Comprehension (MRC).\nWhile these research works have advanced performance to new heights on\nbenchmark datasets, they have been rarely covered in existing surveys on QA\nsystems. In this work, we review the latest research trends in OpenQA, with\nparticular attention to systems that incorporate neural MRC techniques.\nSpecifically, we begin with revisiting the origin and development of OpenQA\nsystems. We then introduce modern OpenQA architecture named \"Retriever-Reader\"\nand analyze the various systems that follow this architecture as well as the\nspecific techniques adopted in each of the components. We then discuss key\nchallenges to developing OpenQA systems and offer an analysis of benchmarks\nthat are commonly used. We hope our work would enable researchers to be\ninformed of the recent advancement and also the open challenges in OpenQA\nresearch, so as to stimulate further progress in this field.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 04:47:46 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 07:25:37 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 16:16:50 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhu", "Fengbin", ""], ["Lei", "Wenqiang", ""], ["Wang", "Chao", ""], ["Zheng", "Jianming", ""], ["Poria", "Soujanya", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2101.00793", "submitter": "Karthik E", "authors": "Karthik E", "title": "A Framework for Fast Scalable BNN Inference using Googlenet and Transfer\n  Learning", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and accurate object detection in video and image analysis is one of\nthe major beneficiaries of the advancement in computer vision systems with the\nhelp of deep learning. With the aid of deep learning, more powerful tools\nevolved, which are capable to learn high-level and deeper features and thus can\novercome the existing problems in traditional architectures of object detection\nalgorithms. The work in this thesis aims to achieve high accuracy in object\ndetection with good real-time performance.\n  In the area of computer vision, a lot of research is going into the area of\ndetection and processing of visual information, by improving the existing\nalgorithms. The binarized neural network has shown high performance in various\nvision tasks such as image classification, object detection, and semantic\nsegmentation. The Modified National Institute of Standards and Technology\ndatabase (MNIST), Canadian Institute for Advanced Research (CIFAR), and Street\nView House Numbers (SVHN) datasets are used which is implemented using a\npre-trained convolutional neural network (CNN) that is 22 layers deep.\nSupervised learning is used in the work, which classifies the particular\ndataset with the proper structure of the model. In still images, to improve\naccuracy, Googlenet is used. The final layer of the Googlenet is replaced with\nthe transfer learning to improve the accuracy of the Googlenet. At the same\ntime, the accuracy in moving images can be maintained by transfer learning\ntechniques. Hardware is the main backbone for any model to obtain faster\nresults with a large number of datasets. Here, Nvidia Jetson Nano is used which\nis a graphics processing unit (GPU), that can handle a large number of\ncomputations in the process of object detection. Results show that the accuracy\nof objects detected by the transfer learning method is more when compared to\nthe existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 06:16:52 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 07:28:38 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["E", "Karthik", ""]]}, {"id": "2101.00798", "submitter": "Quoc-Viet Pham", "authors": "Parimala M and Swarna Priya R M and Quoc-Viet Pham and Kapal Dev and\n  Praveen Kumar Reddy Maddikunta and Thippa Reddy Gadekallu and Thien Huynh-The", "title": "Fusion of Federated Learning and Industrial Internet of Things: A Survey", "comments": "This work has been submitted for possible publication. Any comments\n  and suggestions are appreciated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Internet of Things (IIoT) lays a new paradigm for the concept of\nIndustry 4.0 and paves an insight for new industrial era. Nowadays smart\nmachines and smart factories use machine learning/deep learning based models\nfor incurring intelligence. However, storing and communicating the data to the\ncloud and end device leads to issues in preserving privacy. In order to address\nthis issue, federated learning (FL) technology is implemented in IIoT by the\nresearchers nowadays to provide safe, accurate, robust and unbiased models.\nIntegrating FL in IIoT ensures that no local sensitive data is exchanged, as\nthe distribution of learning models over the edge devices has become more\ncommon with FL. Therefore, only the encrypted notifications and parameters are\ncommunicated to the central server. In this paper, we provide a thorough\noverview on integrating FL with IIoT in terms of privacy, resource and data\nmanagement. The survey starts by articulating IIoT characteristics and\nfundamentals of distributive and FL. The motivation behind integrating IIoT and\nFL for achieving data privacy preservation and on-device learning are\nsummarized. Then we discuss the potential of using machine learning, deep\nlearning and blockchain techniques for FL in secure IIoT. Further we analyze\nand summarize the ways to handle the heterogeneous and huge data. Comprehensive\nbackground on data and resource management are then presented, followed by\napplications of IIoT with FL in healthcare and automobile industry. Finally, we\nshed light on challenges, some possible solutions and potential directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 06:28:32 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["M", "Parimala", ""], ["M", "Swarna Priya R", ""], ["Pham", "Quoc-Viet", ""], ["Dev", "Kapal", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Gadekallu", "Thippa Reddy", ""], ["Huynh-The", "Thien", ""]]}, {"id": "2101.00808", "submitter": "Yaliang Li", "authors": "Yaliang Li, Daoyuan Chen, Bolin Ding, Kai Zeng, Jingren Zhou", "title": "A Pluggable Learned Index Method via Sampling and Gap Insertion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database indexes facilitate data retrieval and benefit broad applications in\nreal-world systems. Recently, a new family of index, named learned index, is\nproposed to learn hidden yet useful data distribution and incorporate such\ninformation into the learning of indexes, which leads to promising performance\nimprovements. However, the \"learning\" process of learned indexes is still\nunder-explored. In this paper, we propose a formal machine learning based\nframework to quantify the index learning objective, and study two general and\npluggable techniques to enhance the learning efficiency and learning\neffectiveness for learned indexes. With the guidance of the formal learning\nobjective, we can efficiently learn index by incorporating the proposed\nsampling technique, and learn precise index with enhanced generalization\nability brought by the proposed result-driven gap insertion technique.\n  We conduct extensive experiments on real-world datasets and compare several\nindexing methods from the perspective of the index learning objective. The\nresults show the ability of the proposed framework to help to design suitable\nindexes for different scenarios. Further, we demonstrate the effectiveness of\nthe proposed sampling technique, which achieves up to 78x construction speedup\nwhile maintaining non-degraded indexing performance. Finally, we show the gap\ninsertion technique can enhance both the static and dynamic indexing\nperformances of existing learned index methods with up to 1.59x query speedup.\nWe will release our codes and processed data for further study, which can\nenable more exploration of learned indexes from both the perspectives of\nmachine learning and database.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 07:17:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Li", "Yaliang", ""], ["Chen", "Daoyuan", ""], ["Ding", "Bolin", ""], ["Zeng", "Kai", ""], ["Zhou", "Jingren", ""]]}, {"id": "2101.00816", "submitter": "Yue Mao", "authors": "Yue Mao, Yi Shen, Chao Yu, Longjun Cai", "title": "A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis", "comments": "to appear in AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based sentiment analysis (ABSA) involves three fundamental subtasks:\naspect term extraction, opinion term extraction, and aspect-level sentiment\nclassification. Early works only focused on solving one of these subtasks\nindividually. Some recent work focused on solving a combination of two\nsubtasks, e.g., extracting aspect terms along with sentiment polarities or\nextracting the aspect and opinion terms pair-wisely. More recently, the triple\nextraction task has been proposed, i.e., extracting the (aspect term, opinion\nterm, sentiment polarity) triples from a sentence. However, previous approaches\nfail to solve all subtasks in a unified end-to-end framework. In this paper, we\npropose a complete solution for ABSA. We construct two machine reading\ncomprehension (MRC) problems and solve all subtasks by joint training two\nBERT-MRC models with parameters sharing. We conduct experiments on these\nsubtasks, and results on several benchmark datasets demonstrate the\neffectiveness of our proposed framework, which significantly outperforms\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 07:47:53 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 02:49:57 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Mao", "Yue", ""], ["Shen", "Yi", ""], ["Yu", "Chao", ""], ["Cai", "Longjun", ""]]}, {"id": "2101.00819", "submitter": "Babak Nouri-Moghaddam", "authors": "Babak Nouri-Moghaddam, Mehdi Ghazanfari, Mohammad Fathian", "title": "A Novel Bio-Inspired Hybrid Multi-Filter Wrapper Gene Selection Method\n  with Ensemble Classifier for Microarray Data", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microarray technology is known as one of the most important tools for\ncollecting DNA expression data. This technology allows researchers to\ninvestigate and examine types of diseases and their origins. However,\nmicroarray data are often associated with challenges such as small sample size,\na significant number of genes, imbalanced data, etc. that make classification\nmodels inefficient. Thus, a new hybrid solution based on multi-filter and\nadaptive chaotic multi-objective forest optimization algorithm (AC-MOFOA) is\npresented to solve the gene selection problem and construct the Ensemble\nClassifier. In the proposed solution, to reduce the dataset's dimensions, a\nmulti-filter model uses a combination of five filter methods to remove\nredundant and irrelevant genes. Then, an AC-MOFOA based on the concepts of\nnon-dominated sorting, crowding distance, chaos theory, and adaptive operators\nis presented. AC-MOFOA as a wrapper method aimed at reducing dataset\ndimensions, optimizing KELM, and increasing the accuracy of the classification,\nsimultaneously. Next, in this method, an ensemble classifier model is presented\nusing AC-MOFOA results to classify microarray data. The performance of the\nproposed algorithm was evaluated on nine public microarray datasets, and its\nresults were compared in terms of the number of selected genes, classification\nefficiency, execution time, time complexity, and hypervolume indicator\ncriterion with five hybrid multi-objective methods. According to the results,\nthe proposed hybrid method could increase the accuracy of the KELM in most\ndatasets by reducing the dataset's dimensions and achieve similar or superior\nperformance compared to other multi-objective methods. Furthermore, the\nproposed Ensemble Classifier model could provide better classification accuracy\nand generalizability in microarray data compared to conventional ensemble\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 07:57:35 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Nouri-Moghaddam", "Babak", ""], ["Ghazanfari", "Mehdi", ""], ["Fathian", "Mohammad", ""]]}, {"id": "2101.00822", "submitter": "Le Fang", "authors": "Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong, Changyou Chen", "title": "Outline to Story: Fine-grained Controllable Story Generation from\n  Cascaded Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pretrained language models have shown thrilling generation\ncapabilities, especially when they generate consistent long text in thousands\nof words with ease. However, users of these models can only control the prefix\nof sentences or certain global aspects of generated text. It is challenging to\nsimultaneously achieve fine-grained controllability and preserve the\nstate-of-the-art unconditional text generation capability. In this paper, we\nfirst propose a new task named \"Outline to Story\" (O2S) as a test bed for\nfine-grained controllable generation of long text, which generates a\nmulti-paragraph story from cascaded events, i.e. a sequence of outline events\nthat guide subsequent paragraph generation. We then create dedicate datasets\nfor future benchmarks, built by state-of-the-art keyword extraction techniques.\nFinally, we propose an extremely simple yet strong baseline method for the O2S\ntask, which fine tunes pre-trained language models on augmented sequences of\noutline-story pairs with simple language modeling objective. Our method does\nnot introduce any new parameters or perform any architecture modification,\nexcept several special tokens as delimiters to build augmented sequences.\nExtensive experiments on various datasets demonstrate state-of-the-art\nconditional story generation performance with our model, achieving better\nfine-grained controllability and user flexibility. Our paper is among the first\nones by our knowledge to propose a model and to create datasets for the task of\n\"outline to story\". Our work also instantiates research interest of\nfine-grained controllable generation of open-domain long text, where\ncontrolling inputs are represented by short text.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 08:16:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Fang", "Le", ""], ["Zeng", "Tao", ""], ["Liu", "Chaochun", ""], ["Bo", "Liefeng", ""], ["Dong", "Wen", ""], ["Chen", "Changyou", ""]]}, {"id": "2101.00828", "submitter": "Le Fang", "authors": "Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong, Changyou Chen", "title": "Transformer-based Conditional Variational Autoencoder for Controllable\n  Story Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate large-scale latent variable models (LVMs) for neural story\ngeneration -- an under-explored application for open-domain long text -- with\nobjectives in two threads: generation effectiveness and controllability. LVMs,\nespecially the variational autoencoder (VAE), have achieved both effective and\ncontrollable generation through exploiting flexible distributional latent\nrepresentations. Recently, Transformers and its variants have achieved\nremarkable effectiveness without explicit latent representation learning, thus\nlack satisfying controllability in generation. In this paper, we advocate to\nrevive latent variable modeling, essentially the power of representation\nlearning, in the era of Transformers to enhance controllability without hurting\nstate-of-the-art generation effectiveness. Specifically, we integrate latent\nrepresentation vectors with a Transformer-based pre-trained architecture to\nbuild conditional variational autoencoder (CVAE). Model components such as\nencoder, decoder and the variational posterior are all built on top of\npre-trained language models -- GPT2 specifically in this paper. Experiments\ndemonstrate state-of-the-art conditional generation ability of our model, as\nwell as its excellent representation learning capability and controllability.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 08:31:11 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 17:18:13 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Fang", "Le", ""], ["Zeng", "Tao", ""], ["Liu", "Chaochun", ""], ["Bo", "Liefeng", ""], ["Dong", "Wen", ""], ["Chen", "Changyou", ""]]}, {"id": "2101.00829", "submitter": "Shangbin Guan", "authors": "Peng Gang, Liao Jinhu, Guan Shangbin", "title": "A Pushing-Grasping Collaborative Method Based on Deep Q-Network\n  Algorithm in Dual Perspectives", "comments": "5pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming at the traditional grasping method for manipulators based on 2D\ncamera, when faced with the scene of gathering or covering, it can hardly\nperform well in unstructured scenes that appear as gathering and covering, for\nthe reason that can't recognize objects accurately in cluster scenes from a\nsingle perspective and the manipulators can't make the environment better for\ngrasping. In this case, a novel method of pushing-grasping collaborative based\non the deep Q-network in dual perspectives is proposed in this paper. This\nmethod adopts an improved deep Q network algorithm, with an RGB-D camera to\nobtain the information of objects' RGB images and point clouds from two\nperspectives, and combines the pushing and grasping actions so that the trained\nmanipulator can make the scenes better for grasping so that it can perform well\nin more complicated grasping scenes. What's more, we improved the reward\nfunction of the deep Q-network and propose the piecewise reward function to\nspeed up the convergence of the deep Q-network. We trained different models and\ntried different methods in the V-REP simulation environment, and it concluded\nthat the method proposed in this paper converges quickly and the success rate\nof grasping objects in unstructured scenes raises up to 83.5%. Besides, it\nshows the generalization ability and well performance when novel objects appear\nin the scenes that the manipulator has never grasped before.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 08:40:57 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Gang", "Peng", ""], ["Jinhu", "Liao", ""], ["Shangbin", "Guan", ""]]}, {"id": "2101.00843", "submitter": "Dennis Soemers", "authors": "Cameron Browne and Dennis J. N. J. Soemers and Eric Piette", "title": "Strategic Features for General Games", "comments": "Paper exactly as it appeared at KEG Workshop held at AAAI 2019", "journal-ref": "Proceedings of the 2nd Workshop on Knowledge Extraction from Games\n  co-located with 33rd AAAI Conference on Artificial Intelligence (AAAI 2019)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper describes an ongoing research project that requires the\nautomated self-play learning and evaluation of a large number of board games in\ndigital form. We describe the approach we are taking to determine relevant\nfeatures, for biasing MCTS playouts for arbitrary games played on arbitrary\ngeometries. Benefits of our approach include efficient implementation, the\npotential to transfer learnt knowledge to new contexts, and the potential to\nexplain strategic knowledge embedded in features in human-comprehensible terms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 09:30:07 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Browne", "Cameron", ""], ["Soemers", "Dennis J. N. J.", ""], ["Piette", "Eric", ""]]}, {"id": "2101.00858", "submitter": "Sinem Aslan", "authors": "Sinem Aslan, Luc Steels", "title": "Identifying centres of interest in paintings using alignment and edge\n  detection: Case studies on works by Luc Tuymans", "comments": "Accepted to International Workshop on Fine Art Pattern Extraction and\n  Recognition of 25th International Conference on Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What is the creative process through which an artist goes from an original\nimage to a painting? Can we examine this process using techniques from computer\nvision and pattern recognition? Here we set the first preliminary steps to\nalgorithmically deconstruct some of the transformations that an artist applies\nto an original image in order to establish centres of interest, which are focal\nareas of a painting that carry meaning. We introduce a comparative methodology\nthat first cuts out the minimal segment from the original image on which the\npainting is based, then aligns the painting with this source, investigates\nmicro-differences to identify centres of interest and attempts to understand\ntheir role. In this paper we focus exclusively on micro-differences with\nrespect to edges. We believe that research into where and how artists create\ncentres of interest in paintings is valuable for curators, art historians,\nviewers, and art educators, and might even help artists to understand and\nrefine their own artistic method.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 10:04:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Aslan", "Sinem", ""], ["Steels", "Luc", ""]]}, {"id": "2101.00916", "submitter": "Mengge He", "authors": "Li Liu, Mengge He, Guanghui Xu, Mingkui Tan, Qi Wu", "title": "How to Train Your Agent to Read and Write", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading and writing research papers is one of the most privileged abilities\nthat a qualified researcher should master. However, it is difficult for new\nresearchers (\\eg{students}) to fully {grasp} this ability. It would be\nfascinating if we could train an intelligent agent to help people read and\nsummarize papers, and perhaps even discover and exploit the potential knowledge\nclues to write novel papers. Although there have been existing works focusing\non summarizing (\\emph{i.e.}, reading) the knowledge in a given text or\ngenerating (\\emph{i.e.}, writing) a text based on the given knowledge, the\nability of simultaneously reading and writing is still under development.\nTypically, this requires an agent to fully understand the knowledge from the\ngiven text materials and generate correct and fluent novel paragraphs, which is\nvery challenging in practice. In this paper, we propose a Deep ReAder-Writer\n(DRAW) network, which consists of a \\textit{Reader} that can extract knowledge\ngraphs (KGs) from input paragraphs and discover potential knowledge, a\ngraph-to-text \\textit{Writer} that generates a novel paragraph, and a\n\\textit{Reviewer} that reviews the generated paragraph from three different\naspects. Extensive experiments show that our DRAW network outperforms\nconsidered baselines and several state-of-the-art methods on AGENDA and\nM-AGENDA datasets. Our code and supplementary are released at\nhttps://github.com/menggehe/DRAW.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 12:22:04 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Liu", "Li", ""], ["He", "Mengge", ""], ["Xu", "Guanghui", ""], ["Tan", "Mingkui", ""], ["Wu", "Qi", ""]]}, {"id": "2101.00922", "submitter": "Yaowen Qiu", "authors": "Qiu Yaowen, Li Yin, Lu Yanchang", "title": "Zombie Account Detection Based on Community Detection and Uneven\n  Assignation PageRank", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the social media, there are a large amount of potential zombie accounts\nwhich may has negative impact on the public opinion. In tradition, PageRank\nalgorithm is used to detect zombie accounts. However, problems such as it\nrequires a large RAM to store adjacent matrix or adjacent list and the value of\nimportance may approximately to zero for large graph exist. To solve the first\nproblem, since the structure of social media makes the graph divisible, we\nconducted a community detection algorithm Louvain to decompose the whole graph\ninto 1,002 subgraphs. The modularity of 0.58 shows the result is effective. To\nsolve the second problem, we performed the uneven assignation PageRank\nalgorithm to calculate the importance of node in each community. Then, a\nthreshold is set to distinguish the zombie account and normal accounts. The\nresult shows that about 20% accounts in the dataset are zombie accounts and\nthey center in tier-one cities in China such as Beijing, Shanghai, and\nGuangzhou. In the future, a classification algorithm with semi-supervised\nlearning can be used to detect zombie accounts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 12:33:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yaowen", "Qiu", ""], ["Yin", "Li", ""], ["Yanchang", "Lu", ""]]}, {"id": "2101.01041", "submitter": "Xiangyuan Zhang", "authors": "Kaiqing Zhang, Xiangyuan Zhang, Bin Hu, Tamer Ba\\c{s}ar", "title": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust\n  Control Design: Implicit Regularization and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct policy search serves as one of the workhorses in modern reinforcement\nlearning (RL), and its applications in continuous control tasks have recently\nattracted increasing attention. In this work, we investigate the convergence\ntheory of policy gradient (PG) methods for learning the linear risk-sensitive\nand robust controller. In particular, we develop PG methods that can be\nimplemented in a derivative-free fashion by sampling system trajectories, and\nestablish both global convergence and sample complexity results in the\nsolutions of two fundamental settings in risk-sensitive and robust control: the\nfinite-horizon linear exponential quadratic Gaussian, and the finite-horizon\nlinear-quadratic disturbance attenuation problems. As a by-product, our results\nalso provide the first sample complexity for the global convergence of PG\nmethods on solving zero-sum linear-quadratic dynamic games, a\nnonconvex-nonconcave minimax optimization problem that serves as a baseline\nsetting in multi-agent reinforcement learning (MARL) with continuous spaces.\nOne feature of our algorithms is that during the learning phase, a certain\nlevel of robustness/risk-sensitivity of the controller is preserved, which we\ntermed as the implicit regularization property, and is an essential requirement\nin safety-critical control systems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 16:00:46 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 02:41:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Zhang", "Xiangyuan", ""], ["Hu", "Bin", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2101.01060", "submitter": "Jizhe Zhou", "authors": "Jizhe Zhou, Chi-Man Pun", "title": "Personal Privacy Protection via Irrelevant Faces Tracking and Pixelation\n  in Video Live Streaming", "comments": null, "journal-ref": null, "doi": "10.1109/TIFS.2020.3029913", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To date, the privacy-protection intended pixelation tasks are still\nlabor-intensive and yet to be studied. With the prevailing of video live\nstreaming, establishing an online face pixelation mechanism during streaming is\nan urgency. In this paper, we develop a new method called Face Pixelation in\nVideo Live Streaming (FPVLS) to generate automatic personal privacy filtering\nduring unconstrained streaming activities. Simply applying multi-face trackers\nwill encounter problems in target drifting, computing efficiency, and\nover-pixelation. Therefore, for fast and accurate pixelation of irrelevant\npeople's faces, FPVLS is organized in a frame-to-video structure of two core\nstages. On individual frames, FPVLS utilizes image-based face detection and\nembedding networks to yield face vectors. In the raw trajectories generation\nstage, the proposed Positioned Incremental Affinity Propagation (PIAP)\nclustering algorithm leverages face vectors and positioned information to\nquickly associate the same person's faces across frames. Such frame-wise\naccumulated raw trajectories are likely to be intermittent and unreliable on\nvideo level. Hence, we further introduce the trajectory refinement stage that\nmerges a proposal network with the two-sample test based on the Empirical\nLikelihood Ratio (ELR) statistic to refine the raw trajectories. A Gaussian\nfilter is laid on the refined trajectories for final pixelation. On the video\nlive streaming dataset we collected, FPVLS obtains satisfying accuracy,\nreal-time efficiency, and contains the over-pixelation problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 16:18:26 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 14:01:09 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhou", "Jizhe", ""], ["Pun", "Chi-Man", ""]]}, {"id": "2101.01067", "submitter": "Khan Md. Hasib", "authors": "Md. Ashek-Al-Aziz, Sagar Mahmud, Md. Azizul Islam, Jubayer Al Mahmud,\n  Khan Md. Hasib", "title": "A Comparative Study of AHP and Fuzzy AHP Method for Inconsistent Data", "comments": "22 Pages, 9 Figures", "journal-ref": "International Journal of Sciences: Basic and Applied Research\n  (IJSBAR), Volume 54 Issue 4, Year 2020, Page - 16 -37", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In various cases of decision analysis we use two popular methods: Analytical\nHierarchical Process (AHP) and Fuzzy based AHP or Fuzzy AHP. Both the methods\ndeal with stochastic data and can determine decision result through Multi\nCriteria Decision Making (MCDM) process. Obviously resulting values of the two\nmethods are not same though same set of data is fed into them. In this research\nwork, we have tried to observe similarities and dissimilarities between two\nmethods outputs. Almost same trend or fluctuations in outputs have been seen\nfor both methods for same set of input data which are not consistent. Both\nmethod outputs ups and down fluctuations are same for fifty percent cases.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 06:08:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ashek-Al-Aziz", "Md.", ""], ["Mahmud", "Sagar", ""], ["Islam", "Md. Azizul", ""], ["Mahmud", "Jubayer Al", ""], ["Hasib", "Khan Md.", ""]]}, {"id": "2101.01073", "submitter": "Ramna Maqsood", "authors": "R. Maqsood, UI. Bajwa, G. Saleem, Rana H. Raza, MW. Anwar", "title": "Anomaly Recognition from surveillance videos using 3D Convolutional\n  Neural Networks", "comments": "25 pages, 7, figures, 8 Tables, Under Review in Multimedia Tools and\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalous activity recognition deals with identifying the patterns and events\nthat vary from the normal stream. In a surveillance paradigm, these events\nrange from abuse to fighting and road accidents to snatching, etc. Due to the\nsparse occurrence of anomalous events, anomalous activity recognition from\nsurveillance videos is a challenging research task. The approaches reported can\nbe generally categorized as handcrafted and deep learning-based. Most of the\nreported studies address binary classification i.e. anomaly detection from\nsurveillance videos. But these reported approaches did not address other\nanomalous events e.g. abuse, fight, road accidents, shooting, stealing,\nvandalism, and robbery, etc. from surveillance videos. Therefore, this paper\naims to provide an effective framework for the recognition of different\nreal-world anomalies from videos. This study provides a simple, yet effective\napproach for learning spatiotemporal features using deep 3-dimensional\nconvolutional networks (3D ConvNets) trained on the University of Central\nFlorida (UCF) Crime video dataset. Firstly, the frame-level labels of the UCF\nCrime dataset are provided, and then to extract anomalous spatiotemporal\nfeatures more efficiently a fine-tuned 3D ConvNets is proposed. Findings of the\nproposed study are twofold 1)There exist specific, detectable, and quantifiable\nfeatures in UCF Crime video feed that associate with each other 2) Multiclass\nlearning can improve generalizing competencies of the 3D ConvNets by\neffectively learning frame-level information of dataset and can be leveraged in\nterms of better results by applying spatial augmentation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 16:32:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Maqsood", "R.", ""], ["Bajwa", "UI.", ""], ["Saleem", "G.", ""], ["Raza", "Rana H.", ""], ["Anwar", "MW.", ""]]}, {"id": "2101.01076", "submitter": "Jiaheng Xie", "authors": "Jiaheng Xie, Yidong Chai, Xiao Liu", "title": "Understanding Health Misinformation Transmission: An Interpretable Deep\n  Learning Approach to Manage Infodemics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Health misinformation on social media devastates physical and mental health,\ninvalidates health gains, and potentially costs lives. Understanding how health\nmisinformation is transmitted is an urgent goal for researchers, social media\nplatforms, health sectors, and policymakers to mitigate those ramifications.\nDeep learning methods have been deployed to predict the spread of\nmisinformation. While achieving the state-of-the-art predictive performance,\ndeep learning methods lack the interpretability due to their blackbox nature.\nTo remedy this gap, this study proposes a novel interpretable deep learning\napproach, Generative Adversarial Network based Piecewise Wide and Attention\nDeep Learning (GAN-PiWAD), to predict health misinformation transmission in\nsocial media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD\ncaptures the interactions among multi-modal data, offers unbiased estimation of\nthe total effect of each feature, and models the dynamic total effect of each\nfeature when its value varies. We select features according to social exchange\ntheory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed\napproach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates\nvideo description, negative video content, and channel credibility are key\nfeatures that drive viral transmission of misinformation. This study\ncontributes to IS with a novel interpretable deep learning method that is\ngeneralizable to understand other human decision factors. Our findings provide\ndirect implications for social media platforms and policymakers to design\nproactive interventions to identify misinformation, control transmissions, and\nmanage infodemics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:49:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Xie", "Jiaheng", ""], ["Chai", "Yidong", ""], ["Liu", "Xiao", ""]]}, {"id": "2101.01082", "submitter": "Axel Parmentier", "authors": "Axel Parmentier and Vincent T'Kindt", "title": "Learning to solve the single machine scheduling problem with release\n  times and sum of completion times", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the solution of a hard single machine scheduling\nproblem by new heuristic algorithms embedding techniques from machine learning\nfield and scheduling theory. These heuristics transform an instance of the hard\nproblem into an instance of a simpler one solved to optimality. The obtained\nschedule is then transposed to the original problem. Computational experiments\nshow that they are competitive with state-of-the-art heuristics, notably on\nlarge instances.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 16:40:18 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Parmentier", "Axel", ""], ["T'Kindt", "Vincent", ""]]}, {"id": "2101.01099", "submitter": "Mohak Sukhwani", "authors": "Mohak Sukhwani, Vishakh Duggal, Said Zahrai", "title": "Dynamic Knowledge Graphs as Semantic Memory Model for Industrial Robots", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present a model for semantic memory that allows machines to\ncollect information and experiences to become more proficient with time. Post\nsemantic analysis of the sensory and other related data, the processed\ninformation is stored in the knowledge graph which is then used to comprehend\nthe work instructions expressed in natural language. This imparts industrial\nrobots cognitive behavior to execute the required tasks in a deterministic\nmanner. The paper outlines the architecture of the system along with an\nimplementation of the proposal.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 17:15:30 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 18:58:44 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 17:39:48 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sukhwani", "Mohak", ""], ["Duggal", "Vishakh", ""], ["Zahrai", "Said", ""]]}, {"id": "2101.01104", "submitter": "Zhen Fang", "authors": "Li Zhong, Zhen Fang, Feng Liu, Jie Lu, Bo Yuan, Guangquan Zhang", "title": "How does the Combined Risk Affect the Performance of Unsupervised Domain\n  Adaptation Approaches?", "comments": "9 pages, 3 figures, Accepted by Association for the Advancement of\n  Artificial Intelligence 2021 (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to train a target classifier with\nlabeled samples from the source domain and unlabeled samples from the target\ndomain. Classical UDA learning bounds show that target risk is upper bounded by\nthree terms: source risk, distribution discrepancy, and combined risk. Based on\nthe assumption that the combined risk is a small fixed value, methods based on\nthis bound train a target classifier by only minimizing estimators of the\nsource risk and the distribution discrepancy. However, the combined risk may\nincrease when minimizing both estimators, which makes the target risk\nuncontrollable. Hence the target classifier cannot achieve ideal performance if\nwe fail to control the combined risk. To control the combined risk, the key\nchallenge takes root in the unavailability of the labeled samples in the target\ndomain. To address this key challenge, we propose a method named E-MixNet.\nE-MixNet employs enhanced mixup, a generic vicinal distribution, on the labeled\nsource samples and pseudo-labeled target samples to calculate a proxy of the\ncombined risk. Experiments show that the proxy can effectively curb the\nincrease of the combined risk when minimizing the source risk and distribution\ndiscrepancy. Furthermore, we show that if the proxy of the combined risk is\nadded into loss functions of four representative UDA methods, their performance\nis also improved.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 00:46:57 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhong", "Li", ""], ["Fang", "Zhen", ""], ["Liu", "Feng", ""], ["Lu", "Jie", ""], ["Yuan", "Bo", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2101.01134", "submitter": "Danica J. Sutherland", "authors": "Pritish Kamath and Akilesh Tangella and Danica J. Sutherland and\n  Nathan Srebro", "title": "Does Invariant Risk Minimization Capture Invariance?", "comments": "Code is available in the arXiv ancillary files, linked from this page", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Invariant Risk Minimization (IRM) formulation of Arjovsky et\nal. (2019) can fail to capture \"natural\" invariances, at least when used in its\npractical \"linear\" form, and even on very simple problems which directly follow\nthe motivating examples for IRM. This can lead to worse generalization on new\nenvironments, even when compared to unconstrained ERM. The issue stems from a\nsignificant gap between the linear variant (as in their concrete method IRMv1)\nand the full non-linear IRM formulation. Additionally, even when capturing the\n\"right\" invariances, we show that it is possible for IRM to learn a sub-optimal\npredictor, due to the loss function not being invariant across environments.\nThe issues arise even when measuring invariance on the population\ndistributions, but are exacerbated by the fact that IRM is extremely fragile to\nsampling.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:02:45 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 23:21:48 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kamath", "Pritish", ""], ["Tangella", "Akilesh", ""], ["Sutherland", "Danica J.", ""], ["Srebro", "Nathan", ""]]}, {"id": "2101.01139", "submitter": "Sarah Aguasvivas Manzano", "authors": "Sarah Aguasvivas Manzano, Patricia Xu, Khoi Ly, Robert Shepherd,\n  Nikolaus Correll", "title": "High-bandwidth nonlinear control for soft actuators with recursive\n  network models", "comments": "International Symposium on Experimental Robotics (ISER) 2020, Malta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NA cs.SE cs.SY eess.SY math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a high-bandwidth, lightweight, and nonlinear output tracking\ntechnique for soft actuators that combines parsimonious recursive layers for\nforward output predictions and online optimization using Newton-Raphson. This\ntechnique allows for reduced model sizes and increased control loop frequencies\nwhen compared with conventional RNN models. Experimental results of this\ncontroller prototype on a single soft actuator with soft positional sensors\nindicate effective tracking of referenced spatial trajectories and rejection of\nmechanical and electromagnetic disturbances. These are evidenced by root mean\nsquared path tracking errors (RMSE) of 1.8mm using a fully connected (FC)\nsubstructure, 1.62mm using a gated recurrent unit (GRU) and 2.11mm using a long\nshort term memory (LSTM) unit, all averaged over three tasks. Among these\nmodels, the highest flash memory requirement is 2.22kB enabling co-location of\ncontroller and actuator.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:12:41 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Manzano", "Sarah Aguasvivas", ""], ["Xu", "Patricia", ""], ["Ly", "Khoi", ""], ["Shepherd", "Robert", ""], ["Correll", "Nikolaus", ""]]}, {"id": "2101.01154", "submitter": "Nikolay Malkin", "authors": "Nikolay Malkin, Caleb Robinson, Nebojsa Jojic", "title": "High-resolution land cover change from low-resolution labels: Simple\n  baselines for the 2021 IEEE GRSS Data Fusion Contest", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present simple algorithms for land cover change detection in the 2021 IEEE\nGRSS Data Fusion Contest. The task of the contest is to create high-resolution\n(1m / pixel) land cover change maps of a study area in Maryland, USA, given\nmulti-resolution imagery and label data. We study several baseline models for\nthis task and discuss directions for further research.\n  See https://dfc2021.blob.core.windows.net/competition-data/dfc2021_index.txt\nfor the data and https://github.com/calebrob6/dfc2021-msd-baseline for an\nimplementation of these baselines.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:33:47 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Malkin", "Nikolay", ""], ["Robinson", "Caleb", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "2101.01162", "submitter": "Wuchen Li", "authors": "Wuchen Li", "title": "Transport information Bregman divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math-ph math.IT math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Bregman divergences in probability density space embedded with the\n$L^2$--Wasserstein metric. Several properties and dualities of transport\nBregman divergences are provided. In particular, we derive the transport\nKullback--Leibler (KL) divergence by a Bregman divergence of negative\nBoltzmann--Shannon entropy in $L^2$--Wasserstein space. We also derive\nanalytical formulas and generalizations of transport KL divergence for\none-dimensional probability densities and Gaussian families.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:52:45 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Li", "Wuchen", ""]]}, {"id": "2101.01165", "submitter": "Ilke Demir", "authors": "Ilke Demir and Umur A. Ciftci", "title": "Where Do Deep Fakes Look? Synthetic Face Detection via Gaze Tracking", "comments": "To appear in the proceedings of ACM ETRA 2021", "journal-ref": null, "doi": "10.1145/3448017.3457387", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent initiatives for the democratization of AI, deep fake\ngenerators have become increasingly popular and accessible, causing dystopian\nscenarios towards social erosion of trust. A particular domain, such as\nbiological signals, attracted attention towards detection methods that are\ncapable of exploiting authenticity signatures in real videos that are not yet\nfaked by generative approaches. In this paper, we first propose several\nprominent eye and gaze features that deep fakes exhibit differently. Second, we\ncompile those features into signatures and analyze and compare those of real\nand fake videos, formulating geometric, visual, metric, temporal, and spectral\nvariations. Third, we generalize this formulation to the deep fake detection\nproblem by a deep neural network, to classify any video in the wild as fake or\nreal. We evaluate our approach on several deep fake datasets, achieving 92.48%\naccuracy on FaceForensics++, 80.0% on Deep Fakes (in the wild), 88.35% on\nCelebDF, and 99.27% on DeeperForensics datasets. Our approach outperforms most\ndeep and biological fake detectors with complex network architectures without\nthe proposed gaze signatures. We conduct ablation studies involving different\nfeatures, architectures, sequence durations, and post-processing artifacts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:54:46 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 17:59:20 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Demir", "Ilke", ""], ["Ciftci", "Umur A.", ""]]}, {"id": "2101.01169", "submitter": "Salman Khan Dr.", "authors": "Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad\n  Shahbaz Khan, Mubarak Shah", "title": "Transformers in Vision: A Survey", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Astounding results from Transformer models on natural language tasks have\nintrigued the vision community to study their application to computer vision\nproblems. Among their salient benefits, Transformers enable modeling long\ndependencies between input sequence elements and support parallel processing of\nsequence as compared to recurrent networks e.g., Long short-term memory (LSTM).\nDifferent from convolutional networks, Transformers require minimal inductive\nbiases for their design and are naturally suited as set-functions. Furthermore,\nthe straightforward design of Transformers allows processing multiple\nmodalities (e.g., images, videos, text and speech) using similar processing\nblocks and demonstrates excellent scalability to very large capacity networks\nand huge datasets. These strengths have led to exciting progress on a number of\nvision tasks using Transformer networks. This survey aims to provide a\ncomprehensive overview of the Transformer models in the computer vision\ndiscipline. We start with an introduction to fundamental concepts behind the\nsuccess of Transformers i.e., self-attention, large-scale pre-training, and\nbidirectional encoding. We then cover extensive applications of transformers in\nvision including popular recognition tasks (e.g., image classification, object\ndetection, action recognition, and segmentation), generative modeling,\nmulti-modal tasks (e.g., visual-question answering, visual reasoning, and\nvisual grounding), video processing (e.g., activity recognition, video\nforecasting), low-level vision (e.g., image super-resolution, image\nenhancement, and colorization) and 3D analysis (e.g., point cloud\nclassification and segmentation). We compare the respective advantages and\nlimitations of popular techniques both in terms of architectural design and\ntheir experimental value. Finally, we provide an analysis on open research\ndirections and possible future works.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:57:24 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 11:40:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Khan", "Salman", ""], ["Naseer", "Muzammal", ""], ["Hayat", "Munawar", ""], ["Zamir", "Syed Waqas", ""], ["Khan", "Fahad Shahbaz", ""], ["Shah", "Mubarak", ""]]}, {"id": "2101.01204", "submitter": "Lawrence Thul", "authors": "Lawrence Thul, Warren Powell", "title": "Stochastic Optimization for Vaccine and Testing Kit Allocation for the\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The pandemic caused by the SARS-CoV-2 virus has exposed many flaws in the\ndecision-making strategies used to distribute resources to combat global health\ncrises. In this paper, we leverage reinforcement learning and optimization to\nimprove upon the allocation strategies for various resources. In particular, we\nconsider a problem where a central controller must decide where to send testing\nkits to learn about the uncertain states of the world (active learning); then,\nuse the new information to construct beliefs about the states and decide where\nto allocate resources. We propose a general model coupled with a tunable\nlookahead policy for making vaccine allocation decisions without perfect\nknowledge about the state of the world. The lookahead policy is compared to a\npopulation-based myopic policy which is more likely to be similar to the\npresent strategies in practice. Each vaccine allocation policy works in\nconjunction with a testing kit allocation policy to perform active learning.\nOur simulation results demonstrate that an optimization-based lookahead\ndecision making strategy will outperform the presented myopic policy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 19:08:32 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Thul", "Lawrence", ""], ["Powell", "Warren", ""]]}, {"id": "2101.01215", "submitter": "Teofilo de Campos", "authors": "Tiago de C. G. Pereira and Teofilo E. de Campos", "title": "Learn by Guessing: Multi-Step Pseudo-Label Refinement for Person\n  Re-Identification", "comments": "11 pages, 2 fitures, 48 references. Submitted to a computer vision\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) methods for person Re-Identification\n(Re-ID) rely on target domain samples to model the marginal distribution of the\ndata. To deal with the lack of target domain labels, UDA methods leverage\ninformation from labeled source samples and unlabeled target samples. A\npromising approach relies on the use of unsupervised learning as part of the\npipeline, such as clustering methods. The quality of the clusters clearly plays\na major role in methods performance, but this point has been overlooked. In\nthis work, we propose a multi-step pseudo-label refinement method to select the\nbest possible clusters and keep improving them so that these clusters become\ncloser to the class divisions without knowledge of the class labels. Our\nrefinement method includes a cluster selection strategy and a camera-based\nnormalization method which reduces the within-domain variations caused by the\nuse of multiple cameras in person Re-ID. This allows our method to reach\nstate-of-the-art UDA results on DukeMTMC-Market1501 (source-target). We surpass\nstate-of-the-art for UDA Re-ID by 3.4% on Market1501-DukeMTMC datasets, which\nis a more challenging adaptation setup because the target domain (DukeMTMC) has\neight distinct cameras. Furthermore, the camera-based normalization method\ncauses a significant reduction in the number of iterations required for\ntraining convergence.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 20:00:33 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Pereira", "Tiago de C. G.", ""], ["de Campos", "Teofilo E.", ""]]}, {"id": "2101.01229", "submitter": "Claudio Daniel Ten\\'orio De Barros", "authors": "Claudio D. T. Barros, Matheus R. F. Mendon\\c{c}a, Alex B. Vieira,\n  Artur Ziviani", "title": "A Survey on Embedding Dynamic Graphs", "comments": "41 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Embedding static graphs in low-dimensional vector spaces plays a key role in\nnetwork analytics and inference, supporting applications like node\nclassification, link prediction, and graph visualization. However, many\nreal-world networks present dynamic behavior, including topological evolution,\nfeature evolution, and diffusion. Therefore, several methods for embedding\ndynamic graphs have been proposed to learn network representations over time,\nfacing novel challenges, such as time-domain modeling, temporal features to be\ncaptured, and the temporal granularity to be embedded. In this survey, we\noverview dynamic graph embedding, discussing its fundamentals and the recent\nadvances developed so far. We introduce the formal definition of dynamic graph\nembedding, focusing on the problem setting and introducing a novel taxonomy for\ndynamic graph embedding input and output. We further explore different dynamic\nbehaviors that may be encompassed by embeddings, classifying by topological\nevolution, feature evolution, and processes on networks. Afterward, we describe\nexisting techniques and propose a taxonomy for dynamic graph embedding\ntechniques based on algorithmic approaches, from matrix and tensor\nfactorization to deep learning, random walks, and temporal point processes. We\nalso elucidate main applications, including dynamic link prediction, anomaly\ndetection, and diffusion prediction, and we further state some promising\nresearch directions in the area.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 20:35:26 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 02:47:17 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Barros", "Claudio D. T.", ""], ["Mendon\u00e7a", "Matheus R. F.", ""], ["Vieira", "Alex B.", ""], ["Ziviani", "Artur", ""]]}, {"id": "2101.01266", "submitter": "Zhiyan Chen", "authors": "Zhiyan Chen, Murat Simsek, Burak Kantarci", "title": "Federated Learning-Based Risk-Aware Decision toMitigate Fake Task\n  Impacts on CrowdsensingPlatforms", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Mobile crowdsensing (MCS) leverages distributed and non-dedicated sensing\nconcepts by utilizing sensors imbedded in a large number of mobile smart\ndevices. However, the openness and distributed nature of MCS leads to various\nvulnerabilities and consequent challenges to address. A malicious user\nsubmitting fake sensing tasks to an MCS platform may be attempting to consume\nresources from any number of participants' devices; as well as attempting to\nclog the MCS server. In this paper, a novel approach that is based on\nhorizontal federated learning is proposed to identify fake tasks that contain a\nnumber of independent detection devices and an aggregation entity. Detection\ndevices are deployed to operate in parallel with each device equipped with a\nmachine learning (ML) module, and an associated training dataset. Furthermore,\nthe aggregation module collects the prediction results from individual devices\nand determines the final decision with the objective of minimizing the\nprediction loss. Loss measurement considers the lost task values with respect\nto misclassification, where the final decision utilizes a risk-aware approach\nwhere the risk is formulated as a function of the utility loss. Experimental\nresults demonstrate that using federated learning-driven illegitimate task\ndetection with a risk aware aggregation function improves the detection\nperformance of the traditional centralized framework. Furthermore, the higher\nperformance of detection and lower loss of utility can be achieved by the\nproposed framework. This scheme can even achieve 100%detection accuracy using\nsmall training datasets distributed across devices, while achieving slightly\nover an 8% increase in detection improvement over traditional approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 22:43:24 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Chen", "Zhiyan", ""], ["Simsek", "Murat", ""], ["Kantarci", "Burak", ""]]}, {"id": "2101.01332", "submitter": "Yichen Yang", "authors": "Yichen Yang, Phitchaya Mangpo Phothilimtha, Yisu Remy Wang, Max\n  Willsey, Sudip Roy, Jacques Pienaar", "title": "Equality Saturation for Tensor Graph Superoptimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major optimizations employed in deep learning frameworks is graph\nrewriting. Production frameworks rely on heuristics to decide if rewrite rules\nshould be applied and in which order. Prior research has shown that one can\ndiscover more optimal tensor computation graphs if we search for a better\nsequence of substitutions instead of relying on heuristics. However, we observe\nthat existing approaches for tensor graph superoptimization both in production\nand research frameworks apply substitutions in a sequential manner. Such\nsequential search methods are sensitive to the order in which the substitutions\nare applied and often only explore a small fragment of the exponential space of\nequivalent graphs. This paper presents a novel technique for tensor graph\nsuperoptimization that employs equality saturation to apply all possible\nsubstitutions at once. We show that our approach can find optimized graphs with\nup to 16% speedup over state-of-the-art, while spending on average 48x less\ntime optimizing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 03:30:35 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 15:05:06 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Yang", "Yichen", ""], ["Phothilimtha", "Phitchaya Mangpo", ""], ["Wang", "Yisu Remy", ""], ["Willsey", "Max", ""], ["Roy", "Sudip", ""], ["Pienaar", "Jacques", ""]]}, {"id": "2101.01352", "submitter": "Chien-Wen Huang", "authors": "Fu-Shun Hsu, Chao-Jung Huang, Chen-Yi Kuo, Shang-Ran Huang, Yuan-Ren\n  Cheng, Jia-Horng Wang, Yi-Lin Wu, Tzu-Ling Tzeng, Feipei Lai", "title": "Development of a Respiratory Sound Labeling Software for Training a Deep\n  Learning-Based Respiratory Sound Analysis Model", "comments": "6 pages, 2 figures, Accepted by International Forum On Medical\n  Imaging In Asia (IFMIA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respiratory auscultation can help healthcare professionals detect abnormal\nrespiratory conditions if adventitious lung sounds are heard. The\nstate-of-the-art artificial intelligence technologies based on deep learning\nshow great potential in the development of automated respiratory sound\nanalysis. To train a deep learning-based model, a huge number of accurate\nlabels of normal breath sounds and adventitious sounds are needed. In this\npaper, we demonstrate the work of developing a respiratory sound labeling\nsoftware to help annotators identify and label the inhalation, exhalation, and\nadventitious respiratory sound more accurately and quickly. Our labeling\nsoftware integrates six features from MATLAB Audio Labeler, and one commercial\naudio editor, RX7. As of October, 2019, we have labeled 9,765 15-second-long\naudio files of breathing lung sounds, and accrued 34,095 inhalation\nlabels,18,349 exhalation labels, 13,883 continuous adventitious sounds (CASs)\nlabels and 15,606 discontinuous adventitious sounds (DASs) labels, which are\nsignificantly larger than previously published studies. The trained\nconvolutional recurrent neural networks based on these labels showed good\nperformance with F1-scores of 86.0% on inhalation event detection, 51.6% on\nCASs event detection and 71.4% on DASs event detection. In conclusion, our\nresults show that our proposed respiratory sound labeling software could easily\npre-define a label, perform one-click labeling, and overall facilitate the\nprocess of accurately labeling. This software helps develop deep learning-based\nmodels that require a huge amount of labeled acoustic data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 04:59:04 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Hsu", "Fu-Shun", ""], ["Huang", "Chao-Jung", ""], ["Kuo", "Chen-Yi", ""], ["Huang", "Shang-Ran", ""], ["Cheng", "Yuan-Ren", ""], ["Wang", "Jia-Horng", ""], ["Wu", "Yi-Lin", ""], ["Tzeng", "Tzu-Ling", ""], ["Lai", "Feipei", ""]]}, {"id": "2101.01353", "submitter": "Weixin Zeng", "authors": "Weixin Zeng, Xiang Zhao, Jiuyang Tang, Xuemin Lin and Paul Groth", "title": "Reinforcement Learning based Collective Entity Alignment with Adaptive\n  Features", "comments": "Accepted by ACM TOIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) is the task of identifying the entities that refer to\nthe same real-world object but are located in different knowledge graphs (KGs).\nFor entities to be aligned, existing EA solutions treat them separately and\ngenerate alignment results as ranked lists of entities on the other side.\nNevertheless, this decision-making paradigm fails to take into account the\ninterdependence among entities. Although some recent efforts mitigate this\nissue by imposing the 1-to-1 constraint on the alignment process, they still\ncannot adequately model the underlying interdependence and the results tend to\nbe sub-optimal. To fill in this gap, in this work, we delve into the dynamics\nof the decision-making process, and offer a reinforcement learning (RL) based\nmodel to align entities collectively. Under the RL framework, we devise the\ncoherence and exclusiveness constraints to characterize the interdependence and\nrestrict collective alignment. Additionally, to generate more precise inputs to\nthe RL framework, we employ representative features to capture different\naspects of the similarity between entities in heterogeneous KGs, which are\nintegrated by an adaptive feature fusion strategy. Our proposal is evaluated on\nboth cross-lingual and mono-lingual EA benchmarks and compared against\nstate-of-the-art solutions. The empirical results verify its effectiveness and\nsuperiority.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 05:04:09 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zeng", "Weixin", ""], ["Zhao", "Xiang", ""], ["Tang", "Jiuyang", ""], ["Lin", "Xuemin", ""], ["Groth", "Paul", ""]]}, {"id": "2101.01386", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "Understanding the Ability of Deep Neural Networks to Count Connected\n  Components in Images", "comments": "7 pages, 12 figures. Accepted by IEEE AIPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can count very fast by subitizing, but slow substantially as the\nnumber of objects increases. Previous studies have shown a trained deep neural\nnetwork (DNN) detector can count the number of objects in an amount of time\nthat increases slowly with the number of objects. Such a phenomenon suggests\nthe subitizing ability of DNNs, and unlike humans, it works equally well for\nlarge numbers. Many existing studies have successfully applied DNNs to object\ncounting, but few studies have studied the subitizing ability of DNNs and its\ninterpretation. In this paper, we found DNNs do not have the ability to\ngenerally count connected components. We provided experiments to support our\nconclusions and explanations to understand the results and phenomena of these\nexperiments. We proposed three ML-learnable characteristics to verify learnable\nproblems for ML models, such as DNNs, and explain why DNNs work for specific\ncounting problems but cannot generally count connected components.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 07:28:34 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2101.01391", "submitter": "Soroush Vosoughi Dr", "authors": "Ruibo Liu, Lili Wang, Chenyan Jia, Soroush Vosoughi", "title": "Political Depolarization of News Articles Using Attribute-aware Word\n  Embeddings", "comments": "In Proceedings of the 15th International AAAI Conference on Weblogs\n  and Social Media (ICWSM 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Political polarization in the US is on the rise. This polarization negatively\naffects the public sphere by contributing to the creation of ideological echo\nchambers. In this paper, we focus on addressing one of the factors that\ncontributes to this polarity, polarized media. We introduce a framework for\ndepolarizing news articles. Given an article on a certain topic with a\nparticular ideological slant (eg., liberal or conservative), the framework\nfirst detects polar language in the article and then generates a new article\nwith the polar language replaced with neutral expressions. To detect polar\nwords, we train a multi-attribute-aware word embedding model that is aware of\nideology and topics on 360k full-length media articles. Then, for text\ngeneration, we propose a new algorithm called Text Annealing Depolarization\nAlgorithm (TADA). TADA retrieves neutral expressions from the word embedding\nmodel that not only decrease ideological polarity but also preserve the\noriginal argument of the text, while maintaining grammatical correctness. We\nevaluate our framework by comparing the depolarized output of our model in two\nmodes, fully-automatic and semi-automatic, on 99 stories spanning 11 topics.\nBased on feedback from 161 human testers, our framework successfully\ndepolarized 90.1% of paragraphs in semi-automatic mode and 78.3% of paragraphs\nin fully-automatic mode. Furthermore, 81.2% of the testers agree that the\nnon-polar content information is well-preserved and 79% agree that\ndepolarization does not harm semantic correctness when they compare the\noriginal text and the depolarized text. Our work shows that data-driven methods\ncan help to locate political polarity and aid in the depolarization of\narticles.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 07:39:12 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 04:42:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Liu", "Ruibo", ""], ["Wang", "Lili", ""], ["Jia", "Chenyan", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2101.01407", "submitter": "Wouter Verbeke", "authors": "Diego Olaya, Wouter Verbeke, Jente Van Belle, Marie-Anne Guerry", "title": "To do or not to do: cost-sensitive causal decision-making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal classification models are adopted across a variety of operational\nbusiness processes to predict the effect of a treatment on a categorical\nbusiness outcome of interest depending on the process instance characteristics.\nThis allows optimizing operational decision-making and selecting the optimal\ntreatment to apply in each specific instance, with the aim of maximizing the\npositive outcome rate. While various powerful approaches have been presented in\nthe literature for learning causal classification models, no formal framework\nhas been elaborated for optimal decision-making based on the estimated\nindividual treatment effects, given the cost of the various treatments and the\nbenefit of the potential outcomes.\n  In this article, we therefore extend upon the expected value framework and\nformally introduce a cost-sensitive decision boundary for double binary causal\nclassification, which is a linear function of the estimated individual\ntreatment effect, the positive outcome probability and the cost and benefit\nparameters of the problem setting. The boundary allows causally classifying\ninstances in the positive and negative treatment class to maximize the expected\ncausal profit, which is introduced as the objective at hand in cost-sensitive\ncausal classification. We introduce the expected causal profit ranker which\nranks instances for maximizing the expected causal profit at each possible\nthreshold for causally classifying instances and differs from the conventional\nranking approach based on the individual treatment effect. The proposed ranking\napproach is experimentally evaluated on synthetic and marketing campaign data\nsets. The results indicate that the presented ranking method effectively\noutperforms the cost-insensitive ranking approach and allows boosting\nprofitability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 08:36:01 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Olaya", "Diego", ""], ["Verbeke", "Wouter", ""], ["Van Belle", "Jente", ""], ["Guerry", "Marie-Anne", ""]]}, {"id": "2101.01418", "submitter": "Petros Spachos", "authors": "Lili Zhu, Petros Spachos", "title": "Support Vector Machine and YOLO for a Mobile Food Grading System", "comments": null, "journal-ref": null, "doi": "10.1016/j.iot.2021.100359", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Food quality and safety are of great concern to society since it is an\nessential guarantee not only for human health but also for social development,\nand stability. Ensuring food quality and safety is a complex process. All food\nprocessing stages should be considered, from cultivating, harvesting and\nstorage to preparation and consumption. Grading is one of the essential\nprocesses to control food quality. This paper proposed a mobile visual-based\nsystem to evaluate food grading. Specifically, the proposed system acquires\nimages of bananas when they are on moving conveyors. A two-layer image\nprocessing system based on machine learning is used to grade bananas, and these\ntwo layers are allocated on edge devices and cloud servers, respectively.\nSupport Vector Machine (SVM) is the first layer to classify bananas based on an\nextracted feature vector composed of color and texture features. Then, the a\nYou Only Look Once (YOLO) v3 model further locating the peel's defected area\nand determining if the inputs belong to the mid-ripened or well-ripened class.\nAccording to experimental results, the first layer's performance achieved an\naccuracy of 98.5% while the accuracy of the second layer is 85.7%, and the\noverall accuracy is 96.4%.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 09:01:06 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zhu", "Lili", ""], ["Spachos", "Petros", ""]]}, {"id": "2101.01473", "submitter": "Tsuyoshi Kato", "authors": "Kenya Tajima, Takahiko Henmi, Kohei Tsuchida, Esmeraldo Ronnie R.\n  Zara, and Tsuyoshi Kato", "title": "Learning Sign-Constrained Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain knowledge is useful to improve the generalization performance of\nlearning machines. Sign constraints are a handy representation to combine\ndomain knowledge with learning machine. In this paper, we consider constraining\nthe signs of the weight coefficients in learning the linear support vector\nmachine, and develop two optimization algorithms for minimizing the empirical\nrisk under the sign constraints. One of the two algorithms is based on the\nprojected gradient method, in which each iteration of the projected gradient\nmethod takes $O(nd)$ computational cost and the sublinear convergence of the\nobjective error is guaranteed. The second algorithm is based on the Frank-Wolfe\nmethod that also converges sublinearly and possesses a clear termination\ncriterion. We show that each iteration of the Frank-Wolfe also requires $O(nd)$\ncost. Furthermore, we derive the explicit expression for the minimal iteration\nnumber to ensure an $\\epsilon$-accurate solution by analyzing the curvature of\nthe objective function. Finally, we empirically demonstrate that the sign\nconstraints are a promising technique when similarities to the training\nexamples compose the feature vector.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 12:08:17 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Tajima", "Kenya", ""], ["Henmi", "Takahiko", ""], ["Tsuchida", "Kohei", ""], ["Zara", "Esmeraldo Ronnie R.", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "2101.01507", "submitter": "Hai Lan", "authors": "Hai Lan, Zhifeng Bao, Yuwei Peng", "title": "A Survey on Advancing the DBMS Query Optimizer: Cardinality Estimation,\n  Cost Model, and Plan Enumeration", "comments": "This paper was accepted by Data Science and Engineering (DSEJ) in\n  Dec, 2020", "journal-ref": null, "doi": "10.1007/s41019-020-00149-7", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query optimizer is at the heart of the database systems. Cost-based optimizer\nstudied in this paper is adopted in almost all current database systems. A\ncost-based optimizer introduces a plan enumeration algorithm to find a\n(sub)plan, and then uses a cost model to obtain the cost of that plan, and\nselects the plan with the lowest cost. In the cost model, cardinality, the\nnumber of tuples through an operator, plays a crucial role. Due to the\ninaccuracy in cardinality estimation, errors in cost model, and the huge plan\nspace, the optimizer cannot find the optimal execution plan for a complex query\nin a reasonable time. In this paper, we first deeply study the causes behind\nthe limitations above. Next, we review the techniques used to improve the\nquality of the three key components in the cost-based optimizer, cardinality\nestimation, cost model, and plan enumeration. We also provide our insights on\nthe future directions for each of the above aspects.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 13:47:45 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Lan", "Hai", ""], ["Bao", "Zhifeng", ""], ["Peng", "Yuwei", ""]]}, {"id": "2101.01510", "submitter": "Xiaowang Zhang", "authors": "Peiyun Wu and Yunjie Wu and Linjuan Wu and Xiaowang Zhang and Zhiyong\n  Feng", "title": "Modeling Global Semantics for Question Answering over Knowledge Bases", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing, as an important approach to question answering over\nknowledge bases (KBQA), transforms a question into the complete query graph for\nfurther generating the correct logical query. Existing semantic parsing\napproaches mainly focus on relations matching with paying less attention to the\nunderlying internal structure of questions (e.g., the dependencies and\nrelations between all entities in a question) to select the query graph. In\nthis paper, we present a relational graph convolutional network (RGCN)-based\nmodel gRGCN for semantic parsing in KBQA. gRGCN extracts the global semantics\nof questions and their corresponding query graphs, including structure\nsemantics via RGCN and relational semantics (label representation of relations\nbetween entities) via a hierarchical relation attention mechanism. Experiments\nevaluated on benchmarks show that our model outperforms off-the-shelf models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 13:51:14 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wu", "Peiyun", ""], ["Wu", "Yunjie", ""], ["Wu", "Linjuan", ""], ["Zhang", "Xiaowang", ""], ["Feng", "Zhiyong", ""]]}, {"id": "2101.01513", "submitter": "Jingkun Chen", "authors": "Jingkun Chen, Wenqi Li, Hongwei Li, Jianguo Zhang", "title": "Deep Class-Specific Affinity-Guided Convolutional Network for Multimodal\n  Unpaired Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-modal medical image segmentation plays an essential role in clinical\ndiagnosis. It remains challenging as the input modalities are often not\nwell-aligned spatially. Existing learning-based methods mainly consider sharing\ntrainable layers across modalities and minimizing visual feature discrepancies.\nWhile the problem is often formulated as joint supervised feature learning,\nmultiple-scale features and class-specific representation have not yet been\nexplored. In this paper, we propose an affinity-guided fully convolutional\nnetwork for multimodal image segmentation. To learn effective representations,\nwe design class-specific affinity matrices to encode the knowledge of\nhierarchical feature reasoning, together with the shared convolutional layers\nto ensure the cross-modality generalization. Our affinity matrix does not\ndepend on spatial alignments of the visual features and thus allows us to train\nwith unpaired, multimodal inputs. We extensively evaluated our method on two\npublic multimodal benchmark datasets and outperform state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 13:56:51 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Chen", "Jingkun", ""], ["Li", "Wenqi", ""], ["Li", "Hongwei", ""], ["Zhang", "Jianguo", ""]]}, {"id": "2101.01524", "submitter": "Dakuo Wang", "authors": "Dakuo Wang and Liuping Wang and Zhan Zhang and Ding Wang and Haiyi Zhu\n  and Yvonne Gao and Xiangmin Fan and Feng Tian", "title": "\"Brilliant AI Doctor\" in Rural China: Tensions and Challenges in\n  AI-Powered CDSS Deployment", "comments": null, "journal-ref": null, "doi": "10.1145/3411764.3445432", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) technology has been increasingly used in the\nimplementation of advanced Clinical Decision Support Systems (CDSS). Research\ndemonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical\ndecision making scenarios. However, post-adoption user perception and\nexperience remain understudied, especially in developing countries. Through\nobservations and interviews with 22 clinicians from 6 rural clinics in China,\nthis paper reports the various tensions between the design of an AI-CDSS system\n(\"Brilliant Doctor\") and the rural clinical context, such as the misalignment\nwith local context and workflow, the technical limitations and usability\nbarriers, as well as issues related to transparency and trustworthiness of\nAI-CDSS. Despite these tensions, all participants expressed positive attitudes\ntoward the future of AI-CDSS, especially acting as \"a doctor's AI assistant\" to\nrealize a Human-AI Collaboration future in clinical settings. Finally we draw\non our findings to discuss implications for designing AI-CDSS interventions for\nrural clinical contexts in developing countries.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 05:32:48 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 22:44:26 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Wang", "Dakuo", ""], ["Wang", "Liuping", ""], ["Zhang", "Zhan", ""], ["Wang", "Ding", ""], ["Zhu", "Haiyi", ""], ["Gao", "Yvonne", ""], ["Fan", "Xiangmin", ""], ["Tian", "Feng", ""]]}, {"id": "2101.01533", "submitter": "John Tsotsos", "authors": "John K. Tsotsos, Omar Abid, Iuliia Kotseruba, Markus D. Solbach", "title": "On the Control of Attentional Processes in Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The study of attentional processing in vision has a long and deep history.\nRecently, several papers have presented insightful perspectives into how the\ncoordination of multiple attentional functions in the brain might occur. These\nbegin with experimental observations and the authors propose structures,\nprocesses, and computations that might explain those observations. Here, we\nconsider a perspective that past works have not, as a complementary approach to\nthe experimentally-grounded ones. We approach the same problem as past authors\nbut from the other end of the computational spectrum, from the problem nature,\nas Marr's Computational Level would prescribe. What problem must the brain\nsolve when orchestrating attentional processes in order to successfully\ncomplete one of the myriad possible visuospatial tasks at which we as humans\nexcel? The hope, of course, is for the approaches to eventually meet and thus\nform a complete theory, but this is likely not soon. We make the first steps\ntowards this by addressing the necessity of attentional control, examining the\nbreadth and computational difficulty of the visuospatial and attentional tasks\nseen in human behavior, and suggesting a sketch of how attentional control\nmight arise in the brain. The key conclusions of this paper are that an\nexecutive controller is necessary for human attentional function in vision, and\nthat there is a 'first principles' computational approach to its understanding\nthat is complementary to the previous approaches that focus on modelling or\nlearning from experimental observations directly.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 14:24:20 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Tsotsos", "John K.", ""], ["Abid", "Omar", ""], ["Kotseruba", "Iuliia", ""], ["Solbach", "Markus D.", ""]]}, {"id": "2101.01625", "submitter": "Devleena Das", "authors": "Devleena Das, Siddhartha Banerjee, Sonia Chernova", "title": "Explainable AI for Robot Failures: Generating Explanations that Improve\n  User Assistance in Fault Recovery", "comments": null, "journal-ref": null, "doi": "10.1145/3434073.3444657", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing capabilities of intelligent systems, the integration of\nrobots in our everyday life is increasing. However, when interacting in such\ncomplex human environments, the occasional failure of robotic systems is\ninevitable. The field of explainable AI has sought to make complex-decision\nmaking systems more interpretable but most existing techniques target domain\nexperts. On the contrary, in many failure cases, robots will require recovery\nassistance from non-expert users. In this work, we introduce a new type of\nexplanation, that explains the cause of an unexpected failure during an agent's\nplan execution to non-experts. In order for error explanations to be\nmeaningful, we investigate what types of information within a set of\nhand-scripted explanations are most helpful to non-experts for failure and\nsolution identification. Additionally, we investigate how such explanations can\nbe autonomously generated, extending an existing encoder-decoder model, and\ngeneralized across environments. We investigate such questions in the context\nof a robot performing a pick-and-place manipulation task in the home\nenvironment. Our results show that explanations capturing the context of a\nfailure and history of past actions, are the most effective for failure and\nsolution identification among non-experts. Furthermore, through a second user\nevaluation, we verify that our model-generated explanations can generalize to\nan unseen office environment, and are just as effective as the hand-scripted\nexplanations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 16:16:39 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Das", "Devleena", ""], ["Banerjee", "Siddhartha", ""], ["Chernova", "Sonia", ""]]}, {"id": "2101.01637", "submitter": "Chao Zhang", "authors": "Chao Zhang, Joaquin Vanschoren, Arlette van Wissen, Daniel Lakens,\n  Boris de Ruyter, and Wijnand A. IJsselsteijn", "title": "Theory-based Habit Modeling for Enhancing Behavior Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Psychological theories of habit posit that when a strong habit is formed\nthrough behavioral repetition, it can trigger behavior automatically in the\nsame environment. Given the reciprocal relationship between habit and behavior,\nchanging lifestyle behaviors (e.g., toothbrushing) is largely a task of\nbreaking old habits and creating new and healthy ones. Thus, representing\nusers' habit strengths can be very useful for behavior change support systems\n(BCSS), for example, to predict behavior or to decide when an intervention\nreaches its intended effect. However, habit strength is not directly observable\nand existing self-report measures are taxing for users. In this paper, built on\nrecent computational models of habit formation, we propose a method to enable\nintelligent systems to compute habit strength based on observable behavior. The\nhypothesized advantage of using computed habit strength for behavior prediction\nwas tested using data from two intervention studies, where we trained\nparticipants to brush their teeth twice a day for three weeks and monitored\ntheir behaviors using accelerometers. Through hierarchical cross-validation, we\nfound that for the task of predicting future brushing behavior, computed habit\nstrength clearly outperformed self-reported habit strength (in both studies)\nand was also superior to models based on past behavior frequency (in the larger\nsecond study). Our findings provide initial support for our theory-based\napproach of modeling user habits and encourages the use of habit computation to\ndeliver personalized and adaptive interventions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 16:42:59 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhang", "Chao", ""], ["Vanschoren", "Joaquin", ""], ["van Wissen", "Arlette", ""], ["Lakens", "Daniel", ""], ["de Ruyter", "Boris", ""], ["IJsselsteijn", "Wijnand A.", ""]]}, {"id": "2101.01669", "submitter": "Zhizhi Yu", "authors": "Di Jin, Zhizhi Yu, Pengfei Jiao, Shirui Pan, Philip S. Yu, Weixiong\n  Zhang", "title": "A Survey of Community Detection Approaches: From Statistical Modeling to\n  Deep Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection, a fundamental task for network analysis, aims to\npartition a network into multiple sub-structures to help reveal their latent\nfunctions. Community detection has been extensively studied in and broadly\napplied to many real-world network problems. Classical approaches to community\ndetection typically utilize probabilistic graphical models and adopt a variety\nof prior knowledge to infer community structures. As the problems that network\nmethods try to solve and the network data to be analyzed become increasingly\nmore sophisticated, new approaches have also been proposed and developed,\nparticularly those that utilize deep learning and convert networked data into\nlow dimensional representation. Despite all the recent advancement, there is\nstill a lack of insightful understanding of the theoretical and methodological\nunderpinning of community detection, which will be critically important for\nfuture development of the area of network analysis. In this paper, we develop\nand present a unified architecture of network community-finding methods to\ncharacterize the state-of-the-art of the field of community detection.\nSpecifically, we provide a comprehensive review of the existing community\ndetection methods and introduce a new taxonomy that divides the existing\nmethods into two categories, namely probabilistic graphical model and deep\nlearning. We then discuss in detail the main idea behind each method in the two\ncategories. Furthermore, to promote future development of community detection,\nwe release several benchmark datasets from several problem domains and\nhighlight their applications to various network analysis tasks. We conclude\nwith discussions of the challenges of the field and suggestions of possible\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 02:32:45 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 06:58:54 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Jin", "Di", ""], ["Yu", "Zhizhi", ""], ["Jiao", "Pengfei", ""], ["Pan", "Shirui", ""], ["Yu", "Philip S.", ""], ["Zhang", "Weixiong", ""]]}, {"id": "2101.01673", "submitter": "Avijit Ghosh", "authors": "Avijit Ghosh, Lea Genuit, Mary Reagan", "title": "Characterizing Intersectional Group Fairness with Worst-Case Comparisons", "comments": "Accepted to the 2nd Affinity Group Workshop on Diversity in\n  Artificial Intelligence: Diversity, Belonging, Equity, and Inclusion (AIDBEI)\n  at AAAI 2021 - camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning or Artificial Intelligence algorithms have gained\nconsiderable scrutiny in recent times owing to their propensity towards\nimitating and amplifying existing prejudices in society. This has led to a\nniche but growing body of work that identifies and attempts to fix these\nbiases. A first step towards making these algorithms more fair is designing\nmetrics that measure unfairness. Most existing work in this field deals with\neither a binary view of fairness (protected vs. unprotected groups) or\npolitically defined categories (race or gender). Such categorization misses the\nimportant nuance of intersectionality - biases can often be amplified in\nsubgroups that combine membership from different categories, especially if such\na subgroup is particularly underrepresented in historical platforms of\nopportunity.\n  In this paper, we discuss why fairness metrics need to be looked at under the\nlens of intersectionality, identify existing work in intersectional fairness,\nsuggest a simple worst case comparison method to expand the definitions of\nexisting group fairness metrics to incorporate intersectionality, and finally\nconclude with the social, legal and political framework to handle\nintersectional fairness in the modern context.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 17:44:33 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 17:53:13 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 03:10:01 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ghosh", "Avijit", ""], ["Genuit", "Lea", ""], ["Reagan", "Mary", ""]]}, {"id": "2101.01676", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira, Renata Vieira", "title": "Dynamic Preference Logic meets Iterated Belief Change: Representation\n  Results and Postulates Characterization", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2020.12.042", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AGM's belief revision is one of the main paradigms in the study of belief\nchange operations. Recently, several logics for belief and information change\nhave been proposed in the literature and used to encode belief change\noperations in rich and expressive semantic frameworks. While the connections of\nAGM-like operations and their encoding in dynamic doxastic logics have been\nstudied before by the work of Segerberg, most works on the area of Dynamic\nEpistemic Logics (DEL) have not, to our knowledge, attempted to use those\nlogics as tools to investigate mathematical properties of belief change\noperators. This work investigates how Dynamic Preference Logic, a logic in the\nDEL family, can be used to study properties of dynamic belief change operators,\nfocusing on well-known postulates of iterated belief change.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 17:47:18 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""], ["Vieira", "Renata", ""]]}, {"id": "2101.01697", "submitter": "Devendra Swami", "authors": "Devendra Swami, Yash Phogat, Aadiraj Batlaw, Ashwin Goyal", "title": "Analyzing movies to predict their commercial viability for producers", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Upon film premiere, a major form of speculation concerns the relative success\nof the film. This relativity is in particular regards to the film's original\nbudget, as many a time have big-budget blockbusters been met with exceptional\nsuccess as met with abject failure. So how does one predict the success of an\nupcoming film? In this paper, we explored a vast array of film data in an\nattempt to develop a model that could predict the expected return of an\nupcoming film. The approach to this development is as follows: First, we began\nwith the MovieLens dataset having common movie attributes along with genome\ntags per each film. Genome tags give insight into what particular\ncharacteristics of the film are most salient. We then included additional\nfeatures regarding film content, cast/crew, audience perception, budget, and\nearnings from TMDB, IMDB, and Metacritic websites. Next, we performed\nexploratory data analysis and engineered a wide range of new features capturing\nhistorical information for the available features. Thereafter, we used singular\nvalue decomposition (SVD) for dimensionality reduction of the high dimensional\nfeatures (ex. genome tags). Finally, we built a Random Forest Classifier and\nperformed hyper-parameter tuning to optimize for model accuracy. A future\napplication of our model could be seen in the film industry, allowing\nproduction companies to better predict the expected return of their projects\nbased on their envisioned outline for their production procedure, thereby\nallowing them to revise their plan in an attempt to achieve optimal returns.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 18:42:38 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Swami", "Devendra", ""], ["Phogat", "Yash", ""], ["Batlaw", "Aadiraj", ""], ["Goyal", "Ashwin", ""]]}, {"id": "2101.01761", "submitter": "Hieu Pham", "authors": "Hieu Pham, Quoc V. Le", "title": "AutoDropout: Learning Dropout Patterns to Regularize Deep Networks", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are often over-parameterized and hence benefit from\naggressive regularization. Conventional regularization methods, such as Dropout\nor weight decay, do not leverage the structures of the network's inputs and\nhidden states. As a result, these conventional methods are less effective than\nmethods that leverage the structures, such as SpatialDropout and DropBlock,\nwhich randomly drop the values at certain contiguous areas in the hidden states\nand setting them to zero. Although the locations of dropout areas random, the\npatterns of SpatialDropout and DropBlock are manually designed and fixed. Here\nwe propose to learn the dropout patterns. In our method, a controller learns to\ngenerate a dropout pattern at every channel and layer of a target network, such\nas a ConvNet or a Transformer. The target network is then trained with the\ndropout pattern, and its resulting validation performance is used as a signal\nfor the controller to learn from. We show that this method works well for both\nimage recognition on CIFAR-10 and ImageNet, as well as language modeling on\nPenn Treebank and WikiText-2. The learned dropout patterns also transfers to\ndifferent tasks and datasets, such as from language model on Penn Treebank to\nEngligh-French translation on WMT 2014. Our code will be available.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 19:54:22 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Pham", "Hieu", ""], ["Le", "Quoc V.", ""]]}, {"id": "2101.01860", "submitter": "Aaquib Tabrez", "authors": "Aaquib Tabrez, Ryan Leonard, Bradley Hayes", "title": "One-shot Policy Elicitation via Semantic Reward Manipulation", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronizing expectations and knowledge about the state of the world is an\nessential capability for effective collaboration. For robots to effectively\ncollaborate with humans and other autonomous agents, it is critical that they\nbe able to generate intelligible explanations to reconcile differences between\ntheir understanding of the world and that of their collaborators. In this work\nwe present Single-shot Policy Explanation for Augmenting Rewards (SPEAR), a\nnovel sequential optimization algorithm that uses semantic explanations derived\nfrom combinations of planning predicates to augment agents' reward functions,\ndriving their policies to exhibit more optimal behavior. We provide an\nexperimental validation of our algorithm's policy manipulation capabilities in\ntwo practically grounded applications and conclude with a performance analysis\nof SPEAR on domains of increasingly complex state space and predicate counts.\nWe demonstrate that our method makes substantial improvements over the\nstate-of-the-art in terms of runtime and addressable problem size, enabling an\nagent to leverage its own expertise to communicate actionable information to\nimprove another's performance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 04:11:22 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Tabrez", "Aaquib", ""], ["Leonard", "Ryan", ""], ["Hayes", "Bradley", ""]]}, {"id": "2101.01883", "submitter": "Takahisa Imagawa", "authors": "Takahisa Imagawa, Takuya Hiraoka, Yoshimasa Tsuruoka", "title": "Off-Policy Meta-Reinforcement Learning Based on Feature Embedding Spaces", "comments": "14pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-reinforcement learning (RL) addresses the problem of sample inefficiency\nin deep RL by using experience obtained in past tasks for a new task to be\nsolved.\n  However, most meta-RL methods require partially or fully on-policy data,\ni.e., they cannot reuse the data collected by past policies, which hinders the\nimprovement of sample efficiency.\n  To alleviate this problem, we propose a novel off-policy meta-RL method,\nembedding learning and evaluation of uncertainty (ELUE).\n  An ELUE agent is characterized by the learning of a feature embedding space\nshared among tasks.\n  It learns a belief model over the embedding space and a belief-conditional\npolicy and Q-function.\n  Then, for a new task, it collects data by the pretrained policy, and updates\nits belief based on the belief model.\n  Thanks to the belief update, the performance can be improved with a small\namount of data.\n  In addition, it updates the parameters of the neural networks to adjust the\npretrained relationships when there are enough data.\n  We demonstrate that ELUE outperforms state-of-the-art meta RL methods through\nexperiments on meta-RL benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 05:51:38 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Imagawa", "Takahisa", ""], ["Hiraoka", "Takuya", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "2101.01896", "submitter": "Xiangchen Song", "authors": "Jieyu Zhang, Xiangchen Song, Ying Zeng, Jiaze Chen, Jiaming Shen,\n  Yuning Mao, Lei Li", "title": "Taxonomy Completion via Triplet Matching Network", "comments": "AAA1 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically constructing taxonomy finds many applications in e-commerce and\nweb search. One critical challenge is as data and business scope grow in real\napplications, new concepts are emerging and needed to be added to the existing\ntaxonomy. Previous approaches focus on the taxonomy expansion, i.e. finding an\nappropriate hypernym concept from the taxonomy for a new query concept. In this\npaper, we formulate a new task, \"taxonomy completion\", by discovering both the\nhypernym and hyponym concepts for a query. We propose Triplet Matching Network\n(TMN), to find the appropriate <hypernym, hyponym> pairs for a given query\nconcept. TMN consists of one primal scorer and multiple auxiliary scorers.\nThese auxiliary scorers capture various fine-grained signals (e.g., query to\nhypernym or query to hyponym semantics), and the primal scorer makes a holistic\nprediction on <query, hypernym, hyponym> triplet based on the internal feature\nrepresentations of all auxiliary scorers. Also, an innovative channel-wise\ngating mechanism that retains task-specific information in concept\nrepresentations is introduced to further boost model performance. Experiments\non four real-world large-scale datasets show that TMN achieves the best\nperformance on both taxonomy completion task and the previous taxonomy\nexpansion task, outperforming existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 07:19:55 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 01:36:22 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 09:51:39 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhang", "Jieyu", ""], ["Song", "Xiangchen", ""], ["Zeng", "Ying", ""], ["Chen", "Jiaze", ""], ["Shen", "Jiaming", ""], ["Mao", "Yuning", ""], ["Li", "Lei", ""]]}, {"id": "2101.01899", "submitter": "Maitree Leekha", "authors": "Vidit Jain, Maitree Leekha, Rajiv Ratn Shah, Jainendra Shukla", "title": "Exploring Semi-Supervised Learning for Predicting Listener Backchannels", "comments": "Accepted at CHI 2021", "journal-ref": null, "doi": "10.1145/3411764.3445449", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing human-like conversational agents is a prime area in HCI research\nand subsumes many tasks. Predicting listener backchannels is one such\nactively-researched task. While many studies have used different approaches for\nbackchannel prediction, they all have depended on manual annotations for a\nlarge dataset. This is a bottleneck impacting the scalability of development.\nTo this end, we propose using semi-supervised techniques to automate the\nprocess of identifying backchannels, thereby easing the annotation process. To\nanalyze our identification module's feasibility, we compared the backchannel\nprediction models trained on (a) manually-annotated and (b) semi-supervised\nlabels. Quantitative analysis revealed that the proposed semi-supervised\napproach could attain 95% of the former's performance. Our user-study findings\nrevealed that almost 60% of the participants found the backchannel responses\npredicted by the proposed model more natural. Finally, we also analyzed the\nimpact of personality on the type of backchannel signals and validated our\nfindings in the user-study.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 07:30:38 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Jain", "Vidit", ""], ["Leekha", "Maitree", ""], ["Shah", "Rajiv Ratn", ""], ["Shukla", "Jainendra", ""]]}, {"id": "2101.01907", "submitter": "Hailin Wang", "authors": "Hailin Wang, Ke Qin, Rufai Yusuf Zakari, Guoming Lu, Jin Yin", "title": "Deep Neural Network Based Relation Extraction: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Knowledge is a formal way of understanding the world, providing a human-level\ncognition and intelligence for the next-generation artificial intelligence\n(AI). One of the representations of knowledge is semantic relations between\nentities. An effective way to automatically acquire this important knowledge,\ncalled Relation Extraction (RE), a sub-task of information extraction, plays a\nvital role in Natural Language Processing (NLP). Its purpose is to identify\nsemantic relations between entities from natural language text. To date, there\nare several studies for RE in previous works, which have documented these\ntechniques based on Deep Neural Networks (DNNs) become a prevailing technique\nin this research. Especially, the supervised and distant supervision methods\nbased on DNNs are the most popular and reliable solutions for RE. This article\n1) introduces some general concepts, and further 2) gives a comprehensive\noverview of DNNs in RE from two points of view: supervised RE, which attempts\nto improve the standard RE systems, and distant supervision RE, which adopts\nDNNs to design sentence encoder and de-noise method. We further 3) cover some\nnovel methods and recent trends as well as discuss possible future research\ndirections for this task.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 07:53:05 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 19:13:54 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wang", "Hailin", ""], ["Qin", "Ke", ""], ["Zakari", "Rufai Yusuf", ""], ["Lu", "Guoming", ""], ["Yin", "Jin", ""]]}, {"id": "2101.01926", "submitter": "Xuekai Li", "authors": "Tongtong Wu, Xuekai Li, Yuan-Fang Li, Reza Haffari, Guilin Qi, Yujin\n  Zhu and Guoqiang Xu", "title": "Curriculum-Meta Learning for Order-Robust Continual Relation Extraction", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual relation extraction is an important task that focuses on extracting\nnew facts incrementally from unstructured text. Given the sequential arrival\norder of the relations, this task is prone to two serious challenges, namely\ncatastrophic forgetting and order-sensitivity. We propose a novel\ncurriculum-meta learning method to tackle the above two challenges in continual\nrelation extraction. We combine meta learning and curriculum learning to\nquickly adapt model parameters to a new task and to reduce interference of\npreviously seen tasks on the current task. We design a novel relation\nrepresentation learning method through the distribution of domain and range\ntypes of relations. Such representations are utilized to quantify the\ndifficulty of tasks for the construction of curricula. Moreover, we also\npresent novel difficulty-based metrics to quantitatively measure the extent of\norder-sensitivity of a given model, suggesting new ways to evaluate model\nrobustness. Our comprehensive experiments on three benchmark datasets show that\nour proposed method outperforms the state-of-the-art techniques. The code is\navailable at the anonymous GitHub repository:\nhttps://github.com/wutong8023/AAAI_CML.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 08:52:34 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 02:25:10 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 10:06:40 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Wu", "Tongtong", ""], ["Li", "Xuekai", ""], ["Li", "Yuan-Fang", ""], ["Haffari", "Reza", ""], ["Qi", "Guilin", ""], ["Zhu", "Yujin", ""], ["Xu", "Guoqiang", ""]]}, {"id": "2101.01953", "submitter": "Alexis de Colnet", "authors": "Alexis de Colnet", "title": "A Lower Bound on DNNF Encodings of Pseudo-Boolean Constraints", "comments": "8 pages, 10 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two major considerations when encoding pseudo-Boolean (PB) constraints into\nSAT are the size of the encoding and its propagation strength, that is, the\nguarantee that it has a good behaviour under unit propagation. Several\nencodings with propagation strength guarantees rely upon prior compilation of\nthe constraints into DNNF (decomposable negation normal form), BDD (binary\ndecision diagram), or some other sub-variants. However it has been shown that\nthere exist PB-constraints whose ordered BDD (OBDD) representations, and thus\nthe inferred CNF encodings, all have exponential size. Since DNNFs are more\nsuccinct than OBDDs, preferring encodings via DNNF to avoid size explosion\nseems a legitimate choice. Yet in this paper, we prove the existence of\nPB-constraints whose DNNFs all require exponential size.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 10:25:22 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["de Colnet", "Alexis", ""]]}, {"id": "2101.01973", "submitter": "Xiaobo Liu", "authors": "Xiaobo Liu, Su Yang", "title": "Weighted Ensemble-model and Network Analysis: A method to predict fluid\n  intelligence via naturalistic functional connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objectives: Functional connectivity triggered by naturalistic stimulus (e.g.,\nmovies) and machine learning techniques provide a great insight in exploring\nthe brain functions such as fluid intelligence. However, functional\nconnectivity are considered to be multi-layered, while traditional machine\nlearning based on individual models not only are limited in performance, but\nalso fail to extract multi-dimensional and multi-layered information from brain\nnetwork. Methods: In this study, inspired by multi-layer brain network\nstructure, we propose a new method namely Weighted Ensemble-model and Network\nAnalysis, which combines the machine learning and graph theory for improved\nfluid intelligence prediction. Firstly, functional connectivity analysis and\ngraphical theory were jointly employed. The functional connectivity and\ngraphical indices computed using the preprocessed fMRI data were then all fed\ninto auto-encoder parallelly for feature extraction to predict the fluid\nintelligence. In order to improve the performance, tree regression and ridge\nregression model were automatically stacked and fused with weighted values.\nFinally, layers of auto-encoder were visualized to better illustrate the\nconnectome patterns, followed by the evaluation of the performance to justify\nthe mechanism of brain functions. Results: Our proposed methods achieved best\nperformance with 3.85 mean absolute deviation, 0.66 correlation coefficient and\n0.42 R-squared coefficient, outperformed other state-of-the-art methods. It is\nalso worth noting that, the optimization of the biological pattern extraction\nwas automated though the auto-encoder algorithm. Conclusion: The proposed\nmethod not only outperforming the state-of-the-art reports, but also able to\neffectively capturing the biological patterns from functional connectivity\nduring naturalistic movies state for potential clinical explorations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 11:17:49 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Liu", "Xiaobo", ""], ["Yang", "Su", ""]]}, {"id": "2101.02030", "submitter": "Sunder Ali Khowaja", "authors": "Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev", "title": "Internet of Everything enabled solution for COVID-19, its new variants\n  and future pandemics: Framework, Challenges, and Research Directions", "comments": "14 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  After affecting the world in unexpected ways, COVID-19 has started mutating\nwhich is evident with the insurgence of its new variants. The governments,\nhospitals, schools, industries, and humans, in general, are looking for a\npotential solution in the vaccine which will eventually be available but its\ntimeline for eradicating the virus is yet unknown. Several researchers have\nencouraged and recommended the use of good practices such as physical\nhealthcare monitoring, immunity-boosting, personal hygiene, mental healthcare,\nand contact tracing for slowing down the spread of the virus. In this article,\nwe propose the use of wearable/mobile sensors integrated with the Internet of\nEverything to cover the spectrum of good practices in an automated manner. We\npresent hypothetical frameworks for each of the good practice modules and\npropose the COvid-19 Resistance Framework using the Internet of Everything\n(CORFIE) to tie all the individual modules in a unified architecture. We\nenvision that CORFIE would be influential in assisting people with the new\nnormal for current and future pandemics as well as instrumental in halting the\neconomic losses, respectively. We also provide potential challenges and their\nprobable solutions in compliance with the proposed CORFIE.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 07:27:34 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 09:49:07 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 09:11:56 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Khowaja", "Sunder Ali", ""], ["Khuwaja", "Parus", ""], ["Dev", "Kapal", ""]]}, {"id": "2101.02032", "submitter": "Lu Cheng", "authors": "Lu Cheng, Kush R. Varshney, Huan Liu", "title": "Socially Responsible AI Algorithms: Issues, Purposes, and Challenges", "comments": "45 pages, 8 figures, Accepted to JAIR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the current era, people and society have grown increasingly reliant on\nartificial intelligence (AI) technologies. AI has the potential to drive us\ntowards a future in which all of humanity flourishes. It also comes with\nsubstantial risks for oppression and calamity. Discussions about whether we\nshould (re)trust AI have repeatedly emerged in recent years and in many\nquarters, including industry, academia, healthcare, services, and so on.\nTechnologists and AI researchers have a responsibility to develop trustworthy\nAI systems. They have responded with great effort to design more responsible AI\nalgorithms. However, existing technical solutions are narrow in scope and have\nbeen primarily directed towards algorithms for scoring or classification tasks,\nwith an emphasis on fairness and unwanted bias. To build long-lasting trust\nbetween AI and human beings, we argue that the key is to think beyond\nalgorithmic fairness and connect major aspects of AI that potentially cause\nAI's indifferent behavior. In this survey, we provide a systematic framework of\nSocially Responsible AI Algorithms that aims to examine the subjects of AI\nindifference and the need for socially responsible AI algorithms, define the\nobjectives, and introduce the means by which we may achieve these objectives.\nWe further discuss how to leverage this framework to improve societal\nwell-being through protection, information, and prevention/mitigation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 17:34:42 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 21:18:17 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 20:12:58 GMT"}, {"version": "v4", "created": "Fri, 25 Jun 2021 21:21:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Cheng", "Lu", ""], ["Varshney", "Kush R.", ""], ["Liu", "Huan", ""]]}, {"id": "2101.02034", "submitter": "Qing Wei", "authors": "Qing Wei, Hailan Ma, Chunlin Chen, Daoyi Dong", "title": "Deep Reinforcement Learning with Quantum-inspired Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel training paradigm inspired by quantum computation is\nproposed for deep reinforcement learning (DRL) with experience replay. In\ncontrast to traditional experience replay mechanism in DRL, the proposed deep\nreinforcement learning with quantum-inspired experience replay (DRL-QER)\nadaptively chooses experiences from the replay buffer according to the\ncomplexity and the replayed times of each experience (also called transition),\nto achieve a balance between exploration and exploitation. In DRL-QER,\ntransitions are first formulated in quantum representations, and then the\npreparation operation and the depreciation operation are performed on the\ntransitions. In this progress, the preparation operation reflects the\nrelationship between the temporal difference errors (TD-errors) and the\nimportance of the experiences, while the depreciation operation is taken into\naccount to ensure the diversity of the transitions. The experimental results on\nAtari 2600 games show that DRL-QER outperforms state-of-the-art algorithms such\nas DRL-PER and DCRL on most of these games with improved training efficiency,\nand is also applicable to such memory-based DRL approaches as double network\nand dueling network.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 13:52:04 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wei", "Qing", ""], ["Ma", "Hailan", ""], ["Chen", "Chunlin", ""], ["Dong", "Daoyi", ""]]}, {"id": "2101.02046", "submitter": "Junyi Li", "authors": "Junyi Li, Tianyi Tang, Gaole He, Jinhao Jiang, Xiaoxuan Hu, Puzhao\n  Xie, Zhipeng Chen, Zhuohao Yu, Wayne Xin Zhao, Ji-Rong Wen", "title": "TextBox: A Unified, Modularized, and Extensible Framework for Text\n  Generation", "comments": "9 pages, 2 figures, 4 tables. For our GitHub page, see\n  https://github.com/RUCAIBox/TextBox", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we release an open-source library, called TextBox, to provide\na unified, modularized, and extensible text generation framework. TextBox aims\nto support a broad set of text generation tasks and models. In our library, we\nimplement 21 text generation models on 9 benchmark datasets, covering the\ncategories of VAE, GAN, and pretrained language models. Meanwhile, our library\nmaintains sufficient modularity and extensibility by properly decomposing the\nmodel architecture, inference, and learning process into highly reusable\nmodules, which allows users to easily incorporate new models into our\nframework. The above features make TextBox specially suitable for researchers\nand practitioners to quickly reproduce baseline models and develop new models.\nTextBox is implemented based on PyTorch, and released under Apache License 2.0\nat https://github.com/RUCAIBox/TextBox.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 14:02:42 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 09:28:10 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 08:36:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Junyi", ""], ["Tang", "Tianyi", ""], ["He", "Gaole", ""], ["Jiang", "Jinhao", ""], ["Hu", "Xiaoxuan", ""], ["Xie", "Puzhao", ""], ["Chen", "Zhipeng", ""], ["Yu", "Zhuohao", ""], ["Zhao", "Wayne Xin", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2101.02082", "submitter": "Yao Rong", "authors": "Yao Rong, Chao Han, Christian Hellert, Antje Loyal, Enkelejda Kasneci", "title": "Artificial Intelligence Methods in In-Cabin Use Cases: A Survey", "comments": "11 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As interest in autonomous driving increases, efforts are being made to meet\nrequirements for the high-level automation of vehicles. In this context, the\nfunctionality inside the vehicle cabin plays a key role in ensuring a safe and\npleasant journey for driver and passenger alike. At the same time, recent\nadvances in the field of artificial intelligence (AI) have enabled a whole\nrange of new applications and assistance systems to solve automated problems in\nthe vehicle cabin. This paper presents a thorough survey on existing work that\nutilizes AI methods for use-cases inside the driving cabin, focusing, in\nparticular, on application scenarios related to (1) driving safety and (2)\ndriving comfort. Results from the surveyed works show that AI technology has a\npromising future in tackling in-cabin tasks within the autonomous driving\naspect.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 15:08:39 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Rong", "Yao", ""], ["Han", "Chao", ""], ["Hellert", "Christian", ""], ["Loyal", "Antje", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2101.02120", "submitter": "Eric Piette E.P.", "authors": "Eric Piette, Cameron Browne and Dennis J. N. J. Soemers", "title": "Ludii Game Logic Guide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report outlines the fundamental workings of the game logic\nbehind Ludii, a general game system, that can be used to play a wide variety of\ngames. Ludii is a program developed for the ERC-funded Digital Ludeme Project,\nin which mathematical and computational approaches are used to study how games\nwere played, and spread, throughout history. This report explains how general\ngame states and equipment are represented in Ludii, and how the rule ludemes\ndictating play are implemented behind the scenes, giving some insight into the\ncore game logic behind the Ludii general game player. This guide is intended to\nhelp game designers using the Ludii game description language to understand it\nmore completely and make fuller use of its features when describing their\ngames.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 16:22:37 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Piette", "Eric", ""], ["Browne", "Cameron", ""], ["Soemers", "Dennis J. N. J.", ""]]}, {"id": "2101.02153", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Rik Sarkar", "title": "The Shapley Value of Classifiers in Ensemble Games", "comments": "Source code is available here:\n  https://github.com/benedekrozemberczki/shapley", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.GT cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What is the value of an individual model in an ensemble of binary\nclassifiers? We answer this question by introducing a class of transferable\nutility cooperative games called \\textit{ensemble games}. In machine learning\nensembles, pre-trained models cooperate to make classification decisions. To\nquantify the importance of models in these ensemble games, we define\n\\textit{Troupe} -- an efficient algorithm which allocates payoffs based on\napproximate Shapley values of the classifiers. We argue that the Shapley value\nof models in these games is an effective decision metric for choosing a high\nperforming subset of models from the ensemble. Our analytical findings prove\nthat our Shapley value estimation scheme is precise and scalable; its\nperformance increases with size of the dataset and ensemble. Empirical results\non real world graph classification tasks demonstrate that our algorithm\nproduces high quality estimates of the Shapley value. We find that Shapley\nvalues can be utilized for ensemble pruning, and that adversarial models\nreceive a low valuation. Complex classifiers are frequently found to be\nresponsible for both correct and incorrect classification decisions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 17:40:23 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 20:38:54 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2101.02158", "submitter": "Kenneth Clarkson", "authors": "Kenneth L. Clarkson and Sanjana Sahayaraj", "title": "Order Embeddings from Merged Ontologies using Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple, low resource method to produce order embeddings from\nontologies. Such embeddings map words to vectors so that order relations on the\nwords, such as hypernymy/hyponymy, are represented in a direct way. Our method\nuses sketching techniques, in particular countsketch, for dimensionality\nreduction. We also study methods to merge ontologies, in particular those in\nmedical domains, so that order relations are preserved. We give computational\nresults for medical ontologies and for wordnet, showing that our merging\ntechniques are effective and our embedding yields an accurate representation in\nboth generic and specialised domains.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 17:50:55 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Clarkson", "Kenneth L.", ""], ["Sahayaraj", "Sanjana", ""]]}, {"id": "2101.02178", "submitter": "Oscar Hsu LiJen", "authors": "Oscar LiJen Hsu", "title": "Improving Training Result of Partially Observable Markov Decision\n  Process by Filtering Beliefs", "comments": "7 pages with rich pictures to show the idea of POMDP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study I proposed a filtering beliefs method for improving performance\nof Partially Observable Markov Decision Processes(POMDPs), which is a method\nwildly used in autonomous robot and many other domains concerning control\npolicy. My method search and compare every similar belief pair. Because a\nsimilar belief have insignificant influence on control policy, the belief is\nfiltered out for reducing training time. The empirical results show that the\nproposed method outperforms the point-based approximate POMDPs in terms of the\nquality of training results as well as the efficiency of the method.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 04:24:54 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Hsu", "Oscar LiJen", ""]]}, {"id": "2101.02179", "submitter": "Mark McPherson", "authors": "Mark McPherson", "title": "The case for psychometric artificial general intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A short review of the literature on measurement and detection of artificial\ngeneral intelligence is made. Proposed benchmarks and tests for artificial\ngeneral intelligence are critically evaluated against multiple criteria. Based\non the findings, the most promising approaches are identified and some useful\ndirections for future work are proposed.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 23:45:03 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["McPherson", "Mark", ""]]}, {"id": "2101.02185", "submitter": "Seyed Sajjadi", "authors": "Volkan Ustun, Rajay Kumar, Adam Reilly, Seyed Sajjadi, Andrew Miller", "title": "Adaptive Synthetic Characters for Military Training", "comments": null, "journal-ref": "2020 Interservice/Industry Training, Simulation, and Education\n  Conference (I/ITSEC)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behaviors of the synthetic characters in current military simulations are\nlimited since they are generally generated by rule-based and reactive\ncomputational models with minimal intelligence. Such computational models\ncannot adapt to reflect the experience of the characters, resulting in brittle\nintelligence for even the most effective behavior models devised via costly and\nlabor-intensive processes. Observation-based behavior model adaptation that\nleverages machine learning and the experience of synthetic entities in\ncombination with appropriate prior knowledge can address the issues in the\nexisting computational behavior models to create a better training experience\nin military training simulations. In this paper, we introduce a framework that\naims to create autonomous synthetic characters that can perform coherent\nsequences of believable behavior while being aware of human trainees and their\nneeds within a training simulation. This framework brings together three\nmutually complementary components. The first component is a Unity-based\nsimulation environment - Rapid Integration and Development Environment (RIDE) -\nsupporting One World Terrain (OWT) models and capable of running and supporting\nmachine learning experiments. The second is Shiva, a novel multi-agent\nreinforcement and imitation learning framework that can interface with a\nvariety of simulation environments, and that can additionally utilize a variety\nof learning algorithms. The final component is the Sigma Cognitive Architecture\nthat will augment the behavior models with symbolic and probabilistic reasoning\ncapabilities. We have successfully created proof-of-concept behavior models\nleveraging this framework on realistic terrain as an essential step towards\nbringing machine learning into military simulations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 18:45:48 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ustun", "Volkan", ""], ["Kumar", "Rajay", ""], ["Reilly", "Adam", ""], ["Sajjadi", "Seyed", ""], ["Miller", "Andrew", ""]]}, {"id": "2101.02230", "submitter": "Kaige Yang Mr", "authors": "Kaige Yang", "title": "Learn Dynamic-Aware State Embedding for Transfer Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer reinforcement learning aims to improve the sample efficiency of\nsolving unseen new tasks by leveraging experiences obtained from previous\ntasks. We consider the setting where all tasks (MDPs) share the same\nenvironment dynamic except reward function. In this setting, the MDP dynamic is\na good knowledge to transfer, which can be inferred by uniformly random policy.\nHowever, trajectories generated by uniform random policy are not useful for\npolicy improvement, which impairs the sample efficiency severely. Instead, we\nobserve that the binary MDP dynamic can be inferred from trajectories of any\npolicy which avoids the need of uniform random policy. As the binary MDP\ndynamic contains the state structure shared over all tasks we believe it is\nsuitable to transfer. Built on this observation, we introduce a method to infer\nthe binary MDP dynamic on-line and at the same time utilize it to guide state\nembedding learning, which is then transferred to new tasks. We keep state\nembedding learning and policy learning separately. As a result, the learned\nstate embedding is task and policy agnostic which makes it ideal for transfer\nlearning. In addition, to facilitate the exploration over the state space, we\npropose a novel intrinsic reward based on the inferred binary MDP dynamic. Our\nmethod can be used out-of-box in combination with model-free RL algorithms. We\nshow two instances on the basis of \\algo{DQN} and \\algo{A2C}. Empirical results\nof intensive experiments show the advantage of our proposed method in various\ntransfer learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 19:07:31 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Yang", "Kaige", ""]]}, {"id": "2101.02231", "submitter": "Seyed Sajjadi", "authors": "Volkan Ustun, Paul S. Rosenbloom, Seyed Sajjadi, Jeremy Nuttal", "title": "Controlling Synthetic Characters in Simulations: A Case for Cognitive\n  Architectures and Sigma", "comments": null, "journal-ref": "Interservice/Industry Training, Simulation, and Education\n  Conference (I/ITSEC) 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulations, along with other similar applications like virtual worlds and\nvideo games, require computational models of intelligence that generate\nrealistic and credible behavior for the participating synthetic characters.\nCognitive architectures, which are models of the fixed structure underlying\nintelligent behavior in both natural and artificial systems, provide a\nconceptually valid common basis, as evidenced by the current efforts towards a\nstandard model of the mind, to generate human-like intelligent behavior for\nthese synthetic characters. Sigma is a cognitive architecture and system that\nstrives to combine what has been learned from four decades of independent work\non symbolic cognitive architectures, probabilistic graphical models, and more\nrecently neural models, under its graphical architecture hypothesis. Sigma\nleverages an extended form of factor graphs towards a uniform grand unification\nof not only traditional cognitive capabilities but also key non-cognitive\naspects, creating unique opportunities for the construction of new kinds of\ncognitive models that possess a Theory-of-Mind and that are perceptual,\nautonomous, interactive, affective, and adaptive. In this paper, we will\nintroduce Sigma along with its diverse capabilities and then use three distinct\nproof-of-concept Sigma models to highlight combinations of these capabilities:\n(1) Distributional reinforcement learning models in; (2) A pair of adaptive and\ninteractive agent models that demonstrate rule-based, probabilistic, and social\nreasoning; and (3) A knowledge-free exploration model in which an agent\nleverages only architectural appraisal variables, namely attention and\ncuriosity, to locate an item while building up a map in a Unity environment.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 19:07:36 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Ustun", "Volkan", ""], ["Rosenbloom", "Paul S.", ""], ["Sajjadi", "Seyed", ""], ["Nuttal", "Jeremy", ""]]}, {"id": "2101.02232", "submitter": "Prateek Agrawal", "authors": "Prateek Agrawal and Pratik Prabhanjan Brahma", "title": "Single Shot Multitask Pedestrian Detection and Behavior Prediction", "comments": "6 pages, 3 figures, Neurips 2020 ML4AD workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detecting and predicting the behavior of pedestrians is extremely crucial for\nself-driving vehicles to plan and interact with them safely. Although there\nhave been several research works in this area, it is important to have fast and\nmemory efficient models such that it can operate in embedded hardware in these\nautonomous machines. In this work, we propose a novel architecture using\nspatial-temporal multi-tasking to do camera based pedestrian detection and\nintention prediction. Our approach significantly reduces the latency by being\nable to detect and predict all pedestrians' intention in a single shot manner\nwhile also being able to attain better accuracy by sharing features with\nrelevant object level information and interactions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 19:10:23 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Agrawal", "Prateek", ""], ["Brahma", "Pratik Prabhanjan", ""]]}, {"id": "2101.02327", "submitter": "Baogang Hu", "authors": "Bao-Gang Hu and Wei-Ming Dong", "title": "A design of human-like robust AI machines in object identification", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a perspective paper inspired from the study of Turing Test proposed\nby A.M. Turing (23 June 1912 - 7 June 1954) in 1950. Following one important\nimplication of Turing Test for enabling a machine with a human-like behavior or\nperformance, we define human-like robustness (HLR) for AI machines. The\nobjective of the new definition aims to enforce AI machines with HLR, including\nto evaluate them in terms of HLR. A specific task is discussed only on object\nidentification, because it is the most common task for every person in daily\nlife. Similar to the perspective, or design, position by Turing, we provide a\nsolution of how to achieve HLR AI machines without constructing them and\nconducting real experiments. The solution should consists of three important\nfeatures in the machines. The first feature of HLR machines is to utilize\ncommon sense from humans for realizing a causal inference. The second feature\nis to make a decision from a semantic space for having interpretations to the\ndecision. The third feature is to include a \"human-in-the-loop\" setting for\nadvancing HLR machines. We show an \"identification game\" using proposed design\nof HLR machines. The present paper shows an attempt to learn and explore\nfurther from Turing Test towards the design of human-like AI machines.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 02:11:45 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Hu", "Bao-Gang", ""], ["Dong", "Wei-Ming", ""]]}, {"id": "2101.02338", "submitter": "Haoran You", "authors": "Randall Balestriero, Haoran You, Zhihan Lu, Yutong Kou, Huihong Shi,\n  Yingyan Lin, Richard Baraniuk", "title": "Max-Affine Spline Insights Into Deep Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the importance of pruning in Deep Networks (DNs) and\nthe yin & yang relationship between (1) pruning highly overparametrized DNs\nthat have been trained from random initialization and (2) training small DNs\nthat have been \"cleverly\" initialized. As in most cases practitioners can only\nresort to random initialization, there is a strong need to develop a grounded\nunderstanding of DN pruning. Current literature remains largely empirical,\nlacking a theoretical understanding of how pruning affects DNs' decision\nboundary, how to interpret pruning, and how to design corresponding principled\npruning techniques. To tackle those questions, we propose to employ recent\nadvances in the theoretical analysis of Continuous Piecewise Affine (CPA) DNs.\nFrom this perspective, we will be able to detect the early-bird (EB) ticket\nphenomenon, provide interpretability into current pruning techniques, and\ndevelop a principled pruning strategy. In each step of our study, we conduct\nextensive experiments supporting our claims and results; while our main goal is\nto enhance the current understanding towards DN pruning instead of developing a\nnew pruning method, our spline pruning criteria in terms of layerwise and\nglobal pruning is on par with or even outperforms state-of-the-art pruning\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 02:42:16 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 01:21:40 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Balestriero", "Randall", ""], ["You", "Haoran", ""], ["Lu", "Zhihan", ""], ["Kou", "Yutong", ""], ["Shi", "Huihong", ""], ["Lin", "Yingyan", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2101.02344", "submitter": "Yufang Huang Dr.", "authors": "Yufang Huang, Kelly M. Axsom, John Lee, Lakshminarayanan Subramanian\n  and Yiye Zhang", "title": "DICE: Deep Significance Clustering for Outcome-Aware Stratification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deep significance clustering (DICE), a framework for jointly\nperforming representation learning and clustering for \"outcome-aware\"\nstratification. DICE is intended to generate cluster membership that may be\nused to categorize a population by individual risk level for a targeted\noutcome. Following the representation learning and clustering steps, we embed\nthe objective function in DICE with a constraint which requires a statistically\nsignificant association between the outcome and cluster membership of learned\nrepresentations. DICE further includes a neural architecture search step to\nmaximize both the likelihood of representation learning and outcome\nclassification accuracy with cluster membership as the predictor. To\ndemonstrate its utility in medicine for patient risk-stratification, the\nperformance of DICE was evaluated using two datasets with different outcome\nratios extracted from real-world electronic health records. Outcomes are\ndefined as acute kidney injury (30.4\\%) among a cohort of COVID-19 patients,\nand discharge disposition (36.8\\%) among a cohort of heart failure patients,\nrespectively. Extensive results demonstrate that DICE has superior performance\nas measured by the difference in outcome distribution across clusters,\nSilhouette score, Calinski-Harabasz index, and Davies-Bouldin index for\nclustering, and Area under the ROC Curve (AUC) for outcome classification\ncompared to several baseline approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 03:06:52 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Huang", "Yufang", ""], ["Axsom", "Kelly M.", ""], ["Lee", "John", ""], ["Subramanian", "Lakshminarayanan", ""], ["Zhang", "Yiye", ""]]}, {"id": "2101.02349", "submitter": "Diddigi Raghuram Bharadwaj", "authors": "P.Parnika, Raghuram Bharadwaj Diddigi, Sai Koti Reddy Danda and\n  Shalabh Bhatnagar", "title": "Attention Actor-Critic algorithm for Multi-Agent Constrained\n  Co-operative Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of computing optimal actions for\nReinforcement Learning (RL) agents in a co-operative setting, where the\nobjective is to optimize a common goal. However, in many real-life\napplications, in addition to optimizing the goal, the agents are required to\nsatisfy certain constraints specified on their actions. Under this setting, the\nobjective of the agents is to not only learn the actions that optimize the\ncommon objective but also meet the specified constraints. In recent times, the\nActor-Critic algorithm with an attention mechanism has been successfully\napplied to obtain optimal actions for RL agents in multi-agent environments. In\nthis work, we extend this algorithm to the constrained multi-agent RL setting.\nThe idea here is that optimizing the common goal and satisfying the constraints\nmay require different modes of attention. By incorporating different attention\nmodes, the agents can select useful information required for optimizing the\nobjective and satisfying the constraints separately, thereby yielding better\nactions. Through experiments on benchmark multi-agent environments, we show the\neffectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 03:21:15 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Parnika", "P.", ""], ["Diddigi", "Raghuram Bharadwaj", ""], ["Danda", "Sai Koti Reddy", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "2101.02352", "submitter": "JianGang Liu", "authors": "Yao Chen, Jiangang Liu, Zhe Zhang, Shiping Wen, Wenjun Xiong", "title": "M\\\"{o}biusE: Knowledge Graph Embedding on M\\\"{o}bius Ring", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2021.107181", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel Knowledge Graph Embedding (KGE) strategy,\ncalled M\\\"{o}biusE, in which the entities and relations are embedded to the\nsurface of a M\\\"{o}bius ring. The proposition of such a strategy is inspired by\nthe classic TorusE, in which the addition of two arbitrary elements is subject\nto a modulus operation. In this sense, TorusE naturally guarantees the critical\nboundedness of embedding vectors in KGE. However, the nonlinear property of\naddition operation on Torus ring is uniquely derived by the modulus operation,\nwhich in some extent restricts the expressiveness of TorusE. As a further\ngeneralization of TorusE, M\\\"{o}biusE also uses modulus operation to preserve\nthe closeness of addition operation on it, but the coordinates on M\\\"{o}bius\nring interacts with each other in the following way: {\\em \\color{red} any\nvector on the surface of a M\\\"{o}bius ring moves along its parametric trace\nwill goes to the right opposite direction after a cycle}. Hence, M\\\"{o}biusE\nassumes much more nonlinear representativeness than that of TorusE, and in turn\nit generates much more precise embedding results. In our experiments,\nM\\\"{o}biusE outperforms TorusE and other classic embedding strategies in\nseveral key indicators.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 03:35:06 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Yao", ""], ["Liu", "Jiangang", ""], ["Zhang", "Zhe", ""], ["Wen", "Shiping", ""], ["Xiong", "Wenjun", ""]]}, {"id": "2101.02353", "submitter": "Shuwei Shen", "authors": "Shuwei Shen, Mengjuan Xu, Fan Zhang, Pengfei Shao, Honghong Liu, Liang\n  Xu, Chi Zhang, Peng Liu, Zhihong Zhang, Peng Yao, Ronald X. Xu", "title": "Low-cost and high-performance data augmentation for deep-learning-based\n  skin lesion classification", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep convolutional neural networks (DCNNs) have achieved significant\naccuracy in skin lesion classification comparable or even superior to those of\ndermatologists, practical implementation of these models for skin cancer\nscreening in low resource settings is hindered by their limitations in\ncomputational cost and training dataset. To overcome these limitations, we\npropose a low-cost and high-performance data augmentation strategy that\nincludes two consecutive stages of augmentation search and network search. At\nthe augmentation search stage, the augmentation strategy is optimized in the\nsearch space of Low-Cost-Augment (LCA) under the criteria of balanced accuracy\n(BACC) with 5-fold cross validation. At the network search stage, the DCNNs are\nfine-tuned with the full training set in order to select the model with the\nhighest BACC. The efficiency of the proposed data augmentation strategy is\nverified on the HAM10000 dataset using EfficientNets as a baseline. With the\nproposed strategy, we are able to reduce the search space to 60 and achieve a\nhigh BACC of 0.853 by using a single DCNN model without external database,\nsuitable to be implemented in mobile devices for DCNN-based skin lesion\ndetection in low resource settings.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 03:43:15 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Shen", "Shuwei", ""], ["Xu", "Mengjuan", ""], ["Zhang", "Fan", ""], ["Shao", "Pengfei", ""], ["Liu", "Honghong", ""], ["Xu", "Liang", ""], ["Zhang", "Chi", ""], ["Liu", "Peng", ""], ["Zhang", "Zhihong", ""], ["Yao", "Peng", ""], ["Xu", "Ronald X.", ""]]}, {"id": "2101.02359", "submitter": "Xiangyang Li", "authors": "Xiangyang Li, Yu Xia, Xiang Long, Zheng Li, Sujian Li", "title": "Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News\n  Detection in English", "comments": "3rd solution of 'Constraint@AAAI2021 - COVID19 Fake News Detection in\n  English'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our system for the AAAI 2021 shared task of\nCOVID-19 Fake News Detection in English, where we achieved the 3rd position\nwith the weighted F1 score of 0.9859 on the test set. Specifically, we proposed\nan ensemble method of different pre-trained language models such as BERT,\nRoberta, Ernie, etc. with various training strategies including\nwarm-up,learning rate schedule and k-fold cross-validation. We also conduct an\nextensive analysis of the samples that are not correctly classified. The code\nis available\nat:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 04:01:13 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Li", "Xiangyang", ""], ["Xia", "Yu", ""], ["Long", "Xiang", ""], ["Li", "Zheng", ""], ["Li", "Sujian", ""]]}, {"id": "2101.02390", "submitter": "Junjie Huang", "authors": "Junjie Huang, Huawei Shen, Liang Hou, Xueqi Cheng", "title": "SDGNN: Learning Node Representation for Signed Directed Networks", "comments": "Accepted and to appear at AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is aimed at mapping nodes in a network into low-dimensional\nvector representations. Graph Neural Networks (GNNs) have received widespread\nattention and lead to state-of-the-art performance in learning node\nrepresentations. However, most GNNs only work in unsigned networks, where only\npositive links exist. It is not trivial to transfer these models to signed\ndirected networks, which are widely observed in the real world yet less\nstudied. In this paper, we first review two fundamental sociological theories\n(i.e., status theory and balance theory) and conduct empirical studies on\nreal-world datasets to analyze the social mechanism in signed directed\nnetworks. Guided by related sociological theories, we propose a novel Signed\nDirected Graph Neural Networks model named SDGNN to learn node embeddings for\nsigned directed networks. The proposed model simultaneously reconstructs link\nsigns, link directions, and signed directed triangles. We validate our model's\neffectiveness on five real-world datasets, which are commonly used as the\nbenchmark for signed network embedding. Experiments demonstrate the proposed\nmodel outperforms existing models, including feature-based methods, network\nembedding methods, and several GNN methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 06:15:07 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 02:23:07 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 11:45:02 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Huang", "Junjie", ""], ["Shen", "Huawei", ""], ["Hou", "Liang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2101.02397", "submitter": "Kaustubh Yadav", "authors": "Kaustubh Yadav", "title": "A Comprehensive Study on Optimization Strategies for Gradient Descent In\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most important parts of Artificial Neural Networks is minimizing\nthe loss functions which tells us how good or bad our model is. To minimize\nthese losses we need to tune the weights and biases. Also to calculate the\nminimum value of a function we need gradient. And to update our weights we need\ngradient descent. But there are some problems with regular gradient descent ie.\nit is quite slow and not that accurate. This article aims to give an\nintroduction to optimization strategies to gradient descent. In addition, we\nshall also discuss the architecture of these algorithms and further\noptimization of Neural Networks in general\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 06:24:55 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Yadav", "Kaustubh", ""]]}, {"id": "2101.02402", "submitter": "Wen-Yi Hsiao", "authors": "Wen-Yi Hsiao, Jen-Yu Liu, Yin-Cheng Yeh, Yi-Hsuan Yang", "title": "Compound Word Transformer: Learning to Compose Full-Song Music over\n  Dynamic Directed Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To apply neural sequence models such as the Transformers to music generation\ntasks, one has to represent a piece of music by a sequence of tokens drawn from\na finite set of pre-defined vocabulary. Such a vocabulary usually involves\ntokens of various types. For example, to describe a musical note, one needs\nseparate tokens to indicate the note's pitch, duration, velocity (dynamics),\nand placement (onset time) along the time grid. While different types of tokens\nmay possess different properties, existing models usually treat them equally,\nin the same way as modeling words in natural languages. In this paper, we\npresent a conceptually different approach that explicitly takes into account\nthe type of the tokens, such as note types and metric types. And, we propose a\nnew Transformer decoder architecture that uses different feed-forward heads to\nmodel tokens of different types. With an expansion-compression trick, we\nconvert a piece of music to a sequence of compound words by grouping\nneighboring tokens, greatly reducing the length of the token sequences. We show\nthat the resulting model can be viewed as a learner over dynamic directed\nhypergraphs. And, we employ it to learn to compose expressive Pop piano music\nof full-song length (involving up to 10K individual tokens per song), both\nconditionally and unconditionally. Our experiment shows that, compared to\nstate-of-the-art models, the proposed model converges 5--10 times faster at\ntraining (i.e., within a day on a single GPU with 11 GB memory), and with\ncomparable quality in the generated music.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 06:57:34 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Hsiao", "Wen-Yi", ""], ["Liu", "Jen-Yu", ""], ["Yeh", "Yin-Cheng", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2101.02409", "submitter": "Ignacio Rodr\\'iguez Dr.", "authors": "Ignacio Rodriguez", "title": "On the Management of Type 1 Diabetes Mellitus with IoT Devices and ML\n  Techniques", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The purpose of this Conference is to present the main lines of base projects\nthat are founded on research already begun in previous years. In this sense,\nthis manuscript will present the main lines of research in Diabetes Mellitus\ntype 1 and Machine Learning techniques in an Internet of Things environment, so\nthat we can summarize the future lines to be developed as follows: data\ncollection through biosensors, massive data processing in the cloud,\ninterconnection of biodevices, local computing vs. cloud computing, and\npossibilities of machine learning techniques to predict blood glucose values,\nincluding both variable selection algorithms and predictive techniques.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 07:31:32 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Rodriguez", "Ignacio", ""]]}, {"id": "2101.02424", "submitter": "Kristiaan Pelckmans", "authors": "Kristiaan Pelckmans, Moustafa Aboushady, Andreas Brosemyr", "title": "Detecting Suspicious Events in Fast Information Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a computational feather-light and intuitive, yet provably\nefficient algorithm, named HALFADO. HALFADO is designed for detecting\nsuspicious events in a high-frequency stream of complex entries, based on a\nrelatively small number of examples of human judgement. Operating a\nsufficiently accurate detection system is vital for {\\em assisting} teams of\nhuman experts in many different areas of the modern digital society. These\nsystems have intrinsically a far-reaching normative effect, and public\nknowledge of the workings of such technology should be a human right.\n  On a conceptual level, the present approach extends one of the most classical\nlearning algorithms for classification, inheriting its theoretical properties.\nIt however works in a semi-supervised way integrating human and computational\nintelligence. On a practical level, this algorithm transcends existing\napproaches (expert systems) by managing and boosting their performance into a\nsingle global detector.\n  We illustrate HALFADO's efficacy on two challenging applications: (1) for\ndetecting {\\em hate speech} messages in a flow of text messages gathered from a\nsocial media platform, and (2) for a Transaction Monitoring System (TMS) in\nFinTech detecting fraudulent transactions in a stream of financial\ntransactions.\n  This algorithm illustrates that - contrary to popular belief - advanced\nmethods of machine learning need not require neither advanced levels of\ncomputation power nor expensive annotation efforts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 08:19:25 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Pelckmans", "Kristiaan", ""], ["Aboushady", "Moustafa", ""], ["Brosemyr", "Andreas", ""]]}, {"id": "2101.02442", "submitter": "Clement Leroy", "authors": "Cl\\'ement Leroy (INTUIDOC), Eric Anquetil (INTUIDOC), Nathalie Girard\n  (INTUIDOC)", "title": "Drift anticipation with forgetting to improve evolving fuzzy system", "comments": null, "journal-ref": "25th International Conference on Pattern Recognition (ICPR2020),\n  Jan 2021, Milan, Italy", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working with a non-stationary stream of data requires for the analysis system\nto evolve its model (the parameters as well as the structure) over time. In\nparticular, concept drifts can occur, which makes it necessary to forget\nknowledge that has become obsolete. However, the forgetting is subjected to the\nstability-plasticity dilemma, that is, increasing forgetting improve reactivity\nof adapting to the new data while reducing the robustness of the system. Based\non a set of inference rules, Evolving Fuzzy Systems-EFS-have proven to be\neffective in solving the data stream learning problem. However tackling the\nstability-plasticity dilemma is still an open question. This paper proposes a\ncoherent method to integrate forgetting in Evolving Fuzzy System, based on the\nrecently introduced notion of concept drift anticipation. The forgetting is\napplied with two methods: an exponential forgetting of the premise part and a\ndeferred directional forgetting of the conclusion part of EFS to preserve the\ncoherence between both parts. The originality of the approach consists in\napplying the forgetting only in the anticipation module and in keeping the EFS\n(called principal system) learned without any forgetting. Then, when a drift is\ndetected in the stream, a selection mechanism is proposed to replace the\nobsolete parameters of the principal system with more suitable parameters of\nthe anticipation module. An evaluation of the proposed methods is carried out\non benchmark online datasets, with a comparison with state-of-the-art online\nclassifiers (Learn++.NSE, PENsemble, pclass) as well as with the original\nsystem using different forgetting strategies.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 09:21:27 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Leroy", "Cl\u00e9ment", "", "INTUIDOC"], ["Anquetil", "Eric", "", "INTUIDOC"], ["Girard", "Nathalie", "", "INTUIDOC"]]}, {"id": "2101.02447", "submitter": "Engkarat Techapanurak", "authors": "Engkarat Techapanurak, Takayuki Okatani", "title": "Practical Evaluation of Out-of-Distribution Detection Methods for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We reconsider the evaluation of OOD detection methods for image recognition.\nAlthough many studies have been conducted so far to build better OOD detection\nmethods, most of them follow Hendrycks and Gimpel's work for the method of\nexperimental evaluation. While the unified evaluation method is necessary for a\nfair comparison, there is a question of if its choice of tasks and datasets\nreflect real-world applications and if the evaluation results can generalize to\nother OOD detection application scenarios. In this paper, we experimentally\nevaluate the performance of representative OOD detection methods for three\nscenarios, i.e., irrelevant input detection, novel class detection, and domain\nshift detection, on various datasets and classification tasks. The results show\nthat differences in scenarios and datasets alter the relative performance among\nthe methods. Our results can also be used as a guide for practitioners for the\nselection of OOD detection methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 09:28:45 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Techapanurak", "Engkarat", ""], ["Okatani", "Takayuki", ""]]}, {"id": "2101.02456", "submitter": "Devika Jay", "authors": "Jahnvi Patel, Devika Jay, Balaraman Ravindran, K.Shanti Swarup", "title": "Neural Fitted Q Iteration based Optimal Bidding Strategy in Real Time\n  Reactive Power Market_1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real time electricity markets, the objective of generation companies while\nbidding is to maximize their profit. The strategies for learning optimal\nbidding have been formulated through game theoretical approaches and stochastic\noptimization problems. Similar studies in reactive power markets have not been\nreported so far because the network voltage operating conditions have an\nincreased impact on reactive power markets than on active power markets.\nContrary to active power markets, the bids of rivals are not directly related\nto fuel costs in reactive power markets. Hence, the assumption of a suitable\nprobability distribution function is unrealistic, making the strategies adopted\nin active power markets unsuitable for learning optimal bids in reactive power\nmarket mechanisms. Therefore, a bidding strategy is to be learnt from market\nobservations and experience in imperfect oligopolistic competition-based\nmarkets. In this paper, a pioneer work on learning optimal bidding strategies\nfrom observation and experience in a three-stage reactive power market is\nreported.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 09:44:00 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Patel", "Jahnvi", ""], ["Jay", "Devika", ""], ["Ravindran", "Balaraman", ""], ["Swarup", "K. Shanti", ""]]}, {"id": "2101.02458", "submitter": "Aite Zhao", "authors": "Aite Zhao, Junyu Dong, Jianbo Li, Lin Qi, Huiyu Zhou", "title": "Associated Spatio-Temporal Capsule Network for Gait Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a challenging task to identify a person based on her/his gait patterns.\nState-of-the-art approaches rely on the analysis of temporal or spatial\ncharacteristics of gait, and gait recognition is usually performed on single\nmodality data (such as images, skeleton joint coordinates, or force signals).\nEvidence has shown that using multi-modality data is more conducive to gait\nresearch. Therefore, we here establish an automated learning system, with an\nassociated spatio-temporal capsule network (ASTCapsNet) trained on multi-sensor\ndatasets, to analyze multimodal information for gait recognition. Specifically,\nwe first design a low-level feature extractor and a high-level feature\nextractor for spatio-temporal feature extraction of gait with a novel recurrent\nmemory unit and a relationship layer. Subsequently, a Bayesian model is\nemployed for the decision-making of class labels. Extensive experiments on\nseveral public datasets (normal and abnormal gait) validate the effectiveness\nof the proposed ASTCapsNet, compared against several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 09:55:17 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhao", "Aite", ""], ["Dong", "Junyu", ""], ["Li", "Jianbo", ""], ["Qi", "Lin", ""], ["Zhou", "Huiyu", ""]]}, {"id": "2101.02459", "submitter": "Ningxin Xu", "authors": "Ningxin Xu, Cheng Yang, Yixin Zhu, Xiaowei Hu, Changhu Wang", "title": "Incorporating Vision Bias into Click Models for Image-oriented Search\n  Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most typical click models assume that the probability of a document to be\nexamined by users only depends on position, such as PBM and UBM. It works well\nin various kinds of search engines. However, in a search engine where massive\ncandidate documents display images as responses to the query, the examination\nprobability should not only depend on position. The visual appearance of an\nimage-oriented document also plays an important role in its opportunity to be\nexamined. In this paper, we assume that vision bias exists in an image-oriented\nsearch engine as another crucial factor affecting the examination probability\naside from position. Specifically, we apply this assumption to classical click\nmodels and propose an extended model, to better capture the examination\nprobabilities of documents. We use regression-based EM algorithm to predict the\nvision bias given the visual features extracted from candidate documents.\nEmpirically, we evaluate our model on a dataset developed from a real-world\nonline image-oriented search engine, and demonstrate that our proposed model\ncan achieve significant improvements over its baseline model in data fitness\nand sparsity handling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 10:01:31 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Xu", "Ningxin", ""], ["Yang", "Cheng", ""], ["Zhu", "Yixin", ""], ["Hu", "Xiaowei", ""], ["Wang", "Changhu", ""]]}, {"id": "2101.02469", "submitter": "Aite Zhao", "authors": "Aite Zhao, Jianbo Li, Junyu Dong, Lin Qi, Qianni Zhang, Ning Li, Xin\n  Wang, Huiyu Zhou", "title": "Multimodal Gait Recognition for Neurodegenerative Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, single modality based gait recognition has been extensively\nexplored in the analysis of medical images or other sensory data, and it is\nrecognised that each of the established approaches has different strengths and\nweaknesses. As an important motor symptom, gait disturbance is usually used for\ndiagnosis and evaluation of diseases; moreover, the use of multi-modality\nanalysis of the patient's walking pattern compensates for the one-sidedness of\nsingle modality gait recognition methods that only learn gait changes in a\nsingle measurement dimension. The fusion of multiple measurement resources has\ndemonstrated promising performance in the identification of gait patterns\nassociated with individual diseases. In this paper, as a useful tool, we\npropose a novel hybrid model to learn the gait differences between three\nneurodegenerative diseases, between patients with different severity levels of\nParkinson's disease and between healthy individuals and patients, by fusing and\naggregating data from multiple sensors. A spatial feature extractor (SFE) is\napplied to generating representative features of images or signals. In order to\ncapture temporal information from the two modality data, a new correlative\nmemory neural network (CorrMNN) architecture is designed for extracting\ntemporal features. Afterwards, we embed a multi-switch discriminator to\nassociate the observations with individual state estimations. Compared with\nseveral state-of-the-art techniques, our proposed framework shows more accurate\nclassification results.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 10:17:11 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhao", "Aite", ""], ["Li", "Jianbo", ""], ["Dong", "Junyu", ""], ["Qi", "Lin", ""], ["Zhang", "Qianni", ""], ["Li", "Ning", ""], ["Wang", "Xin", ""], ["Zhou", "Huiyu", ""]]}, {"id": "2101.02494", "submitter": "Tinghui Ouyang", "authors": "Tinghui Ouyang, Vicent Sant Marco, Yoshinao Isobe, Hideki Asoh, Yutaka\n  Oiwa, Yoshiki Seo", "title": "Corner case data description and detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As the major factors affecting the safety of deep learning models, corner\ncases and related detection are crucial in AI quality assurance for\nconstructing safety- and security-critical systems. The generic corner case\nresearches involve two interesting topics. One is to enhance DL models\nrobustness to corner case data via the adjustment on parameters/structure. The\nother is to generate new corner cases for model retraining and improvement.\nHowever, the complex architecture and the huge amount of parameters make the\nrobust adjustment of DL models not easy, meanwhile it is not possible to\ngenerate all real-world corner cases for DL training. Therefore, this paper\nproposes to a simple and novel study aiming at corner case data detection via a\nspecific metric. This metric is developed on surprise adequacy (SA) which has\nadvantages on capture data behaviors. Furthermore, targeting at characteristics\nof corner case data, three modifications on distanced-based SA are developed\nfor classification applications in this paper. Consequently, through the\nexperiment analysis on MNIST data and industrial data, the feasibility and\nusefulness of the proposed method on corner case data detection are verified.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 11:26:20 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 01:05:19 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Ouyang", "Tinghui", ""], ["Marco", "Vicent Sant", ""], ["Isobe", "Yoshinao", ""], ["Asoh", "Hideki", ""], ["Oiwa", "Yutaka", ""], ["Seo", "Yoshiki", ""]]}, {"id": "2101.02496", "submitter": "Manuel Lagunas", "authors": "Manuel Lagunas, Ana Serrano, Diego Gutierrez, Belen Masia", "title": "The joint role of geometry and illumination on material recognition", "comments": "15 pages, 16 figures, Accepted to the Journal of Vision, 2021", "journal-ref": "Journal of Vision February 2021, Vol.21, 2", "doi": "10.1167/jov.21.2.2", "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Observing and recognizing materials is a fundamental part of our daily life.\nUnder typical viewing conditions, we are capable of effortlessly identifying\nthe objects that surround us and recognizing the materials they are made of.\nNevertheless, understanding the underlying perceptual processes that take place\nto accurately discern the visual properties of an object is a long-standing\nproblem. In this work, we perform a comprehensive and systematic analysis of\nhow the interplay of geometry, illumination, and their spatial frequencies\naffects human performance on material recognition tasks. We carry out\nlarge-scale behavioral experiments where participants are asked to recognize\ndifferent reference materials among a pool of candidate samples. In the\ndifferent experiments, we carefully sample the information in the frequency\ndomain of the stimuli. From our analysis, we find significant first-order\ninteractions between the geometry and the illumination, of both the reference\nand the candidates. In addition, we observe that simple image statistics and\nhigher-order image histograms do not correlate with human performance.\nTherefore, we perform a high-level comparison of highly non-linear statistics\nby training a deep neural network on material recognition tasks. Our results\nshow that such models can accurately classify materials, which suggests that\nthey are capable of defining a meaningful representation of material appearance\nfrom labeled proximal image data. Last, we find preliminary evidence that these\nhighly non-linear models and humans may use similar high-level factors for\nmaterial recognition tasks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 11:29:52 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 12:35:25 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Lagunas", "Manuel", ""], ["Serrano", "Ana", ""], ["Gutierrez", "Diego", ""], ["Masia", "Belen", ""]]}, {"id": "2101.02500", "submitter": "Engkarat Techapanurak", "authors": "Engkarat Techapanurak, Anh-Chuong Dang, Takayuki Okatani", "title": "Bridging In- and Out-of-distribution Samples for Their Better\n  Discriminability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a method for OOD detection. Questioning the premise of\nprevious studies that ID and OOD samples are separated distinctly, we consider\nsamples lying in the intermediate of the two and use them for training a\nnetwork. We generate such samples using multiple image transformations that\ncorrupt inputs in various ways and with different severity levels. We estimate\nwhere the generated samples by a single image transformation lie between ID and\nOOD using a network trained on clean ID samples. To be specific, we make the\nnetwork classify the generated samples and calculate their mean classification\naccuracy, using which we create a soft target label for them. We train the same\nnetwork from scratch using the original ID samples and the generated samples\nwith the soft labels created for them. We detect OOD samples by thresholding\nthe entropy of the predicted softmax probability. The experimental results show\nthat our method outperforms the previous state-of-the-art in the standard\nbenchmark tests. We also analyze the effect of the number and particular\ncombinations of image corrupting transformations on the performance.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 11:34:18 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Techapanurak", "Engkarat", ""], ["Dang", "Anh-Chuong", ""], ["Okatani", "Takayuki", ""]]}, {"id": "2101.02516", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Merging with unknown reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Merging beliefs depends on the relative reliability of their sources. When\nunknown, assuming equal reliability is unwarranted. The solution proposed in\nthis article is that every reliability profile is possible, and only what holds\naccording to all is accepted. Alternatively, one source is completely reliable,\nbut which one is unknown. These two cases motivate two existing forms of\nmerging: maxcons-based merging and arbitration.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 12:32:26 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2101.02547", "submitter": "Ole-Christoffer Granmo", "authors": "Lei Jiao, Xuan Zhang, Ole-Christoffer Granmo, K. Darshana Abeyrathna", "title": "On the Convergence of Tsetlin Machines for the XOR Operator", "comments": "31 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is a novel machine learning algorithm with several\ndistinct properties, including transparent inference and learning using\nhardware-near building blocks. Although numerous papers explore the TM\nempirically, many of its properties have not yet been analyzed mathematically.\nIn this article, we analyze the convergence of the TM when input is\nnon-linearly related to output by the XOR-operator. Our analysis reveals that\nthe TM, with just two conjunctive clauses, can converge almost surely to\nreproducing XOR, learning from training data over an infinite time horizon.\nFurthermore, the analysis shows how the hyper-parameter T guides clause\nconstruction so that the clauses capture the distinct sub-patterns in the data.\nOur analysis of convergence for XOR thus lays the foundation for analyzing\nother more complex logical expressions. These analyses altogether, from a\nmathematical perspective, provide new insights on why TMs have obtained\nstate-of-the-art performance on several pattern recognition problems\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 14:13:41 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Jiao", "Lei", ""], ["Zhang", "Xuan", ""], ["Granmo", "Ole-Christoffer", ""], ["Abeyrathna", "K. Darshana", ""]]}, {"id": "2101.02555", "submitter": "Yehezkel Resheff", "authors": "Daniel Ben David, Yehezkel S. Resheff, Talia Tron", "title": "Explainable AI and Adoption of Financial Algorithmic Advisors: an\n  Experimental Study", "comments": "accepted: AIES '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study whether receiving advice from either a human or algorithmic advisor,\naccompanied by five types of Local and Global explanation labelings, has an\neffect on the readiness to adopt, willingness to pay, and trust in a financial\nAI consultant. We compare the differences over time and in various key\nsituations using a unique experimental framework where participants play a\nweb-based game with real monetary consequences. We observed that accuracy-based\nexplanations of the model in initial phases leads to higher adoption rates.\nWhen the performance of the model is immaculate, there is less importance\nassociated with the kind of explanation for adoption. Using more elaborate\nfeature-based or accuracy-based explanations helps substantially in reducing\nthe adoption drop upon model failure. Furthermore, using an autopilot increases\nadoption significantly. Participants assigned to the AI-labeled advice with\nexplanations were willing to pay more for the advice than the AI-labeled advice\nwith a No-explanation alternative. These results add to the literature on the\nimportance of XAI for algorithmic adoption and trust.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 09:34:38 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 14:26:48 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 06:44:15 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["David", "Daniel Ben", ""], ["Resheff", "Yehezkel S.", ""], ["Tron", "Talia", ""]]}, {"id": "2101.02559", "submitter": "Lois Orosa", "authors": "Muhammad Shafique, Mahum Naseer, Theocharis Theocharides, Christos\n  Kyrkou, Onur Mutlu, Lois Orosa, Jungwook Choi", "title": "Robust Machine Learning Systems: Challenges, Current Trends,\n  Perspectives, and the Road Ahead", "comments": "Final version appears in https://ieeexplore.ieee.org/document/8979377", "journal-ref": "IEEE Design and Test (Volume: 37, Issue: 2, April 2020): 30-57", "doi": "10.1109/MDAT.2020.2971217", "report-no": null, "categories": "cs.CR cs.AI cs.AR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) techniques have been rapidly adopted by smart\nCyber-Physical Systems (CPS) and Internet-of-Things (IoT) due to their powerful\ndecision-making capabilities. However, they are vulnerable to various security\nand reliability threats, at both hardware and software levels, that compromise\ntheir accuracy. These threats get aggravated in emerging edge ML devices that\nhave stringent constraints in terms of resources (e.g., compute, memory,\npower/energy), and that therefore cannot employ costly security and reliability\nmeasures. Security, reliability, and vulnerability mitigation techniques span\nfrom network security measures to hardware protection, with an increased\ninterest towards formal verification of trained ML models.\n  This paper summarizes the prominent vulnerabilities of modern ML systems,\nhighlights successful defenses and mitigation techniques against these\nvulnerabilities, both at the cloud (i.e., during the ML training phase) and\nedge (i.e., during the ML inference stage), discusses the implications of a\nresource-constrained design on the reliability and security of the system,\nidentifies verification methodologies to ensure correct system behavior, and\ndescribes open research challenges for building secure and reliable ML systems\nat both the edge and the cloud.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 20:06:56 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Shafique", "Muhammad", ""], ["Naseer", "Mahum", ""], ["Theocharides", "Theocharis", ""], ["Kyrkou", "Christos", ""], ["Mutlu", "Onur", ""], ["Orosa", "Lois", ""], ["Choi", "Jungwook", ""]]}, {"id": "2101.02561", "submitter": "Yiming Xu", "authors": "Yiming Xu, Diego Klabjan", "title": "Open Set Domain Adaptation by Extreme Value Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common domain adaptation techniques assume that the source domain and the\ntarget domain share an identical label space, which is problematic since when\ntarget samples are unlabeled we have no knowledge on whether the two domains\nshare the same label space. When this is not the case, the existing methods\nfail to perform well because the additional unknown classes are also matched\nwith the source domain during adaptation. In this paper, we tackle the open set\ndomain adaptation problem under the assumption that the source and the target\nlabel spaces only partially overlap, and the task becomes when the unknown\nclasses exist, how to detect the target unknown classes and avoid aligning them\nwith the source domain. We propose to utilize an instance-level reweighting\nstrategy for domain adaptation where the weights indicate the likelihood of a\nsample belonging to known classes and to model the tail of the entropy\ndistribution with Extreme Value Theory for unknown class detection. Experiments\non conventional domain adaptation datasets show that the proposed method\noutperforms the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 19:31:32 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Xu", "Yiming", ""], ["Klabjan", "Diego", ""]]}, {"id": "2101.02562", "submitter": "Zhanglongyuan Longyuan", "authors": "Jinyin Chen, Longyuan Zhang, Haibin Zheng, Xueke Wang and Zhaoyan Ming", "title": "DeepPoison: Feature Transfer Based Stealthy Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks are susceptible to poisoning attacks by purposely\npolluted training data with specific triggers. As existing episodes mainly\nfocused on attack success rate with patch-based samples, defense algorithms can\neasily detect these poisoning samples. We propose DeepPoison, a novel\nadversarial network of one generator and two discriminators, to address this\nproblem. Specifically, the generator automatically extracts the target class'\nhidden features and embeds them into benign training samples. One discriminator\ncontrols the ratio of the poisoning perturbation. The other discriminator works\nas the target model to testify the poisoning effects. The novelty of DeepPoison\nlies in that the generated poisoned training samples are indistinguishable from\nthe benign ones by both defensive methods and manual visual inspection, and\neven benign test samples can achieve the attack. Extensive experiments have\nshown that DeepPoison can achieve a state-of-the-art attack success rate, as\nhigh as 91.74%, with only 7% poisoned samples on publicly available datasets\nLFW and CASIA. Furthermore, we have experimented with high-performance defense\nalgorithms such as autodecoder defense and DBSCAN cluster detection and showed\nthe resilience of DeepPoison.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 15:45:36 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 04:07:19 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Chen", "Jinyin", ""], ["Zhang", "Longyuan", ""], ["Zheng", "Haibin", ""], ["Wang", "Xueke", ""], ["Ming", "Zhaoyan", ""]]}, {"id": "2101.02594", "submitter": "Suguman Bansal", "authors": "Suguman Bansal, Krishnendu Chatterjee, Moshe Y. Vardi", "title": "On Satisficing in Quantitative Games", "comments": "arXiv admin note: text overlap with arXiv:2010.02055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several problems in planning and reactive synthesis can be reduced to the\nanalysis of two-player quantitative graph games. {\\em Optimization} is one form\nof analysis. We argue that in many cases it may be better to replace the\noptimization problem with the {\\em satisficing problem}, where instead of\nsearching for optimal solutions, the goal is to search for solutions that\nadhere to a given threshold bound.\n  This work defines and investigates the satisficing problem on a two-player\ngraph game with the discounted-sum cost model. We show that while the\nsatisficing problem can be solved using numerical methods just like the\noptimization problem, this approach does not render compelling benefits over\noptimization. When the discount factor is, however, an integer, we present\nanother approach to satisficing, which is purely based on automata methods. We\nshow that this approach is algorithmically more performant -- both\ntheoretically and empirically -- and demonstrates the broader applicability of\nsatisficing overoptimization.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 07:47:13 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Bansal", "Suguman", ""], ["Chatterjee", "Krishnendu", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "2101.02634", "submitter": "Dongjie Wang", "authors": "Dongjie Wang, Pengyang Wang, Kunpeng Liu, Yuanchun Zhou, Charles\n  Hughes, Yanjie Fu", "title": "Reinforced Imitative Graph Representation Learning for Mobile User\n  Profiling: An Adversarial Training Perspective", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of mobile user profiling, which is a\ncritical component for quantifying users' characteristics in the human mobility\nmodeling pipeline. Human mobility is a sequential decision-making process\ndependent on the users' dynamic interests. With accurate user profiles, the\npredictive model can perfectly reproduce users' mobility trajectories. In the\nreverse direction, once the predictive model can imitate users' mobility\npatterns, the learned user profiles are also optimal. Such intuition motivates\nus to propose an imitation-based mobile user profiling framework by exploiting\nreinforcement learning, in which the agent is trained to precisely imitate\nusers' mobility patterns for optimal user profiles. Specifically, the proposed\nframework includes two modules: (1) representation module, which produces state\ncombining user profiles and spatio-temporal context in real-time; (2) imitation\nmodule, where Deep Q-network (DQN) imitates the user behavior (action) based on\nthe state that is produced by the representation module. However, there are two\nchallenges in running the framework effectively. First, epsilon-greedy strategy\nin DQN makes use of the exploration-exploitation trade-off by randomly pick\nactions with the epsilon probability. Such randomness feeds back to the\nrepresentation module, causing the learned user profiles unstable. To solve the\nproblem, we propose an adversarial training strategy to guarantee the\nrobustness of the representation module. Second, the representation module\nupdates users' profiles in an incremental manner, requiring integrating the\ntemporal effects of user profiles. Inspired by Long-short Term Memory (LSTM),\nwe introduce a gated mechanism to incorporate new and old user characteristics\ninto the user profile.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 17:10:00 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Wang", "Dongjie", ""], ["Wang", "Pengyang", ""], ["Liu", "Kunpeng", ""], ["Zhou", "Yuanchun", ""], ["Hughes", "Charles", ""], ["Fu", "Yanjie", ""]]}, {"id": "2101.02635", "submitter": "Nahas Pareekutty", "authors": "Nahas Pareekutty, Francis James, Balaraman Ravindran, Suril V. Shah", "title": "qRRT: Quality-Biased Incremental RRT for Optimal Motion Planning in\n  Non-Holonomic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a sampling-based method for optimal motion planning in\nnon-holonomic systems in the absence of known cost functions. It uses the\nprinciple of learning through experience to deduce the cost-to-go of regions\nwithin the workspace. This cost information is used to bias an incremental\ngraph-based search algorithm that produces solution trajectories. Iterative\nimprovement of cost information and search biasing produces solutions that are\nproven to be asymptotically optimal. The proposed framework builds on\nincremental Rapidly-exploring Random Trees (RRT) for random sampling-based\nsearch and Reinforcement Learning (RL) to learn workspace costs. A series of\nexperiments were performed to evaluate and demonstrate the performance of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 17:10:11 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Pareekutty", "Nahas", ""], ["James", "Francis", ""], ["Ravindran", "Balaraman", ""], ["Shah", "Suril V.", ""]]}, {"id": "2101.02644", "submitter": "Hai Huang", "authors": "Hai Huang, Jiaming Mu, Neil Zhenqiang Gong, Qi Li, Bin Liu, Mingwei Xu", "title": "Data Poisoning Attacks to Deep Learning Based Recommender Systems", "comments": "To appear in NDSS 2021", "journal-ref": null, "doi": "10.14722/ndss.2021.24525", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play a crucial role in helping users to find their\ninterested information in various web services such as Amazon, YouTube, and\nGoogle News. Various recommender systems, ranging from neighborhood-based,\nassociation-rule-based, matrix-factorization-based, to deep learning based,\nhave been developed and deployed in industry. Among them, deep learning based\nrecommender systems become increasingly popular due to their superior\nperformance.\n  In this work, we conduct the first systematic study on data poisoning attacks\nto deep learning based recommender systems. An attacker's goal is to manipulate\na recommender system such that the attacker-chosen target items are recommended\nto many users. To achieve this goal, our attack injects fake users with\ncarefully crafted ratings to a recommender system. Specifically, we formulate\nour attack as an optimization problem, such that the injected ratings would\nmaximize the number of normal users to whom the target items are recommended.\nHowever, it is challenging to solve the optimization problem because it is a\nnon-convex integer programming problem. To address the challenge, we develop\nmultiple techniques to approximately solve the optimization problem. Our\nexperimental results on three real-world datasets, including small and large\ndatasets, show that our attack is effective and outperforms existing attacks.\nMoreover, we attempt to detect fake users via statistical analysis of the\nrating patterns of normal and fake users. Our results show that our attack is\nstill effective and outperforms existing attacks even if such a detector is\ndeployed.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 17:32:56 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 12:26:17 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Huang", "Hai", ""], ["Mu", "Jiaming", ""], ["Gong", "Neil Zhenqiang", ""], ["Li", "Qi", ""], ["Liu", "Bin", ""], ["Xu", "Mingwei", ""]]}, {"id": "2101.02648", "submitter": "Quratul-Ain Mahesar", "authors": "Quratul-ain Mahesar and Simon Parsons", "title": "Argument Schemes and Dialogue for Explainable Planning", "comments": "arXiv admin note: text overlap with arXiv:2005.05849", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is being increasingly deployed in practical\napplications. However, there is a major concern whether AI systems will be\ntrusted by humans. In order to establish trust in AI systems, there is a need\nfor users to understand the reasoning behind their solutions. Therefore,\nsystems should be able to explain and justify their output. In this paper, we\npropose an argument scheme-based approach to provide explanations in the domain\nof AI planning. We present novel argument schemes to create arguments that\nexplain a plan and its key elements; and a set of critical questions that allow\ninteraction between the arguments and enable the user to obtain further\ninformation regarding the key elements of the plan. Furthermore, we present a\nnovel dialogue system using the argument schemes and critical questions for\nproviding interactive dialectical explanations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 17:43:12 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 23:03:42 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Mahesar", "Quratul-ain", ""], ["Parsons", "Simon", ""]]}, {"id": "2101.02663", "submitter": "Manoj Vemparala", "authors": "Manoj-Rohit Vemparala, Nael Fasfous, Alexander Frickenstein, Mhd Ali\n  Moraly, Aquib Jamal, Lukas Frickenstein, Christian Unger, Naveen-Shankar\n  Nagaraja, Walter Stechele", "title": "L2PF -- Learning to Prune Faster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various applications in the field of autonomous driving are based on\nconvolutional neural networks (CNNs), especially for processing camera data.\nThe optimization of such CNNs is a major challenge in continuous development.\nNewly learned features must be brought into vehicles as quickly as possible,\nand as such, it is not feasible to spend redundant GPU hours during\ncompression. In this context, we present Learning to Prune Faster which details\na multi-task, try-and-learn method, discretely learning redundant filters of\nthe CNN and a continuous action of how long the layers have to be fine-tuned.\nThis allows us to significantly speed up the convergence process of learning\nhow to find an embedded-friendly filter-wise pruned CNN. For ResNet20, we have\nachieved a compression ratio of 3.84 x with minimal accuracy degradation.\nCompared to the state-of-the-art pruning method, we reduced the GPU hours by\n1.71 x.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 18:13:37 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Vemparala", "Manoj-Rohit", ""], ["Fasfous", "Nael", ""], ["Frickenstein", "Alexander", ""], ["Moraly", "Mhd Ali", ""], ["Jamal", "Aquib", ""], ["Frickenstein", "Lukas", ""], ["Unger", "Christian", ""], ["Nagaraja", "Naveen-Shankar", ""], ["Stechele", "Walter", ""]]}, {"id": "2101.02672", "submitter": "Prarthana Bhattacharyya", "authors": "Prarthana Bhattacharyya, Chengjie Huang and Krzysztof Czarnecki", "title": "SA-Det3D: Self-Attention Based Context-Aware 3D Object Detection", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing point-cloud based 3D object detectors use convolution-like operators\nto process information in a local neighbourhood with fixed-weight kernels and\naggregate global context hierarchically. However, non-local neural networks and\nself-attention for 2D vision have shown that explicitly modeling long-range\ninteractions can lead to more robust and competitive models. In this paper, we\npropose two variants of self-attention for contextual modeling in 3D object\ndetection by augmenting convolutional features with self-attention features. We\nfirst incorporate the pairwise self-attention mechanism into the current\nstate-of-the-art BEV, voxel and point-based detectors and show consistent\nimprovement over strong baseline models of up to 1.5 3D AP while simultaneously\nreducing their parameter footprint and computational cost by 15-80% and 30-50%,\nrespectively, on the KITTI validation set. We next propose a self-attention\nvariant that samples a subset of the most representative features by learning\ndeformations over randomly sampled locations. This not only allows us to scale\nexplicit global contextual modeling to larger point-clouds, but also leads to\nmore discriminative and informative feature descriptors. Our method can be\nflexibly applied to most state-of-the-art detectors with increased accuracy and\nparameter and compute efficiency. We show our proposed method improves 3D\nobject detection performance on KITTI, nuScenes and Waymo Open datasets. Code\nis available at https://github.com/AutoVision-cloud/SA-Det3D.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 18:30:32 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 16:53:42 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 17:35:41 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Bhattacharyya", "Prarthana", ""], ["Huang", "Chengjie", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "2101.02680", "submitter": "Thomas Bi", "authors": "Thomas Bi, Carmelo Sferrazza and Raffaello D'Andrea", "title": "Zero-shot sim-to-real transfer of tactile control policies for\n  aggressive swing-up manipulation", "comments": "Accompanying video: https://youtu.be/In4jkaHzJLc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to show that robots equipped with a vision-based tactile\nsensor can perform dynamic manipulation tasks without prior knowledge of all\nthe physical attributes of the objects to be manipulated. For this purpose, a\nrobotic system is presented that is able to swing up poles of different masses,\nradii and lengths, to an angle of 180 degrees, while relying solely on the\nfeedback provided by the tactile sensor. This is achieved by developing a novel\nsimulator that accurately models the interaction of a pole with the soft\nsensor. A feedback policy that is conditioned on a sensory observation history,\nand which has no prior knowledge of the physical features of the pole, is then\nlearned in the aforementioned simulation. When evaluated on the physical\nsystem, the policy is able to swing up a wide range of poles that differ\nsignificantly in their physical attributes without further adaptation. To the\nauthors' knowledge, this is the first work where a feedback policy from\nhigh-dimensional tactile observations is used to control the swing-up\nmanipulation of poles in closed-loop.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 18:43:18 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 13:33:16 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 06:40:40 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Bi", "Thomas", ""], ["Sferrazza", "Carmelo", ""], ["D'Andrea", "Raffaello", ""]]}, {"id": "2101.02703", "submitter": "Anastasios Angelopoulos", "authors": "Stephen Bates and Anastasios Angelopoulos and Lihua Lei and Jitendra\n  Malik and Michael I. Jordan", "title": "Distribution-Free, Risk-Controlling Prediction Sets", "comments": "Project website available at\n  http://www.angelopoulos.ai/blog/posts/rcps/ and codebase available at\n  https://github.com/aangelopoulos/rcps", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While improving prediction accuracy has been the focus of machine learning in\nrecent years, this alone does not suffice for reliable decision-making.\nDeploying learning systems in consequential settings also requires calibrating\nand communicating the uncertainty of predictions. To convey instance-wise\nuncertainty for prediction tasks, we show how to generate set-valued\npredictions from a black-box predictor that control the expected loss on future\ntest points at a user-specified level. Our approach provides explicit\nfinite-sample guarantees for any dataset by using a holdout set to calibrate\nthe size of the prediction sets. This framework enables simple,\ndistribution-free, rigorous error control for many tasks, and we demonstrate it\nin five large-scale machine learning problems: (1) classification problems\nwhere some mistakes are more costly than others; (2) multi-label\nclassification, where each observation has multiple associated labels; (3)\nclassification problems where the labels have a hierarchical structure; (4)\nimage segmentation, where we wish to predict a set of pixels containing an\nobject of interest; and (5) protein structure prediction. Lastly, we discuss\nextensions to uncertainty quantification for ranking, metric learning and\ndistributionally robust learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 18:59:33 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 03:48:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bates", "Stephen", ""], ["Angelopoulos", "Anastasios", ""], ["Lei", "Lihua", ""], ["Malik", "Jitendra", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2101.02722", "submitter": "Rico Jonschkowski", "authors": "Austin Stone, Oscar Ramirez, Kurt Konolige, Rico Jonschkowski", "title": "The Distracting Control Suite -- A Challenging Benchmark for\n  Reinforcement Learning from Pixels", "comments": "Code available at\n  https://github.com/google-research/google-research/tree/master/distracting_control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robots have to face challenging perceptual settings, including changes in\nviewpoint, lighting, and background. Current simulated reinforcement learning\n(RL) benchmarks such as DM Control provide visual input without such\ncomplexity, which limits the transfer of well-performing methods to the real\nworld. In this paper, we extend DM Control with three kinds of visual\ndistractions (variations in background, color, and camera pose) to produce a\nnew challenging benchmark for vision-based control, and we analyze state of the\nart RL algorithms in these settings. Our experiments show that current RL\nmethods for vision-based control perform poorly under distractions, and that\ntheir performance decreases with increasing distraction complexity, showing\nthat new methods are needed to cope with the visual complexities of the real\nworld. We also find that combinations of multiple distraction types are more\ndifficult than a mere combination of their individual effects.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 19:03:34 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Stone", "Austin", ""], ["Ramirez", "Oscar", ""], ["Konolige", "Kurt", ""], ["Jonschkowski", "Rico", ""]]}, {"id": "2101.02729", "submitter": "Prabuddha Chakraborty", "authors": "Prabuddha Chakraborty and Swarup Bhunia", "title": "Neural Storage: A New Paradigm of Elastic Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.AR cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storage and retrieval of data in a computer memory plays a major role in\nsystem performance. Traditionally, computer memory organization is static -\ni.e., they do not change based on the application-specific characteristics in\nmemory access behaviour during system operation. Specifically, the association\nof a data block with a search pattern (or cues) as well as the granularity of a\nstored data do not evolve. Such a static nature of computer memory, we observe,\nnot only limits the amount of data we can store in a given physical storage,\nbut it also misses the opportunity for dramatic performance improvement in\nvarious applications. On the contrary, human memory is characterized by\nseemingly infinite plasticity in storing and retrieving data - as well as\ndynamically creating/updating the associations between data and corresponding\ncues. In this paper, we introduce Neural Storage (NS), a brain-inspired\nlearning memory paradigm that organizes the memory as a flexible neural memory\nnetwork. In NS, the network structure, strength of associations, and\ngranularity of the data adjust continuously during system operation, providing\nunprecedented plasticity and performance benefits. We present the associated\nstorage/retrieval/retention algorithms in NS, which integrate a formalized\nlearning process. Using a full-blown operational model, we demonstrate that NS\nachieves an order of magnitude improvement in memory access performance for two\nrepresentative applications when compared to traditional content-based memory.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 19:19:25 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Chakraborty", "Prabuddha", ""], ["Bhunia", "Swarup", ""]]}, {"id": "2101.02774", "submitter": "Becky Mashaido", "authors": "Becky Mashaido", "title": "Learning Grammar of Complex Activities via Deep Neural Networks", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the growing amount of publicly available video data on online\nstreaming services and an increased interest in applications that analyze\ncontinuous video streams such as autonomous driving, this technical report\nprovides a theoretical insight into deep neural networks for video learning,\nunder label constraints. I build upon previous work in video learning for\ncomputer vision, make observations on model performance and propose further\nmechanisms to help improve our observations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 21:48:58 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Mashaido", "Becky", ""]]}, {"id": "2101.02780", "submitter": "Tanujay Saha", "authors": "Tanujay Saha, Najwa Aaraj, Neel Ajjarapu, Niraj K. Jha", "title": "SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things\n  and Cyber-Physical Systems based on Machine Learning", "comments": "This article has been accepted in IEEE Transactions on Emerging\n  Topics in Computing. 17 pages, 12 figures, IEEE copyright", "journal-ref": "IEEE Transactions on Emerging Topics in Computing, 2021", "doi": "10.1109/TETC.2021.3050733", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are\nincreasingly being deployed across multiple functionalities, ranging from\nhealthcare devices and wearables to critical infrastructures, e.g., nuclear\npower plants, autonomous vehicles, smart cities, and smart homes. These devices\nare inherently not secure across their comprehensive software, hardware, and\nnetwork stacks, thus presenting a large attack surface that can be exploited by\nhackers. In this article, we present an innovative technique for detecting\nunknown system vulnerabilities, managing these vulnerabilities, and improving\nincident response when such vulnerabilities are exploited. The novelty of this\napproach lies in extracting intelligence from known real-world CPS/IoT attacks,\nrepresenting them in the form of regular expressions, and employing machine\nlearning (ML) techniques on this ensemble of regular expressions to generate\nnew attack vectors and security vulnerabilities. Our results show that 10 new\nattack vectors and 122 new vulnerability exploits can be successfully generated\nthat have the potential to exploit a CPS or an IoT ecosystem. The ML\nmethodology achieves an accuracy of 97.4% and enables us to predict these\nattacks efficiently with an 87.2% reduction in the search space. We demonstrate\nthe application of our method to the hacking of the in-vehicle network of a\nconnected car. To defend against the known attacks and possible novel exploits,\nwe discuss a defense-in-depth mechanism for various classes of attacks and the\nclassification of data targeted by such attacks. This defense mechanism\noptimizes the cost of security measures based on the sensitivity of the\nprotected resource, thus incentivizing its adoption in real-world CPS/IoT by\ncybersecurity practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 22:01:30 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Saha", "Tanujay", ""], ["Aaraj", "Najwa", ""], ["Ajjarapu", "Neel", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2101.02808", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Yi Wan, Richard S. Sutton, Shimon Whiteson", "title": "Average-Reward Off-Policy Policy Evaluation with Function Approximation", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy policy evaluation with function approximation (FA) in\naverage-reward MDPs, where the goal is to estimate both the reward rate and the\ndifferential value function. For this problem, bootstrapping is necessary and,\nalong with off-policy learning and FA, results in the deadly triad (Sutton &\nBarto, 2018). To address the deadly triad, we propose two novel algorithms,\nreproducing the celebrated success of Gradient TD algorithms in the\naverage-reward setting. In terms of estimating the differential value function,\nthe algorithms are the first convergent off-policy linear function\napproximation algorithms. In terms of estimating the reward rate, the\nalgorithms are the first convergent off-policy linear function approximation\nalgorithms that do not require estimating the density ratio. We demonstrate\nempirically the advantage of the proposed algorithms, as well as their\nnonlinear variants, over a competitive density-ratio-based approach, in a\nsimple domain as well as challenging robot simulation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 00:43:04 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 22:36:31 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhang", "Shangtong", ""], ["Wan", "Yi", ""], ["Sutton", "Richard S.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2101.02831", "submitter": "Becky Mashaido", "authors": "Becky Mashaido and Winston Moh Tangongho", "title": "A Tale of Fairness Revisited: Beyond Adversarial Learning for Deep\n  Neural Network Fairness", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need for fair algorithmic decision making in the age of\nautomation and artificially-intelligent technology, this technical report\nprovides a theoretical insight into adversarial training for fairness in deep\nlearning. We build upon previous work in adversarial fairness, show the\npersistent tradeoff between fair predictions and model performance, and explore\nfurther mechanisms that help in offsetting this tradeoff.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 03:13:44 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Mashaido", "Becky", ""], ["Tangongho", "Winston Moh", ""]]}, {"id": "2101.02842", "submitter": "Takuma Yoneda", "authors": "Takuma Yoneda, Charles Schaff, Takahiro Maeda, Matthew Walter", "title": "Grasp and Motion Planning for Dexterous Manipulation for the Real Robot\n  Challenge", "comments": "The winning submission to Real Robot Challenge\n  (https://real-robot-challenge.com/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report describes our winning submission to the Real Robot Challenge\n(https://real-robot-challenge.com/). The Real Robot Challenge is a three-phase\ndexterous manipulation competition that involves manipulating various\nrectangular objects with the TriFinger Platform. Our approach combines motion\nplanning with several motion primitives to manipulate the object. For Phases 1\nand 2, we additionally learn a residual policy in simulation that applies\ncorrective actions on top of our controller. Our approach won first place in\nPhase 2 and Phase 3 of the competition. We were anonymously known as\n`ardentstork' on the competition leaderboard\n(https://real-robot-challenge.com/leader-board). Videos and our code can be\nfound at https://github.com/ripl-ttic/real-robot-challenge.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 04:13:39 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Yoneda", "Takuma", ""], ["Schaff", "Charles", ""], ["Maeda", "Takahiro", ""], ["Walter", "Matthew", ""]]}, {"id": "2101.02860", "submitter": "Khaza Anuarul Hoque", "authors": "Ayesha Siddique, Kanad Basu, Khaza Anuarul Hoque", "title": "Exploring Fault-Energy Trade-offs in Approximate DNN Hardware\n  Accelerators", "comments": "Accepted for publication in the The 22nd International Symposium on\n  Quality Electronic Design (ISQED'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systolic array-based deep neural network (DNN) accelerators have recently\ngained prominence for their low computational cost. However, their high energy\nconsumption poses a bottleneck to their deployment in energy-constrained\ndevices. To address this problem, approximate computing can be employed at the\ncost of some tolerable accuracy loss. However, such small accuracy variations\nmay increase the sensitivity of DNNs towards undesired subtle disturbances,\nsuch as permanent faults. The impact of permanent faults in accurate DNNs has\nbeen thoroughly investigated in the literature. Conversely, the impact of\npermanent faults in approximate DNN accelerators (AxDNNs) is yet\nunder-explored. The impact of such faults may vary with the fault bit\npositions, activation functions and approximation errors in AxDNN layers. Such\ndynamacity poses a considerable challenge to exploring the trade-off between\ntheir energy efficiency and fault resilience in AxDNNs. Towards this, we\npresent an extensive layer-wise and bit-wise fault resilience and energy\nanalysis of different AxDNNs, using the state-of-the-art Evoapprox8b signed\nmultipliers. In particular, we vary the stuck-at-0, stuck-at-1 fault-bit\npositions, and activation functions to study their impact using the most widely\nused MNIST and Fashion-MNIST datasets. Our quantitative analysis shows that the\npermanent faults exacerbate the accuracy loss in AxDNNs when compared to the\naccurate DNN accelerators. For instance, a permanent fault in AxDNNs can lead\nup to 66\\% accuracy loss, whereas the same faulty bit can lead to only 9\\%\naccuracy loss in an accurate DNN accelerator. Our results demonstrate that the\nfault resilience in AxDNNs is orthogonal to the energy efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 05:52:12 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Siddique", "Ayesha", ""], ["Basu", "Kanad", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "2101.02879", "submitter": "Zhengqi He", "authors": "Zhengqi He, Taro Toyoizumi", "title": "An Information-theoretic Progressive Framework for Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Both brain science and the deep learning communities have the problem of\ninterpreting neural activity. For deep learning, even though we can access all\nneurons' activity data, interpretation of how the deep network solves the task\nis still challenging. Although a large amount of effort has been devoted to\ninterpreting a deep network, there is still no consensus of what interpretation\nis. This paper tries to push the discussion in this direction and proposes an\ninformation-theoretic progressive framework to synthesize interpretation.\nFirstly, we discuss intuitions of interpretation: interpretation is\nmeta-information; interpretation should be at the right level; inducing\nindependence is helpful to interpretation; interpretation is naturally\nprogressive; interpretation doesn't have to involve a human. Then, we build the\nframework with an information map splitting idea and implement it with the\nvariational information bottleneck technique. After that, we test the framework\nwith the CLEVR dataset. The framework is shown to be able to split information\nmaps and synthesize interpretation in the form of meta-information.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 06:59:48 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["He", "Zhengqi", ""], ["Toyoizumi", "Taro", ""]]}, {"id": "2101.02914", "submitter": "Meifan Zhang", "authors": "Meifan Zhang and Hongzhi Wang", "title": "Approximate Query Processing for Group-By Queries based on Conditional\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Group-By query is an important kind of query, which is common and widely\nused in data warehouses, data analytics, and data visualization. Approximate\nquery processing is an effective way to increase the querying efficiency on big\ndata. The answer to a group-by query involves multiple values, which makes it\ndifficult to provide sufficiently accurate estimations for all the groups.\nStratified sampling improves the accuracy compared with the uniform sampling,\nbut the samples chosen for some special queries cannot work for other queries.\nOnline sampling chooses samples for the given query at query time, but it\nrequires a long latency. Thus, it is a challenge to achieve both accuracy and\nefficiency at the same time. Facing such challenge, in this work, we propose a\nsample generation framework based on a conditional generative model. The sample\ngeneration framework can generate any number of samples for the given query\nwithout accessing the data. The proposed framework based on the lightweight\nmodel can be combined with stratified sampling and online aggregation to\nimprove the estimation accuracy for group-by queries. The experimental results\nshow that our proposed methods are both efficient and accurate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 08:49:21 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Zhang", "Meifan", ""], ["Wang", "Hongzhi", ""]]}, {"id": "2101.02991", "submitter": "Pathan Faisal Khan", "authors": "Faisal Khan and Debdeep Bose", "title": "Artificial Intelligence enabled Smart Learning", "comments": "4", "journal-ref": "ETH Learning and Teaching Journal: ICED 2020 Proceedings (2020)\n  153-156", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is a discipline of computer science that deals\nwith machine intelligence. It is essential to bring AI into the context of\nlearning because it helps in analysing the enormous amounts of data that is\ncollected from individual students, teachers and academic staff. The major\npriorities of implementing AI in education are making innovative use of\nexisting digital technologies for learning, and teaching practices that\nsignificantly improve traditional educational methods. The main problem with\ntraditional learning is that it cannot be suited to every student in class.\nSome students may grasp the concepts well, while some may have difficulties in\nunderstanding them and some may be more auditory or visual learners. The World\nBank report on education has indicated that the learning gap created by this\nproblem causes many students to drop out (World Development Report, 2018).\nPersonalised learning has been able to solve this grave problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 12:49:33 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Khan", "Faisal", ""], ["Bose", "Debdeep", ""]]}, {"id": "2101.03013", "submitter": "Iknoor Singh", "authors": "Iknoor Singh, Carolina Scarton, Kalina Bontcheva", "title": "Multistage BiCross Encoder: Team GATE Entry for MLIA Multilingual\n  Semantic Search Task 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Coronavirus (COVID-19) pandemic has led to a rapidly growing `infodemic'\nonline. Thus, the accurate retrieval of reliable relevant data from millions of\ndocuments about COVID-19 has become urgently needed for the general public as\nwell as for other stakeholders. The COVID-19 Multilingual Information Access\n(MLIA) initiative is a joint effort to ameliorate exchange of COVID-19 related\ninformation by developing applications and services through research and\ncommunity participation. In this work, we present a search system called\nMultistage BiCross Encoder, developed by team GATE for the MLIA task 2\nMultilingual Semantic Search. Multistage BiCross-Encoder is a sequential three\nstage pipeline which uses the Okapi BM25 algorithm and a transformer based\nbi-encoder and cross-encoder to effectively rank the documents with respect to\nthe query. The results of round 1 show that our models achieve state-of-the-art\nperformance for all ranking metrics for both monolingual and bilingual runs.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 13:59:26 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 20:38:23 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Singh", "Iknoor", ""], ["Scarton", "Carolina", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "2101.03026", "submitter": "Carlos Badenes-Olmedo", "authors": "Carlos Badenes-Olmedo, Jose-Luis Redondo Garc\\'ia, Oscar Corcho", "title": "Scalable Cross-lingual Document Similarity through Language-specific\n  Concept Hierarchies", "comments": "Accepted at the 10th International Conference on Knowledge Capture\n  (K-CAP 2019)", "journal-ref": "AACM Proceedings of the 10th International Conference on Knowledge\n  Capture, pages = 147-153, K-CAP 19 (2020)", "doi": "10.1145/3360901.3364444", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the ongoing growth in number of digital articles in a wider set of\nlanguages and the expanding use of different languages, we need annotation\nmethods that enable browsing multi-lingual corpora. Multilingual probabilistic\ntopic models have recently emerged as a group of semi-supervised machine\nlearning models that can be used to perform thematic explorations on\ncollections of texts in multiple languages. However, these approaches require\ntheme-aligned training data to create a language-independent space. This\nconstraint limits the amount of scenarios that this technique can offer\nsolutions to train and makes it difficult to scale up to situations where a\nhuge collection of multi-lingual documents are required during the training\nphase. This paper presents an unsupervised document similarity algorithm that\ndoes not require parallel or comparable corpora, or any other type of\ntranslation resource. The algorithm annotates topics automatically created from\ndocuments in a single language with cross-lingual labels and describes\ndocuments by hierarchies of multi-lingual concepts from independently-trained\nmodels. Experiments performed on the English, Spanish and French editions of\nJCR-Acquis corpora reveal promising results on classifying and sorting\ndocuments by similar content.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 10:42:40 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Badenes-Olmedo", "Carlos", ""], ["Garc\u00eda", "Jose-Luis Redondo", ""], ["Corcho", "Oscar", ""]]}, {"id": "2101.03027", "submitter": "Alexis Michaud", "authors": "Oliver Adams, Benjamin Galliot (LACITO), Guillaume Wisniewski (LLF\n  UMR7110), Nicholas Lambourne, Ben Foley, Rahasya Sanders-Dwyer, Janet Wiles,\n  Alexis Michaud (LACITO), S\\'everine Guillaume (LACITO), Laurent Besacier\n  (LIG), Christopher Cox, Katya Aplonova (LLACAN), Guillaume Jacques (CRLAO),\n  Nathan Hill", "title": "User-friendly automatic transcription of low-resource languages:\n  Plugging ESPnet into Elpis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on progress integrating the speech recognition toolkit\nESPnet into Elpis, a web front-end originally designed to provide access to the\nKaldi automatic speech recognition toolkit. The goal of this work is to make\nend-to-end speech recognition models available to language workers via a\nuser-friendly graphical interface. Encouraging results are reported on (i)\ndevelopment of an ESPnet recipe for use in Elpis, with preliminary results on\ndata sets previously used for training acoustic models with the Persephone\ntoolkit along with a new data set that had not previously been used in speech\nrecognition, and (ii) incorporating ESPnet into Elpis along with UI\nenhancements and a CUDA-supported Dockerfile.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:06:21 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 07:23:37 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Adams", "Oliver", "", "LACITO"], ["Galliot", "Benjamin", "", "LACITO"], ["Wisniewski", "Guillaume", "", "LLF\n  UMR7110"], ["Lambourne", "Nicholas", "", "LACITO"], ["Foley", "Ben", "", "LACITO"], ["Sanders-Dwyer", "Rahasya", "", "LACITO"], ["Wiles", "Janet", "", "LACITO"], ["Michaud", "Alexis", "", "LACITO"], ["Guillaume", "S\u00e9verine", "", "LACITO"], ["Besacier", "Laurent", "", "LIG"], ["Cox", "Christopher", "", "LLACAN"], ["Aplonova", "Katya", "", "LLACAN"], ["Jacques", "Guillaume", "", "CRLAO"], ["Hill", "Nathan", ""]]}, {"id": "2101.03037", "submitter": "Bobak Kiani", "authors": "Bobak Toussi Kiani, Giacomo De Palma, Milad Marvian, Zi-Wen Liu, Seth\n  Lloyd", "title": "Quantum Earth Mover's Distance: A New Approach to Learning Quantum Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying how far the output of a learning algorithm is from its target is\nan essential task in machine learning. However, in quantum settings, the loss\nlandscapes of commonly used distance metrics often produce undesirable outcomes\nsuch as poor local minima and exponentially decaying gradients. As a new\napproach, we consider here the quantum earth mover's (EM) or Wasserstein-1\ndistance, recently proposed in [De Palma et al., arXiv:2009.04469] as a quantum\nanalog to the classical EM distance. We show that the quantum EM distance\npossesses unique properties, not found in other commonly used quantum distance\nmetrics, that make quantum learning more stable and efficient. We propose a\nquantum Wasserstein generative adversarial network (qWGAN) which takes\nadvantage of the quantum EM distance and provides an efficient means of\nperforming learning on quantum data. Our qWGAN requires resources polynomial in\nthe number of qubits, and our numerical experiments demonstrate that it is\ncapable of learning a diverse set of quantum data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 14:33:19 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Kiani", "Bobak Toussi", ""], ["De Palma", "Giacomo", ""], ["Marvian", "Milad", ""], ["Liu", "Zi-Wen", ""], ["Lloyd", "Seth", ""]]}, {"id": "2101.03091", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Rik Sarkar", "title": "Twitch Gamers: a Dataset for Evaluating Proximity Preserving and\n  Structural Role-based Node Embeddings", "comments": "The dataset is available at\n  https://github.com/benedekrozemberczki/datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proximity preserving and structural role-based node embeddings have become a\nprime workhorse of applied graph mining. Novel node embedding techniques are\noften tested on a restricted set of benchmark datasets. In this paper, we\npropose a new diverse social network dataset called Twitch Gamers with multiple\npotential target attributes. Our analysis of the social network and node\nclassification experiments illustrate that Twitch Gamers is suitable for\nassessing the predictive performance of novel proximity preserving and\nstructural role-based node embedding algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 16:40:37 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 22:17:58 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2101.03138", "submitter": "Tae Wan Kim", "authors": "Tae Wan Kim, Matloob Khushi", "title": "Portfolio Optimization with 2D Relative-Attentional Gated Transformer", "comments": "Accepted to be published in the Proceedings of the IEEE Asia Pacific\n  Conference on Computer Science and Data Engineering 2020 (CSDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio optimization is one of the most attentive fields that have been\nresearched with machine learning approaches. Many researchers attempted to\nsolve this problem using deep reinforcement learning due to its efficient\ninherence that can handle the property of financial markets. However, most of\nthem can hardly be applicable to real-world trading since they ignore or\nextremely simplify the realistic constraints of transaction costs. These\nconstraints have a significantly negative impact on portfolio profitability. In\nour research, a conservative level of transaction fees and slippage are\nconsidered for the realistic experiment. To enhance the performance under those\nconstraints, we propose a novel Deterministic Policy Gradient with 2D\nRelative-attentional Gated Transformer (DPGRGT) model. Applying learnable\nrelative positional embeddings for the time and assets axes, the model better\nunderstands the peculiar structure of the financial data in the portfolio\noptimization domain. Also, gating layers and layer reordering are employed for\nstable convergence of Transformers in reinforcement learning. In our experiment\nusing U.S. stock market data of 20 years, our model outperformed baseline\nmodels and demonstrated its effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 14:08:26 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Kim", "Tae Wan", ""], ["Khushi", "Matloob", ""]]}, {"id": "2101.03163", "submitter": "Elham Ghazizadeh Ms", "authors": "Elham Ghazizadeh, ShiNung Ching", "title": "Slow manifolds in recurrent networks encode working memory efficiently\n  and robustly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working memory is a cognitive function involving the storage and manipulation\nof latent information over brief intervals of time, thus making it crucial for\ncontext-dependent computation. Here, we use a top-down modeling approach to\nexamine network-level mechanisms of working memory, an enigmatic issue and\ncentral topic of study in neuroscience and machine intelligence. We train\nthousands of recurrent neural networks on a working memory task and then\nperform dynamical systems analysis on the ensuing optimized networks, wherein\nwe find that four distinct dynamical mechanisms can emerge. In particular, we\nshow the prevalence of a mechanism in which memories are encoded along slow\nstable manifolds in the network state space, leading to a phasic neuronal\nactivation profile during memory periods. In contrast to mechanisms in which\nmemories are directly encoded at stable attractors, these networks naturally\nforget stimuli over time. Despite this seeming functional disadvantage, they\nare more efficient in terms of how they leverage their attractor landscape and\nparadoxically, are considerably more robust to noise. Our results provide new\ndynamical hypotheses regarding how working memory function is encoded in both\nnatural and artificial neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 18:47:02 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Ghazizadeh", "Elham", ""], ["Ching", "ShiNung", ""]]}, {"id": "2101.03169", "submitter": "Wen Liu", "authors": "Maohan Liang, Ryan Wen Liu, Shichen Li, Zhe Xiao, Xin Liu, Feng Lu", "title": "An Unsupervised Learning Method with Convolutional Auto-Encoder for\n  Vessel Trajectory Similarity Computation", "comments": "22 pages, 16 figures", "journal-ref": "Ocean Engineering, 2021", "doi": "10.1016/j.oceaneng.2021.108803", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To achieve reliable mining results for massive vessel trajectories, one of\nthe most important challenges is how to efficiently compute the similarities\nbetween different vessel trajectories. The computation of vessel trajectory\nsimilarity has recently attracted increasing attention in the maritime data\nmining research community. However, traditional shape- and warping-based\nmethods often suffer from several drawbacks such as high computational cost and\nsensitivity to unwanted artifacts and non-uniform sampling rates, etc. To\neliminate these drawbacks, we propose an unsupervised learning method which\nautomatically extracts low-dimensional features through a convolutional\nauto-encoder (CAE). In particular, we first generate the informative trajectory\nimages by remapping the raw vessel trajectories into two-dimensional matrices\nwhile maintaining the spatio-temporal properties. Based on the massive vessel\ntrajectories collected, the CAE can learn the low-dimensional representations\nof informative trajectory images in an unsupervised manner. The trajectory\nsimilarity is finally equivalent to efficiently computing the similarities\nbetween the learned low-dimensional features, which strongly correlate with the\nraw vessel trajectories. Comprehensive experiments on realistic data sets have\ndemonstrated that the proposed method largely outperforms traditional\ntrajectory similarity computation methods in terms of efficiency and\neffectiveness. The high-quality trajectory clustering performance could also be\nguaranteed according to the CAE-based trajectory similarity computation\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 04:42:11 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liang", "Maohan", ""], ["Liu", "Ryan Wen", ""], ["Li", "Shichen", ""], ["Xiao", "Zhe", ""], ["Liu", "Xin", ""], ["Lu", "Feng", ""]]}, {"id": "2101.03172", "submitter": "Rohan Saha", "authors": "Rohan Saha, Cassidy Pirlot", "title": "Analysis of Evolutionary Program Synthesis for Card Games", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.24925.77280", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this report, we inspect the application of an evolutionary approach to the\ngame of Rack'O, which is a card game revolving around the notion of decision\nmaking. We first apply the evolutionary technique for obtaining a set of rules\nover many generations and then compare them with a script written by a human\nplayer. A high-level domain-specific language is used that deter-mines which\nthe sets of rules are synthesized. We report the results by providing a\ncomprehensive analysis of the set of rules and their implications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 03:28:01 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Saha", "Rohan", ""], ["Pirlot", "Cassidy", ""]]}, {"id": "2101.03207", "submitter": "Sayar Ghosh Roy", "authors": "Sayar Ghosh Roy, Ujwal Narayan, Tathagata Raha, Zubair Abid, Vasudeva\n  Varma", "title": "Leveraging Multilingual Transformers for Hate Speech Detection", "comments": "To be published in: FIRE (Working Notes) 2020, Hate Speech and\n  Offensive Content Identification in Indo-European Languages, HASOC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting and classifying instances of hate in social media text has been a\nproblem of interest in Natural Language Processing in the recent years. Our\nwork leverages state of the art Transformer language models to identify hate\nspeech in a multilingual setting. Capturing the intent of a post or a comment\non social media involves careful evaluation of the language style, semantic\ncontent and additional pointers such as hashtags and emojis. In this paper, we\nlook at the problem of identifying whether a Twitter post is hateful and\noffensive or not. We further discriminate the detected toxic content into one\nof the following three classes: (a) Hate Speech (HATE), (b) Offensive (OFFN)\nand (c) Profane (PRFN). With a pre-trained multilingual Transformer-based text\nencoder at the base, we are able to successfully identify and classify hate\nspeech from multiple languages. On the provided testing corpora, we achieve\nMacro F1 scores of 90.29, 81.87 and 75.40 for English, German and Hindi\nrespectively while performing hate speech detection and of 60.70, 53.28 and\n49.74 during fine-grained classification. In our experiments, we show the\nefficacy of Perspective API features for hate speech classification and the\neffects of exploiting a multilingual training scheme. A feature selection study\nis provided to illustrate impacts of specific features upon the architecture's\nclassification head.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:23:50 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Roy", "Sayar Ghosh", ""], ["Narayan", "Ujwal", ""], ["Raha", "Tathagata", ""], ["Abid", "Zubair", ""], ["Varma", "Vasudeva", ""]]}, {"id": "2101.03208", "submitter": "Xiaonan Jing", "authors": "Xiaonan Jing, Julia Taylor Rayz", "title": "Graph-of-Tweets: A Graph Merging Approach to Sub-event Identification", "comments": "Accepted by 2020 IEEE/WIC/ACM International Joint Conference on Web\n  Intelligence and Intelligent Agent Technology (WI-IAT) Workshop on Data\n  Analytics on Social Media (DASM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph structures are powerful tools for modeling the relationships between\ntextual elements. Graph-of-Words (GoW) has been adopted in many Natural\nLanguage tasks to encode the association between terms. However, GoW provides\nfew document-level relationships in cases when the connections between\ndocuments are also essential. For identifying sub-events on social media like\nTwitter, features from both word- and document-level can be useful as they\nsupply different information of the event. We propose a hybrid Graph-of-Tweets\n(GoT) model which combines the word- and document-level structures for modeling\nTweets. To compress large amount of raw data, we propose a graph merging method\nwhich utilizes FastText word embeddings to reduce the GoW. Furthermore, we\npresent a novel method to construct GoT with the reduced GoW and a Mutual\nInformation (MI) measure. Finally, we identify maximal cliques to extract\npopular sub-events. Our model showed promising results on condensing\nlexical-level information and capturing keywords of sub-events.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:24:25 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Jing", "Xiaonan", ""], ["Rayz", "Julia Taylor", ""]]}, {"id": "2101.03210", "submitter": "Sarvenaz Chaeibakhsh", "authors": "Sarvenaz Chaeibakhsh, Roya Sabbagh Novin, Tucker Hermans, Andrew\n  Merryweather and Alan Kuntz", "title": "Optimizing Hospital Room Layout to Reduce the Risk of Patient Falls", "comments": "Accepted in: \"10th International Conference on Operations Research\n  and Enterprise Systems\". 13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite years of research into patient falls in hospital rooms, falls and\nrelated injuries remain a serious concern to patient safety. In this work, we\nformulate a gradient-free constrained optimization problem to generate and\nreconfigure the hospital room interior layout to minimize the risk of falls. We\ndefine a cost function built on a hospital room fall model that takes into\naccount the supportive or hazardous effect of the patient's surrounding\nobjects, as well as simulated patient trajectories inside the room. We define a\nconstraint set that ensures the functionality of the generated room layouts in\naddition to conforming to architectural guidelines. We solve this problem\nefficiently using a variant of simulated annealing. We present results for two\nreal-world hospital room types and demonstrate a significant improvement of 18%\non average in patient fall risk when compared with a traditional hospital room\nlayout and 41% when compared with randomly generated layouts.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:31:10 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chaeibakhsh", "Sarvenaz", ""], ["Novin", "Roya Sabbagh", ""], ["Hermans", "Tucker", ""], ["Merryweather", "Andrew", ""], ["Kuntz", "Alan", ""]]}, {"id": "2101.03218", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, M. Omair Shafiq, Ashraf Matrawy", "title": "DiPSeN: Differentially Private Self-normalizing Neural Networks For\n  Adversarial Robustness in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need for robust, secure and private machine learning is an important goal\nfor realizing the full potential of the Internet of Things (IoT). Federated\nlearning has proven to help protect against privacy violations and information\nleakage. However, it introduces new risk vectors which make machine learning\nmodels more difficult to defend against adversarial samples. In this study, we\nexamine the role of differential privacy and self-normalization in mitigating\nthe risk of adversarial samples specifically in a federated learning\nenvironment. We introduce DiPSeN, a Differentially Private Self-normalizing\nNeural Network which combines elements of differential privacy noise with\nself-normalizing techniques. Our empirical results on three publicly available\ndatasets show that DiPSeN successfully improves the adversarial robustness of a\ndeep learning classifier in a federated learning environment based on several\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:49:56 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Shafiq", "M. Omair", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2101.03221", "submitter": "Stefano Martina", "authors": "Stefano Martina, Stefano Gherardini, Filippo Caruso", "title": "Machine learning approach for quantum non-Markovian noise classification", "comments": "14 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, machine learning and artificial neural network models are\nproposed for quantum noise classification in stochastic quantum dynamics. For\nthis purpose, we train and then validate support vector machine, multi-layer\nperceptron and recurrent neural network, models with different complexity and\naccuracy, to solve supervised binary classification problems. By exploiting the\nquantum random walk formalism, we demonstrate the high efficacy of such tools\nin classifying noisy quantum dynamics using data sets collected in a single\nrealisation of the quantum system evolution. In addition, we also show that for\na successful classification one just needs to measure, in a sequence of\ndiscrete time instants, the probabilities that the analysed quantum system is\nin one of the allowed positions or energy configurations, without any external\ndriving. Thus, neither measurements of quantum coherences nor sequences of\ncontrol pulses are required. Since in principle the training of the machine\nlearning models can be performed a-priori on synthetic data, our approach is\nexpected to find direct application in a vast number of experimental schemes\nand also for the noise benchmarking of the already available noisy\nintermediate-scale quantum devices.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:56:56 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Martina", "Stefano", ""], ["Gherardini", "Stefano", ""], ["Caruso", "Filippo", ""]]}, {"id": "2101.03235", "submitter": "Krishna Yadav", "authors": "Krishna Yadav, Lakshya Choudhary", "title": "Key Phrase Extraction & Applause Prediction", "comments": "4 pages, 8 figures best project award winner.\n  https://krishna19039.medium.com/key-phrase-extraction-applause-prediction-7b397c7ad76d", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increase in content availability over the internet it is very\ndifficult to get noticed. It has become an upmost the priority of the blog\nwriters to get some feedback over their creations to be confident about the\nimpact of their article. We are training a machine learning model to learn\npopular article styles, in the form of vector space representations using\nvarious word embeddings, and their popularity based on claps and tags.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 12:49:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Yadav", "Krishna", ""], ["Choudhary", "Lakshya", ""]]}, {"id": "2101.03251", "submitter": "Babak Taati", "authors": "Siavash Rezaei, Abhishek Moturu, Shun Zhao, Kenneth M. Prkachin,\n  Thomas Hadjistavropoulos, and Babak Taati", "title": "Unobtrusive Pain Monitoring in Older Adults with Dementia using Pairwise\n  and Contrastive Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Although pain is frequent in old age, older adults are often undertreated for\npain. This is especially the case for long-term care residents with moderate to\nsevere dementia who cannot report their pain because of cognitive impairments\nthat accompany dementia. Nursing staff acknowledge the challenges of\neffectively recognizing and managing pain in long-term care facilities due to\nlack of human resources and, sometimes, expertise to use validated pain\nassessment approaches on a regular basis. Vision-based ambient monitoring will\nallow for frequent automated assessments so care staff could be automatically\nnotified when signs of pain are displayed. However, existing computer vision\ntechniques for pain detection are not validated on faces of older adults or\npeople with dementia, and this population is not represented in existing facial\nexpression datasets of pain. We present the first fully automated vision-based\ntechnique validated on a dementia cohort. Our contributions are threefold.\nFirst, we develop a deep learning-based computer vision system for detecting\npainful facial expressions on a video dataset that is collected unobtrusively\nfrom older adult participants with and without dementia. Second, we introduce a\npairwise comparative inference method that calibrates to each person and is\nsensitive to changes in facial expression while using training data more\nefficiently than sequence models. Third, we introduce a fast contrastive\ntraining method that improves cross-dataset performance. Our pain estimation\nmodel outperforms baselines by a wide margin, especially when evaluated on\nfaces of people with dementia. Pre-trained model and demo code available at\nhttps://github.com/TaatiTeam/pain_detection_demo\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 23:28:30 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Rezaei", "Siavash", ""], ["Moturu", "Abhishek", ""], ["Zhao", "Shun", ""], ["Prkachin", "Kenneth M.", ""], ["Hadjistavropoulos", "Thomas", ""], ["Taati", "Babak", ""]]}, {"id": "2101.03273", "submitter": "Saeed Kaviani", "authors": "Saeed Kaviani, Bo Ryu, Ejaz Ahmed, Kevin A. Larson, Anh Le, Alex\n  Yahja, Jae H. Kim", "title": "Robust and Scalable Routing with Multi-Agent Deep Reinforcement Learning\n  for MANETs", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly dynamic mobile ad-hoc networks (MANETs) are continuing to serve as one\nof the most challenging environments to develop and deploy robust, efficient,\nand scalable routing protocols. In this paper, we present DeepCQ+ routing\nwhich, in a novel manner, integrates emerging multi-agent deep reinforcement\nlearning (MADRL) techniques into existing Q-learning-based routing protocols\nand their variants, and achieves persistently higher performance across a wide\nrange of MANET configurations while training only on a limited range of network\nparameters and conditions. Quantitatively, DeepCQ+ shows consistently higher\nend-to-end throughput with lower overhead compared to its Q-learning-based\ncounterparts with the overall gain of 10-15% in its efficiency. Qualitatively\nand more significantly, DeepCQ+ maintains remarkably similar performance gains\nunder many scenarios that it was not trained for in terms of network sizes,\nmobility conditions, and traffic dynamics. To the best of our knowledge, this\nis the first successful demonstration of MADRL for the MANET routing problem\nthat achieves and maintains a high degree of scalability and robustness even in\nthe environments that are outside the trained range of scenarios. This implies\nthat the proposed hybrid design approach of DeepCQ+ that combines MADRL and\nQ-learning significantly increases its practicality and explainability because\nthe real-world MANET environment will likely vary outside the trained range of\nMANET scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 02:26:14 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 02:53:58 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Kaviani", "Saeed", ""], ["Ryu", "Bo", ""], ["Ahmed", "Ejaz", ""], ["Larson", "Kevin A.", ""], ["Le", "Anh", ""], ["Yahja", "Alex", ""], ["Kim", "Jae H.", ""]]}, {"id": "2101.03275", "submitter": "Anirudh Shah", "authors": "Jordan Lee, Willy Lin, Konstantinos Ntalis, Anirudh Shah, William\n  Tung, Maxwell Wulff", "title": "Identifying Human Edited Images using a CNN", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most non-professional photo manipulations are not made using propriety\nsoftware like Adobe Photoshop, which is expensive and complicated to use for\nthe average consumer selfie-taker or meme-maker. Instead, these individuals opt\nfor user friendly mobile applications like FaceTune and Pixlr to make human\nface edits and alterations. Unfortunately, there is no existing dataset to\ntrain a model to classify these type of manipulations. In this paper, we\npresent a generative model that approximates the distribution of human face\nedits and a method for detecting Facetune and Pixlr manipulations to human\nfaces.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 02:43:35 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Lee", "Jordan", ""], ["Lin", "Willy", ""], ["Ntalis", "Konstantinos", ""], ["Shah", "Anirudh", ""], ["Tung", "William", ""], ["Wulff", "Maxwell", ""]]}, {"id": "2101.03300", "submitter": "Hang Chen", "authors": "Hang Chen, Syed Ali Asif, Jihong Park, Chien-Chung Shen, Mehdi Bennis", "title": "Robust Blockchained Federated Learning with Model Validation and\n  Proof-of-Stake Inspired Consensus", "comments": "8 pages, 7 figures, AAAI 2021 Workshop - Towards Robust, Secure and\n  Efficient Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising distributed learning solution that\nonly exchanges model parameters without revealing raw data. However, the\ncentralized architecture of FL is vulnerable to the single point of failure. In\naddition, FL does not examine the legitimacy of local models, so even a small\nfraction of malicious devices can disrupt global training. To resolve these\nrobustness issues of FL, in this paper, we propose a blockchain-based\ndecentralized FL framework, termed VBFL, by exploiting two mechanisms in a\nblockchained architecture. First, we introduced a novel decentralized\nvalidation mechanism such that the legitimacy of local model updates is\nexamined by individual validators. Second, we designed a dedicated\nproof-of-stake consensus mechanism where stake is more frequently rewarded to\nhonest devices, which protects the legitimate local model updates by increasing\ntheir chances of dictating the blocks appended to the blockchain. Together,\nthese solutions promote more federation within legitimate devices, enabling\nrobust FL. Our emulation results of the MNIST classification corroborate that\nwith 15% of malicious devices, VBFL achieves 87% accuracy, which is 7.4x higher\nthan Vanilla FL.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 06:30:38 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chen", "Hang", ""], ["Asif", "Syed Ali", ""], ["Park", "Jihong", ""], ["Shen", "Chien-Chung", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2101.03303", "submitter": "Anurag Roy", "authors": "Anurag Roy, Shalmoli Ghosh, Kripabandhu Ghosh, Saptarshi Ghosh", "title": "An Unsupervised Normalization Algorithm for Noisy Text: A Case Study for\n  Information Retrieval and Stance Detection", "comments": "Will be appearing in the ACM Journal of Data and Information Quality.\n  Implementation available at https://github.com/ranarag/UnsupClean", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of textual data available today contains various types of\n'noise', such as OCR noise in digitized documents, noise due to informal\nwriting style of users on microblogging sites, and so on. To enable tasks such\nas search/retrieval and classification over all the available data, we need\nrobust algorithms for text normalization, i.e., for cleaning different kinds of\nnoise in the text. There have been several efforts towards cleaning or\nnormalizing noisy text; however, many of the existing text normalization\nmethods are supervised and require language-dependent resources or large\namounts of training data that is difficult to obtain. We propose an\nunsupervised algorithm for text normalization that does not need any training\ndata / human intervention. The proposed algorithm is applicable to text over\ndifferent languages, and can handle both machine-generated and human-generated\nnoise. Experiments over several standard datasets show that text normalization\nthrough the proposed algorithm enables better retrieval and stance detection,\nas compared to that using several baseline text normalization methods.\nImplementation of our algorithm can be found at\nhttps://github.com/ranarag/UnsupClean.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 06:57:09 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Roy", "Anurag", ""], ["Ghosh", "Shalmoli", ""], ["Ghosh", "Kripabandhu", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "2101.03337", "submitter": "Md Shahzamal", "authors": "Saeed Khan and Md Shahzamal", "title": "Land Use Detection & Identification using Geo-tagged Tweets", "comments": "7th IEEE Asia-Pacific Conference on Computer Science and Data\n  Engineering 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.NA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Geo-tagged tweets can potentially help with sensing the interaction of people\nwith their surrounding environment. Based on this hypothesis, this paper makes\nuse of geotagged tweets in order to ascertain various land uses with a broader\ngoal to help with urban/city planning. The proposed method utilises supervised\nlearning to reveal spatial land use within cities with the help of Twitter\nactivity signatures. Specifically, the technique involves using tweets from\nthree cities of Australia namely Brisbane, Melbourne and Sydney. Analytical\nresults are checked against the zoning data provided by respective city\ncouncils and a good match is observed between the predicted land use and\nexisting land zoning by the city councils. We show that geo-tagged tweets\ncontain features that can be useful for land use identification.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 11:32:38 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Khan", "Saeed", ""], ["Shahzamal", "Md", ""]]}, {"id": "2101.03392", "submitter": "Yongfeng Zhang", "authors": "Hanxiong Chen, Xu Chen, Shaoyun Shi, Yongfeng Zhang", "title": "Generate Natural Language Explanations for Recommendation", "comments": "Accepted to the SIGIR 2019 Workshop on ExplainAble Recommendation and\n  Search, Paris, France, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing personalized explanations for recommendations can help users to\nunderstand the underlying insight of the recommendation results, which is\nhelpful to the effectiveness, transparency, persuasiveness and trustworthiness\nof recommender systems. Current explainable recommendation models mostly\ngenerate textual explanations based on pre-defined sentence templates. However,\nthe expressiveness power of template-based explanation sentences are limited to\nthe pre-defined expressions, and manually defining the expressions require\nsignificant human efforts. Motivated by this problem, we propose to generate\nfree-text natural language explanations for personalized recommendation. In\nparticular, we propose a hierarchical sequence-to-sequence model (HSS) for\npersonalized explanation generation. Different from conventional sentence\ngeneration in NLP research, a great challenge of explanation generation in\ne-commerce recommendation is that not all sentences in user reviews are of\nexplanation purpose. To solve the problem, we further propose an auto-denoising\nmechanism based on topical item feature words for sentence generation.\nExperiments on various e-commerce product domains show that our approach can\nnot only improve the recommendation accuracy, but also the explanation quality\nin terms of the offline measures and feature words coverage. This research is\none of the initial steps to grant intelligent agents with the ability to\nexplain itself based on natural language sentences.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 17:00:41 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chen", "Hanxiong", ""], ["Chen", "Xu", ""], ["Shi", "Shaoyun", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2101.03394", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Hamed Zamani and Fabio Crestani and W. Bruce\n  Croft", "title": "Context-Aware Target Apps Selection and Recommendation for Enhancing\n  Personal Mobile Assistants", "comments": "Accepted to ACM TOIS, 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users install many apps on their smartphones, raising issues related to\ninformation overload for users and resource management for devices. Moreover,\nthe recent increase in the use of personal assistants has made mobile devices\neven more pervasive in users' lives. This paper addresses two research problems\nthat are vital for developing effective personal mobile assistants: target apps\nselection and recommendation. The former is the key component of a unified\nmobile search system: a system that addresses the users' information needs for\nall the apps installed on their devices with a unified mode of access. The\nlatter, instead, predicts the next apps that the users would want to launch.\nHere we focus on context-aware models to leverage the rich contextual\ninformation available to mobile devices. We design an in situ study to collect\nthousands of mobile queries enriched with mobile sensor data (now publicly\navailable for research purposes). With the aid of this dataset, we study the\nuser behavior in the context of these tasks and propose a family of\ncontext-aware neural models that take into account the sequential, temporal,\nand personal behavior of users. We study several state-of-the-art models and\nshow that the proposed models significantly outperform the baselines.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 17:07:47 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Zamani", "Hamed", ""], ["Crestani", "Fabio", ""], ["Croft", "W. Bruce", ""]]}, {"id": "2101.03431", "submitter": "Shane Storks", "authors": "Shane Storks, Qiaozi Gao, Govind Thattai, Gokhan Tur", "title": "Are We There Yet? Learning to Localize in Embodied Instruction Following", "comments": "Accepted to HAI @ AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied instruction following is a challenging problem requiring an agent to\ninfer a sequence of primitive actions to achieve a goal environment state from\ncomplex language and visual inputs. Action Learning From Realistic Environments\nand Directives (ALFRED) is a recently proposed benchmark for this problem\nconsisting of step-by-step natural language instructions to achieve subgoals\nwhich compose to an ultimate high-level goal. Key challenges for this task\ninclude localizing target locations and navigating to them through visual\ninputs, and grounding language instructions to visual appearance of objects. To\naddress these challenges, in this study, we augment the agent's field of view\nduring navigation subgoals with multiple viewing angles, and train the agent to\npredict its relative spatial relation to the target location at each timestep.\nWe also improve language grounding by introducing a pre-trained object\ndetection module to the model pipeline. Empirical studies show that our\napproach exceeds the baseline model performance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 21:49:41 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Storks", "Shane", ""], ["Gao", "Qiaozi", ""], ["Thattai", "Govind", ""], ["Tur", "Gokhan", ""]]}, {"id": "2101.03453", "submitter": "Ashim Gupta", "authors": "Ashim Gupta, Giorgi Kvernadze, Vivek Srikumar", "title": "BERT & Family Eat Word Salad: Experiments with Text Understanding", "comments": "Accepted at AAAI 2021, Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the response of large models from the BERT family to\nincoherent inputs that should confuse any model that claims to understand\nnatural language. We define simple heuristics to construct such examples. Our\nexperiments show that state-of-the-art models consistently fail to recognize\nthem as ill-formed, and instead produce high confidence predictions on them. As\na consequence of this phenomenon, models trained on sentences with randomly\npermuted word order perform close to state-of-the-art models. To alleviate\nthese issues, we show that if models are explicitly trained to recognize\ninvalid inputs, they can be robust to such attacks without a drop in\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 01:32:57 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 12:58:59 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Gupta", "Ashim", ""], ["Kvernadze", "Giorgi", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2101.03464", "submitter": "Yiding Yang", "authors": "Yiding Yang, Xinchao Wang, Mingli Song, Junsong Yuan, Dacheng Tao", "title": "SPAGAN: Shortest Path Graph Attention Network", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCN) have recently demonstrated their potential\nin analyzing non-grid structure data that can be represented as graphs. The\ncore idea is to encode the local topology of a graph, via convolutions, into\nthe feature of a center node. In this paper, we propose a novel GCN model,\nwhich we term as Shortest Path Graph Attention Network (SPAGAN). Unlike\nconventional GCN models that carry out node-based attentions within each layer,\nthe proposed SPAGAN conducts path-based attention that explicitly accounts for\nthe influence of a sequence of nodes yielding the minimum cost, or shortest\npath, between the center node and its higher-order neighbors. SPAGAN therefore\nallows for a more informative and intact exploration of the graph structure and\nfurther {a} more effective aggregation of information from distant neighbors\ninto the center node, as compared to node-based GCN methods. We test SPAGAN on\nthe downstream classification task on several standard datasets, and achieve\nperformances superior to the state of the art. Code is publicly available at\nhttps://github.com/ihollywhy/SPAGAN.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 03:18:34 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Yang", "Yiding", ""], ["Wang", "Xinchao", ""], ["Song", "Mingli", ""], ["Yuan", "Junsong", ""], ["Tao", "Dacheng", ""]]}, {"id": "2101.03485", "submitter": "S. Sarthak", "authors": "Sarthak, Shikhar Shukla, Karm Veer Arya", "title": "Detecting Hostile Posts using Relational Graph Convolutional Network", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is based on the submission to the competition Hindi Constraint\nconducted by AAAI@2021 for detection of hostile posts in Hindi on social media\nplatforms. Here, a model is presented for detection and classification of\nhostile posts and further classify into fake, offensive, hate and defamation\nusing Relational Graph Convolutional Networks. Unlike other existing work, our\napproach is focused on using semantic meaning along with contextutal\ninformation for better classification. The results from AAAI@2021 indicates\nthat the proposed model is performing at par with Google's XLM-RoBERTa on the\ngiven dataset. Our best submission with RGCN achieves an F1 score of 0.97 (7th\nRank) on coarse-grained evaluation and achieved best performance on identifying\nfake posts. Among all submissions to the challenge, our classification system\nwith XLM-Roberta secured 2nd rank on fine-grained classification.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 06:50:22 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 15:09:04 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Sarthak", "", ""], ["Shukla", "Shikhar", ""], ["Arya", "Karm Veer", ""]]}, {"id": "2101.03501", "submitter": "Spencer Compton", "authors": "Spencer Compton, Murat Kocaoglu, Kristjan Greenewald, Dmitriy Katz", "title": "Entropic Causal Inference: Identifiability and Finite Sample Results", "comments": "In Proceedings of NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropic causal inference is a framework for inferring the causal direction\nbetween two categorical variables from observational data. The central\nassumption is that the amount of unobserved randomness in the system is not too\nlarge. This unobserved randomness is measured by the entropy of the exogenous\nvariable in the underlying structural causal model, which governs the causal\nrelation between the observed variables. Kocaoglu et al. conjectured that the\ncausal direction is identifiable when the entropy of the exogenous variable is\nnot too large. In this paper, we prove a variant of their conjecture. Namely,\nwe show that for almost all causal models where the exogenous variable has\nentropy that does not scale with the number of states of the observed\nvariables, the causal direction is identifiable from observational data. We\nalso consider the minimum entropy coupling-based algorithmic approach presented\nby Kocaoglu et al., and for the first time demonstrate algorithmic\nidentifiability guarantees using a finite number of samples. We conduct\nextensive experiments to evaluate the robustness of the method to relaxing some\nof the assumptions in our theory and demonstrate that both the constant-entropy\nexogenous variable and the no latent confounder assumptions can be relaxed in\npractice. We also empirically characterize the number of observational samples\nneeded for causal identification. Finally, we apply the algorithm on Tuebingen\ncause-effect pairs dataset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 08:37:54 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Compton", "Spencer", ""], ["Kocaoglu", "Murat", ""], ["Greenewald", "Kristjan", ""], ["Katz", "Dmitriy", ""]]}, {"id": "2101.03541", "submitter": "Fabian Amherd", "authors": "Fabian Amherd, Elias Rodriguez", "title": "Heatmap-based Object Detection and Tracking with a Fully Convolutional\n  Neural Network", "comments": "30 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The main topic of this paper is a brief overview of the field of Artificial\nIntelligence. The core of this paper is a practical implementation of an\nalgorithm for object detection and tracking. The ability to detect and track\nfast-moving objects is crucial for various applications of Artificial\nIntelligence like autonomous driving, ball tracking in sports, robotics or\nobject counting. As part of this paper the Fully Convolutional Neural Network\n\"CueNet\" was developed. It detects and tracks the cueball on a labyrinth game\nrobustly and reliably. While CueNet V1 has a single input image, the approach\nwith CueNet V2 was to take three consecutive 240 x 180-pixel images as an input\nand transform them into a probability heatmap for the cueball's location. The\nnetwork was tested with a separate video that contained all sorts of\ndistractions to test its robustness. When confronted with our testing data,\nCueNet V1 predicted the correct cueball location in 99.6% of all frames, while\nCueNet V2 had 99.8% accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 13:13:38 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Amherd", "Fabian", ""], ["Rodriguez", "Elias", ""]]}, {"id": "2101.03553", "submitter": "Sayar Ghosh Roy", "authors": "Sayar Ghosh Roy, Nikhil Pinnaparaju, Risubh Jain, Manish Gupta,\n  Vasudeva Varma", "title": "Summaformers @ LaySumm 20, LongSumm 20", "comments": "Proceedings of the First Workshop on Scholarly Document Processing\n  (SDP) at EMNLP 2020", "journal-ref": "In Proceedings of the First Workshop on Scholarly Document\n  Processing, pages 336 - 343, 2020, Online. Association for Computational\n  Linguistics", "doi": "10.18653/v1/2020.sdp-1.39", "report-no": "IIIT/TR/2020/75", "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic text summarization has been widely studied as an important task in\nnatural language processing. Traditionally, various feature engineering and\nmachine learning based systems have been proposed for extractive as well as\nabstractive text summarization. Recently, deep learning based, specifically\nTransformer-based systems have been immensely popular. Summarization is a\ncognitively challenging task - extracting summary worthy sentences is\nlaborious, and expressing semantics in brief when doing abstractive\nsummarization is complicated. In this paper, we specifically look at the\nproblem of summarizing scientific research papers from multiple domains. We\ndifferentiate between two types of summaries, namely, (a) LaySumm: A very short\nsummary that captures the essence of the research paper in layman terms\nrestricting overtly specific technical jargon and (b) LongSumm: A much longer\ndetailed summary aimed at providing specific insights into various ideas\ntouched upon in the paper. While leveraging latest Transformer-based models,\nour systems are simple, intuitive and based on how specific paper sections\ncontribute to human summaries of the two types described above. Evaluations\nagainst gold standard summaries using ROUGE metrics prove the effectiveness of\nour approach. On blind test corpora, our system ranks first and third for the\nLongSumm and LaySumm tasks respectively.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 13:48:12 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Roy", "Sayar Ghosh", ""], ["Pinnaparaju", "Nikhil", ""], ["Jain", "Risubh", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "2101.03563", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave and Jean-Baptiste Sevestre and Matthieu Toulemont", "title": "Stabilized Nested Rollout Policy Adaptation", "comments": "arXiv admin note: text overlap with arXiv:2003.10024", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nested Rollout Policy Adaptation (NRPA) is a Monte Carlo search algorithm for\nsingle player games. In this paper we propose to modify NRPA in order to\nimprove the stability of the algorithm. Experiments show it improves the\nalgorithm for different application domains: SameGame, Traveling Salesman with\nTime Windows and Expression Discovery.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 15:05:14 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Cazenave", "Tristan", ""], ["Sevestre", "Jean-Baptiste", ""], ["Toulemont", "Matthieu", ""]]}, {"id": "2101.03581", "submitter": "Zheming Zuo", "authors": "Zheming Zuo, Jie Li, Noura Al Moubayed", "title": "Curvature-based Feature Selection with Application in Classifying\n  Electronic Health Records", "comments": "12 pages, 5 figures, 3 tables, 4 data sets, source code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Electronic Health Records (EHRs) are widely applied in healthcare facilities\nnowadays. Due to the inherent heterogeneity, unbalanced, incompleteness, and\nhigh-dimensional nature of EHRs, it is a challenging task to employ machine\nlearning algorithms to analyse such EHRs for prediction and diagnostics within\nthe scope of precision medicine. Dimensionality reduction is an efficient data\npreprocessing technique for the analysis of high dimensional data that reduces\nthe number of features while improving the performance of the data analysis,\ne.g. classification. In this paper, we propose an efficient curvature-based\nfeature selection method for supporting more precise diagnosis. The proposed\nmethod is a filter-based feature selection method, which directly utilises the\nMenger Curvature for ranking all the attributes in the given data set. We\nevaluate the performance of our method against conventional PCA and recent ones\nincluding BPCM, GSAM, WCNN, BLS II, VIBES, 2L-MJFA, RFGA, and VAF. Our method\nachieves state-of-the-art performance on four benchmark healthcare data sets\nincluding CCRFDS, BCCDS, BTDS, and DRDDS with impressive 24.73% and 13.93%\nimprovements respectively on BTDS and CCRFDS, 7.97% improvement on BCCDS, and\n3.63% improvement on DRDDS. Our CFS source code is publicly available at\nhttps://github.com/zhemingzuo/CFS.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 16:55:40 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zuo", "Zheming", ""], ["Li", "Jie", ""], ["Moubayed", "Noura Al", ""]]}, {"id": "2101.03603", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge, Matthew S. Emigh, Jonathan L. King, Denton L. Woods,\n  J. Tory Cobb, Jose C. Principe", "title": "Target Detection and Segmentation in Circular-Scan\n  Synthetic-Aperture-Sonar Images using Semi-Supervised Convolutional\n  Encoder-Decoders", "comments": "Submitted to IEEE JOE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a saliency-based, multi-target detection and segmentation\nframework for multi-aspect, semi-coherent imagery formed from circular-scan,\nsynthetic-aperture sonar (CSAS). Our framework relies on a multi-branch,\nconvolutional encoder-decoder network (MB-CEDN). The encoder portion extracts\nfeatures from one or more CSAS images of the targets. These features are then\nsplit off and fed into multiple decoders that perform pixel-level\nclassification on the extracted features to roughly mask the target in an\nunsupervised-trained manner and detect foreground and background pixels in a\nsupervised-trained manner. Each of these target-detection estimates provide\ndifferent perspectives as to what constitute a target. These opinions are\ncascaded into a deep-parsing network to model contextual and spatial\nconstraints that help isolate targets better than either solution estimate\nalone.\n  We evaluate our framework using real-world CSAS data with five broad target\nclasses. Since we are the first to consider both CSAS target detection and\nsegmentation, we adapt existing image and video-processing network topologies\nfrom the literature for comparative purposes. We show that our framework\noutperforms supervised deep networks. It greatly outperforms state-of-the-art\nunsupervised approaches for diverse target and seafloor types.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 18:58:45 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 16:36:41 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Emigh", "Matthew S.", ""], ["King", "Jonathan L.", ""], ["Woods", "Denton L.", ""], ["Cobb", "J. Tory", ""], ["Principe", "Jose C.", ""]]}, {"id": "2101.03609", "submitter": "Wlodzislaw Duch", "authors": "W{\\l}odzis{\\l}aw Duch", "title": "Neurocognitive Informatics Manifesto", "comments": "27 pages, Series of Information and Management Sciences, California\n  Polytechnic State University, 8th International Conference on Information and\n  Management Sciences (IMS 2009), Kunming-Banna, Yunan, China, pp. 264-282", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Informatics studies all aspects of the structure of natural and artificial\ninformation systems. Theoretical and abstract approaches to information have\nmade great advances, but human information processing is still unmatched in\nmany areas, including information management, representation and understanding.\nNeurocognitive informatics is a new, emerging field that should help to improve\nthe matching of artificial and natural systems, and inspire better\ncomputational algorithms to solve problems that are still beyond the reach of\nmachines. In this position paper examples of neurocognitive inspirations and\npromising directions in this area are given.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 19:20:15 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Duch", "W\u0142odzis\u0142aw", ""]]}, {"id": "2101.03613", "submitter": "Ekram Hossain", "authors": "F. Hussain, R. Hussain, and E. Hossain", "title": "Explainable Artificial Intelligence (XAI): An Engineering Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The remarkable advancements in Deep Learning (DL) algorithms have fueled\nenthusiasm for using Artificial Intelligence (AI) technologies in almost every\ndomain; however, the opaqueness of these algorithms put a question mark on\ntheir applications in safety-critical systems. In this regard, the\n`explainability' dimension is not only essential to both explain the inner\nworkings of black-box algorithms, but it also adds accountability and\ntransparency dimensions that are of prime importance for regulators, consumers,\nand service providers. eXplainable Artificial Intelligence (XAI) is the set of\ntechniques and methods to convert the so-called black-box AI algorithms to\nwhite-box algorithms, where the results achieved by these algorithms and the\nvariables, parameters, and steps taken by the algorithm to reach the obtained\nresults, are transparent and explainable. To complement the existing literature\non XAI, in this paper, we take an `engineering' approach to illustrate the\nconcepts of XAI. We discuss the stakeholders in XAI and describe the\nmathematical contours of XAI from engineering perspective. Then we take the\nautonomous car as a use-case and discuss the applications of XAI for its\ndifferent components such as object detection, perception, control, action\ndecision, and so on. This work is an exploratory study to identify new avenues\nof research in the field of XAI.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 19:49:12 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Hussain", "F.", ""], ["Hussain", "R.", ""], ["Hossain", "E.", ""]]}, {"id": "2101.03655", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Machine Learning Towards Intelligent Systems: Applications, Challenges,\n  and Opportunities", "comments": "46 pages, 7 figures, 5 tables, journal", "journal-ref": null, "doi": "10.1007/s10462-020-09948-w", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence and continued reliance on the Internet and related technologies\nhas resulted in the generation of large amounts of data that can be made\navailable for analyses. However, humans do not possess the cognitive\ncapabilities to understand such large amounts of data. Machine learning (ML)\nprovides a mechanism for humans to process large amounts of data, gain insights\nabout the behavior of the data, and make more informed decision based on the\nresulting analysis. ML has applications in various fields. This review focuses\non some of the fields and applications such as education, healthcare, network\nsecurity, banking and finance, and social media. Within these fields, there are\nmultiple unique challenges that exist. However, ML can provide solutions to\nthese challenges, as well as create further research opportunities.\nAccordingly, this work surveys some of the challenges facing the aforementioned\nfields and presents some of the previous literature works that tackled them.\nMoreover, it suggests several research opportunities that benefit from the use\nof ML to address these challenges.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 01:32:15 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2101.03678", "submitter": "Yan Qin", "authors": "Xuewen Zhang, Yan Qin, Chau Yuen (Fellow IEEE), Lahiru Jayasinghe, and\n  Xiang Liu", "title": "Time-Series Regeneration with Convolutional Recurrent Generative\n  Adversarial Network for Remaining Useful Life Estimation", "comments": null, "journal-ref": "This paper has been accetped by IEEE Transactions on Industrial\n  Informatics in Dec. 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For health prognostic task, ever-increasing efforts have been focused on\nmachine learning-based methods, which are capable of yielding accurate\nremaining useful life (RUL) estimation for industrial equipment or components\nwithout exploring the degradation mechanism. A prerequisite ensuring the\nsuccess of these methods depends on a wealth of run-to-failure data, however,\nrun-to-failure data may be insufficient in practice. That is, conducting a\nsubstantial amount of destructive experiments not only is high costs, but also\nmay cause catastrophic consequences. Out of this consideration, an enhanced RUL\nframework focusing on data self-generation is put forward for both non-cyclic\nand cyclic degradation patterns for the first time. It is designed to enrich\ndata from a data-driven way, generating realistic-like time-series to enhance\ncurrent RUL methods. First, high-quality data generation is ensured through the\nproposed convolutional recurrent generative adversarial network (CR-GAN), which\nadopts a two-channel fusion convolutional recurrent neural network. Next, a\nhierarchical framework is proposed to combine generated data into current RUL\nestimation methods. Finally, the efficacy of the proposed method is verified\nthrough both non-cyclic and cyclic degradation systems. With the enhanced RUL\nframework, an aero-engine system following non-cyclic degradation has been\ntested using three typical RUL models. State-of-art RUL estimation results are\nachieved by enhancing capsule network with generated time-series. Specifically,\nestimation errors evaluated by the index score function have been reduced by\n21.77%, and 32.67% for the two employed operating conditions, respectively.\nBesides, the estimation error is reduced to zero for the Lithium-ion battery\nsystem, which presents cyclic degradation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 02:44:34 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Zhang", "Xuewen", "", "Fellow IEEE"], ["Qin", "Yan", "", "Fellow IEEE"], ["Yuen", "Chau", "", "Fellow IEEE"], ["Jayasinghe", "Lahiru", ""], ["Liu", "Xiang", ""]]}, {"id": "2101.03697", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Xiangyu Zhang, Ningning Ma, Jungong Han, Guiguang Ding,\n  Jian Sun", "title": "RepVGG: Making VGG-style ConvNets Great Again", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple but powerful architecture of convolutional neural\nnetwork, which has a VGG-like inference-time body composed of nothing but a\nstack of 3x3 convolution and ReLU, while the training-time model has a\nmulti-branch topology. Such decoupling of the training-time and inference-time\narchitecture is realized by a structural re-parameterization technique so that\nthe model is named RepVGG. On ImageNet, RepVGG reaches over 80% top-1 accuracy,\nwhich is the first time for a plain model, to the best of our knowledge. On\nNVIDIA 1080Ti GPU, RepVGG models run 83% faster than ResNet-50 or 101% faster\nthan ResNet-101 with higher accuracy and show favorable accuracy-speed\ntrade-off compared to the state-of-the-art models like EfficientNet and RegNet.\nThe code and trained models are available at\nhttps://github.com/megvii-model/RepVGG.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 04:46:11 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 15:02:08 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 13:02:36 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ding", "Xiaohan", ""], ["Zhang", "Xiangyu", ""], ["Ma", "Ningning", ""], ["Han", "Jungong", ""], ["Ding", "Guiguang", ""], ["Sun", "Jian", ""]]}, {"id": "2101.03704", "submitter": "Yan Qin", "authors": "Yan Qin, Stefan Adams, and Chau Yuen", "title": "A Transfer Learning-based State of Charge Estimation for Lithium-Ion\n  Battery at Varying Ambient Temperatures", "comments": "This paper has been accepted by IEEE Transaction on Industrial\n  Informatics on Jan. 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and reliable state of charge (SoC) estimation becomes increasingly\nimportant to provide a stable and efficient environment for Lithium-ion\nbatteries (LiBs) powered devices. Most data-driven SoC models are built for a\nfixed ambient temperature, which neglect the high sensitivity of LiBs to\ntemperature and may cause severe prediction errors. Nevertheless, a systematic\nevaluation of the impact of temperature on SoC estimation and ways for a prompt\nadjustment of the estimation model to new temperatures using limited data have\nbeen hardly discussed. To solve these challenges, a novel SoC estimation method\nis proposed by exploiting temporal dynamics of measurements and transferring\nconsistent estimation ability among different temperatures. First, temporal\ndynamics, which is presented by correlations between the past fluctuation and\nthe future motion, is extracted using canonical variate analysis. Next, two\nmodels, including a reference SoC estimation model and an estimation ability\nmonitoring model, are developed with temporal dynamics. The monitoring model\nprovides a path to quantitatively evaluate the influences of temperature on SoC\nestimation ability. After that, once the inability of the reference SoC\nestimation model is detected, consistent temporal dynamics between temperatures\nare selected for transfer learning. Finally, the efficacy of the proposed\nmethod is verified through a benchmark. Our proposed method not only reduces\nprediction errors at fixed temperatures (e.g., reduced by 24.35% at -20{\\deg}C,\n49.82% at 25{\\deg}C) but also improves prediction accuracies at new\ntemperatures.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 05:26:37 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Qin", "Yan", ""], ["Adams", "Stefan", ""], ["Yuen", "Chau", ""]]}, {"id": "2101.03737", "submitter": "Gaole He", "authors": "Gaole He, Yunshi Lan, Jing Jiang, Wayne Xin Zhao and Ji-Rong Wen", "title": "Improving Multi-hop Knowledge Base Question Answering by Learning\n  Intermediate Supervision Signals", "comments": "WSDM 2021 camer-ready version. 9 pages, code on\n  https://github.com/RichardHGL/WSDM2021_NSM", "journal-ref": null, "doi": "10.1145/3437963.3441753", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop Knowledge Base Question Answering (KBQA) aims to find the answer\nentities that are multiple hops away in the Knowledge Base (KB) from the\nentities in the question. A major challenge is the lack of supervision signals\nat intermediate steps. Therefore, multi-hop KBQA algorithms can only receive\nthe feedback from the final answer, which makes the learning unstable or\nineffective.\n  To address this challenge, we propose a novel teacher-student approach for\nthe multi-hop KBQA task. In our approach, the student network aims to find the\ncorrect answer to the query, while the teacher network tries to learn\nintermediate supervision signals for improving the reasoning capacity of the\nstudent network. The major novelty lies in the design of the teacher network,\nwhere we utilize both forward and backward reasoning to enhance the learning of\nintermediate entity distributions. By considering bidirectional reasoning, the\nteacher network can produce more reliable intermediate supervision signals,\nwhich can alleviate the issue of spurious reasoning. Extensive experiments on\nthree benchmark datasets have demonstrated the effectiveness of our approach on\nthe KBQA task. The code to reproduce our analysis is available at\nhttps://github.com/RichardHGL/WSDM2021_NSM.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 07:49:50 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 09:07:52 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["He", "Gaole", ""], ["Lan", "Yunshi", ""], ["Jiang", "Jing", ""], ["Zhao", "Wayne Xin", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2101.03742", "submitter": "Soma Bandyopadhyay", "authors": "Soma Bandyopadhyay, Anish Datta and Arpan Pal (TCS Research, TATA\n  Consultancy Services, Kolkata, India)", "title": "Hierarchical Clustering using Auto-encoded Compact Representation for\n  Time-series Analysis", "comments": "6 figures, 8 pages , 6 tables, accepted and presented conference\n  IJCAI-PRICAI LDRC Learning Data Representation for Clustering (LDRC) workshop\n  2020 https://ldrcworkshop.github.io/LDRC2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting a robust time-series clustering with best choice of distance measure\nand appropriate representation is always a challenge. We propose a novel\nmechanism to identify the clusters combining learned compact representation of\ntime-series, Auto Encoded Compact Sequence (AECS) and hierarchical clustering\napproach. Proposed algorithm aims to address the large computing time issue of\nhierarchical clustering as learned latent representation AECS has a length much\nless than the original length of time-series and at the same time want to\nenhance its performance.Our algorithm exploits Recurrent Neural Network (RNN)\nbased under complete Sequence to Sequence(seq2seq) autoencoder and\nagglomerative hierarchical clustering with a choice of best distance measure to\nrecommend the best clustering. Our scheme selects the best distance measure and\ncorresponding clustering for both univariate and multivariate time-series. We\nhave experimented with real-world time-series from UCR and UCI archive taken\nfrom diverse application domains like health, smart-city, manufacturing etc.\nExperimental results show that proposed method not only produce close to\nbenchmark results but also in some cases outperform the benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 08:03:57 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bandyopadhyay", "Soma", "", "TCS Research, TATA\n  Consultancy Services, Kolkata, India"], ["Datta", "Anish", "", "TCS Research, TATA\n  Consultancy Services, Kolkata, India"], ["Pal", "Arpan", "", "TCS Research, TATA\n  Consultancy Services, Kolkata, India"]]}, {"id": "2101.03747", "submitter": "Yuan Yuan Ding", "authors": "Yuanyuan Ding and Junchi Yan and Guoqiang Hu and Jun Zhu", "title": "Cognitive Visual Inspection Service for LCD Manufacturing Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of display devices, quality inspection via machine\nvision technology has become increasingly important for flat-panel displays\n(FPD) industry. This paper discloses a novel visual inspection system for\nliquid crystal display (LCD), which is currently a dominant type in the FPD\nindustry. The system is based on two cornerstones: robust/high-performance\ndefect recognition model and cognitive visual inspection service architecture.\nA hybrid application of conventional computer vision technique and the latest\ndeep convolutional neural network (DCNN) leads to an integrated defect\ndetection, classfication and impact evaluation model that can be economically\ntrained with only image-level class annotations to achieve a high inspection\naccuracy. In addition, the properly trained model is robust to the variation of\nthe image qulity, significantly alleviating the dependency between the model\nprediction performance and the image aquisition environment. This in turn\njustifies the decoupling of the defect recognition functions from the front-end\ndevice to the back-end serivce, motivating the design and realization of the\ncognitive visual inspection service architecture. Empirical case study is\nperformed on a large-scale real-world LCD dataset from a manufacturing line\nwith different layers and products, which shows the promising utility of our\nsystem, which has been deployed in a real-world LCD manufacturing line from a\nmajor player in the world.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 08:14:35 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Ding", "Yuanyuan", ""], ["Yan", "Junchi", ""], ["Hu", "Guoqiang", ""], ["Zhu", "Jun", ""]]}, {"id": "2101.03805", "submitter": "Zhongqiang Ren", "authors": "Zhongqiang Ren, Sivakumar Rathinam and Howie Choset", "title": "Multi-objective Conflict-based Search for Multi-agent Path Finding", "comments": "7 pages, 5 figures, accepted by ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional multi-agent path planners typically compute an ensemble of paths\nwhile optimizing a single objective, such as path length. However, many\napplications may require multiple objectives, say fuel consumption and\ncompletion time, to be simultaneously optimized during planning and these\ncriteria may not be readily compared and sometimes lie in competition with each\nother. Naively applying existing multi-objective search algorithms to\nmulti-agent path finding may prove to be inefficient as the size of the space\nof possible solutions, i.e., the Pareto-optimal set, can grow exponentially\nwith the number of agents (the dimension of the search space). This article\npresents an approach named Multi-objective Conflict-based Search (MO-CBS) that\nbypasses this so-called curse of dimensionality by leveraging prior\nConflict-based Search (CBS), a well-known algorithm for single-objective\nmulti-agent path finding, and principles of dominance from multi-objective\noptimization literature. We prove that MO-CBS is able to compute the entire\nPareto-optimal set. Our results show that MO-CBS can solve problem instances\nwith hundreds of Pareto-optimal solutions which the standard multi-objective A*\nalgorithms could not find within a bounded time.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 10:42:38 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 06:19:25 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 11:54:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ren", "Zhongqiang", ""], ["Rathinam", "Sivakumar", ""], ["Choset", "Howie", ""]]}, {"id": "2101.03841", "submitter": "Yejin Bang", "authors": "Yejin Bang, Etsuko Ishii, Samuel Cahyawijaya, Ziwei Ji, Pascale Fung", "title": "Model Generalization on COVID-19 Fake News Detection", "comments": "CONSTRAINT Workshop 2021 (Camera Ready Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 12:23:41 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bang", "Yejin", ""], ["Ishii", "Etsuko", ""], ["Cahyawijaya", "Samuel", ""], ["Ji", "Ziwei", ""], ["Fung", "Pascale", ""]]}, {"id": "2101.03867", "submitter": "Ahmad Asadi", "authors": "Mehran Taghian, Ahmad Asadi, Reza Safabakhsh", "title": "A Reinforcement Learning Based Encoder-Decoder Framework for Learning\n  Stock Trading Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of deep reinforcement learning (DRL) models have recently been\nproposed to learn profitable investment strategies. The rules learned by these\nmodels outperform the previous strategies specially in high frequency trading\nenvironments. However, it is shown that the quality of the extracted features\nfrom a long-term sequence of raw prices of the instruments greatly affects the\nperformance of the trading rules learned by these models. Employing a neural\nencoder-decoder structure to extract informative features from complex input\ntime-series has proved very effective in other popular tasks like neural\nmachine translation and video captioning in which the models face a similar\nproblem. The encoder-decoder framework extracts highly informative features\nfrom a long sequence of prices along with learning how to generate outputs\nbased on the extracted features. In this paper, a novel end-to-end model based\non the neural encoder-decoder framework combined with DRL is proposed to learn\nsingle instrument trading strategies from a long sequence of raw prices of the\ninstrument. The proposed model consists of an encoder which is a neural\nstructure responsible for learning informative features from the input\nsequence, and a decoder which is a DRL model responsible for learning\nprofitable strategies based on the features extracted by the encoder. The\nparameters of the encoder and the decoder structures are learned jointly, which\nenables the encoder to extract features fitted to the task of the decoder DRL.\nIn addition, the effects of different structures for the encoder and various\nforms of the input sequences on the performance of the learned strategies are\ninvestigated. Experimental results showed that the proposed model outperforms\nother state-of-the-art models in highly dynamic environments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 13:19:01 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Taghian", "Mehran", ""], ["Asadi", "Ahmad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2101.03936", "submitter": "Rocsildes Canoy", "authors": "Rocsildes Canoy, V\\'ictor Bucarey, Jayanta Mandi, Tias Guns", "title": "Learn-n-Route: Learning implicit preferences for vehicle routing", "comments": "arXiv admin note: text overlap with arXiv:1909.07893", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a learning decision support system for vehicle routing, where\nthe routing engine learns implicit preferences that human planners have when\nmanually creating route plans (or routings). The goal is to use these learned\nsubjective preferences on top of the distance-based objective criterion in\nvehicle routing systems. This is an alternative to the practice of\ndistinctively formulating a custom VRP for every company with its own routing\nrequirements. Instead, we assume the presence of past vehicle routing solutions\nover similar sets of customers, and learn to make similar choices. The learning\napproach is based on the concept of learning a Markov model, which corresponds\nto a probabilistic transition matrix, rather than a deterministic distance\nmatrix. This nevertheless allows us to use existing arc routing VRP software in\ncreating the actual routings, and to optimize over both distances and\npreferences at the same time. For the learning, we explore different schemes to\nconstruct the probabilistic transition matrix that can co-evolve with changing\npreferences over time. Our results on a use-case with a small transportation\ncompany show that our method is able to generate results that are close to the\nmanually created solutions, without needing to characterize all constraints and\nsub-objectives explicitly. Even in the case of changes in the customer sets,\nour method is able to find solutions that are closer to the actual routings\nthan when using only distances, and hence, solutions that require fewer manual\nchanges when transformed into practical routings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 14:57:46 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Canoy", "Rocsildes", ""], ["Bucarey", "V\u00edctor", ""], ["Mandi", "Jayanta", ""], ["Guns", "Tias", ""]]}, {"id": "2101.03958", "submitter": "John Co-Reyes", "authors": "John D. Co-Reyes, Yingjie Miao, Daiyi Peng, Esteban Real, Sergey\n  Levine, Quoc V. Le, Honglak Lee, Aleksandra Faust", "title": "Evolving Reinforcement Learning Algorithms", "comments": "ICLR 2021 Oral. See project website at\n  https://sites.google.com/view/evolvingrl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for meta-learning reinforcement learning algorithms by\nsearching over the space of computational graphs which compute the loss\nfunction for a value-based model-free RL agent to optimize. The learned\nalgorithms are domain-agnostic and can generalize to new environments not seen\nduring training. Our method can both learn from scratch and bootstrap off known\nexisting algorithms, like DQN, enabling interpretable modifications which\nimprove performance. Learning from scratch on simple classical control and\ngridworld tasks, our method rediscovers the temporal-difference (TD) algorithm.\nBootstrapped from DQN, we highlight two learned algorithms which obtain good\ngeneralization performance over other classical control tasks, gridworld type\ntasks, and Atari games. The analysis of the learned algorithm behavior shows\nresemblance to recently proposed RL algorithms that address overestimation in\nvalue-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 18:55:07 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 19:41:47 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 22:53:58 GMT"}, {"version": "v4", "created": "Mon, 3 May 2021 16:35:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Co-Reyes", "John D.", ""], ["Miao", "Yingjie", ""], ["Peng", "Daiyi", ""], ["Real", "Esteban", ""], ["Levine", "Sergey", ""], ["Le", "Quoc V.", ""], ["Lee", "Honglak", ""], ["Faust", "Aleksandra", ""]]}, {"id": "2101.03961", "submitter": "William Fedus", "authors": "William Fedus, Barret Zoph, Noam Shazeer", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple\n  and Efficient Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning, models typically reuse the same parameters for all inputs.\nMixture of Experts (MoE) defies this and instead selects different parameters\nfor each incoming example. The result is a sparsely-activated model -- with\noutrageous numbers of parameters -- but a constant computational cost. However,\ndespite several notable successes of MoE, widespread adoption has been hindered\nby complexity, communication costs and training instability -- we address these\nwith the Switch Transformer. We simplify the MoE routing algorithm and design\nintuitive improved models with reduced communication and computational costs.\nOur proposed training techniques help wrangle the instabilities and we show\nlarge sparse models may be trained, for the first time, with lower precision\n(bfloat16) formats. We design models based off T5-Base and T5-Large to obtain\nup to 7x increases in pre-training speed with the same computational resources.\nThese improvements extend into multilingual settings where we measure gains\nover the mT5-Base version across all 101 languages. Finally, we advance the\ncurrent scale of language models by pre-training up to trillion parameter\nmodels on the \"Colossal Clean Crawled Corpus\" and achieve a 4x speedup over the\nT5-XXL model.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 16:11:52 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Fedus", "William", ""], ["Zoph", "Barret", ""], ["Shazeer", "Noam", ""]]}, {"id": "2101.03989", "submitter": "Alexander Lavin", "authors": "Alexander Lavin, Ciar\\'an M. Gilligan-Lee, Alessya Visnjic, Siddha\n  Ganju, Dava Newman, Sujoy Ganguly, Danny Lange, At{\\i}l{\\i}m G\\\"une\\c{s}\n  Baydin, Amit Sharma, Adam Gibson, Yarin Gal, Eric P. Xing, Chris Mattmann,\n  James Parr", "title": "Technology Readiness Levels for Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development and deployment of machine learning (ML) systems can be\nexecuted easily with modern tools, but the process is typically rushed and\nmeans-to-an-end. The lack of diligence can lead to technical debt, scope creep\nand misaligned objectives, model misuse and failures, and expensive\nconsequences. Engineering systems, on the other hand, follow well-defined\nprocesses and testing standards to streamline development for high-quality,\nreliable results. The extreme is spacecraft systems, where mission critical\nmeasures and robustness are ingrained in the development process. Drawing on\nexperience in both spacecraft engineering and ML (from research through product\nacross domain areas), we have developed a proven systems engineering approach\nfor machine learning development and deployment. Our \"Machine Learning\nTechnology Readiness Levels\" (MLTRL) framework defines a principled process to\nensure robust, reliable, and responsible systems while being streamlined for ML\nworkflows, including key distinctions from traditional software engineering.\nEven more, MLTRL defines a lingua franca for people across teams and\norganizations to work collaboratively on artificial intelligence and machine\nlearning technologies. Here we describe the framework and elucidate it with\nseveral real world use-cases of developing ML methods from basic research\nthrough productization and deployment, in areas such as medical diagnostics,\nconsumer computer vision, satellite imagery, and particle physics.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 15:54:48 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Lavin", "Alexander", ""], ["Gilligan-Lee", "Ciar\u00e1n M.", ""], ["Visnjic", "Alessya", ""], ["Ganju", "Siddha", ""], ["Newman", "Dava", ""], ["Ganguly", "Sujoy", ""], ["Lange", "Danny", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Sharma", "Amit", ""], ["Gibson", "Adam", ""], ["Gal", "Yarin", ""], ["Xing", "Eric P.", ""], ["Mattmann", "Chris", ""], ["Parr", "James", ""]]}, {"id": "2101.03996", "submitter": "Baichuan Mo", "authors": "Baichuan Mo, Zhan Zhao, Haris N. Koutsopoulos, Jinhua Zhao", "title": "Individual Mobility Prediction: An Interpretable Activity-based Hidden\n  Markov Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual mobility is driven by demand for activities with diverse\nspatiotemporal patterns, but existing methods for mobility prediction often\noverlook the underlying activity patterns. To address this issue, this study\ndevelops an activity-based modeling framework for individual mobility\nprediction. Specifically, an input-output hidden Markov model (IOHMM) framework\nis proposed to simultaneously predict the (continuous) time and (discrete)\nlocation of an individual's next trip using transit smart card data. The\nprediction task can be transformed into predicting the hidden activity duration\nand end location. Based on a case study of Hong Kong's metro system, we show\nthat the proposed model can achieve similar prediction performance as the\nstate-of-the-art long short-term memory (LSTM) model. Unlike LSTM, the proposed\nIOHMM model can also be used to analyze hidden activity patterns, which\nprovides meaningful behavioral interpretation for why an individual makes a\ncertain trip. Therefore, the activity-based prediction framework offers a way\nto preserve the predictive power of advanced machine learning methods while\nenhancing our ability to generate insightful behavioral explanations, which is\nuseful for enhancing situational awareness in user-centric transportation\napplications such as personalized traveler information.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 16:11:27 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Mo", "Baichuan", ""], ["Zhao", "Zhan", ""], ["Koutsopoulos", "Haris N.", ""], ["Zhao", "Jinhua", ""]]}, {"id": "2101.04017", "submitter": "Antonio Lieto", "authors": "Antonio Lieto, Gian Luca Pozzato, Stefano Zoia, Viviana Patti, Rossana\n  Damiano", "title": "A Commonsense Reasoning Framework for Explanatory Emotion Attribution,\n  Generation and Re-classification", "comments": "50 pages. This work has been partially funded from the European\n  Research Council (ERC) under the European Union'sHorizon 2020 research and\n  innovation programme, grant agreement n{\\deg}870811", "journal-ref": "Knowledge-Based Systems, 2021", "doi": "10.1016/j.knosys.2021.107166", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present DEGARI (Dynamic Emotion Generator And ReclassIfier), an\nexplainable system for emotion attribution and recommendation. This system\nrelies on a recently introduced commonsense reasoning framework, the TCL logic,\nwhich is based on a human-like procedure for the automatic generation of novel\nconcepts in a Description Logics knowledge base. Starting from an ontological\nformalization of emotions based on the Plutchik model, known as ArsEmotica, the\nsystem exploits the logic TCL to automatically generate novel commonsense\nsemantic representations of compound emotions (e.g. Love as derived from the\ncombination of Joy and Trust according to Plutchik). The generated emotions\ncorrespond to prototypes, i.e. commonsense representations of given concepts,\nand have been used to reclassify emotion-related contents in a variety of\nartistic domains, ranging from art datasets to the editorial contents available\nin RaiPlay, the online platform of RAI Radiotelevisione Italiana (the Italian\npublic broadcasting company). We show how the reported results (evaluated in\nthe light of the obtained reclassifications, the user ratings assigned to such\nreclassifications, and their explainability) are encouraging, and pave the way\nto many further research directions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 16:44:38 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 13:58:59 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 13:48:08 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 20:53:30 GMT"}, {"version": "v5", "created": "Wed, 2 Jun 2021 11:10:56 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lieto", "Antonio", ""], ["Pozzato", "Gian Luca", ""], ["Zoia", "Stefano", ""], ["Patti", "Viviana", ""], ["Damiano", "Rossana", ""]]}, {"id": "2101.04047", "submitter": "Linda Boedi", "authors": "Linda H. Boedi and Helmut Grabner", "title": "Learning to Ignore: Fair and Task Independent Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training fair machine learning models, aiming for their interpretability and\nsolving the problem of domain shift has gained a lot of interest in the last\nyears. There is a vast amount of work addressing these topics, mostly in\nseparation. In this work we show that they can be seen as a common framework of\nlearning invariant representations. The representations should allow to predict\nthe target while at the same time being invariant to sensitive attributes which\nsplit the dataset into subgroups. Our approach is based on the simple\nobservation that it is impossible for any learning algorithm to differentiate\nsamples if they have the same feature representation. This is formulated as an\nadditional loss (regularizer) enforcing a common feature representation across\nsubgroups. We apply it to learn fair models and interpret the influence of the\nsensitive attribute. Furthermore it can be used for domain adaptation,\ntransferring knowledge and learning effectively from very few examples. In all\napplications it is essential not only to learn to predict the target, but also\nto learn what to ignore.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 17:33:18 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 09:01:04 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Boedi", "Linda H.", ""], ["Grabner", "Helmut", ""]]}, {"id": "2101.04073", "submitter": "Anush Sankaran", "authors": "Anush Sankaran, Olivier Mastropietro, Ehsan Saboori, Yasser Idris,\n  Davis Sawyer, MohammadHossein AskariHemmat, Ghouthi Boukli Hacene", "title": "Deeplite Neutrino: An End-to-End Framework for Constrained Deep Learning\n  Model Optimization", "comments": "\"IAAI Deployed Application Award\", IAAI 2021 @ AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing deep learning-based solutions is becoming a race for training\ndeeper models with a greater number of layers. While a large-size deeper model\ncould provide competitive accuracy, it creates a lot of logistical challenges\nand unreasonable resource requirements during development and deployment. This\nhas been one of the key reasons for deep learning models not being excessively\nused in various production environments, especially in edge devices. There is\nan immediate requirement for optimizing and compressing these deep learning\nmodels, to enable on-device intelligence. In this research, we introduce a\nblack-box framework, Deeplite Neutrino for production-ready optimization of\ndeep learning models. The framework provides an easy mechanism for the\nend-users to provide constraints such as a tolerable drop in accuracy or target\nsize of the optimized models, to guide the whole optimization process. The\nframework is easy to include in an existing production pipeline and is\navailable as a Python Package, supporting PyTorch and Tensorflow libraries. The\noptimization performance of the framework is shown across multiple benchmark\ndatasets and popular deep learning models. Further, the framework is currently\nused in production and the results and testimonials from several clients are\nsummarized.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 18:07:45 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 14:57:12 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Sankaran", "Anush", ""], ["Mastropietro", "Olivier", ""], ["Saboori", "Ehsan", ""], ["Idris", "Yasser", ""], ["Sawyer", "Davis", ""], ["AskariHemmat", "MohammadHossein", ""], ["Hacene", "Ghouthi Boukli", ""]]}, {"id": "2101.04086", "submitter": "An Nguyen", "authors": "An Nguyen, Stefan Foerstel, Thomas Kittler, Andrey Kurzyukov, Leo\n  Schwinn, Dario Zanca, Tobias Hipp, Da Jun Sun, Michael Schrapp, Eva Rothgang,\n  Bjoern Eskofier", "title": "System Design for a Data-driven and Explainable Customer Sentiment\n  Monitor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important goal of customer services is to keep the customer\nsatisfied. However, service resources are always limited and must be\nprioritized. Therefore, it is important to identify customers who potentially\nbecome unsatisfied and might lead to escalations. Today this prioritization of\ncustomers is often done manually. Data science on IoT data (esp. log data) for\nmachine health monitoring, as well as analytics on enterprise data for customer\nrelationship management (CRM) have mainly been researched and applied\nindependently. In this paper, we present a framework for a data-driven decision\nsupport system which combines IoT and enterprise data to model customer\nsentiment. Such decision support systems can help to prioritize customers and\nservice resources to effectively troubleshoot problems or even avoid them. The\nframework is applied in a real-world case study with a major medical device\nmanufacturer. This includes a fully automated and interpretable machine\nlearning pipeline designed to meet the requirements defined with domain experts\nand end users. The overall framework is currently deployed, learns and\nevaluates predictive models from terabytes of IoT and enterprise data to\nactively monitor the customer sentiment for a fleet of thousands of high-end\nmedical devices. Furthermore, we provide an anonymized industrial benchmark\ndataset for the research community.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 18:29:50 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Nguyen", "An", ""], ["Foerstel", "Stefan", ""], ["Kittler", "Thomas", ""], ["Kurzyukov", "Andrey", ""], ["Schwinn", "Leo", ""], ["Zanca", "Dario", ""], ["Hipp", "Tobias", ""], ["Sun", "Da Jun", ""], ["Schrapp", "Michael", ""], ["Rothgang", "Eva", ""], ["Eskofier", "Bjoern", ""]]}, {"id": "2101.04109", "submitter": "Zijian Zhang", "authors": "Zijian Zhang, Koustav Rudra, Avishek Anand", "title": "Explain and Predict, and then Predict Again", "comments": "Accepted in the WSDM 2021", "journal-ref": null, "doi": "10.1145/3437963.3441758", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A desirable property of learning systems is to be both effective and\ninterpretable. Towards this goal, recent models have been proposed that first\ngenerate an extractive explanation from the input text and then generate a\nprediction on just the explanation called explain-then-predict models. These\nmodels primarily consider the task input as a supervision signal in learning an\nextractive explanation and do not effectively integrate rationales data as an\nadditional inductive bias to improve task performance. We propose a novel yet\nsimple approach ExPred, that uses multi-task learning in the explanation\ngeneration phase effectively trading-off explanation and prediction losses. And\nthen we use another prediction network on just the extracted explanations for\noptimizing the task performance. We conduct an extensive evaluation of our\napproach on three diverse language datasets -- fact verification, sentiment\nclassification, and QA -- and find that we substantially outperform existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:36:52 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 05:19:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Zijian", ""], ["Rudra", "Koustav", ""], ["Anand", "Avishek", ""]]}, {"id": "2101.04117", "submitter": "Miles Cranmer", "authors": "Miles Cranmer, Daniel Tamayo, Hanno Rein, Peter Battaglia, Samuel\n  Hadden, Philip J. Armitage, Shirley Ho, David N. Spergel", "title": "A Bayesian neural network predicts the dissolution of compact planetary\n  systems", "comments": "8 content pages, 7 appendix and references. 8 figures. Source code\n  at: https://github.com/MilesCranmer/bnn_chaos_model inference code at\n  https://github.com/dtamayo/spock", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite over three hundred years of effort, no solutions exist for predicting\nwhen a general planetary configuration will become unstable. We introduce a\ndeep learning architecture to push forward this problem for compact systems.\nWhile current machine learning algorithms in this area rely on\nscientist-derived instability metrics, our new technique learns its own metrics\nfrom scratch, enabled by a novel internal structure inspired from dynamics\ntheory. Our Bayesian neural network model can accurately predict not only if,\nbut also when a compact planetary system with three or more planets will go\nunstable. Our model, trained directly from short N-body time series of raw\norbital elements, is more than two orders of magnitude more accurate at\npredicting instability times than analytical estimators, while also reducing\nthe bias of existing machine learning algorithms by nearly a factor of three.\nDespite being trained on compact resonant and near-resonant three-planet\nconfigurations, the model demonstrates robust generalization to both\nnon-resonant and higher multiplicity configurations, in the latter case\noutperforming models fit to that specific set of integrations. The model\ncomputes instability estimates up to five orders of magnitude faster than a\nnumerical integrator, and unlike previous efforts provides confidence intervals\non its predictions. Our inference model is publicly available in the SPOCK\npackage, with training code open-sourced.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:00:00 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cranmer", "Miles", ""], ["Tamayo", "Daniel", ""], ["Rein", "Hanno", ""], ["Battaglia", "Peter", ""], ["Hadden", "Samuel", ""], ["Armitage", "Philip J.", ""], ["Ho", "Shirley", ""], ["Spergel", "David N.", ""]]}, {"id": "2101.04163", "submitter": "Yipeng Zhou", "authors": "Yao Fu, Yipeng Zhou, Di Wu, Shui Yu, Yonggang Wen, Chao Li", "title": "On the Practicality of Differential Privacy in Federated Learning by\n  Tuning Iteration Times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite that Federated Learning (FL) is well known for its privacy\nprotection when training machine learning models among distributed clients\ncollaboratively, recent studies have pointed out that the naive FL is\nsusceptible to gradient leakage attacks. In the meanwhile, Differential Privacy\n(DP) emerges as a promising countermeasure to defend against gradient leakage\nattacks. However, the adoption of DP by clients in FL may significantly\njeopardize the model accuracy. It is still an open problem to understand the\npracticality of DP from a theoretic perspective. In this paper, we make the\nfirst attempt to understand the practicality of DP in FL through tuning the\nnumber of conducted iterations. Based on the FedAvg algorithm, we formally\nderive the convergence rate with DP noises in FL. Then, we theoretically\nderive: 1) the conditions for the DP based FedAvg to converge as the number of\nglobal iterations (GI) approaches infinity; 2) the method to set the number of\nlocal iterations (LI) to minimize the negative influence of DP noises. By\nfurther substituting the Laplace and Gaussian mechanisms into the derived\nconvergence rate respectively, we show that: 3) The DP based FedAvg with the\nLaplace mechanism cannot converge, but the divergence rate can be effectively\nprohibited by setting the number of LIs with our method; 4) The learning error\nof the DP based FedAvg with the Gaussian mechanism can converge to a constant\nnumber finally if we use a fixed number of LIs per GI. To verify our\ntheoretical findings, we conduct extensive experiments using two real-world\ndatasets. The results not only validate our analysis results, but also provide\nuseful guidelines on how to optimize model accuracy when incorporating DP into\nFL\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:43:12 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Fu", "Yao", ""], ["Zhou", "Yipeng", ""], ["Wu", "Di", ""], ["Yu", "Shui", ""], ["Wen", "Yonggang", ""], ["Li", "Chao", ""]]}, {"id": "2101.04167", "submitter": "Ruiyang Xu", "authors": "Ruiyang Xu, Prashank Kadam, Karl Lieberherr", "title": "First-Order Problem Solving through Neural MCTS based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The formal semantics of an interpreted first-order logic (FOL) statement can\nbe given in Tarskian Semantics or a basically equivalent Game Semantics. The\nlatter maps the statement and the interpretation into a two-player semantic\ngame. Many combinatorial problems can be described using interpreted FOL\nstatements and can be mapped into a semantic game. Therefore, learning to play\na semantic game perfectly leads to the solution of a specific instance of a\ncombinatorial problem. We adapt the AlphaZero algorithm so that it becomes\nbetter at learning to play semantic games that have different characteristics\nthan Go and Chess. We propose a general framework, Persephone, to map the FOL\ndescription of a combinatorial problem to a semantic game so that it can be\nsolved through a neural MCTS based reinforcement learning algorithm. Our goal\nfor Persephone is to make it tabula-rasa, mapping a problem stated in\ninterpreted FOL to a solution without human intervention.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:54:06 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Xu", "Ruiyang", ""], ["Kadam", "Prashank", ""], ["Lieberherr", "Karl", ""]]}, {"id": "2101.04209", "submitter": "Yue Zhao", "authors": "Yue Zhao, Zhi Qiao, Cao Xiao, Lucas Glass, Jimeng Sun", "title": "PyHealth: A Python Library for Health Predictive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the explosion of interest in healthcare AI research, the\nreproducibility and benchmarking of those research works are often limited due\nto the lack of standard benchmark datasets and diverse evaluation metrics. To\naddress this reproducibility challenge, we develop PyHealth, an open-source\nPython toolbox for developing various predictive models on healthcare data.\n  PyHealth consists of data preprocessing module, predictive modeling module,\nand evaluation module. The target users of PyHealth are both computer science\nresearchers and healthcare data scientists. With PyHealth, they can conduct\ncomplex machine learning pipelines on healthcare datasets with fewer than ten\nlines of code. The data preprocessing module enables the transformation of\ncomplex healthcare datasets such as longitudinal electronic health records,\nmedical images, continuous signals (e.g., electrocardiogram), and clinical\nnotes into machine learning friendly formats. The predictive modeling module\nprovides more than 30 machine learning models, including established ensemble\ntrees and deep neural network-based approaches, via a unified but extendable\nAPI designed for both researchers and practitioners. The evaluation module\nprovides various evaluation strategies (e.g., cross-validation and\ntrain-validation-test split) and predictive model metrics.\n  With robustness and scalability in mind, best practices such as unit testing,\ncontinuous integration, code coverage, and interactive examples are introduced\nin the library's development. PyHealth can be installed through the Python\nPackage Index (PyPI) or https://github.com/yzhao062/PyHealth .\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 22:02:08 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Zhao", "Yue", ""], ["Qiao", "Zhi", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "2101.04224", "submitter": "Shruti Jadon", "authors": "Shruti Jadon, Jan Kanty Milczek, Ajit Patankar", "title": "Challenges and approaches to time-series forecasting in data center\n  telemetry: A Survey", "comments": "13 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Time-series forecasting has been an important research domain for so many\nyears. Its applications include ECG predictions, sales forecasting, weather\nconditions, even COVID-19 spread predictions. These applications have motivated\nmany researchers to figure out an optimal forecasting approach, but the\nmodeling approach also changes as the application domain changes. This work has\nfocused on reviewing different forecasting approaches for telemetry data\npredictions collected at data centers. Forecasting of telemetry data is a\ncritical feature of network and data center management products. However, there\nare multiple options of forecasting approaches that range from a simple linear\nstatistical model to high capacity deep learning architectures. In this paper,\nwe attempted to summarize and evaluate the performance of well known time\nseries forecasting techniques. We hope that this evaluation provides a\ncomprehensive summary to innovate in forecasting approaches for telemetry data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 22:36:21 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 21:55:24 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Jadon", "Shruti", ""], ["Milczek", "Jan Kanty", ""], ["Patankar", "Ajit", ""]]}, {"id": "2101.04237", "submitter": "Samuel Sokota", "authors": "Samuel Sokota, Edward Lockhart, Finbarr Timbers, Elnaz Davoodi, Ryan\n  D'Orazio, Neil Burch, Martin Schmid, Michael Bowling, Marc Lanctot", "title": "Solving Common-Payoff Games with Approximate Policy Iteration", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For artificially intelligent learning systems to have widespread\napplicability in real-world settings, it is important that they be able to\noperate decentrally. Unfortunately, decentralized control is difficult --\ncomputing even an epsilon-optimal joint policy is a NEXP complete problem.\nNevertheless, a recently rediscovered insight -- that a team of agents can\ncoordinate via common knowledge -- has given rise to algorithms capable of\nfinding optimal joint policies in small common-payoff games. The Bayesian\naction decoder (BAD) leverages this insight and deep reinforcement learning to\nscale to games as large as two-player Hanabi. However, the approximations it\nuses to do so prevent it from discovering optimal joint policies even in games\nsmall enough to brute force optimal solutions. This work proposes CAPI, a novel\nalgorithm which, like BAD, combines common knowledge with deep reinforcement\nlearning. However, unlike BAD, CAPI prioritizes the propensity to discover\noptimal joint policies over scalability. While this choice precludes CAPI from\nscaling to games as large as Hanabi, empirical results demonstrate that, on the\ngames to which CAPI does scale, it is capable of discovering optimal joint\npolicies even when other modern multi-agent reinforcement learning algorithms\nare unable to do so. Code is available at https://github.com/ssokota/capi .\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 23:42:02 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Sokota", "Samuel", ""], ["Lockhart", "Edward", ""], ["Timbers", "Finbarr", ""], ["Davoodi", "Elnaz", ""], ["D'Orazio", "Ryan", ""], ["Burch", "Neil", ""], ["Schmid", "Martin", ""], ["Bowling", "Michael", ""], ["Lanctot", "Marc", ""]]}, {"id": "2101.04255", "submitter": "Dominic Widdows", "authors": "Dominic Widdows and Kirsty Kitto and Trevor Cohen", "title": "Quantum Mathematics in Artificial Intelligence", "comments": "Manuscript updated to correct one author's email address, and with\n  some extra references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the decade since 2010, successes in artificial intelligence have been at\nthe forefront of computer science and technology, and vector space models have\nsolidified a position at the forefront of artificial intelligence. At the same\ntime, quantum computers have become much more powerful, and announcements of\nmajor advances are frequently in the news.\n  The mathematical techniques underlying both these areas have more in common\nthan is sometimes realized. Vector spaces took a position at the axiomatic\nheart of quantum mechanics in the 1930s, and this adoption was a key motivation\nfor the derivation of logic and probability from the linear geometry of vector\nspaces. Quantum interactions between particles are modelled using the tensor\nproduct, which is also used to express objects and operations in artificial\nneural networks.\n  This paper describes some of these common mathematical areas, including\nexamples of how they are used in artificial intelligence (AI), particularly in\nautomated reasoning and natural language processing (NLP). Techniques discussed\ninclude vector spaces, scalar products, subspaces and implication, orthogonal\nprojection and negation, dual vectors, density matrices, positive operators,\nand tensor products. Application areas include information retrieval,\ncategorization and implication, modelling word-senses and disambiguation,\ninference in knowledge bases, and semantic composition.\n  Some of these approaches can potentially be implemented on quantum hardware.\nMany of the practical steps in this implementation are in early stages, and\nsome are already realized. Explaining some of the common mathematical tools can\nhelp researchers in both AI and quantum computing further exploit these\noverlaps, recognizing and exploring new directions along the way.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 01:35:56 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 20:58:51 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 17:36:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Widdows", "Dominic", ""], ["Kitto", "Kirsty", ""], ["Cohen", "Trevor", ""]]}, {"id": "2101.04257", "submitter": "Joosung Lee", "authors": "Joosung Lee", "title": "Transforming Multi-Conditioned Generation from Meaning Representation", "comments": "Accepted at RANLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In task-oriented conversation systems, natural language generation systems\nthat generate sentences with specific information related to conversation flow\nare useful. Our study focuses on language generation by considering various\ninformation representing the meaning of utterances as multiple conditions of\ngeneration. NLG from meaning representations, the conditions for sentence\nmeaning, generally goes through two steps: sentence planning and surface\nrealization. However, we propose a simple one-stage framework to generate\nutterances directly from MR (Meaning Representation). Our model is based on\nGPT2 and generates utterances with flat conditions on slot and value pairs,\nwhich does not need to determine the structure of the sentence. We evaluate\nseveral systems in the E2E dataset with 6 automatic metrics. Our system is a\nsimple method, but it demonstrates comparable performance to previous systems\nin automated metrics. In addition, using only 10\\% of the data set without any\nother techniques, our model achieves comparable performance, and shows the\npossibility of performing zero-shot generation and expanding to other datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 01:45:06 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 04:42:34 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lee", "Joosung", ""]]}, {"id": "2101.04283", "submitter": "Huimin Peng", "authors": "Huimin Peng", "title": "A Brief Survey of Associations Between Meta-Learning and General AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper briefly reviews the history of meta-learning and describes its\ncontribution to general AI. Meta-learning improves model generalization\ncapacity and devises general algorithms applicable to both in-distribution and\nout-of-distribution tasks potentially. General AI replaces task-specific models\nwith general algorithmic systems introducing higher level of automation in\nsolving diverse tasks using AI. We summarize main contributions of\nmeta-learning to the developments in general AI, including memory module,\nmeta-learner, coevolution, curiosity, forgetting and AI-generating algorithm.\nWe present connections between meta-learning and general AI and discuss how\nmeta-learning can be used to formulate general AI algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 03:57:16 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Peng", "Huimin", ""]]}, {"id": "2101.04293", "submitter": "Md Abul Hayat", "authors": "Md Abul Hayat, Peter Harrington, George Stein, Zarija Luki\\'c, Mustafa\n  Mustafa", "title": "Estimating Galactic Distances From Images Using Self-supervised\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a contrastive self-supervised learning framework to estimate distances\nto galaxies from their photometric images. We incorporate data augmentations\nfrom computer vision as well as an application-specific augmentation accounting\nfor galactic dust. We find that the resulting visual representations of galaxy\nimages are semantically useful and allow for fast similarity searches, and can\nbe successfully fine-tuned for the task of redshift estimation. We show that\n(1) pretraining on a large corpus of unlabeled data followed by fine-tuning on\nsome labels can attain the accuracy of a fully-supervised model which requires\n2-4x more labeled data, and (2) that by fine-tuning our self-supervised\nrepresentations using all available data labels in the Main Galaxy Sample of\nthe Sloan Digital Sky Survey (SDSS), we outperform the state-of-the-art\nsupervised learning method.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 04:39:26 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hayat", "Md Abul", ""], ["Harrington", "Peter", ""], ["Stein", "George", ""], ["Luki\u0107", "Zarija", ""], ["Mustafa", "Mustafa", ""]]}, {"id": "2101.04350", "submitter": "Neslihan Bayramoglu", "authors": "Neslihan Bayramoglu, Miika T. Nieminen, Simo Saarakkala", "title": "Automated Detection of Patellofemoral Osteoarthritis from Knee Lateral\n  View Radiographs Using Deep Learning: Data from the Multicenter\n  Osteoarthritis Study (MOST)", "comments": "24 pages, preprint, Submitted to Osteoarthritis and Cartilage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To assess the ability of imaging-based deep learning to predict\nradiographic patellofemoral osteoarthritis (PFOA) from knee lateral view\nradiographs.\n  Design: Knee lateral view radiographs were extracted from The Multicenter\nOsteoarthritis Study (MOST) (n = 18,436 knees). Patellar region-of-interest\n(ROI) was first automatically detected, and subsequently, end-to-end deep\nconvolutional neural networks (CNNs) were trained and validated to detect the\nstatus of patellofemoral OA. Patellar ROI was detected using\ndeep-learning-based object detection method. Manual PFOA status assessment\nprovided in the MOST dataset was used as a classification outcome for the CNNs.\nPerformance of prediction models was assessed using the area under the receiver\noperating characteristic curve (ROC AUC) and the average precision (AP)\nobtained from the precision-recall (PR) curve in the stratified 5-fold cross\nvalidation setting.\n  Results: Of the 18,436 knees, 3,425 (19%) had PFOA. AUC and AP for the\nreference model including age, sex, body mass index (BMI), the total Western\nOntario and McMaster Universities Arthritis Index (WOMAC) score, and\ntibiofemoral Kellgren-Lawrence (KL) grade to predict PFOA were 0.806 and 0.478,\nrespectively. The CNN model that used only image data significantly improved\nthe prediction of PFOA status (ROC AUC= 0.958, AP= 0.862).\n  Conclusion: We present the first machine learning based automatic PFOA\ndetection method. Furthermore, our deep learning based model trained on patella\nregion from knee lateral view radiographs performs better at predicting PFOA\nthan models based on patient characteristics and clinical assessments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 08:37:55 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bayramoglu", "Neslihan", ""], ["Nieminen", "Miika T.", ""], ["Saarakkala", "Simo", ""]]}, {"id": "2101.04377", "submitter": "Jiajia Guo", "authors": "Jiajia Guo, Chao-Kai Wen, Shi Jin", "title": "CAnet: Uplink-aided Downlink Channel Acquisition in FDD Massive MIMO\n  using Deep Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In frequency-division duplexing systems, the downlink channel state\ninformation (CSI) acquisition scheme leads to high training and feedback\noverheads. In this paper, we propose an uplink-aided downlink channel\nacquisition framework using deep learning to reduce these overheads. Unlike\nmost existing works that focus only on channel estimation or feedback modules,\nto the best of our knowledge, this is the first study that considers the entire\ndownlink CSI acquisition process, including downlink pilot design, channel\nestimation, and feedback. First, we propose an adaptive pilot design module by\nexploiting the correlation in magnitude among bidirectional channels in the\nangular domain to improve channel estimation. Next, to avoid the bit allocation\nproblem during the feedback module, we concatenate the complex channel and\nembed the uplink channel magnitude to the channel reconstruction at the base\nstation. Lastly, we combine the above two modules and compare two popular\ndownlink channel acquisition frameworks. The former framework estimates and\nfeeds back the channel at the user equipment subsequently. The user equipment\nin the latter one directly feeds back the received pilot signals to the base\nstation. Our results reveal that, with the help of uplink, directly feeding\nback the pilot signals can save approximately 20% of feedback bits, which\nprovides a guideline for future research.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 10:12:28 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Guo", "Jiajia", ""], ["Wen", "Chao-Kai", ""], ["Jin", "Shi", ""]]}, {"id": "2101.04406", "submitter": "Dimitris Gkoumas", "authors": "Dimitris Gkoumas, Qiuchi Li, Shahram Dehdashti, Massimo Melucci, Yijun\n  Yu, Dawei Song", "title": "Quantum Cognitively Motivated Decision Fusion for Video Sentiment\n  Analysis", "comments": "The uploaded version is a preprint of the accepted AAAI-21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video sentiment analysis as a decision-making process is inherently complex,\ninvolving the fusion of decisions from multiple modalities and the so-caused\ncognitive biases. Inspired by recent advances in quantum cognition, we show\nthat the sentiment judgment from one modality could be incompatible with the\njudgment from another, i.e., the order matters and they cannot be jointly\nmeasured to produce a final decision. Thus the cognitive process exhibits\n\"quantum-like\" biases that cannot be captured by classical probability\ntheories. Accordingly, we propose a fundamentally new, quantum cognitively\nmotivated fusion strategy for predicting sentiment judgments. In particular, we\nformulate utterances as quantum superposition states of positive and negative\nsentiment judgments, and uni-modal classifiers as mutually incompatible\nobservables, on a complex-valued Hilbert space with positive-operator valued\nmeasures. Experiments on two benchmarking datasets illustrate that our model\nsignificantly outperforms various existing decision level and a range of\nstate-of-the-art content-level fusion approaches. The results also show that\nthe concept of incompatibility allows effective handling of all combination\npatterns, including those extreme cases that are wrongly predicted by all\nuni-modal classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 11:06:04 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 19:54:05 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Gkoumas", "Dimitris", ""], ["Li", "Qiuchi", ""], ["Dehdashti", "Shahram", ""], ["Melucci", "Massimo", ""], ["Yu", "Yijun", ""], ["Song", "Dawei", ""]]}, {"id": "2101.04422", "submitter": "Quirin G\\\"ottl", "authors": "Quirin G\\\"ottl, Dominik G. Grimm, Jakob Burger", "title": "Automated Synthesis of Steady-State Continuous Processes using\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated flowsheet synthesis is an important field in computer-aided process\nengineering. The present work demonstrates how reinforcement learning can be\nused for automated flowsheet synthesis without any heuristics of prior\nknowledge of conceptual design. The environment consists of a steady-state\nflowsheet simulator that contains all physical knowledge. An agent is trained\nto take discrete actions and sequentially built up flowsheets that solve a\ngiven process problem. A novel method named SynGameZero is developed to ensure\ngood exploration schemes in the complex problem. Therein, flowsheet synthesis\nis modelled as a game of two competing players. The agent plays this game\nagainst itself during training and consists of an artificial neural network and\na tree search for forward planning. The method is applied successfully to a\nreaction-distillation process in a quaternary system.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 11:49:34 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 09:42:10 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["G\u00f6ttl", "Quirin", ""], ["Grimm", "Dominik G.", ""], ["Burger", "Jakob", ""]]}, {"id": "2101.04424", "submitter": "Manuel Chica Serrano", "authors": "M. Chica and J. Hernandez and C. Manrique-de-Lara-Pe\\~nate and R.\n  Chiong", "title": "An Evolutionary Game Model for Understanding Fraud in Consumption Taxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a computational evolutionary game model to study and\nunderstand fraud dynamics in the consumption tax system. Players are\ncooperators if they correctly declare their value added tax (VAT), and are\ndefectors otherwise. Each player's payoff is influenced by the amount evaded\nand the subjective probability of being inspected by tax authorities. Since\ntransactions between companies must be declared by both the buyer and seller, a\nstrategy adopted by one influences the other's payoff. We study the model with\na well-mixed population and different scale-free networks. Model parameters\nwere calibrated using real-world data of VAT declarations by businesses\nregistered in the Canary Islands region of Spain. We analyzed several scenarios\nof audit probabilities for high and low transactions and their prevalence in\nthe population, as well as social rewards and penalties to find the most\nefficient policy to increase the proportion of cooperators. Two major insights\nwere found. First, increasing the subjective audit probability for low\ntransactions is more efficient than increasing this probability for high\ntransactions. Second, favoring social rewards for cooperators or alternative\npenalties for defectors can be effective policies, but their success depends on\nthe distribution of the audit probability for low and high transactions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 11:53:31 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Chica", "M.", ""], ["Hernandez", "J.", ""], ["Manrique-de-Lara-Pe\u00f1ate", "C.", ""], ["Chiong", "R.", ""]]}, {"id": "2101.04454", "submitter": "Sahand Rezaei-Shoshtari Mr.", "authors": "Sahand Rezaei-Shoshtari, Francois Robert Hogan, Michael Jenkin, David\n  Meger, Gregory Dudek", "title": "Learning Intuitive Physics with Multimodal Generative Models", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the future interaction of objects when they come into contact with\ntheir environment is key for autonomous agents to take intelligent and\nanticipatory actions. This paper presents a perception framework that fuses\nvisual and tactile feedback to make predictions about the expected motion of\nobjects in dynamic scenes. Visual information captures object properties such\nas 3D shape and location, while tactile information provides critical cues\nabout interaction forces and resulting object motion when it makes contact with\nthe environment. Utilizing a novel See-Through-your-Skin (STS) sensor that\nprovides high resolution multimodal sensing of contact surfaces, our system\ncaptures both the visual appearance and the tactile properties of objects. We\ninterpret the dual stream signals from the sensor using a Multimodal\nVariational Autoencoder (MVAE), allowing us to capture both modalities of\ncontacting objects and to develop a mapping from visual to tactile interaction\nand vice-versa. Additionally, the perceptual system can be used to infer the\noutcome of future physical interactions, which we validate through simulated\nand real-world experiments in which the resting state of an object is predicted\nfrom given initial conditions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 12:55:53 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 21:57:48 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Rezaei-Shoshtari", "Sahand", ""], ["Hogan", "Francois Robert", ""], ["Jenkin", "Michael", ""], ["Meger", "David", ""], ["Dudek", "Gregory", ""]]}, {"id": "2101.04506", "submitter": "Changcheng Wang", "authors": "Yongsheng Zang, Dongming Zhou, Changcheng Wang, Rencan Nie, and Yanbu\n  Guo", "title": "UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image\n  fusion", "comments": "17pages,11 figures, 7 tables. IEEE Transactions on Instrumentation\n  and Measurement", "journal-ref": null, "doi": "10.1109/TIM.2021.3072124", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional and deep learning-based fusion methods generated the intermediate\ndecision map to obtain the fusion image through a series of post-processing\nprocedures. However, the fusion results generated by these methods are easy to\nlose some source image details or results in artifacts. Inspired by the image\nreconstruction techniques based on deep learning, we propose a multi-focus\nimage fusion network framework without any post-processing to solve these\nproblems in the end-to-end and supervised learning way. To sufficiently train\nthe fusion model, we have generated a large-scale multi-focus image dataset\nwith ground-truth fusion images. What's more, to obtain a more informative\nfusion image, we further designed a novel fusion strategy based on unity fusion\nattention, which is composed of a channel attention module and a spatial\nattention module. Specifically, the proposed fusion approach mainly comprises\nthree key components: feature extraction, feature fusion and image\nreconstruction. We firstly utilize seven convolutional blocks to extract the\nimage features from source images. Then, the extracted convolutional features\nare fused by the proposed fusion strategy in the feature fusion layer. Finally,\nthe fused image features are reconstructed by four convolutional blocks.\nExperimental results demonstrate that the proposed approach for multi-focus\nimage fusion achieves remarkable fusion performance compared to 19\nstate-of-the-art fusion methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 14:33:13 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 11:01:45 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 02:55:00 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 08:41:48 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zang", "Yongsheng", ""], ["Zhou", "Dongming", ""], ["Wang", "Changcheng", ""], ["Nie", "Rencan", ""], ["Guo", "Yanbu", ""]]}, {"id": "2101.04520", "submitter": "Morteza Haghir Chehreghani", "authors": "Victor Eberstein, Jonas Sj\\\"oblom, Nikolce Murgovski, Morteza Haghir\n  Chehreghani", "title": "A Unified Framework for Online Trip Destination Prediction", "comments": "18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trip destination prediction is an area of increasing importance in many\napplications such as trip planning, autonomous driving and electric vehicles.\nEven though this problem could be naturally addressed in an online learning\nparadigm where data is arriving in a sequential fashion, the majority of\nresearch has rather considered the offline setting. In this paper, we present a\nunified framework for trip destination prediction in an online setting, which\nis suitable for both online training and online prediction. For this purpose,\nwe develop two clustering algorithms and integrate them within two online\nprediction models for this problem.\n  We investigate the different configurations of clustering algorithms and\nprediction models on a real-world dataset. By using traditional clustering\nmetrics and accuracy, we demonstrate that both the clustering and the entire\nframework yield consistent results compared to the offline setting. Finally, we\npropose a novel regret metric for evaluating the entire online framework in\ncomparison to its offline counterpart. This metric makes it possible to relate\nthe source of erroneous predictions to either the clustering or the prediction\nmodel. Using this metric, we show that the proposed methods converge to a\nprobability distribution resembling the true underlying distribution and enjoy\na lower regret than all of the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 14:45:27 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Eberstein", "Victor", ""], ["Sj\u00f6blom", "Jonas", ""], ["Murgovski", "Nikolce", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2101.04547", "submitter": "Damian Pascual", "authors": "Sumu Zhao, Damian Pascual, Gino Brunner, Roger Wattenhofer", "title": "Of Non-Linearity and Commutativity in BERT", "comments": "Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide new insights into the transformer architecture, and\nin particular, its best-known variant, BERT. First, we propose a method to\nmeasure the degree of non-linearity of different elements of transformers.\nNext, we focus our investigation on the feed-forward networks (FFN) inside\ntransformers, which contain 2/3 of the model parameters and have so far not\nreceived much attention. We find that FFNs are an inefficient yet important\narchitectural element and that they cannot simply be replaced by attention\nblocks without a degradation in performance. Moreover, we study the\ninteractions between layers in BERT and show that, while the layers exhibit\nsome hierarchical structure, they extract features in a fuzzy manner. Our\nresults suggest that BERT has an inductive bias towards layer commutativity,\nwhich we find is mainly due to the skip connections. This provides a\njustification for the strong performance of recurrent and weight-shared\ntransformer models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 15:29:38 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 09:58:42 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 10:23:01 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 07:38:46 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhao", "Sumu", ""], ["Pascual", "Damian", ""], ["Brunner", "Gino", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2101.04626", "submitter": "Stefan Cassar", "authors": "Stefan Cassar, Adrian Muscat, Dylan Seychell", "title": "Predicting Relative Depth between Objects from Semantic Features", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision and language tasks such as Visual Relation Detection and Visual\nQuestion Answering benefit from semantic features that afford proper grounding\nof language. The 3D depth of objects depicted in 2D images is one such feature.\nHowever it is very difficult to obtain accurate depth information without\nlearning the appropriate features, which are scene dependent. The state of the\nart in this area are complex Neural Network models trained on stereo image data\nto predict depth per pixel. Fortunately, in some tasks, its only the relative\ndepth between objects that is required. In this paper the extent to which\nsemantic features can predict course relative depth is investigated. The\nproblem is casted as a classification one and geometrical features based on\nobject bounding boxes, object labels and scene attributes are computed and used\nas inputs to pattern recognition models to predict relative depth. i.e behind,\nin-front and neutral. The results are compared to those obtained from averaging\nthe output of the monodepth neural network model, which represents the\nstate-of-the art. An overall increase of 14% in relative depth accuracy over\nrelative depth computed from the monodepth model derived results is achieved.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 17:28:23 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Cassar", "Stefan", ""], ["Muscat", "Adrian", ""], ["Seychell", "Dylan", ""]]}, {"id": "2101.04627", "submitter": "Majid Raeis", "authors": "Majid Raeis, Ali Tizghadam, Alberto Leon-Garcia", "title": "Queue-Learning: A Reinforcement Learning Approach for Providing Quality\n  of Service", "comments": "8 pages, Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end delay is a critical attribute of quality of service (QoS) in\napplication domains such as cloud computing and computer networks. This metric\nis particularly important in tandem service systems, where the end-to-end\nservice is provided through a chain of services. Service-rate control is a\ncommon mechanism for providing QoS guarantees in service systems. In this\npaper, we introduce a reinforcement learning-based (RL-based) service-rate\ncontroller that provides probabilistic upper-bounds on the end-to-end delay of\nthe system, while preventing the overuse of service resources. In order to have\na general framework, we use queueing theory to model the service systems.\nHowever, we adopt an RL-based approach to avoid the limitations of\nqueueing-theoretic methods. In particular, we use Deep Deterministic Policy\nGradient (DDPG) to learn the service rates (action) as a function of the queue\nlengths (state) in tandem service systems. In contrast to existing RL-based\nmethods that quantify their performance by the achieved overall reward, which\ncould be hard to interpret or even misleading, our proposed controller provides\nexplicit probabilistic guarantees on the end-to-end delay of the system. The\nevaluations are presented for a tandem queueing system with non-exponential\ninter-arrival and service times, the results of which validate our controller's\ncapability in meeting QoS constraints.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 17:28:57 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Raeis", "Majid", ""], ["Tizghadam", "Ali", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2101.04632", "submitter": "Fares Ben Slimane", "authors": "Fares Ben Slimane and Mohamed Bouguessa", "title": "Context Matters: Self-Attention for Sign Language Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an attentional network for the task of Continuous Sign\nLanguage Recognition. The proposed approach exploits co-independent streams of\ndata to model the sign language modalities. These different channels of\ninformation can share a complex temporal structure between each other. For that\nreason, we apply attention to synchronize and help capture entangled\ndependencies between the different sign language components. Even though Sign\nLanguage is multi-channel, handshapes represent the central entities in sign\ninterpretation. Seeing handshapes in their correct context defines the meaning\nof a sign. Taking that into account, we utilize the attention mechanism to\nefficiently aggregate the hand features with their appropriate spatio-temporal\ncontext for better sign recognition. We found that by doing so the model is\nable to identify the essential Sign Language components that revolve around the\ndominant hand and the face areas. We test our model on the benchmark dataset\nRWTH-PHOENIX-Weather 2014, yielding competitive results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 17:40:19 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Slimane", "Fares Ben", ""], ["Bouguessa", "Mohamed", ""]]}, {"id": "2101.04640", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Alessandro Oltramari, Kaixin Ma, Bin Zhang, Deborah L.\n  McGuinness, Pedro Szekely", "title": "Dimensions of Commonsense Knowledge", "comments": null, "journal-ref": "Knowledge-Based Systems 2021", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Commonsense knowledge is essential for many AI applications, including those\nin natural language processing, visual processing, and planning. Consequently,\nmany sources that include commonsense knowledge have been designed and\nconstructed over the past decades. Recently, the focus has been on large\ntext-based sources, which facilitate easier integration with neural (language)\nmodels and application to textual tasks, typically at the expense of the\nsemantics of the sources and their harmonization. Efforts to consolidate\ncommonsense knowledge have yielded partial success, with no clear path towards\na comprehensive solution. We aim to organize these sources around a common set\nof dimensions of commonsense knowledge. We survey a wide range of popular\ncommonsense sources with a special focus on their relations. We consolidate\nthese relations into 13 knowledge dimensions. This consolidation allows us to\nunify the separate sources and to compute indications of their coverage,\noverlap, and gaps with respect to the knowledge dimensions. Moreover, we\nanalyze the impact of each dimension on downstream reasoning tasks that require\ncommonsense knowledge, observing that the temporal and desire/goal dimensions\nare very beneficial for reasoning on current downstream tasks, while\ndistinctness and lexical knowledge have little impact. These results reveal\npreferences for some dimensions in current evaluation, and potential neglect of\nothers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 17:52:39 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 06:28:37 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ilievski", "Filip", ""], ["Oltramari", "Alessandro", ""], ["Ma", "Kaixin", ""], ["Zhang", "Bin", ""], ["McGuinness", "Deborah L.", ""], ["Szekely", "Pedro", ""]]}, {"id": "2101.04719", "submitter": "Upol Ehsan", "authors": "Upol Ehsan, Q. Vera Liao, Michael Muller, Mark O. Riedl, Justin D.\n  Weisz", "title": "Expanding Explainability: Towards Social Transparency in AI systems", "comments": "Accepted to CHI2021", "journal-ref": null, "doi": "10.1145/3411764.3445188", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As AI-powered systems increasingly mediate consequential decision-making,\ntheir explainability is critical for end-users to take informed and accountable\nactions. Explanations in human-human interactions are socially-situated. AI\nsystems are often socio-organizationally embedded. However, Explainable AI\n(XAI) approaches have been predominantly algorithm-centered. We take a\ndevelopmental step towards socially-situated XAI by introducing and exploring\nSocial Transparency (ST), a sociotechnically informed perspective that\nincorporates the socio-organizational context into explaining AI-mediated\ndecision-making. To explore ST conceptually, we conducted interviews with 29 AI\nusers and practitioners grounded in a speculative design scenario. We suggested\nconstitutive design elements of ST and developed a conceptual framework to\nunpack ST's effect and implications at the technical, decision-making, and\norganizational level. The framework showcases how ST can potentially calibrate\ntrust in AI, improve decision-making, facilitate organizational collective\nactions, and cultivate holistic explainability. Our work contributes to the\ndiscourse of Human-Centered XAI by expanding the design space of XAI.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 19:44:27 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Ehsan", "Upol", ""], ["Liao", "Q. Vera", ""], ["Muller", "Michael", ""], ["Riedl", "Mark O.", ""], ["Weisz", "Justin D.", ""]]}, {"id": "2101.04726", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger, Nariman Farsad, Yonina C. Eldar, and Andrea J.\n  Goldsmith", "title": "Model-Based Machine Learning for Communications", "comments": "arXiv admin note: text overlap with arXiv:2002.07806", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an introduction to model-based machine learning for communication\nsystems. We begin by reviewing existing strategies for combining model-based\nalgorithms and machine learning from a high level perspective, and compare them\nto the conventional deep learning approach which utilizes established deep\nneural network (DNN) architectures trained in an end-to-end manner. Then, we\nfocus on symbol detection, which is one of the fundamental tasks of\ncommunication receivers. We show how the different strategies of conventional\ndeep architectures, deep unfolding, and DNN-aided hybrid algorithms, can be\napplied to this problem. The last two approaches constitute a middle ground\nbetween purely model-based and solely DNN-based receivers. By focusing on this\nspecific task, we highlight the advantages and drawbacks of each strategy, and\npresent guidelines to facilitate the design of future model-based deep learning\nsystems for communications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 19:55:34 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Shlezinger", "Nir", ""], ["Farsad", "Nariman", ""], ["Eldar", "Yonina C.", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "2101.04727", "submitter": "Hossein Rajaby Faghihi", "authors": "Hossein Rajaby Faghihi, Roshanak Mirzaee, Sudarshan Paliwal, and\n  Parisa Kordjamshidi", "title": "Latent Alignment of Procedural Concepts in Multimodal Recipes", "comments": "Published in ALVR 2020, a workshop in ACL 2020", "journal-ref": "Proceedings of the First Workshop on Advances in Language and\n  Vision Research 2020 (26-31)", "doi": "10.18653/v1/2020.alvr-1.5", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel alignment mechanism to deal with procedural reasoning on a\nnewly released multimodal QA dataset, named RecipeQA. Our model is solving the\ntextual cloze task which is a reading comprehension on a recipe containing\nimages and instructions. We exploit the power of attention networks,\ncross-modal representations, and a latent alignment space between instructions\nand candidate answers to solve the problem. We introduce constrained\nmax-pooling which refines the max-pooling operation on the alignment matrix to\nimpose disjoint constraints among the outputs of the model. Our evaluation\nresult indicates a 19\\% improvement over the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 19:55:53 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Faghihi", "Hossein Rajaby", ""], ["Mirzaee", "Roshanak", ""], ["Paliwal", "Sudarshan", ""], ["Kordjamshidi", "Parisa", ""]]}, {"id": "2101.04731", "submitter": "Zhiyuan Fang", "authors": "Zhiyuan Fang, Jianfeng Wang, Lijuan Wang, Lei Zhang, Yezhou Yang,\n  Zicheng Liu", "title": "SEED: Self-supervised Distillation For Visual Representation", "comments": "Accepted as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned with self-supervised learning for small models. The\nproblem is motivated by our empirical studies that while the widely used\ncontrastive self-supervised learning method has shown great progress on large\nmodel training, it does not work well for small models. To address this\nproblem, we propose a new learning paradigm, named SElf-SupErvised Distillation\n(SEED), where we leverage a larger network (as Teacher) to transfer its\nrepresentational knowledge into a smaller architecture (as Student) in a\nself-supervised fashion. Instead of directly learning from unlabeled data, we\ntrain a student encoder to mimic the similarity score distribution inferred by\na teacher over a set of instances. We show that SEED dramatically boosts the\nperformance of small networks on downstream tasks. Compared with\nself-supervised baselines, SEED improves the top-1 accuracy from 42.2% to 67.6%\non EfficientNet-B0 and from 36.3% to 68.2% on MobileNet-v3-Large on the\nImageNet-1k dataset.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 20:04:50 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 22:16:01 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Fang", "Zhiyuan", ""], ["Wang", "Jianfeng", ""], ["Wang", "Lijuan", ""], ["Zhang", "Lei", ""], ["Yang", "Yezhou", ""], ["Liu", "Zicheng", ""]]}, {"id": "2101.04736", "submitter": "Ben Abbatematteo", "authors": "Ben Abbatematteo, Eric Rosen, Stefanie Tellex, George Konidaris", "title": "Bootstrapping Motor Skill Learning with Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning a robot motor skill from scratch is impractically slow; so much so\nthat in practice, learning must be bootstrapped using a good skill policy\nobtained from human demonstration. However, relying on human demonstration\nnecessarily degrades the autonomy of robots that must learn a wide variety of\nskills over their operational lifetimes. We propose using kinematic motion\nplanning as a completely autonomous, sample efficient way to bootstrap motor\nskill learning for object manipulation. We demonstrate the use of motion\nplanners to bootstrap motor skills in two complex object manipulation scenarios\nwith different policy representations: opening a drawer with a dynamic movement\nprimitive representation, and closing a microwave door with a deep neural\nnetwork policy. We also show how our method can bootstrap a motor skill for the\nchallenging dynamic task of learning to hit a ball off a tee, where a kinematic\nplan based on treating the scene as static is insufficient to solve the task,\nbut sufficient to bootstrap a more dynamic policy. In all three cases, our\nmethod is competitive with human-demonstrated initialization, and significantly\noutperforms starting with a random policy. This approach enables robots to to\nefficiently and autonomously learn motor policies for dynamic tasks without\nhuman demonstration.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 20:19:22 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Abbatematteo", "Ben", ""], ["Rosen", "Eric", ""], ["Tellex", "Stefanie", ""], ["Konidaris", "George", ""]]}, {"id": "2101.04750", "submitter": "Matt Peng", "authors": "Matt Peng, Banghua Zhu, Jiantao Jiao", "title": "Linear Representation Meta-Reinforcement Learning for Instant Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Fast Linearized Adaptive Policy (FLAP), a new\nmeta-reinforcement learning (meta-RL) method that is able to extrapolate well\nto out-of-distribution tasks without the need to reuse data from training, and\nadapt almost instantaneously with the need of only a few samples during\ntesting. FLAP builds upon the idea of learning a shared linear representation\nof the policy so that when adapting to a new task, it suffices to predict a set\nof linear weights. A separate adapter network is trained simultaneously with\nthe policy such that during adaptation, we can directly use the adapter network\nto predict these linear weights instead of updating a meta-policy via gradient\ndescent, such as in prior meta-RL methods like MAML, to obtain the new policy.\nThe application of the separate feed-forward network not only speeds up the\nadaptation run-time significantly, but also generalizes extremely well to very\ndifferent tasks that prior Meta-RL methods fail to generalize to. Experiments\non standard continuous-control meta-RL benchmarks show FLAP presenting\nsignificantly stronger performance on out-of-distribution tasks with up to\ndouble the average return and up to 8X faster adaptation run-time speeds when\ncompared to prior methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 20:56:34 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Peng", "Matt", ""], ["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""]]}, {"id": "2101.04758", "submitter": "Muhammad Khalifa", "authors": "Muhammad Khalifa and Muhammad Abdul-Mageed and Khaled Shaalan", "title": "Self-Training Pre-Trained Language Models for Zero- and Few-Shot\n  Multi-Dialectal Arabic Sequence Labeling", "comments": "Accepted at EACL 2021 (Camera Ready Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A sufficient amount of annotated data is usually required to fine-tune\npre-trained language models for downstream tasks. Unfortunately, attaining\nlabeled data can be costly, especially for multiple language varieties and\ndialects. We propose to self-train pre-trained language models in zero- and\nfew-shot scenarios to improve performance on data-scarce varieties using only\nresources from data-rich ones. We demonstrate the utility of our approach in\nthe context of Arabic sequence labeling by using a language model fine-tuned on\nModern Standard Arabic (MSA) only to predict named entities (NE) and\npart-of-speech (POS) tags on several dialectal Arabic (DA) varieties. We show\nthat self-training is indeed powerful, improving zero-shot MSA-to-DA transfer\nby as large as \\texttildelow 10\\% F$_1$ (NER) and 2\\% accuracy (POS tagging).\nWe acquire even better performance in few-shot scenarios with limited amounts\nof labeled data. We conduct an ablation study and show that the performance\nboost observed directly results from the unlabeled DA examples used for\nself-training. Our work opens up opportunities for developing DA models\nexploiting only MSA resources and it can be extended to other languages and\ntasks. Our code and fine-tuned models can be accessed at\nhttps://github.com/mohammadKhalifa/zero-shot-arabic-dialects.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 21:29:30 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 00:00:36 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 20:48:15 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 23:36:04 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Khalifa", "Muhammad", ""], ["Abdul-Mageed", "Muhammad", ""], ["Shaalan", "Khaled", ""]]}, {"id": "2101.04765", "submitter": "Erick Moreno-Centeno", "authors": "Dorit S. Hochbaum and Erick Moreno-Centeno", "title": "Joint aggregation of cardinal and ordinal evaluations with an\n  application to a student paper competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in decision theory concerns the aggregation of\nindividual rankings/ratings into a collective evaluation. We illustrate a new\naggregation method in the context of the 2007 MSOM's student paper competition.\nThe aggregation problem in this competition poses two challenges. Firstly, each\npaper was reviewed only by a very small fraction of the judges; thus the\naggregate evaluation is highly sensitive to the subjective scales chosen by the\njudges. Secondly, the judges provided both cardinal and ordinal evaluations\n(ratings and rankings) of the papers they reviewed. The contribution here is a\nnew robust methodology that jointly aggregates ordinal and cardinal evaluations\ninto a collective evaluation. This methodology is particularly suitable in\ncases of incomplete evaluations -- i.e., when the individuals evaluate only a\nstrict subset of the objects. This approach is potentially useful in managerial\ndecision making problems by a committee selecting projects from a large set or\ncapital budgeting involving multiple priorities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 21:36:50 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Hochbaum", "Dorit S.", ""], ["Moreno-Centeno", "Erick", ""]]}, {"id": "2101.04773", "submitter": "Yangyong Zhang", "authors": "Yangyong Zhang, Maliheh Shirvanian, Sunpreet S. Arora, Jianwei Huang,\n  and Guofei Gu", "title": "Practical Speech Re-use Prevention in Voice-driven Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CR eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Voice-driven services (VDS) are being used in a variety of applications\nranging from smart home control to payments using digital assistants. The input\nto such services is often captured via an open voice channel, e.g., using a\nmicrophone, in an unsupervised setting. One of the key operational security\nrequirements in such setting is the freshness of the input speech. We present\nAEOLUS, a security overlay that proactively embeds a dynamic acoustic nonce at\nthe time of user interaction, and detects the presence of the embedded nonce in\nthe recorded speech to ensure freshness. We demonstrate that acoustic nonce can\n(i) be reliably embedded and retrieved, and (ii) be non-disruptive (and even\nimperceptible) to a VDS user. Optimal parameters (acoustic nonce's operating\nfrequency, amplitude, and bitrate) are determined for (i) and (ii) from a\npractical perspective. Experimental results show that AEOLUS yields 0.5% FRR at\n0% FAR for speech re-use prevention upto a distance of 4 meters in three\nreal-world environments with different background noise levels. We also conduct\na user study with 120 participants, which shows that the acoustic nonce does\nnot degrade overall user experience for 94.16% of speech samples, on average,\nin these environments. AEOLUS can therefore be used in practice to prevent\nspeech re-use and ensure the freshness of speech input.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:00:59 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zhang", "Yangyong", ""], ["Shirvanian", "Maliheh", ""], ["Arora", "Sunpreet S.", ""], ["Huang", "Jianwei", ""], ["Gu", "Guofei", ""]]}, {"id": "2101.04775", "submitter": "Bingchen Liu", "authors": "Bingchen Liu, Yizhe Zhu, Kunpeng Song, Ahmed Elgammal", "title": "Towards Faster and Stabilized GAN Training for High-fidelity Few-shot\n  Image Synthesis", "comments": "ICLR-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Generative Adversarial Networks (GAN) on high-fidelity images\nusually requires large-scale GPU-clusters and a vast number of training images.\nIn this paper, we study the few-shot image synthesis task for GAN with minimum\ncomputing cost. We propose a light-weight GAN structure that gains superior\nquality on 1024*1024 resolution. Notably, the model converges from scratch with\njust a few hours of training on a single RTX-2080 GPU, and has a consistent\nperformance, even with less than 100 training samples. Two technique designs\nconstitute our work, a skip-layer channel-wise excitation module and a\nself-supervised discriminator trained as a feature-encoder. With thirteen\ndatasets covering a wide variety of image domains (The datasets and code are\navailable at: https://github.com/odegeasslbc/FastGAN-pytorch), we show our\nmodel's superior performance compared to the state-of-the-art StyleGAN2, when\ndata and computing budget are limited.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:02:54 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Liu", "Bingchen", ""], ["Zhu", "Yizhe", ""], ["Song", "Kunpeng", ""], ["Elgammal", "Ahmed", ""]]}, {"id": "2101.04781", "submitter": "Kilian Kleeberger", "authors": "Kilian Kleeberger and Markus V\\\"olk and Marius Moosmann and Erik\n  Thiessenhusen and Florian Roth and Richard Bormann and Marco F. Huber", "title": "Transferring Experience from Simulation to the Real World for Precise\n  Pick-And-Place Tasks in Highly Cluttered Scenes", "comments": "Accepted at 2020 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel learning-based approach for grasping\nknown rigid objects in highly cluttered scenes and precisely placing them based\non depth images. Our Placement Quality Network (PQ-Net) estimates the object\npose and the quality for each automatically generated grasp pose for multiple\nobjects simultaneously at 92 fps in a single forward pass of a neural network.\nAll grasping and placement trials are executed in a physics simulation and the\ngained experience is transferred to the real world using domain randomization.\nWe demonstrate that our policy successfully transfers to the real world. PQ-Net\noutperforms other model-free approaches in terms of grasping success rate and\nautomatically scales to new objects of arbitrary symmetry without any human\nintervention.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:16:47 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Kleeberger", "Kilian", ""], ["V\u00f6lk", "Markus", ""], ["Moosmann", "Marius", ""], ["Thiessenhusen", "Erik", ""], ["Roth", "Florian", ""], ["Bormann", "Richard", ""], ["Huber", "Marco F.", ""]]}, {"id": "2101.04788", "submitter": "Jayesh Gupta", "authors": "Shushman Choudhury, Jayesh K. Gupta, Peter Morales, Mykel J.\n  Kochenderfer", "title": "Scalable Anytime Planning for Multi-Agent MDPs", "comments": "First two authors contributed equally. Accepted at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable tree search planning algorithm for large multi-agent\nsequential decision problems that require dynamic collaboration. Teams of\nagents need to coordinate decisions in many domains, but naive approaches fail\ndue to the exponential growth of the joint action space with the number of\nagents. We circumvent this complexity through an anytime approach that allows\nus to trade computation for approximation quality and also dynamically\ncoordinate actions. Our algorithm comprises three elements: online planning\nwith Monte Carlo Tree Search (MCTS), factored representations of local agent\ninteractions with coordination graphs, and the iterative Max-Plus method for\njoint action selection. We evaluate our approach on the benchmark SysAdmin\ndomain with static coordination graphs and achieve comparable performance with\nmuch lower computation cost than our MCTS baselines. We also introduce a\nmulti-drone delivery domain with dynamic, i.e., state-dependent coordination\ngraphs, and demonstrate how our approach scales to large problems on this\ndomain that are intractable for other MCTS methods. We provide an open-source\nimplementation of our algorithm at\nhttps://github.com/JuliaPOMDP/FactoredValueMCTS.jl.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:50:17 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Choudhury", "Shushman", ""], ["Gupta", "Jayesh K.", ""], ["Morales", "Peter", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2101.04792", "submitter": "Nikolay Mikhaylovskiy", "authors": "Roman Vygon, Nikolay Mikhaylovskiy", "title": "Learning Efficient Representations for Keyword Spotting with Triplet\n  Loss", "comments": "Submitted to SPECOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, triplet loss-based metric embeddings have become a\nde-facto standard for several important computer vision problems, most\nno-tably, person reidentification. On the other hand, in the area of speech\nrecognition the metric embeddings generated by the triplet loss are rarely used\neven for classification problems. We fill this gap showing that a combination\nof two representation learning techniques: a triplet loss-based embedding and a\nvariant of kNN for classification instead of cross-entropy loss significantly\n(by 26% to 38%) improves the classification accuracy for convolutional networks\non a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel\nphonetic similarity based triplet mining approach. We also improve the current\nbest published SOTA for Google Speech Commands dataset V1 10+2 -class\nclassification by about 34%, achieving 98.55% accuracy, V2 10+2-class\nclassification by about 20%, achieving 98.37% accuracy, and V2 35-class\nclassification by over 50%, achieving 97.0% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:55:17 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 16:48:16 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 21:11:36 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 22:20:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Vygon", "Roman", ""], ["Mikhaylovskiy", "Nikolay", ""]]}, {"id": "2101.04817", "submitter": "Yongfeng Zhang", "authors": "Yunqi Li, Shuyuan Xu, Bo Liu, Zuohui Fu, Shuchang Liu, Xu Chen,\n  Yongfeng Zhang", "title": "Discrete Knowledge Graph Embedding based on Discrete Optimization", "comments": "Accepted at the AAAI-20 Workshop on Knowledge Discovery from\n  Unstructured Data in Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a discrete knowledge graph (KG) embedding (DKGE) method,\nwhich projects KG entities and relations into the Hamming space based on a\ncomputationally tractable discrete optimization algorithm, to solve the\nformidable storage and computation cost challenges in traditional continuous\ngraph embedding methods. The convergence of DKGE can be guaranteed\ntheoretically. Extensive experiments demonstrate that DKGE achieves superior\naccuracy than classical hashing functions that map the effective continuous\nembeddings into discrete codes. Besides, DKGE reaches comparable accuracy with\nmuch lower computational complexity and storage compared to many continuous\ngraph embedding methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 00:23:07 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Li", "Yunqi", ""], ["Xu", "Shuyuan", ""], ["Liu", "Bo", ""], ["Fu", "Zuohui", ""], ["Liu", "Shuchang", ""], ["Chen", "Xu", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2101.04840", "submitter": "Nazneen Fatema Rajani", "authors": "Karan Goel, Nazneen Rajani, Jesse Vig, Samson Tan, Jason Wu, Stephan\n  Zheng, Caiming Xiong, Mohit Bansal, Christopher R\\'e", "title": "Robustness Gym: Unifying the NLP Evaluation Landscape", "comments": "34 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance on standard benchmarks, deep neural networks\nare often brittle when deployed in real-world systems. Consequently, recent\nresearch has focused on testing the robustness of such models, resulting in a\ndiverse set of evaluation methodologies ranging from adversarial attacks to\nrule-based data transformations. In this work, we identify challenges with\nevaluating NLP systems and propose a solution in the form of Robustness Gym\n(RG), a simple and extensible evaluation toolkit that unifies 4 standard\nevaluation paradigms: subpopulations, transformations, evaluation sets, and\nadversarial attacks. By providing a common platform for evaluation, Robustness\nGym enables practitioners to compare results from all 4 evaluation paradigms\nwith just a few clicks, and to easily develop and share novel evaluation\nmethods using a built-in set of abstractions. To validate Robustness Gym's\nutility to practitioners, we conducted a real-world case study with a\nsentiment-modeling team, revealing performance degradations of 18%+. To verify\nthat Robustness Gym can aid novel research analyses, we perform the first study\nof state-of-the-art commercial and academic named entity linking (NEL) systems,\nas well as a fine-grained analysis of state-of-the-art summarization models.\nFor NEL, commercial systems struggle to link rare entities and lag their\nacademic counterparts by 10%+, while state-of-the-art summarization models\nstruggle on examples that require abstraction and distillation, degrading by\n9%+. Robustness Gym can be found at https://robustnessgym.com/\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 02:37:54 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Goel", "Karan", ""], ["Rajani", "Nazneen", ""], ["Vig", "Jesse", ""], ["Tan", "Samson", ""], ["Wu", "Jason", ""], ["Zheng", "Stephan", ""], ["Xiong", "Caiming", ""], ["Bansal", "Mohit", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2101.04869", "submitter": "Shengli Jiang", "authors": "Shengli Jiang and Victor M. Zavala", "title": "Convolutional Neural Nets in Chemical Engineering: Foundations,\n  Computations, and Applications", "comments": null, "journal-ref": "AIChE J. 2021; e17282", "doi": "10.1002/aic.17282", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we review the mathematical foundations of convolutional neural\nnets (CNNs) with the goals of: i) highlighting connections with techniques from\nstatistics, signal processing, linear algebra, differential equations, and\noptimization, ii) demystifying underlying computations, and iii) identifying\nnew types of applications. CNNs are powerful machine learning models that\nhighlight features from grid data to make predictions (regression and\nclassification). The grid data object can be represented as vectors (in 1D),\nmatrices (in 2D), or tensors (in 3D or higher dimensions) and can incorporate\nmultiple channels (thus providing high flexibility in the input data\nrepresentation). CNNs highlight features from the grid data by performing\nconvolution operations with different types of operators. The operators\nhighlight different types of features (e.g., patterns, gradients, geometrical\nfeatures) and are learned by using optimization techniques. In other words,\nCNNs seek to identify optimal operators that best map the input data to the\noutput data. A common misconception is that CNNs are only capable of processing\nimage or video data but their application scope is much wider; specifically,\ndatasets encountered in diverse applications can be expressed as grid data.\nHere, we show how to apply CNNs to new types of applications such as optimal\ncontrol, flow cytometry, multivariate process monitoring, and molecular\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 04:20:42 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 14:06:33 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Jiang", "Shengli", ""], ["Zavala", "Victor M.", ""]]}, {"id": "2101.04882", "submitter": "Lilian Weng", "authors": "OpenAI OpenAI, Matthias Plappert, Raul Sampedro, Tao Xu, Ilge Akkaya,\n  Vineet Kosaraju, Peter Welinder, Ruben D'Sa, Arthur Petron, Henrique P. d.O.\n  Pinto, Alex Paino, Hyeonwoo Noh, Lilian Weng, Qiming Yuan, Casey Chu,\n  Wojciech Zaremba", "title": "Asymmetric self-play for automatic goal discovery in robotic\n  manipulation", "comments": "Videos are shown at https://robotics-self-play.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a single, goal-conditioned policy that can solve many robotic\nmanipulation tasks, including tasks with previously unseen goals and objects.\nWe rely on asymmetric self-play for goal discovery, where two agents, Alice and\nBob, play a game. Alice is asked to propose challenging goals and Bob aims to\nsolve them. We show that this method can discover highly diverse and complex\ngoals without any human priors. Bob can be trained with only sparse rewards,\nbecause the interaction between Alice and Bob results in a natural curriculum\nand Bob can learn from Alice's trajectory when relabeled as a goal-conditioned\ndemonstration. Finally, our method scales, resulting in a single policy that\ncan generalize to many unseen tasks such as setting a table, stacking blocks,\nand solving simple puzzles. Videos of a learned policy is available at\nhttps://robotics-self-play.github.io.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 05:20:20 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["OpenAI", "OpenAI", ""], ["Plappert", "Matthias", ""], ["Sampedro", "Raul", ""], ["Xu", "Tao", ""], ["Akkaya", "Ilge", ""], ["Kosaraju", "Vineet", ""], ["Welinder", "Peter", ""], ["D'Sa", "Ruben", ""], ["Petron", "Arthur", ""], ["Pinto", "Henrique P. d. O.", ""], ["Paino", "Alex", ""], ["Noh", "Hyeonwoo", ""], ["Weng", "Lilian", ""], ["Yuan", "Qiming", ""], ["Chu", "Casey", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2101.04904", "submitter": "Ali Ayub", "authors": "Ali Ayub, Alan R. Wagner", "title": "EEC: Learning to Encode and Regenerate Images for Continual Learning", "comments": "Added link to the code in the paper. A preliminary version of this\n  work was presented at ICML 2020 Workshop on Lifelong Machine Learning:\n  arXiv:2007.06637", "journal-ref": "International Conference on Learning Representations (ICLR) 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The two main impediments to continual learning are catastrophic forgetting\nand memory limitations on the storage of data. To cope with these challenges,\nwe propose a novel, cognitively-inspired approach which trains autoencoders\nwith Neural Style Transfer to encode and store images. During training on a new\ntask, reconstructed images from encoded episodes are replayed in order to avoid\ncatastrophic forgetting. The loss function for the reconstructed images is\nweighted to reduce its effect during classifier training to cope with image\ndegradation. When the system runs out of memory the encoded episodes are\nconverted into centroids and covariance matrices, which are used to generate\npseudo-images during classifier training, keeping classifier performance stable\nwhile using less memory. Our approach increases classification accuracy by\n13-17% over state-of-the-art methods on benchmark datasets, while requiring 78%\nless storage space.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 06:43:10 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 09:16:24 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 05:05:05 GMT"}, {"version": "v4", "created": "Sun, 2 May 2021 05:45:03 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ayub", "Ali", ""], ["Wagner", "Alan R.", ""]]}, {"id": "2101.04921", "submitter": "Segwang Kim", "authors": "Segwang Kim, Hyoungwook Nam, Joonyoung Kim, Kyomin Jung", "title": "Neural Sequence-to-grid Module for Learning Symbolic Rules", "comments": "9 pages, 9 figures, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical reasoning tasks over symbols, such as learning arithmetic operations\nand computer program evaluations, have become challenges to deep learning. In\nparticular, even state-of-the-art neural networks fail to achieve\n\\textit{out-of-distribution} (OOD) generalization of symbolic reasoning tasks,\nwhereas humans can easily extend learned symbolic rules. To resolve this\ndifficulty, we propose a neural sequence-to-grid (seq2grid) module, an input\npreprocessor that automatically segments and aligns an input sequence into a\ngrid. As our module outputs a grid via a novel differentiable mapping, any\nneural network structure taking a grid input, such as ResNet or TextCNN, can be\njointly trained with our module in an end-to-end fashion. Extensive experiments\nshow that neural networks having our module as an input preprocessor achieve\nOOD generalization on various arithmetic and algorithmic problems including\nnumber sequence prediction problems, algebraic word problems, and computer\nprogram evaluation problems while other state-of-the-art sequence transduction\nmodels cannot. Moreover, we verify that our module enhances TextCNN to solve\nthe bAbI QA tasks without external memory.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 07:53:14 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 23:10:25 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kim", "Segwang", ""], ["Nam", "Hyoungwook", ""], ["Kim", "Joonyoung", ""], ["Jung", "Kyomin", ""]]}, {"id": "2101.04922", "submitter": "Mingyu Derek Ma", "authors": "Mingyu Derek Ma, Jiao Sun, Mu Yang, Kung-Hsiang Huang, Nuan Wen,\n  Shikhar Singh, Rujun Han and Nanyun Peng", "title": "EventPlus: A Temporal Event Understanding Pipeline", "comments": "To appear at NAACL 2021 (Demonstrations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present EventPlus, a temporal event understanding pipeline that integrates\nvarious state-of-the-art event understanding components including event trigger\nand type detection, event argument detection, event duration and temporal\nrelation extraction. Event information, especially event temporal knowledge, is\na type of common sense knowledge that helps people understand how stories\nevolve and provides predictive hints for future events. EventPlus as the first\ncomprehensive temporal event understanding pipeline provides a convenient tool\nfor users to quickly obtain annotations about events and their temporal\ninformation for any user-provided document. Furthermore, we show EventPlus can\nbe easily adapted to other domains (e.g., biomedical domain). We make EventPlus\npublicly available to facilitate event-related information extraction and\ndownstream applications.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 08:00:50 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 21:33:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ma", "Mingyu Derek", ""], ["Sun", "Jiao", ""], ["Yang", "Mu", ""], ["Huang", "Kung-Hsiang", ""], ["Wen", "Nuan", ""], ["Singh", "Shikhar", ""], ["Han", "Rujun", ""], ["Peng", "Nanyun", ""]]}, {"id": "2101.04930", "submitter": "Zhenpeng Chen", "authors": "Zhenpeng Chen and Huihan Yao and Yiling Lou and Yanbin Cao and\n  Yuanqiang Liu and Haoyu Wang and Xuanzhe Liu", "title": "An Empirical Study on Deployment Faults of Deep Learning Based Mobile\n  Applications", "comments": "Accepted by the 43rd International Conference on Software Engineering\n  (ICSE 2021). Please include ICSE in any citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) is finding its way into a growing number of mobile\nsoftware applications. These software applications, named as DL based mobile\napplications (abbreviated as mobile DL apps) integrate DL models trained using\nlarge-scale data with DL programs. A DL program encodes the structure of a\ndesirable DL model and the process by which the model is trained using training\ndata. Due to the increasing dependency of current mobile apps on DL, software\nengineering (SE) for mobile DL apps has become important. However, existing\nefforts in SE research community mainly focus on the development of DL models\nand extensively analyze faults in DL programs. In contrast, faults related to\nthe deployment of DL models on mobile devices (named as deployment faults of\nmobile DL apps) have not been well studied. Since mobile DL apps have been used\nby billions of end users daily for various purposes including for\nsafety-critical scenarios, characterizing their deployment faults is of\nenormous importance. To fill the knowledge gap, this paper presents the first\ncomprehensive study on the deployment faults of mobile DL apps. We identify 304\nreal deployment faults from Stack Overflow and GitHub, two commonly used data\nsources for studying software faults. Based on the identified faults, we\nconstruct a fine-granularity taxonomy consisting of 23 categories regarding to\nfault symptoms and distill common fix strategies for different fault types.\nFurthermore, we suggest actionable implications and research avenues that could\nfurther facilitate the deployment of DL models on mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 08:19:50 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 15:12:25 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chen", "Zhenpeng", ""], ["Yao", "Huihan", ""], ["Lou", "Yiling", ""], ["Cao", "Yanbin", ""], ["Liu", "Yuanqiang", ""], ["Wang", "Haoyu", ""], ["Liu", "Xuanzhe", ""]]}, {"id": "2101.05004", "submitter": "Lina Rojas-Barahona", "authors": "Lina M. Rojas-Barahona", "title": "Is the User Enjoying the Conversation? A Case Study on the Impact on the\n  Reward Function", "comments": "Accepted at the Human in the Loop Dialogue Systems, 34st Conference\n  on Neural Information Processing Systems (NeurIPS 2020). Paper updated with\n  minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of user satisfaction in policy learning task-oriented dialogue\nsystems has long been a subject of research interest. Most current models for\nestimating the user satisfaction either (i) treat out-of-context short-texts,\nsuch as product reviews, or (ii) rely on turn features instead of on\ndistributed semantic representations. In this work we adopt deep neural\nnetworks that use distributed semantic representation learning for estimating\nthe user satisfaction in conversations. We evaluate the impact of modelling\ncontext length in these networks. Moreover, we show that the proposed\nhierarchical network outperforms state-of-the-art quality estimators.\nFurthermore, we show that applying these networks to infer the reward function\nin a Partial Observable Markov Decision Process (POMDP) yields to a great\nimprovement in the task success rate.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 11:13:07 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Rojas-Barahona", "Lina M.", ""]]}, {"id": "2101.05014", "submitter": "Max W. Y. Lam", "authors": "Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu", "title": "Effective Low-Cost Time-Domain Audio Separation Using Globally Attentive\n  Locally Recurrent Networks", "comments": "Accepted in IEEE SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on the time-domain audio separation networks (TasNets) has\nbrought great success to speech separation. Nevertheless, conventional TasNets\nstruggle to satisfy the memory and latency constraints in industrial\napplications. In this regard, we design a low-cost high-performance\narchitecture, namely, globally attentive locally recurrent (GALR) network.\nAlike the dual-path RNN (DPRNN), we first split a feature sequence into 2D\nsegments and then process the sequence along both the intra- and inter-segment\ndimensions. Our main innovation lies in that, on top of features recurrently\nprocessed along the inter-segment dimensions, GALR applies a self-attention\nmechanism to the sequence along the inter-segment dimension, which aggregates\ncontext-aware information and also enables parallelization. Our experiments\nsuggest that GALR is a notably more effective network than the prior work. On\none hand, with only 1.5M parameters, it has achieved comparable separation\nperformance at a much lower cost with 36.1% less runtime memory and 49.4% fewer\ncomputational operations, relative to the DPRNN. On the other hand, in a\ncomparable model size with DPRNN, GALR has consistently outperformed DPRNN in\nthree datasets, in particular, with a substantial margin of 2.4dB absolute\nimprovement of SI-SNRi in the benchmark WSJ0-2mix task.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 11:30:14 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Lam", "Max W. Y.", ""], ["Wang", "Jun", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "2101.05043", "submitter": "David Fernandez-Llorca", "authors": "Mahdi Biparva, David Fern\\'andez-Llorca, Rub\\'en Izquierdo-Gonzalo,\n  John K. Tsotsos", "title": "Video action recognition for lane-change classification and prediction\n  of surrounding vehicles", "comments": "This work has been submitted to the IEEE Transactions on Intelligent\n  Transportation Systems. arXiv admin note: substantial text overlap with\n  arXiv:2008.10869", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In highway scenarios, an alert human driver will typically anticipate early\ncut-in/cut-out maneuvers of surrounding vehicles using visual cues mainly.\nAutonomous vehicles must anticipate these situations at an early stage too, to\nincrease their safety and efficiency. In this work, lane-change recognition and\nprediction tasks are posed as video action recognition problems. Up to four\ndifferent two-stream-based approaches, that have been successfully applied to\naddress human action recognition, are adapted here by stacking visual cues from\nforward-looking video cameras to recognize and anticipate lane-changes of\ntarget vehicles. We study the influence of context and observation horizons on\nperformance, and different prediction horizons are analyzed. The different\nmodels are trained and evaluated using the PREVENTION dataset. The obtained\nresults clearly demonstrate the potential of these methodologies to serve as\nrobust predictors of future lane-changes of surrounding vehicles proving an\naccuracy higher than 90% in time horizons of between 1-2 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 13:25:00 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Biparva", "Mahdi", ""], ["Fern\u00e1ndez-Llorca", "David", ""], ["Izquierdo-Gonzalo", "Rub\u00e9n", ""], ["Tsotsos", "John K.", ""]]}, {"id": "2101.05050", "submitter": "Stassa Patsantzis", "authors": "Stassa Patsantzis, Stephen H. Muggleton", "title": "Top Program Construction and Reduction for polynomial time\n  Meta-Interpretive Learning", "comments": "25 pages, 3 figures, to be published in Machine Learning Journal\n  Special Issue on Learning and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta-Interpretive Learners, like most ILP systems, learn by searching for a\ncorrect hypothesis in the hypothesis space, the powerset of all constructible\nclauses. We show how this exponentially-growing search can be replaced by the\nconstruction of a Top program: the set of clauses in all correct hypotheses\nthat is itself a correct hypothesis. We give an algorithm for Top program\nconstruction and show that it constructs a correct Top program in polynomial\ntime and from a finite number of examples. We implement our algorithm in Prolog\nas the basis of a new MIL system, Louise, that constructs a Top program and\nthen reduces it by removing redundant clauses. We compare Louise to the\nstate-of-the-art search-based MIL system Metagol in experiments on grid world\nnavigation, graph connectedness and grammar learning datasets and find that\nLouise improves on Metagol's predictive accuracy when the hypothesis space and\nthe target theory are both large, or when the hypothesis space does not include\na correct hypothesis because of \"classification noise\" in the form of\nmislabelled examples. When the hypothesis space or the target theory are small,\nLouise and Metagol perform equally well.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 13:39:21 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Patsantzis", "Stassa", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "2101.05077", "submitter": "Md Saiful Islam", "authors": "Manal, Ali Hasan Md. Linkon, Md. Mahir Labib, Marium-E-Jannat and Md\n  Saiful Islam", "title": "Restyling Images with the Bangladeshi Paintings Using Neural Style\n  Transfer: A Comprehensive Experiment, Evaluation, and Human Perspective", "comments": "6 pages", "journal-ref": "International Conference on Computer and Information Technology\n  (ICCIT), 19-21 December, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's world, Neural Style Transfer (NST) has become a trendsetting term.\nNST combines two pictures, a content picture and a reference image in style\n(such as the work of a renowned painter) in a way that makes the output image\nlook like an image of the material, but rendered with the form of a reference\npicture. However, there is no study using the artwork or painting of\nBangladeshi painters. Bangladeshi painting has a long history of more than two\nthousand years and is still being practiced by Bangladeshi painters. This study\ngenerates NST stylized image on Bangladeshi paintings and analyzes the human\npoint of view regarding the aesthetic preference of NST on Bangladeshi\npaintings. To assure our study's acceptance, we performed qualitative human\nevaluations on generated stylized images by 60 individual humans of different\nage and gender groups. We have explained how NST works for Bangladeshi\npaintings and assess NST algorithms, both qualitatively \\& quantitatively. Our\nstudy acts as a pre-requisite for the impact of NST stylized image using\nBangladeshi paintings on mobile UI/GUI and material translation from the human\nperspective. We hope that this study will encourage new collaborations to\ncreate more NST related studies and expand the use of Bangladeshi artworks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:22:51 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Manal", "", ""], ["Linkon", "Ali Hasan Md.", ""], ["Labib", "Md. Mahir", ""], ["Marium-E-Jannat", "", ""], ["Islam", "Md Saiful", ""]]}, {"id": "2101.05081", "submitter": "Md Saiful Islam", "authors": "Ali Hasan Md. Linkon, Md. Mahir Labib, Faisal Haque Bappy, Soumik\n  Sarker, Marium-E-Jannat and Md Saiful Islam", "title": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes", "comments": "4 pages", "journal-ref": "2020 11th International Conference on Electrical and Computer\n  Engineering (ICECE)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:36:41 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Linkon", "Ali Hasan Md.", ""], ["Labib", "Md. Mahir", ""], ["Bappy", "Faisal Haque", ""], ["Sarker", "Soumik", ""], ["Marium-E-Jannat", "", ""], ["Islam", "Md Saiful", ""]]}, {"id": "2101.05125", "submitter": "Stephen Clark", "authors": "Stephen Clark, Alexander Lerchner, Tamara von Glehn, Olivier Tieleman,\n  Richard Tanburn, Misha Dashevskiy, Matko Bosnjak", "title": "Formalising Concepts as Grounded Abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of concept has been studied for centuries, by philosophers,\nlinguists, cognitive scientists, and researchers in artificial intelligence\n(Margolis & Laurence, 1999). There is a large literature on formal,\nmathematical models of concepts, including a whole sub-field of AI -- Formal\nConcept Analysis -- devoted to this topic (Ganter & Obiedkov, 2016). Recently,\nresearchers in machine learning have begun to investigate how methods from\nrepresentation learning can be used to induce concepts from raw perceptual data\n(Higgins, Sonnerat, et al., 2018). The goal of this report is to provide a\nformal account of concepts which is compatible with this latest work in deep\nlearning.\n  The main technical goal of this report is to show how techniques from\nrepresentation learning can be married with a lattice-theoretic formulation of\nconceptual spaces. The mathematics of partial orders and lattices is a standard\ntool for modelling conceptual spaces (Ch.2, Mitchell (1997), Ganter and\nObiedkov (2016)); however, there is no formal work that we are aware of which\ndefines a conceptual lattice on top of a representation that is induced using\nunsupervised deep learning (Goodfellow et al., 2016). The advantages of\npartially-ordered lattice structures are that these provide natural mechanisms\nfor use in concept discovery algorithms, through the meets and joins of the\nlattice.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:22:01 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Clark", "Stephen", ""], ["Lerchner", "Alexander", ""], ["von Glehn", "Tamara", ""], ["Tieleman", "Olivier", ""], ["Tanburn", "Richard", ""], ["Dashevskiy", "Misha", ""], ["Bosnjak", "Matko", ""]]}, {"id": "2101.05136", "submitter": "Sara Mohammad Taheri Mrs", "authors": "Jeremy Zucker, Kaushal Paneri, Sara Mohammad-Taheri, Somya Bhargava,\n  Pallavi Kolambkar, Craig Bakker, Jeremy Teuton, Charles Tapley Hoyt, Kristie\n  Oxford, Robert Ness and Olga Vitek", "title": "Leveraging Structured Biological Knowledge for Counterfactual Inference:\n  a Case Study of Viral Pathogenesis", "comments": "In proceeding of IEEE, Transactions on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual inference is a useful tool for comparing outcomes of\ninterventions on complex systems. It requires us to represent the system in\nform of a structural causal model, complete with a causal diagram,\nprobabilistic assumptions on exogenous variables, and functional assignments.\nSpecifying such models can be extremely difficult in practice. The process\nrequires substantial domain expertise, and does not scale easily to large\nsystems, multiple systems, or novel system modifications. At the same time,\nmany application domains, such as molecular biology, are rich in structured\ncausal knowledge that is qualitative in nature. This manuscript proposes a\ngeneral approach for querying a causal biological knowledge graph, and\nconverting the qualitative result into a quantitative structural causal model\nthat can learn from data to answer the question. We demonstrate the\nfeasibility, accuracy and versatility of this approach using two case studies\nin systems biology. The first demonstrates the appropriateness of the\nunderlying assumptions and the accuracy of the results. The second demonstrates\nthe versatility of the approach by querying a knowledge base for the molecular\ndeterminants of a severe acute respiratory syndrome coronavirus 2\n(SARS-CoV-2)-induced cytokine storm, and performing counterfactual inference to\nestimate the causal effect of medical countermeasures for severely ill\npatients.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:32:17 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zucker", "Jeremy", ""], ["Paneri", "Kaushal", ""], ["Mohammad-Taheri", "Sara", ""], ["Bhargava", "Somya", ""], ["Kolambkar", "Pallavi", ""], ["Bakker", "Craig", ""], ["Teuton", "Jeremy", ""], ["Hoyt", "Charles Tapley", ""], ["Oxford", "Kristie", ""], ["Ness", "Robert", ""], ["Vitek", "Olga", ""]]}, {"id": "2101.05147", "submitter": "Niv Nayman", "authors": "Jian Tan, Niv Nayman, Mengchang Wang, Feifei Li, Rong Jin", "title": "CobBO: Coordinate Backoff Bayesian Optimization", "comments": "Jian Tan and Niv Nayman contributed equally. An implementation of\n  CobBO is available at: https://github.com/Alibaba-MIIL/CobBO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a popular method for optimizing expensive black-box\nfunctions. The objective functions of hard real world problems are oftentimes\ncharacterized by a fluctuated landscape of many local optima. Bayesian\noptimization risks in over-exploiting such traps, remaining with insufficient\nquery budget for exploring the global landscape. We introduce Coordinate\nBackoff Bayesian Optimization (CobBO) to alleviate those challenges. CobBO\ncaptures a smooth approximation of the global landscape by interpolating the\nvalues of queried points projected to randomly selected promising subspaces.\nThus also a smaller query budget is required for the Gaussian process\nregressions applied over the lower dimensional subspaces. This approach can be\nviewed as a variant of coordinate ascent, tailored for Bayesian optimization,\nusing a stopping rule for backing off from a certain subspace and switching to\nanother coordinate subset. Extensive evaluations show that CobBO finds\nsolutions comparable to or better than other state-of-the-art methods for\ndimensions ranging from tens to hundreds, while reducing the trial complexity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:39:32 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 10:18:57 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Tan", "Jian", ""], ["Nayman", "Niv", ""], ["Wang", "Mengchang", ""], ["Li", "Feifei", ""], ["Jin", "Rong", ""]]}, {"id": "2101.05151", "submitter": "Zhen Han", "authors": "Zifeng Ding, Zhen Han, Yunpu Ma, Volker Tresp", "title": "Temporal Knowledge Graph Forecasting with Neural ODE", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning node representation on dynamically-evolving, multi-relational graph\ndata has gained great research interest. However, most of the existing models\nfor temporal knowledge graph forecasting use Recurrent Neural Network (RNN)\nwith discrete depth to capture temporal information, while time is a continuous\nvariable. Inspired by Neural Ordinary Differential Equation (NODE), we extend\nthe idea of continuum-depth models to time-evolving multi-relational graph\ndata, and propose a novel Temporal Knowledge Graph Forecasting model with NODE.\nOur model captures temporal information through NODE and structural information\nthrough a Graph Neural Network (GNN). Thus, our graph ODE model achieves a\ncontinuous model in time and efficiently learns node representation for future\nprediction. We evaluate our model on six temporal knowledge graph datasets by\nperforming link forecasting. Experiment results show the superiority of our\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:49:48 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Ding", "Zifeng", ""], ["Han", "Zhen", ""], ["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "2101.05159", "submitter": "Yifan Zhou", "authors": "Yifan Zhou, Peng Zhang", "title": "Neuro-Reachability of Networked Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural ordinary differential equations network (ODE-Net)-enabled\nreachability method (Neuro-Reachability) is devised for the dynamic\nverification of networked microgrids (NMs) with unidentified subsystems and\nheterogeneous uncertainties. Three new contributions are presented: 1) An\nODENet-enabled dynamic model discovery approach is devised to construct the\ndata-driven state-space model which preserves the nonlinear and differential\nstructure of the NMs system; 2) A physics-data-integrated (PDI) NMs model is\nestablished, which empowers various NM analytics; and 3) A\nconformance-empowered reachability analysis is developed to enhance the\nreliability of the PDI-driven dynamic verification. Extensive case studies\ndemonstrate the efficacy of the ODE-Net-enabled method in microgrid dynamic\nmodel discovery, and the effectiveness of the Neuro-Reachability approach in\nverifying the NMs dynamics under multiple uncertainties and various operational\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:56:56 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zhou", "Yifan", ""], ["Zhang", "Peng", ""]]}, {"id": "2101.05208", "submitter": "Dexin Wang", "authors": "Dexin Wang and Deyi Xiong", "title": "Efficient Object-Level Visual Context Modeling for Multimodal Machine\n  Translation: Masking Irrelevant Objects Helps Grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual context provides grounding information for multimodal machine\ntranslation (MMT). However, previous MMT models and probing studies on visual\nfeatures suggest that visual information is less explored in MMT as it is often\nredundant to textual information. In this paper, we propose an object-level\nvisual context modeling framework (OVC) to efficiently capture and explore\nvisual information for multimodal machine translation. With detected objects,\nthe proposed OVC encourages MMT to ground translation on desirable visual\nobjects by masking irrelevant objects in the visual modality. We equip the\nproposed with an additional object-masking loss to achieve this goal. The\nobject-masking loss is estimated according to the similarity between masked\nobjects and the source texts so as to encourage masking source-irrelevant\nobjects. Additionally, in order to generate vision-consistent target words, we\nfurther propose a vision-weighted translation loss for OVC. Experiments on MMT\ndatasets demonstrate that the proposed OVC model outperforms state-of-the-art\nMMT models and analyses show that masking irrelevant objects helps grounding in\nMMT.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 11:10:00 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Wang", "Dexin", ""], ["Xiong", "Deyi", ""]]}, {"id": "2101.05265", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Marlos C. Machado, Pablo Samuel Castro, Marc G.\n  Bellemare", "title": "Contrastive Behavioral Similarity Embeddings for Generalization in\n  Reinforcement Learning", "comments": "ICLR 2021 (Spotlight). Website: https://agarwl.github.io/pse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning methods trained on few environments rarely learn\npolicies that generalize to unseen environments. To improve generalization, we\nincorporate the inherent sequential structure in reinforcement learning into\nthe representation learning process. This approach is orthogonal to recent\napproaches, which rarely exploit this structure explicitly. Specifically, we\nintroduce a theoretically motivated policy similarity metric (PSM) for\nmeasuring behavioral similarity between states. PSM assigns high similarity to\nstates for which the optimal policies in those states as well as in future\nstates are similar. We also present a contrastive representation learning\nprocedure to embed any state similarity metric, which we instantiate with PSM\nto obtain policy similarity embeddings (PSEs). We demonstrate that PSEs improve\ngeneralization on diverse benchmarks, including LQR with spurious correlations,\na jumping task from pixels, and Distracting DM Control Suite.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 18:55:43 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 13:58:01 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Machado", "Marlos C.", ""], ["Castro", "Pablo Samuel", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2101.05303", "submitter": "Han Liu", "authors": "Han Liu, Vivian Lai, Chenhao Tan", "title": "Understanding the Effect of Out-of-distribution Examples and Interactive\n  Explanations on Human-AI Decision Making", "comments": "43 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although AI holds promise for improving human decision making in societally\ncritical domains, it remains an open question how human-AI teams can reliably\noutperform AI alone and human alone in challenging prediction tasks (also known\nas complementary performance). We explore two directions to understand the gaps\nin achieving complementary performance. First, we argue that the typical\nexperimental setup limits the potential of human-AI teams. To account for lower\nAI performance out-of-distribution than in-distribution because of distribution\nshift, we design experiments with different distribution types and investigate\nhuman performance for both in-distribution and out-of-distribution examples.\nSecond, we develop novel interfaces to support interactive explanations so that\nhumans can actively engage with AI assistance. Using virtual pilot studies and\nlarge-scale randomized experiments across three tasks, we demonstrate a clear\ndifference between in-distribution and out-of-distribution, and observe mixed\nresults for interactive explanations: while interactive explanations improve\nhuman perception of AI assistance's usefulness, they may reinforce human biases\nand lead to limited performance improvement. Overall, our work points out\ncritical challenges and future directions towards enhancing human performance\nwith AI assistance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 19:01:32 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 19:02:32 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 18:00:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Liu", "Han", ""], ["Lai", "Vivian", ""], ["Tan", "Chenhao", ""]]}, {"id": "2101.05307", "submitter": "Eloi Zablocki", "authors": "\\'Eloi Zablocki, H\\'edi Ben-Younes, Patrick P\\'erez, Matthieu Cord", "title": "Explainability of vision-based autonomous driving systems: Review and\n  challenges", "comments": "submitted to IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This survey reviews explainability methods for vision-based self-driving\nsystems. The concept of explainability has several facets and the need for\nexplainability is strong in driving, a safety-critical application. Gathering\ncontributions from several research fields, namely computer vision, deep\nlearning, autonomous driving, explainable AI (X-AI), this survey tackles\nseveral points. First, it discusses definitions, context, and motivation for\ngaining more interpretability and explainability from self-driving systems.\nSecond, major recent state-of-the-art approaches to develop self-driving\nsystems are quickly presented. Third, methods providing explanations to a\nblack-box self-driving system in a post-hoc fashion are comprehensively\norganized and detailed. Fourth, approaches from the literature that aim at\nbuilding more interpretable self-driving systems by design are presented and\ndiscussed in detail. Finally, remaining open-challenges and potential future\nresearch directions are identified and examined.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 19:09:38 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Zablocki", "\u00c9loi", ""], ["Ben-Younes", "H\u00e9di", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "2101.05339", "submitter": "Tian Xie", "authors": "Tian Xie, Arthur France-Lanord, Yanming Wang, Jeffrey Lopez, Michael\n  Austin Stolberg, Megan Hill, Graham Michael Leverick, Rafael\n  Gomez-Bombarelli, Jeremiah A. Johnson, Yang Shao-Horn, Jeffrey C. Grossman", "title": "Accelerating the screening of amorphous polymer electrolytes by learning\n  to reduce random and systematic errors in molecular dynamics simulations", "comments": "25 pages, 5 figures + supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been widely adopted to accelerate the screening of\nmaterials. Most existing studies implicitly assume that the training data are\ngenerated through a deterministic, unbiased process, but this assumption might\nnot hold for the simulation of some complex materials. In this work, we aim to\nscreen amorphous polymer electrolytes which are promising candidates for the\nnext generation lithium-ion battery technology but extremely expensive to\nsimulate due to their structural complexity. We demonstrate that a multi-task\ngraph neural network can learn from a large amount of noisy, biased data and a\nsmall number of unbiased data and reduce both random and systematic errors in\npredicting the transport properties of polymer electrolytes. This observation\nallows us to achieve accurate predictions on the properties of complex\nmaterials by learning to reduce errors in the training data, instead of running\nrepetitive, expensive simulations which is conventionally used to reduce\nsimulation errors. With this approach, we screen a space of 6247 polymer\nelectrolytes, orders of magnitude larger than previous computational studies.\nWe also find a good extrapolation performance to the top polymers from a larger\nspace of 53362 polymers and 31 experimentally-realized polymers. The strategy\nemployed in this work may be applicable to a broad class of material discovery\nproblems that involve the simulation of complex, amorphous materials.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 20:46:24 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Xie", "Tian", ""], ["France-Lanord", "Arthur", ""], ["Wang", "Yanming", ""], ["Lopez", "Jeffrey", ""], ["Stolberg", "Michael Austin", ""], ["Hill", "Megan", ""], ["Leverick", "Graham Michael", ""], ["Gomez-Bombarelli", "Rafael", ""], ["Johnson", "Jeremiah A.", ""], ["Shao-Horn", "Yang", ""], ["Grossman", "Jeffrey C.", ""]]}, {"id": "2101.05360", "submitter": "Melanie F. Pradier", "authors": "Melanie F. Pradier, Javier Zazo, Sonali Parbhoo, Roy H. Perlis,\n  Maurizio Zazzi, Finale Doshi-Velez", "title": "Preferential Mixture-of-Experts: Interpretable Models that Rely on Human\n  Expertise as much as Possible", "comments": "10 pages, 5 figures, 4 tables, AMIA 2021 Virtual Informatics Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Preferential MoE, a novel human-ML mixture-of-experts model that\naugments human expertise in decision making with a data-based classifier only\nwhen necessary for predictive performance. Our model exhibits an interpretable\ngating function that provides information on when human rules should be\nfollowed or avoided. The gating function is maximized for using human-based\nrules, and classification errors are minimized. We propose solving a coupled\nmulti-objective problem with convex subproblems. We develop approximate\nalgorithms and study their performance and convergence. Finally, we demonstrate\nthe utility of Preferential MoE on two clinical applications for the treatment\nof Human Immunodeficiency Virus (HIV) and management of Major Depressive\nDisorder (MDD).\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 21:57:00 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Pradier", "Melanie F.", ""], ["Zazo", "Javier", ""], ["Parbhoo", "Sonali", ""], ["Perlis", "Roy H.", ""], ["Zazzi", "Maurizio", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2101.05400", "submitter": "Manuel Ciosici", "authors": "Manuel R. Ciosici, Joseph Cummings, Mitchell DeHaven, Alex Hedges,\n  Yash Kankanampati, Dong-Ho Lee, Ralph Weischedel, Marjorie Freedman", "title": "Machine-Assisted Script Curation", "comments": "Identical to the NAACL 2021 Demo version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We describe Machine-Aided Script Curator (MASC), a system for human-machine\ncollaborative script authoring. Scripts produced with MASC include (1) English\ndescriptions of sub-events that comprise a larger, complex event; (2) event\ntypes for each of those events; (3) a record of entities expected to\nparticipate in multiple sub-events; and (4) temporal sequencing between the\nsub-events. MASC automates portions of the script creation process with\nsuggestions for event types, links to Wikidata, and sub-events that may have\nbeen forgotten. We illustrate how these automations are useful to the script\nwriter with a few case-study scripts.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 00:19:21 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 16:33:01 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ciosici", "Manuel R.", ""], ["Cummings", "Joseph", ""], ["DeHaven", "Mitchell", ""], ["Hedges", "Alex", ""], ["Kankanampati", "Yash", ""], ["Lee", "Dong-Ho", ""], ["Weischedel", "Ralph", ""], ["Freedman", "Marjorie", ""]]}, {"id": "2101.05418", "submitter": "EPTCS", "authors": "Luc Jaulin (Robex, Lab-STICC), Beno\\^it Desrochers (DGA-TN)", "title": "Enclosing the Sliding Surfaces of a Controlled Swing", "comments": "In Proceedings SNR 2020, arXiv:2101.05256", "journal-ref": "EPTCS 331, 2021, pp. 43-55", "doi": "10.4204/EPTCS.331.4", "report-no": null, "categories": "cs.RO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When implementing a non-continuous controller for a cyber-physical system, it\nmay happen that the evolution of the closed-loop system is not anymore\npiecewise differentiable along the trajectory, mainly due to conditional\nstatements inside the controller. This may lead to some unwanted chattering\neffects than may damage the system. This behavior is difficult to observe even\nin simulation. In this paper, we propose an interval approach to characterize\nthe sliding surface which corresponds to the set of all states such that the\nstate trajectory may jump indefinitely between two distinct behaviors. We show\nthat the recent notion of thick sets will allows us to compute efficiently an\nouter approximation of the sliding surface of a given class of hybrid system\ntaking into account all set-membership uncertainties. An application to the\nverification of the controller of a child swing is considered to illustrate the\nprinciple of the approach.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 01:58:15 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Jaulin", "Luc", "", "Robex, Lab-STICC"], ["Desrochers", "Beno\u00eet", "", "DGA-TN"]]}, {"id": "2101.05436", "submitter": "Zengyi Qin", "authors": "Zengyi Qin, Kaiqing Zhang, Yuxiao Chen, Jingkai Chen, Chuchu Fan", "title": "Learning Safe Multi-Agent Control with Decentralized Neural Barrier\n  Certificates", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-agent safe control problem where agents should avoid\ncollisions to static obstacles and collisions with each other while reaching\ntheir goals. Our core idea is to learn the multi-agent control policy jointly\nwith learning the control barrier functions as safety certificates. We propose\na novel joint-learning framework that can be implemented in a decentralized\nfashion, with generalization guarantees for certain function classes. Such a\ndecentralized framework can adapt to an arbitrarily large number of agents.\nBuilding upon this framework, we further improve the scalability by\nincorporating neural network architectures that are invariant to the quantity\nand permutation of neighboring agents. In addition, we propose a new\nspontaneous policy refinement method to further enforce the certificate\ncondition during testing. We provide extensive experiments to demonstrate that\nour method significantly outperforms other leading multi-agent control\napproaches in terms of maintaining safety and completing original tasks. Our\napproach also shows exceptional generalization capability in that the control\npolicy can be trained with 8 agents in one scenario, while being used on other\nscenarios with up to 1024 agents in complex multi-agent environments and\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 03:17:17 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 15:47:04 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 11:29:46 GMT"}, {"version": "v4", "created": "Sat, 17 Apr 2021 05:34:12 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Qin", "Zengyi", ""], ["Zhang", "Kaiqing", ""], ["Chen", "Yuxiao", ""], ["Chen", "Jingkai", ""], ["Fan", "Chuchu", ""]]}, {"id": "2101.05486", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren, Jiyang Bai, and Jiawei Zhang", "title": "Label Contrastive Coding based Graph Neural Network for Graph\n  Classification", "comments": "Accept by DASFAA'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a critical research problem in many applications from\ndifferent domains. In order to learn a graph classification model, the most\nwidely used supervision component is an output layer together with\nclassification loss (e.g.,cross-entropy loss together with softmax or margin\nloss). In fact, the discriminative information among instances are more\nfine-grained, which can benefit graph classification tasks. In this paper, we\npropose the novel Label Contrastive Coding based Graph Neural Network (LCGNN)\nto utilize label information more effectively and comprehensively. LCGNN still\nuses the classification loss to ensure the discriminability of classes.\nMeanwhile, LCGNN leverages the proposed Label Contrastive Loss derived from\nself-supervised learning to encourage instance-level intra-class compactness\nand inter-class separability. To power the contrastive learning, LCGNN\nintroduces a dynamic label memory bank and a momentum updated encoder. Our\nextensive evaluations with eight benchmark graph datasets demonstrate that\nLCGNN can outperform state-of-the-art graph classification models. Experimental\nresults also verify that LCGNN can achieve competitive performance with less\ntraining data because LCGNN exploits label information comprehensively.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 07:45:55 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Ren", "Yuxiang", ""], ["Bai", "Jiyang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "2101.05490", "submitter": "Fengxiang He", "authors": "Fengxiang He, Shiye Lei, Jianmin Ji, Dacheng Tao", "title": "Neural networks behave as hash encoders: An empirical study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input space of a neural network with ReLU-like activations is partitioned\ninto multiple linear regions, each corresponding to a specific activation\npattern of the included ReLU-like activations. We demonstrate that this\npartition exhibits the following encoding properties across a variety of deep\nlearning models: (1) {\\it determinism}: almost every linear region contains at\nmost one training example. We can therefore represent almost every training\nexample by a unique activation pattern, which is parameterized by a {\\it neural\ncode}; and (2) {\\it categorization}: according to the neural code, simple\nalgorithms, such as $K$-Means, $K$-NN, and logistic regression, can achieve\nfairly good performance on both training and test data. These encoding\nproperties surprisingly suggest that {\\it normal neural networks well-trained\nfor classification behave as hash encoders without any extra efforts.} In\naddition, the encoding properties exhibit variability in different scenarios.\n{Further experiments demonstrate that {\\it model size}, {\\it training time},\n{\\it training sample size}, {\\it regularization}, and {\\it label noise}\ncontribute in shaping the encoding properties, while the impacts of the first\nthree are dominant.} We then define an {\\it activation hash phase chart} to\nrepresent the space expanded by {model size}, training time, training sample\nsize, and the encoding properties, which is divided into three canonical\nregions: {\\it under-expressive regime}, {\\it critically-expressive regime}, and\n{\\it sufficiently-expressive regime}. The source code package is available at\n\\url{https://github.com/LeavesLei/activation-code}.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 07:50:40 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["He", "Fengxiang", ""], ["Lei", "Shiye", ""], ["Ji", "Jianmin", ""], ["Tao", "Dacheng", ""]]}, {"id": "2101.05507", "submitter": "Paul Knott PhD MPhys BSc", "authors": "Paul Knott, Micah Carroll, Sam Devlin, Kamil Ciosek, Katja Hofmann, A.\n  D. Dragan and Rohin Shah", "title": "Evaluating the Robustness of Collaborative Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for agents trained by deep reinforcement learning to work alongside\nhumans in realistic settings, we will need to ensure that the agents are\n\\emph{robust}. Since the real world is very diverse, and human behavior often\nchanges in response to agent deployment, the agent will likely encounter novel\nsituations that have never been seen during training. This results in an\nevaluation challenge: if we cannot rely on the average training or validation\nreward as a metric, then how can we effectively evaluate robustness? We take\ninspiration from the practice of \\emph{unit testing} in software engineering.\nSpecifically, we suggest that when designing AI agents that collaborate with\nhumans, designers should search for potential edge cases in \\emph{possible\npartner behavior} and \\emph{possible states encountered}, and write tests which\ncheck that the behavior of the agent in these edge cases is reasonable. We\napply this methodology to build a suite of unit tests for the Overcooked-AI\nenvironment, and use this test suite to evaluate three proposals for improving\nrobustness. We find that the test suite provides significant insight into the\neffects of these proposals that were generally not revealed by looking solely\nat the average validation reward.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 09:02:45 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Knott", "Paul", ""], ["Carroll", "Micah", ""], ["Devlin", "Sam", ""], ["Ciosek", "Kamil", ""], ["Hofmann", "Katja", ""], ["Dragan", "A. D.", ""], ["Shah", "Rohin", ""]]}, {"id": "2101.05509", "submitter": "Ben Chen", "authors": "Ben Chen, Bin Chen, Dehong Gao, Qijin Chen, Chengfu Huo, Xiaonan Meng,\n  Weijun Ren, Yang Zhou", "title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection", "comments": "9 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 09:05:42 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:53:22 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chen", "Ben", ""], ["Chen", "Bin", ""], ["Gao", "Dehong", ""], ["Chen", "Qijin", ""], ["Huo", "Chengfu", ""], ["Meng", "Xiaonan", ""], ["Ren", "Weijun", ""], ["Zhou", "Yang", ""]]}, {"id": "2101.05537", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Federico Califano, Jinkyoo Park,\n  Atsushi Yamashita and Hajime Asama", "title": "Optimal Energy Shaping via Neural Approximators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.NE cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce optimal energy shaping as an enhancement of classical\npassivity-based control methods. A promising feature of passivity theory,\nalongside stability, has traditionally been claimed to be intuitive performance\ntuning along the execution of a given task. However, a systematic approach to\nadjust performance within a passive control framework has yet to be developed,\nas each method relies on few and problem-specific practical insights. Here, we\ncast the classic energy-shaping control design process in an optimal control\nframework; once a task-dependent performance metric is defined, an optimal\nsolution is systematically obtained through an iterative procedure relying on\nneural networks and gradient-based optimization. The proposed method is\nvalidated on state-regulation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 10:25:58 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Califano", "Federico", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "2101.05555", "submitter": "Stefanos Nikolopoulos", "authors": "Stefanos Nikolopoulos, Ioannis Kalogeris, Vissarion Papadopoulos", "title": "Non-intrusive Surrogate Modeling for Parametrized Time-dependent PDEs\n  using Convolutional Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a non-intrusive surrogate modeling scheme based on machine\nlearning technology for predictive modeling of complex systems, described by\nparametrized time-dependent PDEs. For these problems, typical finite element\napproaches involve the spatiotemporal discretization of the PDE and the\nsolution of the corresponding linear system of equations at each time step.\nInstead, the proposed method utilizes a convolutional autoencoder in\nconjunction with a feed forward neural network to establish a low-cost and\naccurate mapping from the problem's parametric space to its solution space. For\nthis purpose, time history response data are collected by solving the\nhigh-fidelity model via FEM for a reduced set of parameter values. Then, by\napplying the convolutional autoencoder to this data set, a low-dimensional\nrepresentation of the high-dimensional solution matrices is provided by the\nencoder, while the reconstruction map is obtained by the decoder. Using the\nlatent representation given by the encoder, a feed-forward neural network is\nefficiently trained to map points from the problem's parametric space to the\ncompressed version of the respective solution matrices. This way, the encoded\nresponse of the system at new parameter values is given by the neural network,\nwhile the entire response is delivered by the decoder. This approach\neffectively bypasses the need to serially formulate and solve the system's\ngoverning equations at each time increment, thus resulting in a significant\ncost reduction and rendering the method ideal for problems requiring repeated\nmodel evaluations or 'real-time' computations. The elaborated methodology is\ndemonstrated on the stochastic analysis of time-dependent PDEs solved with the\nMonte Carlo method, however, it can be straightforwardly applied to other\nsimilar-type problems, such as sensitivity analysis, design optimization, etc.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 11:34:58 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 09:53:13 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Nikolopoulos", "Stefanos", ""], ["Kalogeris", "Ioannis", ""], ["Papadopoulos", "Vissarion", ""]]}, {"id": "2101.05611", "submitter": "Guangneng Hu", "authors": "Guangneng Hu, Qiang Yang", "title": "TrNews: Heterogeneous User-Interest Transfer Learning for News\n  Recommendation", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate how to solve the cross-corpus news recommendation for unseen\nusers in the future. This is a problem where traditional content-based\nrecommendation techniques often fail. Luckily, in real-world recommendation\nservices, some publisher (e.g., Daily news) may have accumulated a large corpus\nwith lots of consumers which can be used for a newly deployed publisher (e.g.,\nPolitical news). To take advantage of the existing corpus, we propose a\ntransfer learning model (dubbed as TrNews) for news recommendation to transfer\nthe knowledge from a source corpus to a target corpus. To tackle the\nheterogeneity of different user interests and of different word distributions\nacross corpora, we design a translator-based transfer-learning strategy to\nlearn a representation mapping between source and target corpora. The learned\ntranslator can be used to generate representations for unseen users in the\nfuture. We show through experiments on real-world datasets that TrNews is\nbetter than various baselines in terms of four metrics. We also show that our\ntranslator is effective among existing transfer strategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 13:52:53 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 06:31:04 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Hu", "Guangneng", ""], ["Yang", "Qiang", ""]]}, {"id": "2101.05633", "submitter": "Byungryul Choi", "authors": "Byungryul Choi", "title": "Enhanced Audit Techniques Empowered by the Reinforcement Learning\n  Pertaining to IFRS 16 Lease", "comments": "for codes, please refer to\n  https://github.com/BryanBYChoi/Reinforcement_Learning_IFRS16_Lease", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of accounting audit is to have clear understanding on the\nfinancial activities of a company, which can be enhanced by machine learning or\nreinforcement learning as numeric analysis better than manual analysis can be\nmade. For the purpose of assessment on the relevance, completeness and accuracy\nof the information produced by entity pertaining to the newly implemented\nInternational Financial Reporting Standard 16 Lease (IFRS 16) is one of such\ncandidates as its characteristic of requiring the understanding on the nature\nof contracts and its complete analysis from listing up without omission, which\ncan be enhanced by the digitalization of contracts for the purpose of creating\nthe lists, still leaving the need of auditing cash flows of companies for the\npossible omission due to the potential error at the stage of data collection,\nespecially for entities with various short or middle term business sites and\nrelated leases, such as construction entities.\n  The implementation of the reinforcement learning and its well-known code is\nto be made for the purpose of drawing the possibility and utilizability of\ninterpreters from domain knowledge to numerical system, also can be called\n'gamification interpreter' or 'numericalization interpreter' which can be\nreferred or compared to the extrapolation with nondimensional numbers, such as\nFroude Number, in physics, which was a source of inspiration at this study.\nStudies on the interpreters can be able to empower the utilizability of\nartificial general intelligence in domain and commercial area.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 14:44:37 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Choi", "Byungryul", ""]]}, {"id": "2101.05677", "submitter": "Ashwin Misra", "authors": "Ashwin Misra, Ankit Mittal, Vihaan Misra and Deepanshu Pandey", "title": "Improving non-deterministic uncertainty modelling in Industry 4.0\n  scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The latest Industrial revolution has helped industries in achieving very high\nrates of productivity and efficiency. It has introduced data aggregation and\ncyber-physical systems to optimize planning and scheduling. Although,\nuncertainty in the environment and the imprecise nature of human operators are\nnot accurately considered for into the decision making process. This leads to\ndelays in consignments and imprecise budget estimations. This widespread\npractice in the industrial models is flawed and requires rectification. Various\nother articles have approached to solve this problem through stochastic or\nfuzzy set model methods. This paper presents a comprehensive method to\nlogically and realistically quantify the non-deterministic uncertainty through\nprobabilistic uncertainty modelling. This method is applicable on virtually all\nIndustrial data sets, as the model is self adjusting and uses\nepsilon-contamination to cater to limited or incomplete data sets. The results\nare numerically validated through an Industrial data set in Flanders, Belgium.\nThe data driven results achieved through this robust scheduling method\nillustrate the improvement in performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 23:17:55 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Misra", "Ashwin", ""], ["Mittal", "Ankit", ""], ["Misra", "Vihaan", ""], ["Pandey", "Deepanshu", ""]]}, {"id": "2101.05700", "submitter": "Marin Lujak", "authors": "Marin Lujak and Alberto Fern\\'andez and Eva Onaindia", "title": "Spillover Algorithm: A Decentralized Coordination Approach for\n  Multi-Robot Production Planning in Open Shared Factories", "comments": null, "journal-ref": null, "doi": "10.1016/j.rcim.2020.102110", "report-no": null, "categories": "cs.RO cs.AI cs.DM cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Open and shared manufacturing factories typically dispose of a limited number\nof robots that should be properly allocated to tasks in time and space for an\neffective and efficient system performance. In particular, we deal with the\ndynamic capacitated production planning problem with sequence independent setup\ncosts where quantities of products to manufacture and location of robots need\nto be determined at consecutive periods within a given time horizon and\nproducts can be anticipated or backordered related to the demand period. We\nconsider a decentralized multi-agent variant of this problem in an open factory\nsetting with multiple owners of robots as well as different owners of the items\nto be produced, both considered self-interested and individually rational.\nExisting solution approaches to the classic constrained lot-sizing problem are\ncentralized exact methods that require sharing of global knowledge of all the\nparticipants' private and sensitive information and are not applicable in the\ndescribed multi-agent context. Therefore, we propose a computationally\nefficient decentralized approach based on the spillover effect that solves this\nNP-hard problem by distributing decisions in an intrinsically decentralized\nmulti-agent system environment while protecting private and sensitive\ninformation. To the best of our knowledge, this is the first decentralized\nalgorithm for the solution of the studied problem in intrinsically\ndecentralized environments where production resources and/or products are owned\nby multiple stakeholders with possibly conflicting objectives. To show its\nefficiency, the performance of the Spillover Algorithm is benchmarked against\nstate-of-the-art commercial solver CPLEX 12.8.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 16:23:45 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 18:40:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Lujak", "Marin", ""], ["Fern\u00e1ndez", "Alberto", ""], ["Onaindia", "Eva", ""]]}, {"id": "2101.05718", "submitter": "Luiz Rodrigues", "authors": "Luiz Rodrigues, Armando M. Toda, Wilk Oliveira, Paula T. Palomino,\n  Julita Vassileva, Seiji Isotani", "title": "Automating Gamification Personalization: To the User and Beyond", "comments": "Submitted to IEEE Transactions on Learning Technologies. 14 pages, 2\n  figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personalized gamification explores knowledge about the users to tailor\ngamification designs to improve one-size-fits-all gamification. The tailoring\nprocess should simultaneously consider user and contextual characteristics\n(e.g., activity to be done and geographic location), which leads to several\noccasions to tailor. Consequently, tools for automating gamification\npersonalization are needed. The problems that emerge are that which of those\ncharacteristics are relevant and how to do such tailoring are open questions,\nand that the required automating tools are lacking. We tackled these problems\nin two steps. First, we conducted an exploratory study, collecting\nparticipants' opinions on the game elements they consider the most useful for\ndifferent learning activity types (LAT) via survey. Then, we modeled opinions\nthrough conditional decision trees to address the aforementioned tailoring\nprocess. Second, as a product from the first step, we implemented a recommender\nsystem that suggests personalized gamification designs (which game elements to\nuse), addressing the problem of automating gamification personalization. Our\nfindings i) present empirical evidence that LAT, geographic locations, and\nother user characteristics affect users' preferences, ii) enable defining\ngamification designs tailored to user and contextual features simultaneously,\nand iii) provide technological aid for those interested in designing\npersonalized gamification. The main implications are that demographics,\ngame-related characteristics, geographic location, and LAT to be done, as well\nas the interaction between different kinds of information (user and contextual\ncharacteristics), should be considered in defining gamification designs and\nthat personalizing gamification designs can be improved with aid from our\nrecommender system.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 16:47:00 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Rodrigues", "Luiz", ""], ["Toda", "Armando M.", ""], ["Oliveira", "Wilk", ""], ["Palomino", "Paula T.", ""], ["Vassileva", "Julita", ""], ["Isotani", "Seiji", ""]]}, {"id": "2101.05786", "submitter": "Peter Gloor", "authors": "Sebastian Duerr, Peter A. Gloor", "title": "Persuasive Natural Language Generation -- A Literature Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This literature review focuses on the use of Natural Language Generation\n(NLG) to automatically detect and generate persuasive texts. Extending previous\nresearch on automatic identification of persuasion in text, we concentrate on\ngenerative aspects through conceptualizing determinants of persuasion in five\nbusiness-focused categories: benevolence, linguistic appropriacy, logical\nargumentation, trustworthiness, tools and datasets. These allow NLG to increase\nan existing message's persuasiveness. Previous research illustrates key aspects\nin each of the above mentioned five categories. A research agenda to further\nstudy persuasive NLG is developed. The review includes analysis of\nseventy-seven articles, outlining the existing body of knowledge and showing\nthe steady progress in this research field.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 18:44:51 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Duerr", "Sebastian", ""], ["Gloor", "Peter A.", ""]]}, {"id": "2101.05851", "submitter": "Chenda Zhang", "authors": "Chenda Zhang, Hedvig Kjellstr\\\"om", "title": "A Subjective Model of Human Decision Making Based on Quantum Decision\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer modeling of human decision making is of large importance for, e.g.,\nsustainable transport, urban development, and online recommendation systems. In\nthis paper we present a model for predicting the behavior of an individual\nduring a binary game under different amounts of risk, gain, and time pressure.\nThe model is based on Quantum Decision Theory (QDT), which has been shown to\nenable modeling of the irrational and subjective aspects of the decision\nmaking, not accounted for by the classical Cumulative Prospect Theory (CPT).\nExperiments on two different datasets show that our QDT-based approach\noutperforms both a CPT-based approach and data driven approaches such as\nfeed-forward neural networks and random forests.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 20:02:51 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Zhang", "Chenda", ""], ["Kjellstr\u00f6m", "Hedvig", ""]]}, {"id": "2101.05875", "submitter": "Ramya Akula", "authors": "Ramya Akula, Ivan Garibay", "title": "Interpretable Multi-Head Self-Attention model for Sarcasm Detection in\n  social media", "comments": null, "journal-ref": null, "doi": "10.3390/e23040394", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sarcasm is a linguistic expression often used to communicate the opposite of\nwhat is said, usually something that is very unpleasant with an intention to\ninsult or ridicule. Inherent ambiguity in sarcastic expressions, make sarcasm\ndetection very difficult. In this work, we focus on detecting sarcasm in\ntextual conversations from various social networking platforms and online\nmedia. To this end, we develop an interpretable deep learning model using\nmulti-head self-attention and gated recurrent units. Multi-head self-attention\nmodule aids in identifying crucial sarcastic cue-words from the input, and the\nrecurrent units learn long-range dependencies between these cue-words to better\nclassify the input text. We show the effectiveness of our approach by achieving\nstate-of-the-art results on multiple datasets from social networking platforms\nand online media. Models trained using our proposed approach are easily\ninterpretable and enable identifying sarcastic cues in the input text which\ncontribute to the final classification score. We visualize the learned\nattention weights on few sample input texts to showcase the effectiveness and\ninterpretability of our model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 21:39:35 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Akula", "Ramya", ""], ["Garibay", "Ivan", ""]]}, {"id": "2101.05880", "submitter": "Shenghui Li", "authors": "Shenghui Li, Edith Ngai, Fanghua Ye, and Thiemo Voigt", "title": "Auto-weighted Robust Federated Learning with Corrupted Data Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning provides a communication-efficient and privacy-preserving\ntraining process by enabling learning statistical models with massive\nparticipants while keeping their data in local clients. However, standard\nfederated learning techniques that naively minimize an average loss function\nare vulnerable to data corruptions from outliers, systematic mislabeling, or\neven adversaries. In addition, it is often prohibited for service providers to\nverify the quality of data samples due to the increasing concern of user data\nprivacy. In this paper, we address this challenge by proposing Auto-weighted\nRobust Federated Learning (arfl), a novel approach that jointly learns the\nglobal model and the weights of local updates to provide robustness against\ncorrupted data sources. We prove a learning bound on the expected risk with\nrespect to the predictor and the weights of clients, which guides the\ndefinition of the objective for robust federated learning. The weights are\nallocated by comparing the empirical loss of a client with the average loss of\nthe best p clients (p-average), thus we can downweight the clients with\nsignificantly high losses, thereby lower their contributions to the global\nmodel. We show that this approach achieves robustness when the data of\ncorrupted clients is distributed differently from benign ones. To optimize the\nobjective function, we propose a communication-efficient algorithm based on the\nblockwise minimization paradigm. We conduct experiments on multiple benchmark\ndatasets, including CIFAR-10, FEMNIST and Shakespeare, considering different\ndeep neural network models. The results show that our solution is robust\nagainst different scenarios including label shuffling, label flipping and noisy\nfeatures, and outperforms the state-of-the-art methods in most scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 21:54:55 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 16:34:49 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Li", "Shenghui", ""], ["Ngai", "Edith", ""], ["Ye", "Fanghua", ""], ["Voigt", "Thiemo", ""]]}, {"id": "2101.05930", "submitter": "Yige Li", "authors": "Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma", "title": "Neural Attention Distillation: Erasing Backdoor Triggers from Deep\n  Neural Networks", "comments": "19 pages, 14 figures, ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known vulnerable to backdoor attacks, a\ntraining time attack that injects a trigger pattern into a small proportion of\ntraining data so as to control the model's prediction at the test time.\nBackdoor attacks are notably dangerous since they do not affect the model's\nperformance on clean examples, yet can fool the model to make incorrect\nprediction whenever the trigger pattern appears during testing. In this paper,\nwe propose a novel defense framework Neural Attention Distillation (NAD) to\nerase backdoor triggers from backdoored DNNs. NAD utilizes a teacher network to\nguide the finetuning of the backdoored student network on a small clean subset\nof data such that the intermediate-layer attention of the student network\naligns with that of the teacher network. The teacher network can be obtained by\nan independent finetuning process on the same clean subset. We empirically\nshow, against 6 state-of-the-art backdoor attacks, NAD can effectively erase\nthe backdoor triggers using only 5\\% clean training data without causing\nobvious performance degradation on clean examples. Code is available in\nhttps://github.com/bboylyg/NAD.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 01:35:22 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 06:23:25 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Yige", ""], ["Lyu", "Xixiang", ""], ["Koren", "Nodens", ""], ["Lyu", "Lingjuan", ""], ["Li", "Bo", ""], ["Ma", "Xingjun", ""]]}, {"id": "2101.05938", "submitter": "Jing Jin", "authors": "Jing Jin, Cai Liang, Tiancheng Wu, Liqin Zou, Zhiliang Gan", "title": "KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with\n  Learned Step Size Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, transformer-based language models such as BERT have shown\ntremendous performance improvement for a range of natural language processing\ntasks. However, these language models usually are computation expensive and\nmemory intensive during inference. As a result, it is difficult to deploy them\non resource-restricted devices. To improve the inference performance, as well\nas reduce the model size while maintaining the model accuracy, we propose a\nnovel quantization method named KDLSQ-BERT that combines knowledge distillation\n(KD) with learned step size quantization (LSQ) for language model quantization.\nThe main idea of our method is that the KD technique is leveraged to transfer\nthe knowledge from a \"teacher\" model to a \"student\" model when exploiting LSQ\nto quantize that \"student\" model during the quantization training process.\nExtensive experiment results on GLUE benchmark and SQuAD demonstrate that our\nproposed KDLSQ-BERT not only performs effectively when doing different bit\n(e.g. 2-bit $\\sim$ 8-bit) quantization, but also outperforms the existing BERT\nquantization methods, and even achieves comparable performance as the\nfull-precision base-line model while obtaining 14.9x compression ratio. Our\ncode will be public available.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 02:21:28 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Jin", "Jing", ""], ["Liang", "Cai", ""], ["Wu", "Tiancheng", ""], ["Zou", "Liqin", ""], ["Gan", "Zhiliang", ""]]}, {"id": "2101.05950", "submitter": "Xiaoyang Wang", "authors": "Xiaoyang Wang, Bo Li, Yibo Zhang, Bhavya Kailkhura, Klara Nahrstedt", "title": "Robusta: Robust AutoML for Feature Selection via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several AutoML approaches have been proposed to automate the machine learning\n(ML) process, such as searching for the ML model architectures and\nhyper-parameters. However, these AutoML pipelines only focus on improving the\nlearning accuracy of benign samples while ignoring the ML model robustness\nunder adversarial attacks. As ML systems are increasingly being used in a\nvariety of mission-critical applications, improving the robustness of ML\nsystems has become of utmost importance. In this paper, we propose the first\nrobust AutoML framework, Robusta--based on reinforcement learning (RL)--to\nperform feature selection, aiming to select features that lead to both accurate\nand robust ML systems. We show that a variation of the 0-1 robust loss can be\ndirectly optimized via an RL-based combinatorial search in the feature\nselection scenario. In addition, we employ heuristics to accelerate the search\nprocedure based on feature scoring metrics, which are mutual information\nscores, tree-based classifiers feature importance scores, F scores, and\nIntegrated Gradient (IG) scores, as well as their combinations. We conduct\nextensive experiments and show that the proposed framework is able to improve\nthe model robustness by up to 22% while maintaining competitive accuracy on\nbenign samples compared with other feature selection methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 03:12:29 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wang", "Xiaoyang", ""], ["Li", "Bo", ""], ["Zhang", "Yibo", ""], ["Kailkhura", "Bhavya", ""], ["Nahrstedt", "Klara", ""]]}, {"id": "2101.05953", "submitter": "Sundeep Teki", "authors": "Ayush Gupta, Rohan Sukumaran, Kevin John, Sundeep Teki", "title": "Hostility Detection and Covid-19 Fake News Detection in Social Media", "comments": "13 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the\ncontent shared online. Consequently, the propagation of fake news and hostile\nmessages on social media platforms has also skyrocketed. In this paper, we\naddress the problem of detecting hostile and fake content in the Devanagari\n(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we\nbuild a model that makes use of an abusive language detector coupled with\nfeatures extracted via Hindi BERT and Hindi FastText models and metadata. Our\nmodel achieves a 0.97 F1 score on coarse grain evaluation on Hostility\ndetection task. Additionally, we built models to identify fake news related to\nCovid-19 in English tweets. We leverage entity information extracted from the\ntweets along with textual representations learned from word embeddings and\nachieve a 0.93 F1 score on the English fake news detection task.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 03:24:36 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Gupta", "Ayush", ""], ["Sukumaran", "Rohan", ""], ["John", "Kevin", ""], ["Teki", "Sundeep", ""]]}, {"id": "2101.05957", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Meeyoung Cha", "title": "Descriptive AI Ethics: Collecting and Understanding the Public Opinion", "comments": "Accepted to the Ethics in Design Workshop at ACM CSCW 2020\n  (https://ethicsindesignworkshop.wordpress.com/). 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for data-driven research efforts on how the public\nperceives the ethical, moral, and legal issues of autonomous AI systems. The\ncurrent debate on the responsibility gap posed by these systems is one such\nexample. This work proposes a mixed AI ethics model that allows normative and\ndescriptive research to complement each other, by aiding scholarly discussion\nwith data gathered from the public. We discuss its implications on bridging the\ngap between optimistic and pessimistic views towards AI systems' deployment.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 03:46:27 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Lima", "Gabriel", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2101.05961", "submitter": "Manish Shetty Molahalli", "authors": "Manish Shetty, Chetan Bansal, Sumit Kumar, Nikitha Rao, Nachiappan\n  Nagappan", "title": "SoftNER: Mining Knowledge Graphs From Cloud Incidents", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.05505", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The move from boxed products to services and the widespread adoption of cloud\ncomputing has had a huge impact on the software development life cycle and\nDevOps processes. Particularly, incident management has become critical for\ndeveloping and operating large-scale services. Prior work on incident\nmanagement has heavily focused on the challenges with incident triaging and\nde-duplication. In this work, we address the fundamental problem of structured\nknowledge extraction from service incidents. We have built SoftNER, a framework\nfor mining Knowledge Graphs from incident reports. First, we build a novel\nmulti-task learning based BiLSTM-CRF model which leverages not just the\nsemantic context but also the data-types for extracting factual information in\nthe form of named entities. Next, we present an approach to mine relations\nbetween the named entities for automatically constructing knowledge graphs. We\nhave deployed SoftNER at Microsoft, a major cloud service provider and have\nevaluated it on more than 2 months of cloud incidents. We show that the\nunsupervised machine learning pipeline has a high precision of 0.96. Our\nmulti-task learning based deep learning model also outperforms the\nstate-of-the-art NER models. Lastly, using the knowledge extracted by SoftNER,\nwe are able to build accurate models for applications such as incident triaging\nand recommending entities based on their relevance to incident titles.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 04:15:26 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 08:35:29 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Shetty", "Manish", ""], ["Bansal", "Chetan", ""], ["Kumar", "Sumit", ""], ["Rao", "Nikitha", ""], ["Nagappan", "Nachiappan", ""]]}, {"id": "2101.05967", "submitter": "Steven Whang", "authors": "Steven Euijong Whang, Ki Hyun Tae, Yuji Roh, Geon Heo", "title": "Responsible AI Challenges in End-to-end Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Responsible AI is becoming critical as AI is widely used in our everyday\nlives. Many companies that deploy AI publicly state that when training a model,\nwe not only need to improve its accuracy, but also need to guarantee that the\nmodel does not discriminate against users (fairness), is resilient to noisy or\npoisoned data (robustness), is explainable, and more. In addition, these\nobjectives are not only relevant to model training, but to all steps of\nend-to-end machine learning, which include data collection, data cleaning and\nvalidation, model training, model evaluation, and model management and serving.\nFinally, responsible AI is conceptually challenging, and supporting all the\nobjectives must be as easy as possible. We thus propose three key research\ndirections towards this vision - depth, breadth, and usability - to measure\nprogress and introduce our ongoing research. First, responsible AI must be\ndeeply supported where multiple objectives like fairness and robust must be\nhandled together. To this end, we propose FR-Train, a holistic framework for\nfair and robust model training in the presence of data bias and poisoning.\nSecond, responsible AI must be broadly supported, preferably in all steps of\nmachine learning. Currently we focus on the data pre-processing steps and\npropose Slice Tuner, a selective data acquisition framework for training fair\nand accurate models, and MLClean, a data cleaning framework that also improves\nfairness and robustness. Finally, responsible AI must be usable where the\ntechniques must be easy to deploy and actionable. We propose FairBatch, a batch\nselection approach for fairness that is effective and simple to use, and Slice\nFinder, a model evaluation tool that automatically finds problematic slices. We\nbelieve we scratched the surface of responsible AI for end-to-end machine\nlearning and suggest research challenges moving forward.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 04:55:03 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Whang", "Steven Euijong", ""], ["Tae", "Ki Hyun", ""], ["Roh", "Yuji", ""], ["Heo", "Geon", ""]]}, {"id": "2101.05970", "submitter": "Tanmay Agarwal", "authors": "Tanmay Agarwal, Hitesh Arora, Jeff Schneider", "title": "Affordance-based Reinforcement Learning for Urban Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional autonomous vehicle pipelines that follow a modular approach have\nbeen very successful in the past both in academia and industry, which has led\nto autonomy deployed on road. Though this approach provides ease of\ninterpretation, its generalizability to unseen environments is limited and\nhand-engineering of numerous parameters is required, especially in the\nprediction and planning systems. Recently, deep reinforcement learning has been\nshown to learn complex strategic games and perform challenging robotic tasks,\nwhich provides an appealing framework for learning to drive. In this work, we\npropose a deep reinforcement learning framework to learn optimal control policy\nusing waypoints and low-dimensional visual representations, also known as\naffordances. We demonstrate that our agents when trained from scratch learn the\ntasks of lane-following, driving around inter-sections as well as stopping in\nfront of other actors or traffic lights even in the dense traffic setting. We\nnote that our method achieves comparable or better performance than the\nbaseline methods on the original and NoCrash benchmarks on the CARLA simulator.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 05:21:25 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Agarwal", "Tanmay", ""], ["Arora", "Hitesh", ""], ["Schneider", "Jeff", ""]]}, {"id": "2101.05982", "submitter": "Che Wang", "authors": "Xinyue Chen, Che Wang, Zijian Zhou, Keith Ross", "title": "Randomized Ensembled Double Q-Learning: Learning Fast Without a Model", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a high Update-To-Data (UTD) ratio, model-based methods have recently\nachieved much higher sample efficiency than previous model-free methods for\ncontinuous-action DRL benchmarks. In this paper, we introduce a simple\nmodel-free algorithm, Randomized Ensembled Double Q-Learning (REDQ), and show\nthat its performance is just as good as, if not better than, a state-of-the-art\nmodel-based algorithm for the MuJoCo benchmark. Moreover, REDQ can achieve this\nperformance using fewer parameters than the model-based method, and with less\nwall-clock run time. REDQ has three carefully integrated ingredients which\nallow it to achieve its high performance: (i) a UTD ratio >> 1; (ii) an\nensemble of Q functions; (iii) in-target minimization across a random subset of\nQ functions from the ensemble. Through carefully designed experiments, we\nprovide a detailed analysis of REDQ and related model-free algorithms. To our\nknowledge, REDQ is the first successful model-free DRL algorithm for\ncontinuous-action spaces using a UTD ratio >> 1.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 06:25:58 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 03:42:07 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chen", "Xinyue", ""], ["Wang", "Che", ""], ["Zhou", "Zijian", ""], ["Ross", "Keith", ""]]}, {"id": "2101.05986", "submitter": "Haoyang Bi", "authors": "Haoyang Bi, Haiping Ma, Zhenya Huang, Yu Yin, Qi Liu, Enhong Chen, Yu\n  Su, Shijin Wang", "title": "Quality meets Diversity: A Model-Agnostic Framework for Computerized\n  Adaptive Testing", "comments": "Accepted by ICDM'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computerized Adaptive Testing (CAT) is emerging as a promising testing\napplication in many scenarios, such as education, game and recruitment, which\ntargets at diagnosing the knowledge mastery levels of examinees on required\nconcepts. It shows the advantage of tailoring a personalized testing procedure\nfor each examinee, which selects questions step by step, depending on her\nperformance. While there are many efforts on developing CAT systems, existing\nsolutions generally follow an inflexible model-specific fashion. That is, they\nneed to observe a specific cognitive model which can estimate examinee's\nknowledge levels and design the selection strategy according to the model\nestimation. In this paper, we study a novel model-agnostic CAT problem, where\nwe aim to propose a flexible framework that can adapt to different cognitive\nmodels. Meanwhile, this work also figures out CAT solution with addressing the\nproblem of how to generate both high-quality and diverse questions\nsimultaneously, which can give a comprehensive knowledge diagnosis for each\nexaminee. Inspired by Active Learning, we propose a novel framework, namely\nModel-Agnostic Adaptive Testing (MAAT) for CAT solution, where we design three\nsophisticated modules including Quality Module, Diversity Module and Importance\nModule. Extensive experimental results on two real-world datasets clearly\ndemonstrate that our MAAT can support CAT with guaranteeing both quality and\ndiversity perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 06:48:50 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Bi", "Haoyang", ""], ["Ma", "Haiping", ""], ["Huang", "Zhenya", ""], ["Yin", "Yu", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""], ["Su", "Yu", ""], ["Wang", "Shijin", ""]]}, {"id": "2101.05993", "submitter": "Guangtao Wang", "authors": "Guangtao Wang, Qinbao Song and Xiaoyan Zhu", "title": "Ensemble Learning Based Classification Algorithm Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending appropriate algorithms to a classification problem is one of the\nmost challenging issues in the field of data mining. The existing algorithm\nrecommendation models are generally constructed on only one kind of\nmeta-features by single learners. Considering that i) ensemble learners usually\nshow better performance and ii) different kinds of meta-features characterize\nthe classification problems in different viewpoints independently, and further\nthe models constructed with different sets of meta-features will be\ncomplementary with each other and applicable for ensemble. This paper proposes\nan ensemble learning-based algorithm recommendation method. To evaluate the\nproposed recommendation method, extensive experiments with 13 well-known\ncandidate classification algorithms and five different kinds of meta-features\nare conducted on 1090 benchmark classification problems. The results show the\neffectiveness of the proposed ensemble learning based recommendation method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 07:14:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wang", "Guangtao", ""], ["Song", "Qinbao", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "2101.06022", "submitter": "Junshen Kevin Chen", "authors": "Junshen Kevin Chen, Wanze Xie, Yutong He", "title": "Motion-Based Handwriting Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We attempt to overcome the restriction of requiring a writing surface for\nhandwriting recognition. In this study, we design a prototype of a stylus\nequipped with motion sensor, and utilizes gyroscopic and acceleration sensor\nreading to perform written letter classification using various deep learning\ntechniques such as CNN and RNNs. We also explore various data augmentation\ntechniques and their effects, reaching up to 86% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 09:14:10 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chen", "Junshen Kevin", ""], ["Xie", "Wanze", ""], ["He", "Yutong", ""]]}, {"id": "2101.06056", "submitter": "Xu Chen", "authors": "Shuai Yu and Xiaowen Gong and Qian Shi and Xiaofei Wang and Xu Chen", "title": "EC-SAGINs: Edge Computing-enhanced Space-Air-Ground Integrated Networks\n  for Internet of Vehicles", "comments": "The paper is accepted by IEEE IoTJ, Jan. 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing-enhanced Internet of Vehicles (EC-IoV) enables ubiquitous data\nprocessing and content sharing among vehicles and terrestrial edge computing\n(TEC) infrastructures (e.g., 5G base stations and roadside units) with little\nor no human intervention, plays a key role in the intelligent transportation\nsystems. However, EC-IoV is heavily dependent on the connections and\ninteractions between vehicles and TEC infrastructures, thus will break down in\nsome remote areas where TEC infrastructures are unavailable (e.g., desert,\nisolated islands and disaster-stricken areas). Driven by the ubiquitous\nconnections and global-area coverage, space-air-ground integrated networks\n(SAGINs) efficiently support seamless coverage and efficient resource\nmanagement, represent the next frontier for edge computing. In light of this,\nwe first review the state-of-the-art edge computing research for SAGINs in this\narticle. After discussing several existing orbital and aerial edge computing\narchitectures, we propose a framework of edge computing-enabled\nspace-air-ground integrated networks (EC-SAGINs) to support various IoV\nservices for the vehicles in remote areas. The main objective of the framework\nis to minimize the task completion time and satellite resource usage. To this\nend, a pre-classification scheme is presented to reduce the size of action\nspace, and a deep imitation learning (DIL) driven offloading and caching\nalgorithm is proposed to achieve real-time decision making. Simulation results\nshow the effectiveness of our proposed scheme. At last, we also discuss some\ntechnology challenges and future directions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 10:56:23 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Yu", "Shuai", ""], ["Gong", "Xiaowen", ""], ["Shi", "Qian", ""], ["Wang", "Xiaofei", ""], ["Chen", "Xu", ""]]}, {"id": "2101.06066", "submitter": "Lun Yiu Nie", "authors": "Mudit Chaudhary, Borislav Dzodzo, Sida Huang, Chun Hei Lo, Mingzhi\n  Lyu, Lun Yiu Nie, Jinbo Xing, Tianhua Zhang, Xiaoying Zhang, Jingyan Zhou,\n  Hong Cheng, Wai Lam, Helen Meng", "title": "Unstructured Knowledge Access in Task-oriented Dialog Modeling using\n  Language Inference, Knowledge Retrieval and Knowledge-Integrative Response\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog systems enriched with external knowledge can handle user queries that\nare outside the scope of the supporting databases/APIs. In this paper, we\nfollow the baseline provided in DSTC9 Track 1 and propose three subsystems,\nKDEAK, KnowleDgEFactor, and Ens-GPT, which form the pipeline for a\ntask-oriented dialog system capable of accessing unstructured knowledge.\nSpecifically, KDEAK performs knowledge-seeking turn detection by formulating\nthe problem as natural language inference using knowledge from dialogs,\ndatabases and FAQs. KnowleDgEFactor accomplishes the knowledge selection task\nby formulating a factorized knowledge/document retrieval problem with three\nmodules performing domain, entity and knowledge level analyses. Ens-GPT\ngenerates a response by first processing multiple knowledge snippets, followed\nby an ensemble algorithm that decides if the response should be solely derived\nfrom a GPT2-XL model, or regenerated in combination with the top-ranking\nknowledge snippet. Experimental results demonstrate that the proposed pipeline\nsystem outperforms the baseline and generates high-quality responses, achieving\nat least 58.77% improvement on BLEU-4 score.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 11:24:32 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chaudhary", "Mudit", ""], ["Dzodzo", "Borislav", ""], ["Huang", "Sida", ""], ["Lo", "Chun Hei", ""], ["Lyu", "Mingzhi", ""], ["Nie", "Lun Yiu", ""], ["Xing", "Jinbo", ""], ["Zhang", "Tianhua", ""], ["Zhang", "Xiaoying", ""], ["Zhou", "Jingyan", ""], ["Cheng", "Hong", ""], ["Lam", "Wai", ""], ["Meng", "Helen", ""]]}, {"id": "2101.06091", "submitter": "Sepinoud Azimi", "authors": "Ivan Porres, Sepinoud Azimi, S\\'ebastien Lafond, Johan Lilius, Johanna\n  Salokannel, Mirva Salokorpi", "title": "On the Verification and Validation of AI Navigation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the state of the art on to methods to verify and validate\nnavigation algorithms for autonomous surface ships. We perform a systematic\nmapping study to find research works published in the last 10 years proposing\nnew algorithms for autonomous navigation and collision avoidance and we have\nextracted what verification and validation approaches have been applied on\nthese algorithms. We observe that most research works use simulations to\nvalidate their algorithms. However, these simulations often involve just a few\nscenarios designed manually. This raises the question if the algorithms have\nbeen validated properly. To remedy this, we propose the use of a systematic\nscenario-based testing approach to validate navigation algorithms extensively.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 13:15:23 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Porres", "Ivan", ""], ["Azimi", "Sepinoud", ""], ["Lafond", "S\u00e9bastien", ""], ["Lilius", "Johan", ""], ["Salokannel", "Johanna", ""], ["Salokorpi", "Mirva", ""]]}, {"id": "2101.06092", "submitter": "K Naveen Kumar", "authors": "K Naveen Kumar, C Vishnu, Reshmi Mitra, C Krishna Mohan", "title": "Black-box Adversarial Attacks in Autonomous Vehicle Technology", "comments": "7 pages, 10 figures, published in 49th Annual IEEE AIPR 2020: Trusted\n  Computing, Privacy, and Securing Multimedia Washington, D.C. October 13-15,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the high quality performance of the deep neural network in real-world\napplications, they are susceptible to minor perturbations of adversarial\nattacks. This is mostly undetectable to human vision. The impact of such\nattacks has become extremely detrimental in autonomous vehicles with real-time\n\"safety\" concerns. The black-box adversarial attacks cause drastic\nmisclassification in critical scene elements such as road signs and traffic\nlights leading the autonomous vehicle to crash into other vehicles or\npedestrians. In this paper, we propose a novel query-based attack method called\nModified Simple black-box attack (M-SimBA) to overcome the use of a white-box\nsource in transfer based attack method. Also, the issue of late convergence in\na Simple black-box attack (SimBA) is addressed by minimizing the loss of the\nmost confused class which is the incorrect class predicted by the model with\nthe highest probability, instead of trying to maximize the loss of the correct\nclass. We evaluate the performance of the proposed approach to the German\nTraffic Sign Recognition Benchmark (GTSRB) dataset. We show that the proposed\nmodel outperforms the existing models like Transfer-based projected gradient\ndescent (T-PGD), SimBA in terms of convergence time, flattening the\ndistribution of confused class probability, and producing adversarial samples\nwith least confidence on the true class.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 13:18:18 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Kumar", "K Naveen", ""], ["Vishnu", "C", ""], ["Mitra", "Reshmi", ""], ["Mohan", "C Krishna", ""]]}, {"id": "2101.06098", "submitter": "David Piorkowski", "authors": "David Piorkowski, Soya Park, April Yi Wang, Dakuo Wang, Michael\n  Muller, Felix Portnoy", "title": "How AI Developers Overcome Communication Challenges in a\n  Multidisciplinary Team: A Case Study", "comments": "25 pages, 7 figures, 4 tables", "journal-ref": null, "doi": "10.1145/3449205", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of AI applications is a multidisciplinary effort, involving\nmultiple roles collaborating with the AI developers, an umbrella term we use to\ninclude data scientists and other AI-adjacent roles on the same team. During\nthese collaborations, there is a knowledge mismatch between AI developers, who\nare skilled in data science, and external stakeholders who are typically not.\nThis difference leads to communication gaps, and the onus falls on AI\ndevelopers to explain data science concepts to their collaborators. In this\npaper, we report on a study including analyses of both interviews with AI\ndevelopers and artifacts they produced for communication. Using the analytic\nlens of shared mental models, we report on the types of communication gaps that\nAI developers face, how AI developers communicate across disciplinary and\norganizational boundaries, and how they simultaneously manage issues regarding\ntrust and expectations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 19:33:34 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Piorkowski", "David", ""], ["Park", "Soya", ""], ["Wang", "April Yi", ""], ["Wang", "Dakuo", ""], ["Muller", "Michael", ""], ["Portnoy", "Felix", ""]]}, {"id": "2101.06133", "submitter": "Jurriaan van Diggelen", "authors": "Jurriaan van Diggelen, Wiard Jorritsma, Bob van der Vecht", "title": "Teaming up with information agents", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the intricacies involved in designing a computer as a teampartner, we\ncan observe patterns in team behavior which allow us to describe at a general\nlevel how AI systems are to collaborate with humans. Whereas most work on\nhuman-machine teaming has focused on physical agents (e.g. robotic systems),\nour aim is to study how humans can collaborate with information agents. We\npropose some appropriate team design patterns, and test them using our\nCollaborative Intelligence Analysis (CIA) tool.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 14:26:12 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["van Diggelen", "Jurriaan", ""], ["Jorritsma", "Wiard", ""], ["van der Vecht", "Bob", ""]]}, {"id": "2101.06150", "submitter": "Mathieu Roche", "authors": "Sarah Valentin, Elena Arsevska, Aline Vilain, Val\\'erie De Waele,\n  Renaud Lancelot, Mathieu Roche", "title": "Annotation of epidemiological information in animal disease-related news\n  articles: guidelines", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a method for annotation of epidemiological information\nin animal disease-related news articles. The annotation guidelines are generic\nand aim to embrace all animal or zoonotic infectious diseases, regardless of\nthe pathogen involved or its way of transmission (e.g. vector-borne, airborne,\nby contact). The framework relies on the successive annotation of all the\nsentences from a news article. The annotator evaluates the sentences in a\nspecific epidemiological context, corresponding to the publication of the news\narticle.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 14:48:01 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Valentin", "Sarah", ""], ["Arsevska", "Elena", ""], ["Vilain", "Aline", ""], ["De Waele", "Val\u00e9rie", ""], ["Lancelot", "Renaud", ""], ["Roche", "Mathieu", ""]]}, {"id": "2101.06159", "submitter": "David Fernandez Llorca", "authors": "David Fern\\'andez Llorca, Antonio Hern\\'andez Mart\\'inez, Iv\\'an\n  Garc\\'ia Daza", "title": "Vision-based Vehicle Speed Estimation: A Survey", "comments": "Manuscript published in the IET Intelligent Transport Systems journal", "journal-ref": "IET Intelligent Transport Systems 2021", "doi": "10.1049/itr2.12079", "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to accurately estimate the speed of road vehicles is becoming\nincreasingly important for at least two main reasons. First, the number of\nspeed cameras installed worldwide has been growing in recent years, as the\nintroduction and enforcement of appropriate speed limits is considered one of\nthe most effective means to increase the road safety. Second, traffic\nmonitoring and forecasting in road networks plays a fundamental role to enhance\ntraffic, emissions and energy consumption in smart cities, being the speed of\nthe vehicles one of the most relevant parameters of the traffic state. Among\nthe technologies available for the accurate detection of vehicle speed, the use\nof vision-based systems brings great challenges to be solved, but also great\npotential advantages, such as the drastic reduction of costs due to the absence\nof expensive range sensors, and the possibility of identifying vehicles\naccurately. This paper provides a review of vision-based vehicle speed\nestimation. We describe the terminology, the application domains, and propose a\ncomplete taxonomy of a large selection of works that categorizes all stages\ninvolved. An overview of performance evaluation metrics and available datasets\nis provided. Finally, we discuss current limitations and future directions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 15:07:54 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 08:45:27 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Llorca", "David Fern\u00e1ndez", ""], ["Mart\u00ednez", "Antonio Hern\u00e1ndez", ""], ["Daza", "Iv\u00e1n Garc\u00eda", ""]]}, {"id": "2101.06162", "submitter": "Ghada Sokar", "authors": "Ghada Sokar, Decebal Constantin Mocanu, Mykola Pechenizkiy", "title": "Learning Invariant Representation for Continual Learning", "comments": "Accepted at the AAAI Meta-Learning for Computer Vision Workshop\n  (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to provide intelligent agents that are capable of\nlearning continually a sequence of tasks, building on previously learned\nknowledge. A key challenge in this learning paradigm is catastrophically\nforgetting previously learned tasks when the agent faces a new one. Current\nrehearsal-based methods show their success in mitigating the catastrophic\nforgetting problem by replaying samples from previous tasks during learning a\nnew one. However, these methods are infeasible when the data of previous tasks\nis not accessible. In this work, we propose a new pseudo-rehearsal-based\nmethod, named learning Invariant Representation for Continual Learning (IRCL),\nin which class-invariant representation is disentangled from a conditional\ngenerative model and jointly used with class-specific representation to learn\nthe sequential tasks. Disentangling the shared invariant representation helps\nto learn continually a sequence of tasks, while being more robust to forgetting\nand having better knowledge transfer. We focus on class incremental learning\nwhere there is no knowledge about task identity during inference. We\nempirically evaluate our proposed method on two well-known benchmarks for\ncontinual learning: split MNIST and split Fashion MNIST. The experimental\nresults show that our proposed method outperforms regularization-based methods\nby a big margin and is better than the state-of-the-art pseudo-rehearsal-based\nmethod. Finally, we analyze the role of the shared invariant representation in\nmitigating the forgetting problem especially when the number of replayed\nsamples for each previous task is small.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 15:12:51 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Sokar", "Ghada", ""], ["Mocanu", "Decebal Constantin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2101.06171", "submitter": "Duc Thien Nguyen", "authors": "Duc Thien Nguyen, Shiau Hoong Lim, Laura Wynter and Desmond Cai", "title": "Probabilistic Inference for Learning from Untrusted Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning brings potential benefits of faster learning, better\nsolutions, and a greater propensity to transfer when heterogeneous data from\ndifferent parties increases diversity. However, because federated learning\ntasks tend to be large and complex, and training times non-negligible, it is\nimportant for the aggregation algorithm to be robust to non-IID data and\ncorrupted parties. This robustness relies on the ability to identify, and\nappropriately weight, incompatible parties. Recent work assumes that a\n\\textit{reference dataset} is available through which to perform the\nidentification. We consider settings where no such reference dataset is\navailable; rather, the quality and suitability of the parties needs to be\n\\textit{inferred}. We do so by bringing ideas from crowdsourced predictions and\ncollaborative filtering, where one must infer an unknown ground truth given\nproposals from participants with unknown quality. We propose novel federated\nlearning aggregation algorithms based on Bayesian inference that adapt to the\nquality of the parties. Empirically, we show that the algorithms outperform\nstandard and robust aggregation in federated learning on both synthetic and\nreal data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 15:30:06 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Nguyen", "Duc Thien", ""], ["Lim", "Shiau Hoong", ""], ["Wynter", "Laura", ""], ["Cai", "Desmond", ""]]}, {"id": "2101.06177", "submitter": "Miquel Junyent", "authors": "Miquel Junyent, Vicen\\c{c} G\\'omez, Anders Jonsson", "title": "Hierarchical Width-Based Planning and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Width-based search methods have demonstrated state-of-the-art performance in\na wide range of testbeds, from classical planning problems to image-based\nsimulators such as Atari games. These methods scale independently of the size\nof the state-space, but exponentially in the problem width. In practice,\nrunning the algorithm with a width larger than 1 is computationally\nintractable, prohibiting IW from solving higher width problems. In this paper,\nwe present a hierarchical algorithm that plans at two levels of abstraction. A\nhigh-level planner uses abstract features that are incrementally discovered\nfrom low-level pruning decisions. We illustrate this algorithm in classical\nplanning PDDL domains as well as in pixel-based simulator domains. In classical\nplanning, we show how IW(1) at two levels of abstraction can solve problems of\nwidth 2. For pixel-based domains, we show how in combination with a learned\npolicy and a learned value function, the proposed hierarchical IW can\noutperform current flat IW-based planners in Atari games with sparse rewards.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 15:37:46 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 15:42:37 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Junyent", "Miquel", ""], ["G\u00f3mez", "Vicen\u00e7", ""], ["Jonsson", "Anders", ""]]}, {"id": "2101.06220", "submitter": "Jichen Zhu", "authors": "Jichen Zhu, Jennifer Villareale, Nithesh Javvaji, Sebastian Risi,\n  Mathias L\\\"owe, Rush Weigelt, Casper Harteveld", "title": "Player-AI Interaction: What Neural Network Games Reveal About AI as Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of artificial intelligence (AI) and machine learning (ML) bring\nhuman-AI interaction to the forefront of HCI research. This paper argues that\ngames are an ideal domain for studying and experimenting with how humans\ninteract with AI. Through a systematic survey of neural network games (n = 38),\nwe identified the dominant interaction metaphors and AI interaction patterns in\nthese games. In addition, we applied existing human-AI interaction guidelines\nto further shed light on player-AI interaction in the context of AI-infused\nsystems. Our core finding is that AI as play can expand current notions of\nhuman-AI interaction, which are predominantly productivity-based. In\nparticular, our work suggests that game and UX designers should consider flow\nto structure the learning curve of human-AI interaction, incorporate\ndiscovery-based learning to play around with the AI and observe the\nconsequences, and offer users an invitation to play to explore new forms of\nhuman-AI interaction.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 17:07:03 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:25:19 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhu", "Jichen", ""], ["Villareale", "Jennifer", ""], ["Javvaji", "Nithesh", ""], ["Risi", "Sebastian", ""], ["L\u00f6we", "Mathias", ""], ["Weigelt", "Rush", ""], ["Harteveld", "Casper", ""]]}, {"id": "2101.06223", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Markus Rabe, Wenda Li, Jimmy Ba, Roger Grosse, Christian\n  Szegedy", "title": "LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While designing inductive bias in neural architectures has been widely\nstudied, we hypothesize that transformer networks are flexible enough to learn\ninductive bias from suitable generic tasks. Here, we replace architecture\nengineering by encoding inductive bias in the form of datasets. Inspired by\nPeirce's view that deduction, induction, and abduction form an irreducible set\nof reasoning primitives, we design three synthetic tasks that are intended to\nrequire the model to have these three abilities. We specifically design these\nsynthetic tasks in a way that they are devoid of mathematical knowledge to\nensure that only the fundamental reasoning biases can be learned from these\ntasks. This defines a new pre-training methodology called \"LIME\" (Learning\nInductive bias for Mathematical rEasoning). Models trained with LIME\nsignificantly outperform vanilla transformers on three very different large\nmathematical reasoning benchmarks. Unlike dominating the computation cost as\ntraditional pre-training approaches, LIME requires only a small fraction of the\ncomputation cost of the typical downstream task.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 17:15:24 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wu", "Yuhuai", ""], ["Rabe", "Markus", ""], ["Li", "Wenda", ""], ["Ba", "Jimmy", ""], ["Grosse", "Roger", ""], ["Szegedy", "Christian", ""]]}, {"id": "2101.06248", "submitter": "Ali Taghibakhshi", "authors": "Ali Taghibakhshi, Nathan Ogden, Matthew West", "title": "Local Navigation and Docking of an Autonomous Robot Mower using\n  Reinforcement Learning and Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate a successful navigation and docking control system for the\nJohn Deere Tango autonomous mower, using only a single camera as the input.\nThis vision-only system is of interest because it is inexpensive, simple for\nproduction, and requires no external sensing. This is in contrast to existing\nsystems that rely on integrated position sensors and global positioning system\n(GPS) technologies. To produce our system we combined a state-of-the-art object\ndetection architecture, You Only Look Once (YOLO), with a reinforcement\nlearning (RL) architecture, Double Deep QNetworks (Double DQN). The object\ndetection network identifies features on the mower and passes its output to the\nRL network, providing it with a low-dimensional representation that enables\nrapid and robust training. Finally, the RL network learns how to navigate the\nmachine to the desired spot in a custom simulation environment. When tested on\nmower hardware, the system is able to dock with centimeter-level accuracy from\narbitrary initial locations and orientations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 18:17:19 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 22:04:24 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 15:45:15 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Taghibakhshi", "Ali", ""], ["Ogden", "Nathan", ""], ["West", "Matthew", ""]]}, {"id": "2101.06278", "submitter": "Shivangi Aneja Ms", "authors": "Shivangi Aneja, Chris Bregler and Matthias Nie{\\ss}ner", "title": "COSMOS: Catching Out-of-Context Misinformation with Self-Supervised\n  Learning", "comments": "Video : https://youtu.be/riI3Cl2xy10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent attention to DeepFakes, one of the most prevalent ways to\nmislead audiences on social media is the use of unaltered images in a new but\nfalse context. To address these challenges and support fact-checkers, we\npropose a new method that automatically detects out-of-context image and text\npairs. Our key insight is to leverage the grounding of image with text to\ndistinguish out-of-context scenarios that cannot be disambiguated with language\nalone. We propose a self-supervised training strategy where we only need a set\nof captioned images. At train time, our method learns to selectively align\nindividual objects in an image with textual claims, without explicit\nsupervision. At test time, we check if both captions correspond to the same\nobject(s) in the image but are semantically different, which allows us to make\nfairly accurate out-of-context predictions. Our method achieves 85%\nout-of-context detection accuracy. To facilitate benchmarking of this task, we\ncreate a large-scale dataset of 200K images with 450K textual captions from a\nvariety of news websites, blogs, and social media posts. The dataset and source\ncode is publicly available at\nhttps://shivangi-aneja.github.io/projects/cosmos/.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 19:00:42 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 15:52:58 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 18:00:07 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Aneja", "Shivangi", ""], ["Bregler", "Chris", ""], ["Nie\u00dfner", "Matthias", ""]]}, {"id": "2101.06308", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz, Kavish Kapoor, Ambareen Siraj, Mahmoud Abouyoussef", "title": "Privacy Protection of Grid Users Data with Blockchain and Adversarial\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilities around the world are reported to invest a total of around 30\nbillion over the next few years for installation of more than 300 million smart\nmeters, replacing traditional analog meters [1]. By mid-decade, with full\ncountry wide deployment, there will be almost 1.3 billion smart meters in place\n[1]. Collection of fine grained energy usage data by these smart meters\nprovides numerous advantages such as energy savings for customers with use of\ndemand optimization, a billing system of higher accuracy with dynamic pricing\nprograms, bidirectional information exchange ability between end-users for\nbetter consumer-operator interaction, and so on. However, all these perks\nassociated with fine grained energy usage data collection threaten the privacy\nof users. With this technology, customers' personal data such as sleeping\ncycle, number of occupants, and even type and number of appliances stream into\nthe hands of the utility companies and can be subject to misuse. This research\npaper addresses privacy violation of consumers' energy usage data collected\nfrom smart meters and provides a novel solution for the privacy protection\nwhile allowing benefits of energy data analytics. First, we demonstrate the\nsuccessful application of occupancy detection attacks using a deep neural\nnetwork method that yields high accuracy results. We then introduce Adversarial\nMachine Learning Occupancy Detection Avoidance with Blockchain (AMLODA-B)\nframework as a counter-attack by deploying an algorithm based on the Long Short\nTerm Memory (LSTM) model into the standardized smart metering infrastructure to\nprevent leakage of consumers personal information. Our privacy-aware approach\nprotects consumers' privacy without compromising the correctness of billing and\npreserves operational efficiency without use of authoritative intermediaries.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 21:54:55 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Yilmaz", "Ibrahim", ""], ["Kapoor", "Kavish", ""], ["Siraj", "Ambareen", ""], ["Abouyoussef", "Mahmoud", ""]]}, {"id": "2101.06319", "submitter": "Rahul Yedida", "authors": "Rahul Yedida, Xueqi Yang, Tim Menzies", "title": "When SIMPLE is better than complex: A case study on deep learning for\n  predicting Bugzilla issue close time", "comments": "v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Is deep learning over-hyped? Where are the case studies that compare\nstate-of-the-art deep learners with simpler options? In response to this gap in\nthe literature, this paper offers one case study on using deep learning to\npredict issue close time in Bugzilla.\n  We report here that a SIMPLE extension to a decades-old feedforward neural\nnetwork works better than the more recent, and more elaborate, \"long-short term\nmemory\" deep learning (which are currently popular in the SE literature).\nSIMPLE is a combination of a fast feedforward network and a hyper-parameter\noptimizer. SIMPLE runs in 3 seconds while the newer algorithms take 6 hours to\nterminate. Since it runs so fast, it is more amenable to being tuned by our\noptimizer. This paper reports results seen after running SIMPLE on issue close\ntime data from 45,364 issues raised in Chromium, Eclipse, and Firefox projects\nfrom January 2010 to March 2016. In our experiments, this SIMPLEr tuning\napproach achieves significantly better predictors for issue close time than the\nmore complex deep learner. These better and SIMPLEr results can be generated\n2,700 times faster than if using a state-of-the-art deep learner.\n  From this result, we make two conclusions. Firstly, for predicting issue\nclose time, we would recommend SIMPLE over complex deep learners. Secondly,\nbefore analysts try very sophisticated (but very slow) algorithms, they might\nachieve better results, much sooner, by applying hyper-parameter optimization\nto simple (but very fast) algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 22:56:14 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Yedida", "Rahul", ""], ["Yang", "Xueqi", ""], ["Menzies", "Tim", ""]]}, {"id": "2101.06328", "submitter": "Alan Smeaton", "authors": "Hyowon Lee, Mingming Liu, Hamza Riaz, Navaneethan Rajasekaren, Michael\n  Scriney, Alan F. Smeaton", "title": "Attention Based Video Summaries of Live Online Zoom Classes", "comments": "Presented at AAAI-2021 Workshop on AI Education: \"Imagining\n  Post-COVID Education with AI\" (TIPCE-2021). 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a system developed to help University students get more\nfrom their online lectures, tutorials, laboratory and other live sessions. We\ndo this by logging their attention levels on their laptops during live Zoom\nsessions and providing them with personalised video summaries of those live\nsessions. Using facial attention analysis software we create personalised video\nsummaries composed of just the parts where a student's attention was below some\nthreshold. We can also factor in other criteria into video summary generation\nsuch as parts where the student was not paying attention while others in the\nclass were, and parts of the video that other students have replayed\nextensively which a given student has not. Attention and usage based video\nsummaries of live classes are a form of personalised content, they are\neducational video segments recommended to highlight important parts of live\nsessions, useful in both topic understanding and in exam preparation. The\nsystem also allows a Professor to review the aggregated attention levels of\nthose in a class who attended a live session and logged their attention levels.\nThis allows her to see which parts of the live activity students were paying\nmost, and least, attention to. The Help-Me-Watch system is deployed and in use\nat our University in a way that protects student's personal data, operating in\na GDPR-compliant way.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 23:28:52 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Lee", "Hyowon", ""], ["Liu", "Mingming", ""], ["Riaz", "Hamza", ""], ["Rajasekaren", "Navaneethan", ""], ["Scriney", "Michael", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2101.06364", "submitter": "Hanif Bhuiyan", "authors": "Jinat Ara, Hanif Bhuiyan, Yeasin Arafat Bhuiyan, Salma Begum Bhyan and\n  Muhammad Ismail Bhuiyan", "title": "AR-based Modern Healthcare: A Review", "comments": "14 pages, 7 figures, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent advances of Augmented Reality (AR) in healthcare have shown that\ntechnology is a significant part of the current healthcare system. In recent\ndays, augmented reality has proposed numerous smart applications in healthcare\ndomain including wearable access, telemedicine, remote surgery, diagnosis of\nmedical reports, emergency medicine, etc. The aim of the developed augmented\nhealthcare application is to improve patient care, increase efficiency, and\ndecrease costs. This article puts on an effort to review the advances in\nAR-based healthcare technologies and goes to peek into the strategies that are\nbeing taken to further this branch of technology. This article explores the\nimportant services of augmented-based healthcare solutions and throws light on\nrecently invented ones as well as their respective platforms. It also addresses\nconcurrent concerns and their relevant future challenges. In addition, this\npaper analyzes distinct AR security and privacy including security requirements\nand attack terminologies. Furthermore, this paper proposes a security model to\nminimize security risks. Augmented reality advantages in healthcare, especially\nfor operating surgery, emergency diagnosis, and medical training is being\ndemonstrated here thorough proper analysis. To say the least, the article\nillustrates a complete overview of augmented reality technology in the modern\nhealthcare sector by demonstrating its impacts, advancements, current\nvulnerabilities; future challenges, and concludes with recommendations to a new\ndirection for further research.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 03:53:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ara", "Jinat", ""], ["Bhuiyan", "Hanif", ""], ["Bhuiyan", "Yeasin Arafat", ""], ["Bhyan", "Salma Begum", ""], ["Bhuiyan", "Muhammad Ismail", ""]]}, {"id": "2101.06371", "submitter": "MyungJoo Ham", "authors": "MyungJoo Ham, Jijoong Moon, Geunsik Lim, Jaeyun Jung, Hyoungjoo Ahn,\n  Wook Song, Sangjung Woo, Parichay Kapoor, Dongju Chae, Gichan Jang, Yongjoo\n  Ahn, Jihoon Lee", "title": "NNStreamer: Efficient and Agile Development of On-Device AI Systems", "comments": "IEEE/ACM ICSE 2021 SEIP (preprint)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NNStreamer, a software system that handles neural networks as\nfilters of stream pipelines, applying the stream processing paradigm to deep\nneural network applications. A new trend with the wide-spread of deep neural\nnetwork applications is on-device AI. It is to process neural networks on\nmobile devices or edge/IoT devices instead of cloud servers. Emerging privacy\nissues, data transmission costs, and operational costs signify the need for\non-device AI, especially if we deploy a massive number of devices. NNStreamer\nefficiently handles neural networks with complex data stream pipelines on\ndevices, significantly improving the overall performance with minimal efforts.\nBesides, NNStreamer simplifies implementations and allows reusing off-the-shelf\nmedia filters directly, which reduces developmental costs significantly. We are\nalready deploying NNStreamer for a wide range of products and platforms,\nincluding the Galaxy series and various consumer electronic devices. The\nexperimental results suggest a reduction in developmental costs and enhanced\nperformance of pipeline architectures and NNStreamer. It is an open-source\nproject incubated by Linux Foundation AI, available to the public and\napplicable to various hardware and software platforms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 04:49:44 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ham", "MyungJoo", ""], ["Moon", "Jijoong", ""], ["Lim", "Geunsik", ""], ["Jung", "Jaeyun", ""], ["Ahn", "Hyoungjoo", ""], ["Song", "Wook", ""], ["Woo", "Sangjung", ""], ["Kapoor", "Parichay", ""], ["Chae", "Dongju", ""], ["Jang", "Gichan", ""], ["Ahn", "Yongjoo", ""], ["Lee", "Jihoon", ""]]}, {"id": "2101.06373", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, George Karypis, Jaideep Srivastava", "title": "An Empirical Comparison of Deep Learning Models for Knowledge Tracing on\n  Large-Scale Dataset", "comments": "Accepted at AAAI workshop on AI in Education, Imagining Post-COVID\n  Education with AI, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Knowledge tracing (KT) is the problem of modeling each student's mastery of\nknowledge concepts (KCs) as (s)he engages with a sequence of learning\nactivities. It is an active research area to help provide learners with\npersonalized feedback and materials. Various deep learning techniques have been\nproposed for solving KT. Recent release of large-scale student performance\ndataset \\cite{choi2019ednet} motivates the analysis of performance of deep\nlearning approaches that have been proposed to solve KT. Our analysis can help\nunderstand which method to adopt when large dataset related to student\nperformance is available. We also show that incorporating contextual\ninformation such as relation between exercises and student forget behavior\nfurther improves the performance of deep learning models.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 04:58:17 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Pandey", "Shalini", ""], ["Karypis", "George", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "2101.06399", "submitter": "Zixu Wang", "authors": "Zixu Wang, Yishu Miao, Lucia Specia", "title": "Latent Variable Models for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conventional models for Visual Question Answering (VQA) explore deterministic\napproaches with various types of image features, question features, and\nattention mechanisms. However, there exist other modalities that can be\nexplored in addition to image and question pairs to bring extra information to\nthe models. In this work, we propose latent variable models for VQA where extra\ninformation (e.g. captions and answer categories) are incorporated as latent\nvariables to improve inference, which in turn benefits question-answering\nperformance. Experiments on the VQA v2.0 benchmarking dataset demonstrate the\neffectiveness of our proposed models in that they improve over strong\nbaselines, especially those that do not rely on extensive language-vision\npre-training.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 08:21:43 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wang", "Zixu", ""], ["Miao", "Yishu", ""], ["Specia", "Lucia", ""]]}, {"id": "2101.06417", "submitter": "Shaopeng Fu", "authors": "Shaopeng Fu, Fengxiang He, Yue Xu, Dacheng Tao", "title": "Bayesian Inference Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to be forgotten has been legislated in many countries but the\nenforcement in machine learning would cause unbearable costs: companies may\nneed to delete whole models learned from massive resources due to single\nindividual requests. Existing works propose to remove the knowledge learned\nfrom the requested data via its influence function which is no longer naturally\nwell-defined in Bayesian inference. This paper proposes a {\\it Bayesian\ninference forgetting} (BIF) framework to realize the right to be forgotten in\nBayesian inference. In the BIF framework, we develop forgetting algorithms for\nvariational inference and Markov chain Monte Carlo. We show that our algorithms\ncan provably remove the influence of single datums on the learned models.\nTheoretical analysis demonstrates that our algorithms have guaranteed\ngeneralizability. Experiments of Gaussian mixture models on the synthetic\ndataset and Bayesian neural networks on the real-world data verify the\nfeasibility of our methods. The source code package is available at\n\\url{https://github.com/fshp971/BIF}.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 09:52:51 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 09:05:14 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Fu", "Shaopeng", ""], ["He", "Fengxiang", ""], ["Xu", "Yue", ""], ["Tao", "Dacheng", ""]]}, {"id": "2101.06471", "submitter": "Likang Wu", "authors": "Likang Wu, Zhi Li, Hongke Zhao, Qi Liu, Jun Wang, Mengdi Zhang, Enhong\n  Chen", "title": "Learning the Implicit Semantic Representation on Graph-Structured Data", "comments": "16 pages, DASFAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing representation learning methods in graph convolutional networks are\nmainly designed by describing the neighborhood of each node as a perceptual\nwhole, while the implicit semantic associations behind highly complex\ninteractions of graphs are largely unexploited. In this paper, we propose a\nSemantic Graph Convolutional Networks (SGCN) that explores the implicit\nsemantics by learning latent semantic-paths in graphs. In previous work, there\nare explorations of graph semantics via meta-paths. However, these methods\nmainly rely on explicit heterogeneous information that is hard to be obtained\nin a large amount of graph-structured data. SGCN first breaks through this\nrestriction via leveraging the semantic-paths dynamically and automatically\nduring the node aggregating process. To evaluate our idea, we conduct\nsufficient experiments on several standard datasets, and the empirical results\nshow the superior performance of our model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 16:18:43 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wu", "Likang", ""], ["Li", "Zhi", ""], ["Zhao", "Hongke", ""], ["Liu", "Qi", ""], ["Wang", "Jun", ""], ["Zhang", "Mengdi", ""], ["Chen", "Enhong", ""]]}, {"id": "2101.06475", "submitter": "Maxwell Aladago", "authors": "Maxwell Mbabilla Aladago and Lorenzo Torresani", "title": "Slot Machines: Discovering Winning Combinations of Random Weights in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In contrast to traditional weight optimization in a continuous space, we\ndemonstrate the existence of effective random networks whose weights are never\nupdated. By selecting a weight among a fixed set of random values for each\nindividual connection, our method uncovers combinations of random weights that\nmatch the performance of traditionally-trained networks of the same capacity.\nWe refer to our networks as \"slot machines\" where each reel (connection)\ncontains a fixed set of symbols (random values). Our backpropagation algorithm\n\"spins\" the reels to seek \"winning\" combinations, i.e., selections of random\nweight values that minimize the given loss. Quite surprisingly, we find that\nallocating just a few random values to each connection (e.g., 8 values per\nconnection) yields highly competitive combinations despite being dramatically\nmore constrained compared to traditionally learned weights. Moreover,\nfinetuning these combinations often improves performance over the trained\nbaselines. A randomly initialized VGG-19 with 8 values per connection contains\na combination that achieves 91% test accuracy on CIFAR-10. Our method also\nachieves an impressive performance of 98.2% on MNIST for neural networks\ncontaining only random weights.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 16:56:48 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 05:27:33 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 15:10:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Aladago", "Maxwell Mbabilla", ""], ["Torresani", "Lorenzo", ""]]}, {"id": "2101.06484", "submitter": "Hamed Jelodar", "authors": "Hamed Jelodar, Rita Orji, Stan Matwin, Swarna Weerasinghe, Oladapo\n  Oyebode, Yongli Wang", "title": "Artificial Intelligence for Emotion-Semantic Trending and People Emotion\n  Detection During COVID-19 Social Isolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Taking advantage of social media platforms, such as Twitter, this paper\nprovides an effective framework for emotion detection among those who are\nquarantined. Early detection of emotional feelings and their trends help\nimplement timely intervention strategies. Given the limitations of medical\ndiagnosis of early emotional change signs during the quarantine period,\nartificial intelligence models provide effective mechanisms in uncovering early\nsigns, symptoms and escalating trends. Novelty of the approach presented herein\nis a multitask methodological framework of text data processing, implemented as\na pipeline for meaningful emotion detection and analysis, based on the\nPlutchik/Ekman approach to emotion detection and trend detection. We present an\nevaluation of the framework and a pilot system. Results of confirm the\neffectiveness of the proposed framework for topic trends and emotion detection\nof COVID-19 tweets. Our findings revealed Stay-At-Home restrictions result in\npeople expressing on twitter both negative and positive emotional semantics.\nSemantic trends of safety issues related to staying at home rapidly decreased\nwithin the 28 days and also negative feelings related to friends dying and\nquarantined life increased in some days. These findings have potential to\nimpact public health policy decisions through monitoring trends of emotional\nfeelings of those who are quarantined. The framework presented here has\npotential to assist in such monitoring by using as an online emotion detection\ntool kit.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 17:20:33 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Jelodar", "Hamed", ""], ["Orji", "Rita", ""], ["Matwin", "Stan", ""], ["Weerasinghe", "Swarna", ""], ["Oyebode", "Oladapo", ""], ["Wang", "Yongli", ""]]}, {"id": "2101.06490", "submitter": "Hunter Johnson", "authors": "Hunter R Johnson", "title": "Binary strings of finite VC dimension", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.FL math.CO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Any binary string can be associated with a unary predicate $P$ on\n$\\mathbb{N}$. In this paper we investigate subsets named by a predicate $P$\nsuch that the relation $P(x+y)$ has finite VC dimension. This provides a\nmeasure of complexity for binary strings with different properties than the\nstandard string complexity function (based on diversity of substrings). We\nprove that strings of bounded VC dimension are meagre in the topology of the\nreals, provide simple rules for bounding the VC dimension of a string, and show\nthat the bi-infinite strings of VC dimension $d$ are a non-sofic shift space.\nAdditionally we characterize the irreducible strings of low VC dimension (0,1\nand 2), and provide connections to mathematical logic.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 17:51:52 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 14:00:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Johnson", "Hunter R", ""]]}, {"id": "2101.06511", "submitter": "Yigit Alparslan", "authors": "Yigit Alparslan, Ethan Jacob Moyer, Isamu Mclean Isozaki, Daniel\n  Schwartz, Adam Dunlop, Shesh Dave, Edward Kim", "title": "Towards Searching Efficient and Accurate Neural Network Architectures in\n  Binary Classification Problems", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, deep neural networks have had great success in machine\nlearning and pattern recognition. Architecture size for a neural network\ncontributes significantly to the success of any neural network. In this study,\nwe optimize the selection process by investigating different search algorithms\nto find a neural network architecture size that yields the highest accuracy. We\napply binary search on a very well-defined binary classification network search\nspace and compare the results to those of linear search. We also propose how to\nrelax some of the assumptions regarding the dataset so that our solution can be\ngeneralized to any binary classification problem. We report a 100-fold running\ntime improvement over the naive linear search when we apply the binary search\nmethod to our datasets in order to find the best architecture candidate. By\nfinding the optimal architecture size for any binary classification problem\nquickly, we hope that our research contributes to discovering intelligent\nalgorithms for optimizing architecture size selection in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 20:00:38 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Alparslan", "Yigit", ""], ["Moyer", "Ethan Jacob", ""], ["Isozaki", "Isamu Mclean", ""], ["Schwartz", "Daniel", ""], ["Dunlop", "Adam", ""], ["Dave", "Shesh", ""], ["Kim", "Edward", ""]]}, {"id": "2101.06518", "submitter": "Yigit Alparslan", "authors": "Yigit Alparslan, Ethan Jacob Moyer, Edward Kim", "title": "Evaluating Online and Offline Accuracy Traversal Algorithms for\n  k-Complete Neural Network Architectures", "comments": "8 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Architecture sizes for neural networks have been studied widely and several\nsearch methods have been offered to find the best architecture size in the\nshortest amount of time possible. In this paper, we study compact neural\nnetwork architectures for binary classification and investigate improvements in\nspeed and accuracy when favoring overcomplete architecture candidates that have\na very high-dimensional representation of the input. We hypothesize that an\novercomplete model architecture that creates a relatively high-dimensional\nrepresentation of the input will be not only be more accurate but would also be\neasier and faster to find. In an NxM search space, we propose an online\ntraversal algorithm that finds the best architecture candidate in O(1) time for\nbest case and O(N) amortized time for average case for any compact binary\nclassification problem by using k-completeness as heuristics in our search. The\ntwo other offline search algorithms we implement are brute force traversal and\ndiagonal traversal, which both find the best architecture candidate in O(NxM)\ntime. We compare our new algorithm to brute force and diagonal searching as a\nbaseline and report search time improvement of 52.1% over brute force and of\n15.4% over diagonal search to find the most accurate neural network\narchitecture when given the same dataset. In all cases discussed in the paper,\nour online traversal algorithm can find an accurate, if not better,\narchitecture in significantly shorter amount of time.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 20:37:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Alparslan", "Yigit", ""], ["Moyer", "Ethan Jacob", ""], ["Kim", "Edward", ""]]}, {"id": "2101.06541", "submitter": "Kelvin Wong", "authors": "Shuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye\n  Ren, Raquel Urtasun", "title": "SceneGen: Learning to Generate Realistic Traffic Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of generating realistic traffic scenes automatically.\nExisting methods typically insert actors into the scene according to a set of\nhand-crafted heuristics and are limited in their ability to model the true\ncomplexity and diversity of real traffic scenes, thus inducing a content gap\nbetween synthesized traffic scenes versus real ones. As a result, existing\nsimulators lack the fidelity necessary to train and test self-driving vehicles.\nTo address this limitation, we present SceneGen, a neural autoregressive model\nof traffic scenes that eschews the need for rules and heuristics. In\nparticular, given the ego-vehicle state and a high definition map of\nsurrounding area, SceneGen inserts actors of various classes into the scene and\nsynthesizes their sizes, orientations, and velocities. We demonstrate on two\nlarge-scale datasets SceneGen's ability to faithfully model distributions of\nreal traffic scenes. Moreover, we show that SceneGen coupled with sensor\nsimulation can be used to train perception models that generalize to the real\nworld.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 22:51:43 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Tan", "Shuhan", ""], ["Wong", "Kelvin", ""], ["Wang", "Shenlong", ""], ["Manivasagam", "Sivabalan", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06543", "submitter": "Yun Chen", "authors": "Yun Chen, Frieda Rong, Shivam Duggal, Shenlong Wang, Xinchen Yan,\n  Sivabalan Manivasagam, Shangjie Xue, Ersin Yumer, Raquel Urtasun", "title": "GeoSim: Realistic Video Simulation via Geometry-Aware Composition for\n  Self-Driving", "comments": "Accepted by CVPR 2021 as Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable sensor simulation is an important yet challenging open problem for\nsafety-critical domains such as self-driving. Current works in image simulation\neither fail to be photorealistic or do not model the 3D environment and the\ndynamic objects within, losing high-level control and physical realism. In this\npaper, we present GeoSim, a geometry-aware image composition process which\nsynthesizes novel urban driving scenarios by augmenting existing images with\ndynamic objects extracted from other scenes and rendered at novel poses.\nTowards this goal, we first build a diverse bank of 3D objects with both\nrealistic geometry and appearance from sensor data. During simulation, we\nperform a novel geometry-aware simulation-by-composition procedure which 1)\nproposes plausible and realistic object placements into a given scene, 2)\nrender novel views of dynamic objects from the asset bank, and 3) composes and\nblends the rendered image segments. The resulting synthetic images are\nrealistic, traffic-aware, and geometrically consistent, allowing our approach\nto scale to complex use cases. We demonstrate two such important applications:\nlong-range realistic video simulation across multiple camera sensors, and\nsynthetic data generation for data augmentation on downstream segmentation\ntasks. Please check https://tmux.top/publication/geosim/ for high-resolution\nvideo results.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 23:00:33 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 16:06:21 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 05:19:19 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chen", "Yun", ""], ["Rong", "Frieda", ""], ["Duggal", "Shivam", ""], ["Wang", "Shenlong", ""], ["Yan", "Xinchen", ""], ["Manivasagam", "Sivabalan", ""], ["Xue", "Shangjie", ""], ["Yumer", "Ersin", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06547", "submitter": "Sergio Casas", "authors": "Alexander Cui, Sergio Casas, Abbas Sadat, Renjie Liao, Raquel Urtasun", "title": "LookOut: Diverse Multi-Future Prediction and Planning for Self-Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present LookOut, a novel autonomy system that perceives the\nenvironment, predicts a diverse set of futures of how the scene might unroll\nand estimates the trajectory of the SDV by optimizing a set of contingency\nplans over these future realizations. In particular, we learn a diverse joint\ndistribution over multi-agent future trajectories in a traffic scene that\ncovers a wide range of future modes with high sample efficiency while\nleveraging the expressive power of generative models. Unlike previous work in\ndiverse motion forecasting, our diversity objective explicitly rewards sampling\nfuture scenarios that require distinct reactions from the self-driving vehicle\nfor improved safety. Our contingency planner then finds comfortable and\nnon-conservative trajectories that ensure safe reactions to a wide range of\nfuture scenarios. Through extensive evaluations, we show that our model\ndemonstrates significantly more diverse and sample-efficient motion forecasting\nin a large-scale self-driving dataset as well as safer and less-conservative\nmotion plans in long-term closed-loop simulations when compared to current\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 23:19:22 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 16:30:19 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 18:47:54 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Cui", "Alexander", ""], ["Casas", "Sergio", ""], ["Sadat", "Abbas", ""], ["Liao", "Renjie", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06549", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat,\n  Sergio Casas, Mengye Ren, Raquel Urtasun", "title": "AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As self-driving systems become better, simulating scenarios where the\nautonomy stack may fail becomes more important. Traditionally, those scenarios\nare generated for a few scenes with respect to the planning module that takes\nground-truth actor states as input. This does not scale and cannot identify all\npossible autonomy failures, such as perception failures due to occlusion. In\nthis paper, we propose AdvSim, an adversarial framework to generate\nsafety-critical scenarios for any LiDAR-based autonomy system. Given an initial\ntraffic scenario, AdvSim modifies the actors' trajectories in a physically\nplausible manner and updates the LiDAR sensor data to match the perturbed\nworld. Importantly, by simulating directly from sensor data, we obtain\nadversarial scenarios that are safety-critical for the full autonomy stack. Our\nexperiments show that our approach is general and can identify thousands of\nsemantically meaningful safety-critical scenarios for a wide range of modern\nself-driving systems. Furthermore, we show that the robustness and safety of\nthese systems can be further improved by training them with scenarios generated\nby AdvSim.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 23:23:12 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 03:42:18 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wang", "Jingkang", ""], ["Pun", "Ava", ""], ["Tu", "James", ""], ["Manivasagam", "Sivabalan", ""], ["Sadat", "Abbas", ""], ["Casas", "Sergio", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06557", "submitter": "Simon Suo", "authors": "Simon Suo, Sebastian Regalado, Sergio Casas, Raquel Urtasun", "title": "TrafficSim: Learning to Simulate Realistic Multi-Agent Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulation has the potential to massively scale evaluation of self-driving\nsystems enabling rapid development as well as safe deployment. To close the gap\nbetween simulation and the real world, we need to simulate realistic\nmulti-agent behaviors. Existing simulation environments rely on heuristic-based\nmodels that directly encode traffic rules, which cannot capture irregular\nmaneuvers (e.g., nudging, U-turns) and complex interactions (e.g., yielding,\nmerging). In contrast, we leverage real-world data to learn directly from human\ndemonstration and thus capture a more diverse set of actor behaviors. To this\nend, we propose TrafficSim, a multi-agent behavior model for realistic traffic\nsimulation. In particular, we leverage an implicit latent variable model to\nparameterize a joint actor policy that generates socially-consistent plans for\nall actors in the scene jointly. To learn a robust policy amenable for long\nhorizon simulation, we unroll the policy in training and optimize through the\nfully differentiable simulation across time. Our learning objective\nincorporates both human demonstrations as well as common sense. We show\nTrafficSim generates significantly more realistic and diverse traffic scenarios\nas compared to a diverse set of baselines. Notably, we can exploit trajectories\ngenerated by TrafficSim as effective data augmentation for training better\nmotion planner.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 00:29:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suo", "Simon", ""], ["Regalado", "Sebastian", ""], ["Casas", "Sergio", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06561", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Gabriel Stanovsky, Jonathan Bragg, Nicholas Lourie,\n  Jungo Kasai, Yejin Choi, Noah A. Smith, Daniel S. Weld", "title": "GENIE: A Leaderboard for Human-in-the-Loop Evaluation of Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leaderboards have eased model development for many NLP datasets by\nstandardizing their evaluation and delegating it to an independent external\nrepository. Their adoption, however, is so far limited to tasks that can be\nreliably evaluated in an automatic manner. This work introduces GENIE, an\nextensible human evaluation leaderboard, which brings the ease of leaderboards\nto text generation tasks. GENIE automatically posts leaderboard submissions to\ncrowdsourcing platforms asking human annotators to evaluate them on various\naxes (e.g., correctness, conciseness, fluency) and compares their answers to\nvarious automatic metrics. We introduce several datasets in English to GENIE,\nrepresenting four core challenges in text generation: machine translation,\nsummarization, commonsense reasoning, and machine comprehension. We provide\nformal granular evaluation metrics and identify areas for future research. We\nmake GENIE publicly available and hope that it will spur progress in language\ngeneration models as well as their automatic and manual evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 00:40:47 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 19:26:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Khashabi", "Daniel", ""], ["Stanovsky", "Gabriel", ""], ["Bragg", "Jonathan", ""], ["Lourie", "Nicholas", ""], ["Kasai", "Jungo", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2101.06569", "submitter": "Yankai Chen", "authors": "Yankai Chen and Yaozu Wu and Shicheng Ma and Irwin King", "title": "A Literature Review of Recent Graph Embedding Techniques for Biomedical\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of biomedical software and hardware, a large\namount of relational data interlinking genes, proteins, chemical components,\ndrugs, diseases, and symptoms has been collected for modern biomedical\nresearch. Many graph-based learning methods have been proposed to analyze such\ntype of data, giving a deeper insight into the topology and knowledge behind\nthe biomedical data, which greatly benefit to both academic research and\nindustrial application for human healthcare. However, the main difficulty is\nhow to handle high dimensionality and sparsity of the biomedical graphs.\nRecently, graph embedding methods provide an effective and efficient way to\naddress the above issues. It converts graph-based data into a low dimensional\nvector space where the graph structural properties and knowledge information\nare well preserved. In this survey, we conduct a literature review of recent\ndevelopments and trends in applying graph embedding methods for biomedical\ndata. We also introduce important applications and tasks in the biomedical\ndomain as well as associated public biomedical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 01:53:50 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 10:21:55 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Chen", "Yankai", ""], ["Wu", "Yaozu", ""], ["Ma", "Shicheng", ""], ["King", "Irwin", ""]]}, {"id": "2101.06573", "submitter": "Stefan Maetschke", "authors": "Stefan Maetschke and David Martinez Iraola and Pieter Barnard and\n  Elaheh ShafieiBavani and Peter Zhong and Ying Xu and Antonio Jimeno Yepes", "title": "Understanding in Artificial Intelligence", "comments": "28 pages, 282 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Artificial Intelligence (AI) methods, most based on deep learning,\nhave facilitated progress in several fields, including computer vision and\nnatural language understanding. The progress of these AI methods is measured\nusing benchmarks designed to solve challenging tasks, such as visual question\nanswering. A question remains of how much understanding is leveraged by these\nmethods and how appropriate are the current benchmarks to measure understanding\ncapabilities. To answer these questions, we have analysed existing benchmarks\nand their understanding capabilities, defined by a set of understanding\ncapabilities, and current research streams. We show how progress has been made\nin benchmark development to measure understanding capabilities of AI methods\nand we review as well how current methods develop understanding capabilities.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 02:29:50 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Maetschke", "Stefan", ""], ["Iraola", "David Martinez", ""], ["Barnard", "Pieter", ""], ["ShafieiBavani", "Elaheh", ""], ["Zhong", "Peter", ""], ["Xu", "Ying", ""], ["Yepes", "Antonio Jimeno", ""]]}, {"id": "2101.06582", "submitter": "Yiwen Han", "authors": "Yiwen Han and Shihao Shen and Xiaofei Wang and Shiqiang Wang and\n  Victor C.M. Leung", "title": "Tailored Learning-Based Scheduling for Kubernetes-Oriented Edge-Cloud\n  System", "comments": "IEEE INFOCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kubernetes (k8s) has the potential to merge the distributed edge and the\ncloud but lacks a scheduling framework specifically for edge-cloud systems.\nBesides, the hierarchical distribution of heterogeneous resources and the\ncomplex dependencies among requests and resources make the modeling and\nscheduling of k8s-oriented edge-cloud systems particularly sophisticated. In\nthis paper, we introduce KaiS, a learning-based scheduling framework for such\nedge-cloud systems to improve the long-term throughput rate of request\nprocessing. First, we design a coordinated multi-agent actor-critic algorithm\nto cater to decentralized request dispatch and dynamic dispatch spaces within\nthe edge cluster. Second, for diverse system scales and structures, we use\ngraph neural networks to embed system state information, and combine the\nembedding results with multiple policy networks to reduce the orchestration\ndimensionality by stepwise scheduling. Finally, we adopt a two-time-scale\nscheduling mechanism to harmonize request dispatch and service orchestration,\nand present the implementation design of deploying the above algorithms\ncompatible with native k8s components. Experiments using real workload traces\nshow that KaiS can successfully learn appropriate scheduling policies,\nirrespective of request arrival patterns and system scales. Moreover, KaiS can\nenhance the average system throughput rate by 14.3% while reducing scheduling\ncost by 34.7% compared to baselines.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 03:45:25 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Han", "Yiwen", ""], ["Shen", "Shihao", ""], ["Wang", "Xiaofei", ""], ["Wang", "Shiqiang", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "2101.06590", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Mengye Ren, Ilija Bogunovic, Yuwen Xiong, Raquel\n  Urtasun", "title": "Cost-Efficient Online Hyperparameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on hyperparameters optimization (HPO) has shown the possibility\nof training certain hyperparameters together with regular parameters. However,\nthese online HPO algorithms still require running evaluation on a set of\nvalidation examples at each training step, steeply increasing the training\ncost. To decide when to query the validation loss, we model online HPO as a\ntime-varying Bayesian optimization problem, on top of which we propose a novel\n\\textit{costly feedback} setting to capture the concept of the query cost.\nUnder this setting, standard algorithms are cost-inefficient as they evaluate\non the validation set at every round. In contrast, the cost-efficient GP-UCB\nalgorithm proposed in this paper queries the unknown function only when the\nmodel is less confident about current decisions. We evaluate our proposed\nalgorithm by tuning hyperparameters online for VGG and ResNet on CIFAR-10 and\nImageNet100. Our proposed online HPO algorithm reaches human expert-level\nperformance within a single run of the experiment, while incurring only modest\ncomputational overhead compared to regular training.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 04:55:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wang", "Jingkang", ""], ["Ren", "Mengye", ""], ["Bogunovic", "Ilija", ""], ["Xiong", "Yuwen", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06599", "submitter": "Pan Zibin", "authors": "Pan Zibin", "title": "Performance Analysis and Improvement of Parallel Differential Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential evolution (DE) is an effective global evolutionary optimization\nalgorithm using to solve global optimization problems mainly in a continuous\ndomain. In this field, researchers pay more attention to improving the\ncapability of DE to find better global solutions, however, the computational\nperformance of DE is also a very interesting aspect especially when the problem\nscale is quite large. Firstly, this paper analyzes the design of parallel\ncomputation of DE which can easily be executed in Math Kernel Library (MKL) and\nCompute Unified Device Architecture (CUDA). Then the essence of the exponential\ncrossover operator is described and we point out that it cannot be used for\nbetter parallel computation. Later, we propose a new exponential crossover\noperator (NEC) that can be executed parallelly with MKL/CUDA. Next, the\nextended experiments show that the new crossover operator can speed up DE\ngreatly. In the end, we test the new parallel DE structure, illustrating that\nthe former is much faster.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 05:57:12 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Zibin", "Pan", ""]]}, {"id": "2101.06618", "submitter": "Zhilin Lu", "authors": "Zhilin Lu, Hongyi He, Zhengyang Duan, Jintao Wang, Jian Song", "title": "Aggregated Network for Massive MIMO CSI Feedback", "comments": "This version is only a draft of the final paper `Binarized Aggregated\n  Network with Quantization: Flexible Deep Learning Deployment for CSI Feedback\n  in Massive MIMO System`, which has been uploaded as arXiv:2105.00354. This\n  incomplete version has some performance error, therefore it should be\n  withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In frequency division duplexing (FDD) mode, it is necessary to send the\nchannel state information (CSI) from user equipment to base station. The\ndownlink CSI is essential for the massive multiple-input multiple-output (MIMO)\nsystem to acquire the potential gain. Recently, deep learning is widely adopted\nto massive MIMO CSI feedback task and proved to be effective compared with\ntraditional compressed sensing methods. In this paper, a novel network named\nACRNet is designed to boost the feedback performance with network aggregation\nand parametric RuLU activation. Moreover, valid approach to expand the network\narchitecture in exchange of better performance is first discussed in CSI\nfeedback task. Experiments show that ACRNet outperforms loads of previous\nstate-of-the-art feedback networks without any extra information.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 08:19:40 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 09:51:23 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Lu", "Zhilin", ""], ["He", "Hongyi", ""], ["Duan", "Zhengyang", ""], ["Wang", "Jintao", ""], ["Song", "Jian", ""]]}, {"id": "2101.06619", "submitter": "Ruiyang Xu", "authors": "Ruiyang Xu, Karl Lieberherr", "title": "Solving QSAT problems with neural MCTS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent achievements from AlphaZero using self-play has shown remarkable\nperformance on several board games. It is plausible to think that self-play,\nstarting from zero knowledge, can gradually approximate a winning strategy for\ncertain two-player games after an amount of training. In this paper, we try to\nleverage the computational power of neural Monte Carlo Tree Search (neural\nMCTS), the core algorithm from AlphaZero, to solve Quantified Boolean Formula\nSatisfaction (QSAT) problems, which are PSPACE complete. Knowing that every\nQSAT problem is equivalent to a QSAT game, the game outcome can be used to\nderive the solutions of the original QSAT problems. We propose a way to encode\nQuantified Boolean Formulas (QBFs) as graphs and apply a graph neural network\n(GNN) to embed the QBFs into the neural MCTS. After training, an off-the-shelf\nQSAT solver is used to evaluate the performance of the algorithm. Our result\nshows that, for problems within a limited size, the algorithm learns to solve\nthe problem correctly merely from self-play.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 08:20:07 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Xu", "Ruiyang", ""], ["Lieberherr", "Karl", ""]]}, {"id": "2101.06634", "submitter": "Ardhendu Behera", "authors": "Ardhendu Behera, Zachary Wharton, Morteza Ghahremani, Swagat Kumar,\n  Nik Bessis", "title": "Regional Attention Network (RAN) for Head Pose and Fine-grained Gesture\n  Recognition", "comments": "This manuscript is the accepted version of the published paper in\n  IEEE Transaction on Affective Computing", "journal-ref": "IEEE Transaction on Affective Computing 2020", "doi": "10.1109/TAFFC.2020.3031841", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Affect is often expressed via non-verbal body language such as\nactions/gestures, which are vital indicators for human behaviors. Recent\nstudies on recognition of fine-grained actions/gestures in monocular images\nhave mainly focused on modeling spatial configuration of body parts\nrepresenting body pose, human-objects interactions and variations in local\nappearance. The results show that this is a brittle approach since it relies on\naccurate body parts/objects detection. In this work, we argue that there exist\nlocal discriminative semantic regions, whose \"informativeness\" can be evaluated\nby the attention mechanism for inferring fine-grained gestures/actions. To this\nend, we propose a novel end-to-end \\textbf{Regional Attention Network (RAN)},\nwhich is a fully Convolutional Neural Network (CNN) to combine multiple\ncontextual regions through attention mechanism, focusing on parts of the images\nthat are most relevant to a given task. Our regions consist of one or more\nconsecutive cells and are adapted from the strategies used in computing HOG\n(Histogram of Oriented Gradient) descriptor. The model is extensively evaluated\non ten datasets belonging to 3 different scenarios: 1) head pose recognition,\n2) drivers state recognition, and 3) human action and facial expression\nrecognition. The proposed approach outperforms the state-of-the-art by a\nconsiderable margin in different metrics.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 10:14:28 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Behera", "Ardhendu", ""], ["Wharton", "Zachary", ""], ["Ghahremani", "Morteza", ""], ["Kumar", "Swagat", ""], ["Bessis", "Nik", ""]]}, {"id": "2101.06635", "submitter": "Ardhendu Behera", "authors": "Ardhendu Behera, Zachary Wharton, Pradeep Hewage, Asish Bera", "title": "Context-aware Attentional Pooling (CAP) for Fine-grained Visual\n  Classification", "comments": "Extended version of the accepted paper in 35th AAAI Conference on\n  Artificial Intelligence 2021", "journal-ref": "35th AAAI Conference on Artificial Intelligence 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional neural networks (CNNs) have shown a strong ability in\nmining discriminative object pose and parts information for image recognition.\nFor fine-grained recognition, context-aware rich feature representation of\nobject/scene plays a key role since it exhibits a significant variance in the\nsame subcategory and subtle variance among different subcategories. Finding the\nsubtle variance that fully characterizes the object/scene is not\nstraightforward. To address this, we propose a novel context-aware attentional\npooling (CAP) that effectively captures subtle changes via sub-pixel gradients,\nand learns to attend informative integral regions and their importance in\ndiscriminating different subcategories without requiring the bounding-box\nand/or distinguishable part annotations. We also introduce a novel feature\nencoding by considering the intrinsic consistency between the informativeness\nof the integral regions and their spatial structures to capture the semantic\ncorrelation among them. Our approach is simple yet extremely effective and can\nbe easily applied on top of a standard classification backbone network. We\nevaluate our approach using six state-of-the-art (SotA) backbone networks and\neight benchmark datasets. Our method significantly outperforms the SotA\napproaches on six datasets and is very competitive with the remaining two.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 10:15:02 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Behera", "Ardhendu", ""], ["Wharton", "Zachary", ""], ["Hewage", "Pradeep", ""], ["Bera", "Asish", ""]]}, {"id": "2101.06636", "submitter": "Ardhendu Behera", "authors": "Zachary Wharton, Ardhendu Behera, Yonghuai Liu, Nik Bessis", "title": "Coarse Temporal Attention Network (CTA-Net) for Driver's Activity\n  Recognition", "comments": "Extended version of the accepted WACV 2021", "journal-ref": "Winter Conference on Applications of Computer Vision (WACV 2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is significant progress in recognizing traditional human activities\nfrom videos focusing on highly distinctive actions involving discriminative\nbody movements, body-object and/or human-human interactions. Driver's\nactivities are different since they are executed by the same subject with\nsimilar body parts movements, resulting in subtle changes. To address this, we\npropose a novel framework by exploiting the spatiotemporal attention to model\nthe subtle changes. Our model is named Coarse Temporal Attention Network\n(CTA-Net), in which coarse temporal branches are introduced in a trainable\nglimpse network. The goal is to allow the glimpse to capture high-level\ntemporal relationships, such as 'during', 'before' and 'after' by focusing on a\nspecific part of a video. These branches also respect the topology of the\ntemporal dynamics in the video, ensuring that different branches learn\nmeaningful spatial and temporal changes. The model then uses an innovative\nattention mechanism to generate high-level action specific contextual\ninformation for activity recognition by exploring the hidden states of an LSTM.\nThe attention mechanism helps in learning to decide the importance of each\nhidden state for the recognition task by weighing them when constructing the\nrepresentation of the video. Our approach is evaluated on four publicly\naccessible datasets and significantly outperforms the state-of-the-art by a\nconsiderable margin with only RGB video as input.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 10:15:37 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wharton", "Zachary", ""], ["Behera", "Ardhendu", ""], ["Liu", "Yonghuai", ""], ["Bessis", "Nik", ""]]}, {"id": "2101.06644", "submitter": "Theophile Sautory", "authors": "Theophile Sautory, Nuri Cingillioglu, Alessandra Russo", "title": "HySTER: A Hybrid Spatio-Temporal Event Reasoner", "comments": "Preprint accepted by the 35th AAAI Conference on Artificial\n  Intelligence (AAAI-21) Workshop on Hybrid Artificial Intelligence (HAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Video Question Answering (VideoQA) consists in answering natural\nlanguage questions about a video and serves as a proxy to evaluate the\nperformance of a model in scene sequence understanding. Most methods designed\nfor VideoQA up-to-date are end-to-end deep learning architectures which\nstruggle at complex temporal and causal reasoning and provide limited\ntransparency in reasoning steps. We present the HySTER: a Hybrid\nSpatio-Temporal Event Reasoner to reason over physical events in videos. Our\nmodel leverages the strength of deep learning methods to extract information\nfrom video frames with the reasoning capabilities and explainability of\nsymbolic artificial intelligence in an answer set programming framework. We\ndefine a method based on general temporal, causal and physics rules which can\nbe transferred across tasks. We apply our model to the CLEVRER dataset and\ndemonstrate state-of-the-art results in question answering accuracy. This work\nsets the foundations for the incorporation of inductive logic programming in\nthe field of VideoQA.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 11:07:17 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sautory", "Theophile", ""], ["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "2101.06704", "submitter": "Xingjun Ma", "authors": "Nodens Koren, Qiuhong Ke, Yisen Wang, James Bailey, Xingjun Ma", "title": "Adversarial Interaction Attack: Fooling AI to Misinterpret Human\n  Intentions", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the actions of both humans and artificial intelligence (AI)\nagents is important before modern AI systems can be fully integrated into our\ndaily life. In this paper, we show that, despite their current huge success,\ndeep learning based AI systems can be easily fooled by subtle adversarial noise\nto misinterpret the intention of an action in interaction scenarios. Based on a\ncase study of skeleton-based human interactions, we propose a novel adversarial\nattack on interactions, and demonstrate how DNN-based interaction models can be\ntricked to predict the participants' reactions in unexpected ways. From a\nbroader perspective, the scope of our proposed attack method is not confined to\nproblems related to skeleton data but can also be extended to any type of\nproblems involving sequential regressions. Our study highlights potential risks\nin the interaction loop with AI and humans, which need to be carefully\naddressed when deploying AI systems in safety-critical applications.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 16:23:20 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Koren", "Nodens", ""], ["Ke", "Qiuhong", ""], ["Wang", "Yisen", ""], ["Bailey", "James", ""], ["Ma", "Xingjun", ""]]}, {"id": "2101.06741", "submitter": "Mateus Roder", "authors": "Mateus Roder, Gustavo H. de Rosa, Victor Hugo C. de Albuquerque,\n  Andr\\'e L. D. Rossi, Jo\\~ao P. Papa", "title": "Energy-based Dropout in Restricted Boltzmann Machines: Why not go random", "comments": null, "journal-ref": null, "doi": "10.1109/TETCI.2020.3043764", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning architectures have been widely fostered throughout the last\nyears, being used in a wide range of applications, such as object recognition,\nimage reconstruction, and signal processing. Nevertheless, such models suffer\nfrom a common problem known as overfitting, which limits the network from\npredicting unseen data effectively. Regularization approaches arise in an\nattempt to address such a shortcoming. Among them, one can refer to the\nwell-known Dropout, which tackles the problem by randomly shutting down a set\nof neurons and their connections according to a certain probability. Therefore,\nthis approach does not consider any additional knowledge to decide which units\nshould be disconnected. In this paper, we propose an energy-based Dropout\n(E-Dropout) that makes conscious decisions whether a neuron should be dropped\nor not. Specifically, we design this regularization method by correlating\nneurons and the model's energy as an importance level for further applying it\nto energy-based models, such as Restricted Boltzmann Machines (RBMs). The\nexperimental results over several benchmark datasets revealed the proposed\napproach's suitability compared to the traditional Dropout and the standard\nRBMs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 18:21:05 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Roder", "Mateus", ""], ["de Rosa", "Gustavo H.", ""], ["de Albuquerque", "Victor Hugo C.", ""], ["Rossi", "Andr\u00e9 L. D.", ""], ["Papa", "Jo\u00e3o P.", ""]]}, {"id": "2101.06742", "submitter": "Simon Suo", "authors": "Shenlong Wang, Simon Suo, Wei-Chiu Ma, Andrei Pokrovsky, Raquel\n  Urtasun", "title": "Deep Parametric Continuous Convolutional Neural Networks", "comments": "Accepted by CVPR 2018", "journal-ref": null, "doi": "10.1109/CVPR.2018.00274", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard convolutional neural networks assume a grid structured input is\navailable and exploit discrete convolutions as their fundamental building\nblocks. This limits their applicability to many real-world applications. In\nthis paper we propose Parametric Continuous Convolution, a new learnable\noperator that operates over non-grid structured data. The key idea is to\nexploit parameterized kernel functions that span the full continuous vector\nspace. This generalization allows us to learn over arbitrary data structures as\nlong as their support relationship is computable. Our experiments show\nsignificant improvement over the state-of-the-art in point cloud segmentation\nof indoor and outdoor scenes, and lidar motion estimation of driving scenes.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 18:28:23 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wang", "Shenlong", ""], ["Suo", "Simon", ""], ["Ma", "Wei-Chiu", ""], ["Pokrovsky", "Andrei", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06749", "submitter": "Mateus Roder", "authors": "Mateus Roder, Leandro A. Passos, Luiz Carlos Felix Ribeiro, Clayton\n  Pereira, Jo\\~ao Paulo Papa", "title": "A Layer-Wise Information Reinforcement Approach to Improve Learning in\n  Deep Belief Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61401-0_22", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of deep learning, the number of works proposing new methods\nor improving existent ones has grown exponentially in the last years. In this\nscenario, \"very deep\" models were emerging, once they were expected to extract\nmore intrinsic and abstract features while supporting a better performance.\nHowever, such models suffer from the gradient vanishing problem, i.e.,\nbackpropagation values become too close to zero in their shallower layers,\nultimately causing learning to stagnate. Such an issue was overcome in the\ncontext of convolution neural networks by creating \"shortcut connections\"\nbetween layers, in a so-called deep residual learning framework. Nonetheless, a\nvery popular deep learning technique called Deep Belief Network still suffers\nfrom gradient vanishing when dealing with discriminative tasks. Therefore, this\npaper proposes the Residual Deep Belief Network, which considers the\ninformation reinforcement layer-by-layer to improve the feature extraction and\nknowledge retaining, that support better discriminative performance.\nExperiments conducted over three public datasets demonstrate its robustness\nconcerning the task of binary image classification.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 18:53:18 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Roder", "Mateus", ""], ["Passos", "Leandro A.", ""], ["Ribeiro", "Luiz Carlos Felix", ""], ["Pereira", "Clayton", ""], ["Papa", "Jo\u00e3o Paulo", ""]]}, {"id": "2101.06768", "submitter": "Pascal Van Hentenryck", "authors": "Minas Chatzos and Terrence W.K. Mak and Pascal Van Hentenryck", "title": "Spatial Network Decomposition for Fast and Scalable AC-OPF Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel machine-learning approach for predicting AC-OPF\nsolutions that features a fast and scalable training. It is motivated by the\ntwo critical considerations: (1) the fact that topology optimization and the\nstochasticity induced by renewable energy sources may lead to fundamentally\ndifferent AC-OPF instances; and (2) the significant training time needed by\nexisting machine-learning approaches for predicting AC-OPF. The proposed\napproach is a 2-stage methodology that exploits a spatial decomposition of the\npower network that is viewed as a set of regions. The first stage learns to\npredict the flows and voltages on the buses and lines coupling the regions, and\nthe second stage trains, in parallel, the machine-learning models for each\nregion. Experimental results on the French transmission system (up to 6,700\nbuses and 9,000 lines) demonstrate the potential of the approach. Within a\nshort training time, the approach predicts AC-OPF solutions with very high\nfidelity and minor constraint violations, producing significant improvements\nover the state-of-the-art. The results also show that the predictions can seed\na load flow optimization to return a feasible solution within 0.03% of the\nAC-OPF objective, while reducing running times significantly.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 20:09:11 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chatzos", "Minas", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2101.06778", "submitter": "Jinning Li", "authors": "Jinning Li, Liting Sun, Jianyu Chen, Masayoshi Tomizuka and Wei Zhan", "title": "A Safe Hierarchical Planning Framework for Complex Driving Scenarios\n  based on Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles need to handle various traffic conditions and make safe\nand efficient decisions and maneuvers. However, on the one hand, a single\noptimization/sampling-based motion planner cannot efficiently generate safe\ntrajectories in real time, particularly when there are many interactive\nvehicles near by. On the other hand, end-to-end learning methods cannot assure\nthe safety of the outcomes. To address this challenge, we propose a\nhierarchical behavior planning framework with a set of low-level safe\ncontrollers and a high-level reinforcement learning algorithm (H-CtRL) as a\ncoordinator for the low-level controllers. Safety is guaranteed by the\nlow-level optimization/sampling-based controllers, while the high-level\nreinforcement learning algorithm makes H-CtRL an adaptive and efficient\nbehavior planner. To train and test our proposed algorithm, we built a\nsimulator that can reproduce traffic scenes using real-world datasets. The\nproposed H-CtRL is proved to be effective in various realistic simulation\nscenarios, with satisfying performance in terms of both safety and efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 20:45:42 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 17:53:03 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Jinning", ""], ["Sun", "Liting", ""], ["Chen", "Jianyu", ""], ["Tomizuka", "Masayoshi", ""], ["Zhan", "Wei", ""]]}, {"id": "2101.06798", "submitter": "Ahmed Qureshi", "authors": "Linjun Li, Yinglong Miao, Ahmed H. Qureshi, and Michael C. Yip", "title": "MPC-MPNet: Model-Predictive Motion Planning Networks for Fast,\n  Near-Optimal Planning under Kinodynamic Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kinodynamic Motion Planning (KMP) is to find a robot motion subject to\nconcurrent kinematics and dynamics constraints. To date, quite a few methods\nsolve KMP problems and those that exist struggle to find near-optimal solutions\nand exhibit high computational complexity as the planning space dimensionality\nincreases. To address these challenges, we present a scalable, imitation\nlearning-based, Model-Predictive Motion Planning Networks framework that\nquickly finds near-optimal path solutions with worst-case theoretical\nguarantees under kinodynamic constraints for practical underactuated systems.\nOur framework introduces two algorithms built on a neural generator,\ndiscriminator, and a parallelizable Model Predictive Controller (MPC). The\ngenerator outputs various informed states towards the given target, and the\ndiscriminator selects the best possible subset from them for the extension. The\nMPC locally connects the selected informed states while satisfying the given\nconstraints leading to feasible, near-optimal solutions. We evaluate our\nalgorithms on a range of cluttered, kinodynamically constrained, and\nunderactuated planning problems with results indicating significant\nimprovements in computation times, path qualities, and success rates over\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 23:07:04 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Li", "Linjun", ""], ["Miao", "Yinglong", ""], ["Qureshi", "Ahmed H.", ""], ["Yip", "Michael C.", ""]]}, {"id": "2101.06806", "submitter": "Sergio Casas", "authors": "Sergio Casas, Abbas Sadat, Raquel Urtasun", "title": "MP3: A Unified Model to Map, Perceive, Predict and Plan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-definition maps (HD maps) are a key component of most modern\nself-driving systems due to their valuable semantic and geometric information.\nUnfortunately, building HD maps has proven hard to scale due to their cost as\nwell as the requirements they impose in the localization system that has to\nwork everywhere with centimeter-level accuracy. Being able to drive without an\nHD map would be very beneficial to scale self-driving solutions as well as to\nincrease the failure tolerance of existing ones (e.g., if localization fails or\nthe map is not up-to-date). Towards this goal, we propose MP3, an end-to-end\napproach to mapless driving where the input is raw sensor data and a high-level\ncommand (e.g., turn left at the intersection). MP3 predicts intermediate\nrepresentations in the form of an online map and the current and future state\nof dynamic agents, and exploits them in a novel neural motion planner to make\ninterpretable decisions taking into account uncertainty. We show that our\napproach is significantly safer, more comfortable, and can follow commands\nbetter than the baselines in challenging long-term closed-loop simulations, as\nwell as when compared to an expert driver in a large-scale real-world dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 00:09:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Casas", "Sergio", ""], ["Sadat", "Abbas", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06813", "submitter": "Zhengchun Liu", "authors": "Jiali Wang, Zhengchun Liu, Ian Foster, Won Chang, Rajkumar Kettimuthu,\n  Rao Kotamarthi", "title": "Fast and accurate learned multiresolution dynamical downscaling for\n  precipitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops a neural network-based approach for emulating\nhigh-resolution modeled precipitation data with comparable statistical\nproperties but at greatly reduced computational cost. The key idea is to use\ncombination of low- and high- resolution simulations to train a neural network\nto map from the former to the latter. Specifically, we define two types of\nCNNs, one that stacks variables directly and one that encodes each variable\nbefore stacking, and we train each CNN type both with a conventional loss\nfunction, such as mean square error (MSE), and with a conditional generative\nadversarial network (CGAN), for a total of four CNN variants. We compare the\nfour new CNN-derived high-resolution precipitation results with precipitation\ngenerated from original high resolution simulations, a bilinear interpolater\nand the state-of-the-art CNN-based super-resolution (SR) technique. Results\nshow that the SR technique produces results similar to those of the bilinear\ninterpolator with smoother spatial and temporal distributions and smaller data\nvariabilities and extremes than the original high resolution simulations. While\nthe new CNNs trained by MSE generate better results over some regions than the\ninterpolator and SR technique do, their predictions are still not as close as\nthe original high resolution simulations. The CNNs trained by CGAN generate\nmore realistic and physically reasonable results, better capturing not only\ndata variability in time and space but also extremes such as intense and\nlong-lasting storms. The new proposed CNN-based downscaling approach can\ndownscale precipitation from 50~km to 12~km in 14~min for 30~years once the\nnetwork is trained (training takes 4~hours using 1~GPU), while the conventional\ndynamical downscaling would take 1~month using 600 CPU cores to generate\nsimulations at the resolution of 12~km over contiguous United States.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 00:25:04 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wang", "Jiali", ""], ["Liu", "Zhengchun", ""], ["Foster", "Ian", ""], ["Chang", "Won", ""], ["Kettimuthu", "Rajkumar", ""], ["Kotamarthi", "Rao", ""]]}, {"id": "2101.06821", "submitter": "Hung Du", "authors": "Yong-Bin Kang, Hung Du, Abdur Rahim Mohammad Forkan, Prem Prakash\n  Jayaraman, Amir Aryani, Timos Sellis (Fellow, IEEE)", "title": "ExpFinder: An Ensemble Expert Finding Model Integrating $N$-gram Vector\n  Space Model and $\\mu$CO-HITS", "comments": "15 pages, 18 figures, \"for source code on Github, see\n  https://github.com/Yongbinkang/ExpFinder\", \"Submitted to IEEE Transactions on\n  Knowledge and Data Engineering\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding an expert plays a crucial role in driving successful collaborations\nand speeding up high-quality research development and innovations. However, the\nrapid growth of scientific publications and digital expertise data makes\nidentifying the right experts a challenging problem. Existing approaches for\nfinding experts given a topic can be categorised into information retrieval\ntechniques based on vector space models, document language models, and\ngraph-based models. In this paper, we propose $\\textit{ExpFinder}$, a new\nensemble model for expert finding, that integrates a novel $N$-gram vector\nspace model, denoted as $n$VSM, and a graph-based model, denoted as\n$\\textit{$\\mu$CO-HITS}$, that is a proposed variation of the CO-HITS algorithm.\nThe key of $n$VSM is to exploit recent inverse document frequency weighting\nmethod for $N$-gram words and $\\textit{ExpFinder}$ incorporates $n$VSM into\n$\\textit{$\\mu$CO-HITS}$ to achieve expert finding. We comprehensively evaluate\n$\\textit{ExpFinder}$ on four different datasets from the academic domains in\ncomparison with six different expert finding models. The evaluation results\nshow that $\\textit{ExpFinder}$ is a highly effective model for expert finding,\nsubstantially outperforming all the compared models in 19% to 160.2%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 00:44:21 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kang", "Yong-Bin", "", "Fellow, IEEE"], ["Du", "Hung", "", "Fellow, IEEE"], ["Forkan", "Abdur Rahim Mohammad", "", "Fellow, IEEE"], ["Jayaraman", "Prem Prakash", "", "Fellow, IEEE"], ["Aryani", "Amir", "", "Fellow, IEEE"], ["Sellis", "Timos", "", "Fellow, IEEE"]]}, {"id": "2101.06829", "submitter": "Tianxing He", "authors": "Tianxing He, Bryan McCann, Caiming Xiong, Ehsan Hosseini-Asl", "title": "Joint Energy-based Model Training for Better Calibrated Natural Language\n  Understanding Models", "comments": null, "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore joint energy-based model (EBM) training during the\nfinetuning of pretrained text encoders (e.g., Roberta) for natural language\nunderstanding (NLU) tasks. Our experiments show that EBM training can help the\nmodel reach a better calibration that is competitive to strong baselines, with\nlittle or no loss in accuracy. We discuss three variants of energy functions\n(namely scalar, hidden, and sharp-hidden) that can be defined on top of a text\nencoder, and compare them in experiments. Due to the discreteness of text data,\nwe adopt noise contrastive estimation (NCE) to train the energy-based model. To\nmake NCE training more effective, we train an auto-regressive noise model with\nthe masked language model (MLM) objective.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 01:41:31 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 18:36:31 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["He", "Tianxing", ""], ["McCann", "Bryan", ""], ["Xiong", "Caiming", ""], ["Hosseini-Asl", "Ehsan", ""]]}, {"id": "2101.06832", "submitter": "Jerry Liu", "authors": "Jerry Liu, Wenyuan Zeng, Raquel Urtasun, Ersin Yumer", "title": "Deep Structured Reactive Planning", "comments": "ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intelligent agent operating in the real-world must balance achieving its\ngoal with maintaining the safety and comfort of not only itself, but also other\nparticipants within the surrounding scene. This requires jointly reasoning\nabout the behavior of other actors while deciding its own actions as these two\nprocesses are inherently intertwined - a vehicle will yield to us if we decide\nto proceed first at the intersection but will proceed first if we decide to\nyield. However, this is not captured in most self-driving pipelines, where\nplanning follows prediction. In this paper we propose a novel data-driven,\nreactive planning objective which allows a self-driving vehicle to jointly\nreason about its own plans as well as how other actors will react to them. We\nformulate the problem as an energy-based deep structured model that is learned\nfrom observational data and encodes both the planning and prediction problems.\nThrough simulations based on both real-world driving and synthetically\ngenerated dense traffic, we demonstrate that our reactive model outperforms a\nnon-reactive variant in successfully completing highly complex maneuvers (lane\nmerges/turns in traffic) faster, without trading off collision rate.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 01:43:36 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 06:26:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Liu", "Jerry", ""], ["Zeng", "Wenyuan", ""], ["Urtasun", "Raquel", ""], ["Yumer", "Ersin", ""]]}, {"id": "2101.06848", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Jose C. Principe", "title": "Faster Convergence in Deep-Predictive-Coding Networks to Learn Deeper\n  Representations", "comments": "Submitted to IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep-predictive-coding networks (DPCNs) are hierarchical, generative models.\nThey rely on feed-forward and feed-back connections to modulate latent feature\nrepresentations of stimuli in a dynamic and context-sensitive manner. A crucial\nelement of DPCNs is a forward-backward inference procedure to uncover sparse,\ninvariant features. However, this inference is a major computational\nbottleneck. It severely limits the network depth due to learning stagnation.\nHere, we prove why this bottleneck occurs. We then propose a new\nforward-inference strategy based on accelerated proximal gradients. This\nstrategy has faster theoretical convergence guarantees than the one used for\nDPCNs. It overcomes learning stagnation. We also demonstrate that it permits\nconstructing deep and wide predictive-coding networks. Such convolutional\nnetworks implement receptive fields that capture well the entire classes of\nobjects on which the networks are trained. This improves the feature\nrepresentations compared with our lab's previous non-convolutional and\nconvolutional DPCNs. It yields unsupervised object recognition that surpass\nconvolutional autoencoders and are on par with convolutional networks trained\nin a supervised manner.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 02:30:13 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 07:03:20 GMT"}, {"version": "v3", "created": "Sat, 15 May 2021 21:52:47 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "2101.06850", "submitter": "Md Fazle Rabby", "authors": "Md Fazle Rabby, Yazhou Tu, Md Imran Hossen, Insup Le, Anthony S Maida,\n  Xiali Hei", "title": "Stacked LSTM Based Deep Recurrent Neural Network with Kalman Smoothing\n  for Blood Glucose Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Blood glucose (BG) management is crucial for type-1 diabetes patients\nresulting in the necessity of reliable artificial pancreas or insulin infusion\nsystems. In recent years, deep learning techniques have been utilized for a\nmore accurate BG level prediction system. However, continuous glucose\nmonitoring (CGM) readings are susceptible to sensor errors. As a result,\ninaccurate CGM readings would affect BG prediction and make it unreliable, even\nif the most optimal machine learning model is used. In this work, we propose a\nnovel approach to predicting blood glucose level with a stacked Long short-term\nmemory (LSTM) based deep recurrent neural network (RNN) model considering\nsensor fault. We use the Kalman smoothing technique for the correction of the\ninaccurate CGM readings due to sensor error. For the OhioT1DM dataset,\ncontaining eight weeks' data from six different patients, we achieve an average\nRMSE of 6.45 and 17.24 mg/dl for 30 minutes and 60 minutes of prediction\nhorizon (PH), respectively. To the best of our knowledge, this is the leading\naverage prediction accuracy for the ohioT1DM dataset. Different physiological\ninformation, e.g., Kalman smoothed CGM data, carbohydrates from the meal, bolus\ninsulin, and cumulative step counts in a fixed time interval, are crafted to\nrepresent meaningful features used as input to the model. The goal of our\napproach is to lower the difference between the predicted CGM values and the\nfingerstick blood glucose readings - the ground truth. Our results indicate\nthat the proposed approach is feasible for more reliable BG forecasting that\nmight improve the performance of the artificial pancreas and insulin infusion\nsystem for T1D diabetes management.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 02:31:38 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Rabby", "Md Fazle", ""], ["Tu", "Yazhou", ""], ["Hossen", "Md Imran", ""], ["Le", "Insup", ""], ["Maida", "Anthony S", ""], ["Hei", "Xiali", ""]]}, {"id": "2101.06871", "submitter": "Pranav Rajpurkar", "authors": "Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y. Ng, Pranav\n  Rajpurkar", "title": "CheXtransfer: Performance and Parameter Efficiency of ImageNet Models\n  for Chest X-Ray Interpretation", "comments": null, "journal-ref": null, "doi": "10.1145/3450439.3451867", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods for chest X-ray interpretation typically rely on\npretrained models developed for ImageNet. This paradigm assumes that better\nImageNet architectures perform better on chest X-ray tasks and that\nImageNet-pretrained weights provide a performance boost over random\ninitialization. In this work, we compare the transfer performance and parameter\nefficiency of 16 popular convolutional architectures on a large chest X-ray\ndataset (CheXpert) to investigate these assumptions. First, we find no\nrelationship between ImageNet performance and CheXpert performance for both\nmodels without pretraining and models with pretraining. Second, we find that,\nfor models without pretraining, the choice of model family influences\nperformance more than size within a family for medical imaging tasks. Third, we\nobserve that ImageNet pretraining yields a statistically significant boost in\nperformance across architectures, with a higher boost for smaller\narchitectures. Fourth, we examine whether ImageNet architectures are\nunnecessarily large for CheXpert by truncating final blocks from pretrained\nmodels, and find that we can make models 3.25x more parameter-efficient on\naverage without a statistically significant drop in performance. Our work\ncontributes new experimental evidence about the relation of ImageNet to chest\nx-ray interpretation performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 04:48:24 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 02:06:43 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ke", "Alexander", ""], ["Ellsworth", "William", ""], ["Banerjee", "Oishi", ""], ["Ng", "Andrew Y.", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2101.06883", "submitter": "Guangyu Huo", "authors": "Guangyu Huo, Yong Zhang, Junbin Gao, Boyue Wang, Yongli Hu, and Baocai\n  Yin", "title": "CaEGCN: Cross-Attention Fusion based Enhanced Graph Convolutional\n  Network for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the powerful learning ability of deep convolutional networks, deep\nclustering methods can extract the most discriminative information from\nindividual data and produce more satisfactory clustering results. However,\nexisting deep clustering methods usually ignore the relationship between the\ndata. Fortunately, the graph convolutional network can handle such\nrelationship, opening up a new research direction for deep clustering. In this\npaper, we propose a cross-attention based deep clustering framework, named\nCross-Attention Fusion based Enhanced Graph Convolutional Network (CaEGCN),\nwhich contains four main modules: the cross-attention fusion module which\ninnovatively concatenates the Content Auto-encoder module (CAE) relating to the\nindividual data and Graph Convolutional Auto-encoder module (GAE) relating to\nthe relationship between the data in a layer-by-layer manner, and the\nself-supervised model that highlights the discriminative information for\nclustering tasks. While the cross-attention fusion module fuses two kinds of\nheterogeneous representation, the CAE module supplements the content\ninformation for the GAE module, which avoids the over-smoothing problem of GCN.\nIn the GAE module, two novel loss functions are proposed that reconstruct the\ncontent and relationship between the data, respectively. Finally, the\nself-supervised module constrains the distributions of the middle layer\nrepresentations of CAE and GAE to be consistent. Experimental results on\ndifferent types of datasets prove the superiority and robustness of the\nproposed CaEGCN.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 05:21:59 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Huo", "Guangyu", ""], ["Zhang", "Yong", ""], ["Gao", "Junbin", ""], ["Wang", "Boyue", ""], ["Hu", "Yongli", ""], ["Yin", "Baocai", ""]]}, {"id": "2101.06890", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "Cooperative and Competitive Biases for Multi-Agent Reinforcement\n  Learning", "comments": "Accepted as a full paper at the Twentieth International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS-21), Virtual Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a multi-agent reinforcement learning (MARL) algorithm is more\nchallenging than training a single-agent reinforcement learning algorithm,\nbecause the result of a multi-agent task strongly depends on the complex\ninteractions among agents and their interactions with a stochastic and dynamic\nenvironment. We propose an algorithm that boosts MARL training using the biased\naction information of other agents based on a friend-or-foe concept. For a\ncooperative and competitive environment, there are generally two groups of\nagents: cooperative-agents and competitive-agents. In the proposed algorithm,\neach agent updates its value function using its own action and the biased\naction information of other agents in the two groups. The biased joint action\nof cooperative agents is computed as the sum of their actual joint action and\nthe imaginary cooperative joint action, by assuming all the cooperative agents\njointly maximize the target agent's value function. The biased joint action of\ncompetitive agents can be computed similarly. Each agent then updates its own\nvalue function using the biased action information, resulting in a biased value\nfunction and corresponding biased policy. Subsequently, the biased policy of\neach agent is inevitably subjected to recommend an action to cooperate and\ncompete with other agents, thereby introducing more active interactions among\nagents and enhancing the MARL policy learning. We empirically demonstrate that\nour algorithm outperforms existing algorithms in various mixed\ncooperative-competitive environments. Furthermore, the introduced biases\ngradually decrease as the training proceeds and the correction based on the\nimaginary assumption vanishes.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 05:52:22 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2101.06896", "submitter": "Yuanchun Li", "authors": "Yuanchun Li, Jiayi Hua, Haoyu Wang, Chunyang Chen, Yunxin Liu", "title": "DeepPayload: Black-box Backdoor Attack on Deep Learning Models through\n  Neural Payload Injection", "comments": "ICSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models are increasingly used in mobile applications as critical\ncomponents. Unlike the program bytecode whose vulnerabilities and threats have\nbeen widely-discussed, whether and how the deep learning models deployed in the\napplications can be compromised are not well-understood since neural networks\nare usually viewed as a black box. In this paper, we introduce a highly\npractical backdoor attack achieved with a set of reverse-engineering techniques\nover compiled deep learning models. The core of the attack is a neural\nconditional branch constructed with a trigger detector and several operators\nand injected into the victim model as a malicious payload. The attack is\neffective as the conditional logic can be flexibly customized by the attacker,\nand scalable as it does not require any prior knowledge from the original\nmodel. We evaluated the attack effectiveness using 5 state-of-the-art deep\nlearning models and real-world samples collected from 30 users. The results\ndemonstrated that the injected backdoor can be triggered with a success rate of\n93.5%, while only brought less than 2ms latency overhead and no more than 1.4%\naccuracy decrease. We further conducted an empirical study on real-world mobile\ndeep learning apps collected from Google Play. We found 54 apps that were\nvulnerable to our attack, including popular and security-critical ones. The\nresults call for the awareness of deep learning application developers and\nauditors to enhance the protection of deployed models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 06:29:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Li", "Yuanchun", ""], ["Hua", "Jiayi", ""], ["Wang", "Haoyu", ""], ["Chen", "Chunyang", ""], ["Liu", "Yunxin", ""]]}, {"id": "2101.06906", "submitter": "Kanata Suzuki", "authors": "Kanata Suzuki, Tetsuya Ogata", "title": "Stable deep reinforcement learning method by predicting uncertainty in\n  rewards as a subtask", "comments": "Published as a conference paper at ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a variety of tasks have been accomplished by deep\nreinforcement learning (DRL). However, when applying DRL to tasks in a\nreal-world environment, designing an appropriate reward is difficult. Rewards\nobtained via actual hardware sensors may include noise, misinterpretation, or\nfailed observations. The learning instability caused by these unstable signals\nis a problem that remains to be solved in DRL. In this work, we propose an\napproach that extends existing DRL models by adding a subtask to directly\nestimate the variance contained in the reward signal. The model then takes the\nfeature map learned by the subtask in a critic network and sends it to the\nactor network. This enables stable learning that is robust to the effects of\npotential noise. The results of experiments in the Atari game domain with\nunstable reward signals show that our method stabilizes training convergence.\nWe also discuss the extensibility of the model by visualizing feature maps.\nThis approach has the potential to make DRL more practical for use in noisy,\nreal-world scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 07:19:14 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suzuki", "Kanata", ""], ["Ogata", "Tetsuya", ""]]}, {"id": "2101.06915", "submitter": "Praveen Damacharla", "authors": "Praveen Damacharla, Achuth Rao M. V., Jordan Ringenberg, and Ahmad Y\n  Javaid", "title": "TLU-Net: A Deep Learning Approach for Automatic Steel Surface Defect\n  Detection", "comments": null, "journal-ref": "International Conference on Applied Artificial Intelligence\n  (ICAPAI 2021), Halden, Norway, May 19-21, 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual steel surface defect detection is an essential step in steel sheet\nmanufacturing. Several machine learning-based automated visual inspection (AVI)\nmethods have been studied in recent years. However, most steel manufacturing\nindustries still use manual visual inspection due to training time and\ninaccuracies involved with AVI methods. Automatic steel defect detection\nmethods could be useful in less expensive and faster quality control and\nfeedback. But preparing the annotated training data for segmentation and\nclassification could be a costly process. In this work, we propose to use the\nTransfer Learning-based U-Net (TLU-Net) framework for steel surface defect\ndetection. We use a U-Net architecture as the base and explore two kinds of\nencoders: ResNet and DenseNet. We compare these nets' performance using random\ninitialization and the pre-trained networks trained using the ImageNet data\nset. The experiments are performed using Severstal data. The results\ndemonstrate that the transfer learning performs 5% (absolute) better than that\nof the random initialization in defect classification. We found that the\ntransfer learning performs 26% (relative) better than that of the random\ninitialization in defect segmentation. We also found the gain of transfer\nlearning increases as the training data decreases, and the convergence rate\nwith transfer learning is better than that of the random initialization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 07:53:20 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Damacharla", "Praveen", ""], ["V.", "Achuth Rao M.", ""], ["Ringenberg", "Jordan", ""], ["Javaid", "Ahmad Y", ""]]}, {"id": "2101.06930", "submitter": "Fan Yang", "authors": "Fan Yang, Ninghao Liu, Mengnan Du, Xia Hu", "title": "Generative Counterfactuals for Neural Networks via Attribute-Informed\n  Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the wide use of deep neural networks (DNN), model interpretability has\nbecome a critical concern, since explainable decisions are preferred in\nhigh-stake scenarios. Current interpretation techniques mainly focus on the\nfeature attribution perspective, which are limited in indicating why and how\nparticular explanations are related to the prediction. To this end, an\nintriguing class of explanations, named counterfactuals, has been developed to\nfurther explore the \"what-if\" circumstances for interpretation, and enables the\nreasoning capability on black-box models. However, generating counterfactuals\nfor raw data instances (i.e., text and image) is still in the early stage due\nto its challenges on high data dimensionality and unsemantic raw features. In\nthis paper, we design a framework to generate counterfactuals specifically for\nraw data instances with the proposed Attribute-Informed Perturbation (AIP). By\nutilizing generative models conditioned with different attributes,\ncounterfactuals with desired labels can be obtained effectively and\nefficiently. Instead of directly modifying instances in the data space, we\niteratively optimize the constructed attribute-informed latent space, where\nfeatures are more robust and semantic. Experimental results on real-world texts\nand images demonstrate the effectiveness, sample quality as well as efficiency\nof our designed framework, and show the superiority over other alternatives.\nBesides, we also introduce some practical applications based on our framework,\nindicating its potential beyond the model interpretability aspect.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 08:37:13 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Yang", "Fan", ""], ["Liu", "Ninghao", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "2101.06968", "submitter": "Javier Fumanal-Idocin Mr.", "authors": "Javier Fumanal-Idocin, Yu-Kai Wang, Chin-Teng Lin, Javier Fern\\'andez,\n  Jose Antonio Sanz, Humberto Bustince", "title": "Motor-Imagery-Based Brain Computer Interface using Signal Derivation and\n  Aggregation Functions", "comments": "IEEE Transactions on Cybernetics (2021)", "journal-ref": null, "doi": "10.1109/TCYB.2021.3073210", "report-no": null, "categories": "cs.HC cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain Computer Interface technologies are popular methods of communication\nbetween the human brain and external devices. One of the most popular\napproaches to BCI is Motor Imagery. In BCI applications, the\nElectroEncephaloGraphy is a very popular measurement for brain dynamics because\nof its non-invasive nature. Although there is a high interest in the BCI topic,\nthe performance of existing systems is still far from ideal, due to the\ndifficulty of performing pattern recognition tasks in EEG signals. BCI systems\nare composed of a wide range of components that perform signal pre-processing,\nfeature extraction and decision making. In this paper, we define a BCI\nFramework, named Enhanced Fusion Framework, where we propose three different\nideas to improve the existing MI-based BCI frameworks. Firstly, we include aan\nadditional pre-processing step of the signal: a differentiation of the EEG\nsignal that makes it time-invariant. Secondly, we add an additional frequency\nband as feature for the system and we show its effect on the performance of the\nsystem. Finally, we make a profound study of how to make the final decision in\nthe system. We propose the usage of both up to six types of different\nclassifiers and a wide range of aggregation functions (including classical\naggregations, Choquet and Sugeno integrals and their extensions and overlap\nfunctions) to fuse the information given by the considered classifiers. We have\ntested this new system on a dataset of 20 volunteers performing motor\nimagery-based brain-computer interface experiments. On this dataset, the new\nsystem achieved a 88.80% of accuracy. We also propose an optimized version of\nour system that is able to obtain up to 90,76%. Furthermore, we find that the\npair Choquet/Sugeno integrals and overlap functions are the ones providing the\nbest results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 10:14:01 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 08:41:37 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Fumanal-Idocin", "Javier", ""], ["Wang", "Yu-Kai", ""], ["Lin", "Chin-Teng", ""], ["Fern\u00e1ndez", "Javier", ""], ["Sanz", "Jose Antonio", ""], ["Bustince", "Humberto", ""]]}, {"id": "2101.06974", "submitter": "Fatema Tuj Johora MSc", "authors": "Fatema T. Johora, Dongfang Yang, J\\\"org P. M\\\"uller, and \\\"Umit\n  \\\"Ozg\\\"uner", "title": "On the Generalizability of Motion Models for Road Users in Heterogeneous\n  Shared Traffic Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling mixed-traffic motion and interactions is crucial to assess safety,\nefficiency, and feasibility of future urban areas. The lack of traffic\nregulations, diverse transport modes, and the dynamic nature of mixed-traffic\nzones like shared spaces make realistic modeling of such environments\nchallenging. This paper focuses on the generalizability of the motion model,\ni.e., its ability to generate realistic behavior in different environmental\nsettings, an aspect which is lacking in existing works. Specifically, our first\ncontribution is a novel and systematic process of formulating general motion\nmodels and application of this process is to extend our Game-Theoretic Social\nForce Model (GSFM) towards a general model for generating a large variety of\nmotion behaviors of pedestrians and cars from different shared spaces. Our\nsecond contribution is to consider different motion patterns of pedestrians by\ncalibrating motion-related features of individual pedestrian and clustering\nthem into groups. We analyze two clustering approaches. The calibration and\nevaluation of our model are performed on three different shared space data\nsets. The results indicate that our model can realistically simulate a wide\nrange of motion behaviors and interaction scenarios, and that adding different\nmotion patterns of pedestrians into our model improves its performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 10:28:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Johora", "Fatema T.", ""], ["Yang", "Dongfang", ""], ["M\u00fcller", "J\u00f6rg P.", ""], ["\u00d6zg\u00fcner", "\u00dcmit", ""]]}, {"id": "2101.06984", "submitter": "Jesus Lovon", "authors": "Jesus Lovon-Melgarejo, Laure Soulier, Karen Pinel-Sauvagnat, Lynda\n  Tamine", "title": "Studying Catastrophic Forgetting in Neural Ranking Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several deep neural ranking models have been proposed in the recent IR\nliterature. While their transferability to one target domain held by a dataset\nhas been widely addressed using traditional domain adaptation strategies, the\nquestion of their cross-domain transferability is still under-studied. We study\nhere in what extent neural ranking models catastrophically forget old knowledge\nacquired from previously observed domains after acquiring new knowledge,\nleading to performance decrease on those domains. Our experiments show that the\neffectiveness of neuralIR ranking models is achieved at the cost of\ncatastrophic forgetting and that a lifelong learning strategy using a\ncross-domain regularizer success-fully mitigates the problem. Using an\nexplanatory approach built on a regression model, we also show the effect of\ndomain characteristics on the rise of catastrophic forgetting. We believe that\nthe obtained results can be useful for both theoretical and practical future\nwork in neural IR.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 10:42:57 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Lovon-Melgarejo", "Jesus", ""], ["Soulier", "Laure", ""], ["Pinel-Sauvagnat", "Karen", ""], ["Tamine", "Lynda", ""]]}, {"id": "2101.07007", "submitter": "Honglin Li", "authors": "Honglin Li, Roonak Rezvani, Magdalena Anita Kolanko, David J. Sharp,\n  Maitreyee Wairagkar, Ravi Vaidyanathan, Ramin Nilforooshan, Payam Barnaghi", "title": "An attention model to analyse the risk of agitation and urinary tract\n  infections in people with dementia", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Behavioural symptoms and urinary tract infections (UTI) are among the most\ncommon problems faced by people with dementia. One of the key challenges in the\nmanagement of these conditions is early detection and timely intervention in\norder to reduce distress and avoid unplanned hospital admissions. Using in-home\nsensing technologies and machine learning models for sensor data integration\nand analysis provides opportunities to detect and predict clinically\nsignificant events and changes in health status. We have developed an\nintegrated platform to collect in-home sensor data and performed an\nobservational study to apply machine learning models for agitation and UTI risk\nanalysis. We collected a large dataset from 88 participants with a mean age of\n82 and a standard deviation of 6.5 (47 females and 41 males) to evaluate a new\ndeep learning model that utilises attention and rational mechanism. The\nproposed solution can process a large volume of data over a period of time and\nextract significant patterns in a time-series data (i.e. attention) and use the\nextracted features and patterns to train risk analysis models (i.e. rational).\nThe proposed model can explain the predictions by indicating which time-steps\nand features are used in a long series of time-series data. The model provides\na recall of 91\\% and precision of 83\\% in detecting the risk of agitation and\nUTIs. This model can be used for early detection of conditions such as UTIs and\nmanaging of neuropsychiatric symptoms such as agitation in association with\ninitial treatment and early intervention approaches. In our study we have\ndeveloped a set of clinical pathways for early interventions using the alerts\ngenerated by the proposed model and a clinical monitoring team has been set up\nto use the platform and respond to the alerts according to the created\nintervention plans.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 11:15:15 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Li", "Honglin", ""], ["Rezvani", "Roonak", ""], ["Kolanko", "Magdalena Anita", ""], ["Sharp", "David J.", ""], ["Wairagkar", "Maitreyee", ""], ["Vaidyanathan", "Ravi", ""], ["Nilforooshan", "Ramin", ""], ["Barnaghi", "Payam", ""]]}, {"id": "2101.07067", "submitter": "Salma Chaieb", "authors": "Salma Chaieb and Ali Ben Mrad and Brahim Hnich and V\\'eronique\n  Delcroix", "title": "Data Obsolescence Detection in the Light of Newly Acquired Valid\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The information describing the conditions of a system or a person is\nconstantly evolving and may become obsolete and contradict other information. A\ndatabase, therefore, must be consistently updated upon the acquisition of new\nvalid observations that contradict obsolete ones contained in the database. In\nthis paper, we propose a novel approach for dealing with the information\nobsolescence problem. Our approach aims to detect, in real-time, contradictions\nbetween observations and then identify the obsolete ones, given a\nrepresentation model. Since we work within an uncertain environment\ncharacterized by the lack of information, we choose to use a Bayesian network\nas our representation model and propose a new approximate concept,\n$\\epsilon$-Contradiction. The new concept is parameterised by a confidence\nlevel of having a contradiction in a set of observations. We propose a\npolynomial-time algorithm for detecting obsolete information. We show that the\nresulting obsolete information is better represented by an AND-OR tree than a\nsimple set of observations. Finally, we demonstrate the effectiveness of our\napproach on a real elderly fall-prevention database and showcase how this tree\ncan be used to give reliable recommendations to doctors. Our experiments give\nsystematically and substantially very good results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 13:24:06 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 11:08:27 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chaieb", "Salma", ""], ["Mrad", "Ali Ben", ""], ["Hnich", "Brahim", ""], ["Delcroix", "V\u00e9ronique", ""]]}, {"id": "2101.07086", "submitter": "Guy Rotman", "authors": "Guy Rotman, Amir Feder and Roi Reichart", "title": "Model Compression for Domain Adaptation through Causal Effect Estimation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent improvements in the predictive quality of natural language processing\nsystems are often dependent on a substantial increase in the number of model\nparameters. This has led to various attempts of compressing such models, but\nexisting methods have not considered the differences in the predictive power of\nvarious model components or in the generalizability of the compressed models.\nTo understand the connection between model compression and out-of-distribution\ngeneralization, we define the task of compressing language representation\nmodels such that they perform best in a domain adaptation setting. We choose to\naddress this problem from a causal perspective, attempting to estimate the\n\\textit{average treatment effect} (ATE) of a model component, such as a single\nlayer, on the model's predictions. Our proposed ATE-guided Model Compression\nscheme (AMoC), generates many model candidates, differing by the model\ncomponents that were removed. Then, we select the best candidate through a\nstepwise regression model that utilizes the ATE to predict the expected\nperformance on the target domain. AMoC outperforms strong baselines on 46 of 60\ndomain pairs across two text classification tasks, with an average improvement\nof more than 3\\% in F1 above the strongest baseline.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 14:18:02 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Rotman", "Guy", ""], ["Feder", "Amir", ""], ["Reichart", "Roi", ""]]}, {"id": "2101.07107", "submitter": "Jeremy Turiel", "authors": "Antonio Briola, Jeremy Turiel, Riccardo Marcaccioli, Tomaso Aste", "title": "Deep Reinforcement Learning for Active High Frequency Trading", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-fin.TR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the first end-to-end Deep Reinforcement Learning (DRL) based\nframework for active high frequency trading. We train DRL agents to trade one\nunit of Intel Corporation stock by employing the Proximal Policy Optimization\nalgorithm. The training is performed on three contiguous months of high\nfrequency Limit Order Book data, of which the last month constitutes the\nvalidation data. In order to maximise the signal to noise ratio in the training\ndata, we compose the latter by only selecting training samples with largest\nprice changes. The test is then carried out on the following month of data.\nHyperparameters are tuned using the Sequential Model Based Optimization\ntechnique. We consider three different state characterizations, which differ in\ntheir LOB-based meta-features. Analysing the agents' performances on test data,\nwe argue that the agents are able to create a dynamic representation of the\nunderlying environment. They identify occasional regularities present in the\ndata and exploit them to create long-term profitable trading strategies.\nIndeed, agents learn trading strategies able to produce stable positive returns\nin spite of the highly stochastic and non-stationary environment.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 15:09:28 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 11:46:03 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Briola", "Antonio", ""], ["Turiel", "Jeremy", ""], ["Marcaccioli", "Riccardo", ""], ["Aste", "Tomaso", ""]]}, {"id": "2101.07116", "submitter": "Yong Huang", "authors": "Yong Huang, Ben Chen, Daiming Qu", "title": "LNSMM: Eye Gaze Estimation With Local Network Share Multiview Multitask", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye gaze estimation has become increasingly significant in computer vision.In\nthis paper,we systematically study the mainstream of eye gaze estimation\nmethods,propose a novel methodology to estimate eye gaze points and eye gaze\ndirections simultaneously.First,we construct a local sharing network for\nfeature extraction of gaze points and gaze directions estimation,which can\nreduce network computational parameters and converge quickly;Second,we propose\na Multiview Multitask Learning (MTL) framework,for gaze directions,a coplanar\nconstraint is proposed for the left and right eyes,for gaze points,three views\ndata input indirectly introduces eye position information,a cross-view pooling\nmodule is designed, propose joint loss which handle both gaze points and gaze\ndirections estimation.Eventually,we collect a dataset to use of gaze\npoints,which have three views to exist public dataset.The experiment show our\nmethod is state-of-the-art the current mainstream methods on two indicators of\ngaze points and gaze directions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 15:14:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Huang", "Yong", ""], ["Chen", "Ben", ""], ["Qu", "Daiming", ""]]}, {"id": "2101.07140", "submitter": "Pradyumna Tambwekar", "authors": "Pradyumna Tambwekar, Andrew Silva, Nakul Gopalan, Matthew Gombolay", "title": "Interpretable Policy Specification and Synthesis through Natural\n  Language and RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy specification is a process by which a human can initialize a robot's\nbehaviour and, in turn, warm-start policy optimization via Reinforcement\nLearning (RL). While policy specification/design is inherently a collaborative\nprocess, modern methods based on Learning from Demonstration or Deep RL lack\nthe model interpretability and accessibility to be classified as such. Current\nstate-of-the-art methods for policy specification rely on black-box models,\nwhich are an insufficient means of collaboration for non-expert users: These\nmodels provide no means of inspecting policies learnt by the agent and are not\nfocused on creating a usable modality for teaching robot behaviour. In this\npaper, we propose a novel machine learning framework that enables humans to 1)\nspecify, through natural language, interpretable policies in the form of\neasy-to-understand decision trees, 2) leverage these policies to warm-start\nreinforcement learning and 3) outperform baselines that lack our natural\nlanguage initialization mechanism. We train our approach by collecting a\nfirst-of-its-kind corpus mapping free-form natural language policy descriptions\nto decision tree-based policies. We show that our novel framework translates\nnatural language to decision trees with a 96% and 97% accuracy on a held-out\ncorpus across two domains, respectively. Finally, we validate that policies\ninitialized with natural language commands are able to significantly outperform\nrelevant baselines (p < 0.001) that do not benefit from our natural\nlanguage-based warm-start technique.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 16:07:00 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Tambwekar", "Pradyumna", ""], ["Silva", "Andrew", ""], ["Gopalan", "Nakul", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2101.07202", "submitter": "Christoph Weinhuber", "authors": "Pranav Ashok, Mathias Jackermeier, Jan K\\v{r}et\\'insk\\'y, Christoph\n  Weinhuber, Maximilian Weininger, Mayank Yadav", "title": "dtControl 2.0: Explainable Strategy Representation via Decision Tree\n  Learning Steered by Experts", "comments": null, "journal-ref": "TACAS (2) (pp. 326-345). Springer. 2021", "doi": "10.1007/978-3-030-72013-1_17", "report-no": null, "categories": "cs.AI cs.FL cs.LG cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances have shown how decision trees are apt data structures for\nconcisely representing strategies (or controllers) satisfying various\nobjectives. Moreover, they also make the strategy more explainable. The recent\ntool dtControl had provided pipelines with tools supporting strategy synthesis\nfor hybrid systems, such as SCOTS and Uppaal Stratego. We present dtControl\n2.0, a new version with several fundamentally novel features. Most importantly,\nthe user can now provide domain knowledge to be exploited in the decision tree\nlearning process and can also interactively steer the process based on the\ndynamically provided information. To this end, we also provide a graphical user\ninterface. It allows for inspection and re-computation of parts of the result,\nsuggesting as well as receiving advice on predicates, and visual simulation of\nthe decision-making process. Besides, we interface model checkers of\nprobabilistic systems, namely Storm and PRISM and provide dedicated support for\ncategorical enumeration-type state variables. Consequently, the controllers are\nmore explainable and smaller.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 11:22:49 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:10:43 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ashok", "Pranav", ""], ["Jackermeier", "Mathias", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weinhuber", "Christoph", ""], ["Weininger", "Maximilian", ""], ["Yadav", "Mayank", ""]]}, {"id": "2101.07217", "submitter": "Paulo Andre Lima De Castro", "authors": "Murilo Sibrao Bernardini and Paulo Andre Lima de Castro", "title": "Is it a great Autonomous FX Trading Strategy or you are just fooling\n  yourself", "comments": "there were some warning, (references not found!), but the references\n  are all there. I think it needs to run latex twice!!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There are many practitioners that create software to buy and sell financial\nassets in an autonomous way. There are some digital platforms that allow the\ndevelopment, test and deployment of trading agents (or robots) in simulated or\nreal markets. Some of these work focus on very short horizons of investment,\nwhile others deal with longer periods. The spectrum of used AI techniques in\nfinance field is wide. There are many cases, where the developers are\nsuccessful in creating robots with great performance in historical price series\n(so called backtesting). Furthermore, some platforms make available thousands\nof robots that [allegedly] are able to be profitable in real markets. These\nstrategies may be created with some simple idea or using complex machine\nlearning schemes. Nevertheless, when they are used in real markets or with data\nnot used in their training or evaluation frequently they present very poor\nperformance. In this paper, we propose a method for testing Foreign Exchange\n(FX) trading strategies that can provide realistic expectations about\nstrategy's performance. This method addresses many pitfalls that can fool even\nexperience practitioners and researchers. We present the results of applying\nsuch method in several famous autonomous strategies in many different financial\nassets. Analyzing these results, we can realize that it is very hard to build a\nreliable strategy and many published strategies are far from being reliable\nvehicles of investment. These facts can be maliciously used by those who try to\nsell such robots, by advertising such great (and non repetitive) results, while\nhiding the bad but meaningful results. The proposed method can be used to\nselect among potential robots, establishes minimal periods and requirements for\nthe test executions. In this way, the method helps to tell if you really have a\ngreat trading strategy or you are just fooling yourself.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 13:25:15 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bernardini", "Murilo Sibrao", ""], ["de Castro", "Paulo Andre Lima", ""]]}, {"id": "2101.07220", "submitter": "Dakota Thompson", "authors": "Amro M. Farid, Dakota Thompson, Prabhat Hegde and Wester Schoonenberg", "title": "A Tensor-Based Formulation of Hetero-functional Graph Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, hetero-functional graph theory (HFGT) has developed as a means to\nmathematically model the structure of large flexible engineering systems. In\nthat regard, it intellectually resembles a fusion of network science and\nmodel-based systems engineering. With respect to the former, it relies on\nmultiple graphs as data structures so as to support matrix-based quantitative\nanalysis. In the meantime, HFGT explicitly embodies the heterogeneity of\nconceptual and ontological constructs found in model-based systems engineering\nincluding system form, system function, and system concept. At their\nfoundation, these disparate conceptual constructs suggest multi-dimensional\nrather than two-dimensional relationships. This paper provides the first\ntensor-based treatment of some of the most important parts of hetero-functional\ngraph theory. In particular, it addresses the \"system concept\", the\nhetero-functional adjacency matrix, and the hetero-functional incidence tensor.\nThe tensor-based formulation described in this work makes a stronger tie\nbetween HFGT and its ontological foundations in MBSE. Finally, the tensor-based\nformulation facilitates an understanding of the relationships between HFGT and\nmulti-layer networks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 15:08:19 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Farid", "Amro M.", ""], ["Thompson", "Dakota", ""], ["Hegde", "Prabhat", ""], ["Schoonenberg", "Wester", ""]]}, {"id": "2101.07223", "submitter": "Simon Pietro Romano", "authors": "Diego Antonelli, Roberta Cascella, Gaetano Perrone, Simon Pietro\n  Romano, Antonio Schiano", "title": "Leveraging AI to optimize website structure discovery during Penetration\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dirbusting is a technique used to brute force directories and file names on\nweb servers while monitoring HTTP responses, in order to enumerate server\ncontents. Such a technique uses lists of common words to discover the hidden\nstructure of the target website. Dirbusting typically relies on response codes\nas discovery conditions to find new pages. It is widely used in web application\npenetration testing, an activity that allows companies to detect websites\nvulnerabilities. Dirbusting techniques are both time and resource consuming and\ninnovative approaches have never been explored in this field. We hence propose\nan advanced technique to optimize the dirbusting process by leveraging\nArtificial Intelligence. More specifically, we use semantic clustering\ntechniques in order to organize wordlist items in different groups according to\ntheir semantic meaning. The created clusters are used in an ad-hoc implemented\nnext-word intelligent strategy. This paper demonstrates that the usage of\nclustering techniques outperforms the commonly used brute force methods.\nPerformance is evaluated by testing eight different web applications. Results\nshow a performance increase that is up to 50% for each of the conducted\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 18:21:42 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Antonelli", "Diego", ""], ["Cascella", "Roberta", ""], ["Perrone", "Gaetano", ""], ["Romano", "Simon Pietro", ""], ["Schiano", "Antonio", ""]]}, {"id": "2101.07235", "submitter": "Jean-Francois Rajotte", "authors": "Jean-Francois Rajotte, Sumit Mukherjee, Caleb Robinson, Anthony Ortiz,\n  Christopher West, Juan Lavista Ferres, Raymond T Ng", "title": "Reducing bias and increasing utility by federated generative modeling of\n  medical images using a centralized adversary", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce FELICIA (FEderated LearnIng with a CentralIzed Adversary) a\ngenerative mechanism enabling collaborative learning. In particular, we show\nhow a data owner with limited and biased data could benefit from other data\nowners while keeping data from all the sources private. This is a common\nscenario in medical image analysis where privacy legislation prevents data from\nbeing shared outside local premises. FELICIA works for a large family of\nGenerative Adversarial Networks (GAN) architectures including vanilla and\nconditional GANs as demonstrated in this work. We show that by using the\nFELICIA mechanism, a data owner with limited image samples can generate\nhigh-quality synthetic images with high utility while neither data owners has\nto provide access to its data. The sharing happens solely through a central\ndiscriminator that has access limited to synthetic data. Here, utility is\ndefined as classification performance on a real test set. We demonstrate these\nbenefits on several realistic healthcare scenarions using benchmark image\ndatasets (MNIST, CIFAR-10) as well as on medical images for the task of skin\nlesion classification. With multiple experiments, we show that even in the\nworst cases, combining FELICIA with real data gracefully achieves performance\non par with real data while most results significantly improves the utility.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 18:40:46 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Rajotte", "Jean-Francois", ""], ["Mukherjee", "Sumit", ""], ["Robinson", "Caleb", ""], ["Ortiz", "Anthony", ""], ["West", "Christopher", ""], ["Ferres", "Juan Lavista", ""], ["Ng", "Raymond T", ""]]}, {"id": "2101.07240", "submitter": "Svetlana Kutuzova", "authors": "Svetlana Kutuzova, Oswin Krause, Douglas McCloskey, Mads Nielsen,\n  Christian Igel", "title": "Multimodal Variational Autoencoders for Semi-Supervised Learning: In\n  Defense of Product-of-Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal generative models should be able to learn a meaningful latent\nrepresentation that enables a coherent joint generation of all modalities\n(e.g., images and text). Many applications also require the ability to\naccurately sample modalities conditioned on observations of a subset of the\nmodalities. Often not all modalities may be observed for all training data\npoints, so semi-supervised learning should be possible. In this study, we\nevaluate a family of product-of-experts (PoE) based variational autoencoders\nthat have these desired properties. We include a novel PoE based architecture\nand training procedure. An empirical evaluation shows that the PoE based models\ncan outperform an additive mixture-of-experts (MoE) approach. Our experiments\nsupport the intuition that PoE models are more suited for a conjunctive\ncombination of modalities while MoEs are more suited for a disjunctive fusion.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 18:47:43 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kutuzova", "Svetlana", ""], ["Krause", "Oswin", ""], ["McCloskey", "Douglas", ""], ["Nielsen", "Mads", ""], ["Igel", "Christian", ""]]}, {"id": "2101.07308", "submitter": "Le Thanh Nguyen-Meidine", "authors": "Le Thanh Nguyen-Meidine, Atif Belal, Madhu Kiran, Jose Dolz,\n  Louis-Antoine Blais-Morin, Eric Granger", "title": "Knowledge Distillation Methods for Efficient Unsupervised Adaptation\n  Across Multiple Domains", "comments": "This is the extended journal version of arXiv:2005.07839", "journal-ref": null, "doi": "10.1016/j.imavis.2021.104096", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond the complexity of CNNs that require training on large annotated\ndatasets, the domain shift between design and operational data has limited the\nadoption of CNNs in many real-world applications. For instance, in person\nre-identification, videos are captured over a distributed set of cameras with\nnon-overlapping viewpoints. The shift between the source (e.g. lab setting) and\ntarget (e.g. cameras) domains may lead to a significant decline in recognition\naccuracy. Additionally, state-of-the-art CNNs may not be suitable for such\nreal-time applications given their computational requirements. Although several\ntechniques have recently been proposed to address domain shift problems through\nunsupervised domain adaptation (UDA), or to accelerate/compress CNNs through\nknowledge distillation (KD), we seek to simultaneously adapt and compress CNNs\nto generalize well across multiple target domains. In this paper, we propose a\nprogressive KD approach for unsupervised single-target DA (STDA) and\nmulti-target DA (MTDA) of CNNs. Our method for KD-STDA adapts a CNN to a single\ntarget domain by distilling from a larger teacher CNN, trained on both target\nand source domain data in order to maintain its consistency with a common\nrepresentation. Our proposed approach is compared against state-of-the-art\nmethods for compression and STDA of CNNs on the Office31 and ImageClef-DA image\nclassification datasets. It is also compared against state-of-the-art methods\nfor MTDA on Digits, Office31, and OfficeHome. In both settings -- KD-STDA and\nKD-MTDA -- results indicate that our approach can achieve the highest level of\naccuracy across target domains, while requiring a comparable or lower CNN\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 19:53:16 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Nguyen-Meidine", "Le Thanh", ""], ["Belal", "Atif", ""], ["Kiran", "Madhu", ""], ["Dolz", "Jose", ""], ["Blais-Morin", "Louis-Antoine", ""], ["Granger", "Eric", ""]]}, {"id": "2101.07312", "submitter": "Tobias Huber", "authors": "Tobias Huber, Benedikt Limmer, Elisabeth Andr\\'e", "title": "Benchmarking Perturbation-based Saliency Maps for Explaining Atari\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years saw a plethora of work on explaining complex intelligent agents.\nOne example is the development of several algorithms that generate saliency\nmaps which show how much each pixel attributed to the agents' decision.\nHowever, most evaluations of such saliency maps focus on image classification\ntasks. As far as we know, there is no work that thoroughly compares different\nsaliency maps for Deep Reinforcement Learning agents. This paper compares four\nperturbation-based approaches to create saliency maps for Deep Reinforcement\nLearning agents trained on four different Atari 2600 games. All four approaches\nwork by perturbing parts of the input and measuring how much this affects the\nagent's output. The approaches are compared using three computational metrics:\ndependence on the learned parameters of the agent (sanity checks), faithfulness\nto the agent's reasoning (input degradation), and run-time. In particular,\nduring the sanity checks we find issues with two approaches and propose a\nsolution to fix one of those issues.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 19:57:52 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 09:02:25 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Huber", "Tobias", ""], ["Limmer", "Benedikt", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "2101.07321", "submitter": "Krenare Pireva Nuci", "authors": "Vedat Apuk, Krenare Pireva Nu\\c{c}i", "title": "Classification of Pedagogical content using conventional machine\n  learning and deep learning model", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of the Internet and a large number of digital technologies has\nbrought with it many different challenges. A large amount of data is found on\nthe web, which in most cases is unstructured and unorganized, and this\ncontributes to the fact that the use and manipulation of this data is quite a\ndifficult process. Due to this fact, the usage of different machine and deep\nlearning techniques for Text Classification has gained its importance, which\nimproved this discipline and made it more interesting for scientists and\nresearchers for further study. This paper aims to classify the pedagogical\ncontent using two different models, the K-Nearest Neighbor (KNN) from the\nconventional models and the Long short-term memory (LSTM) recurrent neural\nnetwork from the deep learning models. The result indicates that the accuracy\nof classifying the pedagogical content reaches 92.52 % using KNN model and\n87.71 % using LSTM model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 20:29:34 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Apuk", "Vedat", ""], ["Nu\u00e7i", "Krenare Pireva", ""]]}, {"id": "2101.07337", "submitter": "Zijian Zhang", "authors": "Zijian Zhang, Jaspreet Singh, Ujwal Gadiraju, Avishek Anand", "title": "Dissonance Between Human and Machine Understanding", "comments": "23 pages, 5 figures", "journal-ref": "[J]. Proceedings of the ACM on Human-Computer Interaction, 2019,\n  3(CSCW): 1-23", "doi": "10.1145/3359158", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Complex machine learning models are deployed in several critical domains\nincluding healthcare and autonomous vehicles nowadays, albeit as functional\nblack boxes. Consequently, there has been a recent surge in interpreting\ndecisions of such complex models in order to explain their actions to humans.\nModels that correspond to human interpretation of a task are more desirable in\ncertain contexts and can help attribute liability, build trust, expose biases\nand in turn build better models. It is, therefore, crucial to understand how\nand which models conform to human understanding of tasks. In this paper, we\npresent a large-scale crowdsourcing study that reveals and quantifies the\ndissonance between human and machine understanding, through the lens of an\nimage classification task. In particular, we seek to answer the following\nquestions: Which (well-performing) complex ML models are closer to humans in\ntheir use of features to make accurate predictions? How does task difficulty\naffect the feature selection capability of machines in comparison to humans?\nAre humans consistently better at selecting features that make image\nrecognition more accurate? Our findings have important implications on\nhuman-machine collaboration, considering that a long term goal in the field of\nartificial intelligence is to make machines capable of learning and reasoning\nlike humans.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 21:45:35 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Zhang", "Zijian", ""], ["Singh", "Jaspreet", ""], ["Gadiraju", "Ujwal", ""], ["Anand", "Avishek", ""]]}, {"id": "2101.07385", "submitter": "Maximilian Amsler", "authors": "Sebastian Ament, Maximilian Amsler, Duncan R. Sutherland, Ming-Chiang\n  Chang, Dan Guevarra, Aine B. Connolly, John M. Gregoire, Michael O. Thompson,\n  Carla P. Gomes, R. Bruce van Dover", "title": "Autonomous synthesis of metastable materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI cs.LG cs.MA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous experimentation enabled by artificial intelligence (AI) offers a\nnew paradigm for accelerating scientific discovery. Non-equilibrium materials\nsynthesis is emblematic of complex, resource-intensive experimentation whose\nacceleration would be a watershed for materials discovery and development. The\nmapping of non-equilibrium synthesis phase diagrams has recently been\naccelerated via high throughput experimentation but still limits materials\nresearch because the parameter space is too vast to be exhaustively explored.\nWe demonstrate accelerated synthesis and exploration of metastable materials\nthrough hierarchical autonomous experimentation governed by the Scientific\nAutonomous Reasoning Agent (SARA). SARA integrates robotic materials synthesis\nand characterization along with a hierarchy of AI methods that efficiently\nreveal the structure of processing phase diagrams. SARA designs lateral\ngradient laser spike annealing (lg-LSA) experiments for parallel materials\nsynthesis and employs optical spectroscopy to rapidly identify phase\ntransitions. Efficient exploration of the multi-dimensional parameter space is\nachieved with nested active learning (AL) cycles built upon advanced machine\nlearning models that incorporate the underlying physics of the experiments as\nwell as end-to-end uncertainty quantification. With this, and the coordination\nof AL at multiple scales, SARA embodies AI harnessing of complex scientific\ntasks. We demonstrate its performance by autonomously mapping synthesis phase\nboundaries for the Bi$_2$O$_3$ system, leading to orders-of-magnitude\nacceleration in establishment of a synthesis phase diagram that includes\nconditions for kinetically stabilizing $\\delta$-Bi$_2$O$_3$ at room\ntemperature, a critical development for electrochemical technologies such as\nsolid oxide fuel cells.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 00:29:26 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Ament", "Sebastian", ""], ["Amsler", "Maximilian", ""], ["Sutherland", "Duncan R.", ""], ["Chang", "Ming-Chiang", ""], ["Guevarra", "Dan", ""], ["Connolly", "Aine B.", ""], ["Gregoire", "John M.", ""], ["Thompson", "Michael O.", ""], ["Gomes", "Carla P.", ""], ["van Dover", "R. Bruce", ""]]}, {"id": "2101.07393", "submitter": "Austin W. Hanjie", "authors": "Austin W. Hanjie, Victor Zhong, Karthik Narasimhan", "title": "Grounding Language to Entities and Dynamics for Generalization in\n  Reinforcement Learning", "comments": "Accepted to ICML 2021. Note author list and name changes from\n  previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of natural language to drive the generalization of\ncontrol policies and introduce the new multi-task environment Messenger with\nfree-form text manuals describing the environment dynamics. Unlike previous\nwork, Messenger does not assume prior knowledge connecting text and state\nobservations $-$ the control policy must simultaneously ground the game manual\nto entity symbols and dynamics in the environment. We develop a new model, EMMA\n(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned\nattention module that allows for selective focus over relevant descriptions in\nthe manual for each entity in the environment. EMMA is end-to-end\ndifferentiable and learns a latent grounding of entities and dynamics from text\nto observations using only environment rewards. EMMA achieves successful\nzero-shot generalization to unseen games with new dynamics, obtaining a 40%\nhigher win rate compared to multiple baselines. However, win rate on the\nhardest stage of Messenger remains low (10%), demonstrating the need for\nadditional work in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 00:59:16 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 23:34:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hanjie", "Austin W.", ""], ["Zhong", "Victor", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "2101.07419", "submitter": "Haiwei Wu", "authors": "Haiwei Wu and Jiantao Zhou", "title": "GIID-Net: Generalizable Image Inpainting Detection via Neural\n  Architecture Search and Attention", "comments": "Some errors are found in the Section V of Experimental Results, and\n  more experiments are needed to be added. Besides, there are some\n  modifications we want to present in the Section III of the Methods, e.g.,\n  updating the figures for better describe the proposed methods. Thanks!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has demonstrated its powerful capabilities in the field of\nimage inpainting, which could produce visually plausible results. Meanwhile,\nthe malicious use of advanced image inpainting tools (e.g. removing key objects\nto report fake news) has led to increasing threats to the reliability of image\ndata. To fight against the inpainting forgeries, in this work, we propose a\nnovel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),\nto detect the inpainted regions at pixel accuracy. The proposed GIID-Net\nconsists of three sub-blocks: the enhancement block, the extraction block and\nthe decision block. Specifically, the enhancement block aims to enhance the\ninpainting traces by using hierarchically combined special layers. The\nextraction block, automatically designed by Neural Architecture Search (NAS)\nalgorithm, is targeted to extract features for the actual inpainting detection\ntasks. In order to further optimize the extracted latent features, we integrate\nglobal and local attention modules in the decision block, where the global\nattention reduces the intra-class differences by measuring the similarity of\nglobal features, while the local attention strengthens the consistency of local\nfeatures. Furthermore, we thoroughly study the generalizability of our\nGIID-Net, and find that different training data could result in vastly\ndifferent generalization capability. Extensive experimental results are\npresented to validate the superiority of the proposed GIID-Net, compared with\nthe state-of-the-art competitors. Our results would suggest that common\nartifacts are shared across diverse image inpainting methods. Finally, we build\na public inpainting dataset of 10K image pairs for the future research in this\narea.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 02:29:40 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 05:44:31 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Wu", "Haiwei", ""], ["Zhou", "Jiantao", ""]]}, {"id": "2101.07425", "submitter": "Jianguo Chen", "authors": "Jianguo Chen and Kenli Li and Keqin Li and Philip S. Yu and Zeng Zeng", "title": "Dynamic Planning of Bicycle Stations in Dockless Public Bicycle-sharing\n  System Using Gated Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from convenient cycling and flexible parking locations, the\nDockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular\nin many countries. However, redundant and low-utility stations waste public\nurban space and maintenance costs of DL-PBS vendors. In this paper, we propose\na Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the\noptimal bicycle station layout for the DL-PBS network. The BSDP system contains\nfour modules: bicycle drop-off location clustering, bicycle-station graph\nmodeling, bicycle-station location prediction, and bicycle-station layout\nrecommendation. In the bicycle drop-off location clustering module, candidate\nbicycle stations are clustered from each spatio-temporal subset of the\nlarge-scale cycling trajectory records. In the bicycle-station graph modeling\nmodule, a weighted digraph model is built based on the clustering results and\ninferior stations with low station revenue and utility are filtered. Then,\ngraph models across time periods are combined to create a graph sequence model.\nIn the bicycle-station location prediction module, the GGNN model is used to\ntrain the graph sequence data and dynamically predict bicycle stations in the\nnext period. In the bicycle-station layout recommendation module, the predicted\nbicycle stations are fine-tuned according to the government urban management\nplan, which ensures that the recommended station layout is conducive to city\nmanagement, vendor revenue, and user convenience. Experiments on actual DL-PBS\nnetworks verify the effectiveness, accuracy and feasibility of the proposed\nBSDP system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 02:51:12 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""], ["Zeng", "Zeng", ""]]}, {"id": "2101.07437", "submitter": "Jianguo Chen", "authors": "Jianguo Chen and Kenli Li and Keqin Li and Philip S. Yu and Zeng Zeng", "title": "Dynamic Bicycle Dispatching of Dockless Public Bicycle-sharing Systems\n  using Multi-objective Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new generation of Public Bicycle-sharing Systems (PBS), the dockless PBS\n(DL-PBS) is an important application of cyber-physical systems and intelligent\ntransportation. How to use AI to provide efficient bicycle dispatching\nsolutions based on dynamic bicycle rental demand is an essential issue for\nDL-PBS. In this paper, we propose a dynamic bicycle dispatching algorithm based\non multi-objective reinforcement learning (MORL-BD) to provide the optimal\nbicycle dispatching solution for DL-PBS. We model the DL-PBS system from the\nperspective of CPS and use deep learning to predict the layout of bicycle\nparking spots and the dynamic demand of bicycle dispatching. We define the\nmulti-route bicycle dispatching problem as a multi-objective optimization\nproblem by considering the optimization objectives of dispatching costs,\ndispatch truck's initial load, workload balance among the trucks, and the\ndynamic balance of bicycle supply and demand. On this basis, the collaborative\nmulti-route bicycle dispatching problem among multiple dispatch trucks is\nmodeled as a multi-agent MORL model. All dispatch paths between parking spots\nare defined as state spaces, and the reciprocal of dispatching costs is defined\nas a reward. Each dispatch truck is equipped with an agent to learn the optimal\ndispatch path in the dynamic DL-PBS network. We create an elite list to store\nthe Pareto optimal solutions of bicycle dispatch paths found in each action,\nand finally, get the Pareto frontier. Experimental results on the actual DL-PBS\nsystems show that compared with existing methods, MORL-BD can find a higher\nquality Pareto frontier with less execution time.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 03:09:51 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""], ["Zeng", "Zeng", ""]]}, {"id": "2101.07496", "submitter": "Jun Han Mr", "authors": "Jun Han, Martin Renqiang Min, Ligong Han, Li Erran Li, Xuan Zhang", "title": "Disentangled Recurrent Wasserstein Autoencoder", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations leads to interpretable models and\nfacilitates data generation with style transfer, which has been extensively\nstudied on static data such as images in an unsupervised learning framework.\nHowever, only a few works have explored unsupervised disentangled sequential\nrepresentation learning due to challenges of generating sequential data. In\nthis paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new\nframework for generative modeling of sequential data. R-WAE disentangles the\nrepresentation of an input sequence into static and dynamic factors (i.e.,\ntime-invariant and time-varying parts). Our theoretical analysis shows that,\nR-WAE minimizes an upper bound of a penalized form of the Wasserstein distance\nbetween model distribution and sequential data distribution, and simultaneously\nmaximizes the mutual information between input data and different disentangled\nlatent factors, respectively. This is superior to (recurrent) VAE which does\nnot explicitly enforce mutual information maximization between input data and\ndisentangled latent representations. When the number of actions in sequential\ndata is available as weak supervision information, R-WAE is extended to learn a\ncategorical latent representation of actions to improve its disentanglement.\nExperiments on a variety of datasets show that our models outperform other\nbaselines with the same settings in terms of disentanglement and unconditional\nvideo generation both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:43:25 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Han", "Jun", ""], ["Min", "Martin Renqiang", ""], ["Han", "Ligong", ""], ["Li", "Li Erran", ""], ["Zhang", "Xuan", ""]]}, {"id": "2101.07498", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Paraconsistent Foundations for Quantum Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is argued that a fuzzy version of 4-truth-valued paraconsistent logic\n(with truth values corresponding to True, False, Both and Neither) can be\napproximately isomorphically mapped into the complex-number algebra of quantum\nprobabilities. I.e., p-bits (paraconsistent bits) can be transformed into close\napproximations of qubits. The approximation error can be made arbitrarily\nsmall, at least in a formal sense, and can be related to the degree of\nirreducible \"evidential error\" assumed to plague an observer's observations.\nThis logical correspondence manifests itself in program space via an\napproximate mapping between probabilistic and quantum types in programming\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:48:41 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2101.07523", "submitter": "Nicolas Becu", "authors": "Ahmed Laatabi, Nicolas Becu (LIENSs), Nicolas Marilleau (UMMISCO),\n  C\\'ecilia Pignon-Mussaud (LIENSs), Marion Amalric (CITERES), X. Bertin\n  (LIENSs), Brice Anselme (PRODIG), Elise Beck (PACTE)", "title": "Mapping and Describing Geospatial Data to Generalize Complex Mapping and\n  Describing Geospatial Data to Generalize Complex Models: The Case of\n  LittoSIM-GEN Models", "comments": null, "journal-ref": "International Journal of Geospatial and Environmental Research,\n  KAGES, 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For some scientific questions, empirical data are essential to develop\nreliable simulation models. These data usually come from different sources with\ndiverse and heterogeneous formats. The design of complex data-driven models is\noften shaped by the structure of the data available in research projects.\nHence, applying such models to other case studies requires either to get\nsimilar data or to transform new data to fit the model inputs. It is the case\nof agent-based models (ABMs) that use advanced data structures such as\nGeographic Information Systems data. We faced this problem in the LittoSIM-GEN\nproject when generalizing our participatory flooding model (LittoSIM) to new\nterritories. From this experience, we provide a mapping approach to structure,\ndescribe, and automatize the integration of geospatial data into ABMs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 09:16:05 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Laatabi", "Ahmed", "", "LIENSs"], ["Becu", "Nicolas", "", "LIENSs"], ["Marilleau", "Nicolas", "", "UMMISCO"], ["Pignon-Mussaud", "C\u00e9cilia", "", "LIENSs"], ["Amalric", "Marion", "", "CITERES"], ["Bertin", "X.", "", "LIENSs"], ["Anselme", "Brice", "", "PRODIG"], ["Beck", "Elise", "", "PACTE"]]}, {"id": "2101.07570", "submitter": "Thomas K.F. Chiu", "authors": "Thomas K.F. Chiu, Helen Meng, Ching-Sing Chai, Irwin King, Savio Wong\n  and Yeung Yam", "title": "Creation and Evaluation of a Pre-tertiary Artificial Intelligence (AI)\n  Curriculum", "comments": "8 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for\nthe Future Project (AI4Future) co-created an AI curriculum for pre-tertiary\neducation and evaluated its efficacy. While AI is conventionally taught in\ntertiary level education, our co-creation process successfully developed the\ncurriculum that has been used in secondary school teaching in Hong Kong and\nreceived positive feedback. Background: AI4Future is a cross-sector project\nthat engages five major partners - CUHK Faculty of Engineering and Faculty of\nEducation, Hong Kong secondary schools, the government and the AI industry. A\nteam of 14 professors with expertise in engineering and education collaborated\nwith 17 principals and teachers from 6 secondary schools to co-create the\ncurriculum. This team formation bridges the gap between researchers in\nengineering and education, together with practitioners in education context.\nResearch Questions: What are the main features of the curriculum content\ndeveloped through the co-creation process? Would the curriculum significantly\nimprove the students perceived competence in, as well as attitude and\nmotivation towards AI? What are the teachers perceptions of the co-creation\nprocess that aims to accommodate and foster teacher autonomy? Methodology: This\nstudy adopted a mix of quantitative and qualitative methods and involved 335\nstudent participants. Findings: 1) two main features of learning resources, 2)\nthe students perceived greater competence, and developed more positive attitude\nto learn AI, and 3) the co-creation process generated a variety of resources\nwhich enhanced the teachers knowledge in AI, as well as fostered teachers\nautonomy in bringing the subject matter into their classrooms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 11:26:19 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chiu", "Thomas K. F.", ""], ["Meng", "Helen", ""], ["Chai", "Ching-Sing", ""], ["King", "Irwin", ""], ["Wong", "Savio", ""], ["Yam", "Yeung", ""]]}, {"id": "2101.07579", "submitter": "Panagiotis Tigas", "authors": "Panagiotis Tigas and Tyson Hosmer", "title": "Spatial Assembly: Generative Architecture With Reinforcement Learning,\n  Self Play and Tree Search", "comments": "Workshop on Machine Learning for Creativity and Design at the 34rd\n  Conference on Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With this work, we investigate the use of Reinforcement Learning (RL) for the\ngeneration of spatial assemblies, by combining ideas from Procedural Generation\nalgorithms (Wave Function Collapse algorithm (WFC)) and RL for Game Solving.\nWFC is a Generative Design algorithm, inspired by Constraint Solving. In WFC,\none defines a set of tiles/blocks and constraints and the algorithm generates\nan assembly that satisfies these constraints. Casting the problem of generation\nof spatial assemblies as a Markov Decision Process whose states transitions are\ndefined by WFC, we propose an algorithm that uses Reinforcement Learning and\nSelf-Play to learn a policy that generates assemblies that maximize objectives\nset by the designer. Finally, we demonstrate the use of our Spatial Assembly\nalgorithm in Architecture Design.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 11:57:10 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Tigas", "Panagiotis", ""], ["Hosmer", "Tyson", ""]]}, {"id": "2101.07599", "submitter": "Timoth\\'ee Anne", "authors": "Timoth\\'ee Anne, Jack Wilkinson, Zhibin Li", "title": "Meta-Reinforcement Learning for Adaptive Motor Control in Changing Robot\n  Dynamics and Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work developed a meta-learning approach that adapts the control policy\non the fly to different changing conditions for robust locomotion. The proposed\nmethod constantly updates the interaction model, samples feasible sequences of\nactions of estimated the state-action trajectories, and then applies the\noptimal actions to maximize the reward. To achieve online model adaptation, our\nproposed method learns different latent vectors of each training condition,\nwhich are selected online given the newly collected data. Our work designs\nappropriate state space and reward functions, and optimizes feasible actions in\nan MPC fashion which are then sampled directly in the joint space considering\nconstraints, hence requiring no prior design of specific walking gaits. We\nfurther demonstrate the robot's capability of detecting unexpected changes\nduring interaction and adapting control policies quickly. The extensive\nvalidation on the SpotMicro robot in a physics simulation shows adaptive and\nrobust locomotion skills under varying ground friction, external pushes, and\ndifferent robot models including hardware faults and changes.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 12:57:12 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Anne", "Timoth\u00e9e", ""], ["Wilkinson", "Jack", ""], ["Li", "Zhibin", ""]]}, {"id": "2101.07621", "submitter": "Tomomi Matsui", "authors": "Akihiro Kawana and Tomomi Matsui", "title": "Trading Transforms of Non-weighted Simple Games and Integer Weights of\n  Weighted Simple Games", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates simple games. A fundamental research question in this\nfield is to determine necessary and sufficient conditions for a simple game to\nbe a weighted majority game. Taylor and Zwicker (1992) showed that a simple\ngame is non-weighted if and only if there exists a trading transform of finite\nsize. They also provided an upper bound on the size of such a trading\ntransform, if it exists. Gvozdeva and Slinko (2011) improved that upper bound;\ntheir proof employed a property of linear inequalities demonstrated by Muroga\n(1971).In this study, we provide a new proof of the existence of a trading\ntransform when a given simple game is non-weighted. Our proof employs Farkas'\nlemma (1894), and yields an improved upper bound on the size of a trading\ntransform.\n  We also discuss an integer-weight representation of a weighted simple game,\nimproving the bounds obtained by Muroga (1971). We show that our bound on the\nquota is tight when the number of players is less than or equal to five, based\non the computational results obtained by Kurz (2012).\n  Furthermore, we discuss the problem of finding an integer-weight\nrepresentation under the assumption that we have minimal winning coalitions and\nmaximal losing coalitions.In particular, we show a performance of a rounding\nmethod.\n  Lastly, we address roughly weighted simple games. Gvozdeva and Slinko (2011)\nshowed that a given simple game is not roughly weighted if and only if there\nexists a potent certificate of non-weightedness. We give an upper bound on the\nlength of a potent certificate of non-weightedness. We also discuss an\ninteger-weight representation of a roughly weighted simple game.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 13:54:41 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 10:21:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kawana", "Akihiro", ""], ["Matsui", "Tomomi", ""]]}, {"id": "2101.07632", "submitter": "Hung-Ting Su", "authors": "Chen-Hsi Chang, Hung-Ting Su, Jui-heng Hsu, Yu-Siang Wang, Yu-Cheng\n  Chang, Zhe Yu Liu, Ya-Liang Chang, Wen-Feng Cheng, Ke-Jyun Wang and Winston\n  H. Hsu", "title": "Situation and Behavior Understanding by Trope Detection on Films", "comments": "WWW 2021. The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human ability of deep cognitive skills are crucial for the development of\nvarious real-world applications that process diverse and abundant user\ngenerated input. While recent progress of deep learning and natural language\nprocessing have enabled learning system to reach human performance on some\nbenchmarks requiring shallow semantics, such human ability still remains\nchallenging for even modern contextual embedding models, as pointed out by many\nrecent studies. Existing machine comprehension datasets assume sentence-level\ninput, lack of casual or motivational inferences, or could be answered with\nquestion-answer bias. Here, we present a challenging novel task, trope\ndetection on films, in an effort to create a situation and behavior\nunderstanding for machines. Tropes are storytelling devices that are frequently\nused as ingredients in recipes for creative works. Comparing to existing movie\ntag prediction tasks, tropes are more sophisticated as they can vary widely,\nfrom a moral concept to a series of circumstances, and embedded with\nmotivations and cause-and-effects. We introduce a new dataset, Tropes in Movie\nSynopses (TiMoS), with 5623 movie synopses and 95 different tropes collecting\nfrom a Wikipedia-style database, TVTropes. We present a multi-stream\ncomprehension network (MulCom) leveraging multi-level attention of words,\nsentences, and role relations. Experimental result demonstrates that modern\nmodels including BERT contextual embedding, movie tag prediction systems, and\nrelational networks, perform at most 37% of human performance (23.97/64.87) in\nterms of F1 score. Our MulCom outperforms all modern baselines, by 1.5 to 5.0\nF1 score and 1.5 to 3.0 mean of average precision (mAP) score. We also provide\na detailed analysis and human evaluation to pave ways for future research.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 14:09:54 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 03:51:10 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Chang", "Chen-Hsi", ""], ["Su", "Hung-Ting", ""], ["Hsu", "Jui-heng", ""], ["Wang", "Yu-Siang", ""], ["Chang", "Yu-Cheng", ""], ["Liu", "Zhe Yu", ""], ["Chang", "Ya-Liang", ""], ["Cheng", "Wen-Feng", ""], ["Wang", "Ke-Jyun", ""], ["Hsu", "Winston H.", ""]]}, {"id": "2101.07671", "submitter": "Jun Chen", "authors": "Jun Chen, Haopeng Chen", "title": "Edge-Featured Graph Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lots of neural network architectures have been proposed to deal with learning\ntasks on graph-structured data. However, most of these models concentrate on\nonly node features during the learning process. The edge features, which\nusually play a similarly important role as the nodes, are often ignored or\nsimplified by these models. In this paper, we present edge-featured graph\nattention networks, namely EGATs, to extend the use of graph neural networks to\nthose tasks learning on graphs with both node and edge features. These models\ncan be regarded as extensions of graph attention networks (GATs). By reforming\nthe model structure and the learning process, the new models can accept node\nand edge features as inputs, incorporate the edge information into feature\nrepresentations, and iterate both node and edge features in a parallel but\nmutual way. The results demonstrate that our work is highly competitive against\nother node classification approaches, and can be well applied in edge-featured\ngraph learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 15:08:12 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chen", "Jun", ""], ["Chen", "Haopeng", ""]]}, {"id": "2101.07674", "submitter": "Ernest Appau Kofi Mensah", "authors": "Appau Ernest", "title": "An Artificial Intelligence based approach to estimating time of arrival\n  and bus occupancy for public transport systems in Africa", "comments": "Needs to be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document entails a progressive report on the design and implementation\nof a bus tracking and monitoring system . This report has its contents within\nthe limits of five chapters with each concisely exploring their various\nobjectives. Chapter one is the introductory chapter. It entails a brief\ndescription of a bus tracking and monitoring system ,the need and the aims and\nobjectives of this project. Chapter two consists the literature review of this\nproject. This entails the critical analysis of previous related research and\nprojects undertaken by other people. The merits and demerits of the various\nimplementations.Chapter three consists of theory and design considerations of\nthe proposed system for Kwame Nkrumah University campus. Chapter four talks\nabout the methods used to collect data and the approach and technology stack\nadopted to build the proposed system.Chapter five concludes the thesis and\ndiscusses the results of test and deployment of the proposed system on Kwame\nNkrumah University of Science and Technology campus\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 15:10:16 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 23:24:51 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ernest", "Appau", ""]]}, {"id": "2101.07685", "submitter": "Mattia Setzu", "authors": "Mattia Setzu, Riccardo Guidotti, Anna Monreale, Franco Turini, Dino\n  Pedreschi, Fosca Giannotti", "title": "GLocalX -- From Local to Global Explanations of Black Box AI Models", "comments": "27 pages, 2 figures, submitted to \"Special Issue on: Explainable AI\n  (XAI) for Web-based Information Processing\"", "journal-ref": "Journal of Artificial Intelligence, Volume 294, May 2021, 103457", "doi": "10.1016/j.artint.2021.103457", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial Intelligence (AI) has come to prominence as one of the major\ncomponents of our society, with applications in most aspects of our lives. In\nthis field, complex and highly nonlinear machine learning models such as\nensemble models, deep neural networks, and Support Vector Machines have\nconsistently shown remarkable accuracy in solving complex tasks. Although\naccurate, AI models often are \"black boxes\" which we are not able to\nunderstand. Relying on these models has a multifaceted impact and raises\nsignificant concerns about their transparency. Applications in sensitive and\ncritical domains are a strong motivational factor in trying to understand the\nbehavior of black boxes. We propose to address this issue by providing an\ninterpretable layer on top of black box models by aggregating \"local\"\nexplanations. We present GLocalX, a \"local-first\" model agnostic explanation\nmethod. Starting from local explanations expressed in form of local decision\nrules, GLocalX iteratively generalizes them into global explanations by\nhierarchically aggregating them. Our goal is to learn accurate yet simple\ninterpretable models to emulate the given black box, and, if possible, replace\nit entirely. We validate GLocalX in a set of experiments in standard and\nconstrained settings with limited or no access to either data or local\nexplanations. Experiments show that GLocalX is able to accurately emulate\nseveral models with simple and small models, reaching state-of-the-art\nperformance against natively global solutions. Our findings show how it is\noften possible to achieve a high level of both accuracy and comprehensibility\nof classification models, even in complex domains with high-dimensional data,\nwithout necessarily trading one property for the other. This is a key\nrequirement for a trustworthy AI, necessary for adoption in high-stakes\ndecision making applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 15:26:09 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 11:26:16 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Setzu", "Mattia", ""], ["Guidotti", "Riccardo", ""], ["Monreale", "Anna", ""], ["Turini", "Franco", ""], ["Pedreschi", "Dino", ""], ["Giannotti", "Fosca", ""]]}, {"id": "2101.07691", "submitter": "Rachel Freedman", "authors": "Rachel Freedman, Rohin Shah and Anca Dragan", "title": "Choice Set Misspecification in Reward Inference", "comments": "Presented at the IJCAI-PRICAI 2020 Workshop on Artificial\n  Intelligence Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specifying reward functions for robots that operate in environments without a\nnatural reward signal can be challenging, and incorrectly specified rewards can\nincentivise degenerate or dangerous behavior. A promising alternative to\nmanually specifying reward functions is to enable robots to infer them from\nhuman feedback, like demonstrations or corrections. To interpret this feedback,\nrobots treat as approximately optimal a choice the person makes from a choice\nset, like the set of possible trajectories they could have demonstrated or\npossible corrections they could have made. In this work, we introduce the idea\nthat the choice set itself might be difficult to specify, and analyze choice\nset misspecification: what happens as the robot makes incorrect assumptions\nabout the set of choices from which the human selects their feedback. We\npropose a classification of different kinds of choice set misspecification, and\nshow that these different classes lead to meaningful differences in the\ninferred reward and resulting performance. While we would normally expect\nmisspecification to hurt, we find that certain kinds of misspecification are\nneither helpful nor harmful (in expectation). However, in other situations,\nmisspecification can be extremely harmful, leading the robot to believe the\nopposite of what it should believe. We hope our results will allow for better\nprediction and response to the effects of misspecification in real-world reward\ninference.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 15:35:30 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Freedman", "Rachel", ""], ["Shah", "Rohin", ""], ["Dragan", "Anca", ""]]}, {"id": "2101.07731", "submitter": "Daniel Shen", "authors": "Daniel Shen, Min Chi", "title": "TC-DTW: Accelerating Multivariate Dynamic Time Warping Through Triangle\n  Inequality and Point Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": "North Carolina State University TR-2021-2", "categories": "cs.LG cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic time warping (DTW) plays an important role in analytics on time\nseries. Despite the large body of research on speeding up univariate DTW, the\nmethod for multivariate DTW has not been improved much in the last two decades.\nThe most popular algorithm used today is still the one developed seventeen\nyears ago. This paper presents a solution that, as far as we know, for the\nfirst time consistently outperforms the classic multivariate DTW algorithm\nacross dataset sizes, series lengths, data dimensions, temporal window sizes,\nand machines. The new solution, named TC-DTW, introduces Triangle Inequality\nand Point Clustering into the algorithm design on lower bound calculations for\nmultivariate DTW. In experiments on DTW-based nearest neighbor finding, the new\nsolution avoids as much as 98% (60% average) DTW distance calculations and\nyields as much as 25X (7.5X average) speedups.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 16:38:28 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 02:55:15 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Shen", "Daniel", ""], ["Chi", "Min", ""]]}, {"id": "2101.07732", "submitter": "Ruocheng Guo", "authors": "Ruocheng Guo, Pengchuan Zhang, Hao Liu, Emre Kiciman", "title": "Out-of-distribution Prediction with Invariant Risk Minimization: The\n  Limitation and An Effective Fix", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the out-of-distribution (OOD) prediction problem where\n(1)~the training data are from multiple domains and (2)~the test domain is\nunseen in the training. DNNs fail in OOD prediction because they are prone to\npick up spurious correlations. Recently, Invariant Risk Minimization (IRM) is\nproposed to address this issue. Its effectiveness has been demonstrated in the\ncolored MNIST experiment. Nevertheless, we find that the performance of IRM can\nbe dramatically degraded under \\emph{strong $\\Lambda$ spuriousness} -- when the\nspurious correlation between the spurious features and the class label is\nstrong due to the strong causal influence of their common cause, the domain\nlabel, on both of them (see Fig. 1). In this work, we try to answer the\nquestions: why does IRM fail in the aforementioned setting? Why does IRM work\nfor the original colored MNIST dataset? How can we fix this problem of IRM?\nThen, we propose a simple and effective approach to fix the problem of IRM. We\ncombine IRM with conditional distribution matching to avoid a specific type of\nspurious correlation under strong $\\Lambda$ spuriousness. Empirically, we\ndesign a series of semi synthetic datasets -- the colored MNIST plus, which\nexposes the problems of IRM and demonstrates the efficacy of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 01:35:06 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 19:42:32 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Guo", "Ruocheng", ""], ["Zhang", "Pengchuan", ""], ["Liu", "Hao", ""], ["Kiciman", "Emre", ""]]}, {"id": "2101.07757", "submitter": "Milad Sikaroudi", "authors": "Milad Sikaroudi, Benyamin Ghojogh, Fakhri Karray, Mark Crowley, H.R.\n  Tizhoosh", "title": "Magnification Generalization for Histopathology Image Embedding", "comments": "Accepted for presentation at International Symposium on Biomedical\n  Imaging (ISBI'2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Histopathology image embedding is an active research area in computer vision.\nMost of the embedding models exclusively concentrate on a specific\nmagnification level. However, a useful task in histopathology embedding is to\ntrain an embedding space regardless of the magnification level. Two main\napproaches for tackling this goal are domain adaptation and domain\ngeneralization, where the target magnification levels may or may not be\nintroduced to the model in training, respectively. Although magnification\nadaptation is a well-studied topic in the literature, this paper, to the best\nof our knowledge, is the first work on magnification generalization for\nhistopathology image embedding. We use an episodic trainable domain\ngeneralization technique for magnification generalization, namely Model\nAgnostic Learning of Semantic Features (MASF), which works based on the Model\nAgnostic Meta-Learning (MAML) concept. Our experimental results on a breast\ncancer histopathology dataset with four different magnification levels show the\nproposed method's effectiveness for magnification generalization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 02:46:26 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Sikaroudi", "Milad", ""], ["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "2101.07769", "submitter": "Peng Gao", "authors": "Peng Gao, Xiaoyuan Liu, Edward Choi, Bhavna Soman, Chinmaya Mishra,\n  Kate Farris, Dawn Song", "title": "A System for Automated Open-Source Threat Intelligence Gathering and\n  Management", "comments": "Accepted paper at SIGMOD 2021 demonstrations track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To remain aware of the fast-evolving cyber threat landscape, open-source\nCyber Threat Intelligence (OSCTI) has received growing attention from the\ncommunity. Commonly, knowledge about threats is presented in a vast number of\nOSCTI reports. Despite the pressing need for high-quality OSCTI, existing OSCTI\ngathering and management platforms, however, have primarily focused on\nisolated, low-level Indicators of Compromise. On the other hand, higher-level\nconcepts (e.g., adversary tactics, techniques, and procedures) and their\nrelationships have been overlooked, which contain essential knowledge about\nthreat behaviors that is critical to uncovering the complete threat scenario.\nTo bridge the gap, we propose SecurityKG, a system for automated OSCTI\ngathering and management. SecurityKG collects OSCTI reports from various\nsources, uses a combination of AI and NLP techniques to extract high-fidelity\nknowledge about threat behaviors, and constructs a security knowledge graph.\nSecurityKG also provides a UI that supports various types of interactivity to\nfacilitate knowledge graph exploration.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 18:31:35 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 20:50:51 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Gao", "Peng", ""], ["Liu", "Xiaoyuan", ""], ["Choi", "Edward", ""], ["Soman", "Bhavna", ""], ["Mishra", "Chinmaya", ""], ["Farris", "Kate", ""], ["Song", "Dawn", ""]]}, {"id": "2101.07816", "submitter": "Ferhat Ozgur Catak", "authors": "Umit Cali, Murat Kuzlu, Vinayak Sharma, Manisa Pipattanasomporn,\n  Ferhat Ozgur Catak", "title": "Internet of Predictable Things (IoPT) Framework to Increase\n  Cyber-Physical System Resiliency", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two decades, distributed energy systems, especially renewable\nenergy sources (RES), have become more economically viable with increasing\nmarket share and penetration levels on power systems. In addition to\ndecarbonization and decentralization of energy systems, digitalization has also\nbecome very important. The use of artificial intelligence (AI), advanced\noptimization algorithms, Industrial Internet of Things (IIoT), and other\ndigitalization frameworks makes modern power system assets more intelligent,\nwhile vulnerable to cybersecurity risks. This paper proposes the concept of the\nInternet of Predictable Things (IoPT) that incorporates advanced data analytics\nand machine learning methods to increase the resiliency of cyber-physical\nsystems against cybersecurity risks. The proposed concept is demonstrated using\na cyber-physical system testbed under a variety of cyber attack scenarios as a\nproof of concept (PoC).\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 19:01:56 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cali", "Umit", ""], ["Kuzlu", "Murat", ""], ["Sharma", "Vinayak", ""], ["Pipattanasomporn", "Manisa", ""], ["Catak", "Ferhat Ozgur", ""]]}, {"id": "2101.07825", "submitter": "Matteo Turchetta", "authors": "Christopher K\\\"onig, Matteo Turchetta, John Lygeros, Alisa Rupenyan,\n  Andreas Krause", "title": "Safe and Efficient Model-free Adaptive Control via Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive control approaches yield high-performance controllers when a precise\nsystem model or suitable parametrizations of the controller are available.\nExisting data-driven approaches for adaptive control mostly augment standard\nmodel-based methods with additional information about uncertainties in the\ndynamics or about disturbances. In this work, we propose a purely data-driven,\nmodel-free approach for adaptive control. Tuning low-level controllers based\nsolely on system data raises concerns on the underlying algorithm safety and\ncomputational performance. Thus, our approach builds on GoOSE, an algorithm for\nsafe and sample-efficient Bayesian optimization. We introduce several\ncomputational and algorithmic modifications in GoOSE that enable its practical\nuse on a rotational motion system. We numerically demonstrate for several types\nof disturbances that our approach is sample efficient, outperforms constrained\nBayesian optimization in terms of safety, and achieves the performance optima\ncomputed by grid evaluation. We further demonstrate the proposed adaptive\ncontrol approach experimentally on a rotational motion system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 19:15:00 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 13:26:34 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["K\u00f6nig", "Christopher", ""], ["Turchetta", "Matteo", ""], ["Lygeros", "John", ""], ["Rupenyan", "Alisa", ""], ["Krause", "Andreas", ""]]}, {"id": "2101.07844", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten, Pieter-Jan Daems, Eugenio Bargiacchi, Diederik M.\n  Roijers, Pieter J.K. Libin, Jan Helsen", "title": "Scalable Optimization for Wind Farm Control using Coordination Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind farms are a crucial driver toward the generation of ecological and\nrenewable energy. Due to their rapid increase in capacity, contemporary wind\nfarms need to adhere to strict constraints on power output to ensure stability\nof the electricity grid. Specifically, a wind farm controller is required to\nmatch the farm's power production with a power demand imposed by the grid\noperator. This is a non-trivial optimization problem, as complex dependencies\nexist between the wind turbines. State-of-the-art wind farm control typically\nrelies on physics-based heuristics that fail to capture the full load spectrum\nthat defines a turbine's health status. When this is not taken into account,\nthe long-term viability of the farm's turbines is put at risk. Given the\ncomplex dependencies that determine a turbine's lifetime, learning a flexible\nand optimal control strategy requires a data-driven approach. However, as wind\nfarms are large-scale multi-agent systems, optimizing control strategies over\nthe full joint action space is intractable. We propose a new learning method\nfor wind farm control that leverages the sparse wind farm structure to\nfactorize the optimization problem. Using a Bayesian approach, based on\nmulti-agent Thompson sampling, we explore the factored joint action space for\nconfigurations that match the demand, while considering the lifetime of\nturbines. We apply our method to a grid-like wind farm layout, and evaluate\nconfigurations using a state-of-the-art wind flow simulator. Our results are\ncompetitive with a physics-based heuristic approach in terms of demand error,\nwhile, contrary to the heuristic, our method prolongs the lifetime of high-risk\nturbines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 20:12:30 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Daems", "Pieter-Jan", ""], ["Bargiacchi", "Eugenio", ""], ["Roijers", "Diederik M.", ""], ["Libin", "Pieter J. K.", ""], ["Helsen", "Jan", ""]]}, {"id": "2101.07868", "submitter": "Jacob Schrum", "authors": "Kirby Steckel and Jacob Schrum", "title": "Illuminating the Space of Beatable Lode Runner Levels Produced By\n  Various Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are capable of generating convincing\nimitations of elements from a training set, but the distribution of elements in\nthe training set affects to difficulty of properly training the GAN and the\nquality of the outputs it produces. This paper looks at six different GANs\ntrained on different subsets of data from the game Lode Runner. The quality\ndiversity algorithm MAP-Elites was used to explore the set of quality levels\nthat could be produced by each GAN, where quality was defined as being beatable\nand having the longest solution path possible. Interestingly, a GAN trained on\nonly 20 levels generated the largest set of diverse beatable levels while a GAN\ntrained on 150 levels generated the smallest set of diverse beatable levels,\nthus challenging the notion that more is always better when training GANs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 21:41:42 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Steckel", "Kirby", ""], ["Schrum", "Jacob", ""]]}, {"id": "2101.07907", "submitter": "Sergio Casas", "authors": "Sergio Casas, Wenjie Luo, Raquel Urtasun", "title": "IntentNet: Learning to Predict Intention from Raw Sensor Data", "comments": "CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to plan a safe maneuver, self-driving vehicles need to understand\nthe intent of other traffic participants. We define intent as a combination of\ndiscrete high-level behaviors as well as continuous trajectories describing\nfuture motion. In this paper, we develop a one-stage detector and forecaster\nthat exploits both 3D point clouds produced by a LiDAR sensor as well as\ndynamic maps of the environment. Our multi-task model achieves better accuracy\nthan the respective separate modules while saving computation, which is\ncritical to reducing reaction time in self-driving applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 00:31:52 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Casas", "Sergio", ""], ["Luo", "Wenjie", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.07918", "submitter": "HongChien Yu", "authors": "HongChien Yu, Zhuyun Dai, Jamie Callan", "title": "PGT: Pseudo Relevance Feedback Using a Graph-Based Transformer", "comments": "Accepted at ECIR 2021 (short paper track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on pseudo relevance feedback (PRF) has been done in vector\nspace and probabilistic retrieval models. This paper shows that\nTransformer-based rerankers can also benefit from the extra context that PRF\nprovides. It presents PGT, a graph-based Transformer that sparsifies attention\nbetween graph nodes to enable PRF while avoiding the high computational\ncomplexity of most Transformer architectures. Experiments show that PGT\nimproves upon non-PRF Transformer reranker, and it is at least as accurate as\nTransformer PRF models that use full attention, but with lower computational\ncosts.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 01:07:47 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Yu", "HongChien", ""], ["Dai", "Zhuyun", ""], ["Callan", "Jamie", ""]]}, {"id": "2101.07937", "submitter": "Woong-Hee Lee", "authors": "Woong-Hee Lee, Mustafa Ozger, Ursula Challita, and Ki Won Sung", "title": "Noise Learning Based Denoising Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This letter introduces a new denoiser that modifies the structure of\ndenoising autoencoder (DAE), namely noise learning based DAE (nlDAE). The\nproposed nlDAE learns the noise of the input data. Then, the denoising is\nperformed by subtracting the regenerated noise from the noisy input. Hence,\nnlDAE is more effective than DAE when the noise is simpler to regenerate than\nthe original data. To validate the performance of nlDAE, we provide three case\nstudies: signal restoration, symbol demodulation, and precise localization.\nNumerical results suggest that nlDAE requires smaller latent space dimension\nand smaller training dataset compared to DAE.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 02:45:13 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 10:13:31 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Lee", "Woong-Hee", ""], ["Ozger", "Mustafa", ""], ["Challita", "Ursula", ""], ["Sung", "Ki Won", ""]]}, {"id": "2101.07947", "submitter": "Zekang Li", "authors": "Zekang Li, Zongjia Li, Jinchao Zhang, Yang Feng and Jie Zhou", "title": "WeChat AI & ICT's Submission for DSTC9 Interactive Dialogue Evaluation\n  Track", "comments": "DSTC9@AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participate in the DSTC9 Interactive Dialogue Evaluation Track (Gunasekara\net al. 2020) sub-task 1 (Knowledge Grounded Dialogue) and sub-task 2\n(Interactive Dialogue). In sub-task 1, we employ a pre-trained language model\nto generate topic-related responses and propose a response ensemble method for\nresponse selection. In sub-task2, we propose a novel Dialogue Planning Model\n(DPM) to capture conversation flow in the interaction with humans. We also\ndesign an integrated open-domain dialogue system containing pre-process,\ndialogue model, scoring model, and post-process, which can generate fluent,\ncoherent, consistent, and humanlike responses. We tie 1st on human ratings and\nalso get the highest Meteor, and Bert-score in sub-task 1, and rank 3rd on\ninteractive human evaluation in sub-task 2.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 03:19:50 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 03:03:52 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Zekang", ""], ["Li", "Zongjia", ""], ["Zhang", "Jinchao", ""], ["Feng", "Yang", ""], ["Zhou", "Jie", ""]]}, {"id": "2101.07965", "submitter": "Jie Chen", "authors": "Veronika Thost, Jie Chen", "title": "Directed Acyclic Graph Neural Networks", "comments": "ICLR 2021. Code is available at https://github.com/vthost/DAGNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data ubiquitously appears in science and engineering. Graph\nneural networks (GNNs) are designed to exploit the relational inductive bias\nexhibited in graphs; they have been shown to outperform other forms of neural\nnetworks in scenarios where structure information supplements node features.\nThe most common GNN architecture aggregates information from neighborhoods\nbased on message passing. Its generality has made it broadly applicable. In\nthis paper, we focus on a special, yet widely used, type of graphs -- DAGs --\nand inject a stronger inductive bias -- partial ordering -- into the neural\nnetwork design. We propose the \\emph{directed acyclic graph neural network},\nDAGNN, an architecture that processes information according to the flow defined\nby the partial order. DAGNN can be considered a framework that entails earlier\nworks as special cases (e.g., models for trees and models updating node\nrepresentations recurrently), but we identify several crucial components that\nprior architectures lack. We perform comprehensive experiments, including\nablation studies, on representative DAG datasets (i.e., source code, neural\narchitectures, and probabilistic graphical models) and demonstrate the\nsuperiority of DAGNN over simpler DAG architectures as well as general graph\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 04:50:16 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 18:18:07 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 18:45:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Thost", "Veronika", ""], ["Chen", "Jie", ""]]}, {"id": "2101.07968", "submitter": "Shangming Cai", "authors": "Shangming Cai, Dongsheng Wang, Haixia Wang, Yongqiang Lyu, Guangquan\n  Xu, Xi Zheng and Athanasios V. Vasilakos", "title": "DynaComm: Accelerating Distributed CNN Training between Edges and Clouds\n  through Dynamic Communication Scheduling", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce uploading bandwidth and address privacy concerns, deep learning at\nthe network edge has been an emerging topic. Typically, edge devices\ncollaboratively train a shared model using real-time generated data through the\nParameter Server framework. Although all the edge devices can share the\ncomputing workloads, the distributed training processes over edge networks are\nstill time-consuming due to the parameters and gradients transmission\nprocedures between parameter servers and edge devices. Focusing on accelerating\ndistributed Convolutional Neural Networks (CNNs) training at the network edge,\nwe present DynaComm, a novel scheduler that dynamically decomposes each\ntransmission procedure into several segments to achieve optimal communications\nand computations overlapping during run-time. Through experiments, we verify\nthat DynaComm manages to achieve optimal scheduling for all cases compared to\ncompeting strategies while the model accuracy remains untouched.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 05:09:41 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cai", "Shangming", ""], ["Wang", "Dongsheng", ""], ["Wang", "Haixia", ""], ["Lyu", "Yongqiang", ""], ["Xu", "Guangquan", ""], ["Zheng", "Xi", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2101.08001", "submitter": "Siyi Hu", "authors": "Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang", "title": "UPDeT: Universal Multi-agent Reinforcement Learning via Policy\n  Decoupling with Transformers", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in multi-agent reinforcement learning have been largely\nlimited in training one model from scratch for every new task. The limitation\nis due to the restricted model architecture related to fixed input and output\ndimensions. This hinders the experience accumulation and transfer of the\nlearned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs\n6 multi-agent games). In this paper, we make the first attempt to explore a\nuniversal multi-agent reinforcement learning pipeline, designing one single\narchitecture to fit tasks with the requirement of different observation and\naction configurations. Unlike previous RNN-based models, we utilize a\ntransformer-based model to generate a flexible policy by decoupling the policy\ndistribution from the intertwined input observation with an importance weight\nmeasured by the merits of the self-attention mechanism. Compared to a standard\ntransformer block, the proposed model, named as Universal Policy Decoupling\nTransformer (UPDeT), further relaxes the action restriction and makes the\nmulti-agent task's decision process more explainable. UPDeT is general enough\nto be plugged into any multi-agent reinforcement learning pipeline and equip\nthem with strong generalization abilities that enables the handling of multiple\ntasks at a time. Extensive experiments on large-scale SMAC multi-agent\ncompetitive games demonstrate that the proposed UPDeT-based multi-agent\nreinforcement learning achieves significant results relative to\nstate-of-the-art approaches, demonstrating advantageous transfer capability in\nterms of both performance and training speed (10 times faster).\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 07:24:24 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 05:12:07 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 10:28:41 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hu", "Siyi", ""], ["Zhu", "Fengda", ""], ["Chang", "Xiaojun", ""], ["Liang", "Xiaodan", ""]]}, {"id": "2101.08020", "submitter": "Xie Luodi", "authors": "Luodi Xie, Hong Shen, Jiaxin Ren", "title": "NEMR: Network Embedding on Metric of Relation", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding maps the nodes of a given network into a low-dimensional\nspace such that the semantic similarities among the nodes can be effectively\ninferred. Most existing approaches use inner-product of node embedding to\nmeasure the similarity between nodes leading to the fact that they lack the\ncapacity to capture complex relationships among nodes. Besides, they take the\npath in the network just as structural auxiliary information when inferring\nnode embeddings, while paths in the network are formed with rich user\ninformations which are semantically relevant and cannot be ignored. In this\npaper, We propose a novel method called Network Embedding on the Metric of\nRelation, abbreviated as NEMR, which can learn the embeddings of nodes in a\nrelational metric space efficiently. First, our NEMR models the relationships\namong nodes in a metric space with deep learning methods including variational\ninference that maps the relationship of nodes to a gaussian distribution so as\nto capture the uncertainties. Secondly, our NEMR considers not only the\nequivalence of multiple-paths but also the natural order of a single-path when\ninferring embeddings of nodes, which makes NEMR can capture the multiple\nrelationships among nodes since multiple paths contain rich user information,\ne.g., age, hobby and profession. Experimental results on several public\ndatasets show that the NEMR outperforms the state-of-the-art methods on\nrelevant inference tasks including link prediction and node classification.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 08:35:03 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Xie", "Luodi", ""], ["Shen", "Hong", ""], ["Ren", "Jiaxin", ""]]}, {"id": "2101.08030", "submitter": "Francesco Cartella", "authors": "Francesco Cartella, Orlando Anunciacao, Yuki Funabiki, Daisuke\n  Yamaguchi, Toru Akishita, Olivier Elshocht", "title": "Adversarial Attacks for Tabular Data: Application to Fraud Detection and\n  Imbalanced Data", "comments": "Will be published on Proceedings of the Workshop on Artificial\n  Intelligence Safety (SafeAI 2021) co-located with 35th AAAI Conference on\n  Artificial Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guaranteeing the security of transactional systems is a crucial priority of\nall institutions that process transactions, in order to protect their\nbusinesses against cyberattacks and fraudulent attempts. Adversarial attacks\nare novel techniques that, other than being proven to be effective to fool\nimage classification models, can also be applied to tabular data. Adversarial\nattacks aim at producing adversarial examples, in other words, slightly\nmodified inputs that induce the Artificial Intelligence (AI) system to return\nincorrect outputs that are advantageous for the attacker. In this paper we\nillustrate a novel approach to modify and adapt state-of-the-art algorithms to\nimbalanced tabular data, in the context of fraud detection. Experimental\nresults show that the proposed modifications lead to a perfect attack success\nrate, obtaining adversarial examples that are also less perceptible when\nanalyzed by humans. Moreover, when applied to a real-world production system,\nthe proposed techniques shows the possibility of posing a serious threat to the\nrobustness of advanced AI-based fraud detection procedures.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 08:58:29 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cartella", "Francesco", ""], ["Anunciacao", "Orlando", ""], ["Funabiki", "Yuki", ""], ["Yamaguchi", "Daisuke", ""], ["Akishita", "Toru", ""], ["Elshocht", "Olivier", ""]]}, {"id": "2101.08035", "submitter": "C. Maria Keet", "authors": "C. Maria Keet", "title": "Bias in ontologies -- a preliminary assessment", "comments": "10 pages, 4 figures, 2 tables, soon to be submitted to an\n  international conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical theories in the form of ontologies and similar artefacts in computing\nand IT are used for structuring, annotating, and querying data, among others,\nand therewith influence data analytics regarding what is fed into the\nalgorithms. Algorithmic bias is a well-known notion, but what does bias mean in\nthe context of ontologies that provide a structuring mechanism for an\nalgorithm's input? What are the sources of bias there and how would they\nmanifest themselves in ontologies? We examine and enumerate types of bias\nrelevant for ontologies, and whether they are explicit or implicit. These eight\ntypes are illustrated with examples from extant production-level ontologies and\nsamples from the literature. We then assessed three concurrently developed\nCOVID-19 ontologies on bias and detected different subsets of types of bias in\neach one, to a greater or lesser extent. This first characterisation aims\ncontribute to a sensitisation of ethical aspects of ontologies primarily\nregarding representation of information and knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 09:28:08 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Keet", "C. Maria", ""]]}, {"id": "2101.08074", "submitter": "Chao Yan", "authors": "Chao Yan, Xiaojia Xiang, Chang Wang, Zhen Lan", "title": "Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs\n  Using Deep Reinforcement Learning", "comments": "Accepted for publication in the proceedings of the 2021 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is\nstill a challenge due to kinematic complexity and environmental uncertainty. In\nthis paper, we deal with the decentralized flocking and collision avoidance\nproblem through deep reinforcement learning (DRL). Specifically, we formulate a\ndecentralized DRL-based decision making framework from the perspective of every\nfollower, where a collision avoidance mechanism is integrated into the flocking\ncontroller. Then, we propose a novel reinforcement learning algorithm PS-CACER\nfor training a shared control policy for all the followers. Besides, we design\na plug-n-play embedding module based on convolutional neural networks and the\nattention mechanism. As a result, the variable-length system state can be\nencoded into a fixed-length embedding vector, which makes the learned DRL\npolicy independent with the number and the order of followers. Finally,\nnumerical simulation results demonstrate the effectiveness of the proposed\nmethod, and the learned policies can be directly transferred to semi-physical\nsimulation without any parameter finetuning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 11:23:35 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 11:37:13 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yan", "Chao", ""], ["Xiang", "Xiaojia", ""], ["Wang", "Chang", ""], ["Lan", "Zhen", ""]]}, {"id": "2101.08114", "submitter": "Jose Manuel Gomez-Perez", "authors": "Andres Garcia-Silva and Jose Manuel Gomez-Perez", "title": "Classifying Scientific Publications with BERT -- Is Self-Attention a\n  Feature Selection Method?", "comments": "Paper accepted for publication at ECIR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the self-attention mechanism of BERT in a fine-tuning scenario\nfor the classification of scientific articles over a taxonomy of research\ndisciplines. We observe how self-attention focuses on words that are highly\nrelated to the domain of the article. Particularly, a small subset of\nvocabulary words tends to receive most of the attention. We compare and\nevaluate the subset of the most attended words with feature selection methods\nnormally used for text classification in order to characterize self-attention\nas a possible feature selection approach. Using ConceptNet as ground truth, we\nalso find that attended words are more related to the research fields of the\narticles. However, conventional feature selection methods are still a better\noption to learn classifiers from scratch. This result suggests that, while\nself-attention identifies domain-relevant terms, the discriminatory information\nin BERT is encoded in the contextualized outputs and the classification layer.\nIt also raises the question whether injecting feature selection methods in the\nself-attention mechanism could further optimize single sequence classification\nusing transformers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 13:22:26 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Garcia-Silva", "Andres", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "2101.08134", "submitter": "Mohamed Abdelfattah", "authors": "Mohamed S. Abdelfattah, Abhinav Mehrotra, {\\L}ukasz Dudziak, Nicholas\n  D. Lane", "title": "Zero-Cost Proxies for Lightweight NAS", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Neural Architecture Search (NAS) is quickly becoming the standard methodology\nto design neural network models. However, NAS is typically compute-intensive\nbecause multiple models need to be evaluated before choosing the best one. To\nreduce the computational power and time needed, a proxy task is often used for\nevaluating each model instead of full training. In this paper, we evaluate\nconventional reduced-training proxies and quantify how well they preserve\nranking between multiple models during search when compared with the rankings\nproduced by final trained accuracy. We propose a series of zero-cost proxies,\nbased on recent pruning literature, that use just a single minibatch of\ntraining data to compute a model's score. Our zero-cost proxies use 3 orders of\nmagnitude less computation but can match and even outperform conventional\nproxies. For example, Spearman's rank correlation coefficient between final\nvalidation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82,\ncompared to 0.61 for EcoNAS (a recently proposed reduced-training proxy).\nFinally, we use these zero-cost proxies to enhance existing NAS search\nalgorithms such as random search, reinforcement learning, evolutionary search\nand predictor-based search. For all search methodologies and across three\ndifferent NAS datasets, we are able to significantly improve sample efficiency,\nand thereby decrease computation, by using our zero-cost proxies. For example\non NAS-Bench-101, we achieved the same accuracy 4$\\times$ quicker than the best\nprevious result. Our code is made public at:\nhttps://github.com/mohsaied/zero-cost-nas.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 13:59:52 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 10:43:12 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Abdelfattah", "Mohamed S.", ""], ["Mehrotra", "Abhinav", ""], ["Dudziak", "\u0141ukasz", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2101.08153", "submitter": "Daniel Kroening", "authors": "Mirco Giacobbe, Mohammadhosein Hasanbeig, Daniel Kroening, Hjalmar\n  Wijk", "title": "Shielding Atari Games with Bounded Prescience", "comments": "To appear at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is applied in safety-critical domains such\nas robotics and autonomous driving. It achieves superhuman abilities in many\ntasks, however whether DRL agents can be shown to act safely is an open\nproblem. Atari games are a simple yet challenging exemplar for evaluating the\nsafety of DRL agents and feature a diverse portfolio of game mechanics. The\nsafety of neural agents has been studied before using methods that either\nrequire a model of the system dynamics or an abstraction; unfortunately, these\nare unsuitable to Atari games because their low-level dynamics are complex and\nhidden inside their emulator. We present the first exact method for analysing\nand ensuring the safety of DRL agents for Atari games. Our method only requires\naccess to the emulator. First, we give a set of 43 properties that characterise\n\"safe behaviour\" for 30 games. Second, we develop a method for exploring all\ntraces induced by an agent and a game and consider a variety of sources of game\nnon-determinism. We observe that the best available DRL agents reliably satisfy\nonly very few properties; several critical properties are violated by all\nagents. Finally, we propose a countermeasure that combines a bounded\nexplicit-state exploration with shielding. We demonstrate that our method\nimproves the safety of all agents over multiple properties.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 14:22:04 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 14:08:01 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Giacobbe", "Mirco", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Kroening", "Daniel", ""], ["Wijk", "Hjalmar", ""]]}, {"id": "2101.08169", "submitter": "Paulo Andr\\'e Lima de Castro", "authors": "Paulo Andr\\'e Lima de Castro", "title": "mt5b3: A Framework for Building AutonomousTraders", "comments": "arXiv admin note: text overlap with arXiv:2101.07217", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Autonomous trading robots have been studied in ar-tificial intelligence area\nfor quite some time. Many AI techniqueshave been tested in finance field\nincluding recent approaches likeconvolutional neural networks and deep\nreinforcement learning.There are many reported cases, where the developers are\nsuc-cessful in creating robots with great performance when executingwith\nhistorical price series, so called backtesting. However, whenthese robots are\nused in real markets or data not used intheir training or evaluation frequently\nthey present very poorperformance in terms of risks and return. In this paper,\nwediscussed some fundamental aspects of modelling autonomoustraders and the\ncomplex environment that is the financialworld. Furthermore, we presented a\nframework that helps thedevelopment and testing of autonomous traders. It may\nalso beused in real or simulated operation in financial markets. Finally,we\ndiscussed some open problems in the area and pointed outsome interesting\ntechnologies that may contribute to advancein such task. We believe that mt5b3\nmay also contribute todevelopment of new autonomous traders.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 15:01:02 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["de Castro", "Paulo Andr\u00e9 Lima", ""]]}, {"id": "2101.08170", "submitter": "Qingyun Sun", "authors": "Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Yuanxing Ning, Phillip S.\n  Yu, Lifang He", "title": "SUGAR: Subgraph Neural Network with Reinforcement Pooling and\n  Self-Supervised Mutual Information Mechanism", "comments": "Accepted by The Web Conference (WWW) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has attracted increasing research attention.\nHowever, most existing studies fuse all structural features and node attributes\nto provide an overarching view of graphs, neglecting finer substructures'\nsemantics, and suffering from interpretation enigmas. This paper presents a\nnovel hierarchical subgraph-level selection and embedding based graph neural\nnetwork for graph classification, namely SUGAR, to learn more discriminative\nsubgraph representations and respond in an explanatory way. SUGAR reconstructs\na sketched graph by extracting striking subgraphs as the representative part of\nthe original graph to reveal subgraph-level patterns. To adaptively select\nstriking subgraphs without prior knowledge, we develop a reinforcement pooling\nmechanism, which improves the generalization ability of the model. To\ndifferentiate subgraph representations among graphs, we present a\nself-supervised mutual information mechanism to encourage subgraph embedding to\nbe mindful of the global graph structural properties by maximizing their mutual\ninformation. Extensive experiments on six typical bioinformatics datasets\ndemonstrate a significant and consistent improvement in model quality with\ncompetitive performance and interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 15:06:16 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 08:57:10 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 06:08:47 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sun", "Qingyun", ""], ["Li", "Jianxin", ""], ["Peng", "Hao", ""], ["Wu", "Jia", ""], ["Ning", "Yuanxing", ""], ["Yu", "Phillip S.", ""], ["He", "Lifang", ""]]}, {"id": "2101.08349", "submitter": "Varun Mandalapu", "authors": "Varun Mandalapu, Jiaqi Gong and Lujie Chen", "title": "Do we need to go Deep? Knowledge Tracing with Big Data", "comments": "9 Pages, 4 figures, AAAI Workshop on AI in Education (Imagining\n  Post-COVID Education with AI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interactive Educational Systems (IES) enabled researchers to trace student\nknowledge in different skills and provide recommendations for a better learning\npath. To estimate the student knowledge and further predict their future\nperformance, the interest in utilizing the student interaction data captured by\nIES to develop learner performance models is increasing rapidly. Moreover, with\nthe advances in computing systems, the amount of data captured by these IES\nsystems is also increasing that enables deep learning models to compete with\ntraditional logistic models and Markov processes. However, it is still not\nempirically evident if these deep models outperform traditional models on the\ncurrent scale of datasets with millions of student interactions. In this work,\nwe adopt EdNet, the largest student interaction dataset publicly available in\nthe education domain, to understand how accurately both deep and traditional\nmodels predict future student performances. Our work observes that logistic\nregression models with carefully engineered features outperformed deep models\nfrom extensive experimentation. We follow this analysis with interpretation\nstudies based on Locally Interpretable Model-agnostic Explanation (LIME) to\nunderstand the impact of various features on best performing model\npre-dictions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 22:40:38 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Mandalapu", "Varun", ""], ["Gong", "Jiaqi", ""], ["Chen", "Lujie", ""]]}, {"id": "2101.08377", "submitter": "Sebastian Rudolph", "authors": "Emanuel Kiero\\'nski and Sebastian Rudolph", "title": "Finite Model Theory of the Triguarded Fragment and Related Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Triguarded Fragment (TGF) is among the most expressive decidable\nfragments of first-order logic, subsuming both its two-variable and guarded\nfragments without equality. We show that the TGF has the finite model property\n(providing a tight doubly exponential bound on the model size) and hence finite\nsatisfiability coincides with satisfiability known to be N2ExpTime-complete.\nUsing similar constructions, we also establish 2ExpTime-completeness for finite\nsatisfiability of the constant-free (tri)guarded fragment with transitive\nguards.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 00:47:50 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 08:56:14 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kiero\u0144ski", "Emanuel", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2101.08387", "submitter": "Yongquan Yang", "authors": "Yongquan Yang, Haijun Lv, Ning Chen", "title": "A Survey on Ensemble Learning under the Era of Deep Learning", "comments": "39 pages, 9 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the dominant position of deep learning (mostly deep neural networks)\nin various artificial intelligence applications, recently, ensemble learning\nbased on deep neural networks (ensemble deep learning) has shown significant\nperformances in improving the generalization of learning system. However, since\nmodern deep neural networks usually have millions to billions of parameters,\nthe time and space overheads for training multiple base deep learners and\ntesting with the ensemble deep learner are far greater than that of traditional\nensemble learning. Though several algorithms of fast ensemble deep learning\nhave been proposed to promote the deployment of ensemble deep learning in some\napplications, further advances still need to be made for many applications in\nspecific fields, where the developing time and computing resources are usually\nrestricted or the data to be processed is of large dimensionality. An urgent\nproblem needs to be solved is how to take the significant advantages of\nensemble deep learning while reduce the required time and space overheads so\nthat many more applications in specific fields can benefit from it. For the\nalleviation of this problem, it is essential to know about how ensemble\nlearning has developed under the era of deep learning. Thus, in this article,\nwe present discussion focusing on data analyses of published works, the\nmethodology, recent works and unattainability of traditional ensemble learning,\nand recent developments of ensemble deep learning. We hope this article will be\nhelpful to realize the technical challenges faced by future developments of\nensemble learning under the era of deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 01:33:23 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 03:28:11 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 03:47:12 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yang", "Yongquan", ""], ["Lv", "Haijun", ""], ["Chen", "Ning", ""]]}, {"id": "2101.08391", "submitter": "Xu Chen", "authors": "Qiong Wu and Xu Chen and Zhi Zhou and Liang Chen and Junshan Zhang", "title": "Deep Reinforcement Learning with Spatio-temporal Traffic Forecasting for\n  Data-Driven Base Station Sleep Control", "comments": "Accepted by IEEE/ACM Transactions on Networking, Jan. 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the ever increasing mobile traffic demand in 5G era, base stations\n(BSs) have been densely deployed in radio access networks (RANs) to increase\nthe network coverage and capacity. However, as the high density of BSs is\ndesigned to accommodate peak traffic, it would consume an unnecessarily large\namount of energy if BSs are on during off-peak time. To save the energy\nconsumption of cellular networks, an effective way is to deactivate some idle\nbase stations that do not serve any traffic demand. In this paper, we develop a\ntraffic-aware dynamic BS sleep control framework, named DeepBSC, which presents\na novel data-driven learning approach to determine the BS active/sleep modes\nwhile meeting lower energy consumption and satisfactory Quality of Service\n(QoS) requirements. Specifically, the traffic demands are predicted by the\nproposed GS-STN model, which leverages the geographical and semantic\nspatial-temporal correlations of mobile traffic. With accurate mobile traffic\nforecasting, the BS sleep control problem is cast as a Markov Decision Process\nthat is solved by Actor-Critic reinforcement learning methods. To reduce the\nvariance of cost estimation in the dynamic environment, we propose a benchmark\ntransformation method that provides robust performance indicator for policy\nupdate. To expedite the training process, we adopt a Deep Deterministic Policy\nGradient (DDPG) approach, together with an explorer network, which can\nstrengthen the exploration further. Extensive experiments with a real-world\ndataset corroborate that our proposed framework significantly outperforms the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 01:39:42 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Wu", "Qiong", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Chen", "Liang", ""], ["Zhang", "Junshan", ""]]}, {"id": "2101.08430", "submitter": "Xiangyu He", "authors": "Xiangyu He, Qinghao Hu, Peisong Wang, Jian Cheng", "title": "Generative Zero-shot Network Quantization", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are able to learn realistic image priors from\nnumerous training samples in low-level image generation and restoration. We\nshow that, for high-level image recognition tasks, we can further reconstruct\n\"realistic\" images of each category by leveraging intrinsic Batch Normalization\n(BN) statistics without any training data. Inspired by the popular VAE/GAN\nmethods, we regard the zero-shot optimization process of synthetic images as\ngenerative modeling to match the distribution of BN statistics. The generated\nimages serve as a calibration set for the following zero-shot network\nquantizations. Our method meets the needs for quantizing models based on\nsensitive information, \\textit{e.g.,} due to privacy concerns, no data is\navailable. Extensive experiments on benchmark datasets show that, with the help\nof generated data, our approach consistently outperforms existing data-free\nquantization methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 04:10:04 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["He", "Xiangyu", ""], ["Hu", "Qinghao", ""], ["Wang", "Peisong", ""], ["Cheng", "Jian", ""]]}, {"id": "2101.08435", "submitter": "Ke He", "authors": "Ke He, Le He, Lisheng Fan, Yansha Deng, George K. Karagiannidis, and\n  Arumugam Nallanathan", "title": "Learning based signal detection for MIMO systems with unknown noise\n  statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to devise a generalized maximum likelihood (ML) estimator to\nrobustly detect signals with unknown noise statistics in multiple-input\nmultiple-output (MIMO) systems. In practice, there is little or even no\nstatistical knowledge on the system noise, which in many cases is non-Gaussian,\nimpulsive and not analyzable. Existing detection methods have mainly focused on\nspecific noise models, which are not robust enough with unknown noise\nstatistics. To tackle this issue, we propose a novel ML detection framework to\neffectively recover the desired signal. Our framework is a fully probabilistic\none that can efficiently approximate the unknown noise distribution through a\nnormalizing flow. Importantly, this framework is driven by an unsupervised\nlearning approach, where only the noise samples are required. To reduce the\ncomputational complexity, we further present a low-complexity version of the\nframework, by utilizing an initial estimation to reduce the search space.\nSimulation results show that our framework outperforms other existing\nalgorithms in terms of bit error rate (BER) in non-analytical noise\nenvironments, while it can reach the ML performance bound in analytical noise\nenvironments. The code of this paper is available at\nhttps://github.com/skypitcher/manfe.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 04:48:15 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["He", "Ke", ""], ["He", "Le", ""], ["Fan", "Lisheng", ""], ["Deng", "Yansha", ""], ["Karagiannidis", "George K.", ""], ["Nallanathan", "Arumugam", ""]]}, {"id": "2101.08448", "submitter": "Kishor Bharti Mr.", "authors": "Kishor Bharti, Alba Cervera-Lierta, Thi Ha Kyaw, Tobias Haug, Sumner\n  Alperin-Lea, Abhinav Anand, Matthias Degroote, Hermanni Heimonen, Jakob S.\n  Kottmann, Tim Menke, Wai-Keong Mok, Sukin Sim, Leong-Chuan Kwek, Al\\'an\n  Aspuru-Guzik", "title": "Noisy intermediate-scale quantum (NISQ) algorithms", "comments": "Review article, 82 pages, 7 figures, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A universal fault-tolerant quantum computer that can solve efficiently\nproblems such as integer factorization and unstructured database search\nrequires millions of qubits with low error rates and long coherence times.\nWhile the experimental advancement towards realizing such devices will\npotentially take decades of research, noisy intermediate-scale quantum (NISQ)\ncomputers already exist. These computers are composed of hundreds of noisy\nqubits, i.e. qubits that are not error-corrected, and therefore perform\nimperfect operations in a limited coherence time. In the search for quantum\nadvantage with these devices, algorithms have been proposed for applications in\nvarious disciplines spanning physics, machine learning, quantum chemistry and\ncombinatorial optimization. The goal of such algorithms is to leverage the\nlimited available resources to perform classically challenging tasks. In this\nreview, we provide a thorough summary of NISQ computational paradigms and\nalgorithms. We discuss the key structure of these algorithms, their\nlimitations, and advantages. We additionally provide a comprehensive overview\nof various benchmarking and software tools useful for programming and testing\nNISQ devices.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 05:27:34 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Bharti", "Kishor", ""], ["Cervera-Lierta", "Alba", ""], ["Kyaw", "Thi Ha", ""], ["Haug", "Tobias", ""], ["Alperin-Lea", "Sumner", ""], ["Anand", "Abhinav", ""], ["Degroote", "Matthias", ""], ["Heimonen", "Hermanni", ""], ["Kottmann", "Jakob S.", ""], ["Menke", "Tim", ""], ["Mok", "Wai-Keong", ""], ["Sim", "Sukin", ""], ["Kwek", "Leong-Chuan", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "2101.08452", "submitter": "Huan Zhang", "authors": "Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh", "title": "Robust Reinforcement Learning on State Observations with Learned Optimal\n  Adversary", "comments": "Accepted by ICLR 2021. Huan Zhang and Hongge Chen contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness of reinforcement learning (RL) with adversarially\nperturbed state observations, which aligns with the setting of many adversarial\nattacks to deep reinforcement learning (DRL) and is also important for rolling\nout real-world RL agent under unpredictable sensing noise. With a fixed agent\npolicy, we demonstrate that an optimal adversary to perturb state observations\ncan be found, which is guaranteed to obtain the worst case agent reward. For\nDRL settings, this leads to a novel empirical adversarial attack to RL agents\nvia a learned adversary that is much stronger than previous ones. To enhance\nthe robustness of an agent, we propose a framework of alternating training with\nlearned adversaries (ATLA), which trains an adversary online together with the\nagent using policy gradient following the optimal adversarial attack framework.\nAdditionally, inspired by the analysis of state-adversarial Markov decision\nprocess (SA-MDP), we show that past states and actions (history) can be useful\nfor learning a robust agent, and we empirically find a LSTM based policy can be\nmore robust under adversaries. Empirical evaluations on a few continuous\ncontrol environments show that ATLA achieves state-of-the-art performance under\nstrong adversaries. Our code is available at\nhttps://github.com/huanzhang12/ATLA_robust_RL.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 05:38:52 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2101.08477", "submitter": "Thesath Nanayakkara", "authors": "Thesath Nanayakkara, Gilles Clermont, Christopher James Langmead, and\n  David Swigon", "title": "Unifying Cardiovascular Modelling with Deep Reinforcement Learning for\n  Uncertainty Aware Control of Sepsis Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a potentially life threatening inflammatory response to infection\nor severe tissue damage. It has a highly variable clinical course, requiring\nconstant monitoring of the patient's state to guide the management of\nintravenous fluids and vasopressors, among other interventions. Despite decades\nof research, there's still debate among experts on optimal treatment. Here, we\ncombine for the first time, distributional deep reinforcement learning with\nmechanistic physiological models to find personalized sepsis treatment\nstrategies. Our method handles partial observability by leveraging known\ncardiovascular physiology, introducing a novel physiology-driven recurrent\nautoencoder, and quantifies the uncertainty of its own results. Moreover, we\nintroduce a framework for uncertainty aware decision support with humans in the\nloop. We show that our method learns physiologically explainable, robust\npolicies that are consistent with clinical knowledge. Further our method\nconsistently identifies high risk states that lead to death, which could\npotentially benefit from more frequent vasopressor administration, providing\nvaluable guidance for future research\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 07:32:02 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 05:55:47 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 18:48:03 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Nanayakkara", "Thesath", ""], ["Clermont", "Gilles", ""], ["Langmead", "Christopher James", ""], ["Swigon", "David", ""]]}, {"id": "2101.08482", "submitter": "Zhaowei Cai", "authors": "Zhaowei Cai, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes,\n  Zhuowen Tu, Stefano Soatto", "title": "Exponential Moving Average Normalization for Self-supervised and\n  Semi-supervised Learning", "comments": "accepted by CVPR21 as Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a plug-in replacement for batch normalization (BN) called\nexponential moving average normalization (EMAN), which improves the performance\nof existing student-teacher based self- and semi-supervised learning\ntechniques. Unlike the standard BN, where the statistics are computed within\neach batch, EMAN, used in the teacher, updates its statistics by exponential\nmoving average from the BN statistics of the student. This design reduces the\nintrinsic cross-sample dependency of BN and enhances the generalization of the\nteacher. EMAN improves strong baselines for self-supervised learning by 4-6/1-2\npoints and semi-supervised learning by about 7/2 points, when 1%/10% supervised\nlabels are available on ImageNet. These improvements are consistent across\nmethods, network architectures, training duration, and datasets, demonstrating\nthe general effectiveness of this technique. The code is available at\nhttps://github.com/amazon-research/exponential-moving-average-normalization.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 07:45:37 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 08:16:27 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Cai", "Zhaowei", ""], ["Ravichandran", "Avinash", ""], ["Maji", "Subhransu", ""], ["Fowlkes", "Charless", ""], ["Tu", "Zhuowen", ""], ["Soatto", "Stefano", ""]]}, {"id": "2101.08523", "submitter": "Ashutosh Modi", "authors": "Vijit Malik and Ashwani Bhat and Ashutosh Modi", "title": "Adv-OLM: Generating Textual Adversaries via OLM", "comments": "5 Pages + 1 Page references + 3 Pages Appendix, Accepted at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models are susceptible to adversarial examples that have\nimperceptible perturbations in the original input, resulting in adversarial\nattacks against these models. Analysis of these attacks on the state of the art\ntransformers in NLP can help improve the robustness of these models against\nsuch adversarial inputs. In this paper, we present Adv-OLM, a black-box attack\nmethod that adapts the idea of Occlusion and Language Models (OLM) to the\ncurrent state of the art attack methods. OLM is used to rank words of a\nsentence, which are later substituted using word replacement strategies. We\nexperimentally show that our approach outperforms other attack methods for\nseveral text classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 10:04:56 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Malik", "Vijit", ""], ["Bhat", "Ashwani", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2101.08540", "submitter": "Megha Nawhal", "authors": "Megha Nawhal, Greg Mori", "title": "Activity Graph Transformer for Temporal Action Localization", "comments": "Project webpage: https://www.sfu.ca/~mnawhal/projects/agt.html; Code\n  available at https://github.com/Nmegha2601/activitygraph_transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Activity Graph Transformer, an end-to-end learnable model for\ntemporal action localization, that receives a video as input and directly\npredicts a set of action instances that appear in the video. Detecting and\nlocalizing action instances in untrimmed videos requires reasoning over\nmultiple action instances in a video. The dominant paradigms in the literature\nprocess videos temporally to either propose action regions or directly produce\nframe-level detections. However, sequential processing of videos is problematic\nwhen the action instances have non-sequential dependencies and/or non-linear\ntemporal ordering, such as overlapping action instances or re-occurrence of\naction instances over the course of the video. In this work, we capture this\nnon-linear temporal structure by reasoning over the videos as non-sequential\nentities in the form of graphs. We evaluate our model on challenging datasets:\nTHUMOS14, Charades, and EPIC-Kitchens-100. Our results show that our proposed\nmodel outperforms the state-of-the-art by a considerable margin.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 10:42:48 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 12:14:19 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Nawhal", "Megha", ""], ["Mori", "Greg", ""]]}, {"id": "2101.08543", "submitter": "Sergei Ivanov", "authors": "Sergei Ivanov, Liudmila Prokhorenkova", "title": "Boost then Convolve: Gradient Boosting Meets Graph Neural Networks", "comments": "ICLR 2021: camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are powerful models that have been successful in\nvarious graph representation learning tasks. Whereas gradient boosted decision\ntrees (GBDT) often outperform other machine learning methods when faced with\nheterogeneous tabular data. But what approach should be used for graphs with\ntabular node features? Previous GNN models have mostly focused on networks with\nhomogeneous sparse features and, as we show, are suboptimal in the\nheterogeneous setting. In this work, we propose a novel architecture that\ntrains GBDT and GNN jointly to get the best of both worlds: the GBDT model\ndeals with heterogeneous features, while GNN accounts for the graph structure.\nOur model benefits from end-to-end optimization by allowing new trees to fit\nthe gradient updates of GNN. With an extensive experimental comparison to the\nleading GBDT and GNN models, we demonstrate a significant increase in\nperformance on a variety of graphs with tabular features. The code is\navailable: https://github.com/nd7141/bgnn.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 10:46:41 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 12:13:30 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Ivanov", "Sergei", ""], ["Prokhorenkova", "Liudmila", ""]]}, {"id": "2101.08552", "submitter": "Yi Chen", "authors": "Yi Chen, Aimin Zhou", "title": "Variable Division and Optimization for Constrained Multiobjective\n  Portfolio Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable division and optimization (D\\&O) is a frequently utilized algorithm\ndesign paradigm in Evolutionary Algorithms (EAs). A D\\&O EA divides a variable\ninto partial variables and then optimize them respectively. A complicated\nproblem is thus divided into simple subtasks. For example, a variable of\nportfolio problem can be divided into two partial variables, i.e. the selection\nof assets and the allocation of capital. Thereby, we optimize these two partial\nvariables respectively. There is no formal discussion about how are the partial\nvariables iteratively optimized and why can it work for both single- and\nmulti-objective problems in D\\&O. In this paper, this gap is filled. According\nto the discussion, an elitist selection method for partial variables in\nmultiobjective problems is developed. Then this method is incorporated into the\nDecomposition-Based Multiobjective Evolutionary Algorithm (D\\&O-MOEA/D). With\nthe help of a mathematical programming optimizer, it is achieved on the\nconstrained multiobjective portfolio problems. In the empirical study,\nD\\&O-MOEA/D is implemented for 20 instances and recent Chinese stock markets.\nThe results show the superiority and versatility of D\\&O-MOEA/D on large-scale\ninstances while the performance of it on small-scale problems is also not bad.\nThe former targets convergence towards the Pareto front and the latter helps\npromote diversity among the non-dominated solutions during the search process.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 11:08:23 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Chen", "Yi", ""], ["Zhou", "Aimin", ""]]}, {"id": "2101.08585", "submitter": "Hadi Moradi", "authors": "Abolfazl Nadi, Hadi Moradi, Khalil Taheri", "title": "Crossbreeding in Random Forest", "comments": "21 pages, 5301 words, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ensemble learning methods are designed to benefit from multiple learning\nalgorithms for better predictive performance. The tradeoff of this improved\nperformance is slower speed and larger size of ensemble learning systems\ncompared to single learning systems. In this paper, we present a novel approach\nto deal with this problem in Random Forest (RF) as one of the most powerful\nensemble methods. The method is based on crossbreeding of the best tree\nbranches to increase the performance of RF in space and speed while keeping the\nperformance in the classification measures. The proposed approach has been\ntested on a group of synthetic and real datasets and compared to the standard\nRF approach. Several evaluations have been conducted to determine the effects\nof the Crossbred RF (CRF) on the accuracy and the number of trees in a forest.\nThe results show better performance of CRF compared to RF.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 12:58:54 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Nadi", "Abolfazl", ""], ["Moradi", "Hadi", ""], ["Taheri", "Khalil", ""]]}, {"id": "2101.08621", "submitter": "Riku Arakawa", "authors": "Riku Arakawa and Hiromu Yakura", "title": "Mindless Attractor: A False-Positive Resistant Intervention for Drawing\n  Attention Using Auditory Perturbation", "comments": "To appear in ACM CHI Conference on Human Factors in Computing Systems\n  (CHI '21), May 8-13, 2021, Yokohama, Japan", "journal-ref": null, "doi": "10.1145/3411764.3445339", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explicitly alerting users is not always an optimal intervention, especially\nwhen they are not motivated to obey. For example, in video-based learning,\nlearners who are distracted from the video would not follow an alert asking\nthem to pay attention. Inspired by the concept of Mindless Computing, we\npropose a novel intervention approach, Mindless Attractor, that leverages the\nnature of human speech communication to help learners refocus their attention\nwithout relying on their motivation. Specifically, it perturbs the voice in the\nvideo to direct their attention without consuming their conscious awareness.\nOur experiments not only confirmed the validity of the proposed approach but\nalso emphasized its advantages in combination with a machine learning-based\nsensing module. Namely, it would not frustrate users even though the\nintervention is activated by false-positive detection of their attentive state.\nOur intervention approach can be a reliable way to induce behavioral change in\nhuman-AI symbiosis.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 14:10:54 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Arakawa", "Riku", ""], ["Yakura", "Hiromu", ""]]}, {"id": "2101.08635", "submitter": "Martin Nwadiugwu", "authors": "Martin C. Nwadiugwu", "title": "Neural Networks, Artificial Intelligence and the Computational Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, several studies have provided insight on the functioning of\nthe brain which consists of neurons and form networks via interconnection among\nthem by synapses. Neural networks are formed by interconnected systems of\nneurons, and are of two types, namely, the Artificial Neural Network (ANNs) and\nBiological Neural Network (interconnected nerve cells). The ANNs are\ncomputationally influenced by human neurons and are used in modelling neural\nsystems. The reasoning foundations of ANNs have been useful in anomaly\ndetection, in areas of medicine such as instant physician, electronic noses,\npattern recognition, and modelling biological systems. Advancing research in\nartificial intelligence using the architecture of the human brain seeks to\nmodel systems by studying the brain rather than looking to technology for brain\nmodels. This study explores the concept of ANNs as a simulator of the\nbiological neuron, and its area of applications. It also explores why\nbrain-like intelligence is needed and how it differs from computational\nframework by comparing neural networks to contemporary computers and their\nmodern day implementation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 05:56:41 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Nwadiugwu", "Martin C.", ""]]}, {"id": "2101.08658", "submitter": "Ofer Mendelevitch", "authors": "Ofer Mendelevitch, Michael D. Lesh", "title": "Fidelity and Privacy of Synthetic Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The digitization of medical records ushered in a new era of big data to\nclinical science, and with it the possibility that data could be shared, to\nmultiply insights beyond what investigators could abstract from paper records.\nThe need to share individual-level medical data to accelerate innovation in\nprecision medicine continues to grow, and has never been more urgent, as\nscientists grapple with the COVID-19 pandemic. However, enthusiasm for the use\nof big data has been tempered by a fully appropriate concern for patient\nautonomy and privacy. That is, the ability to extract private or confidential\ninformation about an individual, in practice, renders it difficult to share\ndata, since significant infrastructure and data governance must be established\nbefore data can be shared. Although HIPAA provided de-identification as an\napproved mechanism for data sharing, linkage attacks were identified as a major\nvulnerability. A variety of mechanisms have been established to avoid leaking\nprivate information, such as field suppression or abstraction, strictly\nlimiting the amount of information that can be shared, or employing\nmathematical techniques such as differential privacy. Another approach, which\nwe focus on here, is creating synthetic data that mimics the underlying data.\nFor synthetic data to be a useful mechanism in support of medical innovation\nand a proxy for real-world evidence, one must demonstrate two properties of the\nsynthetic dataset: (1) any analysis on the real data must be matched by\nanalysis of the synthetic data (statistical fidelity) and (2) the synthetic\ndata must preserve privacy, with minimal risk of re-identification (privacy\nguarantee). In this paper we propose a framework for quantifying the\nstatistical fidelity and privacy preservation properties of synthetic datasets\nand demonstrate these metrics for synthetic data generated by Syntegra\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 23:01:27 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 04:41:17 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Mendelevitch", "Ofer", ""], ["Lesh", "Michael D.", ""]]}, {"id": "2101.08684", "submitter": "Minh-Quan Dao", "authors": "Minh-Quan Dao, Vincent Fr\\'emont", "title": "A two-stage data association approach for 3D Multi-object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-object tracking (MOT) is an integral part of any autonomous driving\npipelines because itproduces trajectories which has been taken by other moving\nobjects in the scene and helps predicttheir future motion. Thanks to the recent\nadvances in 3D object detection enabled by deep learning,track-by-detection has\nbecome the dominant paradigm in 3D MOT. In this paradigm, a MOT systemis\nessentially made of an object detector and a data association algorithm which\nestablishes track-to-detection correspondence. While 3D object detection has\nbeen actively researched, associationalgorithms for 3D MOT seem to settle at a\nbipartie matching formulated as a linear assignmentproblem (LAP) and solved by\nthe Hungarian algorithm. In this paper, we adapt a two-stage dataassociation\nmethod which was successful in image-based tracking to the 3D setting, thus\nprovidingan alternative for data association for 3D MOT. Our method outperforms\nthe baseline using one-stagebipartie matching for data association by achieving\n0.587 AMOTA in NuScenes validation set.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 15:50:17 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Dao", "Minh-Quan", ""], ["Fr\u00e9mont", "Vincent", ""]]}, {"id": "2101.08696", "submitter": "Naifu Zhang", "authors": "Naifu Zhang, Meixia Tao and Jia Wang", "title": "Sum-Rate-Distortion Function for Indirect Multiterminal Source Coding in\n  Federated Learning", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main focus in federated learning (FL) is the communication\nefficiency since a large number of participating edge devices send their\nupdates to the edge server at each round of the model training. Existing works\nreconstruct each model update from edge devices and implicitly assume that the\nlocal model updates are independent over edge devices. In FL, however, the\nmodel update is an indirect multi-terminal source coding problem, also called\nas the CEO problem where each edge device cannot observe directly the gradient\nthat is to be reconstructed at the decoder, but is rather provided only with a\nnoisy version. The existing works do not leverage the redundancy in the\ninformation transmitted by different edges. This paper studies the rate region\nfor the indirect multiterminal source coding problem in FL. The goal is to\nobtain the minimum achievable rate at a particular upper bound of gradient\nvariance. We obtain the rate region for the quadratic vector Gaussian CEO\nproblem under unbiased estimator and derive an explicit formula of the\nsum-rate-distortion function in the special case where gradient are identical\nover edge device and dimension. Finally, we analyse communication efficiency of\nconvex Minibatched SGD and non-convex Minibatched SGD based on the\nsum-rate-distortion function, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 16:17:39 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 13:24:24 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 13:53:10 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhang", "Naifu", ""], ["Tao", "Meixia", ""], ["Wang", "Jia", ""]]}, {"id": "2101.08698", "submitter": "Qingkai Zeng", "authors": "Qingkai Zeng, Mengxia Yu, Wenhao Yu, Tianwen Jiang, Tim Weninger and\n  Meng Jiang", "title": "Validating Label Consistency in NER Data Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data annotation plays a crucial role in ensuring your named entity\nrecognition (NER) projects are trained with the right information to learn\nfrom. Producing the most accurate labels is a challenge due to the complexity\ninvolved with annotation. Label inconsistency between multiple subsets of data\nannotation (e.g., training set and test set, or multiple training subsets) is\nan indicator of label mistakes. In this work, we present an empirical method to\nexplore the relationship between label (in-)consistency and NER model\nperformance. It can be used to validate the label consistency (or catches the\ninconsistency) in multiple sets of NER data annotation. In experiments, our\nmethod identified the label inconsistency of test data in SCIERC and CoNLL03\ndatasets (with 26.7% and 5.4% label mistakes). It validated the consistency in\nthe corrected version of both datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 16:19:00 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Zeng", "Qingkai", ""], ["Yu", "Mengxia", ""], ["Yu", "Wenhao", ""], ["Jiang", "Tianwen", ""], ["Weninger", "Tim", ""], ["Jiang", "Meng", ""]]}, {"id": "2101.08724", "submitter": "Yi Shi", "authors": "Yi Shi and Yalin E. Sagduyu", "title": "Adversarial Machine Learning for Flooding Attacks on 5G Radio Access\n  Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing manages network resources as virtual resource blocks (RBs)\nfor the 5G Radio Access Network (RAN). Each communication request comes with\nquality of experience (QoE) requirements such as throughput and\nlatency/deadline, which can be met by assigning RBs, communication power, and\nprocessing power to the request. For a completed request, the achieved reward\nis measured by the weight (priority) of this request. Then, the reward is\nmaximized over time by allocating resources, e.g., with reinforcement learning\n(RL). In this paper, we introduce a novel flooding attack on 5G network\nslicing, where an adversary generates fake network slicing requests to consume\nthe 5G RAN resources that would be otherwise available to real requests. The\nadversary observes the spectrum and builds a surrogate model on the network\nslicing algorithm through RL that decides on how to craft fake requests to\nminimize the reward of real requests over time. We show that the portion of the\nreward achieved by real requests may be much less than the reward that would be\nachieved when there was no attack. We also show that this flooding attack is\nmore effective than other benchmark attacks such as random fake requests and\nfake requests with the minimum resource requirement (lowest QoE requirement).\nFake requests may be detected due to their fixed weight. As an attack\nenhancement, we present schemes to randomize weights of fake requests and show\nthat it is still possible to reduce the reward of real requests while\nmaintaining the balance on weight distributions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 17:05:31 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 14:39:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2101.08743", "submitter": "Wenjie Chen", "authors": "Wenjie Chen, Shengcai Liu, and Ke Tang", "title": "A New Knowledge Gradient-based Method for Constrained Bayesian\n  Optimization", "comments": "14 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box problems are common in real life like structural design, drug\nexperiments, and machine learning. When optimizing black-box systems,\ndecision-makers always consider multiple performances and give the final\ndecision by comprehensive evaluations. Motivated by such practical needs, we\nfocus on constrained black-box problems where the objective and constraints\nlack known special structure, and evaluations are expensive and even with\nnoise. We develop a novel constrained Bayesian optimization approach based on\nthe knowledge gradient method ($c-\\rm{KG}$). A new acquisition function is\nproposed to determine the next batch of samples considering optimality and\nfeasibility. An unbiased estimator of the gradient of the new acquisition\nfunction is derived to implement the $c-\\rm{KG}$ approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 05:00:38 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Chen", "Wenjie", ""], ["Liu", "Shengcai", ""], ["Tang", "Ke", ""]]}, {"id": "2101.08758", "submitter": "Pedro Saleiro", "authors": "S\\'ergio Jesus, Catarina Bel\\'em, Vladimir Balayan, Jo\\~ao Bento,\n  Pedro Saleiro, Pedro Bizarro, Jo\\~ao Gama", "title": "How can I choose an explainer? An Application-grounded Evaluation of\n  Post-hoc Explanations", "comments": "Accepted at FAccT'21, the ACM Conference on Fairness, Accountability,\n  and Transparency", "journal-ref": null, "doi": "10.1145/3442188.3445941 10.1145/3442188.3445941 10.1145/3442188.3445941\n  10.1145/3442188.3445941", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several research works proposing new Explainable AI (XAI)\nmethods designed to generate model explanations having specific properties, or\ndesiderata, such as fidelity, robustness, or human-interpretability. However,\nexplanations are seldom evaluated based on their true practical impact on\ndecision-making tasks. Without that assessment, explanations might be chosen\nthat, in fact, hurt the overall performance of the combined system of ML model\n+ end-users. This study aims to bridge this gap by proposing XAI Test, an\napplication-grounded evaluation methodology tailored to isolate the impact of\nproviding the end-user with different levels of information. We conducted an\nexperiment following XAI Test to evaluate three popular post-hoc explanation\nmethods -- LIME, SHAP, and TreeInterpreter -- on a real-world fraud detection\ntask, with real data, a deployed ML model, and fraud analysts. During the\nexperiment, we gradually increased the information provided to the fraud\nanalysts in three stages: Data Only, i.e., just transaction data without access\nto model score nor explanations, Data + ML Model Score, and Data + ML Model\nScore + Explanations. Using strong statistical analysis, we show that, in\ngeneral, these popular explainers have a worse impact than desired. Some of the\nconclusion highlights include: i) showing Data Only results in the highest\ndecision accuracy and the slowest decision time among all variants tested, ii)\nall the explainers improve accuracy over the Data + ML Model Score variant but\nstill result in lower accuracy when compared with Data Only; iii) LIME was the\nleast preferred by users, probably due to its substantially lower variability\nof explanations from case to case.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 18:15:13 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 12:05:16 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Jesus", "S\u00e9rgio", ""], ["Bel\u00e9m", "Catarina", ""], ["Balayan", "Vladimir", ""], ["Bento", "Jo\u00e3o", ""], ["Saleiro", "Pedro", ""], ["Bizarro", "Pedro", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "2101.08763", "submitter": "Philipp-Jan Honysz", "authors": "Philipp-Jan Honysz, Sebastian Buschj\\\"ager, Katharina Morik", "title": "GPU-Accelerated Optimizer-Aware Evaluation of Submodular Exemplar\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of submodular functions constitutes a viable way to perform\nclustering. Strong approximation guarantees and feasible optimization w.r.t.\nstreaming data make this clustering approach favorable. Technically, submodular\nfunctions map subsets of data to real values, which indicate how\n\"representative\" a specific subset is. Optimal sets might then be used to\npartition the data space and to infer clusters. Exemplar-based clustering is\none of the possible submodular functions, but suffers from high computational\ncomplexity. However, for practical applications, the particular real-time or\nwall-clock run-time is decisive. In this work, we present a novel way to\nevaluate this particular function on GPUs, which keeps the necessities of\noptimizers in mind and reduces wall-clock run-time. To discuss our GPU\nalgorithm, we investigated both the impact of different run-time critical\nproblem properties, like data dimensionality and the number of data points in a\nsubset, and the influence of required floating-point precision. In reproducible\nexperiments, our GPU algorithm was able to achieve competitive speedups of up\nto 72x depending on whether multi-threaded computation on CPUs was used for\ncomparison and the type of floating-point precision required. Half-precision\nGPU computation led to large speedups of up to 452x compared to\nsingle-precision, single-thread CPU computations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 18:23:44 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Honysz", "Philipp-Jan", ""], ["Buschj\u00e4ger", "Sebastian", ""], ["Morik", "Katharina", ""]]}, {"id": "2101.08845", "submitter": "Kaziwa Saleh", "authors": "Kaziwa Saleh, S\\'andor Sz\\'en\\'asi, Zolt\\'an V\\'amossy", "title": "Occlusion Handling in Generic Object Detection: A Review", "comments": "To be published in the proceedings of IEEE 19th World Symposium on\n  Applied Machine Intelligence and Informatics", "journal-ref": null, "doi": "10.1109/SAMI50585.2021.9378657", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant power of deep learning networks has led to enormous\ndevelopment in object detection. Over the last few years, object detector\nframeworks have achieved tremendous success in both accuracy and efficiency.\nHowever, their ability is far from that of human beings due to several factors,\nocclusion being one of them. Since occlusion can happen in various locations,\nscale, and ratio, it is very difficult to handle. In this paper, we address the\nchallenges in occlusion handling in generic object detection in both outdoor\nand indoor scenes, then we refer to the recent works that have been carried out\nto overcome these challenges. Finally, we discuss some possible future\ndirections of research.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 20:48:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Saleh", "Kaziwa", ""], ["Sz\u00e9n\u00e1si", "S\u00e1ndor", ""], ["V\u00e1mossy", "Zolt\u00e1n", ""]]}, {"id": "2101.08850", "submitter": "Wei Wang", "authors": "Shibo Zhou, Wei Wang, Xiaohua Li, Zhanpeng Jin", "title": "A Spike Learning System for Event-driven Object Recognition", "comments": "Shibo Zhou and Wei Wang contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-driven sensors such as LiDAR and dynamic vision sensor (DVS) have found\nincreased attention in high-resolution and high-speed applications. A lot of\nwork has been conducted to enhance recognition accuracy. However, the essential\ntopic of recognition delay or time efficiency is largely under-explored. In\nthis paper, we present a spiking learning system that uses the spiking neural\nnetwork (SNN) with a novel temporal coding for accurate and fast object\nrecognition. The proposed temporal coding scheme maps each event's arrival time\nand data into SNN spike time so that asynchronously-arrived events are\nprocessed immediately without delay. The scheme is integrated nicely with the\nSNN's asynchronous processing capability to enhance time efficiency. A key\nadvantage over existing systems is that the event accumulation time for each\nrecognition task is determined automatically by the system rather than pre-set\nby the user. The system can finish recognition early without waiting for all\nthe input events. Extensive experiments were conducted over a list of 7 LiDAR\nand DVS datasets. The results demonstrated that the proposed system had\nstate-of-the-art recognition accuracy while achieving remarkable time\nefficiency. Recognition delay was shown to reduce by 56.3% to 91.7% in various\nexperiment settings over the popular KITTI dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 20:57:53 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Zhou", "Shibo", ""], ["Wang", "Wei", ""], ["Li", "Xiaohua", ""], ["Jin", "Zhanpeng", ""]]}, {"id": "2101.08851", "submitter": "Alban Main de Boissiere", "authors": "Alban Main de Boissiere, Rita Noumeir", "title": "Bridging the gap between Human Action Recognition and Online Action\n  Detection", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Action recognition, early prediction, and online action detection are\ncomplementary disciplines that are often studied independently. Most online\naction detection networks use a pre-trained feature extractor, which might not\nbe optimal for its new task. We address the task-specific feature extraction\nwith a teacher-student framework between the aforementioned disciplines, and a\nnovel training strategy. Our network, Online Knowledge Distillation Action\nDetection network (OKDAD), embeds online early prediction and online temporal\nsegment proposal subnetworks in parallel. Low interclass and high intraclass\nsimilarity are encouraged during teacher training. Knowledge distillation to\nthe OKDAD network is ensured via layer reuse and cosine similarity between\nteacher-student feature vectors. Layer reuse and similarity learning\nsignificantly improve our baseline which uses a generic feature extractor. We\nevaluate our framework on infrared videos from two popular datasets, NTU RGB+D\n(action recognition, early prediction) and PKU MMD (action detection). Unlike\nprevious attempts on those datasets, our student networks perform without any\nknowledge of the future. Even with this added difficulty, we achieve\nstate-of-the-art results on both datasets. Moreover, our networks use infrared\nfrom RGB-D cameras, which we are the first to use for online action detection,\nto our knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 21:01:46 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["de Boissiere", "Alban Main", ""], ["Noumeir", "Rita", ""]]}, {"id": "2101.08857", "submitter": "Florian Wolf", "authors": "Florian Wolf", "title": "Knowledge Generation -- Variational Bayes on Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is a proof of concept for the potential of Variational\nAuto-Encoder (VAE) on representation learning of real-world Knowledge Graphs\n(KG). Inspired by successful approaches to the generation of molecular graphs,\nwe evaluate the capabilities of our model, the Relational Graph Variational\nAuto-Encoder (RGVAE). The impact of the modular hyperparameter choices,\nencoding through graph convolutions, graph matching and latent space prior, is\ncompared. The RGVAE is first evaluated on link prediction. The mean reciprocal\nrank (MRR) scores on the two datasets FB15K-237 and WN18RR are compared to the\nembedding-based model DistMult. A variational DistMult and a RGVAE without\nlatent space prior constraint are implemented as control models. The results\nshow that between different settings, the RGVAE with relaxed latent space,\nscores highest on both datasets, yet does not outperform the DistMult. Further,\nwe investigate the latent space in a twofold experiment: first, linear\ninterpolation between the latent representation of two triples, then the\nexploration of each latent dimension in a $95\\%$ confidence interval. Both\ninterpolations show that the RGVAE learns to reconstruct the adjacency matrix\nbut fails to disentangle. For the last experiment we introduce a new validation\nmethod for the FB15K-237 data set. The relation type-constrains of generated\ntriples are filtered and matched with entity types. The observed rate of valid\ngenerated triples is insignificantly higher than the random threshold. All\ngenerated and valid triples are unseen. A comparison between different latent\nspace priors, using the $\\delta$-VAE method, reveals a decoder collapse.\nFinally we analyze the limiting factors of our approach compared to molecule\ngeneration and propose solutions for the decoder collapse and successful\nrepresentation learning of multi-relational KGs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 21:23:17 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Wolf", "Florian", ""]]}, {"id": "2101.08890", "submitter": "Prabhu Kaliamoorthi Mr", "authors": "Prabhu Kaliamoorthi, Aditya Siddhant, Edward Li, Melvin Johnson", "title": "Distilling Large Language Models into Tiny and Effective Students using\n  pQRNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained multilingual models like mBERT, XLM-R achieve state of the\nart results on language understanding tasks. However, they are not well suited\nfor latency critical applications on both servers and edge devices. It's\nimportant to reduce the memory and compute resources required by these models.\nTo this end, we propose pQRNN, a projection-based embedding-free neural encoder\nthat is tiny and effective for natural language processing tasks. Without\npre-training, pQRNNs significantly outperform LSTM models with pre-trained\nembeddings despite being 140x smaller. With the same number of parameters, they\noutperform transformer baselines thereby showcasing their parameter efficiency.\nAdditionally, we show that pQRNNs are effective student architectures for\ndistilling large pre-trained language models. We perform careful ablations\nwhich study the effect of pQRNN parameters, data augmentation, and distillation\nsettings. On MTOP, a challenging multilingual semantic parsing dataset, pQRNN\nstudents achieve 95.9\\% of the performance of an mBERT teacher while being 350x\nsmaller. On mATIS, a popular parsing task, pQRNN students on average are able\nto get to 97.1\\% of the teacher while again being 350x smaller. Our strong\nresults suggest that our approach is great for latency-sensitive applications\nwhile being able to leverage large mBERT-like models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 23:45:50 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Kaliamoorthi", "Prabhu", ""], ["Siddhant", "Aditya", ""], ["Li", "Edward", ""], ["Johnson", "Melvin", ""]]}, {"id": "2101.08942", "submitter": "Ye Liu", "authors": "Ye Liu, Yao Wan, Jian-Guo Zhang, Wenting Zhao, Philip S. Yu", "title": "Enriching Non-Autoregressive Transformer with Syntactic and\n  SemanticStructures for Neural Machine Translation", "comments": "10 pages, Appear in EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-autoregressive models have boosted the efficiency of neural machine\ntranslation through parallelized decoding at the cost of effectiveness when\ncomparing with the autoregressive counterparts. In this paper, we claim that\nthe syntactic and semantic structures among natural language are critical for\nnon-autoregressive machine translation and can further improve the performance.\nHowever, these structures are rarely considered in the existing\nnon-autoregressive models. Inspired by this intuition, we propose to\nincorporate the explicit syntactic and semantic structures of languages into a\nnon-autoregressive Transformer, for the task of neural machine translation.\nMoreover, we also consider the intermediate latent alignment within target\nsentences to better learn the long-term token dependencies. Experimental\nresults on two real-world datasets (i.e., WMT14 En-De and WMT16 En-Ro) show\nthat our model achieves a significantly faster speed, as well as keeps the\ntranslation quality when compared with several state-of-the-art\nnon-autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 04:12:17 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Liu", "Ye", ""], ["Wan", "Yao", ""], ["Zhang", "Jian-Guo", ""], ["Zhao", "Wenting", ""], ["Yu", "Philip S.", ""]]}, {"id": "2101.08986", "submitter": "Stefano Giani", "authors": "Kavyashree Ranawat and Stefano Giani", "title": "Artificial intelligence prediction of stock prices using social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The primary objective of this work is to develop a Neural Network based on\nLSTM to predict stock market movements using tweets. Word embeddings, used in\nthe LSTM network, are initialised using Stanford's GloVe embeddings, pretrained\nspecifically on 2 billion tweets. To overcome the limited size of the dataset,\nan augmentation strategy is proposed to split each input sequence into 150\nsubsets. To achieve further improvements in the original configuration,\nhyperparameter optimisation is performed. The effects of variation in\nhyperparameters such as dropout rate, batch size, and LSTM hidden state output\nsize are assessed individually. Furthermore, an exhaustive set of parameter\ncombinations is examined to determine the optimal model configuration. The best\nperformance on the validation dataset is achieved by hyperparameter combination\n0.4,8,100 for the dropout, batch size, and hidden units respectively. The final\ntesting accuracy of the model is 76.14%.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 07:47:37 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Ranawat", "Kavyashree", ""], ["Giani", "Stefano", ""]]}, {"id": "2101.09048", "submitter": "Shiwei Liu", "authors": "Shiwei Liu, Decebal Constantin Mocanu, Yulong Pei, Mykola Pechenizkiy", "title": "Selfish Sparse RNN Training", "comments": "Published in Proceedings of the 38th International Conference on\n  Machine Learning. Code can be found in\n  https://github.com/Shiweiliuiiiiiii/Selfish-RNN", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse neural networks have been widely applied to reduce the computational\ndemands of training and deploying over-parameterized deep neural networks. For\ninference acceleration, methods that discover a sparse network from a\npre-trained dense network (dense-to-sparse training) work effectively.\nRecently, dynamic sparse training (DST) has been proposed to train sparse\nneural networks without pre-training a dense model (sparse-to-sparse training),\nso that the training process can also be accelerated. However, previous\nsparse-to-sparse methods mainly focus on Multilayer Perceptron Networks (MLPs)\nand Convolutional Neural Networks (CNNs), failing to match the performance of\ndense-to-sparse methods in the Recurrent Neural Networks (RNNs) setting. In\nthis paper, we propose an approach to train intrinsically sparse RNNs with a\nfixed parameter count in one single run, without compromising performance.\nDuring training, we allow RNN layers to have a non-uniform redistribution\nacross cell gates for better regularization. Further, we propose SNT-ASGD, a\nnovel variant of the averaged stochastic gradient optimizer, which\nsignificantly improves the performance of all sparse training methods for RNNs.\nUsing these strategies, we achieve state-of-the-art sparse training results,\nbetter than the dense-to-sparse methods, with various types of RNNs on Penn\nTreeBank and Wikitext-2 datasets. Our codes are available at\nhttps://github.com/Shiweiliuiiiiiii/Selfish-RNN.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 10:45:40 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 16:38:09 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 05:46:23 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Liu", "Shiwei", ""], ["Mocanu", "Decebal Constantin", ""], ["Pei", "Yulong", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2101.09050", "submitter": "Alex Zhavoronkov", "authors": "Yan A. Ivanenkov, Alex Zhebrak, Dmitry Bezrukov, Bogdan Zagribelnyy,\n  Vladimir Aladinskiy, Daniil Polykovskiy, Evgeny Putin, Petrina Kamya,\n  Alexander Aliper, Alex Zhavoronkov", "title": "Chemistry42: An AI-based platform for de novo molecular design", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.BM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Chemistry42 is a software platform for de novo small molecule design that\nintegrates Artificial Intelligence (AI) techniques with computational and\nmedicinal chemistry methods. Chemistry42 is unique in its ability to generate\nnovel molecular structures with predefined properties validated through in\nvitro and in vivo studies. Chemistry42 is a core component of Insilico Medicine\nPharma.ai drug discovery suite that also includes target discovery and\nmulti-omics data analysis (PandaOmics) and clinical trial outcomes predictions\n(InClinico).\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 10:49:26 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Ivanenkov", "Yan A.", ""], ["Zhebrak", "Alex", ""], ["Bezrukov", "Dmitry", ""], ["Zagribelnyy", "Bogdan", ""], ["Aladinskiy", "Vladimir", ""], ["Polykovskiy", "Daniil", ""], ["Putin", "Evgeny", ""], ["Kamya", "Petrina", ""], ["Aliper", "Alexander", ""], ["Zhavoronkov", "Alex", ""]]}, {"id": "2101.09056", "submitter": "Mark Keane", "authors": "Barry Smyth and Mark T Keane", "title": "A Few Good Counterfactuals: Generating Interpretable, Plausible and\n  Diverse Counterfactual Explanations", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations provide a potentially significant solution to the\nExplainable AI (XAI) problem, but good, native counterfactuals have been shown\nto rarely occur in most datasets. Hence, the most popular methods generate\nsynthetic counterfactuals using blind perturbation. However, such methods have\nseveral shortcomings: the resulting counterfactuals (i) may not be valid\ndata-points (they often use features that do not naturally occur), (ii) may\nlack the sparsity of good counterfactuals (if they modify too many features),\nand (iii) may lack diversity (if the generated counterfactuals are minimal\nvariants of one another). We describe a method designed to overcome these\nproblems, one that adapts native counterfactuals in the original dataset, to\ngenerate sparse, diverse synthetic counterfactuals from naturally occurring\nfeatures. A series of experiments are reported that systematically explore\nparametric variations of this novel method on common datasets to establish the\nconditions for optimal performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 11:30:26 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Smyth", "Barry", ""], ["Keane", "Mark T", ""]]}, {"id": "2101.09057", "submitter": "Ziyuan Zhao", "authors": "Ziyuan Zhao, Zeng Zeng, Kaixin Xu, Cen Chen, Cuntai Guan", "title": "DSAL: Deeply Supervised Active Learning from Strong and Weak Labelers\n  for Biomedical Image Segmentation", "comments": "Published as a journal paper at IEEE J-BHI", "journal-ref": null, "doi": "10.1109/JBHI.2021.3052320", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is one of the most essential biomedical image processing\nproblems for different imaging modalities, including microscopy and X-ray in\nthe Internet-of-Medical-Things (IoMT) domain. However, annotating biomedical\nimages is knowledge-driven, time-consuming, and labor-intensive, making it\ndifficult to obtain abundant labels with limited costs. Active learning\nstrategies come into ease the burden of human annotation, which queries only a\nsubset of training data for annotation. Despite receiving attention, most of\nactive learning methods generally still require huge computational costs and\nutilize unlabeled data inefficiently. They also tend to ignore the intermediate\nknowledge within networks. In this work, we propose a deep active\nsemi-supervised learning framework, DSAL, combining active learning and\nsemi-supervised learning strategies. In DSAL, a new criterion based on deep\nsupervision mechanism is proposed to select informative samples with high\nuncertainties and low uncertainties for strong labelers and weak labelers\nrespectively. The internal criterion leverages the disagreement of intermediate\nfeatures within the deep learning network for active sample selection, which\nsubsequently reduces the computational costs. We use the proposed criteria to\nselect samples for strong and weak labelers to produce oracle labels and pseudo\nlabels simultaneously at each active learning iteration in an ensemble learning\nmanner, which can be examined with IoMT Platform. Extensive experiments on\nmultiple medical image datasets demonstrate the superiority of the proposed\nmethod over state-of-the-art active learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 11:31:33 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Zhao", "Ziyuan", ""], ["Zeng", "Zeng", ""], ["Xu", "Kaixin", ""], ["Chen", "Cen", ""], ["Guan", "Cuntai", ""]]}, {"id": "2101.09092", "submitter": "Jo\\~ao P Meneses PhD", "authors": "Jo\\~ao Paulo Meneses", "title": "Deepfakes and the 2020 US elections: what (did not) happen", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alarmed by the volume of disinformation that was assumed to have taken place\nduring the 2016 US elections, scholars, politics and journalists predicted the\nworst when the first deepfakes began to emerge in 2018. After all, US Elections\n2020 were believed to be the most secure in American history. This paper seeks\nexplanations for an apparent contradiction: we believe that it was precisely\nthe multiplication and conjugation of different types of warnings and fears\nthat created the conditions that prevented malicious political deepfakes from\naffecting the 2020 US elections. From these warnings, we identified four\nfactors (more active role of social networks, new laws, difficulties in\naccessing Artificial Intelligence and better awareness of society). But while\nthis formula has proven to be effective in the case of the United States, 2020,\nit is not correct to assume that it can be repeated in other political\ncontexts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 13:10:47 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Meneses", "Jo\u00e3o Paulo", ""]]}, {"id": "2101.09115", "submitter": "Madhura Pande", "authors": "Madhura Pande, Aakriti Budhraja, Preksha Nema, Pratyush Kumar and\n  Mitesh M. Khapra", "title": "The heads hypothesis: A unifying statistical approach towards\n  understanding multi-headed attention in BERT", "comments": "accepted at AAAI 2021 (Main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-headed attention heads are a mainstay in transformer-based models.\nDifferent methods have been proposed to classify the role of each attention\nhead based on the relations between tokens which have high pair-wise attention.\nThese roles include syntactic (tokens with some syntactic relation), local\n(nearby tokens), block (tokens in the same sentence) and delimiter (the special\n[CLS], [SEP] tokens). There are two main challenges with existing methods for\nclassification: (a) there are no standard scores across studies or across\nfunctional roles, and (b) these scores are often average quantities measured\nacross sentences without capturing statistical significance. In this work, we\nformalize a simple yet effective score that generalizes to all the roles of\nattention heads and employs hypothesis testing on this score for robust\ninference. This provides us the right lens to systematically analyze attention\nheads and confidently comment on many commonly posed questions on analyzing the\nBERT model. In particular, we comment on the co-location of multiple functional\nroles in the same attention head, the distribution of attention heads across\nlayers, and effect of fine-tuning for specific NLP tasks on these functional\nroles.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 14:10:59 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Pande", "Madhura", ""], ["Budhraja", "Aakriti", ""], ["Nema", "Preksha", ""], ["Kumar", "Pratyush", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "2101.09163", "submitter": "Aidong Yang", "authors": "Ye Ouyang (1), Lilei Wang (1), Aidong Yang (1), Maulik Shah (2), David\n  Belanger (3 and 4), Tongqing Gao (5), Leping Wei (6), Yaqin Zhang (7) ((1)\n  AsiaInfo Technologies, (2) Verizon, (3) AT&T, (4) Stevens Institute of\n  Technology, (5) China Mobile, (6) China Telecom, (7) Tsinghua University)", "title": "The Next Decade of Telecommunications Artificial Intelligence", "comments": "19 pages, in Chinese, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been an exciting journey since the mobile communications and\nartificial intelligence were conceived 37 years and 64 years ago. While both\nfields evolved independently and profoundly changed communications and\ncomputing industries, the rapid convergence of 5G and deep learning is\nbeginning to significantly transform the core communication infrastructure,\nnetwork management and vertical applications. The paper first outlines the\nindividual roadmaps of mobile communications and artificial intelligence in the\nearly stage, with a concentration to review the era from 3G to 5G when AI and\nmobile communications started to converge. With regard to telecommunications\nartificial intelligence, the paper further introduces in detail the progress of\nartificial intelligence in the ecosystem of mobile communications. The paper\nthen summarizes the classifications of AI in telecom ecosystems along with its\nevolution paths specified by various international telecommunications\nstandardization bodies. Towards the next decade, the paper forecasts the\nprospective roadmap of telecommunications artificial intelligence. In line with\n3GPP and ITU-R timeline of 5G & 6G, the paper further explores the network\nintelligence following 3GPP and ORAN routes respectively, experience and\nintention driven network management and operation, network AI signalling\nsystem, intelligent middle-office based BSS, intelligent customer experience\nmanagement and policy control driven by BSS and OSS convergence, evolution from\nSLA to ELA, and intelligent private network for verticals. The paper is\nconcluded with the vision that AI will reshape the future B5G or 6G landscape\nand we need pivot our R&D, standardizations, and ecosystem to fully take the\nunprecedented opportunities.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:33:44 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 02:25:23 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 10:19:47 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 14:41:49 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ouyang", "Ye", "", "3 and 4"], ["Wang", "Lilei", "", "3 and 4"], ["Yang", "Aidong", "", "3 and 4"], ["Shah", "Maulik", "", "3 and 4"], ["Belanger", "David", "", "3 and 4"], ["Gao", "Tongqing", ""], ["Wei", "Leping", ""], ["Zhang", "Yaqin", ""]]}, {"id": "2101.09167", "submitter": "Sajib Saha Dr.", "authors": "Sajib Saha, Fan Gu, Xue Luo, and Robert L. Lytton", "title": "Improved Sensitivity of Base Layer on the Performance of Rigid Pavement", "comments": "45 pages, 11 figures, 6 tables. journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The performance of rigid pavement is greatly affected by the properties of\nbase/subbase as well as subgrade layer. However, the performance predicted by\nthe AASHTOWare Pavement ME design shows low sensitivity to the properties of\nbase and subgrade layers. To improve the sensitivity and better reflect the\ninfluence of unbound layers a new set of improved models i.e., resilient\nmodulus (MR) and modulus of subgrade reaction (k-value) are adopted in this\nstudy. An Artificial Neural Network (ANN) model is developed to predict the\nmodified k-value based on finite element (FE) analysis. The training and\nvalidation datasets in the ANN model consist of 27000 simulation cases with\ndifferent combinations of pavement layer thickness, layer modulus and slab-base\ninterface bond ratio. To examine the sensitivity of modified MR and k-values on\npavement response, eight pavement sections data are collected from the\nLong-Term Pavement performance (LTPP) database and modeled by using the FE\nsoftware ISLAB2000. The computational results indicate that the modified MR\nvalues have higher sensitivity to water content in base layer on critical\nstress and deflection response of rigid pavements compared to the results using\nthe Pavement ME design model. It is also observed that the k-values using ANN\nmodel has the capability of predicting critical pavement response at any\npartially bonded conditions whereas the Pavement ME design model can only\ncalculate at two extreme bonding conditions (i.e., fully bonding and no\nbonding).\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 23:43:41 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Saha", "Sajib", ""], ["Gu", "Fan", ""], ["Luo", "Xue", ""], ["Lytton", "Robert L.", ""]]}, {"id": "2101.09192", "submitter": "Sadegh Pouriyan Zadeh", "authors": "Dariush Bahrami, Sadegh Pouriyan Zadeh", "title": "Gravity Optimizer: a Kinematic Approach on Optimization in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Gravity, another algorithm for gradient-based optimization. In\nthis paper, we explain how our novel idea change parameters to reduce the deep\nlearning model's loss. It has three intuitive hyper-parameters that the best\nvalues for them are proposed. Also, we propose an alternative to moving\naverage. To compare the performance of the Gravity optimizer with two common\noptimizers, Adam and RMSProp, five standard datasets were trained on two VGGNet\nmodels with a batch size of 128 for 100 epochs. Gravity hyper-parameters did\nnot need to be tuned for different models. As will be explained more in the\npaper, to investigate the direct impact of the optimizer itself on loss\nreduction no overfitting prevention technique was used. The obtained results\nshow that the Gravity optimizer has more stable performance than Adam and\nRMSProp and gives greater values of validation accuracy for datasets with more\noutput classes like CIFAR-100 (Fine).\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 16:27:34 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Bahrami", "Dariush", ""], ["Zadeh", "Sadegh Pouriyan", ""]]}, {"id": "2101.09194", "submitter": "Nathan Cooper", "authors": "Nathan Cooper, Carlos Bernal-C\\'ardenas, Oscar Chaparro, Kevin Moran,\n  Denys Poshyvanyk", "title": "It Takes Two to Tango: Combining Visual and Textual Information for\n  Detecting Duplicate Video-Based Bug Reports", "comments": "13 pages and 1 figure. Published at ICSE'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a bug manifests in a user-facing application, it is likely to be exposed\nthrough the graphical user interface (GUI). Given the importance of visual\ninformation to the process of identifying and understanding such bugs, users\nare increasingly making use of screenshots and screen-recordings as a means to\nreport issues to developers. However, when such information is reported en\nmasse, such as during crowd-sourced testing, managing these artifacts can be a\ntime-consuming process. As the reporting of screen-recordings in particular\nbecomes more popular, developers are likely to face challenges related to\nmanually identifying videos that depict duplicate bugs. Due to their graphical\nnature, screen-recordings present challenges for automated analysis that\npreclude the use of current duplicate bug report detection techniques. To\novercome these challenges and aid developers in this task, this paper presents\nTango, a duplicate detection technique that operates purely on video-based bug\nreports by leveraging both visual and textual information. Tango combines\ntailored computer vision techniques, optical character recognition, and text\nretrieval. We evaluated multiple configurations of Tango in a comprehensive\nempirical evaluation on 4,860 duplicate detection tasks that involved a total\nof 180 screen-recordings from six Android apps. Additionally, we conducted a\nuser study investigating the effort required for developers to manually detect\nduplicate video-based bug reports and compared this to the effort required to\nuse Tango. The results reveal that Tango's optimal configuration is highly\neffective at detecting duplicate video-based bug reports, accurately ranking\ntarget duplicate videos in the top-2 returned results in 83% of the tasks.\nAdditionally, our user study shows that, on average, Tango can reduce developer\neffort by over 60%, illustrating its practicality.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 16:36:19 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:55:22 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Cooper", "Nathan", ""], ["Bernal-C\u00e1rdenas", "Carlos", ""], ["Chaparro", "Oscar", ""], ["Moran", "Kevin", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "2101.09222", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Computability-logic web: an alternative to deep learning", "comments": "9 pages. We discuss an approach to reaching general AI. arXiv admin\n  note: text overlap with arXiv:2010.08925, arXiv:1909.07036; substantial text\n  overlap with arXiv:0712.1345 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  {\\em Computability logic} (CoL) is a powerful, mathematically rigorous\ncomputational model. In this paper, we show that CoL-web, a web extension to\nCoL, naturally supports web programming where database updates are involved. To\nbe specific, we discuss an implementation of the AI ATM based on CoL (CL9 to be\nexact). More importantly, we argue that CoL-web supports a general AI and,\ntherefore, is a good alternative to neural nets and deep learning. We also\ndiscuss how to integrate neural nets into CoL-web.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:46:05 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "2101.09294", "submitter": "Eddie Yang", "authors": "Eddie Yang, Margaret E. Roberts", "title": "Censorship of Online Encyclopedias: Implications for NLP Models", "comments": "Accepted for publication at ACM FAccT 2021", "journal-ref": null, "doi": "10.1145/3442188.3445916", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While artificial intelligence provides the backbone for many tools people use\naround the world, recent work has brought to attention that the algorithms\npowering AI are not free of politics, stereotypes, and bias. While most work in\nthis area has focused on the ways in which AI can exacerbate existing\ninequalities and discrimination, very little work has studied how governments\nactively shape training data. We describe how censorship has affected the\ndevelopment of Wikipedia corpuses, text data which are regularly used for\npre-trained inputs into NLP algorithms. We show that word embeddings trained on\nBaidu Baike, an online Chinese encyclopedia, have very different associations\nbetween adjectives and a range of concepts about democracy, freedom, collective\naction, equality, and people and historical events in China than its regularly\nblocked but uncensored counterpart - Chinese language Wikipedia. We examine the\nimplications of these discrepancies by studying their use in downstream AI\napplications. Our paper shows how government repression, censorship, and\nself-censorship may impact training data and the applications that draw from\nthem.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 19:09:53 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yang", "Eddie", ""], ["Roberts", "Margaret E.", ""]]}, {"id": "2101.09328", "submitter": "Michael Walton", "authors": "Andrew Fuchs, Michael Walton, Theresa Chadwick, Doug Lange", "title": "Theory of Mind for Deep Reinforcement Learning in Hanabi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The partially observable card game Hanabi has recently been proposed as a new\nAI challenge problem due to its dependence on implicit communication\nconventions and apparent necessity of theory of mind reasoning for efficient\nplay. In this work, we propose a mechanism for imbuing Reinforcement Learning\nagents with a theory of mind to discover efficient cooperative strategies in\nHanabi. The primary contributions of this work are threefold: First, a formal\ndefinition of a computationally tractable mechanism for computing hand\nprobabilities in Hanabi. Second, an extension to conventional Deep\nReinforcement Learning that introduces reasoning over finitely nested theory of\nmind belief hierarchies. Finally, an intrinsic reward mechanism enabled by\ntheory of mind that incentivizes agents to share strategically relevant private\nknowledge with their teammates. We demonstrate the utility of our algorithm\nagainst Rainbow, a state-of-the-art Reinforcement Learning agent.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 20:56:42 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fuchs", "Andrew", ""], ["Walton", "Michael", ""], ["Chadwick", "Theresa", ""], ["Lange", "Doug", ""]]}, {"id": "2101.09343", "submitter": "Bin Han", "authors": "Amina Lejla Ibrahimpasic, Bin Han, and Hans D. Schotten", "title": "AI-Empowered VNF Migration as a Cost-Loss-Effective Solution for Network\n  Resilience", "comments": "Accepted by the IEEE WCNC 2021 Workshop on Intelligent Computing and\n  Caching at the Network Edge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a wide deployment of Multi-Access Edge Computing (MEC) in the Fifth\nGeneration (5G) mobile networks, virtual network functions (VNF) can be\nflexibly migrated between difference locations, and therewith significantly\nenhances the network resilience to counter the degradation in quality of\nservice (QoS) due to network function outages. A balance has to be taken\ncarefully, between the loss reduced by VNF migration and the operations cost\ngenerated thereby. To achieve this in practical scenarios with realistic user\nbehavior, it calls for models of both cost and user mobility. This paper\nproposes a novel cost model and a AI-empowered approach for a rational\nmigration of stateful VNFs, which minimizes the sum of operations cost and\npotential loss caused by outages, and is capable to deal with the complex\nrealistic user mobility patterns.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:47:41 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Ibrahimpasic", "Amina Lejla", ""], ["Han", "Bin", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2101.09362", "submitter": "Mehmet Guzel", "authors": "Ay\\c{s}eg\\\"ul Yan{\\i}k, Mehmet Serdar G\\\"uzel, Mertkan Yan{\\i}k, Erkan\n  Bostanc{\\i}", "title": "Machine Learning Based Early Fire Detection System using a Low-Cost\n  Drone", "comments": "14 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new machine learning based system for forest fire\nearlier detection in a low-cost and accurate manner. Accordingly, it is aimed\nto bring a new and definite perspective to visual detection in forest fires. A\ndrone is constructed for this purpose. The microcontroller in the system has\nbeen programmed by training with deep learning methods, and the unmanned aerial\nvehicle has been given the ability to recognize the smoke, the earliest sign of\nfire detection. The common problem in the prevalent algorithms used in fire\ndetection is the high false alarm and overlook rates. Confirming the result\nobtained from the visualization with an additional supervision stage will\nincrease the reliability of the system as well as guarantee the accuracy of the\nresult. Due to the mobile vision ability of the unmanned aerial vehicle, the\ndata can be controlled from any point of view clearly and continuously. System\nperformance are validated by conducting experiments in both simulation and\nphysical environments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 16:18:42 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yan\u0131k", "Ay\u015feg\u00fcl", ""], ["G\u00fczel", "Mehmet Serdar", ""], ["Yan\u0131k", "Mertkan", ""], ["Bostanc\u0131", "Erkan", ""]]}, {"id": "2101.09374", "submitter": "Fanghua Ye", "authors": "Fanghua Ye, Jarana Manotumruksa, Qiang Zhang, Shenghui Li, Emine\n  Yilmaz", "title": "Slot Self-Attentive Dialogue State Tracking", "comments": "11 pages, to appear at The Web Conference (WWW) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An indispensable component in task-oriented dialogue systems is the dialogue\nstate tracker, which keeps track of users' intentions in the course of\nconversation. The typical approach towards this goal is to fill in multiple\npre-defined slots that are essential to complete the task. Although various\ndialogue state tracking methods have been proposed in recent years, most of\nthem predict the value of each slot separately and fail to consider the\ncorrelations among slots. In this paper, we propose a slot self-attention\nmechanism that can learn the slot correlations automatically. Specifically, a\nslot-token attention is first utilized to obtain slot-specific features from\nthe dialogue context. Then a stacked slot self-attention is applied on these\nfeatures to learn the correlations among slots. We conduct comprehensive\nexperiments on two multi-domain task-oriented dialogue datasets, including\nMultiWOZ 2.0 and MultiWOZ 2.1. The experimental results demonstrate that our\napproach achieves state-of-the-art performance on both datasets, verifying the\nnecessity and effectiveness of taking slot correlations into consideration.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 22:48:51 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Ye", "Fanghua", ""], ["Manotumruksa", "Jarana", ""], ["Zhang", "Qiang", ""], ["Li", "Shenghui", ""], ["Yilmaz", "Emine", ""]]}, {"id": "2101.09385", "submitter": "Joshua Kroll", "authors": "Joshua A. Kroll", "title": "Outlining Traceability: A Principle for Operationalizing Accountability\n  in Computing Systems", "comments": "To be published in the Proceedings of the 2021 ACM Conference on\n  Fairness, Accountability, and Transparency (FAccT'21)", "journal-ref": null, "doi": "10.1145/3442188.3445937", "report-no": null, "categories": "cs.CY cs.AI cs.GL cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accountability is widely understood as a goal for well governed computer\nsystems, and is a sought-after value in many governance contexts. But how can\nit be achieved? Recent work on standards for governable artificial intelligence\nsystems offers a related principle: traceability. Traceability requires\nestablishing not only how a system worked but how it was created and for what\npurpose, in a way that explains why a system has particular dynamics or\nbehaviors. It connects records of how the system was constructed and what the\nsystem did mechanically to the broader goals of governance, in a way that\nhighlights human understanding of that mechanical operation and the decision\nprocesses underlying it. We examine the various ways in which the principle of\ntraceability has been articulated in AI principles and other policy documents\nfrom around the world, distill from these a set of requirements on software\nsystems driven by the principle, and systematize the technologies available to\nmeet those requirements. From our map of requirements to supporting tools,\ntechniques, and procedures, we identify gaps and needs separating what\ntraceability requires from the toolbox available for practitioners. This map\nreframes existing discussions around accountability and transparency, using the\nprinciple of traceability to show how, when, and why transparency can be\ndeployed to serve accountability goals and thereby improve the normative\nfidelity of systems and their development processes.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 00:13:20 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kroll", "Joshua A.", ""]]}, {"id": "2101.09391", "submitter": "Brendan Tidd", "authors": "Brendan Tidd, Nicolas Hudson, Akansel Cosgun, Jurgen Leitner", "title": "Learning Setup Policies: Reliable Transition Between Locomotion\n  Behaviours", "comments": "Submitted to Humanoids 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic platforms that operate over manyunique terrain conditions typically\nrequire multiple controllers.To transition safely between controllers, there\nmust be anoverlap of states between adjacent controllers. We developa novel\nmethod for training Setup Policies that bridge thetrajectories between\npre-trained Deep Reinforcement Learning(DRL) policies. We demonstrate our\nmethod with a simulatedbiped traversing a difficult jump terrain, where a\nsingle policyfails to learn the task, and switching between pre-trainedpolicies\nwithout Setup Policies also fails. We perform anablation of key components of\nour system, and show thatour method outperforms others that learn transition\npolicies.We demonstrate our method with several difficult and diverseterrain\ntypes, and show that we can use Setup Policies as partof a modular control\nsuite to successfully traverse a sequence ofcomplex terrains. We show that\nusing Setup Policies improvesthe success rate for traversing a single difficult\njump terrain(from 1.5%success rate without Setup Policies to 82%), and\nasequence of various terrains (from 6.5%without Setup Policiesto 29.1%).\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 01:17:07 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Tidd", "Brendan", ""], ["Hudson", "Nicolas", ""], ["Cosgun", "Akansel", ""], ["Leitner", "Jurgen", ""]]}, {"id": "2101.09427", "submitter": "Abhishek Potnis", "authors": "Abhishek V. Potnis, Rajat C. Shinde, Surya S. Durbha", "title": "Towards Natural Language Question Answering over Earth Observation\n  Linked Data using Attention-based Neural Machine Translation", "comments": "Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2020", "journal-ref": null, "doi": "10.1109/IGARSS39084.2020.9323183", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increase in Geospatial Linked Open Data being adopted and published\nover the web, there is a need to develop intuitive interfaces and systems for\nseamless and efficient exploratory analysis of such rich heterogeneous\nmulti-modal datasets. This work is geared towards improving the exploration\nprocess of Earth Observation (EO) Linked Data by developing a natural language\ninterface to facilitate querying. Questions asked over Earth Observation Linked\nData have an inherent spatio-temporal dimension and can be represented using\nGeoSPARQL. This paper seeks to study and analyze the use of RNN-based neural\nmachine translation with attention for transforming natural language questions\ninto GeoSPARQL queries. Specifically, it aims to assess the feasibility of a\nneural approach for identifying and mapping spatial predicates in natural\nlanguage to GeoSPARQL's topology vocabulary extension including - Egenhofer and\nRCC8 relations. The queries can then be executed over a triple store to yield\nanswers for the natural language questions. A dataset consisting of mappings\nfrom natural language questions to GeoSPARQL queries over the Corine Land\nCover(CLC) Linked Data has been created to train and validate the deep neural\nnetwork. From our experiments, it is evident that neural machine translation\nwith attention is a promising approach for the task of translating spatial\npredicates in natural language questions to GeoSPARQL queries.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 06:12:20 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Potnis", "Abhishek V.", ""], ["Shinde", "Rajat C.", ""], ["Durbha", "Surya S.", ""]]}, {"id": "2101.09429", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh Khaled Ghafoor, Mohiuddin\n  Ahmed", "title": "Explainable Artificial Intelligence Approaches: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The lack of explainability of a decision from an Artificial Intelligence (AI)\nbased \"black box\" system/model, despite its superiority in many real-world\napplications, is a key stumbling block for adopting AI in many high stakes\napplications of different domain or industry. While many popular Explainable\nArtificial Intelligence (XAI) methods or approaches are available to facilitate\na human-friendly explanation of the decision, each has its own merits and\ndemerits, with a plethora of open challenges. We demonstrate popular XAI\nmethods with a mutual case study/task (i.e., credit default prediction),\nanalyze for competitive advantages from multiple perspectives (e.g., local,\nglobal), provide meaningful insight on quantifying explainability, and\nrecommend paths towards responsible or human-centered AI using XAI as a medium.\nPractitioners can use this work as a catalog to understand, compare, and\ncorrelate competitive advantages of popular XAI methods. In addition, this\nsurvey elicits future research directions towards responsible or human-centric\nAI systems, which is crucial to adopt AI in high stakes applications.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 06:15:34 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh Khaled", ""], ["Ahmed", "Mohiuddin", ""]]}, {"id": "2101.09464", "submitter": "Akanksha Nalhotra", "authors": "Akanksha Malhotra and Sudhir Kamle", "title": "ARTH: Algorithm For Reading Text Handily -- An AI Aid for People having\n  Word Processing Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this project is to solve one of the major problems faced by\nthe people having word processing issues like trauma, or mild mental\ndisability. \"ARTH\" is the short form of Algorithm for Reading Handily. ARTH is\na self-learning set of algorithms that is an intelligent way of fulfilling the\nneed for \"reading and understanding the text effortlessly\" which adjusts\naccording to the needs of every user. The research project propagates in two\nsteps. In the first step, the algorithm tries to identify the difficult words\npresent in the text based on two features -- the number of syllables and usage\nfrequency -- using a clustering algorithm. After the analysis of the clusters,\nthe algorithm labels these clusters, according to their difficulty level. In\nthe second step, the algorithm interacts with the user. It aims to test the\nuser's comprehensibility of the text and his/her vocabulary level by taking an\nautomatically generated quiz. The algorithm identifies the clusters which are\ndifficult for the user, based on the result of the analysis. The meaning of\nperceived difficult words is displayed next to them. The technology \"ARTH\"\nfocuses on the revival of the joy of reading among those people, who have a\npoor vocabulary or any word processing issues.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 09:39:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Malhotra", "Akanksha", ""], ["Kamle", "Sudhir", ""]]}, {"id": "2101.09486", "submitter": "Siyuan Chen", "authors": "Siyuan Chen and Jiahai Wang and Guoqing Li", "title": "Neural Relational Inference with Efficient Message Passing Mechanisms", "comments": "Accepted by AAAI 2021, 13 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many complex processes can be viewed as dynamical systems of interacting\nagents. In many cases, only the state sequences of individual agents are\nobserved, while the interacting relations and the dynamical rules are unknown.\nThe neural relational inference (NRI) model adopts graph neural networks that\npass messages over a latent graph to jointly learn the relations and the\ndynamics based on the observed data. However, NRI infers the relations\nindependently and suffers from error accumulation in multi-step prediction at\ndynamics learning procedure. Besides, relation reconstruction without prior\nknowledge becomes more difficult in more complex systems. This paper introduces\nefficient message passing mechanisms to the graph neural networks with\nstructural prior knowledge to address these problems. A relation interaction\nmechanism is proposed to capture the coexistence of all relations, and a\nspatio-temporal message passing mechanism is proposed to use historical\ninformation to alleviate error accumulation. Additionally, the structural prior\nknowledge, symmetry as a special case, is introduced for better relation\nprediction in more complex systems. The experimental results on simulated\nphysics systems show that the proposed method outperforms existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 11:27:31 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Siyuan", ""], ["Wang", "Jiahai", ""], ["Li", "Guoqing", ""]]}, {"id": "2101.09491", "submitter": "Daniel Mitchell MEng", "authors": "Daniel Mitchell, Jamie Blanche, Osama Zaki, Joshua Roe, Leo Kong,\n  Samuel Harper, Valentin Robu, Theodore Lim, David Flynn", "title": "Symbiotic System of Systems Design for Safe and Resilient Autonomous\n  Robotics in Offshore Wind Farms", "comments": "A preprint submit to IEEE Access Reliability Society Section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To reduce Operation and Maintenance (O&M) costs on offshore wind farms,\nwherein 80% of the O&M cost relates to deploying personnel, the offshore wind\nsector looks to Robotics and Artificial Intelligence (RAI) for solutions.\nBarriers to Beyond Visual Line of Sight (BVLOS) robotics include operational\nsafety compliance and resilience, inhibiting the commercialization of\nautonomous services offshore. To address safety and resilience challenges we\npropose a Symbiotic System Of Systems Approach (SSOSA), reflecting the\nlifecycle learning and co-evolution with knowledge sharing for mutual gain of\nrobotic platforms and remote human operators. Our novel methodology enables the\nrun-time verification of safety, reliability and resilience during autonomous\nmissions. To achieve this, a Symbiotic Digital Architecture (SDA) was developed\nto synchronize digital models of the robot, environment, infrastructure, and\nintegrate front-end analytics and bidirectional communication for autonomous\nadaptive mission planning and situation reporting to a remote operator. A\nreliability ontology for the deployed robot, based on our holistic\nhierarchical-relational model, supports computationally efficient platform data\nanalysis. We demonstrate an asset inspection mission within a confined space\nthrough Cooperative, Collaborative and Corroborative (C3) governance (internal\nand external symbiosis) via decision-making processes and the associated\nstructures. We create a hyper enabled human interaction capability to analyze\nthe mission status, diagnostics of critical sub-systems within the robot to\nprovide automatic updates to our AI-driven run-time reliability ontology. This\nenables faults to be translated into failure modes for decision-making during\nthe mission.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 11:58:16 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 16:40:27 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 15:01:55 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Mitchell", "Daniel", ""], ["Blanche", "Jamie", ""], ["Zaki", "Osama", ""], ["Roe", "Joshua", ""], ["Kong", "Leo", ""], ["Harper", "Samuel", ""], ["Robu", "Valentin", ""], ["Lim", "Theodore", ""], ["Flynn", "David", ""]]}, {"id": "2101.09495", "submitter": "Can Gao", "authors": "Can Gao, Jie Zhoua, Duoqian Miao, Xiaodong Yue, Jun Wan", "title": "Granular conditional entropy-based attribute reduction for partially\n  labeled data with proxy labels", "comments": "22 pages, 5 figures, and 5 tables. Preprint submitted to Information\n  Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Attribute reduction is one of the most important research topics in the\ntheory of rough sets, and many rough sets-based attribute reduction methods\nhave thus been presented. However, most of them are specifically designed for\ndealing with either labeled data or unlabeled data, while many real-world\napplications come in the form of partial supervision. In this paper, we propose\na rough sets-based semi-supervised attribute reduction method for partially\nlabeled data. Particularly, with the aid of prior class distribution\ninformation about data, we first develop a simple yet effective strategy to\nproduce the proxy labels for unlabeled data. Then the concept of information\ngranularity is integrated into the information-theoretic measure, based on\nwhich, a novel granular conditional entropy measure is proposed, and its\nmonotonicity is proved in theory. Furthermore, a fast heuristic algorithm is\nprovided to generate the optimal reduct of partially labeled data, which could\naccelerate the process of attribute reduction by removing irrelevant examples\nand excluding redundant attributes simultaneously. Extensive experiments\nconducted on UCI data sets demonstrate that the proposed semi-supervised\nattribute reduction method is promising and even compares favourably with the\nsupervised methods on labeled data and unlabeled data with true labels in terms\nof classification performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 12:50:09 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Gao", "Can", ""], ["Zhoua", "Jie", ""], ["Miao", "Duoqian", ""], ["Yue", "Xiaodong", ""], ["Wan", "Jun", ""]]}, {"id": "2101.09498", "submitter": "Danding Wang", "authors": "Danding Wang, Wencan Zhang and Brian Y. Lim", "title": "Show or Suppress? Managing Input Uncertainty in Machine Learning Model\n  Explanations", "comments": "to be published in Artificial Intelligence Special Issue on\n  Explainable Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attribution is widely used in interpretable machine learning to\nexplain how influential each measured input feature value is for an output\ninference. However, measurements can be uncertain, and it is unclear how the\nawareness of input uncertainty can affect the trust in explanations. We propose\nand study two approaches to help users to manage their perception of\nuncertainty in a model explanation: 1) transparently show uncertainty in\nfeature attributions to allow users to reflect on, and 2) suppress attribution\nto features with uncertain measurements and shift attribution to other features\nby regularizing with an uncertainty penalty. Through simulation experiments,\nqualitative interviews, and quantitative user evaluations, we identified the\nbenefits of moderately suppressing attribution uncertainty, and concerns\nregarding showing attribution uncertainty. This work adds to the understanding\nof handling and communicating uncertainty for model interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 13:10:48 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wang", "Danding", ""], ["Zhang", "Wencan", ""], ["Lim", "Brian Y.", ""]]}, {"id": "2101.09562", "submitter": "Olivier Teytaud", "authors": "Dennis J. N. J. Soemers, Vegard Mella, Cameron Browne, Olivier Teytaud", "title": "Deep Learning for General Game Playing with Ludii and Polygames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combinations of Monte-Carlo tree search and Deep Neural Networks, trained\nthrough self-play, have produced state-of-the-art results for automated\ngame-playing in many board games. The training and search algorithms are not\ngame-specific, but every individual game that these approaches are applied to\nstill requires domain knowledge for the implementation of the game's rules, and\nconstructing the neural network's architecture -- in particular the shapes of\nits input and output tensors. Ludii is a general game system that already\ncontains over 500 different games, which can rapidly grow thanks to its\npowerful and user-friendly game description language. Polygames is a framework\nwith training and search algorithms, which has already produced superhuman\nplayers for several board games. This paper describes the implementation of a\nbridge between Ludii and Polygames, which enables Polygames to train and\nevaluate models for games that are implemented and run through Ludii. We do not\nrequire any game-specific domain knowledge anymore, and instead leverage our\ndomain knowledge of the Ludii system and its abstract state and move\nrepresentations to write functions that can automatically determine the\nappropriate shapes for input and output tensors for any game implemented in\nLudii. We describe experimental results for short training runs in a wide\nvariety of different board games, and discuss several open problems and avenues\nfor future research.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 19:08:33 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Soemers", "Dennis J. N. J.", ""], ["Mella", "Vegard", ""], ["Browne", "Cameron", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2101.09571", "submitter": "Vadim Liventsev", "authors": "Vadim Liventsev, Aki H\\\"arm\\\"a and Milan Petkovi\\'c", "title": "BF++: a language for general-purpose program synthesis", "comments": "8+2 pages (paper+references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most state of the art decision systems based on Reinforcement Learning (RL)\nare data-driven black-box neural models, where it is often difficult to\nincorporate expert knowledge into the models or let experts review and validate\nthe learned decision mechanisms. Knowledge-insertion and model review are\nimportant requirements in many applications involving human health and safety.\nOne way to bridge the gap between data and knowledge driven systems is program\nsynthesis: replacing a neural network that outputs decisions with a symbolic\nprogram generated by a neural network or by means of genetic programming. We\npropose a new programming language, BF++, designed specifically for automatic\nprogramming of agents in a Partially Observable Markov Decision Process (POMDP)\nsetting and apply neural program synthesis to solve standard OpenAI Gym\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 19:44:44 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 12:25:25 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 20:24:02 GMT"}, {"version": "v4", "created": "Thu, 17 Jun 2021 13:01:09 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Liventsev", "Vadim", ""], ["H\u00e4rm\u00e4", "Aki", ""], ["Petkovi\u0107", "Milan", ""]]}, {"id": "2101.09656", "submitter": "Aobo Yang", "authors": "Aobo Yang, Nan Wang, Hongbo Deng, Hongning Wang", "title": "Explanation as a Defense of Recommendation", "comments": "WSDM 2021", "journal-ref": null, "doi": "10.1145/3437963.3441726", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Textual explanations have proved to help improve user satisfaction on\nmachine-made recommendations. However, current mainstream solutions loosely\nconnect the learning of explanation with the learning of recommendation: for\nexample, they are often separately modeled as rating prediction and content\ngeneration tasks. In this work, we propose to strengthen their connection by\nenforcing the idea of sentiment alignment between a recommendation and its\ncorresponding explanation. At training time, the two learning tasks are joined\nby a latent sentiment vector, which is encoded by the recommendation module and\nused to make word choices for explanation generation. At both training and\ninference time, the explanation module is required to generate explanation text\nthat matches sentiment predicted by the recommendation module. Extensive\nexperiments demonstrate our solution outperforms a rich set of baselines in\nboth recommendation and explanation tasks, especially on the improved quality\nof its generated explanations. More importantly, our user studies confirm our\ngenerated explanations help users better recognize the differences between\nrecommended items and understand why an item is recommended.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 06:34:36 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yang", "Aobo", ""], ["Wang", "Nan", ""], ["Deng", "Hongbo", ""], ["Wang", "Hongning", ""]]}, {"id": "2101.09662", "submitter": "Nilanjan Sinhababu", "authors": "Nilanjan Sinhababu, Rahul Saxena, Monalisa Sarma and Debasis Samanta", "title": "Medical Information Retrieval and Interpretation: A Question-Answer\n  based Interaction Model", "comments": "39 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet has become a very powerful platform where diverse medical\ninformation are expressed daily. Recently, a huge growth is seen in searches\nlike symptoms, diseases, medicines, and many other health related queries\naround the globe. The search engines typically populate the result by using the\nsingle query provided by the user and hence reaching to the final result may\nrequire a lot of manual filtering from the user's end. Current search engines\nand recommendation systems still lack real time interactions that may provide\nmore precise result generation. This paper proposes an intelligent and\ninteractive system tied up with the vast medical big data repository on the web\nand illustrates its potential in finding medical information.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 07:01:06 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Sinhababu", "Nilanjan", ""], ["Saxena", "Rahul", ""], ["Sarma", "Monalisa", ""], ["Samanta", "Debasis", ""]]}, {"id": "2101.09671", "submitter": "Tailin Liang", "authors": "Tailin Liang, John Glossner, Lei Wang, Shaobo Shi and Xiaotong Zhang", "title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been applied in many applications exhibiting\nextraordinary abilities in the field of computer vision. However, complex\nnetwork architectures challenge efficient real-time deployment and require\nsignificant computation resources and energy costs. These challenges can be\novercome through optimizations such as network compression. Network compression\ncan often be realized with little loss of accuracy. In some cases accuracy may\neven improve. This paper provides a survey on two types of network compression:\npruning and quantization. Pruning can be categorized as static if it is\nperformed offline or dynamic if it is performed at run-time. We compare pruning\ntechniques and describe criteria used to remove redundant computations. We\ndiscuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise,\nlayer-wise and even network-wise pruning. Quantization reduces computations by\nreducing the precision of the datatype. Weights, biases, and activations may be\nquantized typically to 8-bit integers although lower bit width implementations\nare also discussed including binary neural networks. Both pruning and\nquantization can be used independently or combined. We compare current\ntechniques, analyze their strengths and weaknesses, present compressed network\naccuracy results on a number of frameworks, and provide practical guidance for\ncompressing networks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 08:21:04 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 03:39:39 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 07:15:40 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Liang", "Tailin", ""], ["Glossner", "John", ""], ["Wang", "Lei", ""], ["Shi", "Shaobo", ""], ["Zhang", "Xiaotong", ""]]}, {"id": "2101.09688", "submitter": "Pasquale Minervini", "authors": "Daniel de Vassimon Manela, David Errington, Thomas Fisher, Boris van\n  Breugel, Pasquale Minervini", "title": "Stereotype and Skew: Quantifying Gender Bias in Pre-trained and\n  Fine-tuned Language Models", "comments": "Proceedings of the 16th Conference of the European Chapter of the\n  Association for Computational Linguistics (EACL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two intuitive metrics, skew and stereotype, that quantify\nand analyse the gender bias present in contextual language models when tackling\nthe WinoBias pronoun resolution task. We find evidence that gender stereotype\ncorrelates approximately negatively with gender skew in out-of-the-box models,\nsuggesting that there is a trade-off between these two forms of bias. We\ninvestigate two methods to mitigate bias. The first approach is an online\nmethod which is effective at removing skew at the expense of stereotype. The\nsecond, inspired by previous work on ELMo, involves the fine-tuning of BERT\nusing an augmented gender-balanced dataset. We show that this reduces both skew\nand stereotype relative to its unaugmented fine-tuned counterpart. However, we\nfind that existing gender bias benchmarks do not fully probe professional bias\nas pronoun resolution may be obfuscated by cross-correlations from other\nmanifestations of gender prejudice. Our code is available online, at\nhttps://github.com/12kleingordon34/NLP_masters_project.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 10:57:59 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 14:17:41 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Manela", "Daniel de Vassimon", ""], ["Errington", "David", ""], ["Fisher", "Thomas", ""], ["van Breugel", "Boris", ""], ["Minervini", "Pasquale", ""]]}, {"id": "2101.09698", "submitter": "Longteng Guo", "authors": "Longteng Guo, Jing Liu, Xinxin Zhu, Hanqing Lu", "title": "Fast Sequence Generation with Multi-Agent Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.04690", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoregressive sequence Generation models have achieved state-of-the-art\nperformance in areas like machine translation and image captioning. These\nmodels are autoregressive in that they generate each word by conditioning on\npreviously generated words, which leads to heavy latency during inference.\nRecently, non-autoregressive decoding has been proposed in machine translation\nto speed up the inference time by generating all words in parallel. Typically,\nthese models use the word-level cross-entropy loss to optimize each word\nindependently. However, such a learning process fails to consider the\nsentence-level consistency, thus resulting in inferior generation quality of\nthese non-autoregressive models. In this paper, we propose a simple and\nefficient model for Non-Autoregressive sequence Generation (NAG) with a novel\ntraining paradigm: Counterfactuals-critical Multi-Agent Learning (CMAL). CMAL\nformulates NAG as a multi-agent reinforcement learning system where element\npositions in the target sequence are viewed as agents that learn to\ncooperatively maximize a sentence-level reward. On MSCOCO image captioning\nbenchmark, our NAG method achieves a performance comparable to state-of-the-art\nautoregressive models, while brings 13.9x decoding speedup. On WMT14 EN-DE\nmachine translation dataset, our method outperforms cross-entropy trained\nbaseline by 6.0 BLEU points while achieves the greatest decoding speedup of\n17.46x.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 12:16:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Guo", "Longteng", ""], ["Liu", "Jing", ""], ["Zhu", "Xinxin", ""], ["Lu", "Hanqing", ""]]}, {"id": "2101.09709", "submitter": "Juan Pedro Dominguez-Morales", "authors": "Pablo Lopez-Osorio, Alberto Patino-Saucedo, Juan P. Dominguez-Morales,\n  Horacio Rostro-Gonzalez, Fernando Perez-Pe\\~na", "title": "Neuromorphic adaptive spiking CPG towards bio-inspired locomotion of\n  legged robots", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, locomotion mechanisms exhibited by vertebrate animals have\nbeen the inspiration for the improvement in the performance of robotic systems.\nThese mechanisms include the adaptability of their locomotion to any change\nregistered in the environment through their biological sensors. In this regard,\nwe aim to replicate such kind of adaptability in legged robots through a\nSpiking Central Pattern Generator. This Spiking Central Pattern Generator\ngenerates different locomotion (rhythmic) patterns which are driven by an\nexternal stimulus, that is, the output of a Force Sensitive Resistor connected\nto the robot to provide feedback. The Spiking Central Pattern Generator\nconsists of a network of five populations of Leaky Integrate-and-Fire neurons\ndesigned with a specific topology in such a way that the rhythmic patterns can\nbe generated and driven by the aforementioned external stimulus. Therefore, the\nlocomotion of the end robotic platform (any-legged robot) can be adapted to the\nterrain by using any sensor as input. The Spiking Central Pattern Generator\nwith adaptive learning has been numerically validated at software and hardware\nlevel, using the Brian 2 simulator and the SpiNNaker neuromorphic platform for\nthe latest. In particular, our experiments clearly show an adaptation in the\noscillation frequencies between the spikes produced in the populations of the\nSpiking Central Pattern Generator while the input stimulus varies. To validate\nthe robustness and adaptability of the Spiking Central Pattern Generator, we\nhave performed several tests by variating the output of the sensor. These\nexperiments were carried out in Brian 2 and SpiNNaker; both implementations\nshowed a similar behavior with a Pearson correlation coefficient of 0.905.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 12:44:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Lopez-Osorio", "Pablo", ""], ["Patino-Saucedo", "Alberto", ""], ["Dominguez-Morales", "Juan P.", ""], ["Rostro-Gonzalez", "Horacio", ""], ["Perez-Pe\u00f1a", "Fernando", ""]]}, {"id": "2101.09721", "submitter": "Fabio Ferreira", "authors": "Fabio Ferreira, Thomas Nierhoff, Frank Hutter", "title": "Learning Synthetic Environments for Reinforcement Learning with\n  Evolution Strategies", "comments": null, "journal-ref": "AAAI 2021 Meta-Learning Workshop", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work explores learning agent-agnostic synthetic environments (SEs) for\nReinforcement Learning. SEs act as a proxy for target environments and allow\nagents to be trained more efficiently than when directly trained on the target\nenvironment. We formulate this as a bi-level optimization problem and represent\nan SE as a neural network. By using Natural Evolution Strategies and a\npopulation of SE parameter vectors, we train agents in the inner loop on\nevolving SEs while in the outer loop we use the performance on the target task\nas a score for meta-updating the SE population. We show empirically that our\nmethod is capable of learning SEs for two discrete-action-space tasks\n(CartPole-v0 and Acrobot-v1) that allow us to train agents more robustly and\nwith up to 60% fewer steps. Not only do we show in experiments with 4000\nevaluations that the SEs are robust against hyperparameter changes such as the\nlearning rate, batch sizes and network sizes, we also show that SEs trained\nwith DDQN agents transfer in limited ways to a discrete-action-space version of\nTD3 and very well to Dueling DDQN.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 14:16:13 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 18:53:35 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 15:03:39 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ferreira", "Fabio", ""], ["Nierhoff", "Thomas", ""], ["Hutter", "Frank", ""]]}, {"id": "2101.09723", "submitter": "Anton Andreychuk", "authors": "Anton Andreychuk, Konstantin Yakovlev, Eli Boyarski and Roni Stern", "title": "Improving Continuous-time Conflict Based Search", "comments": "This is a pre-print of the paper accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally\nsolving classical multi-agent path finding (MAPF) problems, where time is\ndiscretized into the time steps. Continuous-time CBS (CCBS) is a recently\nproposed version of CBS that guarantees optimal solutions without the need to\ndiscretize time. However, the scalability of CCBS is limited because it does\nnot include any known improvements of CBS. In this paper, we begin to close\nthis gap and explore how to adapt successful CBS improvements, namely,\nprioritizing conflicts (PC), disjoint splitting (DS), and high-level\nheuristics, to the continuous time setting of CCBS. These adaptions are not\ntrivial, and require careful handling of different types of constraints,\napplying a generalized version of the Safe interval path planning (SIPP)\nalgorithm, and extending the notion of cardinal conflicts. We evaluate the\neffect of the suggested enhancements by running experiments both on general\ngraphs and $2^k$-neighborhood grids. CCBS with these improvements significantly\noutperforms vanilla CCBS, solving problems with almost twice as many agents in\nsome cases and pushing the limits of multiagent path finding in continuous-time\ndomains.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 14:34:25 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 18:37:38 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""], ["Boyarski", "Eli", ""], ["Stern", "Roni", ""]]}, {"id": "2101.09765", "submitter": "Milad Alshomary", "authors": "Milad Alshomary, Wei-Fan Chen, Timon Gurcke, and Henning Wachsmuth", "title": "Belief-based Generation of Argumentative Claims", "comments": "Almost 9 pages, 1 figure, EACL-21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When engaging in argumentative discourse, skilled human debaters tailor\nclaims to the beliefs of the audience, to construct effective arguments.\nRecently, the field of computational argumentation witnessed extensive effort\nto address the automatic generation of arguments. However, existing approaches\ndo not perform any audience-specific adaptation. In this work, we aim to bridge\nthis gap by studying the task of belief-based claim generation: Given a\ncontroversial topic and a set of beliefs, generate an argumentative claim\ntailored to the beliefs. To tackle this task, we model the people's prior\nbeliefs through their stances on controversial topics and extend\nstate-of-the-art text generation models to generate claims conditioned on the\nbeliefs. Our automatic evaluation confirms the ability of our approach to adapt\nclaims to a set of given beliefs. In a manual study, we additionally evaluate\nthe generated claims in terms of informativeness and their likelihood to be\nuttered by someone with a respective belief. Our results reveal the limitations\nof modeling users' beliefs based on their stances, but demonstrate the\npotential of encoding beliefs into argumentative texts, laying the ground for\nfuture exploration of audience reach.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 18:07:02 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 09:03:53 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Alshomary", "Milad", ""], ["Chen", "Wei-Fan", ""], ["Gurcke", "Timon", ""], ["Wachsmuth", "Henning", ""]]}, {"id": "2101.09773", "submitter": "Hongyin Luo", "authors": "Hongyin Luo, Shang-Wen Li, James Glass", "title": "Knowledge Grounded Conversational Symptom Detection with Graph Memory\n  Networks", "comments": "Appears in the Proceedings of the 3rd Clinical Natural Language\n  Processing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a novel goal-oriented dialog task, automatic symptom\ndetection. We build a system that can interact with patients through dialog to\ndetect and collect clinical symptoms automatically, which can save a doctor's\ntime interviewing the patient. Given a set of explicit symptoms provided by the\npatient to initiate a dialog for diagnosing, the system is trained to collect\nimplicit symptoms by asking questions, in order to collect more information for\nmaking an accurate diagnosis. After getting the reply from the patient for each\nquestion, the system also decides whether current information is enough for a\nhuman doctor to make a diagnosis. To achieve this goal, we propose two neural\nmodels and a training pipeline for the multi-step reasoning task. We also build\na knowledge graph as additional inputs to further improve model performance.\nExperiments show that our model significantly outperforms the baseline by 4%,\ndiscovering 67% of implicit symptoms on average with a limited number of\nquestions.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 18:50:16 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Luo", "Hongyin", ""], ["Li", "Shang-Wen", ""], ["Glass", "James", ""]]}, {"id": "2101.09791", "submitter": "Nitesh Kumar", "authors": "Nitesh Kumar and Ond\\v{r}ej Ku\\v{z}elka", "title": "Context-Specific Likelihood Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sampling is a popular method for approximate inference when exact inference\nis impractical. Generally, sampling algorithms do not exploit context-specific\nindependence (CSI) properties of probability distributions. We introduce\ncontext-specific likelihood weighting (CS-LW), a new sampling methodology,\nwhich besides exploiting the classical conditional independence properties,\nalso exploits CSI properties. Unlike the standard likelihood weighting, CS-LW\nis based on partial assignments of random variables and requires fewer samples\nfor convergence due to the sampling variance reduction. Furthermore, the speed\nof generating samples increases. Our novel notion of contextual assignments\ntheoretically justifies CS-LW. We empirically show that CS-LW is competitive\nwith state-of-the-art algorithms for approximate inference in the presence of a\nsignificant amount of CSIs.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 20:23:14 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 12:25:58 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2021 09:46:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kumar", "Nitesh", ""], ["Ku\u017eelka", "Ond\u0159ej", ""]]}, {"id": "2101.09799", "submitter": "Anshul Jindal", "authors": "Anshul Jindal, Paul Staab, Jorge Cardoso, Michael Gerndt and Vladimir\n  Podolskiy", "title": "Online Memory Leak Detection in the Cloud-based Infrastructures", "comments": "12 pages", "journal-ref": "International Workshop on Artificial Intelligence for IT\n  Operations (AIOPS) 2020", "doi": "10.1007/978-3-030-76352-7_21", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A memory leak in an application deployed on the cloud can affect the\navailability and reliability of the application. Therefore, to identify and\nultimately resolve it quickly is highly important. However, in the production\nenvironment running on the cloud, memory leak detection is a challenge without\nthe knowledge of the application or its internal object allocation details.\n  This paper addresses this challenge of online detection of memory leaks in\ncloud-based infrastructure without having any internal application knowledge by\nintroducing a novel machine learning based algorithm Precog. This algorithm\nsolely uses one metric i.e the system's memory utilization on which the\napplication is deployed for the detection of a memory leak. The developed\nalgorithm's accuracy was tested on 60 virtual machines manually labeled memory\nutilization data provided by our industry partner Huawei Munich Research Center\nand it was found that the proposed algorithm achieves the accuracy score of\n85\\% with less than half a second prediction time per virtual machine.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 20:48:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jindal", "Anshul", ""], ["Staab", "Paul", ""], ["Cardoso", "Jorge", ""], ["Gerndt", "Michael", ""], ["Podolskiy", "Vladimir", ""]]}, {"id": "2101.09819", "submitter": "Shubham Shrivastava", "authors": "Edwin Pan and Pankaj Rajak and Shubham Shrivastava", "title": "Meta-Regularization by Enforcing Mutual-Exclusiveness", "comments": "12 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning models have two objectives. First, they need to be able to make\npredictions over a range of task distributions while utilizing only a small\namount of training data. Second, they also need to adapt to new novel unseen\ntasks at meta-test time again by using only a small amount of training data\nfrom that task. It is the second objective where meta-learning models fail for\nnon-mutually exclusive tasks due to task overfitting. Given that guaranteeing\nmutually exclusive tasks is often difficult, there is a significant need for\nregularization methods that can help reduce the impact of task-memorization in\nmeta-learning. For example, in the case of N-way, K-shot classification\nproblems, tasks becomes non-mutually exclusive when the labels associated with\neach task is fixed. Under this design, the model will simply memorize the class\nlabels of all the training tasks, and thus will fail to recognize a new task\n(class) at meta-test time. A direct observable consequence of this memorization\nis that the meta-learning model simply ignores the task-specific training data\nin favor of directly classifying based on the test-data input. In our work, we\npropose a regularization technique for meta-learning models that gives the\nmodel designer more control over the information flow during meta-training. Our\nmethod consists of a regularization function that is constructed by maximizing\nthe distance between task-summary statistics, in the case of black-box models\nand task specific network parameters in the case of optimization based models\nduring meta-training. Our proposed regularization function shows an accuracy\nboost of $\\sim$ $36\\%$ on the Omniglot dataset for 5-way, 1-shot classification\nusing black-box method and for 20-way, 1-shot classification problem using\noptimization-based method.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 22:57:19 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Pan", "Edwin", ""], ["Rajak", "Pankaj", ""], ["Shrivastava", "Shubham", ""]]}, {"id": "2101.09869", "submitter": "Lelia Marie Hampton", "authors": "Lelia Marie Hampton", "title": "Black Feminist Musings on Algorithmic Oppression", "comments": "12 pages, accepted to ACM Conference on Fairness, Accountability, and\n  Transparency 2021", "journal-ref": null, "doi": "10.1145/3442188.3445929", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper unapologetically reflects on the critical role that Black feminism\ncan and should play in abolishing algorithmic oppression. Positioning\nalgorithmic oppression in the broader field of feminist science and technology\nstudies, I draw upon feminist philosophical critiques of science and technology\nand discuss histories and continuities of scientific oppression against\nhistorically marginalized people. Moreover, I examine the concepts of\ninvisibility and hypervisibility in oppressive technologies a l\\'a the\ncanonical double bind. Furthermore, I discuss what it means to call for\ndiversity as a solution to algorithmic violence, and I critique dialectics of\nthe fairness, accountability, and transparency community. I end by inviting you\nto envision and imagine the struggle to abolish algorithmic oppression by\nabolishing oppressive systems and shifting algorithmic development practices,\nincluding engaging our communities in scientific processes, centering\nmarginalized communities in design, and consensual data and algorithmic\npractices.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 03:04:05 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 01:54:26 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Hampton", "Lelia Marie", ""]]}, {"id": "2101.09930", "submitter": "Yixiang Wang", "authors": "Yixiang Wang, Jiqiang Liu, Xiaolin Chang", "title": "Generalizing Adversarial Examples by AdaBelief Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has proved that deep neural networks (DNNs) are vulnerable to\nadversarial examples, the legitimate input added with imperceptible and\nwell-designed perturbations can fool DNNs easily in the testing stage. However,\nmost of the existing adversarial attacks are difficult to fool adversarially\ntrained models. To solve this issue, we propose an AdaBelief iterative Fast\nGradient Sign Method (AB-FGSM) to generalize adversarial examples. By\nintegrating AdaBelief optimization algorithm to I-FGSM, we believe that the\ngeneralization of adversarial examples will be improved, relying on the strong\ngeneralization of AdaBelief optimizer. To validate the effectiveness and\ntransferability of adversarial examples generated by our proposed AB-FGSM, we\nconduct the white-box and black-box attacks on various single models and\nensemble models. Compared with state-of-the-art attack methods, our proposed\nmethod can generate adversarial examples effectively in the white-box setting,\nand the transfer rate is 7%-21% higher than latest attack methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 07:39:16 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wang", "Yixiang", ""], ["Liu", "Jiqiang", ""], ["Chang", "Xiaolin", ""]]}, {"id": "2101.09957", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Activation Functions in Artificial Neural Networks: A Systematic\n  Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions shape the outputs of artificial neurons and, therefore,\nare integral parts of neural networks in general and deep learning in\nparticular. Some activation functions, such as logistic and relu, have been\nused for many decades. But with deep learning becoming a mainstream research\ntopic, new activation functions have mushroomed, leading to confusion in both\ntheory and practice. This paper provides an analytic yet up-to-date overview of\npopular activation functions and their properties, which makes it a timely\nresource for anyone who studies or applies neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 08:55:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "2101.09986", "submitter": "Yurim Lee", "authors": "Yurim Lee, Eunji Jun, Heung-Il Suk", "title": "Multi-view Integration Learning for Irregularly-sampled Clinical Time\n  Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health record (EHR) data is sparse and irregular as it is recorded\nat irregular time intervals, and different clinical variables are measured at\neach observation point. In this work, we propose a multi-view features\nintegration learning from irregular multivariate time series data by\nself-attention mechanism in an imputation-free manner. Specifically, we devise\na novel multi-integration attention module (MIAM) to extract complex\ninformation inherent in irregular time series data. In particular, we\nexplicitly learn the relationships among the observed values, missing\nindicators, and time interval between the consecutive observations,\nsimultaneously. The rationale behind our approach is the use of human knowledge\nsuch as what to measure and when to measure in different situations, which are\nindirectly represented in the data. In addition, we build an attention-based\ndecoder as a missing value imputer that helps empower the representation\nlearning of the inter-relations among multi-view observations for the\nprediction task, which operates at the training phase only. We validated the\neffectiveness of our method over the public MIMIC-III and PhysioNet challenge\n2012 datasets by comparing with and outperforming the state-of-the-art methods\nfor in-hospital mortality prediction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 10:02:50 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 03:25:12 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Lee", "Yurim", ""], ["Jun", "Eunji", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2101.09994", "submitter": "Luca Corinzia", "authors": "Luca Corinzia, Paolo Penna, Wojciech Szpankowski, Joachim M. Buhmann", "title": "On maximum-likelihood estimation in the all-or-nothing regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of estimating a rank-1 additive deformation of a\nGaussian tensor according to the \\emph{maximum-likelihood estimator} (MLE). The\nanalysis is carried out in the sparse setting, where the underlying signal has\na support that scales sublinearly with the total number of dimensions. We show\nthat for Bernoulli distributed signals, the MLE undergoes an\n\\emph{all-or-nothing} (AoN) phase transition, already established for the\nminimum mean-square-error estimator (MMSE) in the same problem. The result\nfollows from two main technical points: (i) the connection established between\nthe MLE and the MMSE, using the first and second-moment methods in the\nconstrained signal space, (ii) a recovery regime for the MMSE stricter than the\nsimple error vanishing characterization given in the standard AoN, that is here\nproved as a general result.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 10:20:36 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Corinzia", "Luca", ""], ["Penna", "Paolo", ""], ["Szpankowski", "Wojciech", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "2101.09995", "submitter": "Vinodkumar Prabhakaran", "authors": "Nithya Sambasivan, Erin Arnesen, Ben Hutchinson, Tulsee Doshi,\n  Vinodkumar Prabhakaran", "title": "Re-imagining Algorithmic Fairness in India and Beyond", "comments": null, "journal-ref": "Proceedings of the 2021 conference on Fairness, Accountability,\n  and Transparency", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional algorithmic fairness is West-centric, as seen in its sub-groups,\nvalues, and methods. In this paper, we de-center algorithmic fairness and\nanalyse AI power in India. Based on 36 qualitative interviews and a discourse\nanalysis of algorithmic deployments in India, we find that several assumptions\nof algorithmic fairness are challenged. We find that in India, data is not\nalways reliable due to socio-economic factors, ML makers appear to follow\ndouble standards, and AI evokes unquestioning aspiration. We contend that\nlocalising model fairness alone can be window dressing in India, where the\ndistance between models and oppressed communities is large. Instead, we\nre-imagine algorithmic fairness in India and provide a roadmap to\nre-contextualise data and models, empower oppressed communities, and enable\nFair-ML ecosystems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 10:20:57 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 02:30:20 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Sambasivan", "Nithya", ""], ["Arnesen", "Erin", ""], ["Hutchinson", "Ben", ""], ["Doshi", "Tulsee", ""], ["Prabhakaran", "Vinodkumar", ""]]}, {"id": "2101.10001", "submitter": "Xudong Han", "authors": "Xudong Han, Timothy Baldwin, Trevor Cohn", "title": "Diverse Adversaries for Mitigating Bias in Training", "comments": "EACL 2021 (5 pages + 1 references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning can learn fairer and less biased models of language than\nstandard methods. However, current adversarial techniques only partially\nmitigate model bias, added to which their training procedures are often\nunstable. In this paper, we propose a novel approach to adversarial learning\nbased on the use of multiple diverse discriminators, whereby discriminators are\nencouraged to learn orthogonal hidden representations from one another.\nExperimental results show that our method substantially improves over standard\nadversarial removal methods, in terms of reducing bias and the stability of\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 10:35:13 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Han", "Xudong", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "2101.10020", "submitter": "Jichen Zhu", "authors": "Jichen Zhu, Diane H. Dallal, Robert C. Gray, Jennifer Villareale,\n  Santiago Onta\\~n\\'on, Evan M. Forman, Danielle Arigo", "title": "Personalization Paradox in Behavior Change Apps: Lessons from a Social\n  Comparison-Based Personalized App for Physical Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social comparison-based features are widely used in social computing apps.\nHowever, most existing apps are not grounded in social comparison theories and\ndo not consider individual differences in social comparison preferences and\nreactions. This paper is among the first to automatically personalize social\ncomparison targets. In the context of an m-health app for physical activity, we\nuse artificial intelligence (AI) techniques of multi-armed bandits. Results\nfrom our user study (n=53) indicate that there is some evidence that motivation\ncan be increased using the AI-based personalization of social comparison. The\ndetected effects achieved small-to-moderate effect sizes, illustrating the\nreal-world implications of the intervention for enhancing motivation and\nphysical activity. In addition to design implications for social comparison\nfeatures in social apps, this paper identified the personalization paradox, the\nconflict between user modeling and adaptation, as a key design challenge of\npersonalized applications for behavior change. Additionally, we propose\nresearch directions to mitigate this Personalization Paradox.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 11:39:32 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:24:12 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Zhu", "Jichen", ""], ["Dallal", "Diane H.", ""], ["Gray", "Robert C.", ""], ["Villareale", "Jennifer", ""], ["Onta\u00f1\u00f3n", "Santiago", ""], ["Forman", "Evan M.", ""], ["Arigo", "Danielle", ""]]}, {"id": "2101.10025", "submitter": "Wenlong Liao", "authors": "Wenlong Liao, Birgitte Bak-Jensen, Jayakrishnan Radhakrishna Pillai,\n  Yuelong Wang, and Yusen Wang", "title": "A Review of Graph Neural Networks and Their Applications in Power\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have revolutionized many machine learning tasks in power\nsystems, ranging from pattern recognition to signal processing. The data in\nthese tasks is typically represented in Euclidean domains. Nevertheless, there\nis an increasing number of applications in power systems, where data are\ncollected from non-Euclidean domains and represented as graph-structured data\nwith high dimensional features and interdependency among nodes. The complexity\nof graph-structured data has brought significant challenges to the existing\ndeep neural networks defined in Euclidean domains. Recently, many publications\ngeneralizing deep neural networks for graph-structured data in power systems\nhave emerged. In this paper, a comprehensive overview of graph neural networks\n(GNNs) in power systems is proposed. Specifically, several classical paradigms\nof GNNs structures (e.g., graph convolutional networks) are summarized, and key\napplications in power systems, such as fault scenario application, time series\nprediction, power flow calculation, and data generation are reviewed in detail.\nFurthermore, main issues and some research trends about the applications of\nGNNs in power systems are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 11:50:45 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 11:38:48 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liao", "Wenlong", ""], ["Bak-Jensen", "Birgitte", ""], ["Pillai", "Jayakrishnan Radhakrishna", ""], ["Wang", "Yuelong", ""], ["Wang", "Yusen", ""]]}, {"id": "2101.10027", "submitter": "Tuan Anh Bui", "authors": "Anh Bui, Trung Le, He Zhao, Paul Montague, Seyit Camtepe, Dinh Phung", "title": "Understanding and Achieving Efficient Robustness with Adversarial\n  Supervised Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Contrastive learning (CL) has recently emerged as an effective approach to\nlearning representation in a range of downstream tasks. Central to this\napproach is the selection of positive (similar) and negative (dissimilar) sets\nto provide the model the opportunity to `contrast' between data and class\nrepresentation in the latent space. In this paper, we investigate CL for\nimproving model robustness using adversarial samples. We first designed and\nperformed a comprehensive study to understand how adversarial vulnerability\nbehaves in the latent space. Based on these empirical evidences, we propose an\neffective and efficient supervised contrastive learning to achieve model\nrobustness against adversarial attacks. Moreover, we propose a new sample\nselection strategy that optimizes the positive/negative sets by removing\nredundancy and improving correlation with the anchor. Experiments conducted on\nbenchmark datasets show that our Adversarial Supervised Contrastive Learning\n(ASCL) approach outperforms the state-of-the-art defenses by $2.6\\%$ in terms\nof the robust accuracy, whilst our ASCL with the proposed selection strategy\ncan further gain $1.4\\%$ improvement with only $42.8\\%$ positives and $6.3\\%$\nnegatives compared with ASCL without a selection strategy.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 11:57:52 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 03:46:14 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Bui", "Anh", ""], ["Le", "Trung", ""], ["Zhao", "He", ""], ["Montague", "Paul", ""], ["Camtepe", "Seyit", ""], ["Phung", "Dinh", ""]]}, {"id": "2101.10066", "submitter": "Cameron Browne", "authors": "Cameron Browne", "title": "Modern Techniques for Ancient Games", "comments": null, "journal-ref": "Proceedings of IEEE Computational Intelligence and Games (CIG\n  2018), Maastricht, 14 August 2018, pp. 490-497", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Games potentially provide a wealth of knowledge about our shared cultural\npast and the development of human civilisation, but our understanding of early\ngames is incomplete and often based on unreliable reconstructions. This paper\ndescribes the Digital Ludeme Project, a five-year research project currently\nunderway that aims to address such issues using modern computational\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 12:08:42 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Browne", "Cameron", ""]]}, {"id": "2101.10074", "submitter": "Setareh Maghsudi", "authors": "Setareh Maghsudi, Andrew Lan, Jie Xu, and Mihaela van der Schaar", "title": "Personalized Education in the AI Era: What to Expect Next?", "comments": null, "journal-ref": null, "doi": "10.1109/MSP.2021.3055032", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of personalized learning is to design an effective knowledge\nacquisition track that matches the learner's strengths and bypasses her\nweaknesses to ultimately meet her desired goal. This concept emerged several\nyears ago and is being adopted by a rapidly-growing number of educational\ninstitutions around the globe. In recent years, the boost of artificial\nintelligence (AI) and machine learning (ML), together with the advances in big\ndata analysis, has unfolded novel perspectives to enhance personalized\neducation in numerous dimensions. By taking advantage of AI/ML methods, the\neducational platform precisely acquires the student's characteristics. This is\ndone, in part, by observing the past experiences as well as analyzing the\navailable big data through exploring the learners' features and similarities.\nIt can, for example, recommend the most appropriate content among numerous\naccessible ones, advise a well-designed long-term curriculum, connect\nappropriate learners by suggestion, accurate performance evaluation, and the\nlike. Still, several aspects of AI-based personalized education remain\nunexplored. These include, among others, compensating for the adverse effects\nof the absence of peers, creating and maintaining motivations for learning,\nincreasing diversity, removing the biases induced by the data and algorithms,\nand the like. In this paper, while providing a brief review of state-of-the-art\nresearch, we investigate the challenges of AI/ML-based personalized education\nand discuss potential solutions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 12:23:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Maghsudi", "Setareh", ""], ["Lan", "Andrew", ""], ["Xu", "Jie", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2101.10075", "submitter": "Baoliang Chen", "authors": "Baoliang Chen, Wenhan Yang, Haoliang Li, Shiqi Wang and Sam Kwong", "title": "Camera Invariant Feature Learning for Generalized Face Anti-spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has been an increasing consensus in learning based face anti-spoofing\nthat the divergence in terms of camera models is causing a large domain gap in\nreal application scenarios. We describe a framework that eliminates the\ninfluence of inherent variance from acquisition cameras at the feature level,\nleading to the generalized face spoofing detection model that could be highly\nadaptive to different acquisition devices. In particular, the framework is\ncomposed of two branches. The first branch aims to learn the camera invariant\nspoofing features via feature level decomposition in the high frequency domain.\nMotivated by the fact that the spoofing features exist not only in the high\nfrequency domain, in the second branch the discrimination capability of\nextracted spoofing features is further boosted from the enhanced image based on\nthe recomposition of the high-frequency and low-frequency information. Finally,\nthe classification results of the two branches are fused together by a\nweighting strategy. Experiments show that the proposed method can achieve\nbetter performance in both intra-dataset and cross-dataset settings,\ndemonstrating the high generalization capability in various application\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 13:40:43 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Baoliang", ""], ["Yang", "Wenhan", ""], ["Li", "Haoliang", ""], ["Wang", "Shiqi", ""], ["Kwong", "Sam", ""]]}, {"id": "2101.10098", "submitter": "Michael Lissack", "authors": "Michael Lissack", "title": "The Slodderwetenschap (Sloppy Science) of Stochastic Parrots -- A Plea\n  for Science to NOT take the Route Advocated by Gebru and Bender", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.GL physics.hist-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article is a position paper written in reaction to the now-infamous\npaper titled \"On the Dangers of Stochastic Parrots: Can Language Models Be Too\nBig?\" by Timnit Gebru, Emily Bender, and others who were, as of the date of\nthis writing, still unnamed. I find the ethics of the Parrot Paper lacking, and\nin that lack, I worry about the direction in which computer science, machine\nlearning, and artificial intelligence are heading. At best, I would describe\nthe argumentation and evidentiary practices embodied in the Parrot Paper as\nSlodderwetenschap (Dutch for Sloppy Science) -- a word which the academic world\nlast widely used in conjunction with the Diederik Stapel affair in psychology\n[2]. What is missing in the Parrot Paper are three critical elements: 1)\nacknowledgment that it is a position paper/advocacy piece rather than research,\n2) explicit articulation of the critical presuppositions, and 3) explicit\nconsideration of cost/benefit trade-offs rather than a mere recitation of\npotential \"harms\" as if benefits did not matter. To leave out these three\nelements is not good practice for either science or research.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:55:09 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Lissack", "Michael", ""]]}, {"id": "2101.10102", "submitter": "Renjue Li", "authors": "Renjue Li and Pengfei Yang and Cheng-Chao Huang and Bai Xue and Lijun\n  Zhang", "title": "Probabilistic Robustness Analysis for DNNs based on PAC Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a black box based approach for analysing deep neural\nnetworks (DNNs). We view a DNN as a function $\\boldsymbol{f}$ from inputs to\noutputs, and consider the local robustness property for a given input. Based on\nscenario optimization technique in robust control design, we learn the score\ndifference function $f_i-f_\\ell$ with respect to the target label $\\ell$ and\nattacking label $i$. We use a linear template over the input pixels, and learn\nthe corresponding coefficients of the score difference function, based on a\nreduction to a linear programming (LP) problems. To make it scalable, we\npropose optimizations including components based learning and focused learning.\nThe learned function offers a probably approximately correct (PAC) guarantee\nfor the robustness property. Since the score difference function is an\napproximation of the local behaviour of the DNN, it can be used to generate\npotential adversarial examples, and the original network can be used to check\nwhether they are spurious or not. Finally, we focus on the input pixels with\nlarge absolute coefficients, and use them to explain the attacking scenario. We\nhave implemented our approach in a prototypical tool DeepPAC. Our experimental\nresults show that our framework can handle very large neural networks like\nResNet152 with $6.5$M neurons, and often generates adversarial examples which\nare very close to the decision boundary.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 14:10:52 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Li", "Renjue", ""], ["Yang", "Pengfei", ""], ["Huang", "Cheng-Chao", ""], ["Xue", "Bai", ""], ["Zhang", "Lijun", ""]]}, {"id": "2101.10115", "submitter": "Iosu Rodr\\'iguez-Mart\\'inez", "authors": "Martin Pap\\v{c}o, Iosu Rodr\\'iguez-Mart\\'inez, Javier Fumanal-Idocin,\n  Abdulrahman H. Altalhi and Humberto Bustince", "title": "A fusion method for multi-valued data", "comments": null, "journal-ref": "Information Fusion, Volume 71, 2021, Pages 1-10", "doi": "10.1016/j.inffus.2021.01.001", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we propose an extension of the notion of deviation-based\naggregation function tailored to aggregate multidimensional data. Our objective\nis both to improve the results obtained by other methods that try to select the\nbest aggregation function for a particular set of data, such as penalty\nfunctions, and to reduce the temporal complexity required by such approaches.\nWe discuss how this notion can be defined and present three illustrative\nexamples of the applicability of our new proposal in areas where temporal\nconstraints can be strict, such as image processing, deep learning and decision\nmaking, obtaining favourable results in the process.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 14:27:21 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Pap\u010do", "Martin", ""], ["Rodr\u00edguez-Mart\u00ednez", "Iosu", ""], ["Fumanal-Idocin", "Javier", ""], ["Altalhi", "Abdulrahman H.", ""], ["Bustince", "Humberto", ""]]}, {"id": "2101.10132", "submitter": "Brahim Hnich", "authors": "Salma Chaieb and Brahim Hnich and Ali Ben Mrad", "title": "Obsolete Personal Information Update System for the Prevention of Falls\n  among Elderly Patients", "comments": "The article is submitted for review to the journal \"Decision Support\n  Systems\" on January 19, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Falls are a common problem affecting the older adults and a major public\nhealth issue. Centers for Disease Control and Prevention, and World Health\nOrganization report that one in three adults over the age of 65 and half of the\nadults over 80 fall each year. In recent years, an ever-increasing range of\napplications have been developed to help deliver more effective falls\nprevention interventions. All these applications rely on a huge elderly\npersonal database collected from hospitals, mutual health, and other\norganizations in caring for elderly. The information describing an elderly is\ncontinually evolving and may become obsolete at a given moment and contradict\nwhat we already know on the same person. So, it needs to be continuously\nchecked and updated in order to restore the database consistency and then\nprovide better service. This paper provides an outline of an Obsolete personal\nInformation Update System (OIUS) designed in the context of the elderly-fall\nprevention project. Our OIUS aims to control and update in real-time the\ninformation acquired about each older adult, provide on-demand consistent\ninformation and supply tailored interventions to caregivers and fall-risk\npatients. The approach outlined for this purpose is based on a polynomial-time\nalgorithm build on top of a causal Bayesian network representing the elderly\ndata. The result is given as a recommendation tree with some accuracy level. We\nconduct a thorough empirical study for such a model on an elderly personal\ninformation base. Experiments confirm the viability and effectiveness of our\nOIUS.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 00:15:14 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chaieb", "Salma", ""], ["Hnich", "Brahim", ""], ["Mrad", "Ali Ben", ""]]}, {"id": "2101.10162", "submitter": "Giulia Francescutto", "authors": "Giulia Francescutto, Konstantin Schekotihin, Mohammed M. S. El-Kholany", "title": "Solving a Multi-resource Partial-ordering Flexible Variant of the\n  Job-shop Scheduling Problem with Hybrid ASP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many complex activities of production cycles, such as quality control or\nfault analysis, require highly experienced specialists to perform various\noperations on (semi)finished products using different tools. In practical\nscenarios, the selection of a next operation is complicated, since each expert\nhas only a local view on the total set of operations to be performed. As a\nresult, decisions made by the specialists are suboptimal and might cause\nsignificant costs. In this paper, we consider a Multi-resource Partial-ordering\nFlexible Job-shop Scheduling (MPF-JSS) problem where partially-ordered\nsequences of operations must be scheduled on multiple required resources, such\nas tools and specialists. The resources are flexible and can perform one or\nmore operations depending on their properties. The problem is modeled using\nAnswer Set Programming (ASP) in which the time assignments are efficiently done\nusing Difference Logic. Moreover, we suggest two multi-shot solving strategies\naiming at the identification of the time bounds allowing for a solution of the\nschedule optimization problem. Experiments conducted on a set of instances\nextracted from a medium-sized semiconductor fault analysis lab indicate that\nour approach can find schedules for 87 out of 91 considered real-world\ninstances.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 15:21:32 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 09:07:04 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Francescutto", "Giulia", ""], ["Schekotihin", "Konstantin", ""], ["El-Kholany", "Mohammed M. S.", ""]]}, {"id": "2101.10179", "submitter": "Marcus Westberg", "authors": "Marcus Westberg, Kary Fr\\\"amling", "title": "Cognitive Perspectives on Context-based Decisions and Explanations", "comments": "Part of IJCAI-PRICAI 2020 Workshop on XAI. Proceedings archived on\n  https://sites.google.com/view/xai2020/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When human cognition is modeled in Philosophy and Cognitive Science, there is\na pervasive idea that humans employ mental representations in order to navigate\nthe world and make predictions about outcomes of future actions. By\nunderstanding how these representational structures work, we not only\nunderstand more about human cognition but also gain a better understanding for\nhow humans rationalise and explain decisions. This has an influencing effect on\nexplainable AI, where the goal is to provide explanations of computer\ndecision-making for a human audience. We show that the Contextual Importance\nand Utility method for XAI share an overlap with the current new wave of\naction-oriented predictive representational structures, in ways that makes CIU\na reliable tool for creating explanations that humans can relate to and trust.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 15:49:52 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Westberg", "Marcus", ""], ["Fr\u00e4mling", "Kary", ""]]}, {"id": "2101.10181", "submitter": "Yongxin Liu", "authors": "Yongxin Liu, Jian Wang, Jianqiang Li, Shuteng Niu, Houbing Song", "title": "Machine Learning for the Detection and Identification of Internet of\n  Things (IoT) Devices: A Survey", "comments": "This paper is currently under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) is becoming an indispensable part of everyday\nlife, enabling a variety of emerging services and applications. However, the\npresence of rogue IoT devices has exposed the IoT to untold risks with severe\nconsequences. The first step in securing the IoT is detecting rogue IoT devices\nand identifying legitimate ones. Conventional approaches use cryptographic\nmechanisms to authenticate and verify legitimate devices' identities. However,\ncryptographic protocols are not available in many systems. Meanwhile, these\nmethods are less effective when legitimate devices can be exploited or\nencryption keys are disclosed. Therefore, non-cryptographic IoT device\nidentification and rogue device detection become efficient solutions to secure\nexisting systems and will provide additional protection to systems with\ncryptographic protocols. Non-cryptographic approaches require more effort and\nare not yet adequately investigated. In this paper, we provide a comprehensive\nsurvey on machine learning technologies for the identification of IoT devices\nalong with the detection of compromised or falsified ones from the viewpoint of\npassive surveillance agents or network operators. We classify the IoT device\nidentification and detection into four categories: device-specific pattern\nrecognition, Deep Learning enabled device identification, unsupervised device\nidentification, and abnormal device detection. Meanwhile, we discuss various\nML-related enabling technologies for this purpose. These enabling technologies\ninclude learning algorithms, feature engineering on network traffic traces and\nwireless signals, continual learning, and abnormality detection.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 15:51:04 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Liu", "Yongxin", ""], ["Wang", "Jian", ""], ["Li", "Jianqiang", ""], ["Niu", "Shuteng", ""], ["Song", "Houbing", ""]]}, {"id": "2101.10203", "submitter": "Eli Schwartz", "authors": "Eli Schwartz, Alex Bronstein, Raja Giryes", "title": "ISP Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, many of the images captured are \"observed\" by machines only and not\nby humans, for example, robots' or autonomous cars' cameras. High-level machine\nvision models, such as object recognition, assume images are transformed to\nsome canonical image space by the camera ISP. However, the camera ISP is\noptimized for producing visually pleasing images to human observers and not for\nmachines, thus, one may spare the ISP compute time and apply the vision models\ndirectly to the raw data. Yet, it has been shown that training such models\ndirectly on the RAW images results in a performance drop. To mitigate this drop\nin performance (without the need to annotate RAW data), we use a dataset of RAW\nand RGB image pairs, which can be easily acquired with no human labeling. We\nthen train a model that is applied directly to the RAW data by using knowledge\ndistillation such that the model predictions for RAW images will be aligned\nwith the predictions of an off-the-shelf pre-trained model for processed RGB\nimages. Our experiments show that our performance on RAW images is\nsignificantly better than a model trained on labeled RAW images. It also\nreasonably matches the predictions of a pre-trained model on processed RGB\nimages, while saving the ISP compute overhead.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 16:12:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Schwartz", "Eli", ""], ["Bronstein", "Alex", ""], ["Giryes", "Raja", ""]]}, {"id": "2101.10215", "submitter": "Yakup Kutlu", "authors": "Enver Kaan Alpturk, Yakup Kutlu", "title": "Analysis of Relation between Motor Activity and Imaginary EEG Records", "comments": "6 pages, 4 figures, Journal of Artificial Intellicence with\n  Application", "journal-ref": "Journal of Artificial Intellicence with Application, 2020", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electroencephalography (EEG) signals signals are often used to learn about\nbrain structure and to learn what thinking. EEG signals can be easily affected\nby external factors. For this reason, they should be applied various\npre-process during their analysis. In this study, it is used the EEG signals\nreceived from 109 subjects when opening and closing their right or left fists\nand performing hand and foot movements and imagining the same movements. The\nrelationship between motor activities and imaginary of that motor activities\nwere investigated. Algorithms with high performance rates have been used for\nfeature extraction , selection and classification using the nearest neighbour\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 05:02:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Alpturk", "Enver Kaan", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2101.10229", "submitter": "Masato Kimura Dr.", "authors": "Yuto Aizawa and Masato Kimura", "title": "Universal Approximation Properties for ODENet and ResNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.CA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove a universal approximation property (UAP) for a class of ODENet and a\nclass of ResNet, which are used in many deep learning algorithms. The UAP can\nbe stated as follows. Let $n$ and $m$ be the dimension of input and output\ndata, and assume $m\\leq n$. Then we show that ODENet width $n+m$ with any\nnon-polynomial continuous activation function can approximate any continuous\nfunction on a compact subset on $\\mathbb{R}^n$. We also show that ResNet has\nthe same property as the depth tends to infinity. Furthermore, we derive\nexplicitly the gradient of a loss function with respect to a certain tuning\nvariable. We use this to construct a learning algorithm for ODENet. To\ndemonstrate the usefulness of this algorithm, we apply it to a regression\nproblem, a binary classification, and a multinomial classification in MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 06:04:09 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 23:21:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Aizawa", "Yuto", ""], ["Kimura", "Masato", ""]]}, {"id": "2101.10249", "submitter": "Greta Laage", "authors": "Greta Laage, Emma Frejinger, Andrea Lodi and Guillaume Rabusseau", "title": "Assessing the Impact: Does an Improvement to a Revenue Management System\n  Lead to an Improved Revenue?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Airlines and other industries have been making use of sophisticated Revenue\nManagement Systems to maximize revenue for decades. While improving the\ndifferent components of these systems has been the focus of numerous studies,\nestimating the impact of such improvements on the revenue has been overlooked\nin the literature despite its practical importance. Indeed, quantifying the\nbenefit of a change in a system serves as support for investment decisions.\nThis is a challenging problem as it corresponds to the difference between the\ngenerated value and the value that would have been generated keeping the system\nas before. The latter is not observable. Moreover, the expected impact can be\nsmall in relative value. In this paper, we cast the problem as counterfactual\nprediction of unobserved revenue. The impact on revenue is then the difference\nbetween the observed and the estimated revenue. The originality of this work\nlies in the innovative application of econometric methods proposed for\nmacroeconomic applications to a new problem setting. Broadly applicable, the\napproach benefits from only requiring revenue data observed for\norigin-destination pairs in the network of the airline at each day, before and\nafter a change in the system is applied. We report results using real\nlarge-scale data from Air Canada. We compare a deep neural network\ncounterfactual predictions model with econometric models. They achieve\nrespectively 1% and 1.1% of error on the counterfactual revenue predictions,\nand allow to accurately estimate small impacts (in the order of 2%).\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:55:29 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 14:00:47 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Laage", "Greta", ""], ["Frejinger", "Emma", ""], ["Lodi", "Andrea", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2101.10263", "submitter": "Yakup Kutlu", "authors": "Gokhan Altan, Yakup Kutlu", "title": "Generative Autoencoder Kernels on Deep Learning for Brain Activity\n  Analysis", "comments": "12 pages, 2 figures, Natural and Engineering Sciences", "journal-ref": "Natural and Engineering Sciences, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) is a two-step classification model that consists feature\nlearning, generating feature representations using unsupervised ways and the\nsupervised learning stage at the last step of model using at least two hidden\nlayers on the proposed structures by fully connected layers depending on of the\nartificial neural networks. The optimization of the predefined classification\nparameters for the supervised models eases reaching the global optimality with\nexact zero training error. The autoencoder (AE) models are the highly\ngeneralized ways of the unsupervised stages for the DL to define the output\nweights of the hidden neurons with various representations. As alternatively to\nthe conventional Extreme Learning Machines (ELM) AE, Hessenberg\ndecomposition-based ELM autoencoder (HessELM-AE) is a novel kernel to generate\ndifferent presentations of the input data within the intended sizes of the\nmodels. The aim of the study is analyzing the performance of the novel Deep AE\nkernel for clinical availability on electroencephalogram (EEG) with stroke\npatients. The slow cortical potentials (SCP) training in stroke patients during\neight neurofeedback sessions were analyzed using Hilbert-Huang Transform. The\nstatistical features of different frequency modulations were fed into the Deep\nELM model for generative AE kernels. The novel Deep ELM-AE kernels have\ndiscriminated the brain activity with high classification performances for\npositivity and negativity tasks in stroke patients.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 08:19:47 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Altan", "Gokhan", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2101.10265", "submitter": "Yakup Kutlu", "authors": "Gokhan Altan, Yakup Kutlu", "title": "Superiorities of Deep Extreme Learning Machines against Convolutional\n  Neural Networks", "comments": "7 pages, 2 figures, Natural and Engineering Sciences", "journal-ref": "Natural and Engineering Sciences, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) is a machine learning procedure for artificial\nintelligence that analyzes the input data in detail by increasing neuron sizes\nand number of the hidden layers. DL has a popularity with the common\nimprovements on the graphical processing unit capabilities. Increasing number\nof the neuron sizes at each layer and hidden layers is directly related to the\ncomputation time and training speed of the classifier models. The\nclassification parameters including neuron weights, output weights, and biases\nneed to be optimized for obtaining an optimum model. Most of the popular DL\nalgorithms require long training times for optimization of the parameters with\nfeature learning progresses and back-propagated training procedures. Reducing\nthe training time and providing a real-time decision system are the basic focus\npoints of the novel approaches. Deep Extreme Learning machines (Deep ELM)\nclassifier model is one of the fastest and effective way to meet fast\nclassification problems. In this study, Deep ELM model, its superiorities and\nweaknesses are discussed, the problems that are more suitable for the\nclassifiers against Convolutional neural network based DL algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 08:22:18 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Altan", "Gokhan", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2101.10267", "submitter": "Uwe Aickelin", "authors": "Mansoureh Maadia, Uwe Aickelin, Hadi Akbarzadeh Khorshidi", "title": "A new interval-based aggregation approach based on bagging and Interval\n  Agreement Approach (IAA) in ensemble learning", "comments": "The Australasian Data Mining Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main aim in ensemble learning is using multiple individual classifiers\noutputs rather than one classifier output to aggregate them for more accurate\nclassification. Generating an ensemble classifier generally is composed of\nthree steps: selecting the base classifier, applying a sampling strategy to\ngenerate different individual classifiers and aggregation the classifiers\noutputs. This paper focuses on the classifiers outputs aggregation step and\npresents a new interval-based aggregation modeling using bagging resampling\napproach and Interval Agreement Approach (IAA) in ensemble learning. IAA is an\ninteresting and practical aggregation approach in decision making which was\nintroduced to combine decision makers opinions when they present their opinions\nby intervals. In this paper, in addition to implementing a new aggregation\napproach in ensemble learning, we designed some experiments to encourage\nresearchers to use interval modeling in ensemble learning because it preserves\nmore uncertainty and this leads to more accurate classification. For this\npurpose, we compared the results of implementing the proposed method to the\nmajority vote as the most common and successful aggregation function in the\nliterature on 10 medical data sets to show the better performance of the\ninterval modeling and the proposed interval-based aggregation function in\nbinary classification when it comes to ensemble learning. The results confirm\nthe good performance of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:33:12 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Maadia", "Mansoureh", ""], ["Aickelin", "Uwe", ""], ["Khorshidi", "Hadi Akbarzadeh", ""]]}, {"id": "2101.10268", "submitter": "Hong Sun", "authors": "Hong Sun, Kristof Depraetere, Laurent Meesseman, Jos De Roo, Martijn\n  Vanbiervliet, Jos De Baerdemaeker, Herman Muys, Vera von Dossow, Nikolai\n  Hulde, Ralph Szymanowsky", "title": "A scalable approach for developing clinical risk prediction applications\n  in different hospitals", "comments": "Preprint of Journal of Biomedical Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Machine learning algorithms are now widely used in predicting\nacute events for clinical applications. While most of such prediction\napplications are developed to predict the risk of a particular acute event at\none hospital, few efforts have been made in extending the developed solutions\nto other events or to different hospitals. We provide a scalable solution to\nextend the process of clinical risk prediction model development of multiple\ndiseases and their deployment in different Electronic Health Records (EHR)\nsystems.\n  Materials and Methods: We defined a generic process for clinical risk\nprediction model development. A calibration tool has been created to automate\nthe model generation process. We applied the model calibration process at four\nhospitals, and generated risk prediction models for delirium, sepsis and acute\nkidney injury (AKI) respectively at each of these hospitals.\n  Results: The delirium risk prediction models achieved area under the\nreceiver-operating characteristic curve (AUROC) ranging from 0.82 to 0.95 over\ndifferent stages of a hospital stay on the test datasets of the four hospitals.\nThe sepsis models achieved AUROC ranging from 0.88 to 0.95, and the AKI models\nachieved AUROC ranging from 0.85 to 0.92.\n  Discussion: The scalability discussed in this paper is based on building\ncommon data representations (syntactic interoperability) between EHRs stored in\ndifferent hospitals. Semantic interoperability, a more challenging requirement\nthat different EHRs share the same meaning of data, e.g. a same lab coding\nsystem, is not mandated with our approach.\n  Conclusions: Our study describes a method to develop and deploy clinical risk\nprediction models in a scalable way. We demonstrate its feasibility by\ndeveloping risk prediction models for three diseases across four hospitals.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 21:22:32 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 11:32:49 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Sun", "Hong", ""], ["Depraetere", "Kristof", ""], ["Meesseman", "Laurent", ""], ["De Roo", "Jos", ""], ["Vanbiervliet", "Martijn", ""], ["De Baerdemaeker", "Jos", ""], ["Muys", "Herman", ""], ["von Dossow", "Vera", ""], ["Hulde", "Nikolai", ""], ["Szymanowsky", "Ralph", ""]]}, {"id": "2101.10276", "submitter": "Michael Noukhovitch", "authors": "Michael Noukhovitch, Travis LaCroix, Angeliki Lazaridou, Aaron\n  Courville", "title": "Emergent Communication under Competition", "comments": "To be presented at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The literature in modern machine learning has only negative results for\nlearning to communicate between competitive agents using standard RL. We\nintroduce a modified sender-receiver game to study the spectrum of\npartially-competitive scenarios and show communication can indeed emerge in a\ncompetitive setting. We empirically demonstrate three key takeaways for future\nresearch. First, we show that communication is proportional to cooperation, and\nit can occur for partially competitive scenarios using standard learning\nalgorithms. Second, we highlight the difference between communication and\nmanipulation and extend previous metrics of communication to the competitive\ncase. Third, we investigate the negotiation game where previous work failed to\nlearn communication between independent agents (Cao et al., 2018). We show\nthat, in this setting, both agents must benefit from communication for it to\nemerge; and, with a slight modification to the game, we demonstrate successful\ncommunication between competitive agents. We hope this work overturns\nmisconceptions and inspires more research in competitive emergent\ncommunication.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 17:58:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Noukhovitch", "Michael", ""], ["LaCroix", "Travis", ""], ["Lazaridou", "Angeliki", ""], ["Courville", "Aaron", ""]]}, {"id": "2101.10280", "submitter": "Dongdong Wang", "authors": "Dongdong Wang, Shunpu Zhang, and Liqiang Wang", "title": "Deep Epidemiological Modeling by Black-box Knowledge Distillation: An\n  Accurate Deep Learning Model for COVID-19", "comments": "Accepted by AAAI-21/IAAI-21, 7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate and efficient forecasting system is imperative to the prevention\nof emerging infectious diseases such as COVID-19 in public health. This system\nrequires accurate transient modeling, lower computation cost, and fewer\nobservation data. To tackle these three challenges, we propose a novel deep\nlearning approach using black-box knowledge distillation for both accurate and\nefficient transmission dynamics prediction in a practical manner. First, we\nleverage mixture models to develop an accurate, comprehensive, yet impractical\nsimulation system. Next, we use simulated observation sequences to query the\nsimulation system to retrieve simulated projection sequences as knowledge.\nThen, with the obtained query data, sequence mixup is proposed to improve query\nefficiency, increase knowledge diversity, and boost distillation model\naccuracy. Finally, we train a student deep neural network with the retrieved\nand mixed observation-projection sequences for practical use. The case study on\nCOVID-19 justifies that our approach accurately projects infections with much\nlower computation cost when observation data are limited.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 19:49:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wang", "Dongdong", ""], ["Zhang", "Shunpu", ""], ["Wang", "Liqiang", ""]]}, {"id": "2101.10284", "submitter": "Mingyu Cai", "authors": "Mingyu Cai, Shaoping Xiao, and Zhen Kan", "title": "Reinforcement Learning Based Temporal Logic Control with Soft\n  Constraints Using Limit-deterministic Generalized Buchi Automata", "comments": "arXiv admin note: text overlap with arXiv:2010.06797,\n  arXiv:2007.14325", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the control synthesis of motion planning subject to\nuncertainties. The uncertainties are considered in robot motion and environment\nproperties, giving rise to the probabilistic labeled Markov decision process\n(MDP). A model-free reinforcement learning (RL) is developed to generate a\nfinite-memory control policy to satisfy high-level tasks expressed in linear\ntemporal logic (LTL) formulas. One of the novelties is to translate LTL into a\nlimit deterministic generalized B\\\"uchi automaton (LDGBA) and develop a\ncorresponding embedded LDGBA (E-LDGBA) by incorporating a tracking-frontier\nfunction to overcome the issue of sparse accepting rewards, resulting in\nimproved learning performance without increasing computational complexity. Due\nto potentially conflicting tasks, a relaxed product MDP is developed to allow\nthe agent to revise its motion plan without strictly following the desired LTL\nconstraints if the desired tasks can only be partially fulfilled. An expected\nreturn composed of violation rewards and accepting rewards is developed. The\ndesigned violation function quantifies the differences between the revised and\nthe desired motion planning, while the accepting rewards are designed to\nenforce the satisfaction of the acceptance condition of the relaxed product\nMDP. Rigorous analysis shows that any RL algorithm that optimizes the expected\nreturn is guaranteed to find policies that, in decreasing order, can 1) satisfy\nacceptance condition of relaxed product MDP and 2) reduce the violation cost\nover long-term behaviors. Also, we validate the control synthesis approach via\nsimulation and experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:09:11 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 18:16:45 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cai", "Mingyu", ""], ["Xiao", "Shaoping", ""], ["Kan", "Zhen", ""]]}, {"id": "2101.10292", "submitter": "Xiaoqian Wu", "authors": "Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Xijie Huang, Liang Xu, Cewu Lu", "title": "Transferable Interactiveness Knowledge for Human-Object Interaction\n  Detection", "comments": "TPAMI version of our CVPR2019 paper with a new benchmark\n  PaStaNet-HOI. Code:\n  https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network. arXiv\n  admin note: substantial text overlap with arXiv:1811.08264", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3054048", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-Object Interaction (HOI) detection is an important problem to\nunderstand how humans interact with objects. In this paper, we explore\ninteractiveness knowledge which indicates whether a human and an object\ninteract with each other or not. We found that interactiveness knowledge can be\nlearned across HOI datasets and bridge the gap between diverse HOI category\nsettings. Our core idea is to exploit an interactiveness network to learn the\ngeneral interactiveness knowledge from multiple HOI datasets and perform\nNon-Interaction Suppression (NIS) before HOI classification in inference. On\naccount of the generalization ability of interactiveness, interactiveness\nnetwork is a transferable knowledge learner and can be cooperated with any HOI\ndetection models to achieve desirable results. We utilize the human instance\nand body part features together to learn the interactiveness in hierarchical\nparadigm, i.e., instance-level and body part-level interactivenesses.\nThereafter, a consistency task is proposed to guide the learning and extract\ndeeper interactive visual clues. We extensively evaluate the proposed method on\nHICO-DET, V-COCO, and a newly constructed PaStaNet-HOI dataset. With the\nlearned interactiveness, our method outperforms state-of-the-art HOI detection\nmethods, verifying its efficacy and flexibility. Code is available at\nhttps://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:21:07 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 04:21:24 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 10:04:29 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Li", "Yong-Lu", ""], ["Liu", "Xinpeng", ""], ["Wu", "Xiaoqian", ""], ["Huang", "Xijie", ""], ["Xu", "Liang", ""], ["Lu", "Cewu", ""]]}, {"id": "2101.10305", "submitter": "Michael Dennis", "authors": "Charlotte Roman, Michael Dennis, Andrew Critch, Stuart Russell", "title": "Accumulating Risk Capital Through Investing in Cooperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on promoting cooperation in multi-agent learning has resulted in\nmany methods which successfully promote cooperation at the cost of becoming\nmore vulnerable to exploitation by malicious actors. We show that this is an\nunavoidable trade-off and propose an objective which balances these concerns,\npromoting both safety and long-term cooperation. Moreover, the trade-off\nbetween safety and cooperation is not severe, and you can receive exponentially\nlarge returns through cooperation from a small amount of risk. We study both an\nexact solution method and propose a method for training policies that targets\nthis objective, Accumulating Risk Capital Through Investing in Cooperation\n(ARCTIC), and evaluate them in iterated Prisoner's Dilemma and Stag Hunt.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:41:45 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 00:37:42 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Roman", "Charlotte", ""], ["Dennis", "Michael", ""], ["Critch", "Andrew", ""], ["Russell", "Stuart", ""]]}, {"id": "2101.10318", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla, Benjamin M. Marlin", "title": "Multi-Time Attention Networks for Irregularly Sampled Time Series", "comments": "Accepted at International Conference on Learning Representations\n  (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregular sampling occurs in many time series modeling applications where it\npresents a significant challenge to standard deep learning models. This work is\nmotivated by the analysis of physiological time series data in electronic\nhealth records, which are sparse, irregularly sampled, and multivariate. In\nthis paper, we propose a new deep learning framework for this setting that we\ncall Multi-Time Attention Networks. Multi-Time Attention Networks learn an\nembedding of continuous-time values and use an attention mechanism to produce a\nfixed-length representation of a time series containing a variable number of\nobservations. We investigate the performance of this framework on interpolation\nand classification tasks using multiple datasets. Our results show that the\nproposed approach performs as well or better than a range of baseline and\nrecently proposed models while offering significantly faster training times\nthan current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:57:42 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 17:52:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2101.10320", "submitter": "Jiaxuan You", "authors": "Jiaxuan You, Jonathan Gomes-Selman, Rex Ying, Jure Leskovec", "title": "Identity-aware Graph Neural Networks", "comments": "AAAI 2021. Version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing Graph Neural Networks (GNNs) provide a powerful modeling\nframework for relational data. However, the expressive power of existing GNNs\nis upper-bounded by the 1-Weisfeiler-Lehman (1-WL) graph isomorphism test,\nwhich means GNNs that are not able to predict node clustering coefficients and\nshortest path distances, and cannot differentiate between different d-regular\ngraphs. Here we develop a class of message passing GNNs, named Identity-aware\nGraph Neural Networks (ID-GNNs), with greater expressive power than the 1-WL\ntest. ID-GNN offers a minimal but powerful solution to limitations of existing\nGNNs. ID-GNN extends existing GNN architectures by inductively considering\nnodes' identities during message passing. To embed a given node, ID-GNN first\nextracts the ego network centered at the node, then conducts rounds of\nheterogeneous message passing, where different sets of parameters are applied\nto the center node than to other surrounding nodes in the ego network. We\nfurther propose a simplified but faster version of ID-GNN that injects node\nidentity information as augmented node features. Altogether, both versions of\nID-GNN represent general extensions of message passing GNNs, where experiments\nshow that transforming existing GNNs to ID-GNNs yields on average 40% accuracy\nimprovement on challenging node, edge, and graph property prediction tasks; 3%\naccuracy improvement on node and graph classification benchmarks; and 15% ROC\nAUC improvement on real-world link prediction tasks. Additionally, ID-GNNs\ndemonstrate improved or comparable performance over other task-specific graph\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:59:01 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 08:14:23 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["You", "Jiaxuan", ""], ["Gomes-Selman", "Jonathan", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""]]}, {"id": "2101.10369", "submitter": "Tze-Yang Tung", "authors": "Tze-Yang Tung, Szymon Kobus, Joan Roig Pujol, Deniz Gunduz", "title": "Effective Communications: A Joint Learning and Communication Framework\n  for Multi-Agent Reinforcement Learning over Noisy Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel formulation of the \"effectiveness problem\" in\ncommunications, put forth by Shannon and Weaver in their seminal work [2], by\nconsidering multiple agents communicating over a noisy channel in order to\nachieve better coordination and cooperation in a multi-agent reinforcement\nlearning (MARL) framework. Specifically, we consider a multi-agent partially\nobservable Markov decision process (MA-POMDP), in which the agents, in addition\nto interacting with the environment can also communicate with each other over a\nnoisy communication channel. The noisy communication channel is considered\nexplicitly as part of the dynamics of the environment and the message each\nagent sends is part of the action that the agent can take. As a result, the\nagents learn not only to collaborate with each other but also to communicate\n\"effectively\" over a noisy channel. This framework generalizes both the\ntraditional communication problem, where the main goal is to convey a message\nreliably over a noisy channel, and the \"learning to communicate\" framework that\nhas received recent attention in the MARL literature, where the underlying\ncommunication channels are assumed to be error-free. We show via examples that\nthe joint policy learned using the proposed framework is superior to that where\nthe communication is considered separately from the underlying MA-POMDP. This\nis a very powerful framework, which has many real world applications, from\nautonomous vehicle planning to drone swarm control, and opens up the rich\ntoolbox of deep reinforcement learning for the design of multi-user\ncommunication systems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 10:43:41 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 17:30:45 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Tung", "Tze-Yang", ""], ["Kobus", "Szymon", ""], ["Pujol", "Joan Roig", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2101.10377", "submitter": "Vladislav Nenchev", "authors": "Andrea Favrin and Vladislav Nenchev and Angelo Cenedese", "title": "Learning to falsify automated driving vehicles with prior knowledge", "comments": "Preprint accepted at IFAC World Congress 2020, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While automated driving technology has achieved a tremendous progress, the\nscalable and rigorous testing and verification of safe automated and autonomous\ndriving vehicles remain challenging. This paper proposes a learning-based\nfalsification framework for testing the implementation of an automated or\nself-driving function in simulation. We assume that the function specification\nis associated with a violation metric on possible scenarios. Prior knowledge is\nincorporated to limit the scenario parameter variance and in a model-based\nfalsifier to guide and improve the learning process. For an exemplary adaptive\ncruise controller, the presented framework yields non-trivial falsifying\nscenarios with higher reward, compared to scenarios obtained by purely\nlearning-based or purely model-based falsification approaches.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 19:51:38 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Favrin", "Andrea", ""], ["Nenchev", "Vladislav", ""], ["Cenedese", "Angelo", ""]]}, {"id": "2101.10384", "submitter": "Anurag Pratik", "authors": "Anurag Pratik, Soumith Chintala, Kavya Srinet, Dhiraj Gandhi, Rebecca\n  Qian, Yuxuan Sun, Ryan Drew, Sara Elkafrawy, Anoushka Tiwari, Tucker Hart,\n  Mary Williamson, Abhinav Gupta, Arthur Szlam", "title": "droidlet: modular, heterogenous, multi-modal agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been significant advances in building end-to-end\nMachine Learning (ML) systems that learn at scale. But most of these systems\nare: (a) isolated (perception, speech, or language only); (b) trained on static\ndatasets. On the other hand, in the field of robotics, large-scale learning has\nalways been difficult. Supervision is hard to gather and real world physical\ninteractions are expensive. In this work we introduce and open-source droidlet,\na modular, heterogeneous agent architecture and platform. It allows us to\nexploit both large-scale static datasets in perception and language and\nsophisticated heuristics often used in robotics; and provides tools for\ninteractive annotation. Furthermore, it brings together perception, language\nand action onto one platform, providing a path towards agents that learn from\nthe richness of real world interactions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 20:10:35 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Pratik", "Anurag", ""], ["Chintala", "Soumith", ""], ["Srinet", "Kavya", ""], ["Gandhi", "Dhiraj", ""], ["Qian", "Rebecca", ""], ["Sun", "Yuxuan", ""], ["Drew", "Ryan", ""], ["Elkafrawy", "Sara", ""], ["Tiwari", "Anoushka", ""], ["Hart", "Tucker", ""], ["Williamson", "Mary", ""], ["Gupta", "Abhinav", ""], ["Szlam", "Arthur", ""]]}, {"id": "2101.10385", "submitter": "Michael Tashman", "authors": "Jiayi Xie, Michael Tashman, John Hoffman, Lee Winikor, Rouzbeh Gerami", "title": "Online and Scalable Model Selection with Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online applications running on live traffic are powered by machine\nlearning models, for which training, validation, and hyper-parameter tuning are\nconducted on historical data. However, it is common for models demonstrating\nstrong performance in offline analysis to yield poorer performance when\ndeployed online. This problem is a consequence of the difficulty of training on\nhistorical data in non-stationary environments. Moreover, the machine learning\nmetrics used for model selection may not sufficiently correlate with real-world\nbusiness metrics used to determine the success of the applications being\ntested. These problems are particularly prominent in the Real-Time Bidding\n(RTB) domain, in which ML models power bidding strategies, and a change in\nmodels will likely affect performance of the advertising campaigns. In this\nwork, we present Automatic Model Selector (AMS), a system for scalable online\nselection of RTB bidding strategies based on real-world performance metrics.\nAMS employs Multi-Armed Bandits (MAB) to near-simultaneously run and evaluate\nmultiple models against live traffic, allocating the most traffic to the\nbest-performing models while decreasing traffic to those with poorer online\nperformance, thereby minimizing the impact of inferior models on overall\ncampaign performance. The reliance on offline data is avoided, instead making\nmodel selections on a case-by-case basis according to actionable business\ngoals. AMS allows new models to be safely introduced into live campaigns as\nsoon as they are developed, minimizing the risk to overall performance. In\nlive-traffic tests on multiple ad campaigns, the AMS system proved highly\neffective at improving ad campaign performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 20:12:52 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Xie", "Jiayi", ""], ["Tashman", "Michael", ""], ["Hoffman", "John", ""], ["Winikor", "Lee", ""], ["Gerami", "Rouzbeh", ""]]}, {"id": "2101.10430", "submitter": "Erin Lanus", "authors": "Erin Lanus, Ivan Hernandez, Adam Dachowicz, Laura Freeman, Melanie\n  Grande, Andrew Lang, Jitesh H. Panchal, Anthony Patrick, Scott Welch", "title": "Test and Evaluation Framework for Multi-Agent Systems of Autonomous\n  Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SE cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Test and evaluation is a necessary process for ensuring that engineered\nsystems perform as intended under a variety of conditions, both expected and\nunexpected. In this work, we consider the unique challenges of developing a\nunifying test and evaluation framework for complex ensembles of cyber-physical\nsystems with embedded artificial intelligence. We propose a framework that\nincorporates test and evaluation throughout not only the development life\ncycle, but continues into operation as the system learns and adapts in a noisy,\nchanging, and contended environment. The framework accounts for the challenges\nof testing the integration of diverse systems at various hierarchical scales of\ncomposition while respecting that testing time and resources are limited. A\ngeneric use case is provided for illustrative purposes and research directions\nemerging as a result of exploring the use case via the framework are suggested.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 21:42:27 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Lanus", "Erin", ""], ["Hernandez", "Ivan", ""], ["Dachowicz", "Adam", ""], ["Freeman", "Laura", ""], ["Grande", "Melanie", ""], ["Lang", "Andrew", ""], ["Panchal", "Jitesh H.", ""], ["Patrick", "Anthony", ""], ["Welch", "Scott", ""]]}, {"id": "2101.10435", "submitter": "Maria Leonor Pacheco", "authors": "Manuel Widmoser, Maria Leonor Pacheco, Jean Honorio, Dan Goldwasser", "title": "Randomized Deep Structured Prediction for Discourse-Level Processing", "comments": "Accepted to EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressive text encoders such as RNNs and Transformer Networks have been at\nthe center of NLP models in recent work. Most of the effort has focused on\nsentence-level tasks, capturing the dependencies between words in a single\nsentence, or pairs of sentences. However, certain tasks, such as argumentation\nmining, require accounting for longer texts and complicated structural\ndependencies between them. Deep structured prediction is a general framework to\ncombine the complementary strengths of expressive neural encoders and\nstructured inference for highly structured domains. Nevertheless, when the need\narises to go beyond sentences, most work relies on combining the output scores\nof independently trained classifiers. One of the main reasons for this is that\nconstrained inference comes at a high computational cost. In this paper, we\nexplore the use of randomized inference to alleviate this concern and show that\nwe can efficiently leverage deep structured prediction and expressive neural\nencoders for a set of tasks involving complicated argumentative structures.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 21:49:32 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Widmoser", "Manuel", ""], ["Pacheco", "Maria Leonor", ""], ["Honorio", "Jean", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2101.10460", "submitter": "Brian Quanz", "authors": "Nam Nguyen, Brian Quanz", "title": "Temporal Latent Auto-Encoder: A Method for Probabilistic Multivariate\n  Time Series Forecasting", "comments": "Accepted at AAAI 2021 (main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic forecasting of high dimensional multivariate time series is a\nnotoriously challenging task, both in terms of computational burden and\ndistribution modeling. Most previous work either makes simple distribution\nassumptions or abandons modeling cross-series correlations. A promising line of\nwork exploits scalable matrix factorization for latent-space forecasting, but\nis limited to linear embeddings, unable to model distributions, and not\ntrainable end-to-end when using deep learning forecasting. We introduce a novel\ntemporal latent auto-encoder method which enables nonlinear factorization of\nmultivariate time series, learned end-to-end with a temporal deep learning\nlatent space forecast model. By imposing a probabilistic latent space model,\ncomplex distributions of the input series are modeled via the decoder.\nExtensive experiments demonstrate that our model achieves state-of-the-art\nperformance on many popular multivariate datasets, with gains sometimes as high\nas $50\\%$ for several standard metrics.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:29:40 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Nguyen", "Nam", ""], ["Quanz", "Brian", ""]]}, {"id": "2101.10461", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou, Norman Fenton, Martin Neil", "title": "How do some Bayesian Network machine learned graphs compare to causal\n  knowledge?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph of a Bayesian Network (BN) can be machine learned, determined by\ncausal knowledge, or a combination of both. In disciplines like bioinformatics,\napplying BN structure learning algorithms can reveal new insights that would\notherwise remain unknown. However, these algorithms are less effective when the\ninput data are limited in terms of sample size, which is often the case when\nworking with real data. This paper focuses on purely machine learned and purely\nknowledge-based BNs and investigates their differences in terms of graphical\nstructure and how well the implied statistical models explain the data. The\ntests are based on four previous case studies whose BN structure was determined\nby domain knowledge. Using various metrics, we compare the knowledge-based\ngraphs to the machine learned graphs generated from various algorithms\nimplemented in TETRAD spanning all three classes of learning. The results show\nthat, while the algorithms produce graphs with much higher model selection\nscore, the knowledge-based graphs are more accurate predictors of variables of\ninterest. Maximising score fitting is ineffective in the presence of limited\nsample size because the fitting becomes increasingly distorted with limited\ndata, guiding algorithms towards graphical patterns that share higher fitting\nscores and yet deviate considerably from the true graph. This highlights the\nvalue of causal knowledge in these cases, as well as the need for more\nappropriate fitting scores suitable for limited data. Lastly, the experiments\nalso provide new evidence that support the notion that results from simulated\ndata tell us little about actual real-world performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:29:54 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 15:10:57 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Constantinou", "Anthony C.", ""], ["Fenton", "Norman", ""], ["Neil", "Martin", ""]]}, {"id": "2101.10463", "submitter": "An Zou", "authors": "An Zou, Jing Li, Christopher D. Gill, and Xuan Zhang", "title": "RTGPU: Real-Time GPU Scheduling of Hard Deadline Parallel Tasks with\n  Fine-Grain Utilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.AR cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many emerging cyber-physical systems, such as autonomous vehicles and robots,\nrely heavily on artificial intelligence and machine learning algorithms to\nperform important system operations. Since these highly parallel applications\nare computationally intensive, they need to be accelerated by graphics\nprocessing units (GPUs) to meet stringent timing constraints. However, despite\nthe wide adoption of GPUs, efficiently scheduling multiple GPU applications\nwhile providing rigorous real-time guarantees remains a challenge. In this\npaper, we propose RTGPU, which can schedule the execution of multiple GPU\napplications in real-time to meet hard deadlines. Each GPU application can have\nmultiple CPU execution and memory copy segments, as well as GPU kernels. We\nstart with a model to explicitly account for the CPU and memory copy segments\nof these applications. We then consider the GPU architecture in the development\nof a precise timing model for the GPU kernels and leverage a technique known as\npersistent threads to implement fine-grained kernel scheduling with improved\nperformance through interleaved execution. Next, we propose a general method\nfor scheduling parallel GPU applications in real time. Finally, to schedule\nmultiple parallel GPU applications, we propose a practical real-time scheduling\nalgorithm based on federated scheduling and grid search (for GPU kernel\nsegments) with uniprocessor fixed priority scheduling (for multiple CPU and\nmemory copy segments). Our approach provides superior schedulability compared\nwith previous work, and gives real-time guarantees to meet hard deadlines for\nmultiple GPU applications according to comprehensive validation and evaluation\non a real NVIDIA GTX1080Ti GPU system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:34:06 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 02:22:33 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Zou", "An", ""], ["Li", "Jing", ""], ["Gill", "Christopher D.", ""], ["Zhang", "Xuan", ""]]}, {"id": "2101.10472", "submitter": "Abdelkareem Jaradat", "authors": "Abdelkareem Jaradat, Hanan Lutfiyya, Anwar Haque", "title": "Appliance Operation Modes Identification Using Cycles Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing cost, energy demand, and environmental issues has led many\nresearchers to find approaches for energy monitoring, and hence energy\nconservation. The emerging technologies of Internet of Things (IoT) and Machine\nLearning (ML) deliver techniques that have the potential to efficiently\nconserve energy and improve the utilization of energy consumption. Smart Home\nEnergy Management Systems (SHEMSs) have the potential to contribute in energy\nconservation through the application of Demand Response (DR) in the residential\nsector. In this paper, we propose appliances Operation Modes Identification\nusing Cycles Clustering (OMICC) which is SHEMS fundamental approach that\nutilizes the sensed residential disaggregated power consumption in supporting\nDR by providing consumers the opportunity to select lighter appliance operation\nmodes. The cycles of the Single Usage Profile (SUP) of an appliance are\nextracted and reformed into features in terms of clusters of cycles. These\nfeatures are then used to identify the operation mode used in every occurrence\nusing K-Nearest Neighbors (KNN). Operation modes identification is considered a\nbasis for many potential smart DR applications within SHEMS towards the\nconsumers or the suppliers\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 23:25:45 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Jaradat", "Abdelkareem", ""], ["Lutfiyya", "Hanan", ""], ["Haque", "Anwar", ""]]}, {"id": "2101.10480", "submitter": "EPTCS", "authors": "Spencer Breiner (National Institute of Standards and Technology), John\n  S. Nolan (University of Maryland)", "title": "Symmetric Monoidal Categories with Attributes", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 33-48", "doi": "10.4204/EPTCS.333.3", "report-no": null, "categories": "math.CT cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing plans in engineering, it is often necessary to consider\nattributes associated to objects, e.g. the location of a robot. Our aim in this\npaper is to incorporate attributes into existing categorical formalisms for\nplanning, namely those based on symmetric monoidal categories and string\ndiagrams. To accomplish this, we define a notion of a \"symmetric monoidal\ncategory with attributes.\" This is a symmetric monoidal category in which\nobjects are equipped with retrievable information and where the interactions\nbetween objects and information are governed by an \"attribute structure.\" We\ndiscuss examples and semantics of such categories in the context of robotics to\nillustrate our definition.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:01:45 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Breiner", "Spencer", "", "National Institute of Standards and Technology"], ["Nolan", "John S.", "", "University of Maryland"]]}, {"id": "2101.10504", "submitter": "Ming Zhao", "authors": "Ming Zhao, Peter Anderson, Vihan Jain, Su Wang, Alexander Ku, Jason\n  Baldridge, Eugene Ie", "title": "On the Evaluation of Vision-and-Language Navigation Instructions", "comments": "Accepted to EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vision-and-Language Navigation wayfinding agents can be enhanced by\nexploiting automatically generated navigation instructions. However, existing\ninstruction generators have not been comprehensively evaluated, and the\nautomatic evaluation metrics used to develop them have not been validated.\nUsing human wayfinders, we show that these generators perform on par with or\nonly slightly better than a template-based generator and far worse than human\ninstructors. Furthermore, we discover that BLEU, ROUGE, METEOR and CIDEr are\nineffective for evaluating grounded navigation instructions. To improve\ninstruction evaluation, we propose an instruction-trajectory compatibility\nmodel that operates without reference instructions. Our model shows the highest\ncorrelation with human wayfinding outcomes when scoring individual\ninstructions. For ranking instruction generation systems, if reference\ninstructions are available we recommend using SPICE.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 01:03:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zhao", "Ming", ""], ["Anderson", "Peter", ""], ["Jain", "Vihan", ""], ["Wang", "Su", ""], ["Ku", "Alexander", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""]]}, {"id": "2101.10524", "submitter": "Abhinav Arora", "authors": "Arash Einolghozati, Abhinav Arora, Lorena Sainz-Maza Lecanda, Anuj\n  Kumar, Sonal Gupta", "title": "El Volumen Louder Por Favor: Code-switching in Task-oriented Semantic\n  Parsing", "comments": null, "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being able to parse code-switched (CS) utterances, such as Spanish+English or\nHindi+English, is essential to democratize task-oriented semantic parsing\nsystems for certain locales. In this work, we focus on Spanglish\n(Spanish+English) and release a dataset, CSTOP, containing 5800 CS utterances\nalongside their semantic parses. We examine the CS generalizability of various\nCross-lingual (XL) models and exhibit the advantage of pre-trained XL language\nmodels when data for only one language is present. As such, we focus on\nimproving the pre-trained models for the case when only English corpus\nalongside either zero or a few CS training instances are available. We propose\ntwo data augmentation methods for the zero-shot and the few-shot settings:\nfine-tune using translate-and-align and augment using a generation model\nfollowed by match-and-filter. Combining the few-shot setting with the above\nimprovements decreases the initial 30-point accuracy gap between the zero-shot\nand the full-data settings by two thirds.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 02:40:44 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 04:28:49 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 08:09:08 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Einolghozati", "Arash", ""], ["Arora", "Abhinav", ""], ["Lecanda", "Lorena Sainz-Maza", ""], ["Kumar", "Anuj", ""], ["Gupta", "Sonal", ""]]}, {"id": "2101.10535", "submitter": "Weixin Zeng", "authors": "Weixin Zeng, Xiang Zhao, Jiuyang Tang, Xinyi Li, Minnan Luo, Qinghua\n  Zheng", "title": "Towards Entity Alignment in the Open World: An Unsupervised Approach", "comments": "Accepted by DASFAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) aims to discover the equivalent entities in different\nknowledge graphs (KGs). It is a pivotal step for integrating KGs to increase\nknowledge coverage and quality. Recent years have witnessed a rapid increase of\nEA frameworks. However, state-of-the-art solutions tend to rely on labeled data\nfor model training. Additionally, they work under the closed-domain setting and\ncannot deal with entities that are unmatchable. To address these deficiencies,\nwe offer an unsupervised framework that performs entity alignment in the open\nworld. Specifically, we first mine useful features from the side information of\nKGs. Then, we devise an unmatchable entity prediction module to filter out\nunmatchable entities and produce preliminary alignment results. These\npreliminary results are regarded as the pseudo-labeled data and forwarded to\nthe progressive learning framework to generate structural representations,\nwhich are integrated with the side information to provide a more comprehensive\nview for alignment. Finally, the progressive learning framework gradually\nimproves the quality of structural embeddings and enhances the alignment\nperformance by enriching the pseudo-labeled data with alignment results from\nthe previous round. Our solution does not require labeled data and can\neffectively filter out unmatchable entities. Comprehensive experimental\nevaluations validate its superiority.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 03:10:24 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zeng", "Weixin", ""], ["Zhao", "Xiang", ""], ["Tang", "Jiuyang", ""], ["Li", "Xinyi", ""], ["Luo", "Minnan", ""], ["Zheng", "Qinghua", ""]]}, {"id": "2101.10545", "submitter": "Sayan Sinha", "authors": "Ritam Dutt and Sayan Sinha, Rishabh Joshi, Surya Shekhar Chakraborty,\n  Meredith Riggs, Xinru Yan, Haogang Bao, Carolyn Penstein Ros\\'e", "title": "RESPER: Computationally Modelling Resisting Strategies in Persuasive\n  Conversations", "comments": "Accepted as a long paper at the 16th Conference of the European\n  Chapter of the Association for Computational Linguistics (EACL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling persuasion strategies as predictors of task outcome has several\nreal-world applications and has received considerable attention from the\ncomputational linguistics community. However, previous research has failed to\naccount for the resisting strategies employed by an individual to foil such\npersuasion attempts. Grounded in prior literature in cognitive and social\npsychology, we propose a generalised framework for identifying resisting\nstrategies in persuasive conversations. We instantiate our framework on two\ndistinct datasets comprising persuasion and negotiation conversations. We also\nleverage a hierarchical sequence-labelling neural architecture to infer the\naforementioned resisting strategies automatically. Our experiments reveal the\nasymmetry of power roles in non-collaborative goal-directed conversations and\nthe benefits accrued from incorporating resisting strategies on the final\nconversation outcome. We also investigate the role of different resisting\nstrategies on the conversation outcome and glean insights that corroborate with\npast findings. We also make the code and the dataset of this work publicly\navailable at https://github.com/americast/resper.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 03:44:17 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Dutt", "Ritam", ""], ["Sinha", "Sayan", ""], ["Joshi", "Rishabh", ""], ["Chakraborty", "Surya Shekhar", ""], ["Riggs", "Meredith", ""], ["Yan", "Xinru", ""], ["Bao", "Haogang", ""], ["Ros\u00e9", "Carolyn Penstein", ""]]}, {"id": "2101.10586", "submitter": "Haekyu Park", "authors": "Haekyu Park, Zijie J. Wang, Nilaksh Das, Anindya S. Paul, Pruthvi\n  Perumalla, Zhiyan Zhou, Duen Horng Chau", "title": "SkeletonVis: Interactive Visualization for Understanding Adversarial\n  Attacks on Human Action Recognition Models", "comments": "Accepted at AAAI'21 Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skeleton-based human action recognition technologies are increasingly used in\nvideo based applications, such as home robotics, healthcare on aging\npopulation, and surveillance. However, such models are vulnerable to\nadversarial attacks, raising serious concerns for their use in safety-critical\napplications. To develop an effective defense against attacks, it is essential\nto understand how such attacks mislead the pose detection models into making\nincorrect predictions. We present SkeletonVis, the first interactive system\nthat visualizes how the attacks work on the models to enhance human\nunderstanding of attacks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 06:40:32 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Park", "Haekyu", ""], ["Wang", "Zijie J.", ""], ["Das", "Nilaksh", ""], ["Paul", "Anindya S.", ""], ["Perumalla", "Pruthvi", ""], ["Zhou", "Zhiyan", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2101.10642", "submitter": "Hyunjin Choi", "authors": "Hyunjin Choi, Judong Kim, Seongho Joe, and Youngjune Gwon", "title": "Evaluation of BERT and ALBERT Sentence Embedding Performance on\n  Downstream NLP Tasks", "comments": "6 pages, 2 figures, to be published in 25th International Conference\n  on Pattern Recognition, ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contextualized representations from a pre-trained language model are central\nto achieve a high performance on downstream NLP task. The pre-trained BERT and\nA Lite BERT (ALBERT) models can be fine-tuned to give state-ofthe-art results\nin sentence-pair regressions such as semantic textual similarity (STS) and\nnatural language inference (NLI). Although BERT-based models yield the [CLS]\ntoken vector as a reasonable sentence embedding, the search for an optimal\nsentence embedding scheme remains an active research area in computational\nlinguistics. This paper explores on sentence embedding models for BERT and\nALBERT. In particular, we take a modified BERT network with siamese and triplet\nnetwork structures called Sentence-BERT (SBERT) and replace BERT with ALBERT to\ncreate Sentence-ALBERT (SALBERT). We also experiment with an outer CNN\nsentence-embedding network for SBERT and SALBERT. We evaluate performances of\nall sentence-embedding models considered using the STS and NLI datasets. The\nempirical results indicate that our CNN architecture improves ALBERT models\nsubstantially more than BERT models for STS benchmark. Despite significantly\nfewer model parameters, ALBERT sentence embedding is highly competitive to BERT\nin downstream NLP evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 09:14:06 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Choi", "Hyunjin", ""], ["Kim", "Judong", ""], ["Joe", "Seongho", ""], ["Gwon", "Youngjune", ""]]}, {"id": "2101.10643", "submitter": "Jie Zhu", "authors": "Jie Zhu, Blanca Gallego", "title": "Casual Inference using Deep Bayesian Dynamic Survival Model (CDS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal inference in longitudinal observational health data often requires the\naccurate estimation of treatment effects on time-to-event outcomes in the\npresence of time-varying covariates. To tackle this sequential treatment effect\nestimation problem, we have developed a causal dynamic survival (CDS) model\nthat uses the potential outcomes framework with the recurrent sub-networks with\nrandom seed ensembles to estimate the difference in survival curves of its\nconfidence interval. Using simulated survival datasets, the CDS model has shown\ngood causal effect estimation performance across scenarios of sample dimension,\nevent rate, confounding and overlapping. However, increasing the sample size is\nnot effective to alleviate the adverse impact from high level of confounding.\nIn two large clinical cohort studies, our model identified the expected\nconditional average treatment effect and detected individual effect\nheterogeneity over time and patient subgroups. CDS provides individualised\nabsolute treatment effect estimations to improve clinical decisions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 09:15:49 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 13:41:07 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 23:06:53 GMT"}, {"version": "v4", "created": "Sun, 28 Feb 2021 12:55:21 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 12:03:38 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 08:23:41 GMT"}, {"version": "v7", "created": "Tue, 13 Jul 2021 09:03:46 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhu", "Jie", ""], ["Gallego", "Blanca", ""]]}, {"id": "2101.10649", "submitter": "Hyunjin Choi", "authors": "Hyunjin Choi, Judong Kim, Seongho Joe, Seungjai Min, Youngjune Gwon", "title": "Analyzing Zero-shot Cross-lingual Transfer in Supervised NLP Tasks", "comments": "6 pages, 4 figures, to be published in 25th International Conference\n  on Pattern Recognition, ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In zero-shot cross-lingual transfer, a supervised NLP task trained on a\ncorpus in one language is directly applicable to another language without any\nadditional training. A source of cross-lingual transfer can be as\nstraightforward as lexical overlap between languages (e.g., use of the same\nscripts, shared subwords) that naturally forces text embeddings to occupy a\nsimilar representation space. Recently introduced cross-lingual language model\n(XLM) pretraining brings out neural parameter sharing in Transformer-style\nnetworks as the most important factor for the transfer. In this paper, we aim\nto validate the hypothetically strong cross-lingual transfer properties induced\nby XLM pretraining. Particularly, we take XLM-RoBERTa (XLMR) in our experiments\nthat extend semantic textual similarity (STS), SQuAD and KorQuAD for machine\nreading comprehension, sentiment analysis, and alignment of sentence embeddings\nunder various cross-lingual settings. Our results indicate that the presence of\ncross-lingual transfer is most pronounced in STS, sentiment analysis the next,\nand MRC the last. That is, the complexity of a downstream task softens the\ndegree of crosslingual transfer. All of our results are empirically observed\nand measured, and we make our code and data publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 09:21:25 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Choi", "Hyunjin", ""], ["Kim", "Judong", ""], ["Joe", "Seongho", ""], ["Min", "Seungjai", ""], ["Gwon", "Youngjune", ""]]}, {"id": "2101.10657", "submitter": "Alessandro Sebastianelli", "authors": "Daniela A. Zaidenberg, Alessandro Sebastianelli, Dario Spiller,\n  Bertrand Le Saux and Silvia Liberata Ullo", "title": "Advantages and Bottlenecks of Quantum Machine Learning for Remote\n  Sensing", "comments": "Submitted and accepted for IEEE IGARSS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This concept paper aims to provide a brief outline of quantum computers,\nexplore existing methods of quantum image classification techniques, so\nfocusing on remote sensing applications, and discuss the bottlenecks of\nperforming these algorithms on currently available open source platforms.\nInitial results demonstrate feasibility. Next steps include expanding the size\nof the quantum hidden layer and increasing the variety of output image options.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 09:31:46 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 09:31:29 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 07:15:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zaidenberg", "Daniela A.", ""], ["Sebastianelli", "Alessandro", ""], ["Spiller", "Dario", ""], ["Saux", "Bertrand Le", ""], ["Ullo", "Silvia Liberata", ""]]}, {"id": "2101.10670", "submitter": "Tobias Joppen", "authors": "Tobias Joppen and Johannes F\\\"urnkranz", "title": "Ordinal Monte Carlo Tree Search", "comments": "preprint. arXiv admin note: substantial text overlap with\n  arXiv:1901.04274", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many problem settings, most notably in game playing, an agent receives a\npossibly delayed reward for its actions. Often, those rewards are handcrafted\nand not naturally given. Even simple terminal-only rewards, like winning equals\none and losing equals minus one, can not be seen as an unbiased statement,\nsince these values are chosen arbitrarily, and the behavior of the learner may\nchange with different encodings. It is hard to argue about good rewards and the\nperformance of an agent often depends on the design of the reward signal. In\nparticular, in domains where states by nature only have an ordinal ranking and\nwhere meaningful distance information between game state values is not\navailable, a numerical reward signal is necessarily biased. In this paper we\ntake a look at MCTS, a popular algorithm to solve MDPs, highlight a reoccurring\nproblem concerning its use of rewards, and show that an ordinal treatment of\nthe rewards overcomes this problem. Using the General Video Game Playing\nframework we show dominance of our newly proposed ordinal MCTS algorithm over\nother MCTS variants, based on a novel bandit algorithm that we also introduce\nand test versus UCB.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 10:01:27 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Joppen", "Tobias", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "2101.10708", "submitter": "Zhuang Li", "authors": "Zhuang Li, Lizhen Qu, Shuo Huang, Gholamreza Haffari", "title": "Few-Shot Semantic Parsing for New Predicates", "comments": "Accepted to EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we investigate the problems of semantic parsing in a few-shot\nlearning setting. In this setting, we are provided with utterance-logical form\npairs per new predicate. The state-of-the-art neural semantic parsers achieve\nless than 25% accuracy on benchmark datasets when k= 1. To tackle this problem,\nwe proposed to i) apply a designated meta-learning method to train the model;\nii) regularize attention scores with alignment statistics; iii) apply a\nsmoothing technique in pre-training. As a result, our method consistently\noutperforms all the baselines in both one and two-shot settings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 11:08:08 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Zhuang", ""], ["Qu", "Lizhen", ""], ["Huang", "Shuo", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2101.10710", "submitter": "Mohammad Naser Sabet Jahromi", "authors": "Satya M. Muddamsetty, Mohammad N. S. Jahromi, Andreea E. Ciontos,\n  Laura M. Fenoy, Thomas B. Moeslund", "title": "Introducing and assessing the explainable AI (XAI)method: SIDU", "comments": "Preprint-submitted to Journal of Pattern Recognition (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) has in recent years become a\nwell-suited framework to generate human understandable explanations of black\nbox models. In this paper, we present a novel XAI visual explanation algorithm\ndenoted SIDU that can effectively localize entire object regions responsible\nfor prediction in a full extend. We analyze its robustness and effectiveness\nthrough various computational and human subject experiments. In particular, we\nassess the SIDU algorithm using three different types of evaluations\n(Application, Human and Functionally-Grounded) to demonstrate its superior\nperformance. The robustness of SIDU is further studied in presence of\nadversarial attack on black box models to better understand its performance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 11:13:50 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Muddamsetty", "Satya M.", ""], ["Jahromi", "Mohammad N. S.", ""], ["Ciontos", "Andreea E.", ""], ["Fenoy", "Laura M.", ""], ["Moeslund", "Thomas B.", ""]]}, {"id": "2101.10739", "submitter": "Jie Zhu", "authors": "Jie Zhu, Blanca Gallego", "title": "Dynamic prediction of time to event with survival curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the ever-growing complexity of primary health care system, proactive\npatient failure management is an effective way to enhancing the availability of\nhealth care resource. One key enabler is the dynamic prediction of\ntime-to-event outcomes. Conventional explanatory statistical approach lacks the\ncapability of making precise individual level prediction, while the data\nadaptive binary predictors does not provide nominal survival curves for\nbiologically plausible survival analysis. The purpose of this article is to\nelucidate that the knowledge of explanatory survival analysis can significantly\nenhance the current black-box data adaptive prediction models. We apply our\nrecently developed counterfactual dynamic survival model (CDSM) to static and\nlongitudinal observational data and testify that the inflection point of its\nestimated individual survival curves provides reliable prediction of the\npatient failure time.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 12:17:27 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 04:32:31 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhu", "Jie", ""], ["Gallego", "Blanca", ""]]}, {"id": "2101.10759", "submitter": "Xutan Peng", "authors": "Xutan Peng, Yi Zheng, Chenghua Lin, Advaith Siddharthan", "title": "Summarising Historical Text in Modern Languages", "comments": "To appear at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of historical text summarisation, where documents in\nhistorical forms of a language are summarised in the corresponding modern\nlanguage. This is a fundamentally important routine to historians and digital\nhumanities researchers but has never been automated. We compile a high-quality\ngold-standard text summarisation dataset, which consists of historical German\nand Chinese news from hundreds of years ago summarised in modern German or\nChinese. Based on cross-lingual transfer learning techniques, we propose a\nsummarisation model that can be trained even with no cross-lingual (historical\nto modern) parallel data, and further benchmark it against state-of-the-art\nalgorithms. We report automatic and human evaluations that distinguish the\nhistoric to modern language summarisation task from standard cross-lingual\nsummarisation (i.e., modern to modern language), highlight the distinctness and\nvalue of our dataset, and demonstrate that our transfer learning approach\noutperforms standard cross-lingual benchmarks on this task.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 13:00:07 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 04:17:02 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Peng", "Xutan", ""], ["Zheng", "Yi", ""], ["Lin", "Chenghua", ""], ["Siddharthan", "Advaith", ""]]}, {"id": "2101.10760", "submitter": "Xiangyu Xu", "authors": "Xiangyu Xu, Muchen Li, Wenxiu Sun, Ming-Hsuan Yang", "title": "Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and\n  Video Denoising", "comments": "Project page: https://sites.google.com/view/xiangyuxu/denoise_stpan.\n  arXiv admin note: substantial text overlap with arXiv:1904.06903", "journal-ref": "IEEE Transactions on Image Processing 29 (2020): 7153-7165", "doi": "10.1109/TIP.2020.2999209", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing denoising methods typically restore clear results by aggregating\npixels from the noisy input. Instead of relying on hand-crafted aggregation\nschemes, we propose to explicitly learn this process with deep neural networks.\nWe present a spatial pixel aggregation network and learn the pixel sampling and\naveraging strategies for image denoising. The proposed model naturally adapts\nto image structures and can effectively improve the denoised results.\nFurthermore, we develop a spatio-temporal pixel aggregation network for video\ndenoising to efficiently sample pixels across the spatio-temporal space. Our\nmethod is able to solve the misalignment issues caused by large motion in\ndynamic scenes. In addition, we introduce a new regularization term for\neffectively training the proposed video denoising model. We present extensive\nanalysis of the proposed method and demonstrate that our model performs\nfavorably against the state-of-the-art image and video denoising approaches on\nboth synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 13:00:46 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Xu", "Xiangyu", ""], ["Li", "Muchen", ""], ["Sun", "Wenxiu", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2101.10785", "submitter": "Michael Gresser", "authors": "Marc Franzen, Michael Stephan Gresser, Tobias M\\\"uller, Prof. Dr.\n  Sebastian Mauser", "title": "Developing emotion recognition for video conference software to support\n  people with autism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an emotion recognition software for the use with a video\nconference software for autistic individuals which are unable to recognize\nemotions properly. It can get an image out of the video stream, detect the\nemotion in it with the help of a neural network and display the prediction to\nthe user. The network is trained on facial landmark features. The software is\nfully modular to support adaption to different video conference software,\nprogramming languages and implementations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 13:54:36 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Franzen", "Marc", ""], ["Gresser", "Michael Stephan", ""], ["M\u00fcller", "Tobias", ""], ["Mauser", "Prof. Dr. Sebastian", ""]]}, {"id": "2101.10790", "submitter": "Simon Meyer Lauritsen", "authors": "Simon Meyer Lauritsen, Bo Thiesson, Marianne Johansson J{\\o}rgensen,\n  Anders Hammerich Riis, Ulrick Skipper Espelund, Jesper Bo Weile and Jeppe\n  Lange", "title": "The Consequences of the Framing of Machine Learning Risk Prediction\n  Models: Evaluation of Sepsis in General Wards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Objectives: To evaluate the consequences of the framing of machine learning\nrisk prediction models. We evaluate how framing affects model performance and\nmodel learning in four different approaches previously applied in published\nartificial-intelligence (AI) models.\n  Setting and participants: We analysed structured secondary healthcare data\nfrom 221,283 citizens from four Danish municipalities who were 18 years of age\nor older.\n  Results: The four models had similar population level performance (a mean\narea under the receiver operating characteristic curve of 0.73 to 0.82), in\ncontrast to the mean average precision, which varied greatly from 0.007 to\n0.385. Correspondingly, the percentage of missing values also varied between\nframing approaches. The on-clinical-demand framing, which involved samples for\neach time the clinicians made an early warning score assessment, showed the\nlowest percentage of missing values among the vital sign parameters, and this\nmodel was also able to learn more temporal dependencies than the others. The\nShapley additive explanations demonstrated opposing interpretations of SpO2 in\nthe prediction of sepsis as a consequence of differentially framed models.\n  Conclusions: The profound consequences of framing mandate attention from\nclinicians and AI developers, as the understanding and reporting of framing are\npivotal to the successful development and clinical implementation of future AI\ntechnology. Model framing must reflect the expected clinical environment. The\nimportance of proper problem framing is by no means exclusive to sepsis\nprediction and applies to most clinical risk prediction models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 14:00:05 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Lauritsen", "Simon Meyer", ""], ["Thiesson", "Bo", ""], ["J\u00f8rgensen", "Marianne Johansson", ""], ["Riis", "Anders Hammerich", ""], ["Espelund", "Ulrick Skipper", ""], ["Weile", "Jesper Bo", ""], ["Lange", "Jeppe", ""]]}, {"id": "2101.10813", "submitter": "Elizabeth J Carter", "authors": "Stephanie Rosenthal and Elizabeth J. Carter", "title": "Impact of Explanation on Trust of a Novel Mobile Robot", "comments": "9 pages, 3 figures", "journal-ref": "Proceedings of the AAAI Fall Symposium Series - Artificial\n  Intelligence for Human-Robot Interaction: Trust Explainability in Artificial\n  Intelligence for Human-Robot Interaction AI-HRI (AI-HRI '20), November 13-14,\n  2020, Washington DC, USA", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One challenge with introducing robots into novel environments is misalignment\nbetween supervisor expectations and reality, which can greatly affect a user's\ntrust and continued use of the robot. We performed an experiment to test\nwhether the presence of an explanation of expected robot behavior affected a\nsupervisor's trust in an autonomous robot. We measured trust both subjectively\nthrough surveys and objectively through a dual-task experiment design to\ncapture supervisors' neglect tolerance (i.e., their willingness to perform\ntheir own task while the robot is acting autonomously). Our objective results\nshow that explanations can help counteract the novelty effect of seeing a new\nrobot perform in an unknown environment. Participants who received an\nexplanation of the robot's behavior were more likely to focus on their own task\nat the risk of neglecting their robot supervision task during the first trials\nof the robot's behavior compared to those who did not receive an explanation.\nHowever, this effect diminished after seeing multiple trials, and participants\nwho received explanations were equally trusting of the robot's behavior as\nthose who did not receive explanations. Interestingly, participants were not\nable to identify their own changes in trust through their survey responses,\ndemonstrating that the dual-task design measured subtler changes in a\nsupervisor's trust.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 14:36:26 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Rosenthal", "Stephanie", ""], ["Carter", "Elizabeth J.", ""]]}, {"id": "2101.10831", "submitter": "Subhasish Goswami", "authors": "Mriganka Nath and Subhasish Goswami", "title": "Toxicity Detection in Drug Candidates using Simplified Molecular-Input\n  Line-Entry System", "comments": "4 Pages, 4 Figures, Published with International Journal of Computer\n  Applications (IJCA)", "journal-ref": "International Journal of Computer Applications 175(21):1-4,\n  September 2020", "doi": "10.5120/ijca2020920695", "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need for analysis of toxicity in new drug candidates and the requirement\nof doing it fast have asked the consideration of scientists towards the use of\nartificial intelligence tools to examine toxicity levels and to develop models\nto a degree where they can be used commercially to measure toxicity levels\nefficiently in upcoming drugs. Artificial Intelligence based models can be used\nto predict the toxic nature of a chemical using Quantitative Structure Activity\nRelationship techniques. Convolutional Neural Network models have demonstrated\ngreat outcomes in predicting the qualitative analysis of chemicals in order to\ndetermine the toxicity. This paper goes for the study of Simplified Molecular\nInput Line-Entry System (SMILES) as a parameter to develop Long short term\nmemory (LSTM) based models in order to examine the toxicity of a molecule and\nthe degree to which the need can be fulfilled for practical use alongside its\nfuture outlooks for the purpose of real world applications.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 07:02:21 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Nath", "Mriganka", ""], ["Goswami", "Subhasish", ""]]}, {"id": "2101.10841", "submitter": "Yong-Goo Shin", "authors": "Seung Park, Yoon-Jae Yeo, and Yong-Goo Shin", "title": "Generative Adversarial Network using Perturbed-Convolutions", "comments": "Submitted to IEEE transactions on Neural networks and learning\n  systems. arXiv admin note: text overlap with arXiv:1911.10979", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite growing insights into the GAN training, it still suffers from\ninstability during the training procedure. To alleviate this problem, this\npaper presents a novel convolutional layer, called perturbed-convolution\n(PConv), which focuses on achieving two goals simultaneously: penalize the\ndiscriminator for training GAN stably and prevent the overfitting problem in\nthe discriminator. PConv generates perturbed features by randomly disturbing an\ninput tensor before performing the convolution operation. This approach is\nsimple but surprisingly effective. First, to reliably classify real and\ngenerated samples using the disturbed input tensor, the intermediate layers in\nthe discriminator should learn features having a small local Lipschitz value.\nSecond, due to the perturbed features in PConv, the discriminator is difficult\nto memorize the real images; this makes the discriminator avoid the overfitting\nproblem. To show the generalization ability of the proposed method, we\nconducted extensive experiments with various loss functions and datasets\nincluding CIFAR-10, CelebA-HQ, LSUN, and tiny-ImageNet. Quantitative\nevaluations demonstrate that WCL significantly improves the performance of GAN\nand conditional GAN in terms of Frechet inception distance (FID). For instance,\nthe proposed method improves FID scores on the tiny-ImageNet dataset from 58.59\nto 50.42.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 22:05:13 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 11:32:20 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Park", "Seung", ""], ["Yeo", "Yoon-Jae", ""], ["Shin", "Yong-Goo", ""]]}, {"id": "2101.10845", "submitter": "Angelo Menezes", "authors": "Angelo G. Menezes", "title": "Analysis and evaluation of Deep Learning based Super-Resolution\n  algorithms to improve performance in Low-Resolution Face Recognition", "comments": "MSc Thesis under supervision of Carlos A. E. Montesco presented at\n  the Federal University of Sergipe, Brazil (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Surveillance scenarios are prone to several problems since they usually\ninvolve low-resolution footage, and there is no control of how far the subjects\nmay be from the camera in the first place. This situation is suitable for the\napplication of upsampling (super-resolution) algorithms since they may be able\nto recover the discriminant properties of the subjects involved. While general\nsuper-resolution approaches were proposed to enhance image quality for\nhuman-level perception, biometrics super-resolution methods seek the best\n\"computer perception\" version of the image since their focus is on improving\nautomatic recognition performance. Convolutional neural networks and deep\nlearning algorithms, in general, have been applied to computer vision tasks and\nare now state-of-the-art for several sub-domains, including image\nclassification, restoration, and super-resolution. However, no work has\nevaluated the effects that the latest proposed super-resolution methods may\nhave upon the accuracy and face verification performance in low-resolution\n\"in-the-wild\" data. This project aimed at evaluating and adapting different\ndeep neural network architectures for the task of face super-resolution driven\nby face recognition performance in real-world low-resolution images. The\nexperimental results in a real-world surveillance and attendance datasets\nshowed that general super-resolution architectures might enhance face\nverification performance of deep neural networks trained on high-resolution\nfaces. Also, since neural networks are function approximators and can be\ntrained based on specific objective functions, the use of a customized loss\nfunction optimized for feature extraction showed promising results for\nrecovering discriminant features in low-resolution face images.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 02:41:57 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Menezes", "Angelo G.", ""]]}, {"id": "2101.10857", "submitter": "Vinayak Elangovan", "authors": "Vinayak Elangovan", "title": "Indoor Group Activity Recognition using Multi-Layered HMMs", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": "Proceedings of Academics World International Conference,\n  Philadelphia, USA, 28th - 29th December, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Discovery and recognition of Group Activities (GA) based on imagery data\nprocessing have significant applications in persistent surveillance systems,\nwhich play an important role in some Internet services. The process is involved\nwith analysis of sequential imagery data with spatiotemporal associations.\nDiscretion of video imagery requires a proper inference system capable of\ndiscriminating and differentiating cohesive observations and interlinking them\nto known ontologies. We propose an Ontology based GAR with a proper inference\nmodel that is capable of identifying and classifying a sequence of events in\ngroup activities. A multi-layered Hidden Markov Model (HMM) is proposed to\nrecognize different levels of abstract GA. The multi-layered HMM consists of N\nlayers of HMMs where each layer comprises of M number of HMMs running in\nparallel. The number of layers depends on the order of information to be\nextracted. At each layer, by matching and correlating attributes of detected\ngroup events, the model attempts to associate sensory observations to known\nontology perceptions. This paper demonstrates and compares performance of three\ndifferent implementation of HMM, namely, concatenated N-HMM, cascaded C-HMM and\nhybrid H-HMM for building effective multi-layered HMM.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 22:02:12 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Elangovan", "Vinayak", ""]]}, {"id": "2101.10865", "submitter": "Jonathan Spring", "authors": "Jonathan M. Spring and April Galyardt and Allen D. Householder and\n  Nathan VanHoudnos", "title": "On managing vulnerabilities in AI/ML systems", "comments": "16 pages. New Security Paradigms Workshop", "journal-ref": null, "doi": "10.1145/3442167.3442177", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores how the current paradigm of vulnerability management\nmight adapt to include machine learning systems through a thought experiment:\nwhat if flaws in machine learning (ML) were assigned Common Vulnerabilities and\nExposures (CVE) identifiers (CVE-IDs)? We consider both ML algorithms and model\nobjects. The hypothetical scenario is structured around exploring the changes\nto the six areas of vulnerability management: discovery, report intake,\nanalysis, coordination, disclosure, and response. While algorithm flaws are\nwell-known in the academic research community, there is no apparent clear line\nof communication between this research community and the operational\ncommunities that deploy and manage systems that use ML. The thought experiments\nidentify some ways in which CVE-IDs may establish some useful lines of\ncommunication between these two communities. In particular, it would start to\nintroduce the research community to operational security concepts, which\nappears to be a gap left by existing efforts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:59:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Spring", "Jonathan M.", ""], ["Galyardt", "April", ""], ["Householder", "Allen D.", ""], ["VanHoudnos", "Nathan", ""]]}, {"id": "2101.10870", "submitter": "Florenc Demrozi Dr.", "authors": "Florenc Demrozi, Cristian Turetta, Graziano Pravadelli", "title": "B-HAR: an open-source baseline framework for in depth study of human\n  activity recognition datasets and workflows", "comments": "9 Pages, 3 Figures, 3 Tables, Link to B-HAR Library:\n  https://github.com/B-HAR-HumanActivityRecognition/B-HAR", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Activity Recognition (HAR), based on machine and deep learning\nalgorithms is considered one of the most promising technologies to monitor\nprofessional and daily life activities for different categories of people\n(e.g., athletes, elderly, kids, employers) in order to provide a variety of\nservices related, for example to well-being, empowering of technical\nperformances, prevention of risky situation, and educational purposes. However,\nthe analysis of the effectiveness and the efficiency of HAR methodologies\nsuffers from the lack of a standard workflow, which might represent the\nbaseline for the estimation of the quality of the developed pattern recognition\nmodels. This makes the comparison among different approaches a challenging\ntask. In addition, researchers can make mistakes that, when not detected,\ndefinitely affect the achieved results. To mitigate such issues, this paper\nproposes an open-source automatic and highly configurable framework, named\nB-HAR, for the definition, standardization, and development of a baseline\nframework in order to evaluate and compare HAR methodologies. It implements the\nmost popular data processing methods for data preparation and the most commonly\nused machine and deep learning pattern recognition models.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 12:42:41 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Demrozi", "Florenc", ""], ["Turetta", "Cristian", ""], ["Pravadelli", "Graziano", ""]]}, {"id": "2101.10892", "submitter": "Pedro Vicente", "authors": "Gon\\c{c}alo Cunha, Pedro Vicente, Alexandre Bernardino, Ricardo\n  Ribeiro, Pl\\'inio Moreno", "title": "Online Body Schema Adaptation through Cost-Sensitive Active Learning", "comments": "6 pages, 7 figures. Submitted to Humanoids 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanoid robots have complex bodies and kinematic chains with several\nDegrees-of-Freedom (DoF) which are difficult to model. Learning the parameters\nof a kinematic model can be achieved by observing the position of the robot\nlinks during prospective motions and minimising the prediction errors. This\nwork proposes a movement efficient approach for estimating online the\nbody-schema of a humanoid robot arm in the form of Denavit-Hartenberg (DH)\nparameters. A cost-sensitive active learning approach based on the A-Optimality\ncriterion is used to select optimal joint configurations. The chosen joint\nconfigurations simultaneously minimise the error in the estimation of the body\nschema and minimise the movement between samples. This reduces energy\nconsumption, along with mechanical fatigue and wear, while not compromising the\nlearning accuracy. The work was implemented in a simulation environment, using\nthe 7DoF arm of the iCub robot simulator. The hand pose is measured with a\nsingle camera via markers placed in the palm and back of the robot's hand. A\nnon-parametric occlusion model is proposed to avoid choosing joint\nconfigurations where the markers are not visible, thus preventing worthless\nattempts. The results show cost-sensitive active learning has similar accuracy\nto the standard active learning approach, while reducing in about half the\nexecuted movement.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 16:01:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Cunha", "Gon\u00e7alo", ""], ["Vicente", "Pedro", ""], ["Bernardino", "Alexandre", ""], ["Ribeiro", "Ricardo", ""], ["Moreno", "Pl\u00ednio", ""]]}, {"id": "2101.10899", "submitter": "Fares Fourati", "authors": "Fares Fourati, Mohamed-Slim Alouini", "title": "Artificial Intelligence for Satellite Communication: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Satellite communication offers the prospect of service continuity over\nuncovered and under-covered areas, service ubiquity, and service scalability.\nHowever, several challenges must first be addressed to realize these benefits,\nas the resource management, network control, network security, spectrum\nmanagement, and energy usage of satellite networks are more challenging than\nthat of terrestrial networks. Meanwhile, artificial intelligence (AI),\nincluding machine learning, deep learning, and reinforcement learning, has been\nsteadily growing as a research field and has shown successful results in\ndiverse applications, including wireless communication. In particular, the\napplication of AI to a wide variety of satellite communication aspects have\ndemonstrated excellent potential, including beam-hopping, anti-jamming, network\ntraffic forecasting, channel modeling, telemetry mining, ionospheric\nscintillation detecting, interference managing, remote sensing, behavior\nmodeling, space-air-ground integrating, and energy managing. This work thus\nprovides a general overview of AI, its diverse sub-fields, and its\nstate-of-the-art algorithms. Several challenges facing diverse aspects of\nsatellite communication systems are then discussed, and their proposed and\npotential AI-based solutions are presented. Finally, an outlook of field is\ndrawn, and future steps are suggested.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 13:01:16 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Fourati", "Fares", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2101.10904", "submitter": "Ranwa Al Mallah", "authors": "Ranwa Al Mallah, David Lopez, Bilal Farooq", "title": "Untargeted Poisoning Attack Detection in Federated Learning via Behavior\n  Attestation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a paradigm in Machine Learning (ML) that addresses\ndata privacy, security, access rights and access to heterogeneous information\nissues by training a global model using distributed nodes. Despite its\nadvantages, there is an increased potential for cyberattacks on FL-based ML\ntechniques that can undermine the benefits. Model-poisoning attacks on FL\ntarget the availability of the model. The adversarial objective is to disrupt\nthe training. We propose attestedFL, a defense mechanism that monitors the\ntraining of individual nodes through state persistence in order to detect a\nmalicious worker. A fine-grained assessment of the history of the worker\npermits the evaluation of its behavior in time and results in innovative\ndetection strategies. We present three lines of defense that aim at assessing\nif the worker is reliable by observing if the node is really training,\nadvancing towards a goal. Our defense exposes an attacker's malicious behavior\nand removes unreliable nodes from the aggregation process so that the FL\nprocess converge faster. Through extensive evaluations and against various\nadversarial settings, attestedFL increased the accuracy of the model between\n12% to 58% under different scenarios such as attacks performed at different\nstages of convergence, attackers colluding and continuous attacks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 20:52:55 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 14:50:24 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Mallah", "Ranwa Al", ""], ["Lopez", "David", ""], ["Farooq", "Bilal", ""]]}, {"id": "2101.10917", "submitter": "Christine De Kock", "authors": "Christine de Kock and Andreas Vlachos", "title": "I Beg to Differ: A study of constructive disagreement in online\n  conversations", "comments": "Accepted to appear in EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Disagreements are pervasive in human communication. In this paper we\ninvestigate what makes disagreement constructive. To this end, we construct\nWikiDisputes, a corpus of 7 425 Wikipedia Talk page conversations that contain\ncontent disputes, and define the task of predicting whether disagreements will\nbe escalated to mediation by a moderator. We evaluate feature-based models with\nlinguistic markers from previous work, and demonstrate that their performance\nis improved by using features that capture changes in linguistic markers\nthroughout the conversations, as opposed to averaged values. We develop a\nvariety of neural models and show that taking into account the structure of the\nconversation improves predictive accuracy, exceeding that of feature-based\nmodels. We assess our best neural model in terms of both predictive accuracy\nand uncertainty by evaluating its behaviour when it is only exposed to the\nbeginning of the conversation, finding that model accuracy improves and\nuncertainty reduces as models are exposed to more information.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 16:36:43 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["de Kock", "Christine", ""], ["Vlachos", "Andreas", ""]]}, {"id": "2101.10946", "submitter": "Yakup Kutlu", "authors": "Gokhan Altan, Yakup Kutlu, Yusuf Garbi, Adnan Ozhan Pekmezci, Serkan\n  Nural", "title": "Multimedia Respiratory Database (RespiratoryDatabase@TR): Auscultation\n  Sounds and Chest X-rays", "comments": "14 pages, 7 figures, Natural and Engineering Sciences", "journal-ref": "Natural and Engineering Sciences, 2017", "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Auscultation is a method for diagnosis of especially internal medicine\ndiseases such as cardiac, pulmonary and cardio-pulmonary by listening the\ninternal sounds from the body parts. It is the simplest and the most common\nphysical examination in the assessment processes of the clinical skills. In\nthis study, the lung and heart sounds are recorded synchronously from left and\nright sides of posterior and anterior chest wall and back using two digital\nstethoscopes in Antakya State Hospital. The chest X-rays and the pulmonary\nfunction test variables and spirometric curves, the St. George respiratory\nquestionnaire (SGRQ-C) are collected as multimedia and clinical functional\nanalysis variables of the patients. The 4 channels of heart sounds are focused\non aortic, pulmonary, tricuspid and mitral areas. The 12 channels of lung\nsounds are focused on upper lung, middle lung, lower lung and costophrenic\nangle areas of posterior and anterior sides of the chest. The recordings are\nvalidated and labelled by two pulmonologists evaluating the collected chest\nx-ray, PFT and auscultation sounds of the subjects. The database consists of 30\nhealthy subjects and 45 subjects with pulmonary diseases such as asthma,\nchronic obstructive pulmonary disease, bronchitis. The novelties of the\ndatabase are the combination ability between auscultation sound results, chest\nX-ray and PFT; synchronously assessment capability of the lungs sounds; image\nprocessing based computerized analysis of the respiratory using chest X-ray and\nproviding opportunity for improving analysis of both lung sounds and heart\nsounds on pulmonary and cardiac diseases.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 08:08:11 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Altan", "Gokhan", ""], ["Kutlu", "Yakup", ""], ["Garbi", "Yusuf", ""], ["Pekmezci", "Adnan Ozhan", ""], ["Nural", "Serkan", ""]]}, {"id": "2101.10953", "submitter": "Wei Zhong Goh", "authors": "Wei Zhong Goh, Varun Ursekar, Marc W. Howard", "title": "Predicting the future with a scale-invariant temporal memory for the\n  past", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years it has become clear that the brain maintains a temporal\nmemory of recent events stretching far into the past. This paper presents a\nneurally-inspired algorithm to use a scale-invariant temporal representation of\nthe past to predict a scale-invariant future. The result is a scale-invariant\nestimate of future events as a function of the time at which they are expected\nto occur. The algorithm is time-local, with credit assigned to the present\nevent by observing how it affects the prediction of the future. To illustrate\nthe potential utility of this approach, we test the model on simultaneous\nrenewal processes with different time scales. The algorithm scales well on\nthese problems despite the fact that the number of states needed to describe\nthem as a Markov process grows exponentially.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 17:22:17 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Goh", "Wei Zhong", ""], ["Ursekar", "Varun", ""], ["Howard", "Marc W.", ""]]}, {"id": "2101.10964", "submitter": "Oren Neumann", "authors": "Oren Neumann, Claudius Gros", "title": "Investment vs. reward in a competitive knapsack problem", "comments": null, "journal-ref": "Learning Meets Combinatorial Algorithms at NeurIPS2020 (2020)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural selection drives species to develop brains, with sizes that increase\nwith the complexity of the tasks to be tackled. Our goal is to investigate the\nbalance between the metabolic costs of larger brains compared to the advantage\nthey provide in solving general and combinatorial problems. Defining advantage\nas the performance relative to competitors, a two-player game based on the\nknapsack problem is used. Within this framework, two opponents compete over\nshared resources, with the goal of collecting more resources than the opponent.\nNeural nets of varying sizes are trained using a variant of the AlphaGo Zero\nalgorithm. A surprisingly simple relation, $N_A/(N_A+N_B)$, is found for the\nrelative win rate of a net with $N_A$ neurons against one with $N_B$. Success\nincreases linearly with investments in additional resources when the networks\nsizes are very different, i.e. when $N_A \\ll N_B$, with returns diminishing\nwhen both networks become comparable in size.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 17:47:56 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Neumann", "Oren", ""], ["Gros", "Claudius", ""]]}, {"id": "2101.11023", "submitter": "Taro Sakurai", "authors": "Taro Sakurai (Chiba University)", "title": "On formal concepts of random formal contexts", "comments": "7 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In formal concept analysis, it is well-known that the number of formal\nconcepts can be exponential in the worst case. To analyze the average case, we\nintroduce a probabilistic model for random formal contexts and prove that the\naverage number of formal concepts has a superpolynomial asymptotic lower bound.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 19:00:06 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Sakurai", "Taro", "", "Chiba University"]]}, {"id": "2101.11059", "submitter": "Muthu Kumar Chandrasekaran", "authors": "Kailash Karthik Saravanakumar, Miguel Ballesteros, Muthu Kumar\n  Chandrasekaran, Kathleen McKeown", "title": "Event-Driven News Stream Clustering using Entity-Aware Contextual\n  Embeddings", "comments": "To appear in Proceedings of The 16th Conference of the European\n  Chapter of the Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for online news stream clustering that is a variant of\nthe non-parametric streaming K-means algorithm. Our model uses a combination of\nsparse and dense document representations, aggregates document-cluster\nsimilarity along these multiple representations and makes the clustering\ndecision using a neural classifier. The weighted document-cluster similarity\nmodel is learned using a novel adaptation of the triplet loss into a linear\nclassification objective. We show that the use of a suitable fine-tuning\nobjective and external knowledge in pre-trained transformer models yields\nsignificant improvements in the effectiveness of contextual embeddings for\nclustering. Our model achieves a new state-of-the-art on a standard stream\nclustering dataset of English documents.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 19:58:30 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Saravanakumar", "Kailash Karthik", ""], ["Ballesteros", "Miguel", ""], ["Chandrasekaran", "Muthu Kumar", ""], ["McKeown", "Kathleen", ""]]}, {"id": "2101.11066", "submitter": "Levon Aslanyan", "authors": "L. Aslanyan, V. Krasnoproshin, V. Ryazanov, H. Sahakyan", "title": "Logical-Combinatorial Approaches in Dynamic Recognition Problems", "comments": "research paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pattern recognition scenario, where instead of object classification into\nthe classes by the learning set, the algorithm aims to allocate all objects to\nthe same, the so-called normal class, is the research objective.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 20:22:59 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Aslanyan", "L.", ""], ["Krasnoproshin", "V.", ""], ["Ryazanov", "V.", ""], ["Sahakyan", "H.", ""]]}, {"id": "2101.11071", "submitter": "William Guss", "authors": "William H. Guss, Mario Ynocente Castro, Sam Devlin, Brandon Houghton,\n  Noboru Sean Kuno, Crissman Loomis, Stephanie Milani, Sharada Mohanty, Keisuke\n  Nakata, Ruslan Salakhutdinov, John Schulman, Shinya Shiroshita, Nicholay\n  Topin, Avinash Ummadisingu, Oriol Vinyals", "title": "The MineRL 2020 Competition on Sample Efficient Reinforcement Learning\n  using Human Priors", "comments": "37 pages, initial submission, accepted at NeurIPS. arXiv admin note:\n  substantial text overlap with arXiv:1904.10079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although deep reinforcement learning has led to breakthroughs in many\ndifficult domains, these successes have required an ever-increasing number of\nsamples, affording only a shrinking segment of the AI community access to their\ndevelopment. Resolution of these limitations requires new, sample-efficient\nmethods. To facilitate research in this direction, we propose this second\niteration of the MineRL Competition. The primary goal of the competition is to\nfoster the development of algorithms which can efficiently leverage human\ndemonstrations to drastically reduce the number of samples needed to solve\ncomplex, hierarchical, and sparse environments. To that end, participants\ncompete under a limited environment sample-complexity budget to develop systems\nwhich solve the MineRL ObtainDiamond task in Minecraft, a sequential decision\nmaking environment requiring long-term planning, hierarchical control, and\nefficient exploration methods. The competition is structured into two rounds in\nwhich competitors are provided several paired versions of the dataset and\nenvironment with different game textures and shaders. At the end of each round,\ncompetitors submit containerized versions of their learning algorithms to the\nAIcrowd platform where they are trained from scratch on a hold-out\ndataset-environment pair for a total of 4-days on a pre-specified hardware\nplatform. In this follow-up iteration to the NeurIPS 2019 MineRL Competition,\nwe implement new features to expand the scale and reach of the competition. In\nresponse to the feedback of the previous participants, we introduce a second\nminor track focusing on solutions without access to environment interactions of\nany kind except during test-time. Further we aim to prompt domain agnostic\nsubmissions by implementing several novel competition mechanics including\naction-space randomization and desemantization of observations and actions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 20:32:30 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Guss", "William H.", ""], ["Castro", "Mario Ynocente", ""], ["Devlin", "Sam", ""], ["Houghton", "Brandon", ""], ["Kuno", "Noboru Sean", ""], ["Loomis", "Crissman", ""], ["Milani", "Stephanie", ""], ["Mohanty", "Sharada", ""], ["Nakata", "Keisuke", ""], ["Salakhutdinov", "Ruslan", ""], ["Schulman", "John", ""], ["Shiroshita", "Shinya", ""], ["Topin", "Nicholay", ""], ["Ummadisingu", "Avinash", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2101.11075", "submitter": "Aaron Defazio", "authors": "Aaron Defazio and Samy Jelassi", "title": "Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged\n  Gradient Method for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce MADGRAD, a novel optimization method in the family of AdaGrad\nadaptive gradient methods. MADGRAD shows excellent performance on deep learning\noptimization problems from multiple fields, including classification and\nimage-to-image tasks in vision, and recurrent and bidirectionally-masked models\nin natural language processing. For each of these tasks, MADGRAD matches or\noutperforms both SGD and ADAM in test set performance, even on problems for\nwhich adaptive methods normally perform poorly.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 20:38:26 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 18:20:52 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Defazio", "Aaron", ""], ["Jelassi", "Samy", ""]]}, {"id": "2101.11110", "submitter": "Rohan Thakker", "authors": "Rohan Thakker, Nikhilesh Alatur, David D. Fan, Jesus Tordesillas,\n  Michael Paton, Kyohei Otsu, Olivier Toupet, Ali-akbar Agha-mohammadi", "title": "Autonomous Off-road Navigation over Extreme Terrains with\n  Perceptually-challenging Conditions", "comments": "12 Pages, 7 Figures, 2020 International Symposium on Experimental\n  Robotics (ISER 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for resilient autonomous navigation in perceptually\nchallenging unknown environments with mobility-stressing elements such as\nuneven surfaces with rocks and boulders, steep slopes, negative obstacles like\ncliffs and holes, and narrow passages. Environments are GPS-denied and\nperceptually-degraded with variable lighting from dark to lit and obscurants\n(dust, fog, smoke). Lack of prior maps and degraded communication eliminates\nthe possibility of prior or off-board computation or operator intervention.\nThis necessitates real-time on-board computation using noisy sensor data. To\naddress these challenges, we propose a resilient architecture that exploits\nredundancy and heterogeneity in sensing modalities. Further resilience is\nachieved by triggering recovery behaviors upon failure. We propose a fast\nsettling algorithm to generate robust multi-fidelity traversability estimates\nin real-time. The proposed approach was deployed on multiple physical systems\nincluding skid-steer and tracked robots, a high-speed RC car and legged robots,\nas a part of Team CoSTAR's effort to the DARPA Subterranean Challenge, where\nthe team won 2nd and 1st place in the Tunnel and Urban Circuits, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 22:13:01 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Thakker", "Rohan", ""], ["Alatur", "Nikhilesh", ""], ["Fan", "David D.", ""], ["Tordesillas", "Jesus", ""], ["Paton", "Michael", ""], ["Otsu", "Kyohei", ""], ["Toupet", "Olivier", ""], ["Agha-mohammadi", "Ali-akbar", ""]]}, {"id": "2101.11155", "submitter": "Shubhanshu Mishra", "authors": "Sudhanshu Mishra, Shivangi Prasad, Shubhanshu Mishra", "title": "Exploring multi-task multi-lingual learning of transformer models for\n  hate speech and offensive speech identification in social media", "comments": "\"To be published in SN Computer Science at\n  https://doi.org/10.1007/s42979-021-00455-5\" \"30 pages, 6 figures\" \"Code\n  available at https://github.com/socialmediaie/MTML_HateSpeech\"", "journal-ref": null, "doi": "10.1007/s42979-021-00455-5", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hate Speech has become a major content moderation issue for online social\nmedia platforms. Given the volume and velocity of online content production, it\nis impossible to manually moderate hate speech related content on any platform.\nIn this paper we utilize a multi-task and multi-lingual approach based on\nrecently proposed Transformer Neural Networks to solve three sub-tasks for hate\nspeech. These sub-tasks were part of the 2019 shared task on hate speech and\noffensive content (HASOC) identification in Indo-European languages. We expand\non our submission to that competition by utilizing multi-task models which are\ntrained using three approaches, a) multi-task learning with separate task\nheads, b) back-translation, and c) multi-lingual training. Finally, we\ninvestigate the performance of various models and identify instances where the\nTransformer based models perform differently and better. We show that it is\npossible to to utilize different combined approaches to obtain models that can\ngeneralize easily on different languages and tasks, while trading off slight\naccuracy (in some cases) for a much reduced inference time compute cost. We\nopen source an updated version of our HASOC 2019 code with the new improvements\nat https://github.com/socialmediaie/MTML_HateSpeech.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 01:25:22 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Mishra", "Sudhanshu", ""], ["Prasad", "Shivangi", ""], ["Mishra", "Shubhanshu", ""]]}, {"id": "2101.11174", "submitter": "Weiwei Jiang", "authors": "Weiwei Jiang, Jiayun Luo", "title": "Graph Neural Network for Traffic Forecasting: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traffic forecasting is important for the success of intelligent\ntransportation systems. Deep learning models, including convolution neural\nnetworks and recurrent neural networks, have been extensively applied in\ntraffic forecasting problems to model spatial and temporal dependencies. In\nrecent years, to model the graph structures in transportation systems as well\nas contextual information, graph neural networks have been introduced and have\nachieved state-of-the-art performance in a series of traffic forecasting\nproblems. In this survey, we review the rapidly growing body of research using\ndifferent graph neural networks, e.g. graph convolutional and graph attention\nnetworks, in various traffic forecasting problems, e.g. road traffic flow and\nspeed forecasting, passenger flow forecasting in urban rail transit systems,\nand demand forecasting in ride-hailing platforms. We also present a\ncomprehensive list of open data and source resources for each problem and\nidentify future research directions. To the best of our knowledge, this paper\nis the first comprehensive survey that explores the application of graph neural\nnetworks for traffic forecasting problems. We have also created a public GitHub\nrepository where the latest papers, open data, and source resources will be\nupdated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 02:35:41 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 14:19:27 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Jiang", "Weiwei", ""], ["Luo", "Jiayun", ""]]}, {"id": "2101.11177", "submitter": "Stefan Larson", "authors": "Jacob Solawetz, Stefan Larson", "title": "LSOIE: A Large-Scale Dataset for Supervised Open Information Extraction", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Information Extraction (OIE) systems seek to compress the factual\npropositions of a sentence into a series of n-ary tuples. These tuples are\nuseful for downstream tasks in natural language processing like knowledge base\ncreation, textual entailment, and natural language understanding. However,\ncurrent OIE datasets are limited in both size and diversity. We introduce a new\ndataset by converting the QA-SRL 2.0 dataset to a large-scale OIE dataset\n(LSOIE). Our LSOIE dataset is 20 times larger than the next largest\nhuman-annotated OIE dataset. We construct and evaluate several benchmark OIE\nmodels on LSOIE, providing baselines for future improvements on the task. Our\nLSOIE data, models, and code are made publicly available\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 02:49:26 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Solawetz", "Jacob", ""], ["Larson", "Stefan", ""]]}, {"id": "2101.11204", "submitter": "Jiaxin Bai", "authors": "Jiaxin Bai, Hongming Zhang, Yangqiu Song, and Kun Xu", "title": "Joint Coreference Resolution and Character Linking for Multiparty\n  Conversation", "comments": "EACL-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Character linking, the task of linking mentioned people in conversations to\nthe real world, is crucial for understanding the conversations. For the\nefficiency of communication, humans often choose to use pronouns (e.g., \"she\")\nor normal phrases (e.g., \"that girl\") rather than named entities (e.g.,\n\"Rachel\") in the spoken language, which makes linking those mentions to real\npeople a much more challenging than a regular entity linking task. To address\nthis challenge, we propose to incorporate the richer context from the\ncoreference relations among different mentions to help the linking. On the\nother hand, considering that finding coreference clusters itself is not a\ntrivial task and could benefit from the global character information, we\npropose to jointly solve these two tasks. Specifically, we propose C$^2$, the\njoint learning model of Coreference resolution and Character linking. The\nexperimental results demonstrate that C$^2$ can significantly outperform\nprevious works on both tasks. Further analyses are conducted to analyze the\ncontribution of all modules in the proposed model and the effect of all\nhyper-parameters.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 04:47:04 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 08:25:29 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Bai", "Jiaxin", ""], ["Zhang", "Hongming", ""], ["Song", "Yangqiu", ""], ["Xu", "Kun", ""]]}, {"id": "2101.11221", "submitter": "Kwanyoung Park", "authors": "Kwanyoung Park, Junseok Park, Hyunseok Oh, Byoung-Tak Zhang, Youngki\n  Lee", "title": "Learning task-agnostic representation via toddler-inspired learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the inherent limitations of current AI systems, stemming from the\npassive learning mechanisms (e.g., supervised learning), is that they perform\nwell on labeled datasets but cannot deduce knowledge on their own. To tackle\nthis problem, we derive inspiration from a highly intentional learning system\nvia action: the toddler. Inspired by the toddler's learning procedure, we\ndesign an interactive agent that can learn and store task-agnostic visual\nrepresentation while exploring and interacting with objects in the virtual\nenvironment. Experimental results show that such obtained representation was\nexpandable to various vision tasks such as image classification, object\nlocalization, and distance estimation tasks. In specific, the proposed model\nachieved 100%, 75.1% accuracy and 1.62% relative error, respectively, which is\nnoticeably better than autoencoder-based model (99.7%, 66.1%, 1.95%), and also\ncomparable with those of supervised models (100%, 87.3%, 0.71%).\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 06:26:56 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Park", "Kwanyoung", ""], ["Park", "Junseok", ""], ["Oh", "Hyunseok", ""], ["Zhang", "Byoung-Tak", ""], ["Lee", "Youngki", ""]]}, {"id": "2101.11253", "submitter": "Sanghyun Jo", "authors": "Sanghyun Jo, In-Jae Yu", "title": "Puzzle-CAM: Improved localization via matching partial and full features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weakly-supervised semantic segmentation (WSSS) is introduced to narrow the\ngap for semantic segmentation performance from pixel-level supervision to\nimage-level supervision. Most advanced approaches are based on class activation\nmaps (CAMs) to generate pseudo-labels to train the segmentation network. The\nmain limitation of WSSS is that the process of generating pseudo-labels from\nCAMs that use an image classifier is mainly focused on the most discriminative\nparts of the objects. To address this issue, we propose Puzzle-CAM, a process\nthat minimizes differences between the features from separate patches and the\nwhole image. Our method consists of a puzzle module and two regularization\nterms to discover the most integrated region in an object. Puzzle-CAM can\nactivate the overall region of an object using image-level supervision without\nrequiring extra parameters. % In experiments, Puzzle-CAM outperformed previous\nstate-of-the-art methods using the same labels for supervision on the PASCAL\nVOC 2012 test dataset. In experiments, Puzzle-CAM outperformed previous\nstate-of-the-art methods using the same labels for supervision on the PASCAL\nVOC 2012 dataset. Code associated with our experiments is available at\nhttps://github.com/OFRIN/PuzzleCAM.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 08:19:38 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 03:34:21 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 06:24:39 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Jo", "Sanghyun", ""], ["Yu", "In-Jae", ""]]}, {"id": "2101.11260", "submitter": "Carole Adam", "authors": "Natasa Vodopivec and Carole Adam and Jean-Pierre Chanteau", "title": "Modeling opinion leader's role in the diffusion of innovation", "comments": "Internship report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The diffusion of innovations is an important topic for the consumer markets.\nEarly research focused on how innovations spread on the level of the whole\nsociety. To get closer to the real world scenarios agent based models (ABM)\nstarted focusing on individual-level agents. In our work we will translate an\nexisting ABM that investigates the role of opinion leaders in the process of\ndiffusion of innovations to a new, more expressive platform designed for agent\nbased modeling, GAMA. We will do it to show that taking advantage of new\nfeatures of the chosen platform should be encouraged when making models in the\nfield of social sciences in the future, because it can be beneficial for the\nexplanatory power of simulation results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 08:37:32 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Vodopivec", "Natasa", ""], ["Adam", "Carole", ""], ["Chanteau", "Jean-Pierre", ""]]}, {"id": "2101.11266", "submitter": "Tomasz Szandala", "authors": "Tomasz Szandala", "title": "TorchPRISM: Principal Image Sections Mapping, a novel method for\n  Convolutional Neural Network features visualization", "comments": "Very early draft, software can be found:\n  https://github.com/szandala/TorchPRISM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce a tool called Principal Image Sections Mapping -\nPRISM, dedicated for PyTorch, but can be easily ported to other deep learning\nframeworks. Presented software relies on Principal Component Analysis to\nvisualize the most significant features recognized by a given Convolutional\nNeural Network. Moreover, it allows to display comparative set features between\nimages processed in the same batch, therefore PRISM can be a method well\nsynerging with technique Explanation by Example.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 08:54:23 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Szandala", "Tomasz", ""]]}, {"id": "2101.11268", "submitter": "Suyuchen Wang", "authors": "Suyuchen Wang, Ruihui Zhao, Xi Chen, Yefeng Zheng and Bang Liu", "title": "Enquire One's Parent and Child Before Decision: Fully Exploit\n  Hierarchical Structure for Self-Supervised Taxonomy Expansion", "comments": "12 pages, 6 figures. To appear in The Web Conference (WWW) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Taxonomy is a hierarchically structured knowledge graph that plays a crucial\nrole in machine intelligence. The taxonomy expansion task aims to find a\nposition for a new term in an existing taxonomy to capture the emerging\nknowledge in the world and keep the taxonomy dynamically updated. Previous\ntaxonomy expansion solutions neglect valuable information brought by the\nhierarchical structure and evaluate the correctness of merely an added edge,\nwhich downgrade the problem to node-pair scoring or mini-path classification.\nIn this paper, we propose the Hierarchy Expansion Framework (HEF), which fully\nexploits the hierarchical structure's properties to maximize the coherence of\nexpanded taxonomy. HEF makes use of taxonomy's hierarchical structure in\nmultiple aspects: i) HEF utilizes subtrees containing most relevant nodes as\nself-supervision data for a complete comparison of parental and sibling\nrelations; ii) HEF adopts a coherence modeling module to evaluate the coherence\nof a taxonomy's subtree by integrating hypernymy relation detection and several\ntree-exclusive features; iii) HEF introduces the Fitting Score for position\nselection, which explicitly evaluates both path and level selections and takes\nfull advantage of parental relations to interchange information for\ndisambiguation and self-correction. Extensive experiments show that by better\nexploiting the hierarchical structure and optimizing taxonomy's coherence, HEF\nvastly surpasses the prior state-of-the-art on three benchmark datasets by an\naverage improvement of 46.7% in accuracy and 32.3% in mean reciprocal rank.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 08:57:47 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Wang", "Suyuchen", ""], ["Zhao", "Ruihui", ""], ["Chen", "Xi", ""], ["Zheng", "Yefeng", ""], ["Liu", "Bang", ""]]}, {"id": "2101.11296", "submitter": "Wei Zhou", "authors": "Yiying Li, Wei Zhou, Huaimin Wang, Haibo Mi, Timothy M. Hospedales", "title": "FedH2L: Federated Learning with Model and Statistical Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables distributed participants to collectively\nlearn a strong global model without sacrificing their individual data privacy.\nMainstream FL approaches require each participant to share a common network\narchitecture and further assume that data are are sampled IID across\nparticipants. However, in real-world deployments participants may require\nheterogeneous network architectures; and the data distribution is almost\ncertainly non-uniform across participants. To address these issues we introduce\nFedH2L, which is agnostic to both the model architecture and robust to\ndifferent data distributions across participants. In contrast to approaches\nsharing parameters or gradients, FedH2L relies on mutual distillation,\nexchanging only posteriors on a shared seed set between participants in a\ndecentralized manner. This makes it extremely bandwidth efficient, model\nagnostic, and crucially produces models capable of performing well on the whole\ndata distribution when learning from heterogeneous silos.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 10:10:18 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 07:17:05 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 10:43:44 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Li", "Yiying", ""], ["Zhou", "Wei", ""], ["Wang", "Huaimin", ""], ["Mi", "Haibo", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "2101.11306", "submitter": "Shuohui Li", "authors": "Shuo-Hui Li", "title": "Learning Non-linear Wavelet Transformation via Normalizing Flow", "comments": "Main text: 7 pages, 5 figures. Supplement: 5 pages. Github link:\n  https://github.com/li012589/NeuralWavelet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wavelet transformation stands as a cornerstone in modern data analysis and\nsignal processing. Its mathematical essence is an invertible transformation\nthat discerns slow patterns from fast patterns in the frequency domain, which\nrepeats at each level. Such an invertible transformation can be learned by a\ndesigned normalizing flow model. With a factor-out scheme resembling the\nwavelet downsampling mechanism, a mutually independent prior, and parameter\nsharing along the depth of the network, one can train normalizing flow models\nto factor-out variables corresponding to fast patterns at different levels,\nthus extending linear wavelet transformations to non-linear learnable models.\nIn this paper, a concrete way of building such flows is given. Then, a\ndemonstration of the model's ability in lossless compression task, progressive\nloading, and super-resolution (upsampling) task. Lastly, an analysis of the\nlearned model in terms of low-pass/high-pass filters is given.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 10:28:51 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Shuo-Hui", ""]]}, {"id": "2101.11351", "submitter": "Dario Stein", "authors": "Dario Stein, Sam Staton", "title": "Compositional Semantics for Probabilistic Programs with Exact\n  Conditioning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO math.CT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a probabilistic programming language for Gaussian random variables\nwith a first-class exact conditioning construct. We give operational,\ndenotational and equational semantics for this language, establishing\nconvenient properties like exchangeability of conditions. Conditioning on\nequality of continuous random variables is nontrivial, as the exact observation\nmay have probability zero; this is Borel's paradox. Using categorical\nformulations of conditional probability, we show that the good properties of\nour language are not particular to Gaussians, but can be derived from universal\nproperties, thus generalizing to wider settings. We define the Cond\nconstruction, which internalizes conditioning as a morphism, providing general\ncompositional semantics for probabilistic programming with exact conditioning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 12:31:18 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Stein", "Dario", ""], ["Staton", "Sam", ""]]}, {"id": "2101.11354", "submitter": "Yongchun Zhu", "authors": "Yongchun Zhu, Fuzhen Zhuang, Xiangliang Zhang, Zhiyuan Qi, Zhiping Shi\n  and Qing He", "title": "Combat Data Shift in Few-shot Learning with Knowledge Graph", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many few-shot learning approaches have been designed under the meta-learning\nframework, which learns from a variety of learning tasks and generalizes to new\ntasks. These meta-learning approaches achieve the expected performance in the\nscenario where all samples are drawn from the same distributions (i.i.d.\nobservations). However, in real-world applications, few-shot learning paradigm\noften suffers from data shift, i.e., samples in different tasks, even in the\nsame task, could be drawn from various data distributions. Most existing\nfew-shot learning approaches are not designed with the consideration of data\nshift, and thus show downgraded performance when data distribution shifts.\nHowever, it is non-trivial to address the data shift problem in few-shot\nlearning, due to the limited number of labeled samples in each task. Targeting\nat addressing this problem, we propose a novel metric-based meta-learning\nframework to extract task-specific representations and task-shared\nrepresentations with the help of knowledge graph. The data shift within/between\ntasks can thus be combated by the combination of task-shared and task-specific\nrepresentations. The proposed model is evaluated on popular benchmarks and two\nconstructed new challenging datasets. The evaluation results demonstrate its\nremarkable performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 12:35:18 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 06:22:21 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Zhu", "Yongchun", ""], ["Zhuang", "Fuzhen", ""], ["Zhang", "Xiangliang", ""], ["Qi", "Zhiyuan", ""], ["Shi", "Zhiping", ""], ["He", "Qing", ""]]}, {"id": "2101.11374", "submitter": "Yichao Du", "authors": "Yichao Du, Pengfei Luo, Xudong Hong, Tong Xu, Zhe Zhang, Chao Ren, Yi\n  Zheng, Enhong Chen", "title": "Inheritance-guided Hierarchical Assignment for Clinical Automatic\n  Diagnosis", "comments": "17 pages, 5 figures, DASFAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical diagnosis, which aims to assign diagnosis codes for a patient based\non the clinical note, plays an essential role in clinical decision-making.\nConsidering that manual diagnosis could be error-prone and time-consuming, many\nintelligent approaches based on clinical text mining have been proposed to\nperform automatic diagnosis. However, these methods may not achieve\nsatisfactory results due to the following challenges. First, most of the\ndiagnosis codes are rare, and the distribution is extremely unbalanced. Second,\nexisting methods are challenging to capture the correlation between diagnosis\ncodes. Third, the lengthy clinical note leads to the excessive dispersion of\nkey information related to codes. To tackle these challenges, we propose a\nnovel framework to combine the inheritance-guided hierarchical assignment and\nco-occurrence graph propagation for clinical automatic diagnosis. Specifically,\nwe propose a hierarchical joint prediction strategy to address the challenge of\nunbalanced codes distribution. Then, we utilize graph convolutional neural\nnetworks to obtain the correlation and semantic representations of medical\nontology. Furthermore, we introduce multi attention mechanisms to extract\ncrucial information. Finally, extensive experiments on MIMIC-III dataset\nclearly validate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 13:16:51 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Du", "Yichao", ""], ["Luo", "Pengfei", ""], ["Hong", "Xudong", ""], ["Xu", "Tong", ""], ["Zhang", "Zhe", ""], ["Ren", "Chao", ""], ["Zheng", "Yi", ""], ["Chen", "Enhong", ""]]}, {"id": "2101.11376", "submitter": "Charles Wilmot", "authors": "Charles Wilmot, Jochen Triesch", "title": "Learning Abstract Representations through Lossy Compression of\n  Multi-Modal Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A key competence for open-ended learning is the formation of increasingly\nabstract representations useful for driving complex behavior. Abstract\nrepresentations ignore specific details and facilitate generalization. Here we\nconsider the learning of abstract representations in a multi-modal setting with\ntwo or more input modalities. We treat the problem as a lossy compression\nproblem and show that generic lossy compression of multimodal sensory input\nnaturally extracts abstract representations that tend to strip away modalitiy\nspecific details and preferentially retain information that is shared across\nthe different modalities. Furthermore, we propose an architecture to learn\nabstract representations by identifying and retaining only the information that\nis shared across multiple modalities while discarding any modality specific\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 13:19:00 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 08:12:11 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wilmot", "Charles", ""], ["Triesch", "Jochen", ""]]}, {"id": "2101.11391", "submitter": "Charles Wilmot", "authors": "Charles Wilmot, Bertram E. Shi, Jochen Triesch", "title": "Self-Calibrating Active Binocular Vision via Active Efficient Coding\n  with Deep Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a model of the self-calibration of active binocular vision\ncomprising the simultaneous learning of visual representations, vergence, and\npursuit eye movements. The model follows the principle of Active Efficient\nCoding (AEC), a recent extension of the classic Efficient Coding Hypothesis to\nactive perception. In contrast to previous AEC models, the present model uses\ndeep autoencoders to learn sensory representations. We also propose a new\nformulation of the intrinsic motivation signal that guides the learning of\nbehavior. We demonstrate the performance of the model in simulations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 13:40:16 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Wilmot", "Charles", ""], ["Shi", "Bertram E.", ""], ["Triesch", "Jochen", ""]]}, {"id": "2101.11429", "submitter": "Gong Cheng", "authors": "Xiao Li, Yawei Sun, Gong Cheng", "title": "TSQA: Tabular Scenario Based Question Answering", "comments": "9 pages, accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scenario-based question answering (SQA) has attracted an increasing research\ninterest. Compared with the well-studied machine reading comprehension (MRC),\nSQA is a more challenging task: a scenario may contain not only a textual\npassage to read but also structured data like tables, i.e., tabular scenario\nbased question answering (TSQA). AI applications of TSQA such as answering\nmultiple-choice questions in high-school exams require synthesizing data in\nmultiple cells and combining tables with texts and domain knowledge to infer\nanswers. To support the study of this task, we construct GeoTSQA. This dataset\ncontains 1k real questions contextualized by tabular scenarios in the geography\ndomain. To solve the task, we extend state-of-the-art MRC methods with TTGen, a\nnovel table-to-text generator. It generates sentences from variously\nsynthesized tabular data and feeds the downstream MRC method with the most\nuseful sentences. Its sentence ranking model fuses the information in the\nscenario, question, and domain knowledge. Our approach outperforms a variety of\nstrong baseline methods on GeoTSQA.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 02:00:33 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Xiao", ""], ["Sun", "Yawei", ""], ["Cheng", "Gong", ""]]}, {"id": "2101.11435", "submitter": "Yakup Kutlu", "authors": "Apdullah Yayik, Yakup Kutlu", "title": "Online LDA based brain-computer interface system to aid disabled people", "comments": "13 pages, 4 figures, Natural and Engineering Sciences", "journal-ref": "Natural and Engineering Sciences, 2017", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to develop brain-computer interface system based on\nelectroencephalography that can aid disabled people in daily life. The system\nrelies on one of the most effective event-related potential wave, P300, which\ncan be elicited by oddball paradigm. Developed application has a basic\ninteraction tool that enables disabled people to convey their needs to other\npeople selecting related objects. These objects pseudo-randomly flash in a\nvisual interface on computer screen. The user must focus on related object to\nconvey desired needs. The system can convey desired needs correctly by\ndetecting P300 wave in acquired 14-channel EEG signal and classifying using\nlinear discriminant analysis classifier just in 15 seconds. Experiments have\nbeen carried out on 19 volunteers to validate developed BCI system. As a\nresult, accuracy rate of 90.83% is achieved in online performance\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 08:17:05 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Yayik", "Apdullah", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2101.11436", "submitter": "Yakup Kutlu", "authors": "Kadir Tohma, Yakup Kutlu", "title": "Challenges Encountered in Turkish Natural Language Processing Studies", "comments": "8 pages, Natural and Engineering Sciences", "journal-ref": "Natural and Engineering Sciences, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language processing is a branch of computer science that combines\nartificial intelligence with linguistics. It aims to analyze a language element\nsuch as writing or speaking with software and convert it into information.\nConsidering that each language has its own grammatical rules and vocabulary\ndiversity, the complexity of the studies in this field is somewhat\nunderstandable. For instance, Turkish is a very interesting language in many\nways. Examples of this are agglutinative word structure, consonant/vowel\nharmony, a large number of productive derivational morphemes (practically\ninfinite vocabulary), derivation and syntactic relations, a complex emphasis on\nvocabulary and phonological rules. In this study, the interesting features of\nTurkish in terms of natural language processing are mentioned. In addition,\nsummary info about natural language processing techniques, systems and various\nsources developed for Turkish are given.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 08:30:33 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Tohma", "Kadir", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2101.11437", "submitter": "Christoph Beierle", "authors": "Anne-Kathrin Schumann, Christoph Beierle, Norbert Bl\\\"o{\\ss}ner", "title": "Using Finite-State Machines to Automatically Scan Classical Greek\n  Hexameter", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a fully automatic approach to the scansion of Classical\nGreek hexameter verse. In particular, the paper describes an algorithm that\nuses deterministic finite-state automata and local linguistic rules to\nimplement a targeted search for valid spondeus patterns and, in addition, a\nweighted finite-state transducer to correct and complete partial analyses and\nto reject invalid candidates. The paper also details the results of an\nempirical evaluation of the annotation quality resulting from this approach on\nhand-annotated data. It is shown that a finite-state approach provides quick\nand linguistically sound analyses of hexameter verses as well as an efficient\nformalisation of linguistic knowledge. The project code is available (see\nhttps://github.com/anetschka/greek_scansion).\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 09:59:46 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Schumann", "Anne-Kathrin", ""], ["Beierle", "Christoph", ""], ["Bl\u00f6\u00dfner", "Norbert", ""]]}, {"id": "2101.11453", "submitter": "Jan Metzen", "authors": "Jan Hendrik Metzen, Nicole Finnie, Robin Hutmacher", "title": "Meta Adversarial Training against Universal Patches", "comments": "Accepted by the ICML 2021 workshop on \"A Blessing in Disguise: The\n  Prospects and Perils of Adversarial Machine Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently demonstrated physical-world adversarial attacks have exposed\nvulnerabilities in perception systems that pose severe risks for\nsafety-critical applications such as autonomous driving. These attacks place\nadversarial artifacts in the physical world that indirectly cause the addition\nof a universal patch to inputs of a model that can fool it in a variety of\ncontexts. Adversarial training is the most effective defense against\nimage-dependent adversarial attacks. However, tailoring adversarial training to\nuniversal patches is computationally expensive since the optimal universal\npatch depends on the model weights which change during training. We propose\nmeta adversarial training (MAT), a novel combination of adversarial training\nwith meta-learning, which overcomes this challenge by meta-learning universal\npatches along with model training. MAT requires little extra computation while\ncontinuously adapting a large set of patches to the current model. MAT\nconsiderably increases robustness against universal patch attacks on image\nclassification and traffic-light detection.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 14:36:23 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 14:07:54 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Metzen", "Jan Hendrik", ""], ["Finnie", "Nicole", ""], ["Hutmacher", "Robin", ""]]}, {"id": "2101.11473", "submitter": "Lin Xie", "authors": "Lin Xie, Hanyi Li and Laurin Luttmann", "title": "Formulating and solving integrated order batching and routing in\n  multi-depot AGV-assisted mixed-shelves warehouses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Different retail and e-commerce companies are facing the challenge of\nassembling large numbers of time-critical picking orders that include both\nsingle-line and multi-line orders. To reduce unproductive picker working time\nas in traditional picker-to-parts warehousing systems, different solutions are\nproposed in the literature and in practice. For example, in a mixed-shelves\nstorage policy, items of the same stock keeping unit are spread over several\nshelves in a warehouse; or automated guided vehicles (AGVs) are used to\ntransport the picked items from the storage area to packing stations instead of\nhuman pickers. This is the first paper to combine both solutions, creating what\nwe call AGV-assisted mixed-shelves picking systems. We model the new integrated\norder batching and routing problem in such systems as an extended multi-depot\nvehicle routing problem with both three-index and two-commodity network flow\nformulations. Due to the complexity of the integrated problem, we develop a\nnovel variable neighborhood search algorithm to solve the integrated problem\nmore efficiently. We test our methods with different sizes of instances, and\nconclude that the mixed-shelves storage policy is more suitable than the usual\nstorage policy in AGV-assisted mixed-shelves systems for both single-line and\nmulti-line orders (saving up to 67% on driving distances for AGVs). Our\nvariable neighborhood search algorithm provides close-to-optimal solutions\nwithin an acceptable computational time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 15:04:05 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Xie", "Lin", ""], ["Li", "Hanyi", ""], ["Luttmann", "Laurin", ""]]}, {"id": "2101.11496", "submitter": "Song-Ju Kim Dr.", "authors": "Song-Ju Kim, Taiki Takahashi, and Kazuo Sano", "title": "A Balance for Fairness: Fair Distribution Utilising Physics in Games of\n  Characteristic Function Form", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.GN physics.soc-ph q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In chaotic modern society, there is an increasing demand for the realization\nof true 'fairness'. In Greek mythology, Themis, the 'goddess of justice', has a\nsword in her right hand to protect society from vices, and a 'balance of\njudgment' in her left hand that measures good and evil. In this study, we\npropose a fair distribution method 'utilising physics' for the profit in games\nof characteristic function form. Specifically, we show that the linear\nprogramming problem for calculating 'nucleolus' can be efficiently solved by\nconsidering it as a physical system in which gravity works. In addition to\nbeing able to significantly reduce computational complexity thereby, we believe\nthat this system could have flexibility necessary to respond to real-time\nchanges in the parameter.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 15:42:35 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:58:03 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Kim", "Song-Ju", ""], ["Takahashi", "Taiki", ""], ["Sano", "Kazuo", ""]]}, {"id": "2101.11501", "submitter": "Adekunle Akinrinmade", "authors": "Emmanuel Adetiba, Temitope John, Adekunle Akinrinmade, Funmilayo\n  Moninuola, Oladipupo Akintade, Joke Badejo", "title": "Evolution of artificial intelligence languages, a systematic literature\n  review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of Artificial Intelligence (AI) has undoubtedly received\nsignificant attention in recent years. AI is being adopted to provide solutions\nto problems in fields such as medicine, engineering, education, government and\nseveral other domains. In order to analyze the state of the art of research in\nthe field of AI, we present a systematic literature review focusing on the\nEvolution of AI programming languages. We followed the systematic literature\nreview method by searching relevant databases like SCOPUS, IEEE Xplore and\nGoogle Scholar. EndNote reference manager was used to catalog the relevant\nextracted papers. Our search returned a total of 6565 documents, whereof 69\nstudies were retained. Of the 69 retained studies, 15 documents discussed LISP\nprogramming language, another 34 discussed PROLOG programming language, the\nremaining 20 documents were spread between Logic and Object Oriented\nProgramming (LOOP), ARCHLOG, Epistemic Ontology Language with Constraints\n(EOLC), Python, C++, ADA and JAVA programming languages. This review provides\ninformation on the year of implementation, development team, capabilities,\nlimitations and applications of each of the AI programming languages discussed.\nThe information in this review could guide practitioners and researchers in AI\nto make the right choice of languages to implement their novel AI methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 15:57:04 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Adetiba", "Emmanuel", ""], ["John", "Temitope", ""], ["Akinrinmade", "Adekunle", ""], ["Moninuola", "Funmilayo", ""], ["Akintade", "Oladipupo", ""], ["Badejo", "Joke", ""]]}, {"id": "2101.11538", "submitter": "Carole Adam", "authors": "Albin Soutif and Carole Adam and Sylvain Bouveret", "title": "Multi-agent simulation of voter's behaviour", "comments": "internship report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to simulate the voters behaviour given a voting\nmethod. Our approach uses a multi-agent simulation in order to model a voting\nprocess through many iterations, so that the voters can vote by taking into\naccount the results of polls. Here we only tried basic rules and a single\nvoting method, but further attempts could explore new features.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 16:48:03 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Soutif", "Albin", ""], ["Adam", "Carole", ""], ["Bouveret", "Sylvain", ""]]}, {"id": "2101.11548", "submitter": "Carole Adam", "authors": "Yassine Bouachrine and Carole Adam", "title": "Modelling the Impact of Scandals: the case of the 2017 French\n  Presidential Election", "comments": "internship report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes an agent-based simulation of a presidential election,\ninspired by the French 2017 presidential election. The simulation is based on\ndata extracted from polls, media coverage, and Twitter. The main contribution\nis to consider the impact of scandals and media bashing on the result of the\nelection. In particular, it is shown that scandals can lead to higher\nabstention at the election, as voters have no relevant candidate left to vote\nfor. The simulation is implemented in Unity 3D and is available to play online.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 17:08:38 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Bouachrine", "Yassine", ""], ["Adam", "Carole", ""]]}, {"id": "2101.11550", "submitter": "Shin-Nosuke Ishikawa", "authors": "Shin-nosuke Ishikawa, Hideaki Matsumura, Yasunobu Uchiyama and Lindsay\n  Glesener", "title": "Automatic Detection of Occulted Hard X-ray Flares Using Deep-Learning\n  Methods", "comments": "11 pages, 3 figures, accepted for publication in Solar Physics", "journal-ref": null, "doi": "10.1007/s11207-021-01780-x", "report-no": null, "categories": "astro-ph.SR astro-ph.IM cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a concept for a machine-learning classification of hard X-ray\n(HXR) emissions from solar flares observed by the Reuven Ramaty High Energy\nSolar Spectroscopic Imager (RHESSI), identifying flares that are either\nocculted by the solar limb or located on the solar disk. Although HXR\nobservations of occulted flares are important for particle-acceleration\nstudies, HXR data analyses for past observations were time consuming and\nrequired specialized expertise. Machine-learning techniques are promising for\nthis situation, and we constructed a sample model to demonstrate the concept\nusing a deep-learning technique. Input data to the model are HXR spectrograms\nthat are easily produced from RHESSI data. The model can detect occulted flares\nwithout the need for image reconstruction nor for visual inspection by experts.\nA technique of convolutional neural networks was used in this model by\nregarding the input data as images. Our model achieved a classification\naccuracy better than 90 %, and the ability for the application of the method to\neither event screening or for an event alert for occulted flares was\nsuccessfully demonstrated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 17:11:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Ishikawa", "Shin-nosuke", ""], ["Matsumura", "Hideaki", ""], ["Uchiyama", "Yasunobu", ""], ["Glesener", "Lindsay", ""]]}, {"id": "2101.11560", "submitter": "Ece Calikus", "authors": "Ece Calikus, Slawomir Nowaczyk, Mohamed-Rafik Bouguelia, and Onur\n  Dikmen", "title": "Wisdom of the Contexts: Active Ensemble Learning for Contextual Anomaly\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contextual anomaly detection, an object is only considered anomalous\nwithin a specific context. Most existing methods for CAD use a single context\nbased on a set of user-specified contextual features. However, identifying the\nright context can be very challenging in practice, especially in datasets, with\na large number of attributes. Furthermore, in real-world systems, there might\nbe multiple anomalies that occur in different contexts and, therefore, require\na combination of several \"useful\" contexts to unveil them. In this work, we\nleverage active learning and ensembles to effectively detect complex contextual\nanomalies in situations where the true contextual and behavioral attributes are\nunknown. We propose a novel approach, called WisCon (Wisdom of the Contexts),\nthat automatically creates contexts from the feature set. Our method constructs\nan ensemble of multiple contexts, with varying importance scores, based on the\nassumption that not all useful contexts are equally so. Experiments show that\nWisCon significantly outperforms existing baselines in different categories\n(i.e., active classifiers, unsupervised contextual and non-contextual anomaly\ndetectors, and supervised classifiers) on seven datasets. Furthermore, the\nresults support our initial hypothesis that there is no single perfect context\nthat successfully uncovers all kinds of contextual anomalies, and leveraging\nthe \"wisdom\" of multiple contexts is necessary.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 17:34:13 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 23:16:56 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Calikus", "Ece", ""], ["Nowaczyk", "Slawomir", ""], ["Bouguelia", "Mohamed-Rafik", ""], ["Dikmen", "Onur", ""]]}, {"id": "2101.11563", "submitter": "Alan Smeaton", "authors": "Rashmiranjan Das and Gaurav Negi and Alan F. Smeaton", "title": "Detecting Deepfake Videos Using Euler Video Magnification", "comments": "Presented at Electronic Imaging: Media Watermarking, Security, and\n  Forensics, 27 January 2021, 6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in artificial intelligence make it progressively hard to\ndistinguish between genuine and counterfeit media, especially images and\nvideos. One recent development is the rise of deepfake videos, based on\nmanipulating videos using advanced machine learning techniques. This involves\nreplacing the face of an individual from a source video with the face of a\nsecond person, in the destination video. This idea is becoming progressively\nrefined as deepfakes are getting progressively seamless and simpler to compute.\nCombined with the outreach and speed of social media, deepfakes could easily\nfool individuals when depicting someone saying things that never happened and\nthus could persuade people in believing fictional scenarios, creating distress,\nand spreading fake news. In this paper, we examine a technique for possible\nidentification of deepfake videos. We use Euler video magnification which\napplies spatial decomposition and temporal filtering on video data to highlight\nand magnify hidden features like skin pulsation and subtle motions. Our\napproach uses features extracted from the Euler technique to train three models\nto classify counterfeit and unaltered videos and compare the results with\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 17:37:23 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Das", "Rashmiranjan", ""], ["Negi", "Gaurav", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2101.11566", "submitter": "Antony Thomas", "authors": "Antony Thomas and Fulvio Mastrogiovanni and Marco Baglietto", "title": "An Integrated Localisation, Motion Planning and Obstacle Avoidance\n  Algorithm in Belief Space", "comments": "Accepted for publication in Intelligent Service Robotics", "journal-ref": null, "doi": "10.1007/s11370-021-00359-6", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As robots are being increasingly used in close proximity to humans and\nobjects, it is imperative that robots operate safely and efficiently under\nreal-world conditions. Yet, the environment is seldom known perfectly. Noisy\nsensors and actuation errors compound to the errors introduced while estimating\nfeatures of the environment. We present a novel approach (1) to incorporate\nthese uncertainties for robot state estimation and (2) to compute the\nprobability of collision pertaining to the estimated robot configurations. The\nexpression for collision probability is obtained as an infinite series and we\nprove its convergence. An upper bound for the truncation error is also derived\nand the number of terms required is demonstrated by analyzing the convergence\nfor different robot and obstacle configurations. We evaluate our approach using\ntwo simulation domains which use a roadmap-based strategy to synthesize\ntrajectories that satisfy collision probability bounds.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 17:47:45 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Thomas", "Antony", ""], ["Mastrogiovanni", "Fulvio", ""], ["Baglietto", "Marco", ""]]}, {"id": "2101.11574", "submitter": "Weihua Li", "authors": "Jiaqi Wu, Weihua Li, Quan Bai, Takayuki Ito, Ahmed Moustafa", "title": "Privacy Information Classification: A Hybrid Approach", "comments": "IJCAI 2019 Workshop. The 4th International Workshop on Smart\n  Simulation and Modelling for Complex Systems", "journal-ref": null, "doi": null, "report-no": "SSMCS2019-11", "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large amount of information has been published to online social networks\nevery day. Individual privacy-related information is also possibly disclosed\nunconsciously by the end-users. Identifying privacy-related data and protecting\nthe online social network users from privacy leakage turn out to be\nsignificant. Under such a motivation, this study aims to propose and develop a\nhybrid privacy classification approach to detect and classify privacy\ninformation from OSNs. The proposed hybrid approach employs both deep learning\nmodels and ontology-based models for privacy-related information extraction.\nExtensive experiments are conducted to validate the proposed hybrid approach,\nand the empirical results demonstrate its superiority in assisting online\nsocial network users against privacy leakage.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 18:03:18 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Wu", "Jiaqi", ""], ["Li", "Weihua", ""], ["Bai", "Quan", ""], ["Ito", "Takayuki", ""], ["Moustafa", "Ahmed", ""]]}, {"id": "2101.11587", "submitter": "Steven Frank", "authors": "Steven J. Frank", "title": "The Work of Art in an Age of Mechanical Generation", "comments": "This is the author's final version; the article has been accepted for\n  publication in Leonardo Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can we define what it means to be \"creative,\" and if so, can our definition\ndrive artificial intelligence (AI) systems to feats of creativity\nindistinguishable from human efforts? This mixed question is considered from\ntechnological and social perspectives. Beginning with an exploration of the\nvalue we attach to authenticity in works of art, the article considers the\nability of AI to detect forgeries of renowned paintings and, in so doing,\nsomehow reveal the quiddity of a work of art. We conclude by considering\nwhether evolving technical capability can revise traditional relationships\namong art, artist, and the market.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 18:32:58 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Frank", "Steven J.", ""]]}, {"id": "2101.11605", "submitter": "Aravind Srinivas Lakshminarayanan", "authors": "Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter\n  Abbeel, Ashish Vaswani", "title": "Bottleneck Transformers for Visual Recognition", "comments": "Technical Report, 20 pages, 13 figures, 19 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BoTNet, a conceptually simple yet powerful backbone architecture\nthat incorporates self-attention for multiple computer vision tasks including\nimage classification, object detection and instance segmentation. By just\nreplacing the spatial convolutions with global self-attention in the final\nthree bottleneck blocks of a ResNet and no other changes, our approach improves\nupon the baselines significantly on instance segmentation and object detection\nwhile also reducing the parameters, with minimal overhead in latency. Through\nthe design of BoTNet, we also point out how ResNet bottleneck blocks with\nself-attention can be viewed as Transformer blocks. Without any bells and\nwhistles, BoTNet achieves 44.4% Mask AP and 49.7% Box AP on the COCO Instance\nSegmentation benchmark using the Mask R-CNN framework; surpassing the previous\nbest published single model and single scale results of ResNeSt evaluated on\nthe COCO validation set. Finally, we present a simple adaptation of the BoTNet\ndesign for image classification, resulting in models that achieve a strong\nperformance of 84.7% top-1 accuracy on the ImageNet benchmark while being up to\n2.33x faster in compute time than the popular EfficientNet models on TPU-v3\nhardware. We hope our simple and effective approach will serve as a strong\nbaseline for future research in self-attention models for vision.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 18:55:27 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Srinivas", "Aravind", ""], ["Lin", "Tsung-Yi", ""], ["Parmar", "Niki", ""], ["Shlens", "Jonathon", ""], ["Abbeel", "Pieter", ""], ["Vaswani", "Ashish", ""]]}, {"id": "2101.11685", "submitter": "Rasul Karimov", "authors": "Rasul Karimov, Yury Malkov, Karim Iskakov, Victor Lempitsky", "title": "CNN with large memory layers", "comments": "Master's dissertation paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work is centred around the recently proposed product key memory\nstructure \\cite{large_memory}, implemented for a number of computer vision\napplications. The memory structure can be regarded as a simple computation\nprimitive suitable to be augmented to nearly all neural network architectures.\nThe memory block allows implementing sparse access to memory with square root\ncomplexity scaling with respect to the memory capacity. The latter scaling is\npossible due to the incorporation of Cartesian product space decomposition of\nthe key space for the nearest neighbour search. We have tested the memory layer\non the classification, image reconstruction and relocalization problems and\nfound that for some of those, the memory layers can provide significant\nspeed/accuracy improvement with the high utilization of the key-value elements,\nwhile others require more careful fine-tuning and suffer from dying keys. To\ntackle the later problem we have introduced a simple technique of memory\nre-initialization which helps us to eliminate unused key-value pairs from the\nmemory and engage them in training again. We have conducted various experiments\nand got improvements in speed and accuracy for classification and PoseNet\nrelocalization models.\n  We showed that the re-initialization has a huge impact on a toy example of\nrandomly labeled data and observed some gains in performance on the image\nclassification task. We have also demonstrated the generalization property\nperseverance of the large memory layers on the relocalization problem, while\nobserving the spatial correlations between the images and the selected memory\ncells.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 20:58:20 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 09:42:58 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Karimov", "Rasul", ""], ["Malkov", "Yury", ""], ["Iskakov", "Karim", ""], ["Lempitsky", "Victor", ""]]}, {"id": "2101.11700", "submitter": "Suiyi Ling", "authors": "Zhenyu Lei, Yejing Xie, Suiyi Ling, Andreas Pastor, Junle Wang,\n  Patrick Le Callet", "title": "Multi-Modal Aesthetic Assessment for MObile Gaming Image", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of various gaming technology, services, game styles,\nand platforms, multi-dimensional aesthetic assessment of the gaming contents is\nbecoming more and more important for the gaming industry. Depending on the\ndiverse needs of diversified game players, game designers, graphical\ndevelopers, etc. in particular conditions, multi-modal aesthetic assessment is\nrequired to consider different aesthetic dimensions/perspectives. Since there\nare different underlying relationships between different aesthetic dimensions,\ne.g., between the `Colorfulness' and `Color Harmony', it could be advantageous\nto leverage effective information attached in multiple relevant dimensions. To\nthis end, we solve this problem via multi-task learning. Our inclination is to\nseek and learn the correlations between different aesthetic relevant dimensions\nto further boost the generalization performance in predicting all the aesthetic\ndimensions. Therefore, the `bottleneck' of obtaining good predictions with\nlimited labeled data for one individual dimension could be unplugged by\nharnessing complementary sources of other dimensions, i.e., augment the\ntraining data indirectly by sharing training information across dimensions.\nAccording to experimental results, the proposed model outperforms\nstate-of-the-art aesthetic metrics significantly in predicting four gaming\naesthetic dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 21:48:31 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lei", "Zhenyu", ""], ["Xie", "Yejing", ""], ["Ling", "Suiyi", ""], ["Pastor", "Andreas", ""], ["Wang", "Junle", ""], ["Callet", "Patrick Le", ""]]}, {"id": "2101.11702", "submitter": "Domen Vre\\v{s}", "authors": "Domen Vre\\v{s} and Marko Robnik \\v{S}ikonja", "title": "Better sampling in explanation methods can prevent dieselgate-like\n  deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models are used in many sensitive areas where besides\npredictive accuracy their comprehensibility is also important. Interpretability\nof prediction models is necessary to determine their biases and causes of\nerrors, and is a necessary prerequisite for users' confidence. For complex\nstate-of-the-art black-box models post-hoc model-independent explanation\ntechniques are an established solution. Popular and effective techniques, such\nas IME, LIME, and SHAP, use perturbation of instance features to explain\nindividual predictions. Recently, Slack et al. (2020) put their robustness into\nquestion by showing that their outcomes can be manipulated due to poor\nperturbation sampling employed. This weakness would allow dieselgate type\ncheating of owners of sensitive models who could deceive inspection and hide\npotentially unethical or illegal biases existing in their predictive models.\nThis could undermine public trust in machine learning models and give rise to\nlegal restrictions on their use.\n  We show that better sampling in these explanation methods prevents malicious\nmanipulations. The proposed sampling uses data generators that learn the\ntraining set distribution and generate new perturbation instances much more\nsimilar to the training set. We show that the improved sampling increases the\nrobustness of the LIME and SHAP, while previously untested method IME is\nalready the most robust of all.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 13:41:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Vre\u0161", "Domen", ""], ["\u0160ikonja", "Marko Robnik", ""]]}, {"id": "2101.11707", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Sarat Varanasi, Farhad Shakerin, Joaquin Arias, Gopal\n  Gupta", "title": "Knowledge-driven Natural Language Understanding of English Text and its\n  Applications", "comments": "Preprint. Accepted by the 35th AAAI Conference (AAAI-21) Main Tracks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of a text is a fundamental challenge of natural\nlanguage understanding (NLU) research. An ideal NLU system should process a\nlanguage in a way that is not exclusive to a single task or a dataset. Keeping\nthis in mind, we have introduced a novel knowledge driven semantic\nrepresentation approach for English text. By leveraging the VerbNet lexicon, we\nare able to map syntax tree of the text to its commonsense meaning represented\nusing basic knowledge primitives. The general purpose knowledge represented\nfrom our approach can be used to build any reasoning based NLU system that can\nalso provide justification. We applied this approach to construct two NLU\napplications that we present here: SQuARE (Semantic-based Question Answering\nand Reasoning Engine) and StaCACK (Stateful Conversational Agent using\nCommonsense Knowledge). Both these systems work by \"truly understanding\" the\nnatural language text they process and both provide natural language\nexplanations for their responses while maintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:02:50 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Basu", "Kinjal", ""], ["Varanasi", "Sarat", ""], ["Shakerin", "Farhad", ""], ["Arias", "Joaquin", ""], ["Gupta", "Gopal", ""]]}, {"id": "2101.11717", "submitter": "Francois Malgouyres", "authors": "Adrien Gauffriau, Fran\\c{c}ois Malgouyres (IMT), M\\'elanie Ducoffe", "title": "Overestimation learning with guarantees", "comments": null, "journal-ref": "AAAI-21, workshop on safeAI, Feb 2021, Valence (Virtual), Spain", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a complete method that learns a neural network which is\nguaranteed to overestimate a reference function on a given domain. The neural\nnetwork can then be used as a surrogate for the reference function. The method\ninvolves two steps. In the first step, we construct an adaptive set of Majoring\nPoints. In the second step, we optimize a well-chosen neural network to\noverestimate the Majoring Points. In order to extend the guarantee on the\nMajoring Points to the whole domain, we necessarily have to make an assumption\non the reference function. In this study, we assume that the reference function\nis monotonic. We provide experiments on synthetic and real problems. The\nexperiments show that the density of the Majoring Points concentrate where the\nreference function varies. The learned over-estimations are both guaranteed to\noverestimate the reference function and are proven empirically to provide good\napproximations of it. Experiments on real data show that the method makes it\npossible to use the surrogate function in embedded systems for which an\nunderestimation is critical; when computing the reference function requires too\nmany resources.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 09:06:03 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Gauffriau", "Adrien", "", "IMT"], ["Malgouyres", "Fran\u00e7ois", "", "IMT"], ["Ducoffe", "M\u00e9lanie", ""]]}, {"id": "2101.11718", "submitter": "Jwala Dhamala", "authors": "Jwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada\n  Pruksachatkun, Kai-Wei Chang, Rahul Gupta", "title": "BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language\n  Generation", "comments": null, "journal-ref": null, "doi": "10.1145/3442188.3445924", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning techniques have enabled machines to generate\ncohesive open-ended text when prompted with a sequence of words as context.\nWhile these models now empower many downstream applications from conversation\nbots to automatic storytelling, they have been shown to generate texts that\nexhibit social biases. To systematically study and benchmark social biases in\nopen-ended language generation, we introduce the Bias in Open-Ended Language\nGeneration Dataset (BOLD), a large-scale dataset that consists of 23,679\nEnglish text generation prompts for bias benchmarking across five domains:\nprofession, gender, race, religion, and political ideology. We also propose new\nautomated metrics for toxicity, psycholinguistic norms, and text gender\npolarity to measure social biases in open-ended text generation from multiple\nangles. An examination of text generated from three popular language models\nreveals that the majority of these models exhibit a larger social bias than\nhuman-written Wikipedia text across all domains. With these results we\nhighlight the need to benchmark biases in open-ended language generation and\ncaution users of language generation models on downstream tasks to be cognizant\nof these embedded prejudices.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:07:03 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Dhamala", "Jwala", ""], ["Sun", "Tony", ""], ["Kumar", "Varun", ""], ["Krishna", "Satyapriya", ""], ["Pruksachatkun", "Yada", ""], ["Chang", "Kai-Wei", ""], ["Gupta", "Rahul", ""]]}, {"id": "2101.11727", "submitter": "Cristina Feier", "authors": "Cristina Feier", "title": "Characterising Fixed Parameter Tractability of Query Evaluation over\n  Guarded TGDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of evaluating Ontology Mediated Queries\n(OMQs) based on Guarded TGDs (GTGDs) and Unions of Conjunctive Queries (UCQs),\nin the case where relational symbols have unrestricted arity and where the\nparameter is the size of the OMQ. We establish exact criteria for\nfixed-parameter tractability (fpt) evaluation of recursively enumerable classes\nof such OMQs (under the widely held Exponential Time Hypothesis). One of the\nmain technical tools introduced in the paper is an fpt-reduction from deciding\nparameterized uniform CSPs to parameterized OMQ evaluation. The reduction\npreserves measures which are known to be essential for classifying recursively\nenumerable classes of parameterized uniform CSPs: submodular width (according\nto the well known result of Marx for unrestricted-arity schemas) and treewidth\n(according to the well known result of Grohe for bounded-arity schemas). As\nsuch, it can be employed to obtain hardness results for evaluation of\nrecursively enumerable classes of parameterized OMQs both in the unrestricted\nand in the bounded arity case. Previously, in the case of bounded arity\nschemas, this has been tackled using a technique requiring full introspection\ninto the construction employed by Grohe.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:32:16 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:08:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feier", "Cristina", ""]]}, {"id": "2101.11750", "submitter": "Chuteng Zhou", "authors": "Chuteng Zhou, Quntao Zhuang, Matthew Mattina, Paul N. Whatmough", "title": "Information contraction in noisy binary neural networks and its\n  implications", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have gained importance as the machine learning models that\nachieve state-of-the-art performance on large-scale image classification,\nobject detection and natural language processing tasks. In this paper, we\nconsider noisy binary neural networks, where each neuron has a non-zero\nprobability of producing an incorrect output. These noisy models may arise from\nbiological, physical and electronic contexts and constitute an important class\nof models that are relevant to the physical world. Intuitively, the number of\nneurons in such systems has to grow to compensate for the noise while\nmaintaining the same level of expressive power and computation reliability. Our\nkey finding is a lower bound for the required number of neurons in noisy neural\nnetworks, which is first of its kind. To prove this lower bound, we take an\ninformation theoretic approach and obtain a novel strong data processing\ninequality (SDPI), which not only generalizes the Evans-Schulman results for\nbinary symmetric channels to general channels, but also improves the tightness\ndrastically when applied to estimate end-to-end information contraction in\nnetworks. Our SDPI can be applied to various information processing systems,\nincluding neural networks and cellular automata. Applying the SDPI in noisy\nbinary neural networks, we obtain our key lower bound and investigate its\nimplications on network depth-width trade-offs, our results suggest a\ndepth-width trade-off for noisy neural networks that is very different from the\nestablished understanding regarding noiseless neural networks. Furthermore, we\napply the SDPI to study fault-tolerant cellular automata and obtain bounds on\nthe error correction overheads and the relaxation time. This paper offers new\nunderstanding of noisy information processing systems through the lens of\ninformation theory.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 00:01:45 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 17:19:25 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhou", "Chuteng", ""], ["Zhuang", "Quntao", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2101.11751", "submitter": "Mohit Yadav", "authors": "Mohit Yadav, Daniel Sheldon, Cameron Musco", "title": "Faster Kernel Interpolation for Gaussian Processes", "comments": "To appear, Artificial Intelligence and Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge in scaling Gaussian Process (GP) regression to massive\ndatasets is that exact inference requires computation with a dense n x n kernel\nmatrix, where n is the number of data points. Significant work focuses on\napproximating the kernel matrix via interpolation using a smaller set of m\ninducing points. Structured kernel interpolation (SKI) is among the most\nscalable methods: by placing inducing points on a dense grid and using\nstructured matrix algebra, SKI achieves per-iteration time of O(n + m log m)\nfor approximate inference. This linear scaling in n enables inference for very\nlarge data sets; however the cost is per-iteration, which remains a limitation\nfor extremely large n. We show that the SKI per-iteration time can be reduced\nto O(m log m) after a single O(n) time precomputation step by reframing SKI as\nsolving a natural Bayesian linear regression problem with a fixed set of m\ncompact basis functions. With per-iteration complexity independent of the\ndataset size n for a fixed grid, our method scales to truly massive data sets.\nWe demonstrate speedups in practice for a wide range of m and n and apply the\nmethod to GP inference on a three-dimensional weather radar dataset with over\n100 million points.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 00:09:22 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Yadav", "Mohit", ""], ["Sheldon", "Daniel", ""], ["Musco", "Cameron", ""]]}, {"id": "2101.11775", "submitter": "Nirav Ajmeri", "authors": "Veljko Dubljevi\\'c (1), Sean Douglas (1), Jovan Milojevich (2), Nirav\n  Ajmeri (3), William A. Bauer (1), George F. List (1) and Munindar P. Singh\n  (1) ((1) North Carolina State University, (2) Oklahoma State University, (3)\n  University of Bristol)", "title": "Moral and Social Ramifications of Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Vehicles (AVs) raise important social and ethical concerns,\nespecially about accountability, dignity, and justice. We focus on the specific\nconcerns arising from how AV technology will affect the lives and livelihoods\nof professional and semi-professional drivers. Whereas previous studies of such\nconcerns have focused on the opinions of experts, we seek to understand these\nethical and societal challenges from the perspectives of the drivers\nthemselves.\n  To this end, we adopted a qualitative research methodology based on\nsemi-structured interviews. This is an established social science methodology\nthat helps understand the core concerns of stakeholders in depth by avoiding\nthe biases of superficial methods such as surveys.\n  We find that whereas drivers agree with the experts that AVs will\nsignificantly impact transportation systems, they are apprehensive about the\nprospects for their livelihoods and dismiss the suggestions that driving jobs\nare unsatisfying and their profession does not merit protection.\n  By showing how drivers differ from the experts, our study has ramifications\nbeyond AVs to AI and other advanced technologies. Our findings suggest that\nqualitative research applied to the relevant, especially disempowered,\nstakeholders is essential to ensuring that new technologies are introduced\nethically.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 01:46:52 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 14:15:15 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Dubljevi\u0107", "Veljko", ""], ["Douglas", "Sean", ""], ["Milojevich", "Jovan", ""], ["Ajmeri", "Nirav", ""], ["Bauer", "William A.", ""], ["List", "George F.", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2101.11812", "submitter": "Shaoxiong Wang", "authors": "Chen Wang, Shaoxiong Wang, Branden Romero, Filipe Veiga, Edward\n  Adelson", "title": "SwingBot: Learning Physical Features from In-hand Tactile Exploration\n  for Dynamic Swing-up Manipulation", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several robot manipulation tasks are extremely sensitive to variations of the\nphysical properties of the manipulated objects. One such task is manipulating\nobjects by using gravity or arm accelerations, increasing the importance of\nmass, center of mass, and friction information. We present SwingBot, a robot\nthat is able to learn the physical features of a held object through tactile\nexploration. Two exploration actions (tilting and shaking) provide the tactile\ninformation used to create a physical feature embedding space. With this\nembedding, SwingBot is able to predict the swing angle achieved by a robot\nperforming dynamic swing-up manipulations on a previously unseen object. Using\nthese predictions, it is able to search for the optimal control parameters for\na desired swing-up angle. We show that with the learned physical features our\nend-to-end self-supervised learning pipeline is able to substantially improve\nthe accuracy of swinging up unseen objects. We also show that objects with\nsimilar dynamics are closer to each other on the embedding space and that the\nembedding can be disentangled into values of specific physical properties.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 04:35:15 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Wang", "Chen", ""], ["Wang", "Shaoxiong", ""], ["Romero", "Branden", ""], ["Veiga", "Filipe", ""], ["Adelson", "Edward", ""]]}, {"id": "2101.11832", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (Montreal AI Ethics Institute and Microsoft)", "title": "Making Responsible AI the Norm rather than the Exception", "comments": "A report prepared by the Montreal AI Ethics Institute for the\n  National Security Commission on Artificial Intelligence in response to their\n  Key Considerations for Responsible Development and Fielding of Artificial\n  Intelligence document; 26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report prepared by the Montreal AI Ethics Institute provides\nrecommendations in response to the National Security Commission on Artificial\nIntelligence (NSCAI) Key Considerations for Responsible Development and\nFielding of Artificial Intelligence document. The report centres on the idea\nthat Responsible AI should be made the Norm rather than an Exception. It does\nso by utilizing the guiding principles of: (1) alleviating friction in existing\nworkflows, (2) empowering stakeholders to get buy-in, and (3) conducting an\neffective translation of abstract standards into actionable engineering\npractices. After providing some overarching comments on the document from the\nNSCAI, the report dives into the primary contribution of an actionable\nframework to help operationalize the ideas presented in the document from the\nNSCAI. The framework consists of: (1) a learning, knowledge, and information\nexchange (LKIE), (2) the Three Ways of Responsible AI, (3) an\nempirically-driven risk-prioritization matrix, and (4) achieving the right\nlevel of complexity. All components reinforce each other to move from\nprinciples to practice in service of making Responsible AI the norm rather than\nthe exception.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 06:39:01 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 08:23:05 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Gupta", "Abhishek", "", "Montreal AI Ethics Institute and Microsoft"]]}, {"id": "2101.11836", "submitter": "Hrituraj Singh", "authors": "Hrituraj Singh, Gaurav Verma, Aparna Garimella, Balaji Vasan\n  Srinivasan", "title": "DRAG: Director-Generator Language Modelling Framework for Non-Parallel\n  Author Stylized Rewriting", "comments": "Accepted as Long Paper to EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Author stylized rewriting is the task of rewriting an input text in a\nparticular author's style. Recent works in this area have leveraged\nTransformer-based language models in a denoising autoencoder setup to generate\nauthor stylized text without relying on a parallel corpus of data. However,\nthese approaches are limited by the lack of explicit control of target\nattributes and being entirely data-driven. In this paper, we propose a\nDirector-Generator framework to rewrite content in the target author's style,\nspecifically focusing on certain target attributes. We show that our proposed\nframework works well even with a limited-sized target author corpus. Our\nexperiments on corpora consisting of relatively small-sized text authored by\nthree distinct authors show significant improvements upon existing works to\nrewrite input texts in target author's style. Our quantitative and qualitative\nanalyses further show that our model has better meaning retention and results\nin more fluent generations.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 06:52:40 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Singh", "Hrituraj", ""], ["Verma", "Gaurav", ""], ["Garimella", "Aparna", ""], ["Srinivasan", "Balaji Vasan", ""]]}, {"id": "2101.11844", "submitter": "Iena Petronella Derks", "authors": "Iena Petronella Derks and Alta de Waal", "title": "A Taxonomy of Explainable Bayesian Networks", "comments": null, "journal-ref": "In: Gerber A. (eds) Artificial Intelligence Research. SACAIR 2021.\n  Communications in Computer and Information Science, vol 1342. Springer, Cham\n  (2020)", "doi": "10.1007/978-3-030-66151-9_14", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI), and in particular, the explainability thereof,\nhas gained phenomenal attention over the last few years. Whilst we usually do\nnot question the decision-making process of these systems in situations where\nonly the outcome is of interest, we do however pay close attention when these\nsystems are applied in areas where the decisions directly influence the lives\nof humans. It is especially noisy and uncertain observations close to the\ndecision boundary which results in predictions which cannot necessarily be\nexplained that may foster mistrust among end-users. This drew attention to AI\nmethods for which the outcomes can be explained. Bayesian networks are\nprobabilistic graphical models that can be used as a tool to manage\nuncertainty. The probabilistic framework of a Bayesian network allows for\nexplainability in the model, reasoning and evidence. The use of these methods\nis mostly ad hoc and not as well organised as explainability methods in the\nwider AI research field. As such, we introduce a taxonomy of explainability in\nBayesian networks. We extend the existing categorisation of explainability in\nthe model, reasoning or evidence to include explanation of decisions. The\nexplanations obtained from the explainability methods are illustrated by means\nof a simple medical diagnostic scenario. The taxonomy introduced in this paper\nhas the potential not only to encourage end-users to efficiently communicate\noutcomes obtained, but also support their understanding of how and, more\nimportantly, why certain predictions were made.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 07:29:57 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Derks", "Iena Petronella", ""], ["de Waal", "Alta", ""]]}, {"id": "2101.11870", "submitter": "Anthony Hunter", "authors": "Emmanuel Hadoux and Anthony Hunter and Sylwia Polberg", "title": "Strategic Argumentation Dialogues for Persuasion: Framework and\n  Experiments Based on Modelling the Beliefs and Concerns of the Persuadee", "comments": "The Data Appendix containing the arguments, argument graphs,\n  assignment of concerns to arguments, preferences over concerns, and\n  assignment of beliefs to arguments, is available at the link\n  http://www0.cs.ucl.ac.uk/staff/a.hunter/papers/unistudydata.zip The code is\n  available at https://github.com/ComputationalPersuasion/MCCP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persuasion is an important and yet complex aspect of human intelligence. When\nundertaken through dialogue, the deployment of good arguments, and therefore\ncounterarguments, clearly has a significant effect on the ability to be\nsuccessful in persuasion. Two key dimensions for determining whether an\nargument is good in a particular dialogue are the degree to which the intended\naudience believes the argument and counterarguments, and the impact that the\nargument has on the concerns of the intended audience. In this paper, we\npresent a framework for modelling persuadees in terms of their beliefs and\nconcerns, and for harnessing these models in optimizing the choice of move in\npersuasion dialogues. Our approach is based on the Monte Carlo Tree Search\nwhich allows optimization in real-time. We provide empirical results of a study\nwith human participants showing that our automated persuasion system based on\nthis technology is superior to a baseline system that does not take the beliefs\nand concerns into account in its strategy.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 08:49:24 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Hadoux", "Emmanuel", ""], ["Hunter", "Anthony", ""], ["Polberg", "Sylwia", ""]]}, {"id": "2101.11881", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Ayush Jain, Divyanshu Singh Chauhan", "title": "Deep learning via LSTM models for COVID-19 infection forecasting in\n  India", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have entered an era of a pandemic that has shaken the world with major\nimpact to medical systems, economics and agriculture. Prominent computational\nand mathematical models have been unreliable due to the complexity of the\nspread of infections. Moreover, lack of data collection and reporting makes any\nsuch modelling attempts unreliable. Hence we need to re-look at the situation\nwith the latest data sources and most comprehensive forecasting models. Deep\nlearning models such as recurrent neural networks are well suited for modelling\ntemporal sequences. In this paper, prominent recurrent neural networks, in\nparticular \\textit{long short term memory} (LSTMs) networks, bidirectional\nLSTM, and encoder-decoder LSTM models for multi-step (short-term) forecasting\nthe spread of COVID-infections among selected states in India. We select states\nwith COVID-19 hotpots in terms of the rate of infections and compare with\nstates where infections have been contained or reached their peak and provide\ntwo months ahead forecast that shows that cases will slowly decline. Our\nresults show that long-term forecasts are promising which motivates the\napplication of the method in other countries or areas. We note that although we\nmade some progress in forecasting, the challenges in modelling remain due to\ndata and difficulty in capturing factors such as population density, travel\nlogistics, and social aspects such culture and lifestyle.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 09:19:10 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Chandra", "Rohitash", ""], ["Jain", "Ayush", ""], ["Chauhan", "Divyanshu Singh", ""]]}, {"id": "2101.11885", "submitter": "Tineke Blom", "authors": "Tineke Blom and Joris M. Mooij", "title": "Causality and independence in perfectly adapted dynamical systems", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perfect adaptation in a dynamical system is the phenomenon that one or more\nvariables have an initial transient response to a persistent change in an\nexternal stimulus but revert to their original value as the system converges to\nequilibrium. The causal ordering algorithm can be used to construct an\nequilibrium causal ordering graph that represents causal relations and a Markov\nordering graph that implies conditional independences from a set of equilibrium\nequations. Based on this, we formulate sufficient graphical conditions to\nidentify perfect adaptation from a set of first-order differential equations.\nFurthermore, we give sufficient conditions to test for the presence of perfect\nadaptation in experimental equilibrium data. We apply our ideas to a simple\nmodel for a protein signalling pathway and test its predictions both in\nsimulations and on real-world protein expression data. We demonstrate that\nperfect adaptation in this model can explain why the presence and orientation\nof edges in the output of causal discovery algorithms does not always appear to\nagree with the direction of edges in biological consensus networks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 09:28:58 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Blom", "Tineke", ""], ["Mooij", "Joris M.", ""]]}, {"id": "2101.11888", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva and Isabelle Augenstein", "title": "Does Typological Blinding Impede Cross-Lingual Sharing?", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bridging the performance gap between high- and low-resource languages has\nbeen the focus of much previous work. Typological features from databases such\nas the World Atlas of Language Structures (WALS) are a prime candidate for\nthis, as such data exists even for very low-resource languages. However,\nprevious work has only found minor benefits from using typological information.\nOur hypothesis is that a model trained in a cross-lingual setting will pick up\non typological cues from the input data, thus overshadowing the utility of\nexplicitly using such features. We verify this hypothesis by blinding a model\nto typological information, and investigate how cross-lingual sharing and\nperformance is impacted. Our model is based on a cross-lingual architecture in\nwhich the latent weights governing the sharing between languages is learnt\nduring training. We show that (i) preventing this model from exploiting\ntypology severely reduces performance, while a control experiment reaffirms\nthat (ii) encouraging sharing according to typology somewhat improves\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 09:32:08 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2101.11890", "submitter": "Timothy Atkinson", "authors": "Timothy Atkinson, Saeed Saremi, Faustino Gomez, Jonathan Masci", "title": "Automatic design of novel potential 3CL$^{\\text{pro}}$ and\n  PL$^{\\text{pro}}$ inhibitors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the goal of designing novel inhibitors for SARS-CoV-1 and SARS-CoV-2, we\npropose the general molecule optimization framework, Molecular Neural Assay\nSearch (MONAS), consisting of three components: a property predictor which\nidentifies molecules with specific desirable properties, an energy model which\napproximates the statistical similarity of a given molecule to known training\nmolecules, and a molecule search method. In this work, these components are\ninstantiated with graph neural networks (GNNs), Deep Energy Estimator Networks\n(DEEN) and Monte Carlo tree search (MCTS), respectively. This implementation is\nused to identify 120K molecules (out of 40-million explored) which the GNN\ndetermined to be likely SARS-CoV-1 inhibitors, and, at the same time, are\nstatistically close to the dataset used to train the GNN.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 09:47:23 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 07:32:36 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Atkinson", "Timothy", ""], ["Saremi", "Saeed", ""], ["Gomez", "Faustino", ""], ["Masci", "Jonathan", ""]]}, {"id": "2101.11946", "submitter": "Stefan Heidekr\\\"uger", "authors": "Stefan Heidekr\\\"uger, Paul Sutterer, Nils Kohring, Maximilian Fichtl,\n  and Martin Bichler", "title": "Equilibrium Learning in Combinatorial Auctions: Computing Approximate\n  Bayesian Nash Equilibria via Pseudogradient Dynamics", "comments": "This version includes the supplementary material with additional\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of combinatorial auctions (CA) as market mechanisms are\nprevalent in practice, yet their Bayesian Nash equilibria (BNE) remain poorly\nunderstood. Analytical solutions are known only for a few cases where the\nproblem can be reformulated as a tractable partial differential equation (PDE).\nIn the general case, finding BNE is known to be computationally hard. Previous\nwork on numerical computation of BNE in auctions has relied either on solving\nsuch PDEs explicitly, calculating pointwise best-responses in strategy space,\nor iteratively solving restricted subgames. In this study, we present a generic\nyet scalable alternative multi-agent equilibrium learning method that\nrepresents strategies as neural networks and applies policy iteration based on\ngradient dynamics in self-play. Most auctions are ex-post nondifferentiable, so\ngradients may be unavailable or misleading, and we rely on suitable\npseudogradient estimates instead. Although it is well-known that gradient\ndynamics cannot guarantee convergence to NE in general, we observe fast and\nrobust convergence to approximate BNE in a wide variety of auctions and present\na sufficient condition for convergence\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 11:53:32 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 11:47:52 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Heidekr\u00fcger", "Stefan", ""], ["Sutterer", "Paul", ""], ["Kohring", "Nils", ""], ["Fichtl", "Maximilian", ""], ["Bichler", "Martin", ""]]}, {"id": "2101.11952", "submitter": "Xue Yang", "authors": "Xue Yang, Junchi Yan, Qi Ming, Wentao Wang, Xiaopeng Zhang, Qi Tian", "title": "Rethinking Rotated Object Detection with Gaussian Wasserstein Distance\n  Loss", "comments": "15 pages, 6 figures, 9 tables, accepted by ICML21, codes are\n  available at https://github.com/yangxue0827/RotationDetection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boundary discontinuity and its inconsistency to the final detection metric\nhave been the bottleneck for rotating detection regression loss design. In this\npaper, we propose a novel regression loss based on Gaussian Wasserstein\ndistance as a fundamental approach to solve the problem. Specifically, the\nrotated bounding box is converted to a 2-D Gaussian distribution, which enables\nto approximate the indifferentiable rotational IoU induced loss by the Gaussian\nWasserstein distance (GWD) which can be learned efficiently by gradient\nback-propagation. GWD can still be informative for learning even there is no\noverlapping between two rotating bounding boxes which is often the case for\nsmall object detection. Thanks to its three unique properties, GWD can also\nelegantly solve the boundary discontinuity and square-like problem regardless\nhow the bounding box is defined. Experiments on five datasets using different\ndetectors show the effectiveness of our approach. Codes are available at\nhttps://github.com/yangxue0827/RotationDetection.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 12:04:35 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 10:30:13 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yang", "Xue", ""], ["Yan", "Junchi", ""], ["Ming", "Qi", ""], ["Wang", "Wentao", ""], ["Zhang", "Xiaopeng", ""], ["Tian", "Qi", ""]]}, {"id": "2101.11954", "submitter": "Tathagata Raha", "authors": "Tathagata Raha, Vijayasaradhi Indurthi, Aayush Upadhyaya, Jeevesh\n  Kataria, Pramud Bommakanti, Vikram Keswani, Vasudeva Varma", "title": "Identifying COVID-19 Fake News in Social Media", "comments": "CONSTRAINT@AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evolution of social media platforms have empowered everyone to access\ninformation easily. Social media users can easily share information with the\nrest of the world. This may sometimes encourage spread of fake news, which can\nresult in undesirable consequences. In this work, we train models which can\nidentify health news related to COVID-19 pandemic as real or fake. Our models\nachieve a high F1-score of 98.64%. Our models achieve second place on the\nleaderboard, tailing the first position with a very narrow margin 0.05% points.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 12:12:50 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 22:27:07 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Raha", "Tathagata", ""], ["Indurthi", "Vijayasaradhi", ""], ["Upadhyaya", "Aayush", ""], ["Kataria", "Jeevesh", ""], ["Bommakanti", "Pramud", ""], ["Keswani", "Vikram", ""], ["Varma", "Vasudeva", ""]]}, {"id": "2101.11956", "submitter": "Pere-Llu\\'is Huguet Cabot", "authors": "Pere-Llu\\'is Huguet-Cabot and David Abadi and Agneta Fischer and\n  Ekaterina Shutova", "title": "Us vs. Them: A Dataset of Populist Attitudes, News Bias and Emotions", "comments": "Camera-ready version in EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational modelling of political discourse tasks has become an\nincreasingly important area of research in natural language processing.\nPopulist rhetoric has risen across the political sphere in recent years;\nhowever, computational approaches to it have been scarce due to its complex\nnature. In this paper, we present the new $\\textit{Us vs. Them}$ dataset,\nconsisting of 6861 Reddit comments annotated for populist attitudes and the\nfirst large-scale computational models of this phenomenon. We investigate the\nrelationship between populist mindsets and social groups, as well as a range of\nemotions typically associated with these. We set a baseline for two tasks\nrelated to populist attitudes and present a set of multi-task learning models\nthat leverage and demonstrate the importance of emotion and group\nidentification as auxiliary tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 12:18:19 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 21:53:40 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 17:42:12 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Huguet-Cabot", "Pere-Llu\u00eds", ""], ["Abadi", "David", ""], ["Fischer", "Agneta", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2101.11967", "submitter": "Patrick Mannion", "authors": "David O'Callaghan and Patrick Mannion", "title": "Exploring the Impact of Tunable Agents in Sequential Social Dilemmas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When developing reinforcement learning agents, the standard approach is to\ntrain an agent to converge to a fixed policy that is as close to optimal as\npossible for a single fixed reward function. If different agent behaviour is\nrequired in the future, an agent trained in this way must normally be either\nfully or partially retrained, wasting valuable time and resources. In this\nstudy, we leverage multi-objective reinforcement learning to create tunable\nagents, i.e. agents that can adopt a range of different behaviours according to\nthe designer's preferences, without the need for retraining. We apply this\ntechnique to sequential social dilemmas, settings where there is inherent\ntension between individual and collective rationality. Learning a single fixed\npolicy in such settings leaves one at a significant disadvantage if the\nopponents' strategies change after learning is complete. In our work, we\ndemonstrate empirically that the tunable agents framework allows easy adaption\nbetween cooperative and competitive behaviours in sequential social dilemmas\nwithout the need for retraining, allowing a single trained agent model to be\nadjusted to cater for a wide range of behaviours and opponent strategies.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 12:44:31 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["O'Callaghan", "David", ""], ["Mannion", "Patrick", ""]]}, {"id": "2101.11974", "submitter": "Zeerak Waseem Butt", "authors": "Zeerak Waseem, Smarika Lulz, Joachim Bingel, Isabelle Augenstein", "title": "Disembodied Machine Learning: On the Illusion of Objectivity in NLP", "comments": "In review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning seeks to identify and encode bodies of knowledge within\nprovided datasets. However, data encodes subjective content, which determines\nthe possible outcomes of the models trained on it. Because such subjectivity\nenables marginalisation of parts of society, it is termed (social) `bias' and\nsought to be removed. In this paper, we contextualise this discourse of bias in\nthe ML community against the subjective choices in the development process.\nThrough a consideration of how choices in data and model development construct\nsubjectivity, or biases that are represented in a model, we argue that\naddressing and mitigating biases is near-impossible. This is because both data\nand ML models are objects for which meaning is made in each step of the\ndevelopment pipeline, from data selection over annotation to model training and\nanalysis. Accordingly, we find the prevalent discourse of bias limiting in its\nability to address social marginalisation. We recommend to be conscientious of\nthis, and to accept that de-biasing methods only correct for a fraction of\nbiases.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 12:58:39 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Waseem", "Zeerak", ""], ["Lulz", "Smarika", ""], ["Bingel", "Joachim", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2101.11981", "submitter": "Yaqi Xie", "authors": "Yaqi Xie, Fan Zhou, Harold Soh", "title": "Embedding Symbolic Temporal Knowledge into Deep Sequential Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences and time-series often arise in robot tasks, e.g., in activity\nrecognition and imitation learning. In recent years, deep neural networks\n(DNNs) have emerged as an effective data-driven methodology for processing\nsequences given sufficient training data and compute resources. However, when\ndata is limited, simpler models such as logic/rule-based methods work\nsurprisingly well, especially when relevant prior knowledge is applied in their\nconstruction. However, unlike DNNs, these \"structured\" models can be difficult\nto extend, and do not work well with raw unstructured data. In this work, we\nseek to learn flexible DNNs, yet leverage prior temporal knowledge when\navailable. Our approach is to embed symbolic knowledge expressed as linear\ntemporal logic (LTL) and use these embeddings to guide the training of deep\nmodels. Specifically, we construct semantic-based embeddings of automata\ngenerated from LTL formula via a Graph Neural Network. Experiments show that\nthese learnt embeddings can lead to improvements in downstream robot tasks such\nas sequential action recognition and imitation learning.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 13:17:46 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Xie", "Yaqi", ""], ["Zhou", "Fan", ""], ["Soh", "Harold", ""]]}, {"id": "2101.11987", "submitter": "Shankar Gangisetty", "authors": "Sindhu Hegde and Shankar Gangisetty", "title": "PIG-Net: Inception based Deep Learning Architecture for 3D Point Cloud\n  Segmentation", "comments": "11 pages, 5 Figures, 6 Tables, Accepted in Computers & Graphics\n  Journal 2021", "journal-ref": null, "doi": "10.1016/j.cag.2021.01.004", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Point clouds, being the simple and compact representation of surface geometry\nof 3D objects, have gained increasing popularity with the evolution of deep\nlearning networks for classification and segmentation tasks. Unlike human,\nteaching the machine to analyze the segments of an object is a challenging task\nand quite essential in various machine vision applications. In this paper, we\naddress the problem of segmentation and labelling of the 3D point clouds by\nproposing a inception based deep network architecture called PIG-Net, that\neffectively characterizes the local and global geometric details of the point\nclouds. In PIG-Net, the local features are extracted from the transformed input\npoints using the proposed inception layers and then aligned by feature\ntransform. These local features are aggregated using the global average pooling\nlayer to obtain the global features. Finally, feed the concatenated local and\nglobal features to the convolution layers for segmenting the 3D point clouds.\nWe perform an exhaustive experimental analysis of the PIG-Net architecture on\ntwo state-of-the-art datasets, namely, ShapeNet [1] and PartNet [2]. We\nevaluate the effectiveness of our network by performing ablation study.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 13:27:55 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Hegde", "Sindhu", ""], ["Gangisetty", "Shankar", ""]]}, {"id": "2101.11992", "submitter": "Esther Derman", "authors": "Esther Derman, Gal Dalal, Shie Mannor", "title": "Acting in Delayed Environments with Non-Stationary Markov Policies", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard Markov Decision Process (MDP) formulation hinges on the\nassumption that an action is executed immediately after it was chosen. However,\nassuming it is often unrealistic and can lead to catastrophic failures in\napplications such as robotic manipulation, cloud computing, and finance. We\nintroduce a framework for learning and planning in MDPs where the\ndecision-maker commits actions that are executed with a delay of $m$ steps. The\nbrute-force state augmentation baseline where the state is concatenated to the\nlast $m$ committed actions suffers from an exponential complexity in $m$, as we\nshow for policy iteration. We then prove that with execution delay,\ndeterministic Markov policies in the original state-space are sufficient for\nattaining maximal reward, but need to be non-stationary. As for stationary\nMarkov policies, we show they are sub-optimal in general. Consequently, we\ndevise a non-stationary Q-learning style model-based algorithm that solves\ndelayed execution tasks without resorting to state-augmentation. Experiments on\ntabular, physical, and Atari domains reveal that it converges quickly to high\nperformance even for substantial delays, while standard approaches that either\nignore the delay or rely on state-augmentation struggle or fail due to\ndivergence. The code is available at\nhttps://github.com/galdl/rl_delay_basic.git.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 13:35:37 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 08:40:13 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Derman", "Esther", ""], ["Dalal", "Gal", ""], ["Mannor", "Shie", ""]]}, {"id": "2101.12002", "submitter": "Sebastien Destercke", "authors": "Soundouss Messoudi, S\\'ebastien Destercke, Sylvain Rousseau", "title": "Copula-based conformal prediction for Multi-Target Regression", "comments": "17 pages, 8 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are relatively few works dealing with conformal prediction for\nmulti-task learning issues, and this is particularly true for multi-target\nregression. This paper focuses on the problem of providing valid (i.e.,\nfrequency calibrated) multi-variate predictions. To do so, we propose to use\ncopula functions applied to deep neural networks for inductive conformal\nprediction. We show that the proposed method ensures efficiency and validity\nfor multi-target regression problems on various data sets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 14:06:25 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Messoudi", "Soundouss", ""], ["Destercke", "S\u00e9bastien", ""], ["Rousseau", "Sylvain", ""]]}, {"id": "2101.12015", "submitter": "Vinicius Carid\\'a", "authors": "Paulo Finardi, Jos\\'e Di\\'e Viegas, Gustavo T. Ferreira, Alex F.\n  Mansano, Vinicius F. Carid\\'a", "title": "BERTa\\'u: Ita\\'u BERT for digital customer service", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, three major topics received increased interest: deep\nlearning, NLP and conversational agents. Bringing these three topics together\nto create an amazing digital customer experience and indeed deploy in\nproduction and solve real-world problems is something innovative and\ndisruptive. We introduce a new Portuguese financial domain language\nrepresentation model called BERTa\\'u. BERTa\\'u is an uncased BERT-base trained\nfrom scratch with data from the Ita\\'u virtual assistant chatbot solution. Our\nnovel contribution is that BERTa\\'u pretrained language model requires less\ndata, reached state-of-the-art performance in three NLP tasks, and generates a\nsmaller and lighter model that makes the deployment feasible. We developed\nthree tasks to validate our model: information retrieval with Frequently Asked\nQuestions (FAQ) from Ita\\'u bank, sentiment analysis from our virtual assistant\ndata, and a NER solution. All proposed tasks are real-world solutions in\nproduction on our environment and the usage of a specialist model proved to be\neffective when compared to Google BERT multilingual and the DPRQuestionEncoder\nfrom Facebook, available at Hugging Face. The BERTa\\'u improves the performance\nin 22% of FAQ Retrieval MRR metric, 2.1% in Sentiment Analysis F1 score, 4.4%\nin NER F1 score and can also represent the same sequence in up to 66% fewer\ntokens when compared to \"shelf models\".\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 14:29:03 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 01:46:41 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 23:26:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Finardi", "Paulo", ""], ["Viegas", "Jos\u00e9 Di\u00e9", ""], ["Ferreira", "Gustavo T.", ""], ["Mansano", "Alex F.", ""], ["Carid\u00e1", "Vinicius F.", ""]]}, {"id": "2101.12016", "submitter": "Peter Bajcsy", "authors": "Peter Bajcsy and Michael Majurski", "title": "Baseline Pruning-Based Approach to Trojan Detection in Neural Networks", "comments": "The funding for all authors was provided by IARPA:\n  IARPA-20001-D2020-2007180011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper addresses the problem of detecting trojans in neural networks\n(NNs) by analyzing systematically pruned NN models. Our pruning-based approach\nconsists of three main steps. First, detect any deviations from the reference\nlook-up tables of model file sizes and model graphs. Next, measure the accuracy\nof a set of systematically pruned NN models following multiple pruning schemas.\nFinally, classify a NN model as clean or poisoned by applying a mapping between\naccuracy measurements and NN model labels. This work outlines a theoretical and\nexperimental framework for finding the optimal mapping over a large search\nspace of pruning parameters. Based on our experiments using Round 1 and Round 2\nTrojAI Challenge datasets, the approach achieves average classification\naccuracy of 69.73 % and 82.41% respectively with an average processing time of\nless than 60 s per model. For both datasets random guessing would produce 50%\nclassification accuracy. Reference model graphs and source code are available\nfrom GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 23:10:31 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 14:58:21 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bajcsy", "Peter", ""], ["Majurski", "Michael", ""]]}, {"id": "2101.12031", "submitter": "Mohit Sewak", "authors": "Hemant Rathore and Sanjay K. Sahay and Piyush Nikam and Mohit Sewak", "title": "Robust Android Malware Detection System against Adversarial Attacks\n  using Q-Learning", "comments": "Inf Syst Front (2020)", "journal-ref": null, "doi": "10.1007/s10796-020-10083-8", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art Android malware detection systems are based on\nmachine learning and deep learning models. Despite having superior performance,\nthese models are susceptible to adversarial attacks. Therefore in this paper,\nwe developed eight Android malware detection models based on machine learning\nand deep neural network and investigated their robustness against adversarial\nattacks. For this purpose, we created new variants of malware using\nReinforcement Learning, which will be misclassified as benign by the existing\nAndroid malware detection models. We propose two novel attack strategies,\nnamely single policy attack and multiple policy attack using reinforcement\nlearning for white-box and grey-box scenario respectively. Putting ourselves in\nthe adversary's shoes, we designed adversarial attacks on the detection models\nwith the goal of maximizing fooling rate, while making minimum modifications to\nthe Android application and ensuring that the app's functionality and behavior\ndo not change. We achieved an average fooling rate of 44.21% and 53.20% across\nall the eight detection models with a maximum of five modifications using a\nsingle policy attack and multiple policy attack, respectively. The highest\nfooling rate of 86.09% with five changes was attained against the decision\ntree-based model using the multiple policy approach. Finally, we propose an\nadversarial defense strategy that reduces the average fooling rate by threefold\nto 15.22% against a single policy attack, thereby increasing the robustness of\nthe detection models i.e. the proposed model can effectively detect variants\n(metamorphic) of malware. The experimental analysis shows that our proposed\nAndroid malware detection system using reinforcement learning is more robust\nagainst adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 16:45:57 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Rathore", "Hemant", ""], ["Sahay", "Sanjay K.", ""], ["Nikam", "Piyush", ""], ["Sewak", "Mohit", ""]]}, {"id": "2101.12047", "submitter": "Samuel Alexander", "authors": "Samuel Alexander, Bill Hibbard", "title": "Measuring Intelligence and Growth Rate: Variations on Hibbard's\n  Intelligence Measure", "comments": "25 pages", "journal-ref": "Journal of Artificial General Intelligence 12(1), 2021", "doi": "10.2478/jagi-2021-0001", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In 2011, Hibbard suggested an intelligence measure for agents who compete in\nan adversarial sequence prediction game. We argue that Hibbard's idea should\nactually be considered as two separate ideas: first, that the intelligence of\nsuch agents can be measured based on the growth rates of the runtimes of the\ncompetitors that they defeat; and second, one specific (somewhat arbitrary)\nmethod for measuring said growth rates. Whereas Hibbard's intelligence measure\nis based on the latter growth-rate-measuring method, we survey other methods\nfor measuring function growth rates, and exhibit the resulting Hibbard-like\nintelligence measures and taxonomies. Of particular interest, we obtain\nintelligence taxonomies based on Big-O and Big-Theta notation systems, which\ntaxonomies are novel in that they challenge conventional notions of what an\nintelligence measure should look like. We discuss how intelligence measurement\nof sequence predictors can indirectly serve as intelligence measurement for\nagents with Artificial General Intelligence (AGIs).\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 01:54:08 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Alexander", "Samuel", ""], ["Hibbard", "Bill", ""]]}, {"id": "2101.12051", "submitter": "Shuai Wang", "authors": "Shuai Wang, Yuncong Hong, Rui Wang, Qi Hao, Yik-Chung Wu, and Derrick\n  Wing Kwan Ng", "title": "Edge Federated Learning Via Unit-Modulus Over-The-Air Computation\n  (Extended Version)", "comments": "34 pages, 6 figures, submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge federated learning (FL) is an emerging machine learning paradigm that\ntrains a global parametric model from distributed datasets via wireless\ncommunications. This paper proposes a unit-modulus over-the-air computation\n(UM-AirComp) framework to facilitate efficient edge federated learning, which\nsimultaneously uploads local model parameters and updates global model\nparameters via analog beamforming. The proposed framework avoids sophisticated\nbaseband signal processing, leading to low communication delays and\nimplementation costs. A training loss bound of UM-AirComp is derived and two\nlow-complexity algorithms, termed penalty alternating minimization (PAM) and\naccelerated gradient projection (AGP), are proposed to minimize the nonconvex\nnonsmooth loss bound. Simulation results show that the proposed UM-AirComp\nframework with PAM algorithm not only achieves a smaller mean square error of\nmodel parameters' estimation, training loss, and testing error, but also\nrequires a significantly shorter runtime than that of other benchmark schemes.\nMoreover, the proposed UM-AirComp framework with AGP algorithm achieves\nsatisfactory performance while reduces the computational complexity by orders\nof magnitude compared with existing optimization algorithms. Finally, we\ndemonstrate the implementation of UM-AirComp in a vehicle-to-everything\nautonomous driving simulation platform. It is found that autonomous driving\ntasks are more sensitive to model parameter errors than other tasks since the\nformer neural networks are more sophisticated containing sparser model\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 15:10:22 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 06:25:58 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 11:06:00 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Shuai", ""], ["Hong", "Yuncong", ""], ["Wang", "Rui", ""], ["Hao", "Qi", ""], ["Wu", "Yik-Chung", ""], ["Ng", "Derrick Wing Kwan", ""]]}, {"id": "2101.12072", "submitter": "Kashif Rasul", "authors": "Kashif Rasul, Calvin Seward, Ingmar Schuster, Roland Vollgraf", "title": "Autoregressive Denoising Diffusion Models for Multivariate Probabilistic\n  Time Series Forecasting", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139:8857-8868, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose \\texttt{TimeGrad}, an autoregressive model for\nmultivariate probabilistic time series forecasting which samples from the data\ndistribution at each time step by estimating its gradient. To this end, we use\ndiffusion probabilistic models, a class of latent variable models closely\nconnected to score matching and energy-based methods. Our model learns\ngradients by optimizing a variational bound on the data likelihood and at\ninference time converts white noise into a sample of the distribution of\ninterest through a Markov chain using Langevin sampling. We demonstrate\nexperimentally that the proposed autoregressive denoising diffusion model is\nthe new state-of-the-art multivariate probabilistic forecasting method on\nreal-world data sets with thousands of correlated dimensions. We hope that this\nmethod is a useful tool for practitioners and lays the foundation for future\nresearch in this area.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 15:46:10 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 12:32:30 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Rasul", "Kashif", ""], ["Seward", "Calvin", ""], ["Schuster", "Ingmar", ""], ["Vollgraf", "Roland", ""]]}, {"id": "2101.12078", "submitter": "Debayan Gupta", "authors": "Prashanthi Ramachandran, Shivam Agarwal, Arup Mondal, Aastha Shah,\n  Debayan Gupta", "title": "S++: A Fast and Deployable Secure-Computation Framework for\n  Privacy-Preserving Neural Network Training", "comments": "Appeared at the Second AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence (PPAI-21). (7 pages, technical paper.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce S++, a simple, robust, and deployable framework for training a\nneural network (NN) using private data from multiple sources, using\nsecret-shared secure function evaluation. In short, consider a virtual third\nparty to whom every data-holder sends their inputs, and which computes the\nneural network: in our case, this virtual third party is actually a set of\nservers which individually learn nothing, even with a malicious (but\nnon-colluding) adversary.\n  Previous work in this area has been limited to just one specific activation\nfunction: ReLU, rendering the approach impractical for many use-cases. For the\nfirst time, we provide fast and verifiable protocols for all common activation\nfunctions and optimize them for running in a secret-shared manner. The ability\nto quickly, verifiably, and robustly compute exponentiation, softmax, sigmoid,\netc., allows us to use previously written NNs without modification, vastly\nreducing developer effort and complexity of code. In recent times, ReLU has\nbeen found to converge much faster and be more computationally efficient as\ncompared to non-linear functions like sigmoid or tanh. However, we argue that\nit would be remiss not to extend the mechanism to non-linear functions such as\nthe logistic sigmoid, tanh, and softmax that are fundamental due to their\nability to express outputs as probabilities and their universal approximation\nproperty. Their contribution in RNNs and a few recent advancements also makes\nthem more relevant.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 15:48:54 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Ramachandran", "Prashanthi", ""], ["Agarwal", "Shivam", ""], ["Mondal", "Arup", ""], ["Shah", "Aastha", ""], ["Gupta", "Debayan", ""]]}, {"id": "2101.12097", "submitter": "Hamidreza Habibollahi Najaf Abadi", "authors": "Hamidreza Habibollahi Najaf Abadi", "title": "Adversarial Machine Learning Attacks on Condition-Based Maintenance\n  Capabilities", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Condition-based maintenance (CBM) strategies exploit machine learning models\nto assess the health status of systems based on the collected data from the\nphysical environment, while machine learning models are vulnerable to\nadversarial attacks. A malicious adversary can manipulate the collected data to\ndeceive the machine learning model and affect the CBM system's performance.\nAdversarial machine learning techniques introduced in the computer vision\ndomain can be used to make stealthy attacks on CBM systems by adding\nperturbation to data to confuse trained models. The stealthy nature causes\ndifficulty and delay in detection of the attacks. In this paper, adversarial\nmachine learning in the domain of CBM is introduced. A case study shows how\nadversarial machine learning can be used to attack CBM capabilities.\nAdversarial samples are crafted using the Fast Gradient Sign method, and the\nperformance of a CBM system under attack is investigated. The obtained results\nreveal that CBM systems are vulnerable to adversarial machine learning attacks\nand defense strategies need to be considered.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 16:34:04 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Abadi", "Hamidreza Habibollahi Najaf", ""]]}, {"id": "2101.12100", "submitter": "Giulio Rossolini", "authors": "Giulio Rossolini, Alessandro Biondi, Giorgio Carlo Buttazzo", "title": "Increasing the Confidence of Deep Neural Networks by Coverage Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The great performance of machine learning algorithms and deep neural networks\nin several perception and control tasks is pushing the industry to adopt such\ntechnologies in safety-critical applications, as autonomous robots and\nself-driving vehicles. At present, however, several issues need to be solved to\nmake deep learning methods more trustworthy, predictable, safe, and secure\nagainst adversarial attacks. Although several methods have been proposed to\nimprove the trustworthiness of deep neural networks, most of them are tailored\nfor specific classes of adversarial examples, hence failing to detect other\ncorner cases or unsafe inputs that heavily deviate from the training samples.\n  This paper presents a lightweight monitoring architecture based on coverage\nparadigms to enhance the model robustness against different unsafe inputs. In\nparticular, four coverage analysis methods are proposed and tested in the\narchitecture for evaluating multiple detection logics. Experimental results\nshow that the proposed approach is effective in detecting both powerful\nadversarial examples and out-of-distribution inputs, introducing limited\nextra-execution time and memory requirements.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 16:38:26 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Rossolini", "Giulio", ""], ["Biondi", "Alessandro", ""], ["Buttazzo", "Giorgio Carlo", ""]]}, {"id": "2101.12136", "submitter": "Ghada Sokar", "authors": "Ghada Sokar, Decebal Constantin Mocanu, Mykola Pechenizkiy", "title": "Self-Attention Meta-Learner for Continual Learning", "comments": null, "journal-ref": "20th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to provide intelligent agents capable of learning\nmultiple tasks sequentially with neural networks. One of its main challenging,\ncatastrophic forgetting, is caused by the neural networks non-optimal ability\nto learn in non-stationary distributions. In most settings of the current\napproaches, the agent starts from randomly initialized parameters and is\noptimized to master the current task regardless of the usefulness of the\nlearned representation for future tasks. Moreover, each of the future tasks\nuses all the previously learned knowledge although parts of this knowledge\nmight not be helpful for its learning. These cause interference among tasks,\nespecially when the data of previous tasks is not accessible. In this paper, we\npropose a new method, named Self-Attention Meta-Learner (SAM), which learns a\nprior knowledge for continual learning that permits learning a sequence of\ntasks, while avoiding catastrophic forgetting. SAM incorporates an attention\nmechanism that learns to select the particular relevant representation for each\nfuture task. Each task builds a specific representation branch on top of the\nselected knowledge, avoiding the interference between tasks. We evaluate the\nproposed method on the Split CIFAR-10/100 and Split MNIST benchmarks in the\ntask agnostic inference. We empirically show that we can achieve a better\nperformance than several state-of-the-art methods for continual learning by\nbuilding on the top of selected representation learned by SAM. We also show the\nrole of the meta-attention mechanism in boosting informative features\ncorresponding to the input data and identifying the correct target in the task\nagnostic inference. Finally, we demonstrate that popular existing continual\nlearning methods gain a performance boost when they adopt SAM as a starting\npoint.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 17:35:04 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Sokar", "Ghada", ""], ["Mocanu", "Decebal Constantin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2101.12153", "submitter": "Huansheng Ning Prof", "authors": "Sahraoui Dhelim, Nyothiri Aung, Mohammed Amine Bouras, Huansheng Ning\n  and Erik Cambria", "title": "A Survey on Personality-Aware Recommendation Systems", "comments": "Under review in Artificial Intelligence Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the emergence of personality computing as a new research field related\nto artificial intelligence and personality psychology, we have witnessed an\nunprecedented proliferation of personality-aware recommendation systems. Unlike\nconventional recommendation systems, these new systems solve traditional\nproblems such as the cold start and data sparsity problems. This survey aims to\nstudy and systematically classify personality-aware recommendation systems. To\nthe best of our knowledge, this survey is the first that focuses on\npersonality-aware recommendation systems. We explore the different design\nchoices of personality-aware recommendation systems, by comparing their\npersonality modeling methods, as well as their recommendation techniques.\nFurthermore, we present the commonly used datasets and point out some of the\nchallenges of personality-aware recommendation systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 18:03:23 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Dhelim", "Sahraoui", ""], ["Aung", "Nyothiri", ""], ["Bouras", "Mohammed Amine", ""], ["Ning", "Huansheng", ""], ["Cambria", "Erik", ""]]}, {"id": "2101.12195", "submitter": "Willi Menapace", "authors": "Willi Menapace, St\\'ephane Lathuili\\`ere, Sergey Tulyakov, Aliaksandr\n  Siarohin, Elisa Ricci", "title": "Playable Video Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the unsupervised learning problem of playable video\ngeneration (PVG). In PVG, we aim at allowing a user to control the generated\nvideo by selecting a discrete action at every time step as when playing a video\ngame. The difficulty of the task lies both in learning semantically consistent\nactions and in generating realistic videos conditioned on the user input. We\npropose a novel framework for PVG that is trained in a self-supervised manner\non a large dataset of unlabelled videos. We employ an encoder-decoder\narchitecture where the predicted action labels act as bottleneck. The network\nis constrained to learn a rich action space using, as main driving loss, a\nreconstruction loss on the generated video. We demonstrate the effectiveness of\nthe proposed approach on several datasets with wide environment variety.\nFurther details, code and examples are available on our project page\nwilli-menapace.github.io/playable-video-generation-website.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 18:55:58 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Menapace", "Willi", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Tulyakov", "Sergey", ""], ["Siarohin", "Aliaksandr", ""], ["Ricci", "Elisa", ""]]}, {"id": "2101.12208", "submitter": "arXiv Admin", "authors": "Maritza Tynes, Mahboobeh Parsapoor", "title": "Meta-learning on Spectral Images of Electroencephalogram of\n  Schizophenics", "comments": "Withdrawn by arXiv administrators as co-author did not consent to\n  submit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Schizophrenia is a complex psychiatric disorder involving changes in thought\npatterns, perception, mood, and behavior. The diagnosis of schizophrenia is\nchallenging and requires that patients show two or more positive symptoms for\nat least one month. Delays in identifying this debilitating disorder can impede\na patient ability to receive much needed treatment. Advances in neuroimaging\nand machine learning algorithms can facilitate the diagnosis of schizophrenia\nand help clinicians to provide an accurate diagnosis of the disease. This paper\npresents a methodology for analyzing spectral images of Electroencephalography\ncollected from patients with schizophrenia using convolutional neural networks.\nIt also explains how we have developed accurate classifiers employing\nModel-Agnostic Meta-Learning and prototypical networks. Such classifiers have\nthe capacity to distinguish people with schizophrenia from healthy controls\nbased on their brain activity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 20:51:25 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 18:34:47 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Tynes", "Maritza", ""], ["Parsapoor", "Mahboobeh", ""]]}, {"id": "2101.12241", "submitter": "Rui Wang", "authors": "Rui Wang, Kai Gao, Daniel Nakhimovich, Jingjin Yu, Kostas E. Bekris", "title": "Uniform Object Rearrangement: From Complete Monotone Primitives to\n  Efficient Non-Monotone Informed Search", "comments": "7 pages. Submitted to IEEE International Conference on Robotics and\n  Automation (ICRA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object rearrangement is a widely-applicable and challenging task for robots.\nGeometric constraints must be carefully examined to avoid collisions and\ncombinatorial issues arise as the number of objects increases. This work\nstudies the algorithmic structure of rearranging uniform objects, where\nrobot-object collisions do not occur but object-object collisions have to be\navoided. The objective is minimizing the number of object transfers under the\nassumption that the robot can manipulate one object at a time. An efficiently\ncomputable decomposition of the configuration space is used to create a \"region\ngraph\", which classifies all continuous paths of equivalent collision\npossibilities. Based on this compact but rich representation, a complete\ndynamic programming primitive DFSDP performs a recursive depth first search to\nsolve monotone problems quickly, i.e., those instances that do not require\nobjects to be moved first to an intermediate buffer. DFSDP is extended to solve\nsingle-buffer, non-monotone instances, given a choice of an object and a\nbuffer. This work utilizes these primitives as local planners in an informed\nsearch framework for more general, non-monotone instances. The search utilizes\npartial solutions from the primitives to identify the most promising choice of\nobjects and buffers. Experiments demonstrate that the proposed solution returns\nnear-optimal paths with higher success rate, even for challenging non-monotone\ninstances, than other leading alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 19:22:39 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Wang", "Rui", ""], ["Gao", "Kai", ""], ["Nakhimovich", "Daniel", ""], ["Yu", "Jingjin", ""], ["Bekris", "Kostas E.", ""]]}, {"id": "2101.12338", "submitter": "Ting Han", "authors": "Ting Han, Sina Zarrie{\\ss}", "title": "Enabling Robots to Draw and Tell: Towards Visually Grounded Multimodal\n  Description Generation", "comments": "The 2nd Workshop on NLG for HRI colocated with The 13th International\n  Conference on Natural Language Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Socially competent robots should be equipped with the ability to perceive the\nworld that surrounds them and communicate about it in a human-like manner.\nRepresentative skills that exhibit such ability include generating image\ndescriptions and visually grounded referring expressions. In the NLG community,\nthese generation tasks are largely investigated in non-interactive and\nlanguage-only settings. However, in face-to-face interaction, humans often\ndeploy multiple modalities to communicate, forming seamless integration of\nnatural language, hand gestures and other modalities like sketches. To enable\nrobots to describe what they perceive with speech and sketches/gestures, we\npropose to model the task of generating natural language together with\nfree-hand sketches/hand gestures to describe visual scenes and real life\nobjects, namely, visually-grounded multimodal description generation. In this\npaper, we discuss the challenges and evaluation metrics of the task, and how\nthe task can benefit from progress recently made in the natural language\nprocessing and computer vision realms, where related topics such as visually\ngrounded NLG, distributional semantics, and photo-based sketch generation have\nbeen extensively studied.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 23:40:23 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Han", "Ting", ""], ["Zarrie\u00df", "Sina", ""]]}, {"id": "2101.12404", "submitter": "Navchetan Awasthi", "authors": "Navchetan Awasthi, Rohit Pardasani and Swati Gupta", "title": "Multi-Threshold Attention U-Net (MTAU) based Model for Multimodal Brain\n  Tumor Segmentation in MRI scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV physics.med-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Gliomas are one of the most frequent brain tumors and are classified into\nhigh grade and low grade gliomas. The segmentation of various regions such as\ntumor core, enhancing tumor etc. plays an important role in determining\nseverity and prognosis. Here, we have developed a multi-threshold model based\non attention U-Net for identification of various regions of the tumor in\nmagnetic resonance imaging (MRI). We propose a multi-path segmentation and\nbuilt three separate models for the different regions of interest. The proposed\nmodel achieved mean Dice Coefficient of 0.59, 0.72, and 0.61 for enhancing\ntumor, whole tumor and tumor core respectively on the training dataset. The\nsame model gave mean Dice Coefficient of 0.57, 0.73, and 0.61 on the validation\ndataset and 0.59, 0.72, and 0.57 on the test dataset.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 04:53:42 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Awasthi", "Navchetan", ""], ["Pardasani", "Rohit", ""], ["Gupta", "Swati", ""]]}, {"id": "2101.12414", "submitter": "Shane Barratt", "authors": "Shane Barratt, Yining Dong, Stephen Boyd", "title": "Low Rank Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of forecasting multiple values of the future of a\nvector time series, using some past values. This problem, and related ones such\nas one-step-ahead prediction, have a very long history, and there are a number\nof well-known methods for it, including vector auto-regressive models,\nstate-space methods, multi-task regression, and others. Our focus is on low\nrank forecasters, which break forecasting up into two steps: estimating a\nvector that can be interpreted as a latent state, given the past, and then\nestimating the future values of the time series, given the latent state\nestimate. We introduce the concept of forecast consistency, which means that\nthe estimates of the same value made at different times are consistent. We\nformulate the forecasting problem in general form, and focus on linear\nforecasters, for which we propose a formulation that can be solved via convex\noptimization. We describe a number of extensions and variations, including\nnonlinear forecasters, data weighting, the inclusion of auxiliary data, and\nadditional objective terms. We illustrate our methods with several examples.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 05:59:19 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Barratt", "Shane", ""], ["Dong", "Yining", ""], ["Boyd", "Stephen", ""]]}, {"id": "2101.12416", "submitter": "Shane Barratt", "authors": "Shane Barratt and Stephen Boyd", "title": "Covariance Prediction via Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting the covariance of a zero mean Gaussian\nvector, based on another feature vector. We describe a covariance predictor\nthat has the form of a generalized linear model, i.e., an affine function of\nthe features followed by an inverse link function that maps vectors to\nsymmetric positive definite matrices. The log-likelihood is a concave function\nof the predictor parameters, so fitting the predictor involves convex\noptimization. Such predictors can be combined with others, or recursively\napplied to improve performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 06:06:58 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Barratt", "Shane", ""], ["Boyd", "Stephen", ""]]}, {"id": "2101.12446", "submitter": "Matthew Olson", "authors": "Matthew L. Olson, Roli Khanna, Lawrence Neal, Fuxin Li, Weng-Keen Wong", "title": "Counterfactual State Explanations for Reinforcement Learning Agents via\n  Generative Deep Learning", "comments": "Full source code available at\n  https://github.com/mattolson93/counterfactual-state-explanations", "journal-ref": "Artificial Intelligence, 2021, 103455, ISSN 0004-3702", "doi": "10.1016/j.artint.2021.103455", "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Counterfactual explanations, which deal with \"why not?\" scenarios, can\nprovide insightful explanations to an AI agent's behavior. In this work, we\nfocus on generating counterfactual explanations for deep reinforcement learning\n(RL) agents which operate in visual input environments like Atari. We introduce\ncounterfactual state explanations, a novel example-based approach to\ncounterfactual explanations based on generative deep learning. Specifically, a\ncounterfactual state illustrates what minimal change is needed to an Atari game\nimage such that the agent chooses a different action. We also evaluate the\neffectiveness of counterfactual states on human participants who are not\nmachine learning experts. Our first user study investigates if humans can\ndiscern if the counterfactual state explanations are produced by the actual\ngame or produced by a generative deep learning approach. Our second user study\ninvestigates if counterfactual state explanations can help non-expert\nparticipants identify a flawed agent; we compare against a baseline approach\nbased on a nearest neighbor explanation which uses images from the actual game.\nOur results indicate that counterfactual state explanations have sufficient\nfidelity to the actual game images to enable non-experts to more effectively\nidentify a flawed RL agent compared to the nearest neighbor baseline and to\nhaving no explanation at all.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 07:43:41 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Olson", "Matthew L.", ""], ["Khanna", "Roli", ""], ["Neal", "Lawrence", ""], ["Li", "Fuxin", ""], ["Wong", "Weng-Keen", ""]]}, {"id": "2101.12476", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus", "title": "Beyond traditional assumptions in fair machine learning", "comments": "PhD Thesis submitted at the University of Cambridge, October 2020.\n  The thesis is based on a number of previous works also available on arxiv\n  (see Chapter 1)", "journal-ref": null, "doi": "10.17863/CAM.59055", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis scrutinizes common assumptions underlying traditional machine\nlearning approaches to fairness in consequential decision making. After\nchallenging the validity of these assumptions in real-world applications, we\npropose ways to move forward when they are violated. First, we show that group\nfairness criteria purely based on statistical properties of observed data are\nfundamentally limited. Revisiting this limitation from a causal viewpoint we\ndevelop a more versatile conceptual framework, causal fairness criteria, and\nfirst algorithms to achieve them. We also provide tools to analyze how\nsensitive a believed-to-be causally fair algorithm is to misspecifications of\nthe causal graph. Second, we overcome the assumption that sensitive data is\nreadily available in practice. To this end we devise protocols based on secure\nmulti-party computation to train, validate, and contest fair decision\nalgorithms without requiring users to disclose their sensitive data or decision\nmakers to disclose their models. Finally, we also accommodate the fact that\noutcome labels are often only observed when a certain decision has been made.\nWe suggest a paradigm shift away from training predictive models towards\ndirectly learning decisions to relax the traditional assumption that labels can\nalways be recorded. The main contribution of this thesis is the development of\ntheoretically substantiated and practically feasible methods to move research\non fair machine learning closer to real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 09:02:15 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Kilbertus", "Niki", ""]]}, {"id": "2101.12491", "submitter": "Francesco Salvetti", "authors": "Vittorio Mazzia, Francesco Salvetti and Marcello Chiaberge", "title": "Efficient-CapsNet: Capsule Network with Self-Attention Routing", "comments": "Accepted by Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep convolutional neural networks, assisted by architectural design\nstrategies, make extensive use of data augmentation techniques and layers with\na high number of feature maps to embed object transformations. That is highly\ninefficient and for large datasets implies a massive redundancy of features\ndetectors. Even though capsules networks are still in their infancy, they\nconstitute a promising solution to extend current convolutional networks and\nendow artificial visual perception with a process to encode more efficiently\nall feature affine transformations. Indeed, a properly working capsule network\nshould theoretically achieve higher results with a considerably lower number of\nparameters count due to intrinsic capability to generalize to novel viewpoints.\nNevertheless, little attention has been given to this relevant aspect. In this\npaper, we investigate the efficiency of capsule networks and, pushing their\ncapacity to the limits with an extreme architecture with barely 160K\nparameters, we prove that the proposed architecture is still able to achieve\nstate-of-the-art results on three different datasets with only 2% of the\noriginal CapsNet parameters. Moreover, we replace dynamic routing with a novel\nnon-iterative, highly parallelizable routing algorithm that can easily cope\nwith a reduced number of capsules. Extensive experimentation with other capsule\nimplementations has proved the effectiveness of our methodology and the\ncapability of capsule networks to efficiently embed visual representations more\nprone to generalization.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 09:56:44 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:34:26 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mazzia", "Vittorio", ""], ["Salvetti", "Francesco", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2101.12501", "submitter": "Thomas Chaffre", "authors": "Thomas Chaffre, Julien Moras, Adrien Chan-Hon-Tong, Julien Marzat,\n  Karl Sammut, Gilles Le Chenadec, Benoit Clement", "title": "Learning-based vs Model-free Adaptive Control of a MAV under Wind Gust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Navigation problems under unknown varying conditions are among the most\nimportant and well-studied problems in the control field. Classic model-based\nadaptive control methods can be applied only when a convenient model of the\nplant or environment is provided. Recent model-free adaptive control methods\naim at removing this dependency by learning the physical characteristics of the\nplant and/or process directly from sensor feedback. Although there have been\nprior attempts at improving these techniques, it remains an open question as to\nwhether it is possible to cope with real-world uncertainties in a control\nsystem that is fully based on either paradigm. We propose a conceptually simple\nlearning-based approach composed of a full state feedback controller, tuned\nrobustly by a deep reinforcement learning framework based on the Soft\nActor-Critic algorithm. We compare it, in realistic simulations, to a\nmodel-free controller that uses the same deep reinforcement learning framework\nfor the control of a micro aerial vehicle under wind gust. The results indicate\nthe great potential of learning-based adaptive control methods in modern\ndynamical systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 10:13:56 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 01:05:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chaffre", "Thomas", ""], ["Moras", "Julien", ""], ["Chan-Hon-Tong", "Adrien", ""], ["Marzat", "Julien", ""], ["Sammut", "Karl", ""], ["Chenadec", "Gilles Le", ""], ["Clement", "Benoit", ""]]}, {"id": "2101.12509", "submitter": "David Lindner", "authors": "David Lindner and Kyle Matoba and Alexander Meulemans", "title": "Challenges for Using Impact Regularizers to Avoid Negative Side Effects", "comments": "Presented at the SafeAI workshop at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Designing reward functions for reinforcement learning is difficult: besides\nspecifying which behavior is rewarded for a task, the reward also has to\ndiscourage undesired outcomes. Misspecified reward functions can lead to\nunintended negative side effects, and overall unsafe behavior. To overcome this\nproblem, recent work proposed to augment the specified reward function with an\nimpact regularizer that discourages behavior that has a big impact on the\nenvironment. Although initial results with impact regularizers seem promising\nin mitigating some types of side effects, important challenges remain. In this\npaper, we examine the main current challenges of impact regularizers and relate\nthem to fundamental design decisions. We discuss in detail which challenges\nrecent approaches address and which remain unsolved. Finally, we explore\npromising directions to overcome the unsolved challenges in preventing negative\nside effects with impact regularizers.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 10:32:51 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 13:49:47 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Lindner", "David", ""], ["Matoba", "Kyle", ""], ["Meulemans", "Alexander", ""]]}, {"id": "2101.12522", "submitter": "Haibin Wang", "authors": "Sujoy Sikdar, Xiaoxi Guo, Haibin Wang, Lirong Xia, Yongzhi Cao", "title": "Sequential Mechanisms for Multi-type Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several resource allocation problems involve multiple types of resources,\nwith a different agency being responsible for \"locally\" allocating the\nresources of each type, while a central planner wishes to provide a guarantee\non the properties of the final allocation given agents' preferences. We study\nthe relationship between properties of the local mechanisms, each responsible\nfor assigning all of the resources of a designated type, and the properties of\na sequential mechanism which is composed of these local mechanisms, one for\neach type, applied sequentially, under lexicographic preferences, a well\nstudied model of preferences over multiple types of resources in artificial\nintelligence and economics. We show that when preferences are O-legal, meaning\nthat agents share a common importance order on the types, sequential mechanisms\nsatisfy the desirable properties of anonymity, neutrality, non-bossiness, or\nPareto-optimality if and only if every local mechanism also satisfies the same\nproperty, and they are applied sequentially according to the order O. Our main\nresults are that under O-legal lexicographic preferences, every mechanism\nsatisfying strategyproofness and a combination of these properties must be a\nsequential composition of local mechanisms that are also strategyproof, and\nsatisfy the same combinations of properties.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 11:09:21 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 06:03:19 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sikdar", "Sujoy", ""], ["Guo", "Xiaoxi", ""], ["Wang", "Haibin", ""], ["Xia", "Lirong", ""], ["Cao", "Yongzhi", ""]]}, {"id": "2101.12584", "submitter": "Yakup Kutlu", "authors": "Yakup Kutlu, Z\\\"ulf\\\"u Alanoglu, Ahmet G\\\"ok\\c{c}en, Mustafa Yeniad", "title": "Raspberry Pi Based Intelligent Robot that Recognizes and Places Puzzle\n  Objects", "comments": "5 pages, in Turkish language, 8 figures, journal of intelligent\n  systems with applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study; in order to diagnose congestive heart failure (CHF) patients,\nnon-linear secondorder difference plot (SODP) obtained from raw 256 Hz sampled\nfrequency and windowed record with different time of ECG records are used. All\nof the data rows are labelled with their belongings to classify much more\nrealistically. SODPs are divided into different radius of quadrant regions and\nnumbers of the points fall in the quadrants are computed in order to extract\nfeature vectors. Fisher's linear discriminant, Naive Bayes, and artificial\nneural network are used as classifier. The results are considered in two step\nvalidation methods as general kfold cross-validation and patient based\ncross-validation. As a result, it is shown that using neural network classifier\nwith features obtained from SODP, the constructed system could distinguish\nnormal and CHF patients with 100% accuracy rate.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 18:58:59 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Kutlu", "Yakup", ""], ["Alanoglu", "Z\u00fclf\u00fc", ""], ["G\u00f6k\u00e7en", "Ahmet", ""], ["Yeniad", "Mustafa", ""]]}, {"id": "2101.12608", "submitter": "Mostafa Abdou", "authors": "Mostafa Abdou, Ana Valeria Gonzalez, Mariya Toneva, Daniel\n  Hershcovich, Anders S{\\o}gaard", "title": "Does injecting linguistic structure into language models lead to better\n  alignment with brain recordings?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists evaluate deep neural networks for natural language processing\nas possible candidate models for how language is processed in the brain. These\nmodels are often trained without explicit linguistic supervision, but have been\nshown to learn some linguistic structure in the absence of such supervision\n(Manning et al., 2020), potentially questioning the relevance of symbolic\nlinguistic theories in modeling such cognitive processes (Warstadt and Bowman,\n2020). We evaluate across two fMRI datasets whether language models align\nbetter with brain recordings, if their attention is biased by annotations from\nsyntactic or semantic formalisms. Using structure from dependency or minimal\nrecursion semantic annotations, we find alignments improve significantly for\none of the datasets. For another dataset, we see more mixed results. We present\nan extensive analysis of these results. Our proposed approach enables the\nevaluation of more targeted hypotheses about the composition of meaning in the\nbrain, expanding the range of possible scientific inferences a neuroscientist\ncould make, and opens up new opportunities for cross-pollination between\ncomputational neuroscience and linguistics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 14:42:02 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Abdou", "Mostafa", ""], ["Gonzalez", "Ana Valeria", ""], ["Toneva", "Mariya", ""], ["Hershcovich", "Daniel", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "2101.12639", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave and Swann Legras and V\\'eronique Ventos", "title": "Optimizing $\\alpha\\mu$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  $\\alpha\\mu$ is a search algorithm which repairs two defaults of Perfect\nInformation Monte Carlo search: strategy fusion and non locality. In this paper\nwe optimize $\\alpha\\mu$ for the game of Bridge, avoiding useless computations.\nThe proposed optimizations are general and apply to other imperfect information\nturn-based games. We define multiple optimizations involving Pareto fronts, and\nshow that these optimizations speed up the search. Some of these optimizations\nare cuts that stop the search at a node, while others keep track of which\npossible worlds have become redundant, avoiding unnecessary, costly\nevaluations. We also measure the benefits of parallelizing the double dummy\nsearches at the leaves of the $\\alpha\\mu$ search tree.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 15:20:03 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Cazenave", "Tristan", ""], ["Legras", "Swann", ""], ["Ventos", "V\u00e9ronique", ""]]}, {"id": "2101.12683", "submitter": "Roman Andriushchenko", "authors": "Roman Andriushchenko, Milan Ceska, Sebastian Junges, Joost-Pieter\n  Katoen", "title": "Inductive Synthesis for Probabilistic Programs Reaches New Horizons", "comments": "Full version of TACAS'21 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel method for the automated synthesis of\nprobabilistic programs. The starting point is a program sketch representing a\nfinite family of finite-state Markov chains with related but distinct\ntopologies, and a PCTL specification. The method builds on a novel inductive\noracle that greedily generates counter-examples (CEs) for violating programs\nand uses them to prune the family. These CEs leverage the semantics of the\nfamily in the form of bounds on its best- and worst-case behaviour provided by\na deductive oracle using an MDP abstraction. The method further monitors the\nperformance of the synthesis and adaptively switches between the inductive and\ndeductive reasoning. Our experiments demonstrate that the novel CE construction\nprovides a significantly faster and more effective pruning strategy leading to\nacceleration of the synthesis process on a wide range of benchmarks. For\nchallenging problems, such as the synthesis of decentralized\npartially-observable controllers, we reduce the run-time from a day to minutes.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 16:59:00 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Andriushchenko", "Roman", ""], ["Ceska", "Milan", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2101.12719", "submitter": "Emma Benjaminson", "authors": "Emma Benjaminson (1), Rebecca E. Taylor (1,2,3), Matthew Travers (4)\n  ((1) Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, (2)\n  Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA, (3)\n  Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh\n  PA, (4) Robotics Institute, Carnegie Mellon University, Pittsburgh, PA)", "title": "Predicting Nanorobot Shapes via Generative Models", "comments": "8 pages, 2 figures, accepted to Machine Learning for Engineering\n  Modeling, Simulation, and Design Workshop at Neural Information Processing\n  Systems 2020, December 12, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The field of DNA nanotechnology has made it possible to assemble, with high\nyields, different structures that have actionable properties. For example,\nresearchers have created components that can be actuated. An exciting next step\nis to combine these components into multifunctional nanorobots that could,\npotentially, perform complex tasks like swimming to a target location in the\nhuman body, detect an adverse reaction and then release a drug load to stop it.\nHowever, as we start to assemble more complex nanorobots, the yield of the\ndesired nanorobot begins to decrease as the number of possible component\ncombinations increases. Therefore, the ultimate goal of this work is to develop\na predictive model to maximize yield. However, training predictive models\ntypically requires a large dataset. For the nanorobots we are interested in\nassembling, this will be difficult to collect. This is because high-fidelity\ndata, which allows us to characterize the shape and size of individual\nstructures, is very time-consuming to collect, whereas low-fidelity data is\nreadily available but only captures bulk statistics for different processes.\nTherefore, this work combines low- and high-fidelity data to train a generative\nmodel using a two-step process. We first use a relatively small, high-fidelity\ndataset to train a generative model. At run time, the model takes low-fidelity\ndata and uses it to approximate the high-fidelity content. We do this by\nbiasing the model towards samples with specific properties as measured by\nlow-fidelity data. In this work we bias our distribution towards a desired node\ndegree of a graphical model that we take as a surrogate representation of the\nnanorobots that this work will ultimately focus on. We have not yet accumulated\na high-fidelity dataset of nanorobots, so we leverage the MolGAN architecture\n[1] and the QM9 small molecule dataset [2-3] to demonstrate our approach.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 18:29:51 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Benjaminson", "Emma", ""], ["Taylor", "Rebecca E.", ""], ["Travers", "Matthew", ""]]}]