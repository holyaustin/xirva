[{"id": "1208.0293", "submitter": "Christoph Lange", "authors": "Christoph Lange and Till Mossakowski and Oliver Kutz and Christian\n  Galinski and Michael Gr\\\"uninger and Daniel Couto Vale", "title": "The Distributed Ontology Language (DOL): Use Cases, Syntax, and\n  Extensibility", "comments": "Terminology and Knowledge Engineering Conference (TKE) 2012-06-20 to\n  2012-06-21 Madrid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Distributed Ontology Language (DOL) is currently being standardized\nwithin the OntoIOp (Ontology Integration and Interoperability) activity of\nISO/TC 37/SC 3. It aims at providing a unified framework for (1) ontologies\nformalized in heterogeneous logics, (2) modular ontologies, (3) links between\nontologies, and (4) annotation of ontologies. This paper presents the current\nstate of DOL's standardization. It focuses on use cases where distributed\nontologies enable interoperability and reusability. We demonstrate relevant\nfeatures of the DOL syntax and semantics and explain how these integrate into\nexisting knowledge engineering environments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 17:25:24 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Lange", "Christoph", ""], ["Mossakowski", "Till", ""], ["Kutz", "Oliver", ""], ["Galinski", "Christian", ""], ["Gr\u00fcninger", "Michael", ""], ["Vale", "Daniel Couto", ""]]}, {"id": "1208.1103", "submitter": "Bhuvaneswari", "authors": "N. S. Bhuvaneswari, R. Praveena, R. Divya", "title": "System identification and modeling for interacting and non-interacting\n  tank systems using intelligent techniques", "comments": "13 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System identification from the experimental data plays a vital role for model\nbased controller design. Derivation of process model from first principles is\noften difficult due to its complexity. The first stage in the development of\nany control and monitoring system is the identification and modeling of the\nsystem. Each model is developed within the context of a specific control\nproblem. Thus, the need for a general system identification framework is\nwarranted. The proposed framework should be able to adapt and emphasize\ndifferent properties based on the control objective and the nature of the\nbehavior of the system. Therefore, system identification has been a valuable\ntool in identifying the model of the system based on the input and output data\nfor the design of the controller. The present work is concerned with the\nidentification of transfer function models using statistical model\nidentification, process reaction curve method, ARX model, genetic algorithm and\nmodeling using neural network and fuzzy logic for interacting and non\ninteracting tank process. The identification technique and modeling used is\nprone to parameter change & disturbance. The proposed methods are used for\nidentifying the mathematical model and intelligent model of interacting and non\ninteracting process from the real time experimental data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2012 07:58:13 GMT"}], "update_date": "2012-08-07", "authors_parsed": [["Bhuvaneswari", "N. S.", ""], ["Praveena", "R.", ""], ["Divya", "R.", ""]]}, {"id": "1208.1136", "submitter": "Jasper De Bock", "authors": "Jasper De Bock and Gert de Cooman", "title": "Credal nets under epistemic irrelevance", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to credal nets, which are graphical models that\ngeneralise Bayesian nets to imprecise probability. Instead of applying the\ncommonly used notion of strong independence, we replace it by the weaker notion\nof epistemic irrelevance. We show how assessments of epistemic irrelevance\nallow us to construct a global model out of given local uncertainty models and\nmention some useful properties. The main results and proofs are presented using\nthe language of sets of desirable gambles, which provides a very general and\nexpressive way of representing imprecise probability models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2012 11:26:31 GMT"}], "update_date": "2012-08-07", "authors_parsed": [["De Bock", "Jasper", ""], ["de Cooman", "Gert", ""]]}, {"id": "1208.1184", "submitter": "John Lai", "authors": "Paul Duetting and Felix Fischer and Pitchayut Jirapinyo and John K.\n  Lai and Benjamin Lubin and David C. Parkes", "title": "Payment Rules through Discriminant-Based Classifiers", "comments": null, "journal-ref": "Proceedings of the 13th ACM Conference on Electronic Commerce (EC\n  '12), pages 477-494, 2012", "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mechanism design it is typical to impose incentive compatibility and then\nderive an optimal mechanism subject to this constraint. By replacing the\nincentive compatibility requirement with the goal of minimizing expected ex\npost regret, we are able to adapt statistical machine learning techniques to\nthe design of payment rules. This computational approach to mechanism design is\napplicable to domains with multi-dimensional types and situations where\ncomputational efficiency is a concern. Specifically, given an outcome rule and\naccess to a type distribution, we train a support vector machine with a special\ndiscriminant function structure such that it implicitly establishes a payment\nrule with desirable incentive properties. We discuss applications to a\nmulti-minded combinatorial auction with a greedy winner-determination algorithm\nand to an assignment problem with egalitarian outcome rule. Experimental\nresults demonstrate both that the construction produces payment rules with low\nex post regret, and that penalizing classification errors is effective in\npreventing failures of ex post individual rationality.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2012 15:07:32 GMT"}], "update_date": "2012-08-07", "authors_parsed": [["Duetting", "Paul", ""], ["Fischer", "Felix", ""], ["Jirapinyo", "Pitchayut", ""], ["Lai", "John K.", ""], ["Lubin", "Benjamin", ""], ["Parkes", "David C.", ""]]}, {"id": "1208.1187", "submitter": "Stamatina Thomaidou", "authors": "Stamatina Thomaidou, Michalis Vazirgiannis, Kyriakos Liakopoulos", "title": "Toward an Integrated Framework for Automated Development and\n  Optimization of Online Advertising Campaigns", "comments": "Submitted to ACM Transactions on the Web (TWEB) Journal - July 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating and monitoring competitive and cost-effective pay-per-click\nadvertisement campaigns through the web-search channel is a resource demanding\ntask in terms of expertise and effort. Assisting or even automating the work of\nan advertising specialist will have an unrivaled commercial value. In this\npaper we propose a methodology, an architecture, and a fully functional\nframework for semi- and fully- automated creation, monitoring, and optimization\nof cost-efficient pay-per-click campaigns with budget constraints. The campaign\ncreation module generates automatically keywords based on the content of the\nweb page to be advertised extended with corresponding ad-texts. These keywords\nare used to create automatically the campaigns fully equipped with the\nappropriate values set. The campaigns are uploaded to the auctioneer platform\nand start running. The optimization module focuses on the learning process from\nexisting campaign statistics and also from applied strategies of previous\nperiods in order to invest optimally in the next period. The objective is to\nmaximize the performance (i.e. clicks, actions) under the current budget\nconstraint. The fully functional prototype is experimentally evaluated on real\nworld Google AdWords campaigns and presents a promising behavior with regards\nto campaign performance statistics as it outperforms systematically the\ncompeting manually maintained campaigns.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2012 15:18:36 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Thomaidou", "Stamatina", ""], ["Vazirgiannis", "Michalis", ""], ["Liakopoulos", "Kyriakos", ""]]}, {"id": "1208.1613", "submitter": "Jingchao Chen", "authors": "Jingchao Chen", "title": "A Dynamic Phase Selection Strategy for Satisfiability Solvers", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase selection is an important of a SAT Solver based on conflict-driven\nDPLL. This paper presents a new phase selection strategy, in which the weight\nof each literal is defined as the sum of its implied-literals static weights.\nThe implied literals of each literal is computed dynamically during the search.\nTherefore, it is call a dynamic phase selection strategy. In general, computing\ndynamically a weight is time-consuming. Hence, so far no SAT solver applies\nsuccessfully a dynamic phase selection. Since the implied literal of our\nstrategy conforms to that of the search process, the usual two watched-literals\nscheme can be applied here. Thus, the cost of our dynamic phase selection is\nvery low. To improve Glucose 2.0 which won a Gold Medal for application\ncategory at SAT 2011 competition, we build five phase selection schemes using\nthe dynamic phase selection policy. On application instances of SAT 2011,\nGlucose improved by the dynamic phase selection is significantly better than\nthe original Glucose. We conduct also experiments on Lingeling, using the\ndynamic phase selection policy, and build two phase selection schemes.\nExperimental results show that the improved Lingeling is better than the\noriginal Lingeling.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 08:39:04 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Chen", "Jingchao", ""]]}, {"id": "1208.1692", "submitter": "Sebastian Ordyniak", "authors": "Serge Gaspers, Mikko Koivisto, Mathieu Liedloff, Sebastian Ordyniak,\n  Stefan Szeider", "title": "On Finding Optimal Polytrees", "comments": "(author's self-archived copy)", "journal-ref": "Proc. AAAI'12, pp. 750-756 (AAAI Press 2012)", "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring probabilistic networks from data is a notoriously difficult task.\nUnder various goodness-of-fit measures, finding an optimal network is NP-hard,\neven if restricted to polytrees of bounded in-degree. Polynomial-time\nalgorithms are known only for rare special cases, perhaps most notably for\nbranchings, that is, polytrees in which the in-degree of every node is at most\none. Here, we study the complexity of finding an optimal polytree that can be\nturned into a branching by deleting some number of arcs or nodes, treated as a\nparameter.\n  We show that the problem can be solved via a matroid intersection formulation\nin polynomial time if the number of deleted arcs is bounded by a constant. The\norder of the polynomial time bound depends on this constant, hence the\nalgorithm does not establish fixed-parameter tractability when parameterized by\nthe number of deleted arcs. We show that a restricted version of the problem\nallows fixed-parameter tractability and hence scales well with the parameter.\nWe contrast this positive result by showing that if we parameterize by the\nnumber of deleted nodes, a somewhat more powerful parameter, the problem is not\nfixed-parameter tractable, subject to a complexity-theoretic assumption.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 15:32:42 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2012 13:36:15 GMT"}], "update_date": "2012-08-16", "authors_parsed": [["Gaspers", "Serge", ""], ["Koivisto", "Mikko", ""], ["Liedloff", "Mathieu", ""], ["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1208.1743", "submitter": "Amir Noori", "authors": "Amir Noori, Mohammad Bagher Menhaj, Masoud Shafiee", "title": "Hybrid systems modeling for gas transmission network", "comments": "This paper has been withdrawn by the author due to a crucial citation\n  error in introduction section", "journal-ref": "The 4th IFAC Conference on Management and Control of Production\n  and Logistics, 2007", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gas Transmission Networks are large-scale complex systems, and corresponding\ndesign and control problems are challenging. In this paper, we consider the\nproblem of control and management of these systems in crisis situations. We\npresent these networks by a hybrid systems framework that provides required\nanalysis models. Further, we discuss decision-making using computational\ndiscrete and hybrid optimization methods. In particular, several reinforcement\nlearning methods are employed to explore decision space and achieve the best\npolicy in a specific crisis situation. Simulations are presented to illustrate\nthe efficiency of the method.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 19:24:08 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2012 20:03:41 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2012 16:00:02 GMT"}, {"version": "v4", "created": "Fri, 28 Sep 2012 07:07:55 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Noori", "Amir", ""], ["Menhaj", "Mohammad Bagher", ""], ["Shafiee", "Masoud", ""]]}, {"id": "1208.1750", "submitter": "Perrine Pittet", "authors": "Perrine Pittet (Le2i), Christophe Nicolle (Le2i), Christophe Cruz\n  (Le2i)", "title": "Guidelines for a Dynamic Ontology - Integrating Tools of Evolution and\n  Versioning in Ontology", "comments": null, "journal-ref": "KMIS 2011 - International Conference on Knowledge Management and\n  Information Sharing is part of 3rd International Joint Conference on\n  Knowledge Discovery, Knowledge Engineering and Knowledge Management., Paris :\n  France (2011)", "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies are built on systems that conceptually evolve over time. In\naddition, techniques and languages for building ontologies evolve too. This has\nled to numerous studies in the field of ontology versioning and ontology\nevolution. This paper presents a new way to manage the lifecycle of an ontology\nincorporating both versioning tools and evolution process. This solution,\ncalled VersionGraph, is integrated in the source ontology since its creation in\norder to make it possible to evolve and to be versioned. Change management is\nstrongly related to the model in which the ontology is represented. Therefore,\nwe focus on the OWL language in order to take into account the impact of the\nchanges on the logical consistency of the ontology like specified in OWL DL.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 19:45:18 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Pittet", "Perrine", "", "Le2i"], ["Nicolle", "Christophe", "", "Le2i"], ["Cruz", "Christophe", "", "Le2i"]]}, {"id": "1208.1921", "submitter": "Jean-Louis Dessalles", "authors": "Jean-Louis Dessalles", "title": "Algorithmic Simplicity and Relevance", "comments": "Presented at the Solomonoff 85th Memorial Conference, Monash\n  University, Melbourne, December 2011 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human mind is known to be sensitive to complexity. For instance, the\nvisual system reconstructs hidden parts of objects following a principle of\nmaximum simplicity. We suggest here that higher cognitive processes, such as\nthe selection of relevant situations, are sensitive to variations of\ncomplexity. Situations are relevant to human beings when they appear simpler to\ndescribe than to generate. This definition offers a predictive (i.e.\nfalsifiable) model for the selection of situations worth reporting\n(interestingness) and for what individuals consider an appropriate move in\nconversation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 14:32:06 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Dessalles", "Jean-Louis", ""]]}, {"id": "1208.1940", "submitter": "Santiago Ontanon", "authors": "Santiago Ontanon", "title": "Experiments with Game Tree Search in Real-Time Strategy Games", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game tree search algorithms such as minimax have been used with enormous\nsuccess in turn-based adversarial games such as Chess or Checkers. However,\nsuch algorithms cannot be directly applied to real-time strategy (RTS) games\nbecause a number of reasons. For example, minimax assumes a turn-taking game\nmechanics, not present in RTS games. In this paper we present RTMM, a real-time\nvariant of the standard minimax algorithm, and discuss its applicability in the\ncontext of RTS games. We discuss its strengths and weaknesses, and evaluate it\nin two real-time games.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 15:02:02 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Ontanon", "Santiago", ""]]}, {"id": "1208.1955", "submitter": "Fahimeh Farahbod", "authors": "Fahimeh Farahbod and Mahdi Eftekhari", "title": "Comparison of different T-norm operators in classification problems", "comments": "6 pages, 1 figure, 4 tables; International Journal of Fuzzy Logic\n  Systems (IJFLS) Vol.2, No.3, July 2012", "journal-ref": null, "doi": "10.5121/ijfls.2012.2303", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy rule based classification systems are one of the most popular fuzzy\nmodeling systems used in pattern classification problems. This paper\ninvestigates the effect of applying nine different T-norms in fuzzy rule based\nclassification systems. In the recent researches, fuzzy versions of confidence\nand support merits from the field of data mining have been widely used for both\nrules selecting and weighting in the construction of fuzzy rule based\nclassification systems. For calculating these merits the product has been\nusually used as a T-norm. In this paper different T-norms have been used for\ncalculating the confidence and support measures. Therefore, the calculations in\nrule selection and rule weighting steps (in the process of constructing the\nfuzzy rule based classification systems) are modified by employing these\nT-norms. Consequently, these changes in calculation results in altering the\noverall accuracy of rule based classification systems. Experimental results\nobtained on some well-known data sets show that the best performance is\nproduced by employing the Aczel-Alsina operator in terms of the classification\naccuracy, the second best operator is Dubois-Prade and the third best operator\nis Dombi. In experiments, we have used 12 data sets with numerical attributes\nfrom the University of California, Irvine machine learning repository (UCI).\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 15:41:27 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Farahbod", "Fahimeh", ""], ["Eftekhari", "Mahdi", ""]]}, {"id": "1208.2102", "submitter": "Abdul Kareem", "authors": "Abdul Kareem, Mohammad Fazle Azeem", "title": "A Novel Fuzzy Logic Based Adaptive Supertwisting Sliding Mode Control\n  Algorithm for Dynamic Uncertain Systems", "comments": "14 pages", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.3, No.4, July 2012, 21-34", "doi": "10.5121/ijaia.2012.3402", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel fuzzy logic based Adaptive Super-twisting Sliding\nMode Controller for the control of dynamic uncertain systems. The proposed\ncontroller combines the advantages of Second order Sliding Mode Control, Fuzzy\nLogic Control and Adaptive Control. The reaching conditions, stability and\nrobustness of the system with the proposed controller are guaranteed. In\naddition, the proposed controller is well suited for simple design and\nimplementation. The effectiveness of the proposed controller over the first\norder Sliding Mode Fuzzy Logic controller is illustrated by Matlab based\nsimulations performed on a DC-DC Buck converter. Based on this comparison, the\nproposed controller is shown to obtain the desired transient response without\ncausing chattering and error under steady-state conditions. The proposed\ncontroller is able to give robust performance in terms of rejection to input\nvoltage variations and load variations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2012 07:19:48 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Kareem", "Abdul", ""], ["Azeem", "Mohammad Fazle", ""]]}, {"id": "1208.2199", "submitter": "Mohammad Havaei", "authors": "Mohammad Havaei, Nandivada Krishna Prasad, and Velleshala Sudheer", "title": "Elimination of ISI Using Improved LMS Based Decision Feedback Equalizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the implementation of Least Mean Square (LMS) algorithm\nin Decision Feedback Equalizer (DFE) for removal of Inter Symbol Interference\n(ISI) at the receiver. The channel disrupts the transmitted signal by spreading\nit in time. Although, the LMS algorithm is robust and reliable, it is slow in\nconvergence. In order to increase the speed of convergence, modifications have\nbeen made in the algorithm where the weights get updated depending on the\nseverity of disturbance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2012 15:05:38 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Havaei", "Mohammad", ""], ["Prasad", "Nandivada Krishna", ""], ["Sudheer", "Velleshala", ""]]}, {"id": "1208.2261", "submitter": "Sudarshan Nandy", "authors": "Sudarshan Nandy, Partha Pratim Sarkar and Achintya Das", "title": "Analysis of Statistical Hypothesis based Learning Mechanism for Faster\n  Crawling", "comments": "14 Pages, 7 Figures This paper has been withdrawn by the author due\n  to a crucial sign error in page no. 3,4,7 and 11. The error is also observed\n  with equation no in page 10", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.3, No.4, July 2012, 117-130", "doi": "10.5121/ijaia.2012.3409", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of world-wide-web (WWW) spreads its wings from an intangible\nquantities of web-pages to a gigantic hub of web information which gradually\nincreases the complexity of crawling process in a search engine. A search\nengine handles a lot of queries from various parts of this world, and the\nanswers of it solely depend on the knowledge that it gathers by means of\ncrawling. The information sharing becomes a most common habit of the society,\nand it is done by means of publishing structured, semi-structured and\nunstructured resources on the web. This social practice leads to an exponential\ngrowth of web-resource, and hence it became essential to crawl for continuous\nupdating of web-knowledge and modification of several existing resources in any\nsituation. In this paper one statistical hypothesis based learning mechanism is\nincorporated for learning the behavior of crawling speed in different\nenvironment of network, and for intelligently control of the speed of crawler.\nThe scaling technique is used to compare the performance proposed method with\nthe standard crawler. The high speed performance is observed after scaling, and\nthe retrieval of relevant web-resource in such a high speed is analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2012 19:43:43 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2012 05:40:17 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Nandy", "Sudarshan", ""], ["Sarkar", "Partha Pratim", ""], ["Das", "Achintya", ""]]}, {"id": "1208.2362", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Jan Broekaert, Liane Gabora and Tomas Veloz", "title": "The Guppy Effect as Interference", "comments": "10 pages", "journal-ref": "Quantum Interaction. Lecture Notes in Computer Science, 7620, pp\n  36-47, 2012", "doi": "10.1007/978-3-642-35659-9_4", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People use conjunctions and disjunctions of concepts in ways that violate the\nrules of classical logic, such as the law of compositionality. Specifically,\nthey overextend conjunctions of concepts, a phenomenon referred to as the Guppy\nEffect. We build on previous efforts to develop a quantum model that explains\nthe Guppy Effect in terms of interference. Using a well-studied data set with\n16 exemplars that exhibit the Guppy Effect, we developed a 17-dimensional\ncomplex Hilbert space H that models the data and demonstrates the relationship\nbetween overextension and interference. We view the interference effect as, not\na logical fallacy on the conjunction, but a signal that out of the two\nconstituent concepts, a new concept has emerged.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2012 15:39:18 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Aerts", "Diederik", ""], ["Broekaert", "Jan", ""], ["Gabora", "Liane", ""], ["Veloz", "Tomas", ""]]}, {"id": "1208.2566", "submitter": "Sebastian Ordyniak", "authors": "Christer Baeckstroem, Yue Chen, Peter Jonsson, Sebastian Ordyniak,\n  Stefan Szeider", "title": "The Complexity of Planning Revisited - A Parameterized Analysis", "comments": "(author's self-archived copy)", "journal-ref": "Proc. AAAI'12 (AAAI Press 2012) pp. 1735-1741", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early classifications of the computational complexity of planning under\nvarious restrictions in STRIPS (Bylander) and SAS+ (Baeckstroem and Nebel) have\ninfluenced following research in planning in many ways. We go back and\nreanalyse their subclasses, but this time using the more modern tool of\nparameterized complexity analysis. This provides new results that together with\nthe old results give a more detailed picture of the complexity landscape. We\ndemonstrate separation results not possible with standard complexity theory,\nwhich contributes to explaining why certain cases of planning have seemed\nsimpler in practice than theory has predicted. In particular, we show that\ncertain restrictions of practical interest are tractable in the parameterized\nsense of the term, and that a simple heuristic is sufficient to make a\nwell-known partial-order planner exploit this fact.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 12:40:44 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Baeckstroem", "Christer", ""], ["Chen", "Yue", ""], ["Jonsson", "Peter", ""], ["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1208.2852", "submitter": "Yong Lai", "authors": "Yong Lai, Dayou Liu", "title": "Ordered {AND, OR}-Decomposition and Binary-Decision Diagram", "comments": "The authors have resubmitted a new version with a different tittle,\n  arXiv:1410.6671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In the context of knowledge compilation (KC), we study the effect of\naugmenting Ordered Binary Decision Diagrams (OBDD) with two kinds of\ndecomposition nodes, i.e., AND-vertices and OR-vertices which denote\nconjunctive and disjunctive decomposition of propositional knowledge bases,\nrespectively. The resulting knowledge compilation language is called Ordered\n{AND, OR}-decomposition and binary-Decision Diagram (OAODD). Roughly speaking,\nseveral previous languages can be seen as special types of OAODD, including\nOBDD, AND/OR Binary Decision Diagram (AOBDD), OBDD with implied Literals\n(OBDD-L), Multi-Level Decomposition Diagrams (MLDD). On the one hand, we\npropose some families of algorithms which can convert some fragments of OAODD\ninto others; on the other hand, we present a rich set of polynomial-time\nalgorithms that perform logical operations. According to these algorithms, as\nwell as theoretical analysis, we characterize the space efficiency and\ntractability of OAODD and its some fragments with respect to the evaluating\ncriteria in the KC map. Finally, we present a compilation algorithm which can\nconvert formulas in negative normal form into OAODD.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 13:08:18 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 07:07:33 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Lai", "Yong", ""], ["Liu", "Dayou", ""]]}, {"id": "1208.3015", "submitter": "Andreas Schutt", "authors": "Andreas Schutt and Thibaut Feydy and Peter J. Stuckey", "title": "Explaining Time-Table-Edge-Finding Propagation for the Cumulative\n  Resource Constraint", "comments": "22 pages, 3 figures, 11 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative resource constraints can model scarce resources in scheduling\nproblems or a dimension in packing and cutting problems. In order to\nefficiently solve such problems with a constraint programming solver, it is\nimportant to have strong and fast propagators for cumulative resource\nconstraints. One such propagator is the recently developed\ntime-table-edge-finding propagator, which considers the current resource\nprofile during the edge-finding propagation. Recently, lazy clause generation\nsolvers, i.e. constraint programming solvers incorporating nogood learning,\nhave proved to be excellent at solving scheduling and cutting problems. For\nsuch solvers, concise and accurate explanations of the reasons for propagation\nare essential for strong nogood learning. In this paper, we develop the first\nexplaining version of time-table-edge-finding propagation and show preliminary\nresults on resource-constrained project scheduling problems from various\nstandard benchmark suites. On the standard benchmark suite PSPLib, we were able\nto close one open instance and to improve the lower bound of about 60% of the\nremaining open instances. Moreover, 6 of those instances were closed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 02:17:55 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2012 05:52:51 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Schutt", "Andreas", ""], ["Feydy", "Thibaut", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "1208.3148", "submitter": "Ernesto Jim\\'enez-Ruiz", "authors": "Christian Meilicke (1), Ondrej Sv\\'ab-Zamazal (2), C\\'assia Trojahn\n  (3), Ernesto Jim\\'enez-Ruiz (4), Jos\\'e-Luis Aguirre (3), Heiner\n  Stuckenschmidt (1), Bernardo Cuenca Grau (4) ((1) University of Mannheim, (2)\n  University of Economics Prague, (3) INRIA and LIG Grenoble, (4) University of\n  Oxford)", "title": "Evaluating Ontology Matching Systems on Large, Multilingual and\n  Real-world Test Cases", "comments": "Technical Report of the OAEI 2011.5 Evaluation Campaign", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of ontology matching, the most systematic evaluation of matching\nsystems is established by the Ontology Alignment Evaluation Initiative (OAEI),\nwhich is an annual campaign for evaluating ontology matching systems organized\nby different groups of researchers. In this paper, we report on the results of\nan intermediary OAEI campaign called OAEI 2011.5. The evaluations of this\ncampaign are divided in five tracks. Three of these tracks are new or have been\nimproved compared to previous OAEI campaigns. Overall, we evaluated 18 matching\nsystems. We discuss lessons learned, in terms of scalability, multilingual\nissues and the ability do deal with real world cases from different domains.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 15:46:31 GMT"}], "update_date": "2012-08-16", "authors_parsed": [["Meilicke", "Christian", ""], ["Sv\u00e1b-Zamazal", "Ondrej", ""], ["Trojahn", "C\u00e1ssia", ""], ["Jim\u00e9nez-Ruiz", "Ernesto", ""], ["Aguirre", "Jos\u00e9-Luis", ""], ["Stuckenschmidt", "Heiner", ""], ["Grau", "Bernardo Cuenca", ""]]}, {"id": "1208.3432", "submitter": "Mahsa Badami Miss", "authors": "Mahsa Badami, Ali Hamzeh, Sattar Hashemi", "title": "A Novel Strategy Selection Method for Multi-Objective Clustering\n  Algorithms Using Game Theory", "comments": "9 Pages, 9 Figures; International Journal of Computer Science Issues\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The most important factors which contribute to the efficiency of\ngame-theoretical algorithms are time and game complexity. In this study, we\nhave offered an elegant method to deal with high complexity of game theoretic\nmulti-objective clustering methods in large-sized data sets. Here, we have\ndeveloped a method which selects a subset of strategies from strategies profile\nfor each player. In this case, the size of payoff matrices reduces\nsignificantly which has a remarkable impact on time complexity. Therefore,\npractical problems with more data are tractable with less computational\ncomplexity. Although strategies set may grow with increasing the number of data\npoints, the presented model of strategy selection reduces the strategy space,\nconsiderably, where clusters are subdivided into several sub-clusters in each\nlocal game. The remarkable results demonstrate the efficiency of the presented\napproach in reducing computational complexity of the problem of concern.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 14:58:55 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Badami", "Mahsa", ""], ["Hamzeh", "Ali", ""], ["Hashemi", "Sattar", ""]]}, {"id": "1208.3600", "submitter": "Piyush Shrivastava", "authors": "Piyush Shrivastava", "title": "Modeling and Control of CSTR using Model based Neural Network Predictive\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a predictive control strategy based on neural network\nmodel of the plant is applied to Continuous Stirred Tank Reactor (CSTR). This\nsystem is a highly nonlinear process; therefore, a nonlinear predictive method,\ne.g., neural network predictive control, can be a better match to govern the\nsystem dynamics. In the paper, the NN model and the way in which it can be used\nto predict the behavior of the CSTR process over a certain prediction horizon\nare described, and some comments about the optimization procedure are made.\nPredictive control algorithm is applied to control the concentration in a\ncontinuous stirred tank reactor (CSTR), whose parameters are optimally\ndetermined by solving quadratic performance index using the optimization\nalgorithm. An efficient control of the product concentration in cstr can be\nachieved only through accurate model. Here an attempt is made to alleviate the\nmodeling difficulties using Artificial Intelligent technique such as Neural\nNetwork. Simulation results demonstrate the feasibility and effectiveness of\nthe NNMPC technique.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2012 13:59:30 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Shrivastava", "Piyush", ""]]}, {"id": "1208.3623", "submitter": "Rafi Muhammad", "authors": "Muhammad Rafi, Sundus Hassan and Mohammad Shahid Shaikh", "title": "Content-based Text Categorization using Wikitology", "comments": "9 pages; IJCSI August 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major computational burden, while performing document clustering, is the\ncalculation of similarity measure between a pair of documents. Similarity\nmeasure is a function that assign a real number between 0 and 1 to a pair of\ndocuments, depending upon the degree of similarity between them. A value of\nzero means that the documents are completely dissimilar whereas a value of one\nindicates that the documents are practically identical. Traditionally,\nvector-based models have been used for computing the document similarity. The\nvector-based models represent several features present in documents. These\napproaches to similarity measures, in general, cannot account for the semantics\nof the document. Documents written in human languages contain contexts and the\nwords used to describe these contexts are generally semantically related.\nMotivated by this fact, many researchers have proposed semantic-based\nsimilarity measures by utilizing text annotation through external thesauruses\nlike WordNet (a lexical database). In this paper, we define a semantic\nsimilarity measure based on documents represented in topic maps. Topic maps are\nrapidly becoming an industrial standard for knowledge representation with a\nfocus for later search and extraction. The documents are transformed into a\ntopic map based coded knowledge and the similarity between a pair of documents\nis represented as a correlation between the common patterns. The experimental\nstudies on the text mining datasets reveal that this new similarity measure is\nmore effective as compared to commonly used similarity measures in text\nclustering.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2012 15:49:38 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Rafi", "Muhammad", ""], ["Hassan", "Sundus", ""], ["Shaikh", "Mohammad Shahid", ""]]}, {"id": "1208.3802", "submitter": "Nisheeth Joshi", "authors": "Archana Vashisth, Iti Mathur, Nisheeth Joshi", "title": "OntoAna: Domain Ontology for Human Anatomy", "comments": "Proceedings of 5th CSI National Conference on Education and Research.\n  Organized by Lingayay University, Faridabad. Sponsored by Computer Society of\n  India and IEEE Delhi Chapter. Proceedings published by Lingayay University\n  Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Today, we can find many search engines which provide us with information\nwhich is more operational in nature. None of the search engines provide domain\nspecific information. This becomes very troublesome to a novice user who wishes\nto have information in a particular domain. In this paper, we have developed an\nontology which can be used by a domain specific search engine. We have\ndeveloped an ontology on human anatomy, which captures information regarding\ncardiovascular system, digestive system, skeleton and nervous system. This\ninformation can be used by people working in medical and health care domain.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2012 02:44:42 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Vashisth", "Archana", ""], ["Mathur", "Iti", ""], ["Joshi", "Nisheeth", ""]]}, {"id": "1208.3809", "submitter": "Nima Taghipour", "authors": "Nima Taghipour, Daan Fierens, Guy Van den Broeck, Jesse Davis, Hendrik\n  Blockeel", "title": "Lifted Variable Elimination: A Novel Operator and Completeness Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods for lifted probabilistic inference have been proposed, but\nour understanding of these methods and the relationships between them is still\nlimited, compared to their propositional counterparts. The only existing\ntheoretical characterization of lifting is for weighted first-order model\ncounting (WFOMC), which was shown to be complete domain-lifted for the class of\n2-logvar models. This paper makes two contributions to lifted variable\nelimination (LVE). First, we introduce a novel inference operator called group\ninversion. Second, we prove that LVE augmented with this operator is complete\nin the same sense as WFOMC.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2012 04:55:25 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2012 18:10:37 GMT"}], "update_date": "2012-08-27", "authors_parsed": [["Taghipour", "Nima", ""], ["Fierens", "Daan", ""], ["Broeck", "Guy Van den", ""], ["Davis", "Jesse", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1208.4692", "submitter": "Francis Maes", "authors": "Francis Maes and David Lupien St-Pierre and Damien Ernst", "title": "Monte Carlo Search Algorithm Discovery for One Player Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much current research in AI and games is being devoted to Monte Carlo search\n(MCS) algorithms. While the quest for a single unified MCS algorithm that would\nperform well on all problems is of major interest for AI, practitioners often\nknow in advance the problem they want to solve, and spend plenty of time\nexploiting this knowledge to customize their MCS algorithm in a problem-driven\nway. We propose an MCS algorithm discovery scheme to perform this in an\nautomatic and reproducible way. We first introduce a grammar over MCS\nalgorithms that enables inducing a rich space of candidate algorithms.\nAfterwards, we search in this space for the algorithm that performs best on\naverage for a given distribution of training problems. We rely on multi-armed\nbandits to approximately solve this optimization problem. The experiments,\ngenerated on three different domains, show that our approach enables\ndiscovering algorithms that outperform several well-known MCS algorithms such\nas Upper Confidence bounds applied to Trees and Nested Monte Carlo search. We\nalso show that the discovered algorithms are generally quite robust with\nrespect to changes in the distribution over the training problems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2012 08:44:59 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2012 15:57:58 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2012 10:44:37 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Maes", "Francis", ""], ["St-Pierre", "David Lupien", ""], ["Ernst", "Damien", ""]]}, {"id": "1208.4773", "submitter": "Tobias Jung", "authors": "Tobias Jung, Louis Wehenkel, Damien Ernst, Francis Maes", "title": "Optimized Look-Ahead Tree Policies: A Bridge Between Look-Ahead Tree\n  Policies and Direct Policy Search", "comments": "In Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct policy search (DPS) and look-ahead tree (LT) policies are two widely\nused classes of techniques to produce high performance policies for sequential\ndecision-making problems. To make DPS approaches work well, one crucial issue\nis to select an appropriate space of parameterized policies with respect to the\ntargeted problem. A fundamental issue in LT approaches is that, to take good\ndecisions, such policies must develop very large look-ahead trees which may\nrequire excessive online computational resources. In this paper, we propose a\nnew hybrid policy learning scheme that lies at the intersection of DPS and LT,\nin which the policy is an algorithm that develops a small look-ahead tree in a\ndirected way, guided by a node scoring function that is learned through DPS.\nThe LT-based representation is shown to be a versatile way of representing\npolicies in a DPS scheme, while at the same time, DPS enables to significantly\nreduce the size of the look-ahead trees that are required to take high-quality\ndecisions.\n  We experimentally compare our method with two other state-of-the-art DPS\ntechniques and four common LT policies on four benchmark domains and show that\nit combines the advantages of the two techniques from which it originates. In\nparticular, we show that our method: (1) produces overall better performing\npolicies than both pure DPS and pure LT policies, (2) requires a substantially\nsmaller number of policy evaluations than other DPS techniques, (3) is easy to\ntune and (4) results in policies that are quite robust with respect to\nperturbations of the initial conditions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2012 14:48:52 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Jung", "Tobias", ""], ["Wehenkel", "Louis", ""], ["Ernst", "Damien", ""], ["Maes", "Francis", ""]]}, {"id": "1208.4942", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea", "title": "A Unifying Survey of Reinforced, Sensitive and Stigmergic Agent-Based\n  Approaches for E-GTSP", "comments": "9 pages, 2 figures", "journal-ref": "Informatica. 26(3) (2015). 509-522", "doi": "10.15388/Informatica.2015.61", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generalized Traveling Salesman Problem (GTSP) is one of the NP-hard\ncombinatorial optimization problems. A variant of GTSP is E-GTSP where E,\nmeaning equality, has the constraint: exactly one node from a cluster of a\ngraph partition is visited. The main objective of the E-GTSP is to find a\nminimum cost tour passing through exactly one node from each cluster of an\nundirected graph. Agent-based approaches involving are successfully used\nnowadays for solving real life complex problems. The aim of the current paper\nis to illustrate some variants of agent-based algorithms including ant-based\nmodels with specific properties for solving E-GTSP.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2012 10:23:37 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 11:02:59 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Pintea", "Camelia-M.", ""]]}, {"id": "1208.4945", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, Gloria Cerasela Crisan, Mihai Manea", "title": "Parallel ACO with a Ring Neighborhood for Dynamic TSP", "comments": "8 pages, 1 figure; accepted J. Information Technology Research", "journal-ref": "J Information Technology Research 5(4): 1-13 (2012)", "doi": "10.4018/jitr.2012100101", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper introduces a new parallel computing technique based on ant\ncolony optimization for a dynamic routing problem. In the dynamic traveling\nsalesman problem the distances between cities as travel times are no longer\nfixed. The new technique uses a parallel model for a problem variant that\nallows a slight movement of nodes within their Neighborhoods. The algorithm is\ntested with success on several large data sets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2012 10:38:49 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2012 13:14:13 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Crisan", "Gloria Cerasela", ""], ["Manea", "Mihai", ""]]}, {"id": "1208.5154", "submitter": "David McAllester", "authors": "David McAllester, Petri Myllymaki", "title": "Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial\n  Intelligence (2008)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2008", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Fourth Conference on Uncertainty in\nArtificial Intelligence, which was held in Helsinki, Finland, July 9 - 12 2008.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2012 18:22:17 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:25:59 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["McAllester", "David", ""], ["Myllymaki", "Petri", ""]]}, {"id": "1208.5155", "submitter": "Ronald Parr", "authors": "Ronald Parr, Linda S. van der Gaag", "title": "Proceedings of the Twenty-Third Conference on Uncertainty in Artificial\n  Intelligence (2007)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2007", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Third Conference on Uncertainty in\nArtificial Intelligence, which was held in Vancouver, British Columbia, July 19\n- 22 2007.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2012 18:26:04 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:24:43 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Parr", "Ronald", ""], ["van der Gaag", "Linda S.", ""]]}, {"id": "1208.5159", "submitter": "Fahiem Bacchus", "authors": "Fahiem Bacchus, Tommi Jaakkola", "title": "Proceedings of the Twenty-First Conference on Uncertainty in Artificial\n  Intelligence (2005)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2005", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-First Conference on Uncertainty in\nArtificial Intelligence, which was held in Edinburgh, Scotland July 26 - 29\n2005.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2012 18:44:38 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:22:02 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Bacchus", "Fahiem", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1208.5160", "submitter": "Rina Dechter", "authors": "Rina Dechter, Thomas S. Richardson", "title": "Proceedings of the Twenty-Second Conference on Uncertainty in Artificial\n  Intelligence (2006)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2006", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Second Conference on Uncertainty in\nArtificial Intelligence, which was held in Cambridge, MA, July 13 - 16 2006.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2012 18:45:05 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:23:23 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Dechter", "Rina", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1208.5161", "submitter": "Max Chickering", "authors": "Max Chickering, Joseph Halpern", "title": "Proceedings of the Twentieth Conference on Uncertainty in Artificial\n  Intelligence (2004)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2004", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twentieth Conference on Uncertainty in\nArtificial Intelligence, which was held in Banff, Canada, July 7 - 11 2004.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2012 18:48:34 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:20:22 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Chickering", "Max", ""], ["Halpern", "Joseph", ""]]}, {"id": "1208.5333", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, Camelia Chira, Gloria-C. Crisan", "title": "A hybrid ACO approach to the Matrix Bandwidth Minimization Problem", "comments": "This paper has been withdrawn by the author, due to an error", "journal-ref": "Lecture Notes in Computer Science 6076 (2010) 405-412", "doi": "10.1007/978-3-642-13769-3_49", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of the human society raises more and more difficult endeavors.\nFor some of the real-life problems, the computing time-restriction enhances\ntheir complexity. The Matrix Bandwidth Minimization Problem (MBMP) seeks for a\nsimultaneous permutation of the rows and the columns of a square matrix in\norder to keep its nonzero entries close to the main diagonal. The MBMP is a\nhighly investigated P-complete problem, as it has broad applications in\nindustry, logistics, artificial intelligence or information recovery. This\npaper describes a new attempt to use the Ant Colony Optimization framework in\ntackling MBMP. The introduced model is based on the hybridization of the Ant\nColony System technique with new local search mechanisms. Computational\nexperiments confirm a good performance of the proposed algorithm for the\nconsidered set of MBMP instances.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2012 08:51:23 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2012 13:12:03 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Chira", "Camelia", ""], ["Crisan", "Gloria-C.", ""]]}, {"id": "1208.5340", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, Camelia Chira, D. Dumitrescu", "title": "New results of ant algorithms for the Linear Ordering Problem", "comments": "5 pages, 5 figures Zbl:06048718", "journal-ref": "An. Univ. Vest Timis., Ser. Mat.-Inform. 48, No. 3, 139-150 (2010)", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant-based algorithms are successful tools for solving complex problems. One\nof these problems is the Linear Ordering Problem (LOP). The paper shows new\nresults on some LOP instances, using Ant Colony System (ACS) and the Step-Back\nSensitive Ant Model (SB-SAM).\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2012 08:58:46 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Chira", "Camelia", ""], ["Dumitrescu", "D.", ""]]}, {"id": "1208.5341", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, Camelia Chira, D. Dumitrescu, Petrica C. Pop", "title": "Sensitive Ants in Solving the Generalized Vehicle Routing Problem", "comments": "5 pages", "journal-ref": "INT J COMPUT COMMUN, VI(4):731-738 (2011)", "doi": "10.15837/ijccc.2011.4.2098", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of sensitivity in ant colony systems has been exploited in hybrid\nant-based models with promising results for many combinatorial optimization\nproblems. Heterogeneity is induced in the ant population by endowing individual\nants with a certain level of sensitivity to the pheromone trail. The variable\npheromone sensitivity within the same population of ants can potentially\nintensify the search while in the same time inducing diversity for the\nexploration of the environment. The performance of sensitive ant models is\ninvestigated for solving the generalized vehicle routing problem. Numerical\nresults and comparisons are discussed and analysed with a focus on emphasizing\nany particular aspects and potential benefits related to hybrid ant-based\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2012 09:12:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Chira", "Camelia", ""], ["Dumitrescu", "D.", ""], ["Pop", "Petrica C.", ""]]}, {"id": "1208.5373", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, D. Dumitrescu", "title": "Distributed Pharaoh System for Network Routing", "comments": "4 pages, 4 figures", "journal-ref": "Automat. Comput. Appl. Math. 16(1-2) (2007) 27-34", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper it is introduced a biobjective ant algorithm for constructing\nlow cost routing networks. The new algorithm is called the Distributed Pharaoh\nSystem (DPS). DPS is based on AntNet algorithm. The algorithm is using Pharaoh\nAnt System (PAS) with an extra-exploration phase and a 'no-entry' condition in\norder to improve the solutions for the Low Cost Network Routing problem.\nAdditionally it is used a cost model for overlay network construction that\nincludes network traffic demands. The Pharaoh ants (Monomorium pharaonis)\nincludes negative pheromones with signals concentrated at decision points where\ntrails fork. The negative pheromones may complement positive pheromone or could\nhelp ants to escape from an unnecessarily long route to food that is being\nreinforced by attractive signals. Numerical experiments were made for a random\n10-node network. The average node degree of the network tested was 4.0. The\nresults are encouraging. The algorithm converges to the shortest path while\nconverging on a low cost overlay routing network topology.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2012 12:35:29 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Dumitrescu", "D.", ""]]}, {"id": "1208.5554", "submitter": "Cm Pintea", "authors": "Gabriela Czibula, Gloria Cerasela Crisan, Camelia-M. Pintea,\n  Istvan-Gergely Czibula", "title": "Soft Computing approaches on the Bandwidth Problem", "comments": "6 pages, 1 figure; accepted to Informatica", "journal-ref": "INFORMATICA 24(2):169-180 (2013)", "doi": "10.15388/Informatica.2013.390", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Matrix Bandwidth Minimization Problem (MBMP) seeks for a simultaneous\nreordering of the rows and the columns of a square matrix such that the nonzero\nentries are collected within a band of small width close to the main diagonal.\nThe MBMP is a NP-complete problem, with applications in many scientific\ndomains, linear systems, artificial intelligence, and real-life situations in\nindustry, logistics, information recovery. The complex problems are hard to\nsolve, that is why any attempt to improve their solutions is beneficent.\nGenetic algorithms and ant-based systems are Soft Computing methods used in\nthis paper in order to solve some MBMP instances. Our approach is based on a\nlearning agent-based model involving a local search procedure. The algorithm is\ncompared with the classical Cuthill-McKee algorithm, and with a hybrid genetic\nalgorithm, using several instances from Matrix Market collection. Computational\nexperiments confirm a good performance of the proposed algorithms for the\nconsidered set of MBMP instances. On Soft Computing basis, we also propose a\nnew theoretical Reinforcement Learning model for solving the MBMP problem.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2012 04:26:35 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Czibula", "Gabriela", ""], ["Crisan", "Gloria Cerasela", ""], ["Pintea", "Camelia-M.", ""], ["Czibula", "Istvan-Gergely", ""]]}, {"id": "1208.5654", "submitter": "Chris De Vries", "authors": "Christopher M. De Vries, Shlomo Geva, Andrew Trotman", "title": "Document Clustering Evaluation: Divergence from a Random Baseline", "comments": "8 pages, 11 figures, WIR2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divergence from a random baseline is a technique for the evaluation of\ndocument clustering. It ensures cluster quality measures are performing work\nthat prevents ineffective clusterings from giving high scores to clusterings\nthat provide no useful result. These concepts are defined and analysed using\nintrinsic and extrinsic approaches to the evaluation of document cluster\nquality. This includes the classical clusters to categories approach and a\nnovel approach that uses ad hoc information retrieval. The divergence from a\nrandom baseline approach is able to differentiate ineffective clusterings\nencountered in the INEX XML Mining track. It also appears to perform a\nnormalisation similar to the Normalised Mutual Information (NMI) measure but it\ncan be applied to any measure of cluster quality. When it is applied to the\nintrinsic measure of distortion as measured by RMSE, subtraction from a random\nbaseline provides a clear optimum that is not apparent otherwise. This approach\ncan be applied to any clustering evaluation. This paper describes its use in\nthe context of document clustering evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2012 13:23:29 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2012 09:04:41 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["De Vries", "Christopher M.", ""], ["Geva", "Shlomo", ""], ["Trotman", "Andrew", ""]]}, {"id": "1208.6335", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Sushmit Mallik and Ravdeep Johar", "title": "Comparative Study and Optimization of Feature-Extraction Techniques for\n  Content based Image Retrieval", "comments": "8 pages, 16 figures, 11 tables", "journal-ref": "International Journal of Computer Applications 52(20):35-42, 2012", "doi": "10.5120/8320-1959", "report-no": "Volume 52, Number 20, 2012", "categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of a Content-Based Image Retrieval (CBIR) system, also known as Query\nby Image Content (QBIC), is to help users to retrieve relevant images based on\ntheir contents. CBIR technologies provide a method to find images in large\ndatabases by using unique descriptors from a trained image. The image\ndescriptors include texture, color, intensity and shape of the object inside an\nimage. Several feature-extraction techniques viz., Average RGB, Color Moments,\nCo-occurrence, Local Color Histogram, Global Color Histogram and Geometric\nMoment have been critically compared in this paper. However, individually these\ntechniques result in poor performance. So, combinations of these techniques\nhave also been evaluated and results for the most efficient combination of\ntechniques have been presented and optimized for each class of image query. We\nalso propose an improvement in image retrieval performance by introducing the\nidea of Query modification through image cropping. It enables the user to\nidentify a region of interest and modify the initial query to refine and\npersonalize the image retrieval results.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2012 23:50:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 01:34:05 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Chadha", "Aman", ""], ["Mallik", "Sushmit", ""], ["Johar", "Ravdeep", ""]]}]